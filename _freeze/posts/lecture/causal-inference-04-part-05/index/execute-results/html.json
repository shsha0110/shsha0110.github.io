{
  "hash": "bb72dc37ff0d8b09f9631068202488f5",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"[Causal Inference] 04. Confounding and Backdoor (Part 5)\"\njupyter: causal-inference-study\ndescription: \"Simpson's Paradox Simulation Using `DoWhy`: Stratification & Refutation\"\nauthor: \"유성현\"\ndate: \"2026-01-08\"\ncategories: [Causal Inference]\nformat:\n  html:\n    toc: true\n    number-sections: true\n    code-fold: true\n    mathjax: true\n---\n\n# Introduction\n\n* 이전 포스트들에서 배운 교란(Confounding)과 Back-door Criterion을 실제 코드로 구현해 보는 시간입니다. \n* 특히 **심슨의 역설(Simpson's Paradox)** 상황을 시뮬레이션하고, `DoWhy` 라이브러리의 **성향 점수 층화(Propensity Score Stratification)** 방법을 통해 올바른 인과 효과를 추정해 봅니다.\n\n# Python Practice: DoWhy Simulation\n\n이제 위 이론을 바탕으로 `DoWhy` 라이브러리를 사용해 인과 추론 프로세스를 단계별로 구현해 봅니다.\n\n# 데이터 생성 (Data Generation)\n\n나이(Age)가 운동(Exercise)과 콜레스테롤(Cholesterol) 모두에 영향을 주어, 단순 관찰 시 역설적인 결과가 나오도록 데이터를 생성합니다.\n\n::: {#cell-data-generation .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport dowhy\nfrom dowhy import CausalModel\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nnp.random.seed(42)\nN = 1000\n\n# (1) 교란 변수: 나이 (Age)\nage = np.random.randint(20, 70, size=N)\n\n# (2) 처치 변수: 운동 여부 (Exercise, 0 or 1)\n# 나이가 많을수록 운동할 확률이 높아짐 (교란 발생)\nprob_exercise = 1 / (1 + np.exp(-(age - 45) / 20))\nexercise = np.random.binomial(1, prob_exercise)\n\n# (3) 결과 변수: 콜레스테롤 (Cholesterol)\n# 나이가 많으면 콜레스테롤 증가 (+2.0 * Age)\n# 운동을 하면 콜레스테롤 감소 (True Effect = -10)\ncholesterol = 2.0 * age - 10 * exercise + np.random.normal(150, 10, size=N)\n\ndf = pd.DataFrame({\n    'Age': age, \n    'Exercise': exercise, \n    'Exercise_Prob': prob_exercise, \n    'Cholesterol': cholesterol\n})\n\n# 데이터 분포 확인 (나이에 따른 색상 구분)\nplt.figure(figsize=(8, 6))\nsns.scatterplot(\n    x='Exercise_Prob', \n    y='Cholesterol', \n    data=df, \n    hue='Age', \n    palette='viridis', \n    alpha=0.6\n)\nplt.title(\"Exercise Probability vs Cholesterol (Colored by Age)\")\nplt.xlabel(\"Probability of Exercise\")\nplt.legend(title='Age')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/data-generation-output-1.png){#data-generation width=668 height=523}\n:::\n:::\n\n\n# 단순 비교 (Naive Comparison)\n* 교란 변수를 고려하지 않고 단순히 운동한 사람과 안 한 사람의 평균 콜레스테롤을 비교해 봅니다.\n\n::: {#naive-estimation .cell execution_count=2}\n``` {.python .cell-code}\nmean_exercise = df[df['Exercise'] == 1]['Cholesterol'].mean()\nmean_no_exercise = df[df['Exercise'] == 0]['Cholesterol'].mean()\nnaive_effect = mean_exercise - mean_no_exercise\n\nprint(\"=\"*50)\nprint(f\"1. 단순 평균 비교 (Naive Estimate): {naive_effect:.4f}\")\nprint(\"   -> 운동한 사람의 콜레스테롤이 더 높게 나옴 (심슨의 역설)\")\nprint(\"=\"*50)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n==================================================\n1. 단순 평균 비교 (Naive Estimate): 11.5646\n   -> 운동한 사람의 콜레스테롤이 더 높게 나옴 (심슨의 역설)\n==================================================\n```\n:::\n:::\n\n\n# DoWhy를 이용한 인과 추론\n## 모델 정의 및 식별 (Modeling & Identification)\n* 인과 그래프(Graph)를 정의하고 Back-door 기준을 통해 식별 가능성을 확인합니다.\n\n::: {#dowhy-modeling .cell execution_count=3}\n``` {.python .cell-code}\n# 단계 1: 모델 정의 (Causal Graph 생성)\nmodel = CausalModel(\n    data=df,\n    treatment='Exercise',\n    outcome='Cholesterol',\n    common_causes=['Age'] # 교란 변수 지정\n)\n\n# 단계 2: 식별 (Identification)\nidentified_estimand = model.identify_effect()\nprint(identified_estimand)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEstimand type: EstimandType.NONPARAMETRIC_ATE\n\n### Estimand : 1\nEstimand name: backdoor\nEstimand expression:\n     d                         \n───────────(E[Cholesterol|Age])\nd[Exercise]                    \nEstimand assumption 1, Unconfoundedness: If U→{Exercise} and U→Cholesterol then P(Cholesterol|Exercise,Age,U) = P(Cholesterol|Exercise,Age)\n\n### Estimand : 2\nEstimand name: iv\nNo such variable(s) found!\n\n### Estimand : 3\nEstimand name: frontdoor\nNo such variable(s) found!\n\n```\n:::\n:::\n\n\n## 인과 효과 추정 (Estimation: Stratification)\n* 여기서는 성향 점수 층화(Propensity Score Stratification) 방법을 사용합니다. 나이가 비슷하여 운동할 확률(성향 점수)이 유사한 사람들끼리 묶어서 비교하는 방식입니다.\n\n::: {#dowhy-estimation .cell execution_count=4}\n``` {.python .cell-code}\n# 단계 3: 추정 (Estimation)\n# num_strata=5: 데이터를 성향 점수에 따라 5개 구간으로 나눔\nestimate = model.estimate_effect(\n    identified_estimand,\n    method_name=\"backdoor.propensity_score_stratification\",\n    method_params={'num_strata': 5, 'clipping_threshold': 5}\n)\n\nprint(\"=\"*50)\nprint(f\"2. 인과 효과 추정 (Causal Estimate): {estimate.value:.4f}\")\nprint(f\"   -> 실제 효과 (-10.0)에 매우 근접함\")\nprint(\"=\"*50)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n==================================================\n2. 인과 효과 추정 (Causal Estimate): -9.1264\n   -> 실제 효과 (-10.0)에 매우 근접함\n==================================================\n```\n:::\n:::\n\n\n# 결과 검증 (Refutation)\n* 구해진 인과 효과가 통계적으로 유의미하고 견고한지 검증하기 위해 **가짜 처치(Placebo)**와 랜덤 변수 추가(Random Common Cause) 테스트를 수행합니다.\n\n::: {#refutation .cell execution_count=5}\n``` {.python .cell-code}\nprint(\"\\n[검증 시작] 모델이 얼마나 튼튼한지 테스트합니다...\")\n\n# (1) 가짜 처치 검증 (Placebo Treatment)\n# 운동 여부를 랜덤으로 섞으면 효과가 0이 나와야 함\nrefute_placebo = model.refute_estimate(\n    identified_estimand,\n    estimate,\n    method_name=\"placebo_treatment_refuter\",\n    method_params={\"placebo_type\": \"permute_treatment\"}\n)\nprint(f\"\\n- Placebo Test (Expected 0): {refute_placebo.new_effect:.4f}\")\n\n# (2) 랜덤 공통 원인 검증 (Random Common Cause)\n# 아무 상관 없는 랜덤 변수를 추가해도 원래 효과(-10)가 유지되어야 함\nrefute_random = model.refute_estimate(\n    identified_estimand,\n    estimate,\n    method_name=\"random_common_cause\"\n)\nprint(f\"- Random Cause Test (Expected ~ -10): {refute_random.new_effect:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n[검증 시작] 모델이 얼마나 튼튼한지 테스트합니다...\n\n- Placebo Test (Expected 0): 0.0059\n- Random Cause Test (Expected ~ -10): -9.1264\n```\n:::\n:::\n\n\n# 최종 시각화 (Visualization)\n* 단순 비교했을 때와 교란 변수를 통제했을 때의 차이를 시각적으로 확인합니다.\n\n::: {#cell-final-visualization .cell execution_count=6}\n``` {.python .cell-code}\nplt.figure(figsize=(12, 5))\n\n# (왼쪽) 단순 비교 시각화\nplt.subplot(1, 2, 1)\nsns.boxplot(x='Exercise', y='Cholesterol', data=df)\nplt.title(f\"Naive Comparison\\n(Effect: {naive_effect:.2f})\")\n\n# (오른쪽) 나이 통제 후 시각화 (회귀선)\nplt.subplot(1, 2, 2)\nsns.scatterplot(x='Age', y='Cholesterol', hue='Exercise', data=df, alpha=0.5)\n\n# 운동 O/X 별 추세선\nsns.regplot(x='Age', y='Cholesterol', data=df[df['Exercise']==0], \n            scatter=False, label='No Exercise', color='blue')\nsns.regplot(x='Age', y='Cholesterol', data=df[df['Exercise']==1], \n            scatter=False, label='Exercise', color='orange')\n\nplt.title(f\"Controlled Comparison by Age\\n(True Effect: -10.0)\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Left: Naive View (Simpson's Paradox), Right: Controlled View (True Effect)](index_files/figure-html/final-visualization-output-1.png){#final-visualization width=1142 height=471}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}