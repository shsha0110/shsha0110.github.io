<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="유성현">
<meta name="dcterms.date" content="2026-01-31">
<meta name="description" content="VAE와 GNN을 결합하여 비선형 관계와 다양한 데이터 타입을 포괄하는 새로운 DAG 구조 학습 프레임워크 제안">

<title>[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks – shsha0110.github.io</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-5b4ad623e5705c0698d39aec6f10cf02.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<meta name="google-site-verification" content="wnUhrJyUH9DivslRuyTASn9K6KXZlRrojFuwYY1q2hI">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">shsha0110.github.io</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks</h1>
                  <div>
        <div class="description">
          VAE와 GNN을 결합하여 비선형 관계와 다양한 데이터 타입을 포괄하는 새로운 DAG 구조 학습 프레임워크 제안
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Paper Review</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>유성현 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 31, 2026</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction-the-challenge-of-structure-learning" id="toc-introduction-the-challenge-of-structure-learning" class="nav-link active" data-scroll-target="#introduction-the-challenge-of-structure-learning">1. Introduction: The Challenge of Structure Learning</a>
  <ul class="collapse">
  <li><a href="#the-combinatorial-problem-기존의-한계" id="toc-the-combinatorial-problem-기존의-한계" class="nav-link" data-scroll-target="#the-combinatorial-problem-기존의-한계">The Combinatorial Problem (기존의 한계)</a></li>
  <li><a href="#the-paradigm-shift-from-discrete-to-continuous" id="toc-the-paradigm-shift-from-discrete-to-continuous" class="nav-link" data-scroll-target="#the-paradigm-shift-from-discrete-to-continuous">The Paradigm Shift: From Discrete to Continuous</a>
  <ul class="collapse">
  <li><a href="#limitation-of-existing-continuous-methods" id="toc-limitation-of-existing-continuous-methods" class="nav-link" data-scroll-target="#limitation-of-existing-continuous-methods">Limitation of Existing Continuous Methods</a></li>
  </ul></li>
  <li><a href="#dag-gnn-a-deep-generative-approach" id="toc-dag-gnn-a-deep-generative-approach" class="nav-link" data-scroll-target="#dag-gnn-a-deep-generative-approach">DAG-GNN: A Deep Generative Approach</a>
  <ul class="collapse">
  <li><a href="#key-idea-vae-graph-neural-networks" id="toc-key-idea-vae-graph-neural-networks" class="nav-link" data-scroll-target="#key-idea-vae-graph-neural-networks">Key Idea: VAE + Graph Neural Networks</a></li>
  <li><a href="#a-new-acyclicity-constraint" id="toc-a-new-acyclicity-constraint" class="nav-link" data-scroll-target="#a-new-acyclicity-constraint">A New Acyclicity Constraint</a></li>
  </ul></li>
  <li><a href="#main-contributions" id="toc-main-contributions" class="nav-link" data-scroll-target="#main-contributions">Main Contributions</a></li>
  </ul></li>
  <li><a href="#background-and-related-work" id="toc-background-and-related-work" class="nav-link" data-scroll-target="#background-and-related-work">2. Background and Related Work</a>
  <ul class="collapse">
  <li><a href="#problem-definition-faithfulness-structure-learning" id="toc-problem-definition-faithfulness-structure-learning" class="nav-link" data-scroll-target="#problem-definition-faithfulness-structure-learning">Problem Definition: Faithfulness &amp; Structure Learning</a></li>
  <li><a href="#traditional-approaches-the-era-of-discrete-search" id="toc-traditional-approaches-the-era-of-discrete-search" class="nav-link" data-scroll-target="#traditional-approaches-the-era-of-discrete-search">Traditional Approaches: The Era of Discrete Search</a>
  <ul class="collapse">
  <li><a href="#score-based-approaches" id="toc-score-based-approaches" class="nav-link" data-scroll-target="#score-based-approaches">1) Score-based Approaches</a></li>
  <li><a href="#constraint-based-approaches" id="toc-constraint-based-approaches" class="nav-link" data-scroll-target="#constraint-based-approaches">2) Constraint-based Approaches</a></li>
  <li><a href="#hybrid-approaches-approximations" id="toc-hybrid-approaches-approximations" class="nav-link" data-scroll-target="#hybrid-approaches-approximations">3) Hybrid Approaches &amp; Approximations</a></li>
  </ul></li>
  <li><a href="#the-computational-bottleneck" id="toc-the-computational-bottleneck" class="nav-link" data-scroll-target="#the-computational-bottleneck">The Computational Bottleneck</a></li>
  <li><a href="#the-paradigm-shift-continuous-optimization" id="toc-the-paradigm-shift-continuous-optimization" class="nav-link" data-scroll-target="#the-paradigm-shift-continuous-optimization">The Paradigm Shift: Continuous Optimization</a></li>
  <li><a href="#neural-network-approaches" id="toc-neural-network-approaches" class="nav-link" data-scroll-target="#neural-network-approaches">Neural Network Approaches</a></li>
  </ul></li>
  <li><a href="#neural-dag-structure-learning" id="toc-neural-dag-structure-learning" class="nav-link" data-scroll-target="#neural-dag-structure-learning">3. Neural DAG Structure Learning</a>
  <ul class="collapse">
  <li><a href="#linear-structural-equation-model-linear-sem" id="toc-linear-structural-equation-model-linear-sem" class="nav-link" data-scroll-target="#linear-structural-equation-model-linear-sem">3.1. Linear Structural Equation Model (Linear SEM)</a>
  <ul class="collapse">
  <li><a href="#notation-및-정의" id="toc-notation-및-정의" class="nav-link" data-scroll-target="#notation-및-정의">Notation 및 정의</a></li>
  <li><a href="#선형-관계식-the-model" id="toc-선형-관계식-the-model" class="nav-link" data-scroll-target="#선형-관계식-the-model">선형 관계식 (The Model)</a></li>
  <li><a href="#from-structure-to-generation-derivation" id="toc-from-structure-to-generation-derivation" class="nav-link" data-scroll-target="#from-structure-to-generation-derivation">From Structure to Generation (Derivation)</a></li>
  </ul></li>
  <li><a href="#proposed-graph-neural-network-model" id="toc-proposed-graph-neural-network-model" class="nav-link" data-scroll-target="#proposed-graph-neural-network-model">3.2. Proposed Graph Neural Network Model</a>
  <ul class="collapse">
  <li><a href="#linear-sem-as-a-graph-neural-network" id="toc-linear-sem-as-a-graph-neural-network" class="nav-link" data-scroll-target="#linear-sem-as-a-graph-neural-network">Linear SEM as a Graph Neural Network</a></li>
  <li><a href="#the-dag-gnn-architecture" id="toc-the-dag-gnn-architecture" class="nav-link" data-scroll-target="#the-dag-gnn-architecture">The DAG-GNN Architecture</a></li>
  <li><a href="#generalizing-the-linear-sem-interpretation" id="toc-generalizing-the-linear-sem-interpretation" class="nav-link" data-scroll-target="#generalizing-the-linear-sem-interpretation">Generalizing the Linear SEM (Interpretation)</a></li>
  <li><a href="#note-on-implementation" id="toc-note-on-implementation" class="nav-link" data-scroll-target="#note-on-implementation">Note on Implementation</a></li>
  </ul></li>
  <li><a href="#model-learning-with-variational-autoencoder" id="toc-model-learning-with-variational-autoencoder" class="nav-link" data-scroll-target="#model-learning-with-variational-autoencoder">3.3. Model Learning with Variational Autoencoder</a>
  <ul class="collapse">
  <li><a href="#the-challenge-of-intractability" id="toc-the-challenge-of-intractability" class="nav-link" data-scroll-target="#the-challenge-of-intractability">The Challenge of Intractability</a></li>
  <li><a href="#the-evidence-lower-bound-elbo" id="toc-the-evidence-lower-bound-elbo" class="nav-link" data-scroll-target="#the-evidence-lower-bound-elbo">The Evidence Lower Bound (ELBO)</a></li>
  <li><a href="#architecture-encoder-and-decoder" id="toc-architecture-encoder-and-decoder" class="nav-link" data-scroll-target="#architecture-encoder-and-decoder">Architecture: Encoder and Decoder</a></li>
  </ul></li>
  <li><a href="#architecture-and-loss-function" id="toc-architecture-and-loss-function" class="nav-link" data-scroll-target="#architecture-and-loss-function">3.4. Architecture and Loss Function</a>
  <ul class="collapse">
  <li><a href="#distribution-specifications" id="toc-distribution-specifications" class="nav-link" data-scroll-target="#distribution-specifications">Distribution Specifications</a></li>
  <li><a href="#encoder-architecture-inference-model" id="toc-encoder-architecture-inference-model" class="nav-link" data-scroll-target="#encoder-architecture-inference-model">Encoder Architecture (Inference Model)</a></li>
  <li><a href="#decoder-architecture-generative-model" id="toc-decoder-architecture-generative-model" class="nav-link" data-scroll-target="#decoder-architecture-generative-model">Decoder Architecture (Generative Model)</a></li>
  <li><a href="#loss-function-derivation-elbo" id="toc-loss-function-derivation-elbo" class="nav-link" data-scroll-target="#loss-function-derivation-elbo">Loss Function Derivation (ELBO)</a></li>
  <li><a href="#a-note-on-latent-dimensions" id="toc-a-note-on-latent-dimensions" class="nav-link" data-scroll-target="#a-note-on-latent-dimensions">A Note on Latent Dimensions</a></li>
  </ul></li>
  <li><a href="#discrete-variables" id="toc-discrete-variables" class="nav-link" data-scroll-target="#discrete-variables">3.5. Discrete Variables</a>
  <ul class="collapse">
  <li><a href="#data-representation-one-hot-encoding" id="toc-data-representation-one-hot-encoding" class="nav-link" data-scroll-target="#data-representation-one-hot-encoding">Data Representation (One-Hot Encoding)</a></li>
  <li><a href="#encoder-and-prior-unchanged" id="toc-encoder-and-prior-unchanged" class="nav-link" data-scroll-target="#encoder-and-prior-unchanged">Encoder and Prior (Unchanged)</a></li>
  <li><a href="#decoder-modification-categorical-likelihood" id="toc-decoder-modification-categorical-likelihood" class="nav-link" data-scroll-target="#decoder-modification-categorical-likelihood">Decoder Modification (Categorical Likelihood)</a></li>
  <li><a href="#loss-function-modification-cross-entropy" id="toc-loss-function-modification-cross-entropy" class="nav-link" data-scroll-target="#loss-function-modification-cross-entropy">Loss Function Modification (Cross-Entropy)</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  </ul></li>
  <li><a href="#connection-to-linear-sem" id="toc-connection-to-linear-sem" class="nav-link" data-scroll-target="#connection-to-linear-sem">3.6. Connection to Linear SEM</a>
  <ul class="collapse">
  <li><a href="#step-1-from-vae-to-plain-autoencoder" id="toc-step-1-from-vae-to-plain-autoencoder" class="nav-link" data-scroll-target="#step-1-from-vae-to-plain-autoencoder">Step 1: From VAE to Plain Autoencoder</a></li>
  <li><a href="#step-2-from-nonlinear-to-linear-the-core-derivation" id="toc-step-2-from-nonlinear-to-linear-the-core-derivation" class="nav-link" data-scroll-target="#step-2-from-nonlinear-to-linear-the-core-derivation">Step 2: From Nonlinear to Linear (The Core Derivation)</a></li>
  <li><a href="#deriving-the-notears-loss" id="toc-deriving-the-notears-loss" class="nav-link" data-scroll-target="#deriving-the-notears-loss">Deriving the NOTEARS Loss</a></li>
  <li><a href="#summary-1" id="toc-summary-1" class="nav-link" data-scroll-target="#summary-1">Summary</a></li>
  </ul></li>
  <li><a href="#acyclicity-constraint" id="toc-acyclicity-constraint" class="nav-link" data-scroll-target="#acyclicity-constraint">3.7. Acyclicity Constraint</a>
  <ul class="collapse">
  <li><a href="#motivation-trace-and-cycles" id="toc-motivation-trace-and-cycles" class="nav-link" data-scroll-target="#motivation-trace-and-cycles">Motivation: Trace and Cycles</a></li>
  <li><a href="#the-matrix-exponential-previous-work" id="toc-the-matrix-exponential-previous-work" class="nav-link" data-scroll-target="#the-matrix-exponential-previous-work">The Matrix Exponential (Previous Work)</a></li>
  <li><a href="#proposed-solution-polynomial-constraint" id="toc-proposed-solution-polynomial-constraint" class="nav-link" data-scroll-target="#proposed-solution-polynomial-constraint">Proposed Solution: Polynomial Constraint</a></li>
  <li><a href="#stability-analysis-why-polynomial" id="toc-stability-analysis-why-polynomial" class="nav-link" data-scroll-target="#stability-analysis-why-polynomial">Stability Analysis (Why Polynomial?)</a></li>
  <li><a href="#summary-2" id="toc-summary-2" class="nav-link" data-scroll-target="#summary-2">Summary</a></li>
  </ul></li>
  <li><a href="#training" id="toc-training" class="nav-link" data-scroll-target="#training">3.8. Training</a>
  <ul class="collapse">
  <li><a href="#problem-formulation" id="toc-problem-formulation" class="nav-link" data-scroll-target="#problem-formulation">Problem Formulation</a></li>
  <li><a href="#the-augmented-lagrangian-method" id="toc-the-augmented-lagrangian-method" class="nav-link" data-scroll-target="#the-augmented-lagrangian-method">The Augmented Lagrangian Method</a></li>
  <li><a href="#algorithm-iterative-update-rule" id="toc-algorithm-iterative-update-rule" class="nav-link" data-scroll-target="#algorithm-iterative-update-rule">Algorithm: Iterative Update Rule</a></li>
  <li><a href="#hyperparameters-and-implementation" id="toc-hyperparameters-and-implementation" class="nav-link" data-scroll-target="#hyperparameters-and-implementation">Hyperparameters and Implementation</a></li>
  <li><a href="#summary-3" id="toc-summary-3" class="nav-link" data-scroll-target="#summary-3">Summary</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#experiments" id="toc-experiments" class="nav-link" data-scroll-target="#experiments">4. Experiments</a>
  <ul class="collapse">
  <li><a href="#synthetic-data-sets" id="toc-synthetic-data-sets" class="nav-link" data-scroll-target="#synthetic-data-sets">4.1. Synthetic Data Sets</a>
  <ul class="collapse">
  <li><a href="#linear-case" id="toc-linear-case" class="nav-link" data-scroll-target="#linear-case">4.1.1. Linear Case</a></li>
  <li><a href="#nonlinear-case-core-contribution" id="toc-nonlinear-case-core-contribution" class="nav-link" data-scroll-target="#nonlinear-case-core-contribution">4.1.2. Nonlinear Case (Core Contribution)</a></li>
  <li><a href="#vector-valued-case" id="toc-vector-valued-case" class="nav-link" data-scroll-target="#vector-valued-case">4.1.3. Vector-Valued Case</a></li>
  </ul></li>
  <li><a href="#benchmark-data-sets-discrete-variables" id="toc-benchmark-data-sets-discrete-variables" class="nav-link" data-scroll-target="#benchmark-data-sets-discrete-variables">4.2. Benchmark Data Sets (Discrete Variables)</a></li>
  <li><a href="#applications" id="toc-applications" class="nav-link" data-scroll-target="#applications">4.3. Applications</a>
  <ul class="collapse">
  <li><a href="#protein-signaling-network" id="toc-protein-signaling-network" class="nav-link" data-scroll-target="#protein-signaling-network">Protein Signaling Network</a></li>
  <li><a href="#knowledge-base-construction" id="toc-knowledge-base-construction" class="nav-link" data-scroll-target="#knowledge-base-construction">Knowledge Base Construction</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">5. Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="introduction-the-challenge-of-structure-learning" class="level1">
<h1>1. Introduction: The Challenge of Structure Learning</h1>
<ul>
<li><p>인과추론(Causal Inference)과 머신러닝의 교차점에서, 데이터의 생성 과정을 설명하는 <strong>방향성 비순환 그래프(Directed Acyclic Graph, DAG)</strong>를 학습하는 것은 매우 중요한 문제입니다. 이를 <strong>Structure Learning</strong>이라고 부릅니다.</p></li>
<li><p>Bayesian Network(BN)의 구조인 DAG는 변수 간의 조건부 독립성을 표현하며, Pearl(1988) 이후 의학, 유전학, 경제학 등 다양한 분야에서 인과관계를 파악하는 도구로 사용되어 왔습니다.</p></li>
<li><p>하지만 데이터의 결합 분포(Joint Distribution)로부터 “Faithful”한 DAG를 찾아내는 것은 악명 높은 난제입니다.</p></li>
</ul>
<blockquote class="blockquote">
<p><strong>Faithfulness란?</strong></p>
<p>그래프 <span class="math inline">\(G\)</span>와 결합 분포 <span class="math inline">\(\mathcal{P}\)</span>가 서로 “Faithful”하다는 것은, <span class="math inline">\(\mathcal{P}\)</span>에서 성립하는 모든 조건부 독립성이 그래프 <span class="math inline">\(G\)</span>에서도 (d-separation을 통해) 나타나고, 그 역도 성립함을 의미합니다.</p>
</blockquote>
<section id="the-combinatorial-problem-기존의-한계" class="level2">
<h2 class="anchored" data-anchor-id="the-combinatorial-problem-기존의-한계">The Combinatorial Problem (기존의 한계)</h2>
<ul>
<li><p>DAG 구조 학습이 어려운 근본적인 이유는 <strong>탐색 공간(Search Space)의 방대함</strong> 때문입니다.</p></li>
<li><p>노드(변수)의 개수가 늘어날 때, 가능한 그래프의 수는 초지수적(Superexponential)으로 증가합니다.</p></li>
<li><p>이는 NP-hard 문제로 알려져 있습니다.</p></li>
<li><p>전통적인 접근 방식은 크게 두 가지로 나뉩니다:</p></li>
<li><ol type="1">
<li><strong>Score-based Methods:</strong></li>
</ol>
<ul>
<li>가능한 그래프 구조에 대해 점수(BIC, BDeu 등)를 매기고, 이 점수를 최적화하는 그래프를 찾습니다.</li>
<li>하지만 그래프는 반드시 Acyclic(비순환)이어야 한다는 조합적 제약 조건(Combinatorial Constraint) 때문에, 전역 최적해를 찾는 것이 매우 어렵습니다.</li>
<li>따라서 탐욕적 탐색(Greedy Search)이나 트리 구조(Tree-structure) 가정 같은 근사법을 사용해야 했습니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Constraint-based Methods:</strong></li>
</ol>
<ul>
<li>변수 간의 조건부 독립성 검정(Independence Test)을 수행하여 엣지를 연결하거나 제거합니다 (예: PC Algorithm).</li>
<li>데이터 효율성이나 다중 가설 검정의 오류 문제 등이 존재합니다.</li>
</ul></li>
</ul>
</section>
<section id="the-paradigm-shift-from-discrete-to-continuous" class="level2">
<h2 class="anchored" data-anchor-id="the-paradigm-shift-from-discrete-to-continuous">The Paradigm Shift: From Discrete to Continuous</h2>
<ul>
<li>최근 <strong>Zheng et al.&nbsp;(2018)</strong>의 연구(흔히 <strong>NOTEARS</strong>로 알려짐)는 이 분야에 혁신적인 돌파구를 마련했습니다.</li>
<li>그들은 조합적 문제였던 “Acyclicity Constraint”를 미분 가능한 연속 함수 형태로 재정의했습니다.</li>
</ul>
<p><span class="math display">\[
h(A) = \text{Tr}(e^{A \circ A}) - d = 0
\]</span></p>
<ul>
<li>여기서 <span class="math inline">\(A\)</span>는 인접 행렬(Adjacency Matrix), <span class="math inline">\(d\)</span>는 노드의 개수입니다.</li>
<li>이 제약 조건 덕분에 구조 학습 문제는 이제 <strong>연속 최적화(Continuous Optimization)</strong> 문제로 변환되어, 경사 하강법(Gradient Descent)과 같은 표준적인 최적화 기법을 사용할 수 있게 되었습니다.</li>
</ul>
<section id="limitation-of-existing-continuous-methods" class="level3">
<h3 class="anchored" data-anchor-id="limitation-of-existing-continuous-methods">Limitation of Existing Continuous Methods</h3>
<ul>
<li>하지만 Zheng et al.&nbsp;(2018)의 접근법에도 한계가 있었습니다:
<ul>
<li><ol type="1">
<li><strong>선형성 가정 (Linearity Assumption):</strong> 기본적으로 선형 구조 방정식 모델(Linear SEM)을 가정합니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>분포의 제약:</strong> 최소제곱(Least-squares) 손실 함수를 사용하므로, 실제 데이터의 복잡한 분포를 반영하기 어렵습니다.</li>
</ol></li>
</ul></li>
<li>현실 세계의 데이터는 비선형적 관계를 가지며, 단순한 선형 모델로는 포착할 수 없는 복잡한 메커니즘으로 생성됩니다.</li>
</ul>
</section>
</section>
<section id="dag-gnn-a-deep-generative-approach" class="level2">
<h2 class="anchored" data-anchor-id="dag-gnn-a-deep-generative-approach">DAG-GNN: A Deep Generative Approach</h2>
<ul>
<li>본 논문(Yu et al., 2019)은 딥러닝의 강력한 표현력을 활용하여 기존의 선형 가정을 극복하고자 합니다. 저자들은 <strong>DAG-GNN</strong>이라는 새로운 아키텍처를 제안합니다.</li>
</ul>
<section id="key-idea-vae-graph-neural-networks" class="level3">
<h3 class="anchored" data-anchor-id="key-idea-vae-graph-neural-networks">Key Idea: VAE + Graph Neural Networks</h3>
<ul>
<li><p>이 모델의 핵심은 <strong>Variational Autoencoder (VAE)</strong> 프레임워크에 <strong>Graph Neural Network (GNN)</strong>을 결합한 것입니다.</p></li>
<li><p><strong>Deep Generative Model:</strong> 신경망은 “Universal Approximator”입니다. 이를 통해 변수 간의 복잡한 비선형 관계를 모델링합니다.</p></li>
<li><p><strong>Encoder/Decoder Parameterization:</strong> VAE의 인코더와 디코더를 일반적인 MLP가 아닌, 특별히 설계된 <strong>GNN</strong>으로 파라미터화합니다.</p></li>
<li><p><strong>Evidence Lower Bound (ELBO):</strong> 모델의 목적 함수(Score)는 VAE의 ELBO가 됩니다. 이는 데이터의 우도(Likelihood)를 최대화하는 방향으로 학습됨을 의미합니다.</p></li>
</ul>
</section>
<section id="a-new-acyclicity-constraint" class="level3">
<h3 class="anchored" data-anchor-id="a-new-acyclicity-constraint">A New Acyclicity Constraint</h3>
<ul>
<li><p>또한, 저자들은 NOTEARS에서 제안된 행렬 지수(Matrix Exponential) 제약 조건 대신, 딥러닝 프레임워크에서 구현하기 더 용이하고 수치적으로 안정적인 <strong>다항식(Polynomial) 형태의 새로운 제약 조건</strong>을 제안합니다.</p></li>
<li><p><strong>NOTEARS</strong> (Zheng et al., 2018): <span class="math inline">\(Tr(e^{A \circ A}) - d = 0\)</span></p></li>
<li><p><strong>DAG-GNN 제안:</strong> 수치적 안정성을 높인 변형된 형태를 사용합니다.</p></li>
</ul>
</section>
</section>
<section id="main-contributions" class="level2">
<h2 class="anchored" data-anchor-id="main-contributions">Main Contributions</h2>
<ul>
<li><p>이 논문의 Introduction에서 강조하는 주요 기여점은 다음과 같이 네 가지로 요약할 수 있습니다.</p></li>
<li><ol type="1">
<li><strong>Deep Generative Model 기반 접근:</strong></li>
</ol>
<ul>
<li>기존의 Linear SEM을 넘어, VAE를 사용하여 데이터의 복잡한 비선형 분포를 포착하고 샘플링할 수 있는 모델을 제안했습니다.</li>
<li>그래프 구조(Weighted Adjacency Matrix)는 잠재 변수가 아니라, 신경망 파라미터와 함께 학습되는 명시적인 파라미터로 설정됩니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>다양한 데이터 타입 지원:</strong></li>
</ol>
<ul>
<li>VAE 프레임워크의 특성상, 디코더의 출력 분포(Likelihood)를 적절히 설정함으로써 연속형 변수뿐만 아니라 이산형(Discrete) 변수도 자연스럽게 처리할 수 있습니다.</li>
</ul></li>
<li><ol start="3" type="1">
<li><strong>벡터 값 노드(Vector-valued Nodes) 지원:</strong></li>
</ol>
<ul>
<li>GNN을 사용하므로 각 노드가 단순 스칼라 값이 아닌 벡터 값을 가질 수 있습니다. 이는 각 노드가 여러 특징(Feature)을 가지는 복잡한 시나리오에 적용 가능함을 의미합니다.</li>
</ul></li>
<li><ol start="4" type="1">
<li><strong>개선된 Acyclicity Constraint:</strong></li>
</ol>
<ul>
<li>기존의 행렬 지수 제약 조건이 자동 미분(Automatic Differentiation) 라이브러리에서 구현하기 까다로울 수 있다는 점을 지적하며, 더 실용적이고 수치적으로 안정적인 다항식 기반의 대안을 제시했습니다.</li>
</ul></li>
</ul>
<hr>
</section>
</section>
<section id="background-and-related-work" class="level1">
<h1>2. Background and Related Work</h1>
<ul>
<li>DAG-GNN이 제안하는 새로운 방법론을 이해하기 위해서는, 먼저 <strong>구조 학습(Structure Learning)</strong>이 무엇인지, 그리고 지금까지 연구자들이 이 난제를 해결하기 위해 어떤 접근 방식을 취해왔는지 살펴볼 필요가 있습니다.</li>
<li>본 포스트에서는 논문의 <strong>Background</strong> 섹션을 바탕으로 인과 그래프 학습의 기술적 흐름을 정리합니다.</li>
</ul>
<section id="problem-definition-faithfulness-structure-learning" class="level2">
<h2 class="anchored" data-anchor-id="problem-definition-faithfulness-structure-learning">Problem Definition: Faithfulness &amp; Structure Learning</h2>
<ul>
<li>가장 먼저 정립해야 할 개념은 데이터와 그래프 사이의 관계입니다.</li>
<li>DAG(Directed Acyclic Graph) <span class="math inline">\(G\)</span>와 결합 분포(Joint Distribution) <span class="math inline">\(\mathcal{P}\)</span>가 서로 <strong>Faithful</strong>하다는 것은 다음을 의미합니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Faithfulness Condition (Pearl, 1988)</strong></p>
<p>분포 <span class="math inline">\(\mathcal{P}\)</span>에서 성립하는 모든 조건부 독립성(Conditional Independence)이 그래프 <span class="math inline">\(G\)</span>에서의 <strong>d-separation</strong> 조건에 의해 정확히 함의(entail)될 때, 그리고 그 역도 성립할 때 <span class="math inline">\(G\)</span>와 <span class="math inline">\(\mathcal{P}\)</span>는 Faithful하다고 합니다.</p>
</blockquote>
<ul>
<li><strong>구조 학습(Structure Learning)</strong>이란, 미지의 분포로부터 생성된 i.i.d. 샘플 데이터 <span class="math inline">\(D\)</span>가 주어졌을 때, 이 분포와 Faithful한 관계에 있는 (미지의) DAG <span class="math inline">\(G\)</span>를 복원해내는 과정을 말합니다.</li>
</ul>
</section>
<section id="traditional-approaches-the-era-of-discrete-search" class="level2">
<h2 class="anchored" data-anchor-id="traditional-approaches-the-era-of-discrete-search">Traditional Approaches: The Era of Discrete Search</h2>
<ul>
<li>전통적으로 DAG를 학습하는 알고리즘은 크게 <strong>Score-based</strong> 방법과 <strong>Constraint-based</strong> 방법으로 나뉩니다.</li>
</ul>
<section id="score-based-approaches" class="level3">
<h3 class="anchored" data-anchor-id="score-based-approaches">1) Score-based Approaches</h3>
<p>이 접근법은 그래프의 ’적합도’를 평가하는 점수(Score)를 정의하고, 이 점수를 최적화하는 그래프 구조를 탐색합니다.</p>
<ul>
<li><strong>점수 기준 (Score Criteria):</strong> 주로 베이지안 관점의 점수들이 사용됩니다. 대표적으로 BDeu, BIC(Bayesian Information Criterion) 등이 있으며, 이들은 <strong>Decomposable</strong>(분해 가능), <strong>Consistent</strong>(일치성), <strong>Score Equivalent</strong>(점수 등가성) 등의 좋은 수학적 성질을 가집니다.</li>
<li><strong>탐색 알고리즘 (Search Procedures):</strong> 가능한 모든 그래프를 탐색하는 것은 불가능하므로 다양한 전략이 사용됩니다.
<ul>
<li><em>Hill-climbing:</em> 지역적 최적해를 찾아가는 탐욕적 방법 (Heckerman et al., 1995 등)</li>
<li><em>Forward-backward search</em> (Chickering, 2002)</li>
<li><em>Dynamic Programming</em> (Singh &amp; Moore, 2005 등)</li>
<li><em>A* Search:</em> 최단 경로 탐색 알고리즘 응용 (Yuan &amp; Malone, 2013)</li>
<li><em>Integer Programming:</em> 정수 계획법을 통한 최적화 (Cussens, 2011 등)</li>
</ul></li>
</ul>
</section>
<section id="constraint-based-approaches" class="level3">
<h3 class="anchored" data-anchor-id="constraint-based-approaches">2) Constraint-based Approaches</h3>
<ul>
<li><p>이 방식은 변수 쌍 사이의 조건부 독립성 검정(Independence Test)을 수행하여 엣지의 존재 여부를 결정합니다.</p></li>
<li><p><strong>대표 알고리즘:</strong> SGS, PC (Spirtes et al.), IC (Pearl), FCI (Zhang) 등이 있습니다.</p></li>
<li><p>독립성 검정 결과를 바탕으로 엣지를 제거하거나 방향을 설정하여 그래프를 완성합니다.</p></li>
</ul>
</section>
<section id="hybrid-approaches-approximations" class="level3">
<h3 class="anchored" data-anchor-id="hybrid-approaches-approximations">3) Hybrid Approaches &amp; Approximations</h3>
<ul>
<li><p>순수한 Score-based나 Constraint-based 방법의 단점을 보완하기 위한 시도들도 있습니다.</p></li>
<li><p><strong>Hybrid:</strong> MMHC (Tsamardinos et al., 2003)와 같이 Constraint-based 방법으로 후보군을 줄인 뒤 Score-based로 최적화하는 방식입니다.</p></li>
<li><p><strong>Approximations:</strong> 탐색 공간을 줄이기 위해 Tree-width를 제한하거나(Nie et al., 2014), 트리 구조를 가정하는(Chow &amp; Liu, 1968) 등의 가정을 도입하기도 합니다.</p></li>
</ul>
</section>
</section>
<section id="the-computational-bottleneck" class="level2">
<h2 class="anchored" data-anchor-id="the-computational-bottleneck">The Computational Bottleneck</h2>
<ul>
<li><p>이러한 전통적 방법론들이 직면한 가장 큰 문제는 <strong>NP-Hardness</strong>입니다.</p></li>
<li><p>변수의 수가 늘어남에 따라 가능한 DAG의 수는 초지수적(Superexponential)으로 증가합니다.</p></li>
<li><p>따라서 많은 알고리즘이 이산형 변수(Discrete variables)로 대상을 한정하거나, 변수들이 결합 가우시안 분포(Jointly Gaussian)를 따른다고 가정해야만 했습니다.</p></li>
</ul>
</section>
<section id="the-paradigm-shift-continuous-optimization" class="level2">
<h2 class="anchored" data-anchor-id="the-paradigm-shift-continuous-optimization">The Paradigm Shift: Continuous Optimization</h2>
<ul>
<li><p>최근 <strong>Zheng et al.&nbsp;(2018)</strong>의 연구(NOTEARS)는 이 분야에 새로운 패러다임을 제시했습니다.</p></li>
<li><p><strong>핵심 아이디어:</strong> 이산적인 탐색 과정(Discrete Search Procedure)을 <strong>등식 제약조건(Equality Constraint)이 있는 연속 최적화 문제</strong>로 변환했습니다.</p></li>
<li><p><strong>장점:</strong> 경사 하강법(Gradient Descent)과 같은 연속 최적화 기법을 사용하여 DAG 구조를 학습할 수 있게 되었습니다.</p></li>
<li><p><strong>한계:</strong> 이 접근법은 구조 복원 성능이 우수하지만, 설명의 편의를 위해 <strong>선형 구조 방정식 모델(Linear SEM)</strong>에만 적용된다는 한계가 있었습니다.</p></li>
</ul>
</section>
<section id="neural-network-approaches" class="level2">
<h2 class="anchored" data-anchor-id="neural-network-approaches">Neural Network Approaches</h2>
<ul>
<li><p>최근에는 신경망(Neural Network)을 이용한 접근 방식도 등장하기 시작했습니다.</p></li>
<li><p><strong>GAN-style Approach (Kalainathan et al., 2018):</strong></p>
<ul>
<li>각 변수마다 별도의 생성 모델(Generative Model)을 두고, 생성된 샘플과 실제 데이터의 분포를 구분하는 판별자(Discriminator)를 두는 GAN 스타일의 방법론입니다.</li>
<li><strong>한계:</strong> 확장성(Scalability)은 좋아 보이지만, 결정적으로 <strong>비순환성(Acyclicity)이 강제되지 않는다</strong>는 문제가 있습니다. 즉, 학습된 결과가 DAG임을 보장할 수 없습니다.</li>
</ul></li>
</ul>
<blockquote class="blockquote">
<p><strong>Summary:</strong> 기존의 전통적 방법은 탐색 공간 문제로 확장이 어렵고, 최근 등장한 연속 최적화 방법(NOTEARS)은 선형성에 갇혀 있으며, 기존의 딥러닝 접근(GAN)은 DAG 구조를 보장하지 못합니다. <strong>DAG-GNN</strong>은 이러한 한계점들을 극복하기 위해 제안되었습니다.</p>
</blockquote>
<hr>
</section>
</section>
<section id="neural-dag-structure-learning" class="level1">
<h1>3. Neural DAG Structure Learning</h1>
<ul>
<li>본 논문은 선형 구조 방정식 모델(Linear SEM)을 일반화(Generalize)하여 딥러닝 기반의 생성 모델(Deep Generative Model)을 구축하는 것을 목표로 합니다.</li>
<li>첫 단계로, 가장 기본이 되는 <strong>Linear SEM</strong>의 수식적 구조와 그 의미를 먼저 명확히 짚고 넘어가겠습니다.</li>
</ul>
<section id="linear-structural-equation-model-linear-sem" class="level2">
<h2 class="anchored" data-anchor-id="linear-structural-equation-model-linear-sem">3.1. Linear Structural Equation Model (Linear SEM)</h2>
<ul>
<li>우리가 찾고자 하는 DAG(Directed Acyclic Graph)의 구조는 <strong>가중치가 있는 인접 행렬(Weighted Adjacency Matrix)</strong> <span class="math inline">\(A\)</span>로 표현됩니다.</li>
</ul>
<section id="notation-및-정의" class="level3">
<h3 class="anchored" data-anchor-id="notation-및-정의">Notation 및 정의</h3>
<ul>
<li><p>먼저 모델링에 필요한 변수들을 정의합니다.</p></li>
<li><p><strong><span class="math inline">\(m\)</span></strong>: 노드(변수)의 개수입니다.</p></li>
<li><p><strong><span class="math inline">\(A \in \mathbb{R}^{m \times m}\)</span></strong>:</p>
<ul>
<li>DAG의 가중치 인접 행렬입니다.</li>
<li><span class="math inline">\(A_{ij}\)</span>가 0이 아니라면 <span class="math inline">\(i\)</span>에서 <span class="math inline">\(j\)</span>로 가는 엣지가 존재함을 의미합니다.</li>
</ul></li>
<li><p><strong><span class="math inline">\(X \in \mathbb{R}^{m \times d}\)</span></strong>:</p>
<ul>
<li><span class="math inline">\(m\)</span>개의 변수에 대한 데이터 행렬입니다.</li>
<li>일반적인 문헌에서 변수는 스칼라(<span class="math inline">\(d=1\)</span>)로 취급되지만, 본 논문에서는 이를 <span class="math inline">\(d\)</span>-차원 벡터로 일반화(Generalize)하여 <strong>Vector-valued Node</strong>를 다룹니다.</li>
<li>각 행(Row)은 하나의 변수(노드)에 대응하고, 각 열(Column)은 해당 변수의 특징(Feature) 혹은 샘플 차원을 의미합니다.</li>
</ul></li>
<li><p><strong><span class="math inline">\(Z \in \mathbb{R}^{m \times d}\)</span></strong>:</p>
<ul>
<li>노이즈 행렬(Noise Matrix)입니다.</li>
<li>외생 변수(Exogenous variable)에 해당합니다.</li>
</ul></li>
</ul>
</section>
<section id="선형-관계식-the-model" class="level3">
<h3 class="anchored" data-anchor-id="선형-관계식-the-model">선형 관계식 (The Model)</h3>
<ul>
<li>Linear SEM은 변수 <span class="math inline">\(X\)</span>가 부모 변수들의 선형 결합(Linear Combination)과 노이즈 <span class="math inline">\(Z\)</span>의 합으로 생성된다고 가정합니다. 이를 행렬식으로 표현하면 다음과 같습니다.</li>
</ul>
<p><span id="eq-(1)"><span class="math display">\[
X = A^T X + Z
\tag{1}\]</span></span></p>
<ul>
<li>이 식은 <strong>“현재 노드의 값(<span class="math inline">\(X\)</span>)은 부모 노드들의 값(<span class="math inline">\(A^T X\)</span>)에 가중치를 곱해 더한 뒤, 고유한 노이즈(<span class="math inline">\(Z\)</span>)를 더한 것과 같다”</strong>는 인과적 메커니즘을 나타냅니다.</li>
</ul>
</section>
<section id="from-structure-to-generation-derivation" class="level3">
<h3 class="anchored" data-anchor-id="from-structure-to-generation-derivation">From Structure to Generation (Derivation)</h3>
<ul>
<li>이제 이 구조 방정식(Structural Equation)을 데이터를 생성하는 <strong>생성 모델(Generative Model)</strong>의 관점으로 전환해보겠습니다.</li>
<li>이를 위해서는 <span class="math inline">\(Z\)</span>에서 <span class="math inline">\(X\)</span>를 만들어내는 과정으로 수식을 변형해야 합니다.</li>
</ul>
<section id="topological-sort" class="level4">
<h4 class="anchored" data-anchor-id="topological-sort">Topological Sort</h4>
<ul>
<li><p>DAG의 가장 중요한 성질 중 하나는, 그래프 내에 사이클(Cycle)이 없기 때문에 모든 노드를 <strong>위상 정렬(Topological Order)</strong> 순서로 나열할 수 있다는 점입니다.</p></li>
<li><p>만약 노드들을 위상 정렬 순서대로 재배열한다면, 인접 행렬 <span class="math inline">\(A\)</span>는 <strong>엄격한 상삼각 행렬(Strictly Upper Triangular Matrix)</strong>이 됩니다.</p>
<ul>
<li>즉, 대각 성분과 그 아래 성분들이 모두 0이 됩니다 (<span class="math inline">\(A_{ij} = 0 \text{ for } i \ge j\)</span>).</li>
<li>이는 어떤 노드도 자기 자신이나 자신의 후손(descendant)으로부터 영향을 받지 않음을 수학적으로 보장합니다.</li>
</ul></li>
</ul>
</section>
<section id="transformation" class="level4">
<h4 class="anchored" data-anchor-id="transformation">Transformation</h4>
<ul>
<li>식 (1)을 <span class="math inline">\(X\)</span>에 대해 정리하는 과정을 단계별로 유도해보겠습니다.</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
X - A^T X &amp;= Z \\
(I - A^T)X &amp;= Z \\
X &amp;= (I - A^T)^{-1} Z
\end{aligned}
\]</span></p>
</section>
<section id="equivalence-with-ancestral-sampling" class="level4">
<h4 class="anchored" data-anchor-id="equivalence-with-ancestral-sampling">Equivalence with Ancestral Sampling</h4>
<p><span id="eq-(2)"><span class="math display">\[
X = (I - A^T)^{-1} Z
\tag{2}\]</span></span></p>
<ul>
<li>이 식은 <strong>“DAG를 따르는 Ancestral Sampling”</strong> 과정을 수학적으로 압축해 놓은 형태입니다. 그 이유를 단계별로 살펴보겠습니다.</li>
</ul>
<section id="ancestral-sampling이란" class="level5">
<h5 class="anchored" data-anchor-id="ancestral-sampling이란">Ancestral Sampling이란?</h5>
<ul>
<li><strong>Ancestral Sampling(조상 샘플링)</strong>은 베이지안 네트워크에서 데이터를 생성하는 가장 표준적인 방법입니다.</li>
<li>인과관계의 흐름(부모 <span class="math inline">\(\to\)</span> 자식)에 따라 순차적으로 값을 결정하는 방식입니다.
<ul>
<li><ol type="1">
<li><strong>Top-down:</strong> 부모가 없는 루트 노드(조상)의 값을 먼저 노이즈(<span class="math inline">\(Z\)</span>)로부터 결정합니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Propagation:</strong> 그 결정된 값이 자식 노드로 전파되어, 자식 노드의 값 결정에 영향을 줍니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li>이 과정을 위상 정렬(Topological Sort) 순서대로 끝까지 반복합니다.</li>
</ol></li>
</ul></li>
</ul>
</section>
<section id="neumann-series를-통한-연결" class="level5">
<h5 class="anchored" data-anchor-id="neumann-series를-통한-연결">Neumann Series를 통한 연결</h5>
<ul>
<li>식 (2) 의 역행렬 부분 <span class="math inline">\((I - A^T)^{-1}\)</span>을 <strong>노이만 급수(Neumann Series)</strong>를 이용해 전개합니다.</li>
</ul>
<p><span class="math display">\[
(I - A^T)^{-1} = I + A^T + (A^T)^2 + (A^T)^3 + \dots
\]</span></p>
<ul>
<li>이 전개식을 식 2에 대입하면 다음과 같습니다.</li>
</ul>
<p><span class="math display">\[
X = \underbrace{I \cdot Z}_{\text{Self}} + \underbrace{A^T \cdot Z}_{\text{Parents}} + \underbrace{(A^T)^2 \cdot Z}_{\text{Grandparents}} + \dots
\]</span></p>
</section>
<section id="행렬-거듭제곱ak의-의미" class="level5">
<h5 class="anchored" data-anchor-id="행렬-거듭제곱ak의-의미">행렬 거듭제곱(<span class="math inline">\(A^k\)</span>)의 의미</h5>
<ul>
<li>여기서 행렬의 거듭제곱 항들은 그래프 이론에서 <strong>경로(Path)</strong>의 개념과 일치합니다.
<ul>
<li><strong><span class="math inline">\(I\)</span> (0-hop):</strong> 자기 자신의 고유한 노이즈(<span class="math inline">\(Z\)</span>)입니다.</li>
<li><strong><span class="math inline">\(A^T\)</span> (1-hop):</strong> 부모 노드들로부터 직접 받는 영향입니다.</li>
<li><strong><span class="math inline">\((A^T)^2\)</span> (2-hop):</strong> 부모를 거쳐서 오는 <strong>조부모(Grandparents)</strong>의 영향입니다.</li>
<li><strong><span class="math inline">\((A^T)^k\)</span> (<span class="math inline">\(k\)</span>-hop):</strong> <span class="math inline">\(k\)</span>단계를 거쳐서 오는 <strong><span class="math inline">\(k\)</span>대 조상</strong>들의 영향입니다.</li>
</ul></li>
<li>즉, <span class="math inline">\(X = (I - A^T)^{-1} Z\)</span>라는 수식은 <strong>“나의 값(<span class="math inline">\(X\)</span>)은 내 고유한 성향(<span class="math inline">\(Z\)</span>)뿐만 아니라, 부모, 조부모 등 모든 조상들의 영향력이 누적되어 형성된 것이다”</strong>라는 Ancestral Sampling의 철학을 행렬 연산 한 번으로 표현한 것입니다.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="보충: 왜 거듭제곱이 경로인가? (수학적 귀납법 증명)">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>보충: 왜 거듭제곱이 경로인가? (수학적 귀납법 증명)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>행렬 <span class="math inline">\(A\)</span>의 거듭제곱 <span class="math inline">\(A^k\)</span>의 <span class="math inline">\((i, j)\)</span> 성분이 <strong>노드 <span class="math inline">\(i\)</span>에서 <span class="math inline">\(j\)</span>로 가는 길이 <span class="math inline">\(k\)</span>인 모든 경로의 가중치 합</strong>임을 수학적 귀납법으로 간단히 증명할 수 있습니다.</p>
<p><strong>명제 <span class="math inline">\(P(k)\)</span>:</strong> <span class="math inline">\((A^k)_{ij}\)</span>는 <span class="math inline">\(i \to j\)</span>로 가는 길이 <span class="math inline">\(k\)</span>인 경로들의 가중치 합이다.</p>
<p><strong>1. 기초 단계 (Base Case, <span class="math inline">\(k=1\)</span>):</strong> 정의에 의해 <span class="math inline">\((A^1)_{ij} = A_{ij}\)</span>입니다. 이는 <span class="math inline">\(i\)</span>에서 <span class="math inline">\(j\)</span>로 직접 연결된 엣지(길이 1)의 가중치이므로 명제 <span class="math inline">\(P(1)\)</span>은 참입니다.</p>
<p><strong>2. 귀납 가정 (Inductive Step):</strong> 임의의 자연수 <span class="math inline">\(k\)</span>에 대해 <span class="math inline">\(P(k)\)</span>가 참이라고 가정합니다. 즉, <span class="math inline">\((A^k)_{it}\)</span>는 <span class="math inline">\(i \to t\)</span>로 가는 길이 <span class="math inline">\(k\)</span>인 경로의 합입니다.</p>
<p>이제 <span class="math inline">\(k+1\)</span>일 때를 살펴봅니다. 행렬 곱셈의 정의에 따라: <span class="math display">\[
(A^{k+1})_{ij} = (A^k \cdot A)_{ij} = \sum_{t} (A^k)_{it} \cdot A_{tj}
\]</span></p>
<p>이 수식의 의미를 해석해 보면: * <span class="math inline">\((A^k)_{it}\)</span>: <span class="math inline">\(i\)</span>에서 중간 노드 <span class="math inline">\(t\)</span>까지 가는 길이 <span class="math inline">\(k\)</span>인 경로 (귀납 가정) * <span class="math inline">\(A_{tj}\)</span>: <span class="math inline">\(t\)</span>에서 도착 노드 <span class="math inline">\(j\)</span>로 가는 길이 <span class="math inline">\(1\)</span>인 엣지 * <span class="math inline">\(\sum_{t}\)</span>: 가능한 모든 중간 경유지 <span class="math inline">\(t\)</span>에 대해 합산</p>
<p>즉, <strong>“<span class="math inline">\(i\)</span>에서 <span class="math inline">\(t\)</span>까지 <span class="math inline">\(k\)</span>걸음으로 간 뒤, <span class="math inline">\(t\)</span>에서 <span class="math inline">\(j\)</span>로 1걸음 더 가는 모든 경우의 수”</strong>를 더한 것이므로, 이는 <span class="math inline">\(i\)</span>에서 <span class="math inline">\(j\)</span>로 가는 <strong>길이 <span class="math inline">\(k+1\)</span>인 모든 경로의 합</strong>과 같습니다.</p>
<p><strong>3. 결론:</strong> 수학적 귀납법에 의해 모든 자연수 <span class="math inline">\(k\)</span>에 대해 명제 <span class="math inline">\(P(k)\)</span>는 참입니다. 따라서 <span class="math inline">\((A^T)^k\)</span>는 <span class="math inline">\(k\)</span>단계를 거친 조상들의 영향력을 의미하게 됩니다.</p>
</div>
</div>
</div>
</section>
</section>
<section id="결론-vae-도입의-동기" class="level4">
<h4 class="anchored" data-anchor-id="결론-vae-도입의-동기">결론: VAE 도입의 동기</h4>
<ul>
<li>이러한 관점은 DAG 구조 학습 문제를 새로운 시각으로 바라보게 합니다.</li>
<li>복잡한 인과관계 추론 문제를 <strong>“노이즈 <span class="math inline">\(Z\)</span>를 데이터 <span class="math inline">\(X\)</span>로 매핑하는 인코더/디코더를 학습하는 문제”</strong>로 치환할 수 있습니다.</li>
<li>이것이 바로 저자들이 생성 모델의 대표 주자인 <strong>VAE(Variational Autoencoder)</strong>를 도입하여, 인코더와 디코더를 통해 <span class="math inline">\(A\)</span>를 학습하고자 한 핵심적인 <strong>동기(Motivation)</strong>입니다.</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="proposed-graph-neural-network-model" class="level2">
<h2 class="anchored" data-anchor-id="proposed-graph-neural-network-model">3.2. Proposed Graph Neural Network Model</h2>
<ul>
<li>앞선 섹션에서 우리는 Linear SEM이 다음과 같이 노이즈 <span class="math inline">\(Z\)</span>를 데이터 <span class="math inline">\(X\)</span>로 변환하는 선형 과정으로 표현됨을 확인했습니다.</li>
<li>본 섹션에서는 이 수식을 <strong>Graph Neural Network(GNN)</strong>의 관점에서 재해석하고, 이를 바탕으로 비선형 관계까지 포착할 수 있는 <strong>DAG-GNN</strong>만의 독창적인 아키텍처를 검토합니다.</li>
</ul>
<section id="linear-sem-as-a-graph-neural-network" class="level3">
<h3 class="anchored" data-anchor-id="linear-sem-as-a-graph-neural-network">Linear SEM as a Graph Neural Network</h3>
<ul>
<li>저자들은 위 식 (2)를 딥러닝 커뮤니티의 관점에서 다음과 같은 일반적인 함수 꼴로 바라봅니다.</li>
</ul>
<p><span class="math display">\[
X = f_A(Z)
\]</span></p>
<ul>
<li>여기서 <span class="math inline">\(f_A\)</span>는 그래프 구조(인접 행렬 <span class="math inline">\(A\)</span>)에 의해 파라미터화된 함수입니다.</li>
<li>즉, <strong>“노드 특징(Feature)인 <span class="math inline">\(Z\)</span>를 입력받아, 그래프 구조를 통과시켜 고차원 표현인 <span class="math inline">\(X\)</span>를 반환하는 과정”</strong>으로 해석할 수 있습니다.</li>
</ul>
<section id="existing-gnn-architectures" class="level4">
<h4 class="anchored" data-anchor-id="existing-gnn-architectures">Existing GNN Architectures</h4>
<ul>
<li>대부분의 최신 GNN 모델들(GCN, GraphSAGE, GAT 등)도 이와 유사한 형태를 띱니다.</li>
<li>예를 들어, 널리 쓰이는 <strong>GCN (Graph Convolutional Network)</strong>의 수식은 다음과 같습니다. <span class="math display">\[
X = \hat{A} \cdot \text{ReLU}(\hat{A} Z W^1) \cdot W^2
\]</span>
<ul>
<li><span class="math inline">\(\hat{A}\)</span>: 정규화된 인접 행렬 (Normalized Adjacency Matrix)</li>
<li><span class="math inline">\(W^1, W^2\)</span>: 학습 가능한 가중치 행렬</li>
</ul></li>
<li>하지만 일반적인 GNN은 주어진 고정된 그래프 위에서 노드 임베딩을 학습하는 것이 목표인 반면, 우리의 목표는 <strong>그래프 구조 <span class="math inline">\(A\)</span> 자체를 학습</strong>하는 것입니다.</li>
</ul>
</section>
</section>
<section id="the-dag-gnn-architecture" class="level3">
<h3 class="anchored" data-anchor-id="the-dag-gnn-architecture">The DAG-GNN Architecture</h3>
<ul>
<li>저자들은 Linear SEM의 구조적 특성(<span class="math inline">\((I-A^T)^{-1}\)</span>)을 그대로 계승하면서, 신경망의 표현력을 더하기 위해 <strong>새로운 GNN 아키텍처</strong>를 제안합니다.</li>
</ul>
<section id="the-proposed-equation" class="level4">
<h4 class="anchored" data-anchor-id="the-proposed-equation">The Proposed Equation</h4>
<p>제안하는 모델의 핵심 수식은 다음과 같습니다.</p>
<p><span id="eq-(3)"><span class="math display">\[
X = f_2 \left( (I - A^T)^{-1} f_1(Z) \right)
\tag{3}\]</span></span></p>
<ul>
<li><p>이 수식은 세 단계의 변환 과정으로 구성됩니다:</p></li>
<li><ol type="1">
<li><strong>Transforming Noise (<span class="math inline">\(f_1(Z)\)</span>):</strong></li>
</ol>
<ul>
<li>입력 노이즈 <span class="math inline">\(Z\)</span>를 비선형 함수 <span class="math inline">\(f_1\)</span> (MLP 등)을 통해 변환합니다.</li>
<li>이는 단순한 가우시안 노이즈가 아닌 복잡한 잠재 분포를 표현하기 위함입니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Structural Aggregation (<span class="math inline">\((I-A^T)^{-1}\)</span>):</strong></li>
</ol>
<ul>
<li>변환된 신호들이 DAG 구조 <span class="math inline">\(A\)</span>에 따라 전파(Propagation)됩니다.</li>
<li>이 부분은 Linear SEM의 인과적 흐름을 그대로 따르며, 부모 노드의 영향력이 자식 노드로 전달되는 과정을 수학적으로 구현합니다.</li>
</ul></li>
<li><ol start="3" type="1">
<li><strong>Transforming into Data Space (<span class="math inline">\(f_2(\cdot)\)</span>):</strong></li>
</ol>
<ul>
<li>구조적 정보가 반영된 신호를 다시 비선형 함수 <span class="math inline">\(f_2\)</span>를 통해 관측 데이터 공간(<span class="math inline">\(X\)</span>)으로 매핑합니다.</li>
</ul></li>
</ul>
</section>
</section>
<section id="generalizing-the-linear-sem-interpretation" class="level3">
<h3 class="anchored" data-anchor-id="generalizing-the-linear-sem-interpretation">Generalizing the Linear SEM (Interpretation)</h3>
<ul>
<li><p>이 모델이 중요한 이유는, 이것이 기존의 <strong>Linear SEM을 비선형(Non-linear)으로 일반화(Generalize)</strong>한 형태이기 때문입니다.</p></li>
<li><p>만약 <span class="math inline">\(f_2\)</span>가 <strong>역함수(Invertible)를 가진다</strong>고 가정해봅시다. 그렇다면 식 (3)의 양변에 <span class="math inline">\(f_2^{-1}\)</span>를 취하고 정리하여 다음과 같은 관계를 유도할 수 있습니다.</p></li>
</ul>
<section id="derivation" class="level4">
<h4 class="anchored" data-anchor-id="derivation">Derivation</h4>
<p><span class="math display">\[
\begin{aligned}
X &amp;= f_2((I - A^T)^{-1} f_1(Z)) \\
f_2^{-1}(X) &amp;= (I - A^T)^{-1} f_1(Z) \\
(I - A^T) f_2^{-1}(X) &amp;= f_1(Z) \\
f_2^{-1}(X) - A^T f_2^{-1}(X) &amp;= f_1(Z) \\
f_2^{-1}(X) &amp;= A^T f_2^{-1}(X) + f_1(Z)
\end{aligned}
\]</span></p>
</section>
<section id="generalized-sem" class="level4">
<h4 class="anchored" data-anchor-id="generalized-sem">Generalized SEM</h4>
<ul>
<li>결과적으로 다음과 같은 <strong>Generalized SEM</strong> 식을 얻게 됩니다.</li>
</ul>
<p><span class="math display">\[
\underbrace{f_2^{-1}(X)}_{\text{Transformed Data}} = A^T \underbrace{f_2^{-1}(X)}_{\text{Parents}} + \underbrace{f_1(Z)}_{\text{Transformed Noise}}
\]</span></p>
<ul>
<li><strong>Linear SEM (<span class="math inline">\(X = A^T X + Z\)</span>)과의 비교:</strong>
<ul>
<li>Linear SEM은 데이터 <span class="math inline">\(X\)</span> 자체가 선형 결합을 이룹니다.</li>
<li>DAG-GNN은 데이터 <span class="math inline">\(X\)</span>를 적절히 비선형 변환한 <strong><span class="math inline">\(f_2^{-1}(X)\)</span> 공간에서 선형 관계(<span class="math inline">\(A^T\)</span>)가 성립</strong>한다고 가정합니다.</li>
<li>또한 노이즈 역시 단순 합이 아니라 <span class="math inline">\(f_1(Z)\)</span> 형태로 비선형적으로 결합됩니다.</li>
</ul></li>
<li>이러한 설계를 통해 DAG-GNN은 변수 간의 관계가 복잡한 비선형일 때도, 이를 잠재 공간(Latent Space)에서의 구조적 관계로 포착할 수 있게 됩니다.</li>
</ul>
</section>
</section>
<section id="note-on-implementation" class="level3">
<h3 class="anchored" data-anchor-id="note-on-implementation">Note on Implementation</h3>
<ul>
<li>저자들은 <span class="math inline">\(f_1\)</span>과 <span class="math inline">\(f_2\)</span>를 구체적으로 어떤 신경망으로 구현할지에 대해서는 후속 섹션으로 미루고 있습니다.</li>
<li>다만 중요한 제약 사항 하나를 언급합니다:</li>
</ul>
<blockquote class="blockquote">
<p>“<span class="math inline">\(f_2\)</span>의 마지막 활성화 함수(Activation function)는 반드시 변수 <span class="math inline">\(X\)</span>의 타입(Domain)과 일치해야 한다.”</p>
</blockquote>
<ul>
<li>예를 들어, <span class="math inline">\(X\)</span>가 실수형(Continuous)이라면 Identity 함수를, 이진형(Binary)이라면 Sigmoid 등을 사용해야 한다는 뜻입니다. 이는 추후 논의될 <strong>Discrete Variable</strong> 처리를 위한 포석입니다.</li>
</ul>
<hr>
</section>
</section>
<section id="model-learning-with-variational-autoencoder" class="level2">
<h2 class="anchored" data-anchor-id="model-learning-with-variational-autoencoder">3.3. Model Learning with Variational Autoencoder</h2>
<ul>
<li>이제 우리의 목표는 주어진 데이터 <span class="math inline">\(X^1, \dots, X^n\)</span>을 가장 잘 설명하는 모델 파라미터(신경망 가중치 및 그래프 구조 <span class="math inline">\(A\)</span>)를 찾는 것입니다.</li>
<li>본 섹션에서는 이를 위해 <strong>Variational Autoencoder (VAE)</strong> 프레임워크를 도입하는 과정과 그 수학적 배경을 상세히 다룹니다.</li>
</ul>
<section id="the-challenge-of-intractability" class="level3">
<h3 class="anchored" data-anchor-id="the-challenge-of-intractability">The Challenge of Intractability</h3>
<ul>
<li><p>일반적으로 확률 모델의 학습은 관측 데이터의 <strong>로그 우도(Log-Likelihood)</strong>, 또는 <strong>로그 증거(Log-Evidence)</strong>를 최대화하는 방향으로 진행됩니다.</p></li>
<li><p>데이터 샘플 <span class="math inline">\(X^1, \dots, X^n\)</span>이 주어졌을 때, 평균 로그 증거는 다음과 같습니다.</p></li>
</ul>
<p><span class="math display">\[
\frac{1}{n} \sum_{k=1}^n \log p(X^k) = \frac{1}{n} \sum_{k=1}^n \log \int p(X^k | Z) p(Z) \, dZ
\]</span></p>
<ul>
<li>여기서 문제가 발생합니다.
<ul>
<li>우변의 적분 <span class="math inline">\(\int p(X^k | Z) p(Z) \, dZ\)</span>는 잠재 변수 <span class="math inline">\(Z\)</span>의 모든 가능한 값에 대해 주변화(Marginalization)를 수행해야 합니다.</li>
<li>하지만 <span class="math inline">\(Z\)</span>가 고차원이거나 <span class="math inline">\(p(X|Z)\)</span>가 복잡한 신경망(Neural Network)으로 구성된 경우, 이 적분은 해석적으로 구하는 것이 불가능하며(Intractable), 수치적으로 근사하기에도 계산 비용이 매우 큽니다.</li>
</ul></li>
<li>따라서 저자들은 이 문제를 해결하기 위해 <strong>변분 베이즈(Variational Bayes)</strong> 방법론을 도입합니다.</li>
</ul>
</section>
<section id="the-evidence-lower-bound-elbo" class="level3">
<h3 class="anchored" data-anchor-id="the-evidence-lower-bound-elbo">The Evidence Lower Bound (ELBO)</h3>
<ul>
<li>계산 불가능한 사후 분포 <span class="math inline">\(p(Z|X)\)</span>를 근사하기 위해, 우리는 다루기 쉬운 분포인 <strong>변분 사후 분포(Variational Posterior)</strong> <span class="math inline">\(q(Z|X)\)</span>를 도입합니다.</li>
</ul>
<section id="derivation-of-elbo" class="level4">
<h4 class="anchored" data-anchor-id="derivation-of-elbo">Derivation of ELBO</h4>
<ul>
<li><p>로그 증거 <span class="math inline">\(\log p(X)\)</span>에서 출발하여 <strong>ELBO(Evidence Lower Bound)</strong>를 유도하는 과정은 다음과 같습니다. (편의상 <span class="math inline">\(X^k\)</span>를 <span class="math inline">\(X\)</span>로 표기합니다.)</p></li>
<li><ol type="1">
<li><strong>로그 내부의 분모/분자에 <span class="math inline">\(q(Z|X)\)</span> 곱하기:</strong> <span class="math display">\[
  \begin{aligned}
  \log p(X) &amp;= \log \int p(X|Z) p(Z) \, dZ \\  
  &amp;= \log \int p(X, Z) \, dZ \\
  &amp;= \log \int p(X, Z) \frac{q(Z|X)}{q(Z|X)} \, dZ
  \end{aligned}
  \]</span></li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>기댓값 형태로 변환:</strong> <span class="math display">\[
  \begin{aligned}
  &amp;= \log \int \frac{p(X, Z)}{q(Z|X)} q(Z|X) \, dZ \\
  &amp;= \log \mathbb{E}_{q(Z|X)} \left[ \frac{p(X, Z)}{q(Z|X)} \right]
  \end{aligned}
  \]</span></li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>젠센 부등식(Jensen’s Inequality) 적용:</strong></li>
</ol>
<ul>
<li>로그 함수는 오목(Concave) 함수이므로 <span class="math inline">\(\log(\mathbb{E}[Y]) \ge \mathbb{E}[\log(Y)]\)</span>가 성립합니다. <span class="math display">\[
  \ge \mathbb{E}_{q(Z|X)} \left[ \log \frac{p(X, Z)}{q(Z|X)} \right]
  \]</span></li>
</ul></li>
<li><ol start="4" type="1">
<li><strong>항 분리 및 정리 (ELBO의 도출):</strong></li>
</ol>
<ul>
<li>로그의 성질을 이용해 항을 분리하고, <span class="math inline">\(Z\)</span>와 관련된 항들을 묶어 정리합니다.</li>
</ul>
<p><span class="math display">\[
  \begin{aligned}
  \mathcal{L} &amp;= \mathbb{E}_{q(Z|X)} \left[ \log \frac{p(X|Z)p(Z)}{q(Z|X)} \right] \\
  &amp;= \mathbb{E}_{q(Z|X)} \Big[ \log p(X|Z) + \underbrace{\log p(Z) - \log q(Z|X)}_{\text{Latent Variable Terms}} \Big]
  \end{aligned}
  \]</span></p>
<ul>
<li>여기서 <strong>KL Divergence(Kullback-Leibler Divergence)</strong>의 정의를 도입하여 식을 간결하게 정리할 수 있습니다.</li>
<li>두 확률분포 <span class="math inline">\(q\)</span>와 <span class="math inline">\(p\)</span>의 차이를 측정하는 KL Divergence는 다음과 같이 정의됩니다. <span class="math display">\[D_{\text{KL}}(q || p) = \mathbb{E}_{x \sim q} [ \log q(x) - \log p(x) ]\]</span></li>
<li>위 식의 뒷부분(<span class="math inline">\(\log p(Z) - \log q(Z|X)\)</span>)은 KL Divergence 정의와 부호가 반대입니다. 따라서 마이너스(<span class="math inline">\(-\)</span>)를 밖으로 빼내어 형태를 맞춥니다.</li>
</ul>
<p><span class="math display">\[
  \begin{aligned}
  &amp;= \mathbb{E}_{q(Z|X)} [\log p(X|Z)] - \mathbb{E}_{q(Z|X)} [\underbrace{\log q(Z|X) - \log p(Z)}_{D_{\text{KL}}(q||p) \text{ Form}} ] \\
  &amp;= \mathbb{E}_{q(Z|X)} [\log p(X|Z)] - D_{\text{KL}}(q(Z|X) || p(Z))
  \end{aligned}
  \]</span></p>
<ul>
<li>최종적으로 식 (4)에 해당하는 <strong>ELBO(Evidence Lower Bound)</strong>를 얻게 됩니다.</li>
</ul></li>
</ul>
<p><span id="eq-(4)"><span class="math display">\[
\mathcal{L}_{\text{ELBO}} \equiv -D_{\text{KL}} \Big( q(Z|X^k) \,||\, p(Z) \Big) + \mathbb{E}_{q(Z|X^k)} \Big[ \log p(X^k|Z) \Big]
\tag{4}\]</span></span></p>
</section>
<section id="interpretation-of-elbo" class="level4">
<h4 class="anchored" data-anchor-id="interpretation-of-elbo">Interpretation of ELBO</h4>
<ul>
<li><p>식 (4)는 두 가지 직관적인 항으로 구성됩니다.</p></li>
<li><ol type="1">
<li><strong>Reconstruction Loss:</strong> <span class="math inline">\(\mathbb{E}_{q(Z|X^k)} [\log p(X^k|Z)]\)</span></li>
</ol>
<ul>
<li>잠재 변수 <span class="math inline">\(Z\)</span>로부터 데이터 <span class="math inline">\(X\)</span>를 복원할 확률(Likelihood)을 최대화합니다.</li>
<li>Autoencoder의 복원 오차 최소화와 대응됩니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Regularization Term:</strong> <span class="math inline">\(-D_{\text{KL}}(q(Z|X^k) || p(Z))\)</span></li>
</ol>
<ul>
<li>우리가 근사한 사후 분포 <span class="math inline">\(q(Z|X)\)</span>가 사전 분포 <span class="math inline">\(p(Z)\)</span>(일반적으로 표준 정규분포)와 얼마나 다른지를 측정합니다.</li>
<li>이 차이를 최소화(음수이므로 최대화)하여, 잠재 공간이 과도하게 찌그러지는 것을 방지합니다.</li>
</ul></li>
<li><p>결론적으로, 실제 로그 증거와 ELBO의 차이는 KL Divergence <span class="math inline">\(D_{\text{KL}}(q(Z|X) || p(Z|X)) \ge 0\)</span> 만큼 발생하므로, <strong>ELBO를 최대화하는 것은 로그 증거의 하한(Lower Bound)을 최대화하는 것</strong>과 같습니다.</p></li>
</ul>
</section>
</section>
<section id="architecture-encoder-and-decoder" class="level3">
<h3 class="anchored" data-anchor-id="architecture-encoder-and-decoder">Architecture: Encoder and Decoder</h3>
<ul>
<li>VAE 프레임워크를 DAG-GNN에 적용하기 위해, Encoder와 Decoder를 구체적인 신경망 구조로 정의해야 합니다.</li>
</ul>
<section id="decoder-generative-model" class="level4">
<h4 class="anchored" data-anchor-id="decoder-generative-model">Decoder (Generative Model)</h4>
<ul>
<li>Decoder는 잠재 변수 <span class="math inline">\(Z\)</span>에서 데이터 <span class="math inline">\(X\)</span>를 생성하는 역할을 합니다.</li>
<li>이는 3.2절에서 정의한 <strong>Generalized SEM (식 3)</strong>과 정확히 일치합니다.</li>
</ul>
<p><span class="math display">\[
\text{Decoder: } \quad X = f_2 \left( (I - A^T)^{-1} f_1(Z) \right)
\]</span></p>
<ul>
<li>여기서 <span class="math inline">\((I-A^T)^{-1}\)</span> 항은 <span class="math inline">\(Z\)</span>의 정보가 그래프 구조를 따라 퍼져나가며(Propagation) <span class="math inline">\(X\)</span>를 형성하는 과정을 담당합니다.</li>
</ul>
</section>
<section id="encoder-inference-model" class="level4">
<h4 class="anchored" data-anchor-id="encoder-inference-model">Encoder (Inference Model)</h4>
<ul>
<li>Encoder는 관측된 데이터 <span class="math inline">\(X\)</span>로부터 잠재 변수 <span class="math inline">\(Z\)</span>를 추론하는 역할을 합니다.</li>
<li>저자들은 Decoder의 역연산 개념을 적용하여 다음과 같은 <strong>Encoder 구조</strong>를 제안합니다.</li>
</ul>
<p><span id="eq-(5)"><span class="math display">\[
\text{Encoder: } \quad Z = f_4 \left( (I - A^T) f_3(X) \right)
\tag{5}\]</span></span></p>
<ul>
<li>이 수식의 의미는 다음과 같습니다:
<ul>
<li><ol type="1">
<li><strong><span class="math inline">\(f_3(X)\)</span>:</strong></li>
</ol>
<ul>
<li>데이터 <span class="math inline">\(X\)</span>를 비선형 변환합니다. 개념적으로 Decoder의 <span class="math inline">\(f_2\)</span>의 역함수 역할을 수행합니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong><span class="math inline">\((I - A^T)\)</span>:</strong></li>
</ol>
<ul>
<li>Decoder에서는 역행렬 <span class="math inline">\((I-A^T)^{-1}\)</span>을 사용해 정보를 확산시켰다면, Encoder에서는 그 역연산인 <span class="math inline">\((I-A^T)\)</span>를 곱합니다.</li>
<li>이는 섞여 있는 정보들로부터 <strong>부모 노드의 영향을 제거</strong>하여 독립적인 노이즈(Latent factor)를 발라내는 과정으로 해석할 수 있습니다.</li>
</ul></li>
<li><ol start="3" type="1">
<li><strong><span class="math inline">\(f_4(\cdot)\)</span>:</strong></li>
</ol>
<ul>
<li>최종적으로 비선형 변환을 통해 <span class="math inline">\(Z\)</span> 공간으로 매핑합니다. 개념적으로 Decoder의 <span class="math inline">\(f_1\)</span>의 역함수 역할을 합니다.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="parameterization" class="level4">
<h4 class="anchored" data-anchor-id="parameterization">Parameterization</h4>
<ul>
<li><strong>함수:</strong> <span class="math inline">\(f_1, f_2\)</span> (Decoder)와 <span class="math inline">\(f_3, f_4\)</span> (Encoder)는 모두 MLP(Multi-Layer Perceptron)로 파라미터화됩니다.</li>
<li><strong>분포:</strong>
<ul>
<li><span class="math inline">\(q(Z|X)\)</span>와 <span class="math inline">\(p(X|Z)\)</span>는 각각 가우시안 분포 등을 가정하며, 신경망은 이 분포의 평균(<span class="math inline">\(\mu\)</span>)과 분산(<span class="math inline">\(\sigma^2\)</span>)을 출력하도록 설계됩니다.</li>
<li>구체적인 분포의 형태와 활성화 함수는 데이터 <span class="math inline">\(X\)</span>의 타입(연속형 vs 이산형)에 따라 결정됩니다.</li>
</ul></li>
</ul>
<hr>
</section>
</section>
</section>
<section id="architecture-and-loss-function" class="level2">
<h2 class="anchored" data-anchor-id="architecture-and-loss-function">3.4. Architecture and Loss Function</h2>
<ul>
<li>이전 섹션에서 우리는 DAG 구조 학습을 위한 VAE 프레임워크를 정의했습니다.</li>
<li>이제 추상적인 수식(<span class="math inline">\(f_1, f_2, f_3, f_4\)</span>)을 넘어, 실제로 모델을 어떻게 구현하고 학습시킬지 구체적인 <strong>Architecture</strong>와 <strong>Loss Function</strong>을 정의할 차례입니다.</li>
<li>이 과정에서 우리는 입력 데이터 <span class="math inline">\(X\)</span>와 잠재 변수 <span class="math inline">\(Z\)</span>의 확률 분포를 가정하고, 이를 바탕으로 ELBO(Evidence Lower Bound)를 계산 가능한 수식으로 유도합니다.</li>
</ul>
<section id="distribution-specifications" class="level3">
<h3 class="anchored" data-anchor-id="distribution-specifications">Distribution Specifications</h3>
<ul>
<li>모델 학습을 위해서는 변수들의 확률 분포를 명시해야 합니다.</li>
<li>여기서 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Z\)</span>는 모두 <span class="math inline">\(m \times d\)</span> 차원의 행렬입니다 (<span class="math inline">\(m\)</span>: 노드 수, <span class="math inline">\(d\)</span>: 특징 차원).</li>
</ul>
<section id="prior-distribution-pz" class="level4">
<h4 class="anchored" data-anchor-id="prior-distribution-pz">Prior Distribution <span class="math inline">\(p(Z)\)</span></h4>
<ul>
<li>잠재 변수 <span class="math inline">\(Z\)</span>의 사전 분포(Prior)는 가장 일반적인 가정인 <strong>Standard Matrix Normal</strong> 분포를 따릅니다.</li>
</ul>
<p><span class="math display">\[
p(Z) = \mathcal{MN}_{m \times d}(0, I, I)
\]</span></p>
<ul>
<li>이는 <span class="math inline">\(Z\)</span>의 모든 원소 <span class="math inline">\(Z_{ij}\)</span>가 평균이 0이고 분산이 1인 독립적인 정규분포(i.i.d. Gaussian)를 따른다는 것을 의미하며, 계산의 편의성을 위해 다음과 같이 요소별(element-wise) 분포로 취급할 수 있습니다. <span class="math display">\[p(Z_{ij}) = \mathcal{N}(0, 1)\]</span></li>
</ul>
</section>
</section>
<section id="encoder-architecture-inference-model" class="level3">
<h3 class="anchored" data-anchor-id="encoder-architecture-inference-model">Encoder Architecture (Inference Model)</h3>
<ul>
<li><p>Encoder는 데이터 <span class="math inline">\(X\)</span>를 입력받아 잠재 변수 <span class="math inline">\(Z\)</span>의 분포 <span class="math inline">\(q(Z|X)\)</span>를 추론합니다.</p></li>
<li><p><strong>가정:</strong> <span class="math inline">\(q(Z|X)\)</span>는 <strong>Factored Gaussian</strong> (대각 공분산을 갖는 정규분포)을 따른다고 가정합니다.</p></li>
<li><p><strong>구성:</strong> 평균 행렬 <span class="math inline">\(M_Z \in \mathbb{R}^{m \times d}\)</span>와 표준편차 행렬 <span class="math inline">\(S_Z \in \mathbb{R}^{m \times d}\)</span>를 출력합니다.</p></li>
<li><p><strong>함수 매핑:</strong></p>
<ul>
<li>앞선 섹션의 <span class="math inline">\(f_3\)</span> (데이터 변환): <strong>MLP (Multi-Layer Perceptron)</strong></li>
<li>앞선 섹션의 <span class="math inline">\(f_4\)</span> (잠재 공간 매핑): <strong>Identity Mapping</strong></li>
</ul></li>
<li><p>이를 수식으로 표현하면 다음과 같습니다.</p></li>
</ul>
<p><span id="eq-(6)"><span class="math display">\[
[M_Z | \log S_Z] = \underbrace{(I - A^T)}_{\text{Structure Removal}} \underbrace{\text{MLP}(X, W^1, W^2)}_{\text{Feature Transform}}
\tag{6}\]</span></span></p>
<ul>
<li>여기서 <span class="math inline">\(\text{MLP}(X, W^1, W^2) := \text{ReLU}(X W^1) W^2\)</span> 입니다.</li>
</ul>
<section id="interpretation" class="level4">
<h4 class="anchored" data-anchor-id="interpretation">Interpretation</h4>
<ul>
<li>식 (6)을 보면 <span class="math inline">\((I-A^T)\)</span> 연산이 MLP <strong>다음에</strong> 적용됩니다.</li>
<li>이는 MLP를 통해 데이터의 비선형 특징을 추출한 뒤, <span class="math inline">\((I-A^T)\)</span> 선형 변환을 통해 변수 간의 인과적 종속성(Parent effect)을 제거(Decorrelation)하여 독립적인 잠재 변수 <span class="math inline">\(Z\)</span>를 만들어내겠다는 의도입니다.</li>
</ul>
</section>
</section>
<section id="decoder-architecture-generative-model" class="level3">
<h3 class="anchored" data-anchor-id="decoder-architecture-generative-model">Decoder Architecture (Generative Model)</h3>
<ul>
<li><p>Decoder는 잠재 변수 <span class="math inline">\(Z\)</span>로부터 데이터 <span class="math inline">\(X\)</span>를 복원(Reconstruction)합니다.</p></li>
<li><p><strong>가정:</strong> <span class="math inline">\(p(X|Z)\)</span> 역시 <strong>Factored Gaussian</strong>을 따른다고 가정합니다.</p></li>
<li><p><strong>구성:</strong> 평균 행렬 <span class="math inline">\(M_X \in \mathbb{R}^{m \times d}\)</span>와 표준편차 행렬 <span class="math inline">\(S_X \in \mathbb{R}^{m \times d}\)</span>를 출력합니다.</p></li>
<li><p><strong>함수 매핑:</strong></p>
<ul>
<li>앞선 섹션의 <span class="math inline">\(f_1\)</span> (노이즈 변환): <strong>Identity Mapping</strong></li>
<li>앞선 섹션의 <span class="math inline">\(f_2\)</span> (데이터 복원): <strong>MLP</strong></li>
</ul></li>
<li><p>이를 수식으로 표현하면 다음과 같습니다.</p></li>
</ul>
<p><span id="eq-(7)"><span class="math display">\[
[M_X | \log S_X] = \underbrace{\text{MLP}}_{\text{Data Generation}} \left( \underbrace{(I - A^T)^{-1} Z}_{\text{Structure Propagation}}, W^3, W^4 \right)
\tag{7}\]</span></span></p>
<section id="interpretation-1" class="level4">
<h4 class="anchored" data-anchor-id="interpretation-1">Interpretation</h4>
<ul>
<li>저자들은 <span class="math inline">\(f_1\)</span>과 <span class="math inline">\(f_2\)</span>의 위치를 바꾸어 실험해 보았으나, 현재의 설계(내부에 Identity, 외부에 MLP)가 성능이 더 좋았다고 보고합니다.</li>
<li>그 이유는 식 (7)의 설계가 <strong>Linear SEM의 구조적 변환 <span class="math inline">\((I-A^T)^{-1}Z\)</span>를 강조</strong>하기 때문입니다.</li>
<li>구조적 전파(Propagation)가 먼저 일어난 뒤 MLP가 비선형성을 입히는 방식이 비선형 데이터 생성 과정을 더 잘 포착한다는 것입니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/dag_gnn_architecture_schematic.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: DAG-GNN의 전체 아키텍처 (Continuous Variables). 입력 <span class="math inline">\(X\)</span>가 MLP와 <span class="math inline">\((I-A^T)\)</span>를 거쳐 잠재 변수 <span class="math inline">\(Z\)</span>의 통계량(<span class="math inline">\(M_Z, S_Z\)</span>)으로 인코딩되고, 샘플링된 <span class="math inline">\(Z\)</span>는 <span class="math inline">\((I-A^T)^{-1}\)</span>와 MLP를 거쳐 다시 <span class="math inline">\(X\)</span>의 통계량(<span class="math inline">\(M_X, S_X\)</span>)으로 디코딩된다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="loss-function-derivation-elbo" class="level3">
<h3 class="anchored" data-anchor-id="loss-function-derivation-elbo">Loss Function Derivation (ELBO)</h3>
<ul>
<li>이제 정의된 분포(<span class="math inline">\(p(Z), q(Z|X), p(X|Z)\)</span>)를 바탕으로, VAE의 목적 함수인 <strong>ELBO</strong>를 구체적인 수식으로 유도해 봅시다.</li>
</ul>
<p><span class="math display">\[
\mathcal{L}_{\text{ELBO}} = -D_{\text{KL}}(q(Z|X) || p(Z)) + \mathbb{E}_{q(Z|X)}[\log p(X|Z)]
\]</span></p>
<section id="kl-divergence-term-regularization" class="level4">
<h4 class="anchored" data-anchor-id="kl-divergence-term-regularization">KL Divergence Term (Regularization)</h4>
<ul>
<li><p>이 항은 근사 분포 <span class="math inline">\(q(Z|X)\)</span>가 사전 분포 <span class="math inline">\(p(Z)\)</span>와 얼마나 다른지를 측정합니다.</p></li>
<li><p>두 분포가 모두 가우시안일 경우, 복잡한 적분 없이도 파라미터(<span class="math inline">\(M_Z, S_Z\)</span>)만으로 계산 가능한 <strong>Closed Form(닫힌 해)</strong>이 존재합니다.</p></li>
<li><p><strong>가정:</strong></p>
<ul>
<li><strong>Variational Posterior:</strong> <span class="math inline">\(q(Z|X) = \mathcal{N}(M_Z, S_Z^2)\)</span> (Factored Gaussian)</li>
<li><strong>Prior:</strong> <span class="math inline">\(p(Z) = \mathcal{N}(0, I)\)</span> (Standard Normal)</li>
</ul></li>
<li><p>모든 변수가 독립(Independent)이므로, 단일 원소 <span class="math inline">\(z \sim q(z) = \mathcal{N}(\mu, \sigma^2)\)</span>와 <span class="math inline">\(p(z) = \mathcal{N}(0, 1)\)</span> 사이의 KL Divergence를 먼저 유도한 뒤 합산하면 됩니다.</p></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="상세 유도: 두 가우시안 사이의 KL Divergence">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>상세 유도: 두 가우시안 사이의 KL Divergence
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>1. 정의:</strong> <span class="math display">\[D_{\text{KL}}(q||p) = \mathbb{E}_{z \sim q} [\log q(z) - \log p(z)]\]</span></p>
<p><strong>2. 로그 확률밀도함수 전개:</strong> <span class="math display">\[\log q(z) = -\frac{1}{2}\log(2\pi) - \log\sigma - \frac{(z-\mu)^2}{2\sigma^2}\]</span> <span class="math display">\[\log p(z) = -\frac{1}{2}\log(2\pi) - \frac{z^2}{2}\]</span></p>
<p><strong>3. 차이 계산:</strong> <span class="math display">\[
\begin{aligned}
\log q(z) - \log p(z) &amp;= \left( -\log\sigma - \frac{(z-\mu)^2}{2\sigma^2} \right) - \left( - \frac{z^2}{2} \right) \\
&amp;= -\log\sigma + \frac{1}{2}z^2 - \frac{(z-\mu)^2}{2\sigma^2}
\end{aligned}
\]</span></p>
<p><strong>4. 기댓값(<span class="math inline">\(\mathbb{E}_q\)</span>) 취하기:</strong> <span class="math inline">\(z \sim \mathcal{N}(\mu, \sigma^2)\)</span>일 때, <span class="math inline">\(\mathbb{E}[z^2] = \mu^2 + \sigma^2\)</span> 이고 <span class="math inline">\(\mathbb{E}[(z-\mu)^2] = \sigma^2\)</span> 임을 이용합니다.</p>
<p><span class="math display">\[
\begin{aligned}
\mathbb{E}_q [\dots] &amp;= -\log\sigma + \frac{1}{2}(\mu^2 + \sigma^2) - \frac{\sigma^2}{2\sigma^2} \\
&amp;= -\log\sigma + \frac{1}{2}\mu^2 + \frac{1}{2}\sigma^2 - \frac{1}{2} \\
&amp;= \frac{1}{2} (\sigma^2 + \mu^2 - 2\log\sigma - 1)
\end{aligned}
\]</span></p>
</div>
</div>
</div>
<ul>
<li>위의 스칼라 유도 결과를 행렬 전체(<span class="math inline">\(m \times d\)</span>)에 대해 합산하면 다음과 같습니다.</li>
</ul>
<p><span id="eq-(8)"><span class="math display">\[
D_{\text{KL}}\Big(q(Z|X) \,||\, p(Z)\Big) = \frac{1}{2} \sum_{i=1}^m \sum_{j=1}^d \left( \underbrace{(S_Z)_{ij}^2}_{\sigma^2} + \underbrace{(M_Z)_{ij}^2}_{\mu^2} - \underbrace{2\log(S_Z)_{ij}}_{2\log\sigma} - 1 \right)
\tag{8}\]</span></span></p>
<ul>
<li><strong>의의:</strong> 이 식은 적분(Sampling)이 필요 없으므로 계산이 매우 빠르고, 역전파(Backpropagation)를 통한 미분이 용이하여 안정적인 학습을 가능하게 합니다.</li>
<li><strong>역할:</strong> 잠재 변수 <span class="math inline">\(Z\)</span>가 평균 0, 분산 1인 분포에서 너무 멀어지지 않도록 강제하는 <strong>Regularizer</strong> 역할을 수행합니다.</li>
</ul>
</section>
<section id="reconstruction-term-likelihood" class="level4">
<h4 class="anchored" data-anchor-id="reconstruction-term-likelihood">Reconstruction Term (Likelihood)</h4>
<ul>
<li>두 번째 항은 모델이 잠재 변수 <span class="math inline">\(Z\)</span>로부터 관측 데이터 <span class="math inline">\(X\)</span>를 얼마나 잘 복원하는지를 나타내는 <strong>복원 오차(Reconstruction Error)</strong>입니다.</li>
<li>이 수식이 유도되는 과정은 <strong>Factored Gaussian 가정</strong>에 의해 다음과 같이 논리적으로 전개됩니다.</li>
</ul>
<section id="step-1-factored-gaussian-가정-행렬-to-스칼라-분해" class="level5">
<h5 class="anchored" data-anchor-id="step-1-factored-gaussian-가정-행렬-to-스칼라-분해"><strong>Step 1: Factored Gaussian 가정 (행렬 <span class="math inline">\(\to\)</span> 스칼라 분해)</strong></h5>
<ul>
<li><p>우리가 구해야 할 것은 전체 데이터 행렬 <span class="math inline">\(X\)</span>에 대한 우도 <span class="math inline">\(P(X|Z)\)</span>입니다.</p></li>
<li><p>앞서 우리는 <span class="math inline">\(p(X|Z)\)</span>가 <strong>Factored Gaussian</strong>을 따른다고 가정했습니다.</p></li>
<li><p>이는 <span class="math inline">\(Z\)</span>가 주어졌을 때 <span class="math inline">\(X\)</span>의 각 원소 <span class="math inline">\(X_{ij}\)</span>가 서로 <strong>조건부 독립(Conditionally Independent)</strong>임을 의미합니다.</p></li>
<li><p>따라서 결합 확률(Joint Probability)은 개별 스칼라 확률들의 곱으로 분해됩니다.</p></li>
</ul>
<p><span class="math display">\[
P(X|Z) = \prod_{i=1}^m \prod_{j=1}^d p(X_{ij} | Z)
\]</span></p>
</section>
<section id="step-2-로그-변환과-덧셈으로의-전환-prod-to-sum" class="level5">
<h5 class="anchored" data-anchor-id="step-2-로그-변환과-덧셈으로의-전환-prod-to-sum"><strong>Step 2: 로그 변환과 덧셈으로의 전환 (<span class="math inline">\(\prod \to \sum\)</span>)</strong></h5>
<ul>
<li>목적 함수는 <strong>로그 우도(Log-Likelihood)</strong>입니다. 양변에 로그를 취하면, 거대한 곱셈이 덧셈(Summation)으로 변환됩니다.</li>
</ul>
<p><span class="math display">\[
\log P(X|Z) = \sum_{i=1}^m \sum_{j=1}^d \log p(X_{ij} | Z)
\]</span></p>
<ul>
<li>이제 문제는 복잡한 행렬 연산에서 <strong>“개별 요소(<span class="math inline">\(X_{ij}\)</span>)의 스칼라 가우시안 로그 우도를 구해서 더하는 문제”</strong>로 단순화되었습니다.</li>
</ul>
</section>
<section id="step-3-스칼라-가우시안-로그-우도-계산" class="level5">
<h5 class="anchored" data-anchor-id="step-3-스칼라-가우시안-로그-우도-계산"><strong>Step 3: 스칼라 가우시안 로그 우도 계산</strong></h5>
<ul>
<li>단일 변수 <span class="math inline">\(x\)</span>가 평균 <span class="math inline">\(\mu\)</span>, 표준편차 <span class="math inline">\(\sigma\)</span>인 정규분포를 따를 때, 그 로그 확률밀도함수는 다음과 같습니다.</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\log p(x | \mu, \sigma) &amp;= \log \left( \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{(x-\mu)^2}{2\sigma^2}} \right) \\
&amp;= \underbrace{-\log(\sqrt{2\pi})}_{\text{Constant } c} - \log \sigma - \frac{(x - \mu)^2}{2\sigma^2}
\end{aligned}
\]</span></p>
<ul>
<li>이 식을 위 Step 2의 합산 기호 안에 대입합니다.</li>
</ul>
</section>
<section id="step-4-몬테카를로-근사-monte-carlo-approximation" class="level5">
<h5 class="anchored" data-anchor-id="step-4-몬테카를로-근사-monte-carlo-approximation"><strong>Step 4: 몬테카를로 근사 (Monte Carlo Approximation)</strong></h5>
<ul>
<li><p>마지막으로 기댓값 <span class="math inline">\(\mathbb{E}_{q(Z|X)}\)</span>를 계산하기 위해, 잠재 변수 <span class="math inline">\(Z\)</span>를 <span class="math inline">\(L\)</span>번 샘플링하여 그 평균으로 적분을 근사합니다.</p></li>
<li><p>이 모든 단계를 종합하면 식 (9)를 얻게 됩니다.</p></li>
</ul>
<p><span id="eq-(9)"><span class="math display">\[
\mathbb{E}_{q(Z|X)} \Big[ \log p(X|Z) \Big] \approx \frac{1}{L} \sum_{l=1}^L \sum_{i=1}^m \sum_{j=1}^d \left( \underbrace{- \frac{(X_{ij} - (M_X^{(l)})_{ij})^2}{2(S_X^{(l)})_{ij}^2}}_{\text{Weighted MSE}} \underbrace{- \log(S_X^{(l)})_{ij}}_{\text{Uncertainty Penalty}} \right) - c
\tag{9}\]</span></span></p>
<ul>
<li><strong>해석:</strong> 이 수식은 본질적으로 <strong>가중치(분산의 역수)가 적용된 MSE</strong>와, 모델이 불확실성(분산)을 무작정 키우는 것을 막는 <strong>Penalty(<span class="math inline">\(\log S_X\)</span>)</strong>의 합입니다.</li>
</ul>
</section>
</section>
</section>
<section id="a-note-on-latent-dimensions" class="level3">
<h3 class="anchored" data-anchor-id="a-note-on-latent-dimensions">A Note on Latent Dimensions</h3>
<ul>
<li>Linear SEM에서는 <span class="math inline">\(Z\)</span>를 단순한 “Noise”로 보기에 <span class="math inline">\(X\)</span>와 차원이 같아야 했습니다.</li>
<li>하지만 VAE 프레임워크에서 <span class="math inline">\(Z\)</span>는 <strong>Latent Factor</strong>로 해석됩니다.</li>
<li>따라서 <span class="math inline">\(Z\)</span>의 열(column) 차원을 <span class="math inline">\(X\)</span>의 차원 <span class="math inline">\(d\)</span>와 다르게 설정할 수 있습니다.</li>
<li>만약 데이터의 내재적 차원(Intrinsic Dimension)이 작다고 판단되면, <span class="math inline">\(Z\)</span>의 차원을 줄여서 모델의 파라미터 수(<span class="math inline">\(W^2, W^3\)</span>)를 줄이고 효율적인 표현을 학습할 수 있습니다.</li>
</ul>
<hr>
</section>
</section>
<section id="discrete-variables" class="level2">
<h2 class="anchored" data-anchor-id="discrete-variables">3.5. Discrete Variables</h2>
<ul>
<li><p>현실 세계의 인과관계 데이터는 키, 몸무게 같은 연속형(Continuous) 변수뿐만 아니라, 질병 유무, 성별, 등급과 같은 <strong>이산형(Discrete) 변수</strong>로 구성된 경우가 많습니다.</p></li>
<li><p>DAG-GNN의 가장 큰 장점 중 하나는 VAE(Variational Autoencoder) 프레임워크를 기반으로 하기 때문에, 데이터의 타입에 따라 <strong>우도(Likelihood) 분포만 적절히 교체</strong>해주면 자연스럽게 다양한 데이터 타입을 처리할 수 있다는 점입니다.</p></li>
<li><p>이번 포스트에서는 DAG-GNN이 이산형 변수를 어떻게 모델링하는지 그 수식적 변형 과정을 살펴보겠습니다.</p></li>
</ul>
<section id="data-representation-one-hot-encoding" class="level3">
<h3 class="anchored" data-anchor-id="data-representation-one-hot-encoding">Data Representation (One-Hot Encoding)</h3>
<ul>
<li><p>이산형 변수를 처리하기 위해 데이터 표현 방식부터 정의합니다.</p></li>
<li><p><strong>가정:</strong> 각 변수는 크기(Cardinality)가 <span class="math inline">\(d\)</span>인 유한한 지지 집합(Finite support)을 가집니다.</p></li>
<li><p><strong>입력 <span class="math inline">\(X\)</span>:</strong> <span class="math inline">\(X\)</span>의 각 행(변수)은 <strong>One-Hot Vector</strong>로 표현됩니다.</p>
<ul>
<li>즉, “On” 위치(값이 1인 인덱스)가 해당 변수의 범주(Category)를 나타냅니다.</li>
<li>따라서 <span class="math inline">\(X \in \mathbb{R}^{m \times d}\)</span> 차원을 유지합니다.</li>
</ul></li>
</ul>
</section>
<section id="encoder-and-prior-unchanged" class="level3">
<h3 class="anchored" data-anchor-id="encoder-and-prior-unchanged">Encoder and Prior (Unchanged)</h3>
<ul>
<li>이산형 데이터를 다룸에도 불구하고 <strong>Encoder(Inference Model)와 Prior는 연속형 모델과 동일</strong>하게 유지됩니다.</li>
<li><ol type="1">
<li><strong>Prior <span class="math inline">\(p(Z)\)</span>:</strong> 여전히 Standard Matrix Normal <span class="math inline">\(\mathcal{MN}(0, I, I)\)</span>을 따릅니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Posterior <span class="math inline">\(q(Z|X)\)</span>:</strong> Factored Gaussian 분포를 가정합니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Encoder 함수:</strong> 식 (6)의 구조를 그대로 사용합니다.</li>
</ol></li>
</ul>
<p><span class="math display">\[
[M_Z | \log S_Z] = (I - A^T) \text{MLP}(X)
\]</span></p>
<ul>
<li>이는 <strong>잠재 공간(Latent Space) <span class="math inline">\(Z\)</span>는 여전히 연속적인 공간</strong>으로 남겨두고, 이 공간에서 그래프 구조 학습과 변분 추론을 수행하겠다는 의도입니다.</li>
</ul>
</section>
<section id="decoder-modification-categorical-likelihood" class="level3">
<h3 class="anchored" data-anchor-id="decoder-modification-categorical-likelihood">Decoder Modification (Categorical Likelihood)</h3>
<ul>
<li>변화가 필요한 부분은 잠재 변수 <span class="math inline">\(Z\)</span>에서 다시 데이터 <span class="math inline">\(X\)</span>를 복원하는 <strong>Decoder(Generative Model)</strong> 파트입니다.</li>
<li><span class="math inline">\(X\)</span>가 이산형이므로, 더 이상 가우시안 분포를 가정할 수 없습니다.</li>
</ul>
<section id="distribution-assumption" class="level4">
<h4 class="anchored" data-anchor-id="distribution-assumption">Distribution Assumption</h4>
<ul>
<li><p>우리는 우도 <span class="math inline">\(p(X|Z)\)</span>를 <strong>Factored Categorical Distribution</strong>으로 가정합니다.</p></li>
<li><p><strong>출력:</strong> 확률 행렬 <span class="math inline">\(P_X \in \mathbb{R}^{m \times d}\)</span></p></li>
<li><p>각 행(Row)은 해당 변수가 각 범주에 속할 확률을 나타내는 확률 벡터(Probability Vector)가 됩니다.</p></li>
</ul>
</section>
<section id="architecture-change" class="level4">
<h4 class="anchored" data-anchor-id="architecture-change">Architecture Change</h4>
<ul>
<li><p>이를 구현하기 위해, Decoder의 마지막 변환 함수 <span class="math inline">\(f_2\)</span>를 <strong>Softmax</strong> 함수로 변경합니다.</p></li>
<li><p>기존 (Continuous): <span class="math inline">\(f_2 = \text{MLP}\)</span> (Identity mapping for output range)</p></li>
<li><p><strong>변경 (Discrete):</strong> <span class="math inline">\(f_2 = \text{softmax}(\text{MLP})\)</span></p></li>
<li><p>수식으로 표현하면 다음과 같습니다:</p></li>
</ul>
<p><span id="eq-(10)"><span class="math display">\[
P_X = \text{softmax} \left( \text{MLP} \big( (I - A^T)^{-1} Z, W^3, W^4 \big) \right)
\tag{10}\]</span></span></p>
<ul>
<li>여기서 <code>softmax</code>는 각 행(Row-wise)에 대해 적용되어, 각 변수의 범주별 확률 합이 1이 되도록 만듭니다.</li>
</ul>
</section>
</section>
<section id="loss-function-modification-cross-entropy" class="level3">
<h3 class="anchored" data-anchor-id="loss-function-modification-cross-entropy">Loss Function Modification (Cross-Entropy)</h3>
<ul>
<li><p>목적 함수인 ELBO(Evidence Lower Bound)의 두 항 중, KL Divergence 항은 <span class="math inline">\(q(Z|X)\)</span>와 <span class="math inline">\(p(Z)\)</span>가 변하지 않았으므로 식 (8) 그대로 유지됩니다.</p></li>
<li><p>하지만 <strong>Reconstruction Term (Likelihood)</strong>은 가우시안 로그 우도(MSE 형태)에서 <strong>Categorical 로그 우도</strong>로 변경되어야 합니다. 이는 머신러닝에서 흔히 쓰이는 <strong>Cross-Entropy Loss</strong>와 형태가 같습니다.</p></li>
</ul>
<section id="derivation-1" class="level4">
<h4 class="anchored" data-anchor-id="derivation-1">Derivation</h4>
<ul>
<li>Categorical 분포의 로그 우도는 관측된 클래스(<span class="math inline">\(X_{ij}=1\)</span>)의 예측 확률(<span class="math inline">\(P_{X_{ij}}\)</span>)에 로그를 취한 값입니다. 이를 몬테카를로 샘플링을 적용하여 정리하면 식 (11)을 얻습니다. <span id="eq-(11)"><span class="math display">\[
\mathbb{E}_{q(Z|X)} \Big[ \log p(X|Z) \Big] \approx \frac{1}{L} \sum_{l=1}^L \sum_{i=1}^m \sum_{j=1}^d X_{ij} \log (P_X^{(l)})_{ij} \quad \cdots (11)
\tag{11}\]</span></span></li>
<li><span class="math inline">\(L\)</span>: 몬테카를로 샘플 개수</li>
<li><span class="math inline">\(X_{ij}\)</span>: 실제 데이터의 One-hot 값 (0 또는 1)</li>
<li><span class="math inline">\((P_X^{(l)})_{ij}\)</span>: Decoder가 예측한 <span class="math inline">\(l\)</span>번째 샘플의 확률 값</li>
<li>이 식은 <span class="math inline">\(X\)</span>와 <span class="math inline">\(P_X\)</span> 사이의 Cross-Entropy를 계산하여, 모델이 실제 데이터의 범주를 정확하게 예측하도록 학습시킵니다.</li>
</ul>
</section>
</section>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<ul>
<li>DAG-GNN은 데이터 타입에 따라 모델의 핵심 구조(Encoder, Graph Operations, Latent Space)를 변경할 필요 없이, <strong>Decoder의 출력층(Softmax)과 손실 함수(Cross-Entropy)</strong>만 유연하게 교체하여 이산형 변수를 처리합니다.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">구분</th>
<th style="text-align: left;">연속형 (Continuous)</th>
<th style="text-align: left;">이산형 (Discrete)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Input <span class="math inline">\(X\)</span></strong></td>
<td style="text-align: left;">Real Values (<span class="math inline">\(\mathbb{R}^{m \times d}\)</span>)</td>
<td style="text-align: left;">One-hot Vectors (<span class="math inline">\(\mathbb{R}^{m \times d}\)</span>)</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Prior / Encoder</strong></td>
<td style="text-align: left;">Gaussian / MLP</td>
<td style="text-align: left;">Gaussian / MLP (동일)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Likelihood</strong></td>
<td style="text-align: left;">Gaussian <span class="math inline">\(\mathcal{N}(M_X, S_X)\)</span></td>
<td style="text-align: left;">Categorical <span class="math inline">\(P_X\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Output Function (<span class="math inline">\(f_2\)</span>)</strong></td>
<td style="text-align: left;">Identity / MLP</td>
<td style="text-align: left;">Softmax</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Reconstruction Loss</strong></td>
<td style="text-align: left;">Mean Squared Error (approx)</td>
<td style="text-align: left;">Cross Entropy</td>
</tr>
</tbody>
</table>
<ul>
<li>이러한 설계는 다양한 형태의 변수가 섞여 있는(Mixed type) 실제 데이터셋에도 쉽게 확장 적용할 수 있는 가능성을 보여줍니다.</li>
</ul>
<hr>
</section>
</section>
<section id="connection-to-linear-sem" class="level2">
<h2 class="anchored" data-anchor-id="connection-to-linear-sem">3.6. Connection to Linear SEM</h2>
<ul>
<li><p>지금까지 우리는 Linear SEM에서 출발하여 비선형성을 더하고(Non-linearity), VAE 프레임워크를 입혀(Probabilistic) DAG-GNN을 완성했습니다.</p></li>
<li><p>이제 저자들은 <strong>“역방향 사고(Reverse Thought Flow)”</strong>를 통해, DAG-GNN의 껍질을 하나씩 벗겨내면 결국 기존의 <strong>Linear SEM (Zheng et al., 2018, NOTEARS)</strong>과 수학적으로 완전히 일치함을 보입니다.</p></li>
<li><p>이 과정은 DAG-GNN이 근본 없는 블랙박스 모델이 아니라, 기존의 최적화 기반 구조 학습 이론을 <strong>확장(Extension)</strong>한 것임을 증명하는 중요한 이론적 토대가 됩니다.</p></li>
</ul>
<section id="step-1-from-vae-to-plain-autoencoder" class="level3">
<h3 class="anchored" data-anchor-id="step-1-from-vae-to-plain-autoencoder">Step 1: From VAE to Plain Autoencoder</h3>
<ul>
<li>가장 먼저, 확률적(Probabilistic) 모델인 VAE에서 변분(Variational) 요소를 제거하여 결정론적(Deterministic)인 <strong>Plain Autoencoder</strong>로 축소해 봅시다.</li>
</ul>
<section id="deterministic-setup" class="level4">
<h4 class="anchored" data-anchor-id="deterministic-setup">Deterministic Setup</h4>
<ul>
<li><p>확률 분포 <span class="math inline">\(q(Z|X)\)</span> 대신, 입력 <span class="math inline">\(X\)</span>가 주어졌을 때 잠재 변수 <span class="math inline">\(Z\)</span>가 고정된 값으로 결정된다고 가정합니다. 또한 비선형 함수 <span class="math inline">\(f_1 \dots f_4\)</span>는 그대로 유지합니다.</p></li>
<li><p><strong>Encoder (식 5 기반):</strong> <span class="math display">\[Z = f_4((I - A^T) f_3(X))\]</span></p></li>
<li><p><strong>Decoder (식 3 기반):</strong> <span class="math display">\[\hat{X} = f_2((I - A^T)^{-1} f_1(Z))\]</span></p>
<ul>
<li>여기서 <span class="math inline">\(\hat{X}\)</span>는 Decoder에 의해 복원된 값을 의미합니다.</li>
</ul></li>
</ul>
</section>
<section id="correspondence-of-loss-functions" class="level4">
<h4 class="anchored" data-anchor-id="correspondence-of-loss-functions">Correspondence of Loss Functions</h4>
<ul>
<li>일반적인 Autoencoder가 최소화하려는 손실 함수(Sample Loss)는 <strong>복원 오차(Reconstruction Error)</strong>와 <strong>잠재 변수 규제(Regularization)</strong>의 합으로 표현됩니다.</li>
</ul>
<p><span class="math display">\[
\mathcal{L}_{\text{AE}} = \underbrace{\frac{1}{2} \sum_{i=1}^m \sum_{j=1}^d (X_{ij} - \hat{X}_{ij})^2}_{\text{Reconstruction}} + \underbrace{\frac{1}{2} \sum_{i=1}^m \sum_{j=1}^d Z_{ij}^2}_{\text{Regularization}}
\]</span></p>
<ul>
<li><p>이 결정론적 손실 함수는 VAE의 <strong>ELBO</strong>와 정확히 대응됩니다:</p></li>
<li><ol type="1">
<li><strong>Reconstruction Term:</strong></li>
</ol>
<ul>
<li>ELBO의 복원 정확도 항(식 9)에서, <span class="math inline">\(S_X\)</span> (Decoder 분산)를 1로 고정하고 <span class="math inline">\(M_X\)</span> (Decoder 평균)를 <span class="math inline">\(\hat{X}\)</span>로 두면, 로그 우도 최대화는 곧 <strong>MSE(Mean Squared Error) 최소화</strong>와 같아집니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Regularization Term:</strong></li>
</ol>
<ul>
<li>ELBO의 KL Divergence 항(식 8)에서, <span class="math inline">\(S_Z\)</span> (Encoder 분산)를 1로 고정하고 <span class="math inline">\(M_Z\)</span> (Encoder 평균)를 <span class="math inline">\(Z\)</span>로 두면, KL 항은 <span class="math inline">\(\sum Z_{ij}^2\)</span>에 비례하게 됩니다. 이는 <strong>L2 Regularization</strong>과 같습니다.</li>
</ul></li>
</ul>
</section>
</section>
<section id="step-2-from-nonlinear-to-linear-the-core-derivation" class="level3">
<h3 class="anchored" data-anchor-id="step-2-from-nonlinear-to-linear-the-core-derivation">Step 2: From Nonlinear to Linear (The Core Derivation)</h3>
<ul>
<li>이제 두 번째 단계로, 모델의 <strong>비선형성(Non-linearity)</strong>을 제거해 봅시다. 즉, 모든 활성화 함수와 MLP를 걷어냅니다.</li>
</ul>
<section id="linear-assumptions" class="level4">
<h4 class="anchored" data-anchor-id="linear-assumptions">Linear Assumptions</h4>
<ul>
<li><p>모든 매핑 함수 <span class="math inline">\(f_1, f_2, f_3, f_4\)</span>를 <strong>항등 함수(Identity Mapping)</strong>로 가정합니다.</p></li>
<li><p>그렇다면 Encoder와 Decoder는 다음과 같이 단순한 선형 변환이 됩니다.</p></li>
<li><p><strong>Linear Encoder:</strong> <span class="math display">\[Z = (I - A^T) X\]</span></p></li>
<li><p><strong>Linear Decoder:</strong> <span class="math display">\[\hat{X} = (I - A^T)^{-1} Z\]</span></p></li>
</ul>
</section>
<section id="perfect-reconstruction" class="level4">
<h4 class="anchored" data-anchor-id="perfect-reconstruction">Perfect Reconstruction</h4>
<p>위 두 식을 결합하기 위해 Decoder 식의 <span class="math inline">\(Z\)</span> 자리에 Encoder 식을 대입합니다.</p>
<p><span class="math display">\[
\begin{aligned}
\hat{X} &amp;= (I - A^T)^{-1} \left( (I - A^T) X \right) \\
&amp;= \underbrace{(I - A^T)^{-1} (I - A^T)}_{I} X \\
&amp;= X
\end{aligned}
\]</span></p>
<ul>
<li>즉, 선형 모델 하에서는 입력 <span class="math inline">\(X\)</span>가 손실 없이 완벽하게 복원(<span class="math inline">\(\hat{X} = X\)</span>)됩니다.</li>
<li>따라서 손실 함수의 첫 번째 항인 <strong>Reconstruction Error는 0</strong>이 되어 사라집니다.</li>
</ul>
</section>
</section>
<section id="deriving-the-notears-loss" class="level3">
<h3 class="anchored" data-anchor-id="deriving-the-notears-loss">Deriving the NOTEARS Loss</h3>
<ul>
<li>이제 남은 것은 두 번째 항인 <strong>Regularization Term</strong> 뿐입니다.</li>
<li>여기에 Linear Encoder 식 <span class="math inline">\(Z = (I - A^T)X\)</span>를 대입하여 정리해 봅시다.</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\mathcal{L}_{\text{Linear}} &amp;= \frac{1}{2} \sum_{i=1}^m \sum_{j=1}^d Z_{ij}^2 \\
&amp;= \frac{1}{2} \| Z \|_F^2 \quad (\text{Frobenius Norm}) \\
&amp;= \frac{1}{2} \| (I - A^T) X \|_F^2 \quad \cdots (12)
\end{aligned}
\]</span></p>
<section id="result-and-interpretation" class="level4">
<h4 class="anchored" data-anchor-id="result-and-interpretation">Result and Interpretation</h4>
<ul>
<li>유도된 최종 식 (12) <span class="math inline">\(\frac{1}{2} \| (I - A^T) X \|_F^2\)</span>는 정확히 <strong>Zheng et al.&nbsp;(2018)</strong>이 제안한 <strong>NOTEARS 알고리즘의 손실 함수(Least-squares loss)</strong>와 일치합니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>의미 (Insight):</strong> * Linear SEM(NOTEARS)은 모델이 완벽하게 복원된다고 가정하고, 노이즈 <span class="math inline">\(Z\)</span>의 크기(L2 norm)를 최소화하는 문제로 해석될 수 있습니다. * <strong>DAG-GNN</strong>은 이를 확장하여, <strong>“완벽한 복원이 불가능한(비선형/노이즈 존재) 상황”</strong>까지 고려하기 위해 Reconstruction Loss 항을 추가하고, 비선형 변환을 도입한 일반화된 모델입니다.</p>
</blockquote>
</section>
</section>
<section id="summary-1" class="level3">
<h3 class="anchored" data-anchor-id="summary-1">Summary</h3>
<ul>
<li><ol type="1">
<li><strong>DAG-GNN (VAE + Nonlinear)</strong></li>
</ol>
<ul>
<li><span class="math inline">\(\downarrow\)</span> (Variational 제거: <span class="math inline">\(S_Z, S_X \to 1\)</span>)</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Deterministic Autoencoder (MSE + L2 Reg)</strong></li>
</ol>
<ul>
<li><span class="math inline">\(\downarrow\)</span> (Nonlinearity 제거: <span class="math inline">\(f \to Identity\)</span>)</li>
</ul></li>
<li><ol start="3" type="1">
<li><strong>Linear Model (Perfect Reconstruction, Reg only)</strong></li>
</ol>
<ul>
<li><span class="math inline">\(\downarrow\)</span> (<span class="math inline">\(Z = (I-A^T)X\)</span> 대입)</li>
</ul></li>
<li><ol start="4" type="1">
<li><strong>Linear SEM Loss (Zheng et al., 2018)</strong></li>
</ol></li>
<li>이로써 DAG-GNN은 Linear SEM의 탄탄한 이론적 기반 위에 서 있으면서도, 딥러닝의 표현력을 통해 더 복잡한 데이터 분포를 학습할 수 있는 모델임이 증명되었습니다.</li>
</ul>
<hr>
</section>
</section>
<section id="acyclicity-constraint" class="level2">
<h2 class="anchored" data-anchor-id="acyclicity-constraint">3.7. Acyclicity Constraint</h2>
<ul>
<li><p>앞선 섹션들에서 우리는 VAE 기반의 손실 함수(ELBO)와 선형/비선형 모델링을 정의했습니다.</p></li>
<li><p>하지만 여기에는 치명적인 허점이 하나 있습니다.</p></li>
<li><p>ELBO를 최대화하든, Least-squares loss를 최소화하든, 학습된 인접 행렬 <span class="math inline">\(A\)</span>가 <strong>DAG(비순환 그래프)</strong>라는 보장이 없다는 점입니다.</p></li>
<li><p>그래프 <span class="math inline">\(G\)</span>가 인과관계 모델이 되기 위해서는 반드시 사이클(Cycle)이 없어야 합니다.</p></li>
<li><p>이번 포스트에서는 이 조합적(Combinatorial) 제약 조건을 어떻게 연속적인(Continuous) 수식으로 변환하여 최적화 과정에 통합했는지 살펴봅니다.</p></li>
</ul>
<section id="motivation-trace-and-cycles" class="level3">
<h3 class="anchored" data-anchor-id="motivation-trace-and-cycles">Motivation: Trace and Cycles</h3>
<ul>
<li>그래프 이론에서 인접 행렬의 거듭제곱은 경로(Path)와 깊은 연관이 있습니다.</li>
</ul>
<section id="path-counting-logic" class="level4">
<h4 class="anchored" data-anchor-id="path-counting-logic">Path Counting Logic</h4>
<ul>
<li><p>가중치가 있는 인접 행렬 <span class="math inline">\(A\)</span>에 대해, 요소별 제곱(Element-wise square)을 수행하여 비음수(Non-negative) 행렬 <span class="math inline">\(B\)</span>를 정의해 봅시다 (<span class="math inline">\(B = A \circ A\)</span>).</p></li>
<li><p>행렬 <span class="math inline">\(B\)</span>의 <span class="math inline">\((i, j)\)</span> 요소가 양수라면, 노드 <span class="math inline">\(i\)</span>에서 <span class="math inline">\(j\)</span>로 가는 엣지가 존재함을 의미합니다.</p></li>
<li><p>행렬의 곱셈 성질에 따라, <span class="math inline">\(B^k\)</span>의 <span class="math inline">\((i, j)\)</span> 요소가 양수라는 것은 <strong>노드 <span class="math inline">\(i\)</span>에서 <span class="math inline">\(j\)</span>로 가는 길이가 <span class="math inline">\(k\)</span>인 경로가 존재함</strong>을 의미합니다.</p></li>
</ul>
</section>
<section id="detecting-cycles" class="level4">
<h4 class="anchored" data-anchor-id="detecting-cycles">Detecting Cycles</h4>
<ul>
<li><p>사이클이란 무엇일까요? 바로 <strong>자기 자신으로 돌아오는 경로(<span class="math inline">\(i \to \dots \to i\)</span>)</strong>입니다.</p></li>
<li><p>따라서, 어떤 정수 <span class="math inline">\(k\)</span>에 대해 <span class="math inline">\(B^k\)</span>의 대각 성분(Diagonal element) <span class="math inline">\((B^k)_{ii}\)</span>가 양수라면, 노드 <span class="math inline">\(i\)</span>를 포함하는 길이 <span class="math inline">\(k\)</span>의 사이클이 존재한다는 뜻입니다.</p></li>
<li><p>이 논리를 확장하면 다음과 같은 결론에 도달합니다.</p></li>
</ul>
<blockquote class="blockquote">
<p><strong>“모든 <span class="math inline">\(k &gt; 0\)</span>에 대해 <span class="math inline">\(B^k\)</span>의 대각 성분이 모두 0이라면(즉, Trace가 0이라면), 그 그래프는 DAG이다.”</strong></p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/adjacency_power_cycles.png" class="img-fluid figure-img"></p>
<figcaption>Figure: 인접 행렬의 거듭제곱과 사이클 검출의 원리. (A) 사이클이 있는 그래프 예시. (B) 인접 행렬 <span class="math inline">\(A\)</span>와 <span class="math inline">\(A^2, A^3\)</span> 계산 결과. 대각 성분에 0이 아닌 값이 등장하는 순간 사이클이 존재함을 수학적으로 알 수 있다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="the-matrix-exponential-previous-work" class="level3">
<h3 class="anchored" data-anchor-id="the-matrix-exponential-previous-work">The Matrix Exponential (Previous Work)</h3>
<ul>
<li><strong>Zheng et al.&nbsp;(2018)</strong>의 NOTEARS 알고리즘은 이 원리를 이용하여 <strong>행렬 지수(Matrix Exponential)</strong> 형태의 제약 조건을 제안했습니다.</li>
</ul>
<p><span class="math display">\[
h(A) = \text{tr}(e^{A \circ A}) - m = 0
\]</span></p>
<ul>
<li>이 수식은 테일러 급수 전개를 통해 이해할 수 있습니다.</li>
</ul>
<p><span class="math display">\[
e^B = I + B + \frac{B^2}{2!} + \frac{B^3}{3!} + \dots
\]</span></p>
<ul>
<li><span class="math inline">\(B\)</span>의 모든 거듭제곱(<span class="math inline">\(B^k\)</span>)의 합을 포함하므로, 어떤 길이의 사이클이라도 존재한다면 <span class="math inline">\(e^B\)</span>의 대각 성분 합(Trace)은 <span class="math inline">\(m\)</span> (항등 행렬 <span class="math inline">\(I\)</span>의 Trace)보다 커지게 됩니다.</li>
<li>수학적으로 매우 우아(Elegant)하지만, 실제 딥러닝 프레임워크에서 구현할 때 두 가지 문제가 있습니다.
<ol type="1">
<li><strong>자동 미분 지원 미비:</strong> 모든 플랫폼이 행렬 지수의 미분을 효율적으로 지원하지 않습니다.</li>
<li><strong>수치적 불안정성:</strong> <span class="math inline">\(e^B\)</span>는 값이 매우 빠르게 커지므로, 고유값(Eigenvalue)이 클 경우 오버플로우나 수치 오류가 발생하기 쉽습니다.</li>
</ol></li>
</ul>
</section>
<section id="proposed-solution-polynomial-constraint" class="level3">
<h3 class="anchored" data-anchor-id="proposed-solution-polynomial-constraint">Proposed Solution: Polynomial Constraint</h3>
<ul>
<li>저자들은 위 문제를 해결하기 위해, 행렬 지수 대신 <strong>다항식(Polynomial)</strong> 형태의 새로운 제약 조건을 제안합니다.</li>
</ul>
<section id="theorem-1-polynomial-acyclicity" class="level4">
<h4 class="anchored" data-anchor-id="theorem-1-polynomial-acyclicity">Theorem 1 (Polynomial Acyclicity)</h4>
<ul>
<li><span class="math inline">\(A \in \mathbb{R}^{m \times m}\)</span>를 유향 그래프의 가중치 인접 행렬이라고 합시다.</li>
<li>임의의 양수 <span class="math inline">\(\alpha &gt; 0\)</span>에 대하여, 다음 조건이 성립하면 그래프는 Acyclic입니다.</li>
</ul>
<p><span class="math display">\[
\text{tr}\left[ (I + \alpha A \circ A)^m \right] - m = 0 \quad \cdots (13)
\]</span></p>
</section>
<section id="derivation-proof-logic" class="level4">
<h4 class="anchored" data-anchor-id="derivation-proof-logic">Derivation &amp; Proof Logic</h4>
<ul>
<li><p>이 식이 성립하는 이유는 다음과 같습니다.</p></li>
<li><ol type="1">
<li><strong>최장 경로의 길이:</strong> 노드가 <span class="math inline">\(m\)</span>개인 그래프에서 사이클이 없다면(DAG라면), 존재할 수 있는 경로의 최대 길이는 <span class="math inline">\(m-1\)</span>입니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>이항 전개 (Binomial Expansion):</strong> <span class="math inline">\((I + \alpha B)^m\)</span>을 전개하면 다음과 같은 형태가 됩니다. <span class="math display">\[I + \binom{m}{1}\alpha B + \binom{m}{2}\alpha^2 B^2 + \dots + \alpha^m B^m\]</span></li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>포괄성:</strong> 이 식은 <span class="math inline">\(I\)</span>부터 <span class="math inline">\(B^m\)</span>까지의 모든 항을 양수 계수로 포함합니다.</li>
</ol></li>
<li><ol start="4" type="1">
<li><strong>결론:</strong> 만약 그래프에 사이클이 있다면, <span class="math inline">\(m\)</span> 이하의 어떤 길이 <span class="math inline">\(k\)</span>에 대해 <span class="math inline">\(B^k\)</span>의 Trace가 양수가 될 것입니다. 위 식은 <span class="math inline">\(B^1\)</span>부터 <span class="math inline">\(B^m\)</span>까지 모든 거듭제곱의 합을 검사하므로, 사이클이 하나라도 있다면 전체 Trace는 <span class="math inline">\(m\)</span> (<span class="math inline">\(I\)</span>의 Trace)보다 반드시 커지게 됩니다.</li>
</ol></li>
<li><p>따라서 식 (13)을 0으로 만드는 제약 조건은 그래프가 DAG임을 보장합니다.</p></li>
</ul>
</section>
</section>
<section id="stability-analysis-why-polynomial" class="level3">
<h3 class="anchored" data-anchor-id="stability-analysis-why-polynomial">Stability Analysis (Why Polynomial?)</h3>
<ul>
<li>왜 <span class="math inline">\(e^B\)</span> 대신 <span class="math inline">\((I + \alpha B)^m\)</span>을 써야 할까요? 저자들은 <strong>Theorem 2</strong>를 통해 수치적 안정성을 증명합니다.</li>
</ul>
<section id="theorem-2-comparison" class="level4">
<h4 class="anchored" data-anchor-id="theorem-2-comparison">Theorem 2 (Comparison)</h4>
<ul>
<li><span class="math inline">\(\alpha = c/m &gt; 0\)</span> (단, <span class="math inline">\(c\)</span>는 상수)라고 설정하면, 임의의 복소수 <span class="math inline">\(\lambda\)</span>에 대해 다음 부등식이 성립합니다.</li>
</ul>
<p><span class="math display">\[
(1 + \alpha |\lambda|)^m \le e^{c|\lambda|}
\]</span></p>
</section>
<section id="interpretation-2" class="level4">
<h4 class="anchored" data-anchor-id="interpretation-2">Interpretation</h4>
<ul>
<li><strong>좌변:</strong> 제안된 다항식 제약 조건의 성장 속도와 관련됨.</li>
<li><strong>우변:</strong> 기존 행렬 지수 제약 조건의 성장 속도와 관련됨.</li>
<li>이 부등식은 <strong>다항식 제약 조건이 지수 함수보다 훨씬 완만하게 증가함</strong>을 보여줍니다.</li>
<li>즉, <span class="math inline">\(B\)</span>의 고유값(Eigenvalue) 크기가 클 때, 다항식 기반 제약 조건이 수치적 폭발(Numerical difficulty)을 겪을 위험이 훨씬 적습니다 (“less severe”).</li>
</ul>
</section>
<section id="practical-implementation" class="level4">
<h4 class="anchored" data-anchor-id="practical-implementation">Practical Implementation</h4>
<ul>
<li>실제 구현에서 <span class="math inline">\(\alpha\)</span>는 하이퍼파라미터로 취급됩니다.</li>
<li>이론적으로 <span class="math inline">\(\alpha\)</span>는 <span class="math inline">\(B\)</span>의 가장 큰 고유값(Spectral radius)에 의존합니다.</li>
<li>Perron-Frobenius 정리에 따라, 비음수 행렬 <span class="math inline">\(B\)</span>의 Spectral radius는 최대 행 합(Maximum row sum)에 의해 제한(Bounded)되므로, 이를 참고하여 <span class="math inline">\(\alpha\)</span>를 설정할 수 있습니다.</li>
</ul>
</section>
</section>
<section id="summary-2" class="level3">
<h3 class="anchored" data-anchor-id="summary-2">Summary</h3>
<ul>
<li><p>DAG-GNN은 구조 학습의 핵심인 Acyclicity Constraint를 현대적인 딥러닝 환경에 맞게 재설계했습니다.</p></li>
<li><ol type="1">
<li><strong>기존:</strong> <span class="math inline">\(h(A) = \text{tr}(e^{A \circ A}) - m = 0\)</span> (NOTEARS)</li>
</ol>
<ul>
<li>우아하지만 구현이 어렵고 불안정할 수 있음.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>제안:</strong> <span class="math inline">\(h(A) = \text{tr}((I + \alpha A \circ A)^m) - m = 0\)</span> (DAG-GNN)</li>
</ol>
<ul>
<li><strong>Finite Power:</strong> <span class="math inline">\(m\)</span>차수까지만 검사해도 충분함 (DAG의 성질).</li>
<li><strong>Stability:</strong> 지수 함수보다 완만하게 증가하여 수치적으로 안정적.</li>
<li><strong>Convenience:</strong> 일반적인 행렬 곱셈만으로 구현 가능하여 모든 딥러닝 프레임워크와 호환됨.</li>
</ul></li>
<li><p>이로써 DAG-GNN은 VAE를 통한 확률적 모델링, GNN을 통한 비선형성 확보, 그리고 Polynomial Constraint를 통한 구조적 보장까지 갖춘 완전한 프레임워크가 되었습니다.</p></li>
</ul>
<hr>
</section>
</section>
<section id="training" class="level2">
<h2 class="anchored" data-anchor-id="training">3.8. Training</h2>
<ul>
<li>지금까지 우리는 DAG-GNN의 두 가지 핵심 기둥을 세웠습니다.
<ul>
<li><ol type="1">
<li><strong>Objective:</strong> 데이터를 잘 설명하기 위한 VAE의 손실 함수 (Negative ELBO).</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Constraint:</strong> 그래프가 DAG임을 보장하기 위한 다항식 제약 조건 (<span class="math inline">\(h(A) = 0\)</span>).</li>
</ol></li>
</ul></li>
<li>이제 이 두 가지를 하나로 묶어 실제 학습을 수행하는 <strong>최적화 전략(Optimization Strategy)</strong>을 다룰 차례입니다.</li>
<li>이 문제는 전형적인 <strong>비선형 등식 제약 최적화(Nonlinear Equality-Constrained Optimization)</strong> 문제입니다.</li>
</ul>
<section id="problem-formulation" class="level3">
<h3 class="anchored" data-anchor-id="problem-formulation">Problem Formulation</h3>
<ul>
<li>전체 학습 문제는 다음과 같은 최적화 문제로 정식화됩니다.</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\min_{A, \theta} \quad &amp; f(A, \theta) \equiv -L_{\text{ELBO}} \\
\text{s.t.} \quad &amp; h(A) \equiv \text{tr}[(I + \alpha A \circ A)^m] - m = 0
\end{aligned}
\]</span></p>
<ul>
<li><strong>Objective <span class="math inline">\(f(A, \theta)\)</span>:</strong> ELBO(Evidence Lower Bound)를 최대화하는 것은 Negative ELBO를 최소화하는 것과 같습니다.</li>
<li><strong>Constraint <span class="math inline">\(h(A)\)</span>:</strong> 앞서 유도한 다항식 제약 조건으로, 이 값이 0이 되어야만 <span class="math inline">\(A\)</span>가 DAG임이 보장됩니다.</li>
<li><strong>Unknowns:</strong>
<ul>
<li><span class="math inline">\(A\)</span>: 가중치 인접 행렬 (Weighted Adjacency Matrix)</li>
<li><span class="math inline">\(\theta\)</span>: VAE를 구성하는 신경망의 파라미터들 (<span class="math inline">\(\{W^1, W^2, W^3, W^4\}\)</span>).</li>
</ul></li>
</ul>
</section>
<section id="the-augmented-lagrangian-method" class="level3">
<h3 class="anchored" data-anchor-id="the-augmented-lagrangian-method">The Augmented Lagrangian Method</h3>
<ul>
<li><p>이러한 제약 조건이 있는 최적화 문제를 풀기 위해, 저자들은 <strong>증강 라그랑주(Augmented Lagrangian)</strong> 방법을 사용합니다.</p></li>
<li><p>이는 표준적인 라그랑주 승수법에 페널티 항(Penalty term)을 추가하여 수치적 안정성과 수렴성을 높인 기법입니다 (Bertsekas, 1999).</p></li>
<li><p>정의된 증강 라그랑주 함수 <span class="math inline">\(L_c\)</span>는 다음과 같습니다.</p></li>
</ul>
<p><span class="math display">\[
L_c(A, \theta, \lambda) = f(A, \theta) + \lambda h(A) + \frac{c}{2}|h(A)|^2
\]</span></p>
<ul>
<li>이 식은 세 가지 부분으로 구성됩니다:
<ul>
<li><ol type="1">
<li><strong><span class="math inline">\(f(A, \theta)\)</span>:</strong> 원래의 목적 함수 (Negative ELBO).</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong><span class="math inline">\(\lambda h(A)\)</span>:</strong> 표준 라그랑주 항. 여기서 <span class="math inline">\(\lambda\)</span>는 라그랑주 승수(Lagrange Multiplier)입니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong><span class="math inline">\(\frac{c}{2}|h(A)|^2\)</span>:</strong> 제약 조건 위반에 대한 2차 페널티(Quadratic Penalty) 항입니다. <span class="math inline">\(c\)</span>는 페널티 파라미터(Penalty Parameter)입니다.</li>
</ol></li>
</ul></li>
</ul>
<section id="motivation" class="level4">
<h4 class="anchored" data-anchor-id="motivation">Motivation</h4>
<ul>
<li>왜 단순 라그랑주나 단순 페널티 기법을 쓰지 않고 이 둘을 섞었을까요?</li>
<li>단순 페널티 기법은 <span class="math inline">\(c\)</span>를 무한대로 보내야만 제약 조건을 만족하는데, 이는 해 주변에서 함수를 매우 뾰족하게(Ill-conditioned) 만들어 최적화를 어렵게 합니다.</li>
<li>증강 라그랑주 방법은 <span class="math inline">\(\lambda\)</span>의 도움을 받아, <span class="math inline">\(c\)</span>가 적당히 크더라도 정확한 해로 수렴할 수 있게 해줍니다. 즉, <strong><span class="math inline">\(c \to \infty\)</span>일 때 <span class="math inline">\(L_c\)</span>의 최소해는 제약 조건 <span class="math inline">\(h(A)=0\)</span>을 만족하며 원래 목적 함수 <span class="math inline">\(f\)</span>를 최소화</strong>하게 됩니다.</li>
</ul>
</section>
</section>
<section id="algorithm-iterative-update-rule" class="level3">
<h3 class="anchored" data-anchor-id="algorithm-iterative-update-rule">Algorithm: Iterative Update Rule</h3>
<ul>
<li><p>학습은 <strong><span class="math inline">\(c\)</span>를 점진적으로 증가</strong>시키면서 일련의 비제약 최적화 문제(Unconstrained optimization)를 푸는 방식으로 진행됩니다.</p></li>
<li><p>구체적인 알고리즘은 다음의 반복(Iteration) 과정으로 요약됩니다.</p></li>
<li><p>각 반복 단계 <span class="math inline">\(k\)</span>에서 다음을 수행합니다:</p></li>
</ul>
<section id="step-1-primal-update-subproblem" class="level4">
<h4 class="anchored" data-anchor-id="step-1-primal-update-subproblem">Step 1: Primal Update (Subproblem)</h4>
<ul>
<li>현재 고정된 <span class="math inline">\(\lambda^k\)</span>와 <span class="math inline">\(c^k\)</span>에 대해, 증강 라그랑주 함수 <span class="math inline">\(L_{c^k}\)</span>를 최소화하는 <span class="math inline">\(A\)</span>와 <span class="math inline">\(\theta\)</span>를 찾습니다.</li>
</ul>
<p><span class="math display">\[
(A^k, \theta^k) = \underset{A, \theta}{\text{argmin}} \ L_{c^k}(A, \theta, \lambda^k) \quad \cdots (14)
\]</span></p>
<ul>
<li>이 단계(Subproblem)는 경사 하강법(Gradient Descent)과 같은 Blackbox Stochastic Optimization Solver(예: Adam)를 사용하여 해결합니다.</li>
<li>ELBO가 샘플 기반으로 정의되므로 확률적(Stochastic) 최적화가 적합합니다.</li>
</ul>
</section>
<section id="step-2-dual-update-lambda" class="level4">
<h4 class="anchored" data-anchor-id="step-2-dual-update-lambda">Step 2: Dual Update (<span class="math inline">\(\lambda\)</span>)</h4>
<ul>
<li>제약 조건 위반 정도(<span class="math inline">\(h(A^k)\)</span>)를 반영하여 라그랑주 승수를 업데이트합니다.</li>
</ul>
<p><span class="math display">\[
\lambda^{k+1} = \lambda^k + c^k h(A^k) \quad \cdots (15)
\]</span></p>
<ul>
<li>이 규칙은 쌍대 오름법(Dual Ascent)의 형태를 띠며, 제약 조건이 만족되지 않으면(즉 <span class="math inline">\(h(A) \neq 0\)</span>), <span class="math inline">\(\lambda\)</span>를 조정하여 다음 단계에서 해당 제약 조건이 더 중요하게 다뤄지도록 합니다.</li>
</ul>
</section>
<section id="step-3-penalty-parameter-update-c" class="level4">
<h4 class="anchored" data-anchor-id="step-3-penalty-parameter-update-c">Step 3: Penalty Parameter Update (<span class="math inline">\(c\)</span>)</h4>
<ul>
<li>제약 조건 위반 정도가 충분히 줄어들지 않았다면, 페널티 강도 <span class="math inline">\(c\)</span>를 증가시킵니다.</li>
</ul>
<p><span class="math display">\[
c^{k+1} = \begin{cases}
\eta c^k, &amp; \text{if } |h(A^k)| &gt; \gamma |h(A^{k-1})| \\
c^k, &amp; \text{otherwise}
\end{cases} \quad \cdots (16)
\]</span></p>
<ul>
<li><strong>조건 (<span class="math inline">\(|h(A^k)| &gt; \gamma |h(A^{k-1})|\)</span>):</strong> 이번 단계의 제약 위반 값이 이전 단계의 <span class="math inline">\(\gamma\)</span>배보다 크다는 것은, 위반 정도가 충분히(빠르게) 감소하지 않았음을 의미합니다.</li>
<li><strong>대응 (<span class="math inline">\(c \leftarrow \eta c\)</span>):</strong> 이 경우 <span class="math inline">\(c\)</span>를 <span class="math inline">\(\eta\)</span>배 키워서 제약 조건 위반에 대한 비용을 더 비싸게 만듭니다.</li>
</ul>
</section>
</section>
<section id="hyperparameters-and-implementation" class="level3">
<h3 class="anchored" data-anchor-id="hyperparameters-and-implementation">Hyperparameters and Implementation</h3>
<ul>
<li>논문에서는 이 알고리즘의 효과적인 작동을 위한 하이퍼파라미터 설정 값을 제안합니다.
<ul>
<li><strong><span class="math inline">\(\eta &gt; 1\)</span>:</strong> 페널티 증가 비율. 논문에서는 <strong><span class="math inline">\(\eta = 10\)</span></strong>을 권장합니다.</li>
<li><strong><span class="math inline">\(\gamma &lt; 1\)</span>:</strong> 허용 가능한 위반 감소율. 논문에서는 <strong><span class="math inline">\(\gamma = 1/4\)</span></strong> (<span class="math inline">\(0.25\)</span>)를 권장합니다.</li>
</ul></li>
<li>이 설정은 제약 조건 위반이 매 단계마다 최소 25%씩은 줄어들기를 기대하며, 그렇지 않을 경우 페널티를 10배로 강력하게 키우겠다는 공격적인 전략을 의미합니다.</li>
</ul>
</section>
<section id="summary-3" class="level3">
<h3 class="anchored" data-anchor-id="summary-3">Summary</h3>
<ul>
<li>DAG-GNN의 학습 과정은 단순히 손실 함수를 미분하여 역전파하는 것을 넘어섭니다.
<ul>
<li><ol type="1">
<li><strong>Augmented Lagrangian</strong>을 통해 연속적인 제약 조건(Acyclicity)을 목적 함수에 부드럽게 통합했습니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Primal-Dual Update</strong> 방식을 통해 모델 파라미터(<span class="math inline">\(A, \theta\)</span>)와 제약 파라미터(<span class="math inline">\(\lambda, c\)</span>)를 번갈아 최적화하며, 점진적으로 DAG 구조를 만족하는 해로 수렴해 나갑니다.</li>
</ol></li>
</ul></li>
<li>이로써 우리는 복잡한 조합 최적화 문제였던 구조 학습을, 딥러닝 프레임워크 위에서 수행 가능한 연속 최적화 문제로 완벽하게 변환하였습니다.</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="experiments" class="level1">
<h1>4. Experiments</h1>
<ul>
<li>본 섹션에서는 제안된 <strong>DAG-GNN</strong> 모델의 성능을 다양한 합성 데이터셋(Synthetic Data)과 벤치마크 데이터셋(Benchmark Data)을 통해 검증합니다.</li>
<li><ul>
<li>비교 대상으로는 당시 SOTA였던 연속 최적화 기반의 <strong>DAG-NOTEARS (Zheng et al., 2018)</strong>를 주로 사용합니다.</li>
</ul></li>
<li>실험의 목표는 DAG-GNN이 <strong>선형성(Linearity)</strong> 가정에 국한되지 않고, <strong>비선형(Nonlinear)</strong> 관계나 <strong>이산형(Discrete)</strong> 변수, 그리고 <strong>벡터 값 노드(Vector-valued node)</strong>까지 얼마나 유연하게 처리할 수 있는지 보여주는 데 있습니다.</li>
</ul>
<hr>
<section id="synthetic-data-sets" class="level2">
<h2 class="anchored" data-anchor-id="synthetic-data-sets">4.1. Synthetic Data Sets</h2>
<ul>
<li><p>저자들은 Erdős-Rényi 모델을 사용하여 임의의 DAG 구조를 생성하고, 노드 수 <span class="math inline">\(m \in \{10, 20, 50, 100\}\)</span>에 대해 데이터를 생성하여 실험을 진행했습니다. (샘플 수 <span class="math inline">\(n=5000\)</span>)</p></li>
<li><p>평가 지표로는 다음 두 가지를 사용합니다:</p>
<ul>
<li><ol type="1">
<li><strong>SHD (Structural Hamming Distance):</strong> 예측된 그래프와 정답 그래프 간의 엣지 불일치 개수 (낮을수록 좋음).</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>FDR (False Discovery Rate):</strong> 잘못 예측된 엣지의 비율 (낮을수록 좋음).</li>
</ol></li>
</ul></li>
</ul>
<section id="linear-case" class="level3">
<h3 class="anchored" data-anchor-id="linear-case">4.1.1. Linear Case</h3>
<ul>
<li>먼저, DAG-GNN이 기존 Linear SEM 환경에서도 잘 작동하는지 확인합니다. 데이터 생성 과정은 다음과 같습니다.</li>
</ul>
<p><span class="math display">\[
x = A^T x + z
\]</span></p>
<ul>
<li>여기서 <span class="math inline">\(g\)</span>는 항등 함수(Identity mapping)입니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/figure2_linear_case.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: Linear Case에서의 성능 비교. 그래프 크기(m)가 커짐에 따라 DAG-NOTEARS(파란색)와 DAG-GNN(빨간색)의 SHD와 FDR 변화를 보여준다. DAG-GNN이 선형 모델에서도 NOTEARS와 대등하거나 더 우수한 성능을 보임을 알 수 있다.</figcaption>
</figure>
</div>
<ul>
<li><strong>결과:</strong> 선형 데이터임에도 불구하고, DAG-GNN은 Linear 전용 모델인 NOTEARS보다 더 정확한 구조를 학습했습니다. 특히 그래프 크기가 커질수록(<span class="math inline">\(m=100\)</span>) 격차가 벌어지는 경향을 보입니다.</li>
</ul>
</section>
<section id="nonlinear-case-core-contribution" class="level3">
<h3 class="anchored" data-anchor-id="nonlinear-case-core-contribution">4.1.2. Nonlinear Case (Core Contribution)</h3>
<ul>
<li>DAG-GNN의 진가는 비선형 데이터에서 드러납니다. 저자들은 다음과 같은 비선형 생성 모델을 사용했습니다.</li>
</ul>
<p><span class="math display">\[
x = A^T h(x) + z, \quad \text{where } h(x) = \cos(x + 1)
\]</span></p>
<ul>
<li>이 경우 <span class="math inline">\(h(x)\)</span>를 1차 테일러 근사하면 <span class="math inline">\(h(x) \approx h(0)\mathbf{1} + h'(0)x\)</span>가 되며, 이는 <span class="math inline">\(h'(0)A\)</span>를 인접 행렬로 갖는 선형 모델로 근사될 수 있습니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/figure3_nonlinear_case.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3: Nonlinear Case (<span class="math inline">\(h(x)=\cos(x+1)\)</span>)에서의 성능 비교. 비선형성이 도입되자 NOTEARS(파란색)의 SHD와 FDR이 급격히 증가하는 반면, DAG-GNN(빨간색)은 안정적인 성능을 유지한다.</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/figure4_heatmap_nonlinear.png" class="img-fluid figure-img"></p>
<figcaption>Figure 4: 파라미터 추정 히트맵 (Heatmap). (왼쪽) True Graph, (중간) DAG-GNN 추정, (오른쪽) NOTEARS 추정. DAG-GNN은 정답의 희소(Sparse)한 구조를 잘 복원하고 “False Alarm”이 적은 반면, NOTEARS는 노이즈가 많이 낀 결과를 보여준다.</figcaption>
</figure>
</div>
<ul>
<li><strong>결과:</strong> SHD 측면에서 약간의 개선이 있었고, 특히 <strong>FDR(가짜 발견율)이 약 3배 가량 개선</strong>되었습니다. 이는 DAG-GNN이 비선형 관계 속에서도 진짜 인과관계만을 정확하게 발라내는 능력이 탁월함을 의미합니다.</li>
</ul>
</section>
<section id="vector-valued-case" class="level3">
<h3 class="anchored" data-anchor-id="vector-valued-case">4.1.3. Vector-Valued Case</h3>
<ul>
<li><p>기존 방법론들은 변수를 스칼라(Scalar)로만 취급했습니다. 하지만 DAG-GNN은 GNN 구조 덕분에 각 노드가 벡터(<span class="math inline">\(d &gt; 1\)</span>)인 경우도 자연스럽게 처리합니다.</p></li>
<li><p>실험 설정은 다음과 같습니다:</p>
<ul>
<li>노드 차원 <span class="math inline">\(d=5\)</span>, 잠재 차원 <span class="math inline">\(d_Z=1\)</span>.</li>
<li>데이터는 더욱 복잡한 비선형 식 <span class="math inline">\(x = 2\sin(A^T(x + 0.5 \cdot 1)) + A^T(x + 0.5 \cdot 1) + z\)</span> 로 생성됩니다.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/figure6_vector_case.png" class="img-fluid figure-img"></p>
<figcaption>Figure 6: Vector-valued Case의 성능 비교. 벡터 노드와 복잡한 비선형성이 결합된 환경에서 DAG-GNN(빨간색)이 NOTEARS(파란색)를 압도하는 성능 차이를 보여준다.</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/figure7_heatmap_vector.png" class="img-fluid figure-img"></p>
<figcaption>Figure 7: Vector-valued 데이터에 대한 파라미터 추정 비교. DAG-GNN은 Ground Truth의 구조를 거의 완벽하게 복원한 반면, NOTEARS는 구조를 거의 학습하지 못했다.</figcaption>
</figure>
</div>
<ul>
<li><strong>결과:</strong> NOTEARS는 이러한 설정(벡터 입력)을 처리할 수 없어, 데이터를 강제로 스칼라로 변환하거나 가정을 단순화해야 했습니다. 반면 DAG-GNN은 구조적 정보를 잠재 공간(Latent Space)에서 효과적으로 포착하여 압도적인 성능 차이를 보여줍니다.</li>
</ul>
<hr>
</section>
</section>
<section id="benchmark-data-sets-discrete-variables" class="level2">
<h2 class="anchored" data-anchor-id="benchmark-data-sets-discrete-variables">4.2. Benchmark Data Sets (Discrete Variables)</h2>
<ul>
<li>다음으로, 이산형 변수(Discrete Variables)로 구성된 유명한 베이지안 네트워크 벤치마크 데이터셋(Child, Alarm, Pigs)에 대한 실험입니다.</li>
<li>여기서는 <strong>GOPNILP</strong> (Integer Programming을 이용한 Exact Solver)와 비교하여, <strong>BIC Score</strong>를 평가 지표로 사용했습니다.</li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Dataset</th>
<th style="text-align: left;"><span class="math inline">\(m\)</span> (Nodes)</th>
<th style="text-align: left;">Ground Truth BIC</th>
<th style="text-align: left;">GOPNILP BIC</th>
<th style="text-align: left;">DAG-GNN BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Child</strong></td>
<td style="text-align: left;">20</td>
<td style="text-align: left;">-1.27e+4</td>
<td style="text-align: left;">-1.27e+4</td>
<td style="text-align: left;">-1.38e+4</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Alarm</strong></td>
<td style="text-align: left;">37</td>
<td style="text-align: left;">-1.07e+4</td>
<td style="text-align: left;">-1.12e+4</td>
<td style="text-align: left;">-1.28e+4</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Pigs</strong></td>
<td style="text-align: left;">441</td>
<td style="text-align: left;">-3.48e+5</td>
<td style="text-align: left;">-3.50e+5</td>
<td style="text-align: left;">-3.69e+5</td>
</tr>
</tbody>
</table>
<p><em>(Table 1의 내용을 재구성)</em></p>
<ul>
<li><strong>해석:</strong> GOPNILP는 전역 최적해(Global Optimum)를 찾는 알고리즘이므로 가장 좋은 점수를 보입니다. DAG-GNN은 근사 해법임에도 불구하고, 전역 최적해에 <strong>합리적으로 근접한(reasonably close)</strong> 결과를 보여줍니다.</li>
<li>BIC 차이가 나는 이유는 VAE 구조가 다항 분포(Multinomial distribution)를 근사하는 과정에서 발생하는 한계로 보이지만, 통합된 프레임워크로 이산형 데이터까지 처리할 수 있다는 점은 큰 강점입니다.</li>
</ul>
<hr>
</section>
<section id="applications" class="level2">
<h2 class="anchored" data-anchor-id="applications">4.3. Applications</h2>
<section id="protein-signaling-network" class="level3">
<h3 class="anchored" data-anchor-id="protein-signaling-network">Protein Signaling Network</h3>
<ul>
<li>Sachs et al.&nbsp;(2005)의 단백질 신호 전달 네트워크 데이터(<span class="math inline">\(n=7466, m=11\)</span>)를 사용하여 실제 인과 구조 복원 능력을 테스트했습니다.</li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Method</th>
<th style="text-align: left;">SHD</th>
<th style="text-align: left;">Predicted Edges</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">FGS (Fast Greedy Search)</td>
<td style="text-align: left;">22</td>
<td style="text-align: left;">17</td>
</tr>
<tr class="even">
<td style="text-align: left;">NOTEARS</td>
<td style="text-align: left;">22</td>
<td style="text-align: left;">16</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>DAG-GNN</strong></td>
<td style="text-align: left;"><strong>19</strong></td>
<td style="text-align: left;"><strong>18</strong></td>
</tr>
</tbody>
</table>
<p><em>(Table 2의 내용을 재구성)</em></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/figure8_protein_network.png" class="img-fluid figure-img"></p>
<figcaption>Figure 8: DAG-GNN이 추정한 단백질 신호 전달 네트워크. 붉은색 화살표는 Ground Truth와 일치하는 엣지, 파란색 점선은 간접 연결, 노란색은 역방향 연결을 나타낸다.</figcaption>
</figure>
</div>
<ul>
<li><strong>결과:</strong> DAG-GNN은 SHD 19를 기록하여, NOTEARS(22) 및 FGS(22)보다 <strong>더 정확하게 실제 생물학적 인과관계(Ground Truth)를 복원</strong>했습니다.</li>
</ul>
</section>
<section id="knowledge-base-construction" class="level3">
<h3 class="anchored" data-anchor-id="knowledge-base-construction">Knowledge Base Construction</h3>
<ul>
<li><p>FB15K-237 데이터셋을 사용하여, 지식 베이스(Knowledge Base) 내의 관계(Relation)들 사이의 인과성을 추론하는 새로운 태스크를 제안했습니다.</p></li>
<li><p>예를 들어, <code>Person/Nationality</code>라는 관계가 있다면, 이것이 <code>Person/Language</code> 관계의 원인이 될 수 있다는 식의 메타 관계를 학습합니다.</p></li>
<li><p>Table 3 결과에 따르면, <code>film/ProducedBy</code> <span class="math inline">\(\Rightarrow\)</span> <code>film/Country</code>와 같이 직관적으로 타당한 인과 관계들을 성공적으로 추출했습니다.</p></li>
</ul>
<hr>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>5. Conclusion</h1>
<ul>
<li><p>본 논문은 그래프 구조 학습(Structure Learning)이라는 난제를 해결하기 위해, <strong>딥러닝(Deep Generative Model)과 연속 최적화(Continuous Optimization)</strong>를 결합한 <strong>DAG-GNN</strong> 프레임워크를 제안했습니다.</p></li>
<li><p>이 연구의 핵심 기여와 의의는 다음과 같이 요약할 수 있습니다.</p>
<ul>
<li><ol type="1">
<li><strong>Generalized SEM:</strong> 기존의 선형 구조 방정식 모델(Linear SEM)을 일반화하여, 비선형 관계와 복잡한 데이터 분포를 포착할 수 있는 VAE 기반 생성 모델을 설계했습니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Novel GNN Architecture:</strong> 인코더와 디코더를 구조 학습에 특화된 새로운 Graph Neural Network로 파라미터화했습니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Polynomial Acyclicity Constraint:</strong> 기존의 Matrix Exponential 제약 조건의 수치적 불안정성을 개선하고 구현 용이성을 높인 다항식 형태의 제약 조건을 제안했습니다.</li>
</ol></li>
<li><ol start="4" type="1">
<li><strong>Versatility:</strong> 실험을 통해 선형/비선형, 연속형/이산형, 스칼라/벡터 노드 등 다양한 데이터 형태에 대해 일관되게 우수한 성능을 입증했습니다.</li>
</ol></li>
</ul></li>
<li><p>DAG-GNN은 인과추론 분야에서 딥러닝의 표현력을 구조 학습에 성공적으로 이식한 중요한 이정표가 되는 연구라 할 수 있습니다.</p></li>
</ul>



</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/shsha0110\.github\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>