{
  "hash": "28cd04722b8109988df545a56f8cbc8f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"[Causal Inference] 13. IV (Part 3)\"\ndescription: \"Linear 2SLS vs. Deep IV\"\nauthor: \"유성현\"\ndate: \"2026-01-18\"\ncategories: [Causal Inference]\nformat:\n  html:\n    toc: true\n    number-sections: false\n    code-fold: show\n    math: true\njupyter: python3\n---\n\n## 1. Introduction\n\n사회과학 데이터, 특히 범죄학이나 경제학 데이터를 다루다 보면 선형(Linear) 모델로는 설명하기 힘든 복잡한 인과관계를 마주하게 됩니다.\n\n전통적인 **2단계 최소제곱법(2SLS)**은 강력한 도구이지만, 다음과 같은 한계가 있습니다.\n1.  처치(Treatment)와 결과(Outcome)의 관계를 **선형**으로 가정합니다.\n2.  공변량(Covariate)과 처치 변수 간의 복잡한 **상호작용**을 포착하기 어렵습니다.\n\n이번 포스트에서는 Hartford et al.(2017)이 제안한 **Deep IV** 방법론을 소개하고, 가격($P$)과 판매량($Y$)의 비선형적 관계를 시뮬레이션 데이터를 통해 추정해보겠습니다.\n\n### The Problem Formulation\n\n우리가 관심 있는 인과 모델은 다음과 같습니다.\n\n$$Y = g(P, X) + \\epsilon$$\n\n여기서:\n* $Y$: 결과 변수 (예: 판매량, 범죄율)\n* $P$: 처치 변수 (예: 가격, 경찰 순찰 빈도) - **내생성(Endogeneity) 존재** ($E[\\epsilon|P] \\neq 0$)\n* $X$: 관측 가능한 공변량 (예: 성수기 여부, 지역 특성)\n* $Z$: 도구 변수 (예: 원자재 가격, 예산) - 외생성 만족\n\nDeep IV는 이 문제를 풀기 위해 **두 단계의 신경망**을 사용합니다.\n\n1.  **Stage 1 (Treatment Network):** 도구 변수를 이용해 처치 변수의 조건부 분포 $F(P|Z, X)$를 학습합니다.\n2.  **Stage 2 (Outcome Network):** 1단계에서 추정된 분포를 적분(Integrate out)하여 인과 함수 $g(P, X)$를 학습합니다.\n\n---\n\n## 2. Data Generation\n\n먼저 내생성과 비선형성이 존재하는 가상의 데이터를 생성합니다.\n상황은 다음과 같습니다.\n* **가격($P$)**이 오르면 **판매량($Y$)**은 줄어듭니다.\n* 하지만 **성수기($X$)**에는 가격도 비싸고 판매량도 많아, 단순 회귀 시 양의 상관관계(편향)가 관찰됩니다.\n* 실제 인과 효과는 특정 가격 이상에서 급격히 판매량이 떨어지는 **S자 곡선(Sigmoid)** 형태입니다.\n\n::: {#data-generation .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.distributions as D\nimport torch.nn.functional as F\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\n```\n:::\n\n\n::: {#2c402ad1 .cell execution_count=2}\n``` {.python .cell-code}\ndef generate_data(n, seed=42):\n    np.random.seed(seed)\n    \n    # 1. 외생 변수 생성\n    # X: 공변량 (성수기 여부)\n    x = np.random.uniform(0, 1, n) \n    # Z: 도구변수 (연료비)\n    z = np.random.uniform(0, 1, n) \n    # E: 교란 변수\n    e = np.random.normal(0, 1, n)   \n\n    # 2. 처치 변수 (P) 생성\n    p = 10 + (60 * z) + (20 * x) + (5 * e) + np.random.normal(0, 1, n)\n\n    # 3. 결과 변수 (Y) 생성\n    # True Structural Function: g(p, x)\n    def true_structural_function(p_val, x_val):\n        threshold = 35 + (40 * x_val) # X에 따라 임계값이 변함 (Heterogeneity)\n        base_effect = 150 / (1 + np.exp(0.8 * (p_val - threshold)))\n        return base_effect + (50 * x_val)\n        \n    y_structural = true_structural_function(p, x)\n    y = y_structural + (10 * e) + np.random.normal(0, 2, n)\n\n    return (z.reshape(-1, 1), x.reshape(-1, 1), p.reshape(-1, 1), y.reshape(-1, 1), true_structural_function)\n```\n:::\n\n\n::: {#d1fe5ae9 .cell execution_count=3}\n``` {.python .cell-code}\n# 1. 데이터 생성\nZ_data, X_data, P_data, Y_data, true_func = generate_data(n=100)\n\n# 2. Scaler 선언\nscaler_z = StandardScaler()\nscaler_x = StandardScaler()\nscaler_p = StandardScaler()\nscaler_y = StandardScaler()\n\n# 3. Fitting & Transform\nZ_scaled = scaler_z.fit_transform(Z_data)\nX_scaled = scaler_x.fit_transform(X_data)\nP_scaled = scaler_p.fit_transform(P_data)\nY_scaled = scaler_y.fit_transform(Y_data)\n\n# 4. 텐서 변환\nZ = torch.tensor(Z_scaled, dtype=torch.float32)\nX = torch.tensor(X_scaled, dtype=torch.float32)\nP = torch.tensor(P_scaled, dtype=torch.float32)\nY = torch.tensor(Y_scaled, dtype=torch.float32)\n```\n:::\n\n\n::: {#abe4b2b0 .cell execution_count=4}\n``` {.python .cell-code}\n# 스타일 설정\nsns.set_style(\"whitegrid\")\nplt.rcParams['figure.figsize'] = (18, 12)\nplt.rcParams['font.size'] = 12\n\n# 데이터 1차원 변환\nz_flat = Z_data.flatten()\nx_flat = X_data.flatten()\np_flat = P_data.flatten()\ny_flat = Y_data.flatten()\n\nfig, axes = plt.subplots(2, 2)\nfig.suptitle('DeepIV Simulation: Non-linear Causal Inference', fontsize=22, weight='bold')\n\n# ---------------------------------------------------------\n# (A) First Stage Strength: 도구 변수(Z) -> 처치(P)\n# ---------------------------------------------------------\nsns.regplot(x=z_flat, y=p_flat, ax=axes[0, 0], \n            scatter_kws={'alpha': 0.05, 'color': 'navy'}, line_kws={'color': 'red'})\naxes[0, 0].set_title('(A) First Stage Relevance: Instrument(Z) -> Treatment(P)', fontsize=14, weight='bold')\naxes[0, 0].set_xlabel('Instrument Z (Fuel Cost)')\naxes[0, 0].set_ylabel('Treatment P (Price)')\naxes[0, 0].text(0.05, 0.9, f\"Corr(Z, P): {np.corrcoef(z_flat, p_flat)[0,1]:.2f}\\nStrong Relevance\", \n                transform=axes[0, 0].transAxes, bbox=dict(facecolor='white', alpha=0.9))\n\n# ---------------------------------------------------------\n# (B) Confounding Bias: 가격(P) vs 판매량(Y) (관측 데이터)\n# ---------------------------------------------------------\n# X(성수기 여부)가 P와 Y 모두를 증가시키는 교란(Confounding) 현상 시각화\nscatter = axes[0, 1].scatter(p_flat, y_flat, c=x_flat, cmap='coolwarm', alpha=0.3, s=15)\naxes[0, 1].set_title('(B) Confounding Bias: Observed P vs Y', fontsize=14, weight='bold')\naxes[0, 1].set_xlabel('Price P')\naxes[0, 1].set_ylabel('Sales Y')\ncbar = plt.colorbar(scatter, ax=axes[0, 1])\ncbar.set_label('Confounder X (Seasonality)', rotation=270, labelpad=15)\naxes[0, 1].text(0.05, 0.05, \"Endogeneity Present:\\nHigh X causes High P & High Y\", \n                transform=axes[0, 1].transAxes, bbox=dict(facecolor='white', alpha=0.9))\n\n# ---------------------------------------------------------\n# (C) Covariate Distribution: 공변량(X) -> 가격(P)\n# ---------------------------------------------------------\nsns.kdeplot(x=p_flat, hue=(x_flat > 0.5), fill=True, ax=axes[1, 0], palette='coolwarm')\naxes[1, 0].set_title('(C) P Distribution by Seasonality (X)', fontsize=14, weight='bold')\naxes[1, 0].set_xlabel('Treatment P (Price)')\naxes[1, 0].legend(['High Season (X>0.5)', 'Low Season (X<=0.5)'])\n\n# ---------------------------------------------------------\n# (D) The \"True\" Causal Curve (Ground Truth)\n# ---------------------------------------------------------\ndef get_true_effect_consistent(p_input, x_val):\n    threshold = 35 + (40 * x_val)\n    base_effect = 150 / (1 + np.exp(0.8 * (p_input - threshold)))\n    return base_effect + (50 * x_val)\n\np_range = np.linspace(p_flat.min(), p_flat.max(), 300)\n\naxes[1, 1].scatter(p_flat, y_flat, color='gray', alpha=0.05, label='Observed Samples')\n\n# 시나리오별 True Curve 그리기\n# X=0.1 (비수기), X=0.5 (평균), X=0.9 (성수기)\nlines_x = [0.1, 0.5, 0.9]\ncolors = ['blue', 'green', 'red']\nlabels = ['Low Season (X=0.1)', 'Avg Season (X=0.5)', 'High Season (X=0.9)']\n\nfor lx, c, lbl in zip(lines_x, colors, labels):\n    y_true = get_true_effect_consistent(p_range, lx)\n    axes[1, 1].plot(p_range, y_true, color=c, linewidth=2.5, linestyle='--', label=f'True: {lbl}')\n\naxes[1, 1].set_title('(D) Ground Truth: Heterogeneous S-Curves', fontsize=14, weight='bold')\naxes[1, 1].set_xlabel('Treatment P (Price)')\naxes[1, 1].set_ylabel('Outcome Y (Sales)')\naxes[1, 1].legend(loc='upper right', frameon=True, framealpha=0.9)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-1.png){width=1712 height=1130}\n:::\n:::\n\n\n---\n\n## 3. Benchmark: Linear 2SLS\n\n비교를 위해 전통적인 Linear 2SLS를 먼저 수행합니다. `scikit-learn`을 사용하여 2단계 회귀분석을 진행합니다.\n\n1. Stage 1: Predict  using \n2. Stage 2: Regress  on \n\n::: {#linear-2sls .cell execution_count=5}\n``` {.python .cell-code}\n# ==========================================\n# 2. Linear 2SLS Implementation\n# ==========================================\n\n# [Stage 1] P ~ Z + X\n# 도구변수(Z)와 공변량(X)를 사용하여 내생변수(P)를 예측.\nZX_data = np.concatenate((Z_data, X_data), axis=1)\nstage1_model = LinearRegression()\nstage1_model.fit(ZX_data, P_data)\n\n# P_hat (Hat P): 내생성이 제거된 P의 부분\nP_hat = stage1_model.predict(ZX_data)\n\n# [Stage 2] Y ~ P_hat + X\n# 예측된 처치(P_hat)와 공변량(X)를 사용하여 결과(Y)를 예측.\nPX_hat_data = np.concatenate((P_hat, X_data), axis=1)\nstage2_model = LinearRegression()\nstage2_model.fit(PX_hat_data, Y_data)\n\nprint(\"Linear 2SLS Training Complete.\")\nprint(f\"Estimated Causal Effect (Coefficient of P): {stage2_model.coef_[0][0]:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear 2SLS Training Complete.\nEstimated Causal Effect (Coefficient of P): -3.1744\n```\n:::\n:::\n\n\n---\n\n## 4. Deep IV Implementation\n\n### Stage 1: Mixture Density Network (MDN)\n\nDeep IV의 첫 단계는 의 값을 하나로 예측하는 것이 아니라, 의 **조건부 확률 분포**를 추정하는 것입니다. 이를 위해 가우시안 혼합 모델(Gaussian Mixture Model)을 출력하는 신경망을 사용합니다.\n\n$$ \\hat{F}(P|Z,X) = \\sum_{k=1}^{K} \\pi_k(Z,X) \\mathcal{N}(\\mu_k(Z,X), \\sigma_k^2(Z,X)) $$\n\n::: {#deep-iv-stage1 .cell execution_count=6}\n``` {.python .cell-code}\nclass FirstStageMDN(nn.Module):\n    def __init__(self, input_dim, num_gaussians=5):\n        super().__init__()\n        self.shared_layer = nn.Sequential(\n            nn.Linear(input_dim, 64),\n            nn.ReLU(),\n            nn.Linear(64, 64),\n            nn.ReLU()\n        )\n        self.pi_head = nn.Linear(64, num_gaussians) \n        self.mu_head = nn.Linear(64, num_gaussians) \n        self.sigma_head = nn.Linear(64, num_gaussians) \n\n    def forward(self, x, z):\n        # 입력: 공변량(X)와 도구변수(Z)를 결합\n        inputs = torch.cat([x, z], dim=1)\n        features = self.shared_layer(inputs)\n        # 1. Pi (혼합 비율): Softmax로 합이 1이 되도록 함\n        pi = F.softmax(self.pi_head(features), dim=1)\n        # 2. Mu (평균)\n        mu = self.mu_head(features)\n        # 3. Sigma (표준편차)\n        sigma = F.softplus(self.sigma_head(features)) + 1e-5\n        return pi, mu, sigma\n\n    def sample(self, x, z, n_samples=1):\n        pi, mu, sigma = self.forward(x, z)    \n        # GMM(Gaussian Mixture Model) 객체 생성\n        mix = D.Categorical(probs=pi)\n        comp = D.Normal(loc=mu, scale=sigma)\n        gmm = D.MixtureSameFamily(mix, comp)\n        # 샘플링 수행 (Batch, n_samples)\n        if n_samples == 1:\n            return gmm.sample().unsqueeze(-1)\n        else:\n            return gmm.sample((n_samples,)).permute(1, 0)\n\n# 손실 함수 (Negative Log Likelihood)\ndef first_stage_loss_fn(pi, mu, sigma, p):\n    # 1. 각 가우시안 분포에서의 확률 밀도 계산\n    m = D.Normal(loc=mu, scale=sigma)\n    log_probs_component = m.log_prob(p)\n    # 2. 혼합 비율(pi) 반영 (Log-Sum-Exp Trick)\n    weighted_log_probs = torch.log(pi + 1e-8) + log_probs_component\n    log_likelihood = torch.logsumexp(weighted_log_probs, dim=1)\n    # 3. NLL 최소화\n    return -torch.mean(log_likelihood)\n```\n:::\n\n\n### Stage 2: Outcome Network\n\n두 번째 단계는 인과 함수 $g(P, X)$를 근사하는 신경망입니다. 손실 함수는 1단계 분포에서 샘플링한 $\\hat{P}$를 사용하여 계산된 기댓값과 실제 의 차이를 최소화합니다.\n\n$$ L = E \\left[ \\left( Y - \\int g(\\hat{p}, X) d\\hat{F}(\\hat{p}|Z,X) \\right)^2 \\right] $$\n\n::: {#deep-iv-stage2 .cell execution_count=7}\n``` {.python .cell-code}\n# 2단계: Causal Function h (Outcome Network)\nclass SecondStageH(nn.Module):\n    def __init__(self, x_dim, p_dim=1, output_dim=1):\n        super().__init__()\n        input_dim = x_dim + p_dim\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, 128),\n            nn.ReLU(),\n            nn.Linear(128, 128),\n            nn.ReLU(),\n            nn.Linear(128, output_dim)\n        )\n        \n    def forward(self, p, x):\n        inputs = torch.cat([p, x], dim=-1) \n        return self.net(inputs)\n\ndef second_stage_loss_fn(model_h, pi, mu, sigma, x, y, num_samples=32):\n    # mu shape: (Batch, K)\n    batch_size, n_components = mu.shape\n    x_dim = x.shape[1]\n    \n    # [Step 1] Stratified Sampling (벡터화 구현)\n    # 모든 컴포넌트(K)와 샘플(S)을 한꺼번에 처리하기 위해 차원 확장\n    # eps: (Batch, S, K)\n    eps = torch.randn(batch_size, num_samples, n_components, device=mu.device)\n    \n    # mu, sigma 확장: (Batch, 1, K) -> 브로드캐스팅 -> (Batch, S, K)\n    mu_exp = mu.unsqueeze(1)\n    sigma_exp = sigma.unsqueeze(1)\n    \n    # Reparameterization Trick\n    # p_samples: (Batch, S, K) -> 모든 가우시안 성분별로 S개씩 샘플링\n    # 주의: 1단계 모델의 그래디언트는 필요 없으므로 detach() 권장 (일반적인 2SLS)\n    p_samples = (mu_exp + sigma_exp * eps).detach()\n    \n    # [Step 2] X 확장\n    # x: (Batch, x_dim) -> (Batch, S, K, x_dim)\n    # p_samples와 짝을 맞추기 위해 차원을 늘립니다.\n    x_expanded = x.view(batch_size, 1, 1, x_dim).expand(-1, num_samples, n_components, -1)\n    \n    # p_samples 차원 맞추기: (Batch, S, K) -> (Batch, S, K, 1)\n    p_samples_reshaped = p_samples.unsqueeze(-1)\n    \n    # [Step 3] Forward Pass\n    # 입력 shape: (Batch, S, K, dim) -> model_h는 마지막 dim만 신경 씀\n    h_out = model_h(p_samples_reshaped, x_expanded) # 결과: (Batch, S, K, 1)\n    \n    # [Step 4] 가중 평균 (Expectation 계산)\n    # 4-1. 각 성분(K)에 대한 가중치(pi) 적용\n    # pi: (Batch, K) -> (Batch, 1, K, 1)\n    pi_expanded = pi.view(batch_size, 1, n_components, 1)\n    \n    # 성분별 기댓값 합산 (Sum over K)\n    # h_weighted_sum: (Batch, S, 1)\n    h_weighted_sum = torch.sum(h_out * pi_expanded, dim=2)\n    \n    # 4-2. 샘플링(S)에 대한 평균 (Mean over S)\n    # y_pred_expectation: (Batch, 1)\n    y_pred_expectation = torch.mean(h_weighted_sum, dim=1)\n    \n    # [Step 5] MSE Loss\n    # y: (Batch, 1)\n    loss = torch.mean((y.view(-1, 1) - y_pred_expectation) ** 2)\n    \n    return loss\n```\n:::\n\n\n### Training Loop\n\n::: {#training .cell execution_count=8}\n``` {.python .cell-code}\n# ==========================================\n# 4. Training\n# ==========================================\n\n# -----------------------------------------------------\n# [Stage 1] Treatment Network Training (Z + X -> P distribution)\n# -----------------------------------------------------\ntreatment_net = FirstStageMDN(\n    input_dim=X.shape[-1] + Z.shape[-1], \n    num_gaussians=5\n)\n\nopt1 = optim.Adam(treatment_net.parameters(), lr=1e-4)\nepochs_stage1 = 1000\n\nprint(f\"Starting Stage 1 Training (Epochs: {epochs_stage1})...\")\n\ntreatment_net.train()\nfor epoch in range(epochs_stage1):\n    # 1. Forward Pass\n    pi, mu, sigma = treatment_net(X, Z)\n    # 2. Loss Calculation (Negative Log Likelihood)\n    loss1 = first_stage_loss_fn(pi, mu, sigma, P)\n    # 3. Optimization\n    opt1.zero_grad()\n    loss1.backward()\n    opt1.step()\n    \n    if (epoch + 1) % 100 == 0:\n        print(f\"[Stage 1] Epoch [{epoch+1}/{epochs_stage1}] | Loss: {loss1:.4f} | Avg Sigma: {sigma.mean().item():.4f}\")\n\n# -----------------------------------------------------\n# [Transition] Freeze Stage 1\n# -----------------------------------------------------\ntreatment_net.eval()\nfor param in treatment_net.parameters():\n    param.requires_grad = False\nprint(\"Stage 1 Freezed.\")\n\n# -----------------------------------------------------\n# [Stage 2] Outcome Network Training (Resampled P + X -> Y)\n# -----------------------------------------------------\noutcome_net = SecondStageH(\n    x_dim=X.shape[-1], \n    p_dim=1, \n    output_dim=1\n)\n\nopt2 = optim.Adam(outcome_net.parameters(), lr=1e-4)\nepochs_stage2 = 1000\n\nprint(f\"\\nStarting Stage 2 Training (Epochs: {epochs_stage2})...\")\n\noutcome_net.train()\nfor epoch in range(epochs_stage2):\n    total_loss = 0\n\n    with torch.no_grad():\n        pi, mu, sigma = treatment_net(X, Z)\n    \n    # 2단계 Loss 계산\n    loss2 = second_stage_loss_fn(\n        model_h=outcome_net, \n        pi=pi, \n        mu=mu, \n        sigma=sigma, \n        x=X, \n        y=Y, \n        num_samples=20 \n    )\n    # Optimization\n    opt2.zero_grad()\n    loss2.backward()\n    opt2.step()\n\n    \n    if (epoch + 1) % 100 == 0:\n        print(f\"[Stage 2] Epoch [{epoch+1}/{epochs_stage2}] | Loss: {loss2:.4f}\")\n   \nprint(\"Deep IV Training Complete.\")\n```\n:::\n\n\n---\n\n## 5. Result Visualization\n\n학습된 모델이 실제 인과 효과 곡선(Ground Truth)을 얼마나 잘 복원했는지 확인합니다.\n테스트는 **성수기와 비성수기의 중간()** 조건을 가정합니다.\n\n::: {#cell-visualization .cell execution_count=9}\n``` {.python .cell-code}\n# ==========================================\n# 4. Visualization & Evaluation\n# ==========================================\n# ===========================================================\n# 1. 테스트 데이터 생성\n# ===========================================================\np_min, p_max = P_data.min(), P_data.max()\np_test = np.linspace(p_min, p_max, 200).reshape(-1, 1)\n\nfixed_x_val = 0.5\nx_test = np.full_like(p_test, fixed_x_val)\n\ndef true_structural_function(p_val, x_val):\n    threshold = 35 + (40 * x_val)\n    base_effect = 150 / (1 + np.exp(0.8 * (p_val - threshold)))\n    return base_effect + (50 * x_val)\n        \ntrue_y = true_structural_function(p_test, x_test)\n\n# ===========================================================\n# 2. Linear 2SLS 예측\n# ===========================================================\npx_test_linear = np.concatenate((p_test, x_test), axis=1)\nlinear_pred = stage2_model.predict(px_test_linear)\n\n# ===========================================================\n# 3. DeepIV 예측\n# ===========================================================\noutcome_net.eval()\n\np_test_scaled = scaler_p.transform(p_test)\nx_test_scaled = scaler_x.transform(x_test)\np_tensor = torch.tensor(p_test_scaled, dtype=torch.float32)\nx_tensor = torch.tensor(x_test_scaled, dtype=torch.float32)\n\nwith torch.no_grad():\n    y_pred_scaled = outcome_net(p_tensor, x_tensor)    \n    deep_pred = scaler_y.inverse_transform(y_pred_scaled.numpy())\n\n# ===========================================================\n# 4. 최종 시각화\n# ===========================================================\nplt.figure(figsize=(12, 8))\n\n# 배경: 관측 데이터\nplt.scatter(P_data, Y_data, color='gray', alpha=0.1, s=10, label='Observed Data')\n\n# 1. Ground Truth (검은 실선)\nplt.plot(p_test, true_y, 'k-', linewidth=3, label='Ground Truth')\n\n# 2. Linear 2SLS (빨간 점선)\nplt.plot(p_test, linear_pred, 'r--', linewidth=2.5, label='Linear 2SLS')\n\n# 3. Deep IV (파란 실선)\nplt.plot(p_test, deep_pred, 'b-', linewidth=2.5, label='Deep IV')\n\nplt.title(f\"Causal Effect Estimation: Non-linear Pricing (at Seasonality X={fixed_x_val})\", fontsize=16, weight='bold')\nplt.xlabel(\"Treatment: Ticket Price (P)\", fontsize=13)\nplt.ylabel(\"Outcome: Sales (Y)\", fontsize=13)\nplt.legend(fontsize=12, loc='upper right', framealpha=0.9)\nplt.grid(True, alpha=0.3, linestyle='--')\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Comparison of Causal Effect Estimation](index_files/figure-html/visualization-output-1.png){#visualization width=1138 height=755}\n:::\n:::\n\n\n## Conclusion\n\n결과 그래프에서 볼 수 있듯이:\n\n1. **Linear 2SLS**는 데이터의 비선형성을 무시하고 단순한 직선으로 효과를 추정하여, 가격 임계값 근처에서의 급격한 수요 변화를 포착하지 못합니다.\n2. **Deep IV**는 실제 인과 곡선(Ground Truth)인 S자 형태를 매우 정확하게 복원해냈습니다.\n\n이는 사회과학 연구에서 비선형성이 강하게 의심될 때, 딥러닝 기반의 인과추론 방법론이 강력한 대안이 될 수 있음을 시사합니다.\n\n```\n\n```\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}