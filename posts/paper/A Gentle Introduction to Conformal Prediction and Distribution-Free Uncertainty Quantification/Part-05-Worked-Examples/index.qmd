---
title: "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 5)"
subtitle: "5. Worked Examples"
author: "유성현"
date: "2026-01-16"
categories: [Paper Review]
format:
  html:
    toc: true
    number-sections: false
    code-fold: show
---

# Introduction

* 지금까지 우리는 Conformal Prediction(CP)의 다양한 이론적 확장(Extension)들을 다루었습니다. 
* 이제 이 도구들이 실제 머신러닝 문제에서 어떻게 작동하는지 확인할 차례입니다.

* 이번 포스트에서는 논문의 **Section 5**에서 소개된 5가지의 구체적인 적용 사례를 살펴봅니다.
* 각 사례는 단순한 분류/회귀를 넘어, **Risk Control**, **Distribution Shift**, **Outlier Detection** 등 현실적인 난제들을 어떻게 해결하는지 보여줍니다.

# 1. Multilabel Classification with FNR Control

## Problem Setup
* 이미지 안에 있는 모든 객체를 맞추는 다중 라벨 분류(Multilabel Classification) 문제입니다.
* 단순히 정답을 포함하는 것을 넘어, **"정답 객체 중 90% 이상을 찾아내라(Recall $\ge$ 90%)"**와 같은 요구사항이 있을 때 사용합니다. 
* 이를 위해 **False Negative Rate (FNR)**를 제어합니다.
    * **Dataset**: Microsoft COCO (Common Objects in Context)
    * **Goal**: 실제 객체들($Y$) 중 모델이 예측한 집합($\mathcal{C}$)에 포함되지 않은 비율(FNR)을 $\alpha$ 이하로 유지.

## Methodology: Conformal Risk Control
* 여기서는 **Section 4.3**에서 다룬 Conformal Risk Control(CRC)을 사용합니다.

* 1.  **Prediction Set Construction**:
    * 모델의 예측 확률 $\hat{f}(x)$가 임계값 $\lambda$ 이상인 클래스들을 선택합니다.
    $$ \mathcal{C}_\lambda(x) = \{ k : \hat{f}(x)_k \ge \lambda \} $$
        * $\lambda$가 작을수록 더 많은 클래스를 포함하므로 보수적이 됨.

* 2.  **Loss Function ($l_{FNR}$)**:
    * 예측 집합이 정답을 얼마나 놓쳤는지를 정의합니다.
    $$l_{FNR}(\mathcal{C}_\lambda(x), y) = 1 - \frac{|\mathcal{C}_\lambda(x) \cap y|}{|y|}$$
    * 만약 정답 $y=\{\text{사람, 차}\}$인데 예측 $\mathcal{C}=\{\text{사람}\}$이라면, 교집합은 1개, 정답은 2개이므로 손실은 $1 - 1/2 = 0.5$입니다.

3.  **Threshold Optimization**:
    * Calibration Set에서 경험적 리스크가 $\alpha$ (보정항 포함) 이하가 되는 $\hat{\lambda}$를 찾습니다.
    $$ \hat{\lambda} = \inf \left\{ \lambda : \frac{1}{n}\sum_{i=1}^n l_{FNR}(\mathcal{C}_\lambda(X_i), Y_i) \le \alpha - \frac{1-\alpha}{n} \right\} $$

![Figure: MS COCO 데이터셋에 대한 Multilabel Classification 결과 ($\alpha=0.1$). 빨간색 텍스트는 놓친 정답(False Negative), 파란색은 잘못 예측한 오답(False Positive), 검은색은 맞춘 정답(True Positive)을 나타낸다. 평균적으로 90% 이상의 정답 라벨을 찾아내고 있다.](./images/multilabel.png)

# 2. Tumor Segmentation

## Problem Setup
* 의료 영상에서 종양(Tumor) 부위를 픽셀 단위로 분할(Segmentation)하는 문제입니다.
* 여기서도 핵심은 **"종양 픽셀을 놓치지 않는 것"**입니다. 즉, 픽셀 단위의 FNR 제어가 필요합니다.
    * **Dataset**: Gut Polyps dataset
    * **Goal**: 전체 종양 픽셀 중 예측 마스크가 커버하지 못한 비율을 제어.

## Methodology
* Multilabel Classification과 원리는 동일하지만, 대상이 **클래스**에서 **픽셀**로 바뀝니다.

* 1.  **Output**: $M \times N$ 크기의 확률 맵 $\hat{f}(x)$.
* 2.  **Prediction Mask**: 각 픽셀 $(i,j)$에 대해 확률이 $\lambda$ 이상이면 종양으로 예측.
$$\mathcal{C}_\lambda(x) = \{ (i,j) : \hat{f}(x)_{(i,j)} \ge \lambda \}$$
* 3.  **Loss Function**:
$$l(\mathcal{C}, Y) = \frac{\text{\# of missed tumor pixels}} {\text{total \# of tumor pixels}}$$    

* 이 방법을 적용하면 의사는 "이 AI가 표시한 영역 안에 실제 종양의 90%가 포함되어 있다"는 확신을 가지고 진단에 임할 수 있습니다.

![Figure: 종양 분할(Tumor Segmentation) 결과 ($\alpha=0.1$). 붉은 영역은 모델이 놓친 종양 부위(False Negative)이다. CRC를 통해 놓치는 부위를 통계적으로 최소화할 수 있다.](./images/segmentation.png)

# 3. Weather Prediction (Time-Series)

## Problem Setup
* 시간의 흐름에 따라 기온(Temperature)을 예측하는 시계열 회귀 문제입니다.
* 시간이 지남에 따라 계절이 바뀌고 기후가 변하므로, 데이터는 **i.i.d.가 아니며 분포가 표류(Distribution Drift)**합니다.
    * **Dataset**: Yandex Weather Prediction (Shifts Project)
    * **Challenge**: 과거 데이터와 현재 데이터의 상관관계가 변함.

## Methodology: Weighted Conformal Prediction
* **Section 4.6**의 분포 표류(Distribution Drift) 대응법을 사용합니다.
* 1.  **Score Function**:
    * 예측값 $\hat{f}(X_t)$와 불확실성 추정값 $\hat{u}(X_t)$를 이용한 정규화된 잔차(Normalized Residual)를 사용합니다.
    $$ s_t = \frac{|Y_t - \hat{f}(X_t)|}{\hat{u}(X_t)} $$
* 2.  **Weighted Quantile**:
    * 최근 $K$개의 데이터만 사용하는 **Sliding Window** 방식을 적용합니다.
    * 가중치 $w_{t'} = \mathbb{I}\{t' \ge t - K\}$를 사용하여, 오래된 데이터는 과감히 버리고 최근 데이터 분포에만 맞춥니다.
    $$ \hat{q}_t = \text{Quantile}_{\text{weighted}}(s_{t-K}, \dots, s_{t-1}) $$

* 결과적으로 급격한 기온 변화나 계절 변화가 발생했을 때, 일반 CP보다 훨씬 빠르게 적응하여 적절한 커버리지를 회복합니다.

![Figure: 시계열 기온 예측 결과. (왼쪽) 일반 CP(주황색)는 분포 변화 시 커버리지가 무너지지만, Weighted CP(파란색)는 빠르게 회복하여 목표 커버리지(0.9)를 유지한다. (오른쪽) 예측된 구간의 시각화.](./images/weather.png)

# 4. Toxic Comment Identification (Outlier Detection)

## Problem Setup
* 온라인 댓글이 유해한지(Toxic) 아닌지를 판별하는 문제입니다.
* 정상적인 대화(Non-toxic) 데이터만 잔뜩 있는 상태에서, 새로운 댓글이 **정상 범주를 벗어난(Outlier/Toxic)** 것인지 탐지합니다.
    * **Dataset**: Jigsaw Multilingual Toxic Comment Classification
    * **Goal**: 정상 댓글을 유해하다고 잘못 판별할 확률(False Positive Rate)을 $\alpha$ 이하로 제어. (Type-1 Error Control)

## Methodology: Conformal Outlier Detection
* **Section 4.4**의 방법을 적용합니다.
* 1.  **Heuristic Model**: BERT 기반의 유해성 점수 예측 모델 $f(x) \in [0, 1]$.
* 2.  **Calibration**: 정상 댓글(Non-toxic) $n$개에 대해 점수 $s_i = f(X_i)$를 계산하고 Quantile $\hat{q}$를 구합니다.
* 3.  **Detection**:
    $$ \mathcal{C}(x) = \begin{cases} \text{Normal} & \text{if } f(x) \le \hat{q} \\ \text{Toxic (Outlier)} & \text{if } f(x) > \hat{q} \end{cases} $$

* 이 방식은 "이 댓글은 유해합니다"라고 경보를 울릴 때, 그 경보가 오작동일 확률을 수학적으로 보장해줍니다.

![Figure: 유해 댓글 탐지 예시 ($\alpha=0.1$). 다국어 댓글에 대해 정상 댓글을 유해하다고 잘못 분류할 확률을 10%로 제한하면서, 실제 유해 댓글의 70%를 성공적으로 잡아냈다.](./images/toxic.png)

# 5. Selective Classification (Abstention)

## Problem Setup
* 모델이 확신할 수 없을 때는 **"모르겠습니다(I don't know)"**라고 대답을 거부(Abstain)하는 시스템입니다.
* 목표는 대답을 거부하지 않고 예측을 내놓았을 때의 정확도가 $\ge 1-\alpha$가 되도록 하는 것입니다.
    * **Dataset**: ImageNet
    * **Goal**: Selective Accuracy $\ge 90\%$.

## Methodology: Learn then Test
* 이 문제는 정확도(Accuracy)가 임계값 $\lambda$에 따라 단조 증가(Monotone)하지 않을 수 있기 때문에, 표준 CRC 대신 **Learn then Test** (Appendix A 내용) 프레임워크를 사용합니다.
* 1.  **Risk Definition**:
    $$ R(\lambda) = \mathbb{P}(\text{Error} \mid \text{Confidence} \ge \lambda) $$
    * 조건부 확률이므로 직접 제어하기 까다롭습니다.

* 2.  **Empirical Estimate & Upper Bound**:
    * Calibration Set에서 특정 신뢰도 $\lambda$ 이상인 샘플들의 에러율 $\hat{R}(\lambda)$를 계산합니다.
    * 이 에러율은 이항 분포(Binomial Distribution)를 따르므로, 클로퍼-피어슨(Clopper-Pearson) 구간 등을 이용해 **에러율의 보수적 상한선(Upper Bound) $\hat{R}^+(\lambda)$**을 구합니다.

* 3.  **Scan & Select**:
    $\hat{R}^+(\lambda) \le \alpha$를 만족하는 가장 작은 $\lambda$를 선택합니다.

* 결과적으로 모델은 자신이 없으면 대답을 회피하고, 대답을 했을 때는 매우 높은 정확도를 보장하게 됩니다.

![Figure: ImageNet에 대한 Selective Classification 결과. (왼쪽) $\lambda$가 커질수록(가로축), 예측을 수행하는 비율(주황색)은 줄어들지만, 정확도(파란색)는 올라간다. 점선은 목표 정확도 90%를 달성하는 지점을 나타낸다. (오른쪽) 모델이 예측한 예시(가오리)와 기권을 선택한 예시(여우).](./images/selective.png)

# Conclusion

* 이상의 5가지 예제는 Conformal Prediction이 단순히 이론적인 개념에 머무르지 않고, **실제 현업의 복잡한 문제들을 해결하는 강력한 도구**임을 보여줍니다.
    * **Segmentation/Multilabel**: 단순 에러율이 아닌 FNR 등 복잡한 Metric 제어.
    * **Time-series**: 데이터 분포 변화(Drift)에 대한 적응.
    * **Outlier Detection**: 비지도 학습 환경에서의 통계적 보장.
    * **Selective Classification**: 고위험 환경에서의 안전한 AI.

* 이 모든 과정에서 가장 중요한 것은 **"적절한 Score Function의 정의"**와 **"올바른 Calibration 기법의 선택"**입니다.

---
**Next Step**: 이제 Conformal Prediction의 핵심 이론과 응용 사례를 모두 살펴보았습니다. 다음 포스트에서는 이 모든 내용을 아우르는 **Full Conformal Prediction**과 문서를 마무리하는 논의들을 정리하며 시리즈를 마치겠습니다.