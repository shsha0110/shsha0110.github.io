[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html",
    "title": "[Paper Review] Conformal Inference of Counterfactuals and Individual Treatment Effects",
    "section": "",
    "text": "Causal Inference (인과추론) 분야에서 지난 수십 년간의 연구는 주로 모집단에 대한 평균 처치 효과(Average Treatment Effect, ATE)를 추정하는 데 집중해 왔습니다.\n식별(Identification), 추정(Estimation), 그리고 불확실성 정량화(Uncertainty Quantification)에 대한 광범위한 통계적 이론이 이를 뒷받침하고 있습니다.\n하지만 평균 효과(ATE)는 처치 효과의 분포를 매우 거칠게(coarse) 요약한 것에 불과합니다.\n경우에 따라서는 ATE만으로 개입(Intervention)의 타당성을 판단하는 것이 불충분하거나, 심지어 오해를 불러일으킬 수도 있습니다.\n\n\nMotivating Example: The 70/30 Drug Scenario\n어떤 약물이 환자의 70%를 완치시키지만, 나머지 30%의 환자에게는 증상을 훨씬 악화시킨다고 가정해 봅시다.\n\n이 경우 ATE(평균 효과)는 “양수(Positive)”로 계산될 수 있습니다.\n하지만 이 평균값만 보고 약물 승인을 결정하는 것이 윤리적으로나 의학적으로 올바른지는 불분명합니다.\n\n\n\n이것은 인위적인 예시가 아닙니다. 실제 임상 시험에서 명확한 결과가 나오지 않는 경우는 흔하며, 이러한 이질성(Heterogeneity)은 매우 일반적입니다.\n\n\n\n\n의학 분야에서는 이미 “환자의 개별성(Individuality)”을 치료 결정의 핵심에 두어야 한다는 목소리가 높습니다.\nNAM은 2018년 보고서를 통해 “One-size-fits-all(천편일률적인)” 접근 방식은 부적절하며, 임상적 특성과 개인의 선호도에 따른 맞춤형 치료가 필요함을 강조했습니다.\n이러한 개별 처치 효과(Individual Treatment Effect, ITE)에 대한 관심은 의학뿐만 아니라 정치학, 심리학, 사회학, 경제학 등 다양한 분야로 확장되고 있습니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#the-importance-of-ite-individual-treatment-effect",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#the-importance-of-ite-individual-treatment-effect",
    "title": "[Paper Review] Conformal Inference of Counterfactuals and Individual Treatment Effects",
    "section": "",
    "text": "의학 분야에서는 이미 “환자의 개별성(Individuality)”을 치료 결정의 핵심에 두어야 한다는 목소리가 높습니다.\nNAM은 2018년 보고서를 통해 “One-size-fits-all(천편일률적인)” 접근 방식은 부적절하며, 임상적 특성과 개인의 선호도에 따른 맞춤형 치료가 필요함을 강조했습니다.\n이러한 개별 처치 효과(Individual Treatment Effect, ITE)에 대한 관심은 의학뿐만 아니라 정치학, 심리학, 사회학, 경제학 등 다양한 분야로 확장되고 있습니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#problem-setup",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#problem-setup",
    "title": "[Paper Review] Conformal Inference of Counterfactuals and Individual Treatment Effects",
    "section": "2.1 Problem Setup",
    "text": "2.1 Problem Setup\n\n이 논문은 Neyman(1923)과 Rubin(1974)의 잠재적 결과 프레임워크(Potential Outcome Framework)를 따릅니다.\nSample Size: \\(n\\)명의 대상(Subjects)\nTreatment Indicator: \\(T_i \\in \\{0, 1\\}\\) (Binary)\nPotential Outcomes: \\((Y_i(1), Y_i(0))\\)\n\n\\(Y_i(1)\\): 처치를 받았을 때의 결과\n\\(Y_i(0)\\): 처치를 받지 않았을 때의 결과\n\nCovariates: \\(X_i\\) (특성 벡터)\n데이터는 i.i.d. 분포 \\((Y(1), Y(0), T, X)\\)에서 생성된다고 가정합니다. \\[(Y_i(1), Y_i(0), T_i, X_i)\\overset{\\mathrm{iid}}{\\sim}(Y(1), Y(0), T, X)\\]\n\n\nKey Assumption 1: SUTVA\n\nSUTVA(Stable Unit Treatment Value Assumption) 하에서 관측된 결과 \\(Y_i^{obs}\\)는 다음과 같이 정의됩니다.\n\n\\[\nY_i^{obs} = \\begin{cases}\nY_i(1) & \\text{if } T_i = 1 \\\\\nY_i(0) & \\text{if } T_i = 0\n\\end{cases}\n\\]\n\n우리가 알고자 하는 개별 처치 효과(ITE) \\(\\tau_i\\)는 다음과 같이 정의됩니다.\n\n\\[\n\\tau_i \\triangleq Y_i(1) - Y_i(0)\n\\tag{1}\\]\n\n여기서 인과추론의 근본적인 문제(Fundamental Problem of Causal Inference)가 발생합니다.\n각 개체에 대해 \\(Y_i(1)\\)과 \\(Y_i(0)\\) 중 오직 하나만 관측되며, 나머지는 결측(Missing)됩니다.\n\n\n\nKey Assumption 2: Strong Ignorability\n\n본 논문은 Strong Ignorability 가정을 전제합니다.\n\n\\[\n(Y(1), Y(0)) \\perp T \\mid X\n\\tag{2}\\]\n\n즉, 공변량 \\(X\\)가 주어졌을 때, 처치 할당 \\(T\\)와 잠재적 결과들은 독립입니다.\n이는 처치 할당과 결과 모두에 영향을 미치는 측정되지 않은 교란 요인(Unmeasured Confounder)이 없음을 의미합니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#traditional-inference-targets",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#traditional-inference-targets",
    "title": "[Paper Review] Conformal Inference of Counterfactuals and Individual Treatment Effects",
    "section": "2.2 Traditional Inference Targets",
    "text": "2.2 Traditional Inference Targets\n\n대부분의 머신러닝 기반 인과추론 방법론은 CATE를 추정하는 데 집중합니다.\nCATE, \\(\\tau(x)\\)는 다음과 같이 정의됩니다.\n\n\\[\n\\tau(x) \\triangleq \\mathbb{E}[Y(1) - Y(0) \\mid X=x]\n\\tag{3}\\]\n\n이 함수는 두 조건부 평균 함수 \\(m_1(x)\\)와 \\(m_0(x)\\)의 차이로 분해할 수 있습니다.\n\n\\[\n\\begin{aligned}\n\\tau(x) &= m_1(x) - m_0(x) \\\\\n\\text{where } m_1(x) &= \\mathbb{E}[Y(1) \\mid X=x] \\\\\nm_0(x) &= \\mathbb{E}[Y(0) \\mid X=x]\n\\end{aligned}\n\\]\n\nStrong Ignorability 가정 하에서, 이들은 관측 데이터의 조건부 기댓값인 \\(\\mathbb{E}[Y^{obs} \\mid X=x, T=t]\\)로 식별 가능합니다.\n\n\nWhy CATE is Insufficient?\n\n기존 연구들이 집중해 온 CATE(Conditional Average Treatment Effect)는 ATE보다 세밀한 정보를 제공하지만, 개별 의사결정(Individual Decision Making)을 위해서는 여전히 불충분합니다.\n본 논문은 크게 세 가지 관점에서 그 이유를 설명합니다.\n\n\n1. Expectation vs. Inherent Variability (CI vs. PI)\n\nCATE는 정의상 ’조건부 평균’에 불과합니다.\n\n\\[\\tau(x) = \\mathbb{E}[Y(1) - Y(0) \\mid X=x]\\]\n\n우리가 \\(n \\to \\infty\\)로 데이터를 무한히 모은다면, CATE의 추정 오차(Estimation Uncertainty)는 0으로 수렴합니다.\n이때 사용되는 것이 신뢰 구간(Confidence Interval, CI)입니다.\n하지만 실제 환자가 겪게 될 결과는 평균이 아니라 개별 사건입니다.\n개별 처치 효과(ITE)는 다음과 같이 모델링할 수 있습니다.\n\n\\[\\text{ITE}_i = \\tau(X_i) + \\varepsilon_i\\]\n\n여기서 \\(\\varepsilon_i\\)는 줄어들지 않는 내재적 변동성(Inherent Variability, Noise)입니다.\n따라서 개별 환자를 위한 의사결정에는 평균의 위치가 아니라, \\(\\varepsilon\\)까지 포함한 예측 구간(Prediction Interval, PI)이 필요합니다.\nCATE의 신뢰 구간은 이 변동성을 포착하지 못하므로, 개인이 겪을 리스크를 과소평가할 위험이 있습니다.\n\n\n\n2. Underestimation in High-Dimensional Models\n\nCATE를 추정하기 위해 Random Forest나 Neural Networks 같은 고차원 기계학습 모델을 사용할 때, 신뢰대(Confidence Band) 형성에는 근본적인 어려움이 따릅니다.\n\nBias-Variance Tradeoff: 고차원 모델은 과적합(Overfitting)을 막기 위해 정규화(Regularization) 등을 사용하며, 이는 필연적으로 추정량에 편향(Bias)을 도입합니다.\nFailure of Bootstrap: 부트스트랩이나 정규 근사(Normal Approximation)는 추정량의 분산(Variance)을 측정하는 데는 효과적이지만, 편향(Bias)은 보정하지 못합니다.\n\n결과적으로, 표준적인 기법으로 생성된 신뢰 구간은 편향된 추정치를 중심으로 형성되므로, 실제 참값(Truth)을 포함하지 못하는 과소평가(Undercoverage) 문제가 발생합니다.\n\n\n\n3. Unidentifiability of ITE Distribution\n\n변동성을 고려하기 위해 \\(Y(1)\\)과 \\(Y(0)\\)의 차이에 대한 분포를 알고 싶을 수 있습니다.\n하지만 ITE의 분산을 수식으로 분해해보면 문제가 드러납니다. \\[\n\\begin{aligned}\n\\text{Var}(\\text{ITE}) &= \\text{Var}(Y(1) - Y(0)) \\\\\n&= \\text{Var}(Y(1)) + \\text{Var}(Y(0)) - 2\\text{Cov}(Y(1), Y(0))\n\\end{aligned}\n\\]\n\\(\\text{Var}(Y(1))\\)과 \\(\\text{Var}(Y(0))\\)는 각각 처치군과 대조군 데이터로부터 식별 가능(Identifiable)합니다.\n하지만 공분산 \\(\\text{Cov}(Y(1), Y(0))\\)는 동일한 개체에 대해 두 잠재적 결과를 동시에 관측할 수 없기 때문에 데이터로부터 결코 식별할 수 없습니다(Unidentifiable).\n\n\nNote on Conditional Quantile Treatment Effect (CQTE)\n대안으로 제시되는 CQTE는 \\(Y(1)\\)의 분위수와 \\(Y(0)\\)의 분위수의 차이(\\(Q_{Y(1)} - Q_{Y(0)}\\))일 뿐입니다. 우리가 진정으로 원하는 ITE의 분위수(\\(Q_{Y(1)-Y(0)}\\))는 위에서 언급한 결합 분포(Joint Distribution)의 식별 불가능성 문제로 인해 구할 수 없습니다.\n이것이 본 논문이 결합 분포를 직접 모델링하는 대신, Conformal Inference를 통해 각 잠재적 결과의 한계 분포(Marginal Distribution)를 보장하는 우회로를 택한 이유입니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#coverage-of-interval-estimates",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#coverage-of-interval-estimates",
    "title": "[Paper Review] Conformal Inference of Counterfactuals and Individual Treatment Effects",
    "section": "2.3 Coverage of Interval Estimates",
    "text": "2.3 Coverage of Interval Estimates\n\n이 연구의 목표는 \\(Y(1)\\), \\(Y(0)\\), 그리고 최종적으로 ITE \\(\\tau_i\\)를 포함하는 예측 구간(Prediction Interval)을 구성하는 것입니다.\n예를 들어, 사전 지정된 유의 수준 \\(\\alpha\\)에 대해 \\(Y(1)\\)에 대한 구간 \\(\\hat{C}_1(x)\\)는 다음의 주변 커버리지(Marginal Coverage)를 만족해야 합니다.\n\n\\[\n\\mathbb{P}(Y(1) \\in \\hat{C}_1(X)) \\ge 1 - \\alpha\n\\tag{4}\\]\n\n마찬가지로 ITE에 대해서도 다음을 만족하는 \\(\\hat{C}_{ITE}(x)\\)를 찾고자 합니다.\n\n\\[\n\\mathbb{P}(Y(1) - Y(0) \\in \\hat{C}_{ITE}(X)) \\ge 1 - \\alpha\n\\tag{5}\\]\n\nThe Oracle Estimate\n\n만약 우리가 \\(X=x\\)일 때 \\(Y(1)\\)의 참 분위수(True Quantile) \\(q_{\\beta}(x)\\)를 완벽하게 알고 있다면, 오라클 구간(Oracle Estimate)은 다음과 같이 설정될 것입니다.\n\n\\[\nC_1(x) = [q_{\\alpha/2}(x), q_{1-\\alpha/2}(x)]\n\\]\n\n현실에서는 제한된 샘플 크기와 모델 불확실성으로 인해 \\(q_{\\beta}(x)\\)를 정확히 추정하기 어렵습니다.\n\n\nMarginal vs. Conditional Coverage\n위 식 (4), (5)는 \\(X\\)에 대한 평균적인(Marginal) 커버리지를 의미합니다.\n특정 환자 \\(x\\)에 대한 조건부 커버리지(Conditional Coverage)를 보장하는 것은 가정 없이는 불가능하다고 알려져 있습니다.\n하지만 본 연구는 조건부 커버리지에 근접하는 합리적인 근사(Approximation)를 목표로 합니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#general-coverage-criteria-transportability",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#general-coverage-criteria-transportability",
    "title": "[Paper Review] Conformal Inference of Counterfactuals and Individual Treatment Effects",
    "section": "2.4 General Coverage Criteria (Transportability)",
    "text": "2.4 General Coverage Criteria (Transportability)\n\n전통적인 인과추론에서는 ATE보다 처치군에 대한 평균 처치 효과(ATT, Average Treatment Effect on the Treated)를 선호하기도 합니다.\n이는 \\(T=1\\)인 집단의 특성을 반영합니다.\n\n\\[\n\\mathbb{P}(Y(t) \\in \\hat{C}_t(X) \\mid T=1) \\ge 1 - \\alpha \\quad (t = 0, 1)\n\\tag{6}\\]\n\n이를 일반화하여, 연구 집단(Study Population)과 타겟 집단(Target Population)의 분포가 다를 때(Covariate Shift), 타겟 집단의 공변량 분포 \\(Q_X\\)를 고려한 일반화된 커버리지 기준을 세울 수 있습니다.\n\n\\[\n\\mathbb{P}_{(X, Y(t)) \\sim Q_X \\times P_{Y(t)|X}} (Y(t) \\in \\hat{C}_t(X)) \\ge 1 - \\alpha \\quad (t = 0, 1)\n\\tag{7}\\]\n\n만약 \\(Q_X = P_{X|T=1}\\)이라면, 이는 ATT 관점에서의 커버리지가 됩니다.\n이러한 접근은 일반화 가능성(Generalizability) 또는 이식 가능성(Transportability) 문제로 확장될 수 있습니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#counterfactuals-and-covariate-shift",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#counterfactuals-and-covariate-shift",
    "title": "[Paper Review] Conformal Inference of Counterfactuals and Individual Treatment Effects",
    "section": "3.1 Counterfactuals and Covariate Shift",
    "text": "3.1 Counterfactuals and Covariate Shift\n\n반사실적 추론(Counterfactual Inference)은 기계학습에서 널리 연구된 Covariate Shift 문제의 특수한 형태로 볼 수 있습니다.\nStrong Ignorability 가정(\\((Y(1), Y(0)) \\perp T | X\\)) 하에서, 관측된 처치군 데이터의 결합 분포는 다음과 같습니다.\n\n\\[\nP_{X|T=1} \\times P_{Y(1)|X}\n\\]\n\n하지만 우리가 추론하고자 하는 타겟 모집단(전체 모집단 또는 특정 타겟 집단)의 분포는 다음과 같습니다.\n\n\\[\nQ_X \\times P_{Y(1)|X}\n\\]\n\n여기서 중요한 점은 조건부 결과 분포 \\(P_{Y(1)|X}\\)는 동일하지만, 공변량 분포가 \\(P_{X|T=1}\\)에서 \\(Q_X\\)로 변화했다는 것입니다.\n기존의 Conformal Inference는 훈련 데이터와 테스트 데이터의 분포가 동일하다는 가정(Exchangeability)에 의존하므로, 이러한 분포 변화(Shift)가 있을 때는 보정(Calibration)이 필요합니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#weighted-conformal-inference",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#weighted-conformal-inference",
    "title": "[Paper Review] Conformal Inference of Counterfactuals and Individual Treatment Effects",
    "section": "3.2. Weighted Conformal Inference",
    "text": "3.2. Weighted Conformal Inference\n\n분포 변화에 대응하기 위해, 저자들은 Tibshirani et al. (2019b)이 제안한 Weighted Conformal Inference를 도입합니다.\n\n\nStandard vs. Weighted Coverage\n\n표준 Conformal Prediction은 다음의 Marginal Coverage를 보장합니다.\n\n\\[\n\\mathbb{P}_{(X, Y) \\sim P_X \\times P_{Y|X}} (Y \\in \\hat{C}(X)) \\ge 1 - \\alpha\n\\tag{8}\\]\n\n하지만 Covariate Shift가 존재하는 우리의 설정에서는, 타겟 분포 \\(Q_X\\)에 대한 커버리지가 필요합니다.\n\n\\[\n\\mathbb{P}_{(X, Y) \\sim Q_X \\times P_{Y|X}} (Y \\in \\hat{C}(X)) \\ge 1 - \\alpha\n\\tag{9}\\]\n\n이를 달성하기 위해, 우리는 훈련 분포 \\(P_X\\)와 타겟 분포 \\(Q_X\\) 사이의 우도비(Likelihood Ratio)인 \\(w(x)\\)를 사용해야 합니다.\n\n\\[\nw(x) = \\frac{dQ_X(x)}{dP_X(x)}\n\\]\n\n\nAlgorithm: Weighted Split-CQR\n\n본 논문에서는 Conformal Quantile Regression(CQR)을 확장한 Weighted Split-CQR 알고리즘을 사용합니다.\n\n\n\n\nFigure 1: Algorithm 1 - Weighted Split-CQR. 이 알고리즘은 데이터를 학습(Training)과 교정(Calibration) 폴드로 나눈 뒤, 교정 데이터에서 계산된 Non-conformity Score들에 가중치 \\(w(x)\\)를 적용하여 예측 구간을 보정합니다.\n\n\n\n알고리즘의 핵심 단계는 다음과 같습니다:\n\n\nSplit: 데이터를 훈련 집합 \\(\\mathcal{Z}_{tr}\\)과 교정 집합 \\(\\mathcal{Z}_{ca}\\)로 분할합니다.\n\n\nFit: \\(\\mathcal{Z}_{tr}\\)을 사용하여 조건부 분위수 함수 \\(\\hat{q}_{\\alpha_{lo}}(x), \\hat{q}_{\\alpha_{hi}}(x)\\)를 학습합니다.\n\n\nScore: \\(\\mathcal{Z}_{ca}\\)의 각 데이터 포인트에 대해 Non-conformity Score \\(V_i\\)를 계산합니다. \\[V_i = \\max \\{ \\hat{q}_{\\alpha_{lo}}(X_i) - Y_i, Y_i - \\hat{q}_{\\alpha_{hi}}(X_i) \\}\\]\n\n\nWeight: 각 포인트의 가중치 \\(W_i = \\hat{w}(X_i)\\)를 계산하고, 이를 정규화하여 확률 질량(Probability Mass)을 구합니다. 이때 과거 데이터와 현재 테스트 데이터에 서로 다른 가중치 확률을 부여합니다.\n\n\n교정 데이터의 가중치 (\\(\\hat{p}_i(x)\\)): 테스트 포인트 \\(x\\)와 유사한 교정 데이터 \\(X_i\\)의 오차를 더 중요하게 반영합니다. \\[\\hat{p}_i(x) = \\frac{W_i}{\\sum_{j \\in \\mathcal{I}_{ca}} W_j + \\hat{w}(x)}\\]\n테스트 포인트의 가중치 (\\(\\hat{p}_\\infty(x)\\)): 현재 예측하려는 데이터 \\(x\\) 자신이 가질 수 있는 잠재적 불확실성을 반영합니다. 이론적 보장을 위해 이 확률은 무한대 오차(\\(\\infty\\))에 할당됩니다. \\[\\hat{p}_\\infty(x) = \\frac{\\hat{w}(x)}{\\sum_{j \\in \\mathcal{I}_{ca}} W_j + \\hat{w}(x)}\\]\n\n\nCalibrate:\n\n\n오차들의 가중 분포(Weighted Empirical Distribution)에서 \\((1-\\alpha)\\)-th 분위수 \\(\\eta(x)\\)를 계산합니다.\n즉, 오차 \\(V_i\\)를 오름차순으로 정렬한 뒤, 누적 가중치 합이 \\(1-\\alpha\\)를 넘어서는 지점을 찾습니다.\n\n\\[\\eta(x) = \\inf \\left\\{ v : \\sum_{i \\in \\mathcal{I}_{ca}} \\hat{p}_i(x) \\mathbb{I}(V_i \\le v) + \\hat{p}_\\infty(x) \\mathbb{I}(\\infty \\le v) \\ge 1-\\alpha \\right\\}\\]\n\n최종적으로 이 \\(\\eta(x)\\)만큼 구간을 확장하여 예측 구간을 생성합니다. \\[\\hat{C}(x) = [\\hat{q}_{\\alpha_{lo}}(x) - \\eta(x), \\hat{q}_{\\alpha_{hi}}(x) + \\eta(x)] \\tag{10}\\]\n\n\n\n\n\nTheoretical Guarantee (Proposition 1)\n\n만약 우도비 \\(w(x)\\)가 정확하다면, 이 알고리즘은 식 (2)의 커버리지를 정확히 만족합니다.\n\\(w(x)\\)를 추정해서 사용하더라도, 추정 오차가 작다면 커버리지는 근사적으로 보장됩니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#the-role-of-propensity-score",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#the-role-of-propensity-score",
    "title": "[Paper Review] Conformal Inference of Counterfactuals and Individual Treatment Effects",
    "section": "3.3. The Role of Propensity Score",
    "text": "3.3. The Role of Propensity Score\n\n그렇다면 이 가중치 \\(w(x)\\)는 인과추론에서 무엇에 해당할까요?\n놀랍게도(혹은 자연스럽게도), 이것은 성향 점수(Propensity Score)와 직결됩니다.\n\n\nConnection to IPW\n\n성향 점수 \\(e(x) = \\mathbb{P}(T=1|X=x)\\)는 관찰 연구에서 ATE를 식별하는 데 핵심적인 역할을 합니다. \\[\n\\begin{aligned}\n\\mathbb{E}[Y(1) - Y(0)] &= \\mathbb{E}[w_1(X){Y^{obs} I(T=1)} - w_0(X){Y^{obs} I(T=0)}] \\\\\n\\text{where } w_1(x) &= \\frac{1}{e(x)}, w_0(x) = \\frac{1}{1- e(x)}\n\\end{aligned}\n\\tag{11}\\]\nInverse Propensity Weighting (IPW) 추정량은 다음과 같이 정의됩니다. \\[\n\\mathbb{E}[Y(1)] = \\mathbb{E}\\left[ \\frac{Y^{obs} I(T=1)}{e(X)} \\right]\n\\]\nWeighted Conformal Inference에서의 가중치 도출 과정은 IPW와 매우 유사합니다.\n예를 들어, \\(Y(1)\\)에 대한 ATE 타입의 추론을 위해 베이즈 정리를 적용하면 다음과 같습니다.\n\n\\[\n\\begin{aligned}\nw_1(x) &= \\frac{dP_X(x)}{dP_{X|T=1}(x)} \\\\\n&= \\frac{dP_X(x)}{dP_X(x) \\times \\mathbb{P}(T=1 \\mid x) / \\mathbb{P}(T=1)} \\\\\n&= \\frac{dP_X(x)}{dP_X(x) \\times e(x) / \\mathbb{P}(T=1)} \\\\\n&= \\frac{\\mathbb{P}(T=1)}{e(x)} \\propto \\frac{1}{e(x)}\n\\end{aligned}\n\\]\n\nWeighted Conformal Inference는 가중치의 스케일(상수배)에 불변(Invariant)하므로, 단순히 성향 점수의 역수를 가중치로 사용하면 됩니다.\n\n\n\nSummary of Weight Functions\n\n추론 대상(ATE, ATT, ATC)이나 타겟 분포(Generalizability)에 따라 적절한 가중치 함수가 달라집니다.\n\n\n\n\nFigure 2: Table 1 - Summary of weight functions for different inferential targets. 추론하고자 하는 대상(Target)에 따라 \\(Y(1)\\)과 \\(Y(0)\\) 예측에 사용해야 할 가중치 함수 \\(w_1(x), w_0(x)\\)가 정리되어 있습니다.\n\n\n\nATE: \\(Y(1)\\)에는 \\(1/e(x)\\), \\(Y(0)\\)에는 \\(1/(1-e(x))\\)를 사용.\nATT (Effect on Treated): \\(Y(1)\\)에 대해서는 가중치가 필요 없음(1), \\(Y(0)\\)에 대해서는 오즈(Odds)인 \\(e(x)/(1-e(x))\\)를 사용.\nGeneralizability: 타겟 분포와의 비율 \\(dQ/dP\\)를 추가적으로 곱해줌.\n\n\n\n이 방법론은 두 가지 강력한 이론적 성질을 가집니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#conformalized-counterfactual-inference-is-exact-for-randomized-trials",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#conformalized-counterfactual-inference-is-exact-for-randomized-trials",
    "title": "[Paper Review] Conformal Inference of Counterfactuals and Individual Treatment Effects",
    "section": "3.4. Conformalized Counterfactual Inference is Exact for Randomized Trials",
    "text": "3.4. Conformalized Counterfactual Inference is Exact for Randomized Trials\n\n완전 순응(Perfect Compliance)이 있는 무작위 실험(RCT)의 경우, 성향 점수 \\(e(x)\\)는 연구자에 의해 설계되었으므로 정확히 알 수 있습니다.\n따라서 Weighted Conformal Inference는 유한 샘플(Finite Sample)에서도 완벽한 커버리지를 보장합니다.\n이는 점근적(Asymptotic) 이론에 의존하는 기존 방법론들과 차별화되는 지점입니다.\n심지어 Overlap 조건이 위배되어 \\(e(x) \\approx 0\\)인 영역이 있더라도, 알고리즘은 자연스럽게 구간의 길이를 무한대로 늘려 커버리지를 방어합니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#conformalized-counterfactual-inference-is-doubly-robust",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#conformalized-counterfactual-inference-is-doubly-robust",
    "title": "[Paper Review] Conformal Inference of Counterfactuals and Individual Treatment Effects",
    "section": "3.5. Conformalized Counterfactual Inference is Doubly Robust",
    "text": "3.5. Conformalized Counterfactual Inference is Doubly Robust\n\n관찰 연구에서는 성향 점수 \\(e(x)\\)와 결과 모델(Quantile) \\(q(x)\\)를 모두 추정해야 합니다.\n본 논문의 방법론은 이중 강건성(Double Robustness)을 가집니다. 즉, 다음 두 조건 중 하나만 만족해도 커버리지가 근사적으로 보장됩니다.\n\n\n성향 점수 모델이 정확함 (\\(\\hat{e}(x) \\approx e(x)\\))\n\n\n조건부 분위수 모델이 정확함 (\\(\\hat{q}(x) \\approx q(x)\\))\n\n\n\n\nIntuition\n\n만약 \\(\\hat{e} \\approx e\\)라면:\n\n가중치가 정확하므로, 분위수 모델 \\(\\hat{q}\\)가 엉망이어도 Weighted CP의 원리에 의해 커버리지가 보장됩니다.\n\n\n\n만약 \\(\\hat{q} \\approx q\\)라면:\n\n잔차(Residuals)의 분포가 안정화되어, 가중치가 부정확해도 \\(0\\) 주변에서의 분포(Quantile of residuals)가 보존됩니다.\n\n\n\n\nTheorem 1 (Formal Statement)\n\n정리 1은 이를 수학적으로 정당화합니다.\n\\(\\hat{e}_N\\)과 \\(\\hat{q}_{\\beta, N}\\)이 데이터 크기 \\(N\\)이 커짐에 따라 수렴할 때, 다음의 이중 강건성 커버리지를 만족합니다.\n\n\\[\n\\lim_{N,n \\to \\infty} \\mathbb{P}_{(X, Y(1)) \\sim P_X \\times P_{Y(1)|X}} (Y(1) \\in \\hat{C}_{N,n}(X)) \\ge 1 - \\alpha\n\\tag{12}\\]\n\n또한, 조건부 분위수 모델이 정확하게 추정된 경우(A2 조건), 조건부 커버리지(Conditional Coverage) 또한 점근적으로 달성됩니다.\n\n\\[\n\\lim_{N,n \\to \\infty} \\mathbb{P}_{X \\sim P_X} (\\mathbb{P}(Y(1) \\in \\hat{C}_{N,n}(X) | X) \\le 1 - \\alpha - \\epsilon) = 0\n\\tag{13}\\]\n\n이는 이 방법론이 단순히 평균적인 커버리지만 맞추는 것이 아니라, 개별 환자 수준에서의 불확실성도 잘 포착할 수 있음을 시사합니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#numerical-experiments",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#numerical-experiments",
    "title": "[Paper Review] Conformal Inference of Counterfactuals and Individual Treatment Effects",
    "section": "3.6. Numerical Experiments",
    "text": "3.6. Numerical Experiments\n\nSimulation Setup\n\n저자들은 Wager and Athey (2018)의 설정을 변형하여 시뮬레이션을 설계했습니다.\n\n\nData Generation Process\n\nCovariates (\\(X\\)):\n\n\\(X = (X_1, ..., X_d)^T\\)는 다변량 가우시안 분포에서 생성된 뒤 변환됩니다. \\[X_j = \\Phi(X_j')\\]\n여기서 \\(\\Phi\\)는 표준정규분포의 CDF이며, \\(Var(X_j')=1\\), \\(Cov(X_j', X_{j'}') = \\rho\\)입니다. \\(\\rho=0\\)이면 독립, \\(\\rho&gt;0\\)이면 상관관계가 존재합니다.\n\nPotential Outcomes:\n\n순수한 반사실적(Counterfactual) 추론 문제를 다루기 위해 \\(Y(0) \\equiv 0\\)으로 고정합니다.\n\\(Y(1)\\)은 다음과 같이 생성됩니다:\n\n\\[\n\\mathbb{E}[Y(1)|X] = f(X_1)f(X_2), \\quad f(x) = \\frac{2}{1+\\exp\\{-12(x-0.5)\\}}\n\\]\n\\[\nY(1) = \\mathbb{E}[Y(1)|X] + \\sigma(X)\\epsilon, \\quad \\epsilon \\sim N(0, 1)\n\\]\n\n이 설정은 비선형성(Non-linearity)을 포함하고 있습니다.\n\nPropensity Score:\n\n성향 점수 \\(e(x)\\)는 다음과 같이 설정하여, 항상 \\(0.25 \\le e(x) \\le 0.5\\) 범위에 있도록 하여 충분한 Overlap을 보장합니다.\n\n\\[\ne(x) = \\frac{1}{4}(1 + \\beta_{2,4}(X_1))\n\\]\n\n여기서 \\(\\beta_{2,4}\\)는 Beta(2,4) 분포의 CDF입니다.\n\n\n\n\nScenarios\n\n총 \\(2 \\times 2 \\times 2 = 8\\)가지 시나리오를 고려합니다.\n\n\nDimension: Low (\\(d=10\\)) vs. High (\\(d=100\\))\n\n\nCorrelation: Uncorrelated (\\(\\rho=0\\)) vs. Correlated (\\(\\rho=0.9\\))\n\n\nError Variance: Homoscedastic (\\(\\sigma^2(x) \\equiv 1\\)) vs. Heteroscedastic (\\(\\sigma^2(x) = -\\log X_1\\))\n\n\n\n\n\n\nCompeting Methods\n\n본 연구의 방법론(Weighted Split-CQR)을 다음의 세 가지 널리 알려진 방법들과 비교합니다.\n\nCausal Forest (CF):\n\n\ngrf 패키지 사용.\nInfinitesimal Jackknife를 사용해 CATE의 분산을 추정합니다.\n본래 ITE 구간 추정용은 아닙니다.\n\n\nX-learner:\n\n\ncausalToolbox 패키지 사용.\nBootstrap을 사용해 CATE의 분산을 추정합니다.\n역시 ITE용은 아닙니다.\n\n\nBART (Bayesian Additive Regression Trees):\n\n\nbartMachine 패키지 사용.\n베이지안 기법으로 Credible Interval(CATE용)과 Prediction Interval(ITE용)을 모두 생성할 수 있어 가장 강력한 경쟁자입니다.\n\nWeighted Split-CQR (Our Method)은 성향 점수 추정에 Gradient Boosting을 사용하며, 조건부 분위수(Quantile) 추정에는 (1) Quantile RF, (2) Quantile Boosting, (3) BART 세 가지를 각각 적용하여 테스트했습니다.\n\n\n\n\nResults: Coverage Performance\n\n실험은 100번 반복되었으며, 매번 10,000개의 테스트 포인트에 대해 95% 신뢰구간/예측구간을 생성했습니다.\n\n\nTheoretical vs. Empirical Coverage\n\n먼저 각 방법론이 이론적으로 보장하는 커버리지와 실제 시뮬레이션 결과를 요약한 표입니다.\n\n\n\n\nFigure 1: Table 2 - Summary of coverage guarantees. 이론적으로 Causal Forest와 X-learner는 CATE만 커버하도록 설계되었으며, ITE는 커버하지 못합니다. BART와 CQR만이 ITE 커버리지를 목표로 합니다.\n\n\n\n이론(Theory):\n\nCF와 X-learner는 CATE(\\(\\tau(x)\\))에 대한 커버리지만 보장합니다.\n반면, CQR은 ITE(\\(Y(1)-Y(0)\\))에 대한 커버리지를 보장합니다.\n\n실제(Simulation):\n\nCATE에 대해서조차 CF와 X-learner는 커버리지가 불충분함을 보여줍니다.\n반면 CQR은 CATE와 ITE 모두에 대해 유효한 커버리지를 달성합니다.\n\n\n\n\nCoverage of CATE\n\n아래 그림은 CATE(조건부 평균)에 대한 커버리지 결과입니다.\n\n\n\n\nFigure 2: Figure 1 - Empirical 95% coverage of CATE. 8가지 시나리오에 대한 CATE 커버리지 결과입니다. 빨간 실선은 목표 수준인 0.95를 나타냅니다.\n\n\n\nCF & X-learner: 모든 시나리오에서 저조한 성능을 보이며, 특히 고차원(\\(d=100\\))에서 성능이 급격히 하락합니다.\nBART: 대체로 좋은 성능을 보이지만, “Correlated Covariates + Heteroscedastic Errors” (가장 오른쪽 열) 시나리오에서는 커버리지가 무너지는 모습을 보입니다.\nCQR (제안 방법): ITE를 타겟으로 설계되었음에도 불구하고, 모든 시나리오에서 95% 이상의 CATE 커버리지를 달성합니다. 다소 보수적(Conservative)일 수 있으나, 안정적입니다.\n\n\n\nCoverage of ITE (Main Result)\n\n이 논문의 핵심 주제인 개별 처치 효과(ITE)에 대한 커버리지입니다.\n\n\n\n\nFigure 3: Figure 2 - Empirical 95% coverage of ITE. ITE에 대한 커버리지 결과입니다. Causal Forest와 X-learner는 ITE 예측 구간을 생성하도록 설계되지 않았으므로 매우 낮은 커버리지를 보입니다.\n\n\n\nCF & X-learner: 예상대로 ITE를 전혀 커버하지 못합니다. 이는 CATE 신뢰 구간을 ITE 예측 구간으로 오해해서는 안 된다는 점을 시사합니다.\nBART: 등분산(Homoscedastic) 환경에서는 완벽한 커버리지를 보이지만, 이분산(Heteroscedastic) 환경, 특히 상관관계가 있는 경우 성능이 떨어집니다.\nCQR: 모든 시나리오(차원, 상관관계, 이분산성 여부)에서 거의 정확한 95% 커버리지를 달성합니다.\n\n\n\n\n\nResults: Interval Length & Efficiency\n\n커버리지가 높다고 무조건 좋은 것은 아닙니다. 구간의 길이가 너무 넓으면 정보가치가 없기 때문입니다.\n\n\n\n\nFigure 4: Figure 3 - Lengths of interval estimates for ITE. 파란색 수직선은 Oracle Interval(이상적인 길이)을 나타냅니다.\n\n\n\nCF & X-learner: 구간 길이가 매우 짧습니다. 앞서 보았듯 이는 커버리지 실패(Poor calibration)의 결과이므로 의미가 없습니다.\nBART vs. CQR:\n\n등분산(Homoscedastic) 환경에서 BART는 가장 짧은 구간을 생성합니다. CQR(with BART learner)도 이에 근접한 효율성을 보입니다.\n이분산(Heteroscedastic) 환경에서 BART의 구간은 너무 짧아 커버리지 실패로 이어집니다. 반면 CQR은 커버리지를 유지하기 위해 구간 길이를 늘립니다. 이때 CQR의 구간 길이 변동성이 커지는 경향이 있습니다.\n\n\n\n\n\nResults: Conditional Coverage\n\n마지막으로, 조건부 커버리지(Conditional Coverage)를 분석합니다.\n이분산 설정(\\(\\sigma^2(x) = -\\log X_1\\))에서는 \\(X_1 \\to 0\\)일 때 분산이 무한대로 발산하므로, 예측하기 가장 어려운 영역입니다.\n\n\n\n\nFigure 5: Figure 4 - Estimated conditional coverage of ITE. x축은 조건부 분산의 분위수(Percentile)를 나타냅니다. 오른쪽으로 갈수록 예측이 어려운 데이터 포인트입니다.\n\n\n\nBART: 조건부 분산이 커질수록(x축의 오른쪽), 커버리지 확률이 급격히 떨어지는 것을 확인할 수 있습니다. 평균적으로는 괜찮을지 몰라도, 불확실성이 큰 환자군에 대해서는 리스크를 과소평가할 위험이 있습니다.\nCQR: 분산이 큰 영역에서도 커버리지를 안정적으로 유지(Flat curve)합니다. 특히 Quantile RF나 Quantile Boosting을 사용한 CQR이 BART 기반 CQR보다 더 나은 조건부 커버리지를 보입니다.\n\n\n\n\nSummary\n\n이번 실험 결과는 Weighted Split-CQR의 강력함을 실증적으로 보여주었습니다.\n\n\nRobustness: 기존 방법론(BART 포함)이 실패하는 고차원, 상관관계, 이분산성 환경에서도 CQR은 약속된 커버리지(95%)를 지켜냈습니다.\n\n\nSafety: CATE를 위한 신뢰 구간(CF, X-learner)을 ITE 예측에 무리하게 사용할 경우, 불확실성을 심각하게 과소평가할 수 있음이 드러났습니다.\n\n\nAdaptability: CQR은 데이터의 불확실성 수준(조건부 분산)에 따라 구간의 길이를 적절히 조절하여, 어려운 케이스에서도 신뢰할 수 있는 예측을 제공합니다.\n\n\n이로써 우리는 평균적인 효과를 넘어, 개별 환자에게 적용 가능한 안전하고 신뢰할 수 있는 인과추론 도구를 확보하게 되었습니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#a-naive-approach",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#a-naive-approach",
    "title": "[Paper Review] Conformal Inference of Counterfactuals and Individual Treatment Effects",
    "section": "4.1. A Naive Approach",
    "text": "4.1. A Naive Approach\n\n가장 직관적인 첫 번째 방법은 Part 2에서 개발한 반사실적 예측 구간을 각각 독립적으로 적용하는 것입니다.\n임의의 테스트 포인트 \\(x\\)에 대해, 우리는 \\(Y(1)\\)과 \\(Y(0)\\)에 대한 \\(1-\\alpha/2\\) 수준의 예측 구간을 각각 생성할 수 있습니다.\n\n\\(Y(1)\\)에 대한 구간: \\([\\hat{Y}^L(1; x), \\hat{Y}^R(1; x)]\\)\n\\(Y(0)\\)에 대한 구간: \\([\\hat{Y}^L(0; x), \\hat{Y}^R(0; x)]\\)\n\n이 두 구간을 결합(Contrast)하여 ITE(\\(\\tau = Y(1) - Y(0)\\))에 대한 구간 \\(\\hat{C}_{ITE}(x)\\)를 다음과 같이 구성할 수 있습니다.\n\n\\[\n\\hat{C}_{ITE}(x) = [\\hat{Y}^L(1; x) - \\hat{Y}^R(0; x), \\quad \\hat{Y}^R(1; x) - \\hat{Y}^L(0; x)]\n\\]\n\nCoverage Guarantee\n\n만약 각각의 반사실적 구간이 유효한 커버리지를 가진다면, 본페로니 교정(Bonferroni correction)의 원리에 의해 이 결합 구간 또한 최소 \\(1-\\alpha\\) 수준의 커버리지를 보장합니다.\n하지만 이 방식은 보수적(Conservative)일 가능성이 높습니다.\n두 구간의 최악의 경우(Worst-case)를 조합하기 때문에 구간의 길이가 필요 이상으로 넓어질 수 있습니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#a-nested-approach",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#a-nested-approach",
    "title": "[Paper Review] Conformal Inference of Counterfactuals and Individual Treatment Effects",
    "section": "4.2. A Nested Approach",
    "text": "4.2. A Nested Approach\n\n저자들은 Naive Approach의 한계를 극복하기 위해 Nested Approach(중첩 접근법)를 제안합니다.\n이 방법은 데이터를 분할하여 ITE에 대한 ’대리 구간(Surrogate Interval)’을 먼저 생성하고, 이를 학습하여 일반화하는 전략을 취합니다.\n\n\nThe Procedure\n\n이 절차는 데이터를 두 개의 폴드(Fold 1, Fold 2)로 나누는 것으로 시작합니다.\n\nFold 1 (Training Counterfactuals):\n\n\n첫 번째 폴드를 사용하여 반사실적 구간 모델 \\(\\hat{C}_1(x)\\)와 \\(\\hat{C}_0(x)\\)를 학습합니다.\n\n\nFold 2 (Constructing Surrogate Intervals):\n\n\n두 번째 폴드에 있는 각 유닛 \\(i\\)에 대해, 관측된 \\(Y_i^{obs}\\)와 처치 여부 \\(T_i\\)를 바탕으로 ITE 구간 \\(\\hat{C}_i\\)를 생성합니다.\n만약 \\(T_i = 1\\)이라면:\n\n우리는 \\(Y_i(1)\\)을 알고 있습니다.\n따라서 \\(Y_i(0)\\)에 대한 예측 구간 \\(\\hat{C}_0(X_i)\\)를 사용하여 ITE 구간을 만듭니다. \\[\\hat{C}_i = Y_i^{obs} - \\hat{C}_0(X_i) = [Y_i^{obs} - \\hat{Y}_R(0), Y_i^{obs} - \\hat{Y}_L(0)]\\]\n\n만약 \\(T_i = 0\\)이라면:\n\n우리는 \\(Y_i(0)\\)를 알고 있습니다.\n\\(Y_i(1)\\)에 대한 예측 구간 \\(\\hat{C}_1(X_i)\\)를 사용합니다. \\[\\hat{C}_i = \\hat{C}_1(X_i) - Y_i^{obs} = [\\hat{Y}_L(0) - Y_i^{obs}, \\hat{Y}_R(0) - Y_i^{obs}]\\]\n\n\n\n\n\n\nFigure 1: Table 3 - Sketch of the two folds in the nested approach. 첫 번째 폴드는 반사실적 구간을 학습하는 데 사용되고, 두 번째 폴드는 이를 바탕으로 ITE를 추론하는 데 사용됩니다. 이 표는 각 처치 그룹별로 어떤 값이 관측되고 어떤 값이 예측 구간으로 대체되는지 보여줍니다.\n\n\n\n\nTheoretical Justification\n\n이렇게 생성된 구간 \\(\\hat{C}_i\\)가 실제로 ITE를 잘 커버할까요? 수학적으로 이를 증명할 수 있습니다.\nFold 2에 있는 임의의 유닛 \\(i\\)에 대해 커버리지 확률은 다음과 같이 분해됩니다.\n\n\\[\n\\begin{aligned}\n\\mathbb{P}(Y_i(1) - Y_i(0) \\in \\hat{C}_i) &= \\mathbb{P}(T_i=1)\\mathbb{P}(Y_i(0) \\in \\hat{C}_0(X_i) \\mid T_i=1) \\\\\n&+ \\mathbb{P}(T_i=0)\\mathbb{P}(Y_i(1) \\in \\hat{C}_1(X_i) \\mid T_i=0)\n\\end{aligned}\n\\tag{14}\\]\n\nWeighted Conformal Inference를 통해 각 조건부 확률이 \\(1-\\alpha\\) 이상이 되도록 만들었으므로, 전체 확률 또한 보장됩니다.\n\n\\[\n\\mathbb{P}(Y_i(1) - Y_i(0) \\in \\hat{C}_i) \\ge 1-\\alpha\n\\tag{15}\\]\n\n결과적으로, Nested Procedure는 Fold 2 데이터셋을 \\((X_i, \\hat{C}_i)\\) 형태의 새로운 데이터셋으로 변환합니다.\n여기서 \\(\\hat{C}_i\\)는 ITE에 대한 불확실한 관측값(Noisy measurement) 역할을 합니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#an-inexact-and-an-exact-method-under-the-nested-framework",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#an-inexact-and-an-exact-method-under-the-nested-framework",
    "title": "[Paper Review] Conformal Inference of Counterfactuals and Individual Treatment Effects",
    "section": "4.3. An Inexact and an Exact Method Under The Nested Framework",
    "text": "4.3. An Inexact and an Exact Method Under The Nested Framework\n\n이제 우리는 \\((X_i, \\hat{C}_i)\\) 데이터셋을 가지고 있습니다.\n이를 활용해 새로운 환자 \\(x\\)에 대한 ITE 구간 \\(\\tilde{C}_{ITE}(x)\\)를 어떻게 생성할까요?\n저자들은 Inexact Method와 Exact Method 두 가지를 제시합니다.\n\n\nThe Inexact Method\n\n가장 간단한 방법은 머신러닝 모델을 사용하여 \\(\\hat{C}_i\\)의 왼쪽 끝점(Left endpoint)과 오른쪽 끝점(Right endpoint)을 학습하는 것입니다.\n예를 들어, 왼쪽 끝점의 40% 분위수와 오른쪽 끝점의 60% 분위수를 예측하는 모델을 각각 적합할 수 있습니다.\n이 방법은 계산이 빠르고 구현이 쉽지만, 새로운 데이터 포인트에 대한 엄밀한 커버리지 보장(Formal Guarantee)은 제공하지 않습니다.\n따라서 “Inexact”라고 부릅니다.\n\n\n\nThe Exact Method (Double Conformal)\n\n매우 민감한 의료 결정 등 엄밀한 보장이 필요한 경우, 두 번째 Conformal Inference를 적용할 수 있습니다.\n우리의 목표는 다음을 만족하는 구간 확장 함수(Interval Expansion Function) \\(\\hat{\\mathcal{C}}(X)\\)를 찾는 것입니다. \\[\\mathbb{P}(\\hat{C}_i \\subset \\hat{\\mathcal{C}}(X)) \\ge 1-\\gamma \\tag{16}\\]\n만약 이것이 성립한다면, 전체 ITE에 대한 커버리지는 \\(1 - (\\alpha + \\gamma)\\) 수준으로 보장됩니다.\n\n\n\nAlgorithm 2: Conformal Inference for Interval Outcomes\n\n이를 위해 저자들은 구간형 결과변수(Interval Outcome)를 위한 Conformal Inference 알고리즘을 제안합니다.\n\n\n\n\nFigure 2: Algorithm 2 - Conformal inference for interval outcomes. 구간 \\(C_i=[C_i^L, C_i^R]\\)를 타겟으로 하여, 이를 포함하는 예측 구간을 생성하는 알고리즘입니다. \\(C^L\\)과 \\(C^R\\)에 대한 회귀 모델을 기반으로 Non-conformity Score를 계산하고 보정합니다.\n\n\n\n\n데이터 \\((X_i, C_i)\\)를 다시 학습/교정 폴드로 나눕니다.\n\n\n구간의 양 끝점 \\(C^L, C^R\\)에 대한 평균/중앙값을 예측하는 모델 \\(\\hat{m}^L, \\hat{m}^R\\)을 학습합니다.\n\n\nNon-conformity Score \\(V_i\\)를 계산합니다. \\[V_i = \\max \\{ \\hat{m}^L(X_i) - C_i^L, \\quad C_i^R - \\hat{m}^R(X_i) \\}\\]\n\n\n이 점수는 예측된 구간 \\([\\hat{m}^L, \\hat{m}^R]\\)이 실제 구간 \\(C_i\\)를 포함하지 못하는 정도(거리)를 의미합니다.\n\n\n이 점수의 분위수 \\(\\eta\\)를 계산하여 최종 구간을 확장합니다.\n\n\n\n\nSummary of Nested Algorithm\n\n최종적으로, 이 모든 과정을 통합한 Algorithm 3는 다음과 같습니다.\n\n\n\n\nFigure 3: Algorithm 3 - Nested approach for interval estimates of ITE. 전체 과정을 요약한 알고리즘입니다. Step 1에서 데이터 분할 및 성향 점수 추정, Step 2에서 Counterfactual Inference를 통한 대리 구간 생성, Step 3에서 이를 일반화하여 최종 ITE 구간을 도출합니다.\n\n\n\nStep I: 데이터 분할 (\\(\\mathcal{Z}_1, \\mathcal{Z}_2\\)) 및 성향 점수 추정.\nStep II: \\(\\mathcal{Z}_2\\)의 각 데이터에 대해 Counterfactual Inference 수행 \\(\\to\\) 대리 구간 \\(\\hat{C}_i\\) 생성.\nStep III: \\((X_i, \\hat{C}_i)\\) 데이터를 사용하여 Inexact(Quantile Regression) 또는 Exact(Algorithm 2) 방식으로 최종 모델 학습."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#empirical-performance",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#empirical-performance",
    "title": "[Paper Review] Conformal Inference of Counterfactuals and Individual Treatment Effects",
    "section": "4.4. Empirical Performance",
    "text": "4.4. Empirical Performance\n\n새로운 환자(Test Subject)에 대해 ITE 구간을 추정하기 위한 Naive Approach와 Nested Approach를 제안했습니다.\n특히 Nested Approach는 대리 구간(Surrogate Interval)을 생성하여 모델을 학습시키는 독창적인 방식이었습니다.\n아래에서는 이 방법론들의 실증적 성능(Empirical Performance)을 검증합니다.\n2018 Atlantic Causal Inference Conference (ACIC) 워크숍 데이터를 기반으로 한 시뮬레이션 결과와, 실제 교육학 실험인 NLSM(National Study of Learning Mindsets) 데이터 재분석 결과를 다룹니다.\n\n\n\nSimulation Study: ACIC 2018 / NLSM Data\n\n연구진은 방법론의 성능을 평가하기 위해 2018 ACIC 워크숍 데이터를 활용하여 수치 실험을 설계했습니다.\n이 데이터는 NLSM이라는 대규모 무작위 행동 개입 실험을 기반으로 하여, 관찰 연구(Observational Study)의 특성을 모방하도록 생성된 합성 데이터셋입니다.\n\n\nData Generation Process\n\n커버리지(Coverage)를 평가하기 위해서는 Ground Truth(실제 ITE)를 알아야 합니다.\n하지만 원본 데이터는 개인정보 문제로 제한적으로 공개되었고, ITE에 대한 Ground Truth가 없었습니다.\n따라서 저자들은 공개된 정보를 바탕으로 다음과 같이 합성 데이터를 생성했습니다.\n\nData Splitting: 전체 데이터를 \\(\\mathcal{Z}_1\\)(20%)과 \\(\\mathcal{Z}_2\\)(80%)로 나눕니다.\n\n\nBase Outcomes: \\(\\mathcal{Z}_1\\)에서 Random Forest를 학습하여 \\(\\mathbb{E}[Y(0)]\\)인 \\(\\hat{m}_0(x)\\)를 추정합니다.\n\n\nHeterogeneity: Carvalho et al. (2019)의 CATE 함수 \\(\\tau(x)\\)를 \\(\\hat{m}_0(x)\\)에 더해 \\(\\mathbb{E}[Y(1)]\\)을 생성합니다.\n\n\nHeteroscedasticity: 이분산성을 반영하기 위해 Quantile Random Forest로 조건부 사분위수 범위 \\(\\hat{r}_0(x), \\hat{r}_1(x)\\)를 추정합니다.\n\n최종적으로 잠재적 결과(Potential Outcomes)는 다음과 같이 생성됩니다: \\[\n\\begin{aligned}\nY_i(1) &= \\hat{m}_0(X_i) + \\tau(X_i) + 0.5\\hat{r}_1(X_i)\\epsilon_{i1} \\\\\nY_i(0) &= \\hat{m}_0(X_i) + 0.5\\hat{r}_0(X_i)\\epsilon_{i0}\n\\end{aligned}\n\\]\n\n단, \\(\\epsilon \\sim N(0,1)\\)\n\n성향 점수(Propensity Score) \\(\\hat{e}(x)\\)는 Random Forest로 추정한 뒤 \\([0.1, 0.9]\\)로 잘라내어(Truncating) 충분한 Overlap을 보장했습니다.\n\n\n\nExperimental Setup\n\nTraining Set: \\(n=1000\\)개의 관찰 데이터 \\((X_i, T_i, Y_i^{obs})\\).\nTest Set: \\(5000\\)개의 데이터. 분석가에게는 \\(X_i\\)만 제공되며, \\((T_i, Y_i(1), Y_i(0))\\)는 오직 평가용으로만 사용됩니다.\nMethods Compared:\n\nOur Methods: Weighted Split-CQR 기반의 (1) Naive, (2) Exact Nested, (3) Inexact Nested 방식. (Base Learner: BART)\nCompetitors: BART (Naive, Inexact), Causal Forest, X-learner.\nNote: Causal Forest와 X-learner는 반사실적 구간(Counterfactual Interval)을 생성할 수 없으므로, 그들의 신뢰 구간(CI)을 벤치마크로 직접 비교합니다.\n\n\n\n\n\n\nSimulation Results\n\nMarginal Coverage and Interval Length\n\n\n\nFigure 1: Coverage (left) and average length (right) of intervals for ITE on synthetic data. 왼쪽 패널의 빨간 수직선은 목표 커버리지(95%)를 나타냅니다. Causal Forest와 X-learner는 ITE를 커버하지 못하는 반면, 제안된 CQR 기반 방법들은 모두 목표를 달성합니다. 특히 Inexact CQR은 효율적인 구간 길이를 보여줍니다.\n\n\n\n실험 결과(Figure 5)에서 주목할 점은 다음과 같습니다:\n\nNaive Methods (Conservative): CQR(Naive)과 BART(Naive)는 95%를 훨씬 상회하는 커버리지를 보입니다. 이는 두 개의 반사실적 구간을 단순 결합했기 때문에 구간 길이가 불필요하게 길어졌음을 의미합니다.\n\n\nNested Methods:\n\n\nExact Nested CQR: 여전히 보수적이지만 유효한 커버리지를 보장합니다.\nInexact Nested CQR: 가장 균형 잡힌 성능을 보입니다. 보수성을 줄이면서도 목표 커버리지(95%)를 달성했습니다. 구간 길이 또한 Inexact BART와 유사한 수준으로 매우 짧습니다.\n\n\nCompetitors:\n\n\nBART: 단독으로 사용된 BART(Inexact)는 목표 커버리지를 달성하지 못했습니다. 하지만 CQR의 Learner로 사용된 BART는 성공적으로 보정(Calibrated)되었습니다.\nCF / X-learner: 이전 실험과 마찬가지로 ITE를 커버하지 못했습니다.\n\n\n\n\nConditional Coverage\n\n단순히 평균적인 커버리지만 맞추는 것이 아니라, 조건부 분산 \\(\\sigma^2(x)\\)이나 CATE \\(\\tau(x)\\)에 따라 커버리지가 어떻게 변하는지 확인해야 합니다.\n\n\n\n\nFigure 2: Estimated conditional coverage of ITE. 상단 행은 조건부 분산에 따른 커버리지, 하단 행은 CATE 값에 따른 커버리지입니다. Inexact-CQR(오른쪽)은 조건부 분산이 변해도 커버리지를 안정적으로 유지하는 반면, Inexact-BART(왼쪽에서 두 번째)는 불안정한 모습을 보입니다.\n\n\n\nInexact-CQR: 조건부 분산이 크거나 작은 영역 모두에서 상대적으로 균일한(Even) 커버리지를 유지합니다.\nInexact-BART: 조건부 분산이 커질수록(상단 두 번째 패널의 오른쪽) 커버리지가 급격히 떨어지는 경향을 보입니다. 이는 리스크가 큰 환자군에 대해 잘못된 확신을 줄 수 있음을 시사합니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#re-analysing-nlsm-data",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#re-analysing-nlsm-data",
    "title": "[Paper Review] Conformal Inference of Counterfactuals and Individual Treatment Effects",
    "section": "4.5. Re-analysing NLSM Data",
    "text": "4.5. Re-analysing NLSM Data\n\n마지막으로, 실제 NLSM(National Study of Learning Mindsets) 데이터를 사용하여 탐색적 분석(Exploratory Analysis)을 수행했습니다.\n실제 데이터이므로 Ground Truth는 알 수 없지만, 제안된 방법론이 실제 의사결정에 어떻게 활용될 수 있는지 보여줍니다.\n\n\nMethodology\n\n데이터를 두 개의 폴드(\\(\\mathcal{Z}_1, \\mathcal{Z}_2\\))로 나누고, 서로를 테스트 셋으로 활용하는 교차 검증 방식을 사용했습니다.\nWeighted Inexact-CQR (with BART) 모델을 적용하여 각 개인의 ITE 구간을 추정했습니다.\n\n\n\nFindings\n\n\n\nFigure 3: Re-analysis of NLSM data. (a) 유의수준 \\(\\alpha\\)에 따른 평균 구간 길이, (b) 하한이 양수인 구간(확실한 긍정 효과)의 비율, (c) 상한이 음수인 구간(확실한 부정 효과)의 비율을 보여줍니다.\n\n\n\n분석 결과는 다음과 같은 통찰을 제공합니다:\n\nInterval Length (a): 유의 수준 \\(\\alpha\\)가 커질수록(즉, 신뢰 수준이 낮아질수록) 구간의 길이는 감소합니다.\n\n\nPositive Effects (b): \\(\\alpha &gt; 0.25\\)인 지점부터 하한이 0보다 큰(Lower bound &gt; 0) 구간들이 나타나기 시작합니다.\n\n\n이는 해당 환자들에게 처치가 확실히 긍정적인 효과를 준다는 증거로 해석할 수 있습니다.\n의사결정자는 이러한 구간을 가진 환자들을 선별하여 처치를 배정할 수 있습니다.\n\n\nNegative Effects (c): \\(\\alpha=0.5\\)까지 높여도 상한이 0보다 작은(Upper bound &lt; 0) 구간은 나타나지 않았습니다.\n\n\n이는 이 개입(Intervention)이 적어도 해로움을 주지는 않는다는 강력한 증거가 됩니다.\n\n이러한 분석은 단순히 평균 효과(ATE)가 양수라는 것을 넘어, “누구에게 확실히 효과가 있는가?” 그리고 “누구에게 해로울 가능성이 있는가?”라는 질문에 답할 수 있게 해줍니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#causal-diagram-framwork",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#causal-diagram-framwork",
    "title": "[Paper Review] Conformal Inference of Counterfactuals and Individual Treatment Effects",
    "section": "5.1. Causal Diagram Framwork",
    "text": "5.1. Causal Diagram Framwork\n\nJudea Pearl의 인과 도표(Causal Diagram) 프레임워크는 반사실적(Counterfactual) 개념 대신 \\(do\\)-operator를 사용하여 인과 효과를 정의합니다.\n\n\nProblem Setup\n\n\\(T\\): 개입 변수 (Intervention Variable)\n\\(Y\\): 결과 변수 (Outcome Variable)\n\\(X\\): 교란 요인 집합 (Set of variables satisfying the back-door criterion)\nPearl의 프레임워크에서 \\(X\\)가 Back-door Criterion을 만족한다는 것은, \\(X\\)가 모든 교란 요인을 포함하고 처치 후 변수(Post-treatment variables)는 배제한다는 것을 의미합니다.\n\n\n\nIdentification via Do-Calculus\n\nPearl (1995)의 근본적인 결과에 따르면, 개입(Intervention) 후의 결합 분포는 다음과 같이 분해됩니다.\n\n\\[\nP_{(X,Y)|do(T=t)} = P_X \\times P_{Y|X, T=t}\n\\]\n\n여기서 개입(\\(do(T=t)\\))을 했을 때 \\(X\\)가 편향되지 않는 이유는 인과 도표(Causal Diagram)의 관점에서 명확히 이해할 수 있습니다.\n\nGraph Surgery: \\(do(T=t)\\) 연산은 인과 그래프에서 \\(T\\)로 들어오는 모든 화살표(Causal paths pointing to \\(T\\))를 제거합니다. 즉, 교란 요인 \\(X\\)가 처치 \\(T\\)에 영향을 미치는 경로(\\(X \\to T\\))가 차단됩니다.\n\n\nIndependence: 경로가 차단되었으므로, \\(T\\)는 더 이상 \\(X\\)에 의존하지 않고 외부에서 강제로 고정된 값이 됩니다.\n\n\nResult: 따라서 \\(T=t\\)라는 조건 하에서도 공변량 \\(X\\)의 분포는 변하지 않고, 원래 모집단의 분포 \\(P_X\\)를 그대로 유지합니다. 즉, 특정 처치를 선택한 집단에 쏠리지 않게 됩니다.\n\n반면, 우리가 실제 데이터에서 관측(Observation)하는 조건부 분포는 다음과 같습니다.\n\n\\[\nP_{(X,Y)|T=t} = P_{X|T=t} \\times P_{Y|X, T=t}\n\\]\n\n관찰(Observation) 상황에서는 \\(X \\to T\\)의 영향이 존재하므로, 처치군(\\(T=t\\))의 공변량 분포 \\(P_{X|T=t}\\)는 전체 모집단 분포 \\(P_X\\)와 다릅니다(Selection Bias).\n하지만 반응 메커니즘인 \\(P_{Y|X, T=t}\\)는 개입 여부와 상관없이 동일(Invariant)하다는 것이 이 식별 전략의 핵심입니다.\n\n\n\nConnection to Conformal Inference\n\n위 두 식을 비교해보면, 잠재적 결과 프레임워크와 정확히 동일한 구조를 가지고 있음을 알 수 있습니다.\n조건부 분포 \\(P_{Y|X, T=t}\\)는 개입 여부와 상관없이 불변(Invariant)입니다.\n차이점은 오직 공변량 분포의 변화(\\(P_{X|T=t} \\to P_X\\))뿐입니다.\n결론: 따라서 Weighted Split-CQR을 수정 없이 그대로 적용하여, \\(do(T=t)\\) 개입 하에서의 결과 \\(Y\\)에 대한 이중 강건(Doubly Robust) 예측 구간을 생성할 수 있습니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#extension-to-invariant-prediction-framework",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/index.html#extension-to-invariant-prediction-framework",
    "title": "[Paper Review] Conformal Inference of Counterfactuals and Individual Treatment Effects",
    "section": "5.2. Extension to Invariant Prediction Framework",
    "text": "5.2. Extension to Invariant Prediction Framework\n\nPeters et al. (2016)이 제안한 불변 예측(Invariant Prediction) 프레임워크는 서로 다른 환경(Environments)이나 개입(예: 유전자 Knock-out 실험) 하에서 수집된 여러 데이터 소스가 있을 때 강력한 힘을 발휘합니다.\n\n\nProblem Setup\n\n\\(Y\\): 결과 변수\n\\(X\\): 개입 또는 공변량\n\\(E\\): 데이터 소스(환경)를 나타내는 환경 변수 (Environment Variable)\n이 프레임워크의 핵심 가정은 결과 변수 \\(Y\\)의 조건부 분포가 환경 \\(E\\)에 독립이라는 것입니다.\n\n\\[\nY \\perp E \\mid X\n\\]\n\n하지만 공변량 \\(X\\)의 분포는 환경에 따라 달라질 수 있습니다. \\[X|E \\sim P_X^E\\]\n\n\n\nSingle Source Shift (\\(J=1\\))\n\n가장 간단한 경우로, 하나의 훈련 환경 \\(e_1\\)에서 데이터를 얻어 타겟 환경 \\(e_0\\)에서의 결과를 예측한다고 가정해 봅시다.\n\nObserved (Environment \\(e_1\\)): \\(P_X^{e_1} \\times P_{Y|X}\\)\nTarget (Environment \\(e_0\\)): \\(P_X^{e_0} \\times P_{Y|X}\\)\n\n이 역시 Covariate Shift 문제로 귀결됩니다.\n따라서 잠재적 결과 프레임워크와 동일한 구조를 가지며, 다음의 가중치 함수를 사용한 Weighted Split-CQR로 해결할 수 있습니다.\n\n\\[\nw(x) = \\frac{dP_X^{e_0}(x)}{dP_X^{e_1}(x)}\n\\]\n\n\nMulti-Source Shift (\\(J&gt;1\\))\n\n여러 환경 \\(e_1, \\dots, e_J\\)에서 데이터를 수집한 경우(\\(J&gt;1\\)), 문제는 조금 더 복잡해집니다.\nTibshirani et al. (2019b)의 일반화된 가중치 방법을 사용할 수 있지만 가중치 함수가 복잡해집니다.\n저자들은 대안으로 가중 모집단(Weighted Population) 접근법을 제안합니다.\n\n여러 환경의 분포를 혼합하여 의사 데이터셋(Pseudo Dataset)을 구성합니다. \\[\\left( \\sum_{j=1}^J q_j P_X^{e_j} \\right) \\times P_{Y|X}\\]\n\n\n이 혼합 분포가 타겟 분포 \\(P_X^{e_0}\\)와 유사해지도록 가중치 \\(q_j\\)를 조정(Balancing)합니다.\n\n\n최종적으로 다음의 가중치를 적용하여 알고리즘을 수행합니다. \\[w(x) = \\frac{1}{\\sum_{j=1}^J q_j \\frac{dP_X^{e_j}}{dP_X^{e_0}}(x)}\\]\n\n이 아이디어의 구체적인 전개는 향후 연구 과제로 남겨두었습니다."
  },
  {
    "objectID": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html",
    "href": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html",
    "title": "[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "section": "",
    "text": "최근 의료, 정치, 사회과학 등 다양한 분야에서 개별 대상에 대한 처치 효과의 이질성(Heterogeneity in Treatment Effects)을 식별하는 문제는 핵심적인 과제로 떠올랐습니다.\n단순히 집단 전체의 평균적인 효과를 아는 것을 넘어, “이 약이 특정 환자에게 얼마나 효과가 있을까?”와 같은 질문에 답하기 위해 Machine Learning(ML) 모델을 활용하려는 시도가 늘어나고 있습니다.\n하지만 기존의 ML 기반 인과추론 모델들은 대부분 조건부 평균 처치 효과(CATE, Conditional Average Treatment Effect)의 점 추정(Point Estimate)에만 집중해 왔습니다. 즉, 주어진 공변량 \\(X\\)를 가진 개인의 기대 처치 효과를 하나의 숫자로만 예측할 뿐, 그 예측이 얼마나 불확실한지에 대한 정보는 제공하지 못했습니다.\n이 논문은 이러한 한계를 극복하기 위해, 개별 처치 효과(ITE, Individual Treatment Effect)에 대한 예측 구간(Predictive Intervals)을 생성하는 새로운 프레임워크를 제안합니다.\n\n\n\n\n기존에 ITE의 불확실성을 다루기 위한 시도들은 주로 Bayesian 방법론에 의존해 왔습니다.\n대표적으로 BART(Bayesian Additive Regression Trees)나 Gaussian Processes(GPs)가 있습니다.\n이들은 사후 분포(Posterior Distribution)를 통해 신용 구간(Credible Interval)을 제공할 수 있다는 장점이 있습니다.\n그러나 이러한 Bayesian 접근법은 다음과 같은 명확한 한계가 존재합니다:\n\n\nModel-Specific: 특정 모델 구조에 종속적입니다. 최근 Vision이나 NLP 분야에서 두각을 나타내는 Transformer와 같은 현대적인 딥러닝 아키텍처에 유연하게 적용하기 어렵습니다.\n\n\nLack of Frequentist Guarantee: Bayesian 신용 구간의 커버리지(Coverage)는 사전 분포(Prior)에 의존하며, 유한한 샘플(Finite-sample)에서 빈도주의적 커버리지(Frequentist Coverage)를 보장하지 못합니다.\n\n\n\n\n\n\n\n이러한 배경에서 저자들은 Conformal Prediction (CP)에 주목합니다.\nCP는 어떤 ML 모델이든 상관없이(Model-agnostic), 데이터 분포에 대한 가정 없이(Distribution-free), 유효한 예측 구간을 생성할 수 있는 빈도주의적 대안입니다.\n하지만 일반적인 회귀(Regression) 문제와 달리, 인과추론 문제에 CP를 적용하는 것은 “인과추론의 근본적인 문제(Fundamental Problem of Causal Inference)” 때문에 훨씬 까다롭습니다.\n\n\n\n\n\n일반적인 지도 학습(Supervised Learning)에서 우리는 입력 \\(X\\)와 정답 라벨 \\(Y\\)를 모두 관측할 수 있습니다.\n하지만 인과추론에서의 “라벨”은 ITE(Individual Treatment Effect)이며, 이는 관측이 불가능합니다.\n\n\\[\n\\text{ITE}_i = Y_i(1) - Y_i(0)\n\\]\n\n여기서 \\(Y_i(1)\\)은 처치를 받았을 때의 잠재적 결과, \\(Y_i(0)\\)는 받지 않았을 때의 결과입니다.\n우리는 현실에서 둘 중 하나만 관측할 수 있습니다(Factual Outcome). 나머지 하나는 영원히 알 수 없는 반사실적 결과(Counterfactual Outcome)입니다.\n이로 인해 ITE에 대한 예측 구간을 생성할 때 두 가지 주요한 도전 과제가 발생합니다.\n\n\n\n\n처치 집단과 통제 집단은 무작위로 배정되지 않는 경우가 많습니다.\n개인의 특성(Covariate)에 따라 처치를 받을 확률이 달라지기 때문에, 처치군과 대조군의 공변량 분포가 서로 다릅니다.\n결과적으로 모델을 학습시키는 데이터의 분포와 우리가 예측하고자 하는 목표 모집단의 분포가 달라지는 Covariate Shift 문제가 발생합니다.\n\n\n\n\n\nITE는 직접 관측되지 않기 때문에 모델을 ITE에 직접 피팅(Fit)할 수 없습니다.\n대신 우리는 \\(Y(1)\\)과 \\(Y(0)\\)라는 Nuisance Parameters(관심 없는 모수)를 각각 추정하고 이를 조합해야 합니다.\n이 과정에서 어떤 방식으로 잠재적 결과를 추정하고 결합하느냐에 따라 모델의 성능이 달라지며, 이를 해결하기 위해 다양한 Meta-learner들이 개발되었습니다.\n\n\n\n\n\n\n이 논문의 핵심 기여는 위의 두 가지 문제(Covariate Shift, Inductive Biases)를 동시에 해결하는 Conformal Meta-learners 프레임워크를 제안한 것입니다.\n\n\n\n\n저자들은 Two-stage pseudo-outcome regression에 기반한 광범위한 Meta-learner 클래스에 집중합니다.\n이 방법론은 다음과 같은 2단계로 진행됩니다:\n\n\nPseudo-outcome Estimation: 관측 가능한 변수들만을 사용하여 ITE의 대리 변수(Proxy) 역할을 하는 Pseudo-outcome을 생성합니다.\n\n\nRegression: 이 Pseudo-outcome을 공변량 \\(X\\)에 대해 회귀 분석하여 CATE의 점 추정치를 얻습니다.\n\n\n\n\n\n\n\nConformal Meta-learner는 이 과정 위에 CP를 적용합니다.\n핵심 아이디어는 보류된 보정 데이터셋(Held-out Calibration Set)에서 Pseudo-outcome에 대한 적합성 점수(Conformity Scores)를 계산하고, 이 점수의 경험적 분위수(Empirical Quantile)를 사용하여 구간을 구성하는 것입니다.\n이 접근법이 갖는 장점은 다음과 같습니다:\n\nCovariate Shift 해결: Pseudo-outcome과 연관된 공변량의 분포는 학습 데이터와 테스트 데이터에서 동일하게 취급될 수 있습니다.\nInductive Biases 해결: 보정 단계(Calibration step)가 모델 아키텍처와 분리되어 있습니다. 따라서 CATE 추정에 효과적이라고 알려진 기존의 다양한 Meta-learner(예: T-learner, X-learner 등)나 딥러닝 아키텍처를 그대로 가져와서 사용할 수 있습니다.\n\n\n\n\n\n\n하지만 Pseudo-outcome에 대해 CP를 적용한다고 해서, 그것이 곧바로 관측되지 않은 ITE에 대한 커버리지를 보장하는 것은 아닙니다.\n저자들은 이를 증명하기 위해 확률적 순서(Stochastic Ordering) 프레임워크를 도입했습니다.\n만약 우리가 사용하는 Pseudo-outcome 기반의 적합성 점수(Conformity Score)가, 실제 ITE를 알았을 때 계산할 수 있는 “Oracle” 적합성 점수보다 확률적으로 우월(Stochastically Dominate)하다면, 결과적으로 생성된 구간은 유효(Valid)합니다.\n특히, 널리 사용되는 Doubly-Robust Learner와 같은 Meta-learner들이 이러한 확률적 지배 조건(또는 볼록 지배 조건)을 만족함을 증명했습니다."
  },
  {
    "objectID": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#기존-방법론bayesian의-한계",
    "href": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#기존-방법론bayesian의-한계",
    "title": "[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "section": "",
    "text": "기존에 ITE의 불확실성을 다루기 위한 시도들은 주로 Bayesian 방법론에 의존해 왔습니다.\n대표적으로 BART(Bayesian Additive Regression Trees)나 Gaussian Processes(GPs)가 있습니다.\n이들은 사후 분포(Posterior Distribution)를 통해 신용 구간(Credible Interval)을 제공할 수 있다는 장점이 있습니다.\n그러나 이러한 Bayesian 접근법은 다음과 같은 명확한 한계가 존재합니다:\n\n\nModel-Specific: 특정 모델 구조에 종속적입니다. 최근 Vision이나 NLP 분야에서 두각을 나타내는 Transformer와 같은 현대적인 딥러닝 아키텍처에 유연하게 적용하기 어렵습니다.\n\n\nLack of Frequentist Guarantee: Bayesian 신용 구간의 커버리지(Coverage)는 사전 분포(Prior)에 의존하며, 유한한 샘플(Finite-sample)에서 빈도주의적 커버리지(Frequentist Coverage)를 보장하지 못합니다."
  },
  {
    "objectID": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#conformal-prediction-cp의-도입",
    "href": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#conformal-prediction-cp의-도입",
    "title": "[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "section": "",
    "text": "이러한 배경에서 저자들은 Conformal Prediction (CP)에 주목합니다.\nCP는 어떤 ML 모델이든 상관없이(Model-agnostic), 데이터 분포에 대한 가정 없이(Distribution-free), 유효한 예측 구간을 생성할 수 있는 빈도주의적 대안입니다.\n하지만 일반적인 회귀(Regression) 문제와 달리, 인과추론 문제에 CP를 적용하는 것은 “인과추론의 근본적인 문제(Fundamental Problem of Causal Inference)” 때문에 훨씬 까다롭습니다."
  },
  {
    "objectID": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#core-challenges-in-causal-conformal-prediction",
    "href": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#core-challenges-in-causal-conformal-prediction",
    "title": "[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "section": "",
    "text": "일반적인 지도 학습(Supervised Learning)에서 우리는 입력 \\(X\\)와 정답 라벨 \\(Y\\)를 모두 관측할 수 있습니다.\n하지만 인과추론에서의 “라벨”은 ITE(Individual Treatment Effect)이며, 이는 관측이 불가능합니다.\n\n\\[\n\\text{ITE}_i = Y_i(1) - Y_i(0)\n\\]\n\n여기서 \\(Y_i(1)\\)은 처치를 받았을 때의 잠재적 결과, \\(Y_i(0)\\)는 받지 않았을 때의 결과입니다.\n우리는 현실에서 둘 중 하나만 관측할 수 있습니다(Factual Outcome). 나머지 하나는 영원히 알 수 없는 반사실적 결과(Counterfactual Outcome)입니다.\n이로 인해 ITE에 대한 예측 구간을 생성할 때 두 가지 주요한 도전 과제가 발생합니다.\n\n\n\n\n처치 집단과 통제 집단은 무작위로 배정되지 않는 경우가 많습니다.\n개인의 특성(Covariate)에 따라 처치를 받을 확률이 달라지기 때문에, 처치군과 대조군의 공변량 분포가 서로 다릅니다.\n결과적으로 모델을 학습시키는 데이터의 분포와 우리가 예측하고자 하는 목표 모집단의 분포가 달라지는 Covariate Shift 문제가 발생합니다.\n\n\n\n\n\nITE는 직접 관측되지 않기 때문에 모델을 ITE에 직접 피팅(Fit)할 수 없습니다.\n대신 우리는 \\(Y(1)\\)과 \\(Y(0)\\)라는 Nuisance Parameters(관심 없는 모수)를 각각 추정하고 이를 조합해야 합니다.\n이 과정에서 어떤 방식으로 잠재적 결과를 추정하고 결합하느냐에 따라 모델의 성능이 달라지며, 이를 해결하기 위해 다양한 Meta-learner들이 개발되었습니다."
  },
  {
    "objectID": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#proposed-framework-conformal-meta-learners",
    "href": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#proposed-framework-conformal-meta-learners",
    "title": "[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "section": "",
    "text": "이 논문의 핵심 기여는 위의 두 가지 문제(Covariate Shift, Inductive Biases)를 동시에 해결하는 Conformal Meta-learners 프레임워크를 제안한 것입니다.\n\n\n\n\n저자들은 Two-stage pseudo-outcome regression에 기반한 광범위한 Meta-learner 클래스에 집중합니다.\n이 방법론은 다음과 같은 2단계로 진행됩니다:\n\n\nPseudo-outcome Estimation: 관측 가능한 변수들만을 사용하여 ITE의 대리 변수(Proxy) 역할을 하는 Pseudo-outcome을 생성합니다.\n\n\nRegression: 이 Pseudo-outcome을 공변량 \\(X\\)에 대해 회귀 분석하여 CATE의 점 추정치를 얻습니다.\n\n\n\n\n\n\n\nConformal Meta-learner는 이 과정 위에 CP를 적용합니다.\n핵심 아이디어는 보류된 보정 데이터셋(Held-out Calibration Set)에서 Pseudo-outcome에 대한 적합성 점수(Conformity Scores)를 계산하고, 이 점수의 경험적 분위수(Empirical Quantile)를 사용하여 구간을 구성하는 것입니다.\n이 접근법이 갖는 장점은 다음과 같습니다:\n\nCovariate Shift 해결: Pseudo-outcome과 연관된 공변량의 분포는 학습 데이터와 테스트 데이터에서 동일하게 취급될 수 있습니다.\nInductive Biases 해결: 보정 단계(Calibration step)가 모델 아키텍처와 분리되어 있습니다. 따라서 CATE 추정에 효과적이라고 알려진 기존의 다양한 Meta-learner(예: T-learner, X-learner 등)나 딥러닝 아키텍처를 그대로 가져와서 사용할 수 있습니다.\n\n\n\n\n\n\n하지만 Pseudo-outcome에 대해 CP를 적용한다고 해서, 그것이 곧바로 관측되지 않은 ITE에 대한 커버리지를 보장하는 것은 아닙니다.\n저자들은 이를 증명하기 위해 확률적 순서(Stochastic Ordering) 프레임워크를 도입했습니다.\n만약 우리가 사용하는 Pseudo-outcome 기반의 적합성 점수(Conformity Score)가, 실제 ITE를 알았을 때 계산할 수 있는 “Oracle” 적합성 점수보다 확률적으로 우월(Stochastically Dominate)하다면, 결과적으로 생성된 구간은 유효(Valid)합니다.\n특히, 널리 사용되는 Doubly-Robust Learner와 같은 Meta-learner들이 이러한 확률적 지배 조건(또는 볼록 지배 조건)을 만족함을 증명했습니다."
  },
  {
    "objectID": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#problem-setup",
    "href": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#problem-setup",
    "title": "[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "section": "2.1. Problem Setup",
    "text": "2.1. Problem Setup\n\n논문은 인과추론의 표준인 잠재적 결과 프레임워크(Potential Outcomes Framework), 혹은 Rubin Causal Model을 따릅니다.\n\n\nNotation & Definition\n\n데이터는 \\(n\\)명의 대상(subject)에 대해 관측되며, 각 대상 \\(i\\)는 다음과 같은 변수들을 가집니다.\n\nCovariates (공변량) \\(X \\in \\mathcal{X}\\): 개인의 특징.\nTreatment Indicator (처치 여부) \\(W \\in \\{0, 1\\}\\): \\(1\\)이면 처치군, \\(0\\)이면 대조군.\nOutcome (결과) \\(Y \\in \\mathbb{R}\\): 우리가 관심 있는 결과 변수.\n\n각 대상 \\(i\\)에 대해 두 가지 잠재적 결과(Potential Outcomes)가 존재합니다.\n\n\\(Y_i(1)\\): 처치를 받았을 때의 결과 (\\(W=1\\))\n\\(Y_i(0)\\): 처치를 받지 않았을 때의 결과 (\\(W=0\\))\n\n하지만 현실에서는 인과추론의 근본적인 문제(Fundamental Problem of Causal Inference)로 인해, 우리는 오직 실제 발생한 결과(Factual Outcome)만을 관측할 수 있습니다.\n\n\\[\nY_i = W_i Y_i(1) + (1 - W_i) Y_i(0)\n\\]\n\n반면, 관측되지 않은 쪽인 \\(Y_i(1-W_i)\\)는 반사실적 결과(Counterfactual Outcome)가 됩니다.\n우리는 \\(n\\)명의 대상에 대한 데이터 생성 과정(Data Generation Process)이 결합 분포 \\(P\\)로부터 독립적이고 동일하게 분포(i.i.d.)한다고 가정합니다.\n\n\\[\n(X_i, W_i, Y_i(0), Y_i(1)) \\overset{iid}{\\sim} P(X, W, Y(0), Y(1)), \\quad i = 1, \\dots, n\n\\tag{1}\\]\n\n\nAssumptions\n\n관측된 데이터 \\(\\{Z_i = (X_i, W_i, Y_i)\\}_{i=1}^n\\)로부터 인과 효과를 식별(Identification)하기 위해 다음 세 가지 가정을 도입합니다.\n\nUnconfoundedness (Ignorability): \\[(Y(0), Y(1)) \\perp W \\mid X\\]\n\n\n공변량 \\(X\\)가 주어졌을 때, 처치 할당 \\(W\\)는 잠재적 결과들과 독립입니다.\n즉, \\(X\\) 외에 처치와 결과 모두에 영향을 주는 숨겨진 교란 변수(Confounder)는 없습니다.\n\n\nConsistency: \\[Y = Y(W)\\]\n\n\n관측된 결과 \\(Y\\)는 실제로 받은 처치 \\(W\\)에 해당하는 잠재적 결과와 일치합니다.\n\n\nPositivity (Overlap): \\[0 &lt; P(W=1 \\mid X=x) &lt; 1, \\quad \\forall x \\in \\mathcal{X}\\]\n\n\n모든 공변량 영역에서 처치군과 대조군이 될 확률이 0이 아니어야 합니다.\n\n\n\n\nCATE vs. ITE: 무엇이 다른가?\n\n이 논문에서 가장 중요하게 강조하는 구분이 바로 CATE와 ITE의 차이입니다.\nCATE (Conditional Average Treatment Effect):\n\n기존 연구들이 주로 추정해온 결정론적(Deterministic) 함수로, 조건부 기대값의 차이입니다. \\[\\tau(x) \\triangleq \\mathbb{E}[Y(1) - Y(0) \\mid X=x]\\]\n\nITE (Individual Treatment Effect):\n\n이 논문의 관심 대상인 확률 변수(Random Variable)입니다. \\[\\text{ITE}_i = Y_i(1) - Y_i(0)\\]\n\nCATE는 “당신과 같은 특성을 가진 사람들의 평균적인 효과”를 말해주지만, ITE는 “당신이 겪을 실제 효과”를 의미합니다.\nITE는 모델의 오차뿐만 아니라, 같은 \\(X\\)를 가진 사람들 사이에서도 존재하는 내재적 변동성(Intrinsic Variability)을 포함합니다.\n관측된 변수 \\(Z=(X, W, Y)\\)의 분포를 기술하기 위해, 우리는 다음과 같은 두 가지 Nuisance Functions(방해 모수 함수)를 정의합니다.\n\nPropensity Score \\(\\pi(x)\\): 처치 할당 메커니즘을 나타냅니다.\nOutcome Mean Functions \\(\\mu_w(x)\\): 각 처치 그룹 내에서의 조건부 기대 결과를 나타냅니다.\n\n\n\\[\n\\begin{aligned}\n\\pi(x) &= \\mathbb{P}(W=1 \\mid X=x), \\\\\n\\mu_w(x) &= \\mathbb{E}[Y \\mid X=x, W=w], \\quad w \\in \\{0, 1\\}.\n\\end{aligned}\n\\tag{2}\\]\n\n특히 본 논문에서는 데이터가 실험 연구(Experimental Study)에서 얻어졌거나 처치 할당 메커니즘이 알려져 있어, Propensity Score \\(\\pi(x)\\)를 알고 있다(Known)고 가정합니다.\n\n\n\n목표: Marginally Valid Predictive Interval\n\n논문의 목표는 새로운 데이터 \\(X_{n+1}\\)이 주어졌을 때, 실제 ITE가 포함될 확률이 \\(1-\\alpha\\) 이상인 예측 구간(Predictive Band) \\(\\hat{C}(x)\\)를 구성하는 것입니다.\n\n\\[\n\\mathbb{P}(Y_{n+1}(1) - Y_{n+1}(0) \\in \\hat{C}(X_{n+1})) \\ge 1 - \\alpha\n\\tag{3}\\]\n\n이 확률은 훈련 데이터 \\(\\{Z_i\\}\\)와 새로운 테스트 포인트의 랜덤성을 모두 고려한 Marginal Validity를 의미합니다."
  },
  {
    "objectID": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#conformal-prediction",
    "href": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#conformal-prediction",
    "title": "[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "section": "2.2. Conformal Prediction",
    "text": "2.2. Conformal Prediction\n\n이 목표를 달성하기 위한 도구로 Conformal Prediction (CP)을 사용합니다.\nCP는 모델이나 분포에 대한 가정 없이(Model-free, Distribution-free) 유효한 예측 구간을 생성하는 프레임워크입니다.\n\n\nSplit Conformal Prediction (Inductive CP)\n\n가장 기본적인 형태인 Split CP의 절차는 다음과 같습니다.\n\nData Splitting: 전체 데이터 \\(\\mathcal{D}\\)를 훈련 집합 \\(\\mathcal{D}_{t}\\)와 보정 집합(Calibration set) \\(\\mathcal{D}_{c}\\)로 나눕니다.\n\n\nModel Fitting: \\(\\mathcal{D}_{t}\\)를 사용하여 예측 모델 \\(\\hat{\\mu}(x)\\)를 학습합니다.\n\n\nConformity Scores Calculation: 보정 집합 \\(\\mathcal{D}_{c}\\)의 모든 샘플에 대해, 실제 값과 예측 값의 괴리를 나타내는 점수(Conformity Score)를 계산합니다. \\[V_k(\\hat{\\mu}) \\triangleq V(X_k, Y_k; \\hat{\\mu}), \\quad \\forall k \\in \\mathcal{D}_c \\tag{4}\\]\n\n\n\n일반적인 회귀 문제에서는 절대 잔차(Absolute Residual)를 사용합니다. \\[V_k(\\hat{\\mu}) \\triangleq | \\hat{\\mu}(X_k) - Y_k |, \\quad \\forall k \\in \\mathcal{D}_c\\]\n\n\nQuantile Computation: 계산된 모든 점수들의 집합을 \\(\\mathcal{V}(\\hat{\\mu}) = \\{V_k(\\hat{\\mu}) : k \\in \\mathcal{D}_c\\}\\)라고 할 때, 목표 커버리지 \\(1-\\alpha\\)에 해당하는 경험적 분위수(Empirical Quantile)를 구합니다. \\[Q_{\\mathcal{V}}(1-\\alpha) \\triangleq (1-\\alpha)(1 + 1/|\\mathcal{D}_c|)\\text{-th quantile of } \\mathcal{V}(\\hat{\\mu}) \\tag{5}\\]\n\n\nInterval Construction: 새로운 데이터 \\(X_{n+1}=x\\)에 대한 예측 구간 \\(\\hat{C}(x)\\)는 예측값 \\(\\hat{\\mu}(x)\\)를 중심으로 해당 분위수만큼 벌린 구간으로 정의됩니다. \\[\\hat{C}(x) = [\\hat{\\mu}(x) - Q_{\\mathcal{V}}(1-\\alpha), \\;\\; \\hat{\\mu}(x) + Q_{\\mathcal{V}}(1-\\alpha)] \\tag{6}\\]\n\n이 구간은 훈련 데이터와 테스트 데이터 간의 Exchangeability (교환 가능성) 가정 하에서, 새로운 데이터 \\(Y_{n+1}\\)을 포함할 확률이 \\(1-\\alpha\\) 이상임이 수학적으로 보장됩니다 (Marginal Coverage Guarantee)."
  },
  {
    "objectID": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#oracle-conformal-prediction-of-ites",
    "href": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#oracle-conformal-prediction-of-ites",
    "title": "[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "section": "2.3. Oracle Conformal Prediction of ITEs",
    "text": "2.3. Oracle Conformal Prediction of ITEs\n\n이제 CP를 ITE 추정에 적용해봅시다. 만약 우리가 신(Oracle)이어서 반사실적 결과까지 모두 볼 수 있다면, 문제는 매우 간단해집니다.\n가상의 “Oracle 데이터셋” \\({\\mathcal{D}}^* = \\{(X_i, \\underbrace{Y_i(1) - Y_i(0)}_{\\text{True ITE}})\\}_{i}\\) 가 있다고 가정해봅시다.\n이 경우 Oracle Conformity Score를 다음과 같이 정의할 수 있습니다. \\[V^*_k(\\hat{\\tau}) \\triangleq V(X_k, \\underbrace{Y_k(1) - Y_k(0)}_{\\text{Label}}, \\hat{\\tau}) \\tag{7}\\]\n이 점수를 사용해 CP를 수행하면 식 (3)의 coverage 조건을 완벽하게 만족하는 구간 \\(\\hat{C}^*(X)\\)를 얻을 수 있습니다.\n하지만 현실에서는 \\(Y_i(1)\\)과 \\(Y_i(0)\\) 중 하나만 관측되므로, 이 Oracle 절차는 불가능(Infeasible)합니다."
  },
  {
    "objectID": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#the-two-challenges-of-predictive-inference-on-ites",
    "href": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#the-two-challenges-of-predictive-inference-on-ites",
    "title": "[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "section": "2.4. The Two Challenges of Predictive Inference on ITEs",
    "text": "2.4. The Two Challenges of Predictive Inference on ITEs\n\n현실적인 대안으로, 관측된 데이터를 처치군(\\(W=1\\))과 대조군(\\(W=0\\))으로 나누어 각각의 잠재적 결과 \\(Y(1)\\)과 \\(Y(0)\\)에 대해 별도로 CP를 적용하는 “Naïve Approach”를 생각할 수 있습니다.\n데이터 분할(Data Splitting)\n\n이 방식은 먼저 데이터를 처치 그룹(\\(\\mathcal{D}_1\\))과 대조 그룹(\\(\\mathcal{D}_0\\))으로 분할합니다.\n\n적합성 점수 계산(Conformity Score Calculation)\n\n각각의 Nuisance Estimate (\\(\\hat{\\mu}_1, \\hat{\\mu}_0\\))에 대해 다음과 같이 별도의 적합성 점수를 계산합니다. \\[\n\\begin{aligned}\nV_k^{(0)}(\\hat{\\mu}_0) &\\triangleq |Y_k(0) - \\hat{\\mu}_0(X_k)|, \\quad \\forall k \\in \\mathcal{D}_{c,0} \\\\\nV_k^{(1)}(\\hat{\\mu}_1) &\\triangleq |Y_k(1) - \\hat{\\mu}_1(X_k)|, \\quad \\forall k \\in \\mathcal{D}_{c,1}\n\\end{aligned}\n\\tag{8}\\]\n여기서 \\(\\mathcal{D}_{c,0}\\)와 \\(\\mathcal{D}_{c,1}\\)은 각각 대조군과 처치군의 보정(Calibration) 데이터셋을 의미합니다.\n\n개별 구간 생성 (Individual Calibration):\n\n그 다음, 각 그룹에서 \\(1-\\alpha/2\\) 수준의 분위수(Quantile) \\(\\hat{q}_0, \\hat{q}_1\\)를 계산하여 개별 예측 구간 \\(\\hat{C}_0(X), \\hat{C}_1(X)\\)를 생성합니다.\n이때 ITE의 동시 포함 확률(Joint Coverage) \\(1-\\alpha\\)를 보장하기 위해, 본페로니 보정(Bonferroni Correction)을 적용하여 각 구간의 신뢰 수준을 높여야 합니다.\n\n\n\\[\n\\hat{C}_w(X) = \\left[ \\hat{\\mu}_w(X) - \\hat{q}_w, \\;\\; \\hat{\\mu}_w(X) + \\hat{q}_w \\right], \\quad w \\in \\{0, 1\\}\n\\]\n\n구간 결합 (Interval Combination):\n\n최종적으로 ITE \\(\\tau(X) = Y(1) - Y(0)\\)에 대한 예측 구간 \\(\\hat{C}_{\\text{ITE}}(X)\\)는 두 구간의 차이(Minkowski difference)로 정의됩니다.\n즉, \\(Y(1)\\)이 가질 수 있는 구간에서 \\(Y(0)\\)가 가질 수 있는 구간을 뺐을 때 나올 수 있는 최소값과 최대값의 범위를 구합니다. \\[\n\\begin{aligned}\n\\hat{C}_{\\text{ITE}}(X) &= \\hat{C}_1(X) \\ominus \\hat{C}_0(X) \\\\\n&= \\left[ \\min(\\hat{C}_1) - \\max(\\hat{C}_0), \\;\\; \\max(\\hat{C}_1) - \\min(\\hat{C}_0) \\right] \\\\\n&= \\left[ (\\hat{\\mu}_1(X) - \\hat{\\mu}_0(X)) - (\\hat{q}_1 + \\hat{q}_0), \\;\\; (\\hat{\\mu}_1(X) - \\hat{\\mu}_0(X)) + (\\hat{q}_1 + \\hat{q}_0) \\right]\n\\end{aligned}\n\\]\n이 식을 통해 알 수 있듯, Naïve Approach의 ITE 구간 폭(Width)은 두 개별 구간 폭의 합(\\(2\\hat{q}_1 + 2\\hat{q}_0\\))이 되어 불확실성이 단순 합산됩니다.\n\n이러한 접근법은 직관적이지만, 실제로는 다음과 같은 두 가지 심각한 문제에 직면합니다.\n\n\nChallenge 1: Covariate Shift (공변량 이동)\n\nCP의 핵심 가정은 Exchangeability입니다. 즉, 보정 데이터(Calibration data)와 테스트 데이터(Test data)가 같은 분포에서 와야 합니다.\n그러나 인과추론 상황에서는 필연적으로 Covariate Shift가 발생합니다.처치를 받을 확률(Propensity Score, \\(\\pi(x)\\))이 개인마다 다르기 때문입니다.\n처치군(\\(W=1\\))의 공변량 분포 \\(P_{X|W=1}\\)와 대조군(\\(W=0\\))의 분포 \\(P_{X|W=0}\\)는 서로 다릅니다. 무엇보다, 이 둘은 우리가 예측하고자 하는 전체 모집단의 분포 \\(P_X\\)와도 다릅니다. \\[P_{X|W=0} \\neq P_{X|W=1} \\neq P_X\\]\n이러한 공변량의 이동은 결과적으로 우리가 계산하는 Conformity Score (\\(V\\))의 결합 분포에도 영향을 미칩니다. 즉, 특정 처치 그룹에서 계산한 점수의 분포가 전체 모집단에서의 분포와 일치하지 않게 됩니다.\n\n\\[\nP_{X,V^{(0)}|W=0} \\neq P_{X,V^{(0)}}, \\quad P_{X,V^{(1)}|W=1} \\neq P_{X,V^{(1)}}\n\\]\n\n따라서 단순히 처치군 데이터로 학습하고 보정한 모델을 전체 모집단에 적용하면 Exchangeability 가정이 깨지므로, CP의 커버리지 보장(Validity)이 성립하지 않습니다.\n\n\n\nChallenge 2: Inductive Biases (귀납적 편향)\n\n지도 학습에서는 \\((X, Y)\\) 쌍을 통해 하나의 함수를 학습하지만, ITE 추정은 관측되지 않는 효과를 추정해야 하므로 모델링의 자유도가 훨씬 높습니다. 이를 위해 다양한 Meta-learner들이 존재합니다.\n\nT-learner: \\(\\mu_0(x)\\)와 \\(\\mu_1(x)\\)를 별도로 학습하여 \\(Y(0), Y(1)\\) 각각에 서로 다른 규제(Regularization)를 가함.\nS-learner: 처치 변수 \\(W\\)를 공변량에 포함시켜 하나의 모델 \\(\\mu(X, W)\\) 학습.\n\n각 Meta-learner는 \\(Y(0)\\)와 \\(Y(1)\\)이라는 Nuisance Parameters(방해 모수)를 추정하고 결합하는 방식에 있어 서로 다른 Inductive Bias를 가집니다.\n\n\n\nLimitations of Existing Approaches (기존 방법의 한계)\n\n기존 연구들은 이러한 Covariate Shift를 해결하기 위해 Conformity Score에 가중치를 부여(Reweighting)하거나, \\(Y(0)\\)와 \\(Y(1)\\) 각각에 대한 구간을 구한 뒤 이를 결합하는 방식을 사용했습니다. 하지만 이는 다음과 같은 한계를 가집니다.\n\n\nLoss of Post-hoc Nature (사후적 특성 상실): CP 절차가 모델 아키텍처(Nuisance Parameter 추정 방식)에 종속되게 만들어, CP 고유의 장점인 ‘모델에 구애받지 않는(Model-agnostic)’ 성격을 잃게 합니다.\n\n\nConservativeness (보수성): 두 개의 잠재적 결과(PO) 구간을 결합하여 ITE 구간을 생성할 경우, 구간이 불필요하게 넓어져 효율성이 떨어집니다.\n\n\nLimited Applicability (적용의 한계): 모든 CATE 모델이 \\(Y(0)\\)와 \\(Y(1)\\)을 명시적으로 추정하는 것은 아니므로, 다양한 Inductive Prior를 유연하게 적용하기 어렵습니다."
  },
  {
    "objectID": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#pseudo-outcome-regression-for-cate-estimation",
    "href": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#pseudo-outcome-regression-for-cate-estimation",
    "title": "[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "section": "3.1. Pseudo-outcome Regression for CATE Estimation",
    "text": "3.1. Pseudo-outcome Regression for CATE Estimation\n\nConformal Meta-learner의 핵심 아이디어는 관측되지 않는 ITE(\\(Y(1)-Y(0)\\))를 직접 예측하려 드는 대신, 관측 가능한 변수들로 구성된 대리 변수, 즉 Pseudo-outcome (\\(\\tilde{Y}_{\\varphi}\\))을 정의하는 것입니다.\n\n\nTwo-stage Regression Procedure\n\n이 프레임워크는 크게 두 단계로 구성됩니다.\n\nStage 1 (Nuisance Estimation):\n\n\n데이터의 일부(\\(\\mathcal{D}_{\\varphi}\\))를 사용하여 Nuisance parameter인 \\(\\varphi = (\\pi, \\mu_0, \\mu_1)\\)를 추정합니다.\n\\(\\pi(x) = P(W=1|X=x)\\): Propensity score (실험 데이터라면 알려져 있음)\n\\(\\mu_w(x) = \\mathbb{E}[Y|X=x, W=w]\\): Response surfaces\n\n\nStage 2 (CATE Estimation):\n\n\n추정된 Nuisance parameter \\(\\hat{\\varphi}\\)를 사용하여 각 관측치에 대해 Pseudo-outcome \\(\\tilde{Y}_{\\varphi}\\)를 생성합니다.\n그 후, 공변량 \\(X\\)를 입력으로 하고 \\(\\tilde{Y}_{\\varphi}\\)를 타겟으로 하는 회귀 모델을 학습하여 CATE(\\(\\hat{\\tau}\\))를 추정합니다.\n\n\n\\[\n\\hat{\\tau}(x) = \\mathbb{E}[\\tilde{Y}_{\\varphi} \\mid X=x]\n\\]\n\n\nMeta-learners as Pseudo-outcomes\n\n흥미로운 점은, 기존에 제안된 유명한 Meta-learner들이 사실 이 Pseudo-outcome Regression의 특수한 형태(Instantiation)로 해석될 수 있다는 것입니다.\n논문에서는 다음 세 가지 대표적인 Learner들을 재정의합니다.\n\n\n\n\n\n\n\n\n\nMeta-learner\nPseudo-outcome Definition (\\(\\tilde{Y}_{\\varphi}\\))\n설명\n\n\n\n\nIPW-learner\n\\(\\displaystyle \\frac{W-\\pi(X)}{\\pi(X)(1-\\pi(X))}Y\\)\nPropensity Score로 가중치를 부여하여 Factual Outcome을 재조정함. 편향은 적으나 분산이 큼.\n\n\nX-learner\n\\(\\displaystyle W(Y-\\hat{\\mu}_0(X)) + (1-W)(\\hat{\\mu}_1(X)-Y)\\)\n처치군에서는 \\(\\hat{\\mu}_0\\)를 빼고, 대조군에서는 \\(\\hat{\\mu}_1\\)을 빼서 반사실적 결과를 보정(Imputation)함.\n\n\nDR-learner\n\\(\\displaystyle \\frac{W-\\pi(X)}{\\pi(X)(1-\\pi(X))}(Y-\\hat{\\mu}_W(X)) + \\hat{\\mu}_1(X) - \\hat{\\mu}_0(X)\\)\nIPW와 Regression Adjustment를 결합한 Doubly Robust 형태. 모델 설정이 하나라도 맞으면 일치성(Consistency)을 가짐.\n\n\n\n\n이러한 통합된 관점은 우리가 어떤 Meta-learner를 사용하든, 공통된 Conformal Prediction 절차를 적용할 수 있게 해줍니다."
  },
  {
    "objectID": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#conformal-pseudo-intervals-for-ites",
    "href": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#conformal-pseudo-intervals-for-ites",
    "title": "[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "section": "3.2. Conformal Pseudo-Intervals for ITEs",
    "text": "3.2. Conformal Pseudo-Intervals for ITEs\n\n이제 이 Pseudo-outcome 위에 CP를 얹어 예측 구간(Pseudo-intervals)을 생성하는 전체 알고리즘을 살펴보겠습니다.\n\n\n\n\nFigure 1: Conformal Meta-learners의 전체 구조. (Left) Nuisance Estimator를 통해 생성된 Pseudo-outcome을 사용하여 CATE Estimator를 학습한다. (Right) Calibration Set에서 계산된 Pseudo-outcome의 잔차(Conformity Score) 분포를 이용해 불확실성 구간을 계산한다.\n\n\n\nData Splitting Strategy\n\n데이터의 독립성을 보장하기 위해 전체 데이터셋 \\(\\mathcal{D}\\)를 세 개의 상호 배타적인(Mutually Exclusive) 부분집합으로 나눕니다.\n\n\\(\\mathcal{D}_{\\varphi}\\): Nuisance parameter (\\(\\hat{\\pi}, \\hat{\\mu}_0, \\hat{\\mu}_1\\)) 학습용\n\n\n\\(\\mathcal{D}_{t}\\): CATE 모델(\\(\\hat{\\tau}\\)) 학습용 (Pseudo-outcome 타겟 회귀)\n\n\n\\(\\mathcal{D}_{c}\\): Calibration(보정) 및 Conformity score 계산용\n\n\n\n\nAlgorithm Steps (Algorithm 1)\n\n\n\nAlgorithm 1: Conformal Meta-Learner\n\n\n\n\nEstimation: \\(\\mathcal{D}_{\\varphi}\\)를 이용해 \\(\\hat{\\varphi} = (\\pi, \\hat{\\mu}_0, \\hat{\\mu}_1)\\)를 추정합니다.\n\n\nTransformation: \\(\\mathcal{D}_{t}\\)의 각 데이터에 대해 Pseudo-outcome \\(\\tilde{Y}_{\\varphi}\\)를 계산하고, 이를 타겟으로 하는 모델 \\(\\hat{\\tau}(x)\\)를 학습합니다.\n\n\nCalibration: 보정 데이터셋 \\(\\mathcal{D}_{c}\\)에 대해 Pseudo-outcome 기반의 Conformity Score를 계산합니다. \\[\n  V_{\\varphi, k}(\\hat{\\tau}) \\triangleq V(X_k, \\tilde{Y}_{\\varphi, k}; \\hat{\\tau}), \\quad \\forall k \\in \\mathcal{D}_{c}\n   \\tag{9}\\]\n\n\nInterval Construction: 점수들의 \\(1-\\alpha\\) 분위수(Quantile)인 \\(Q_{\\mathcal{V}_{\\varphi}}(1-\\alpha)\\)를 구하여, 새로운 데이터 \\(X_{n+1}\\)에 대한 구간을 반환합니다. \\[\n  \\hat{C}_{\\varphi}(X_{n+1}) = [\\hat{\\tau}(X_{n+1}) - Q_{\\mathcal{V}_{\\varphi}}(1-\\alpha), \\;\\; \\hat{\\tau}(X_{n+1}) + Q_{\\mathcal{V}_{\\varphi}}(1-\\alpha)]\n   \\tag{10}\\]\n\n\n\n\nWhy this solves the challenges?\n\nCovariate Shift 해결: Pseudo-outcome \\(\\tilde{Y}_{\\varphi}\\)는 관측 데이터 \\((X, W, Y)\\)의 함수이므로, Calibration set과 Test set의 공변량 분포가 동일합니다(Exchangeability 성립).\nInductive Bias 분리: 어떤 Meta-learner를 쓰든 Pseudo-outcome으로 변환만 하면 되므로, CP 절차는 모델 구조와 무관(Model-agnostic)하게 적용 가능합니다."
  },
  {
    "objectID": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#the-validity-gap-exchangeability-breakdown",
    "href": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#the-validity-gap-exchangeability-breakdown",
    "title": "[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "section": "The Validity Gap: Exchangeability Breakdown",
    "text": "The Validity Gap: Exchangeability Breakdown\n\nConformal Prediction(CP)의 강력함은 Exchangeability(교환 가능성) 가정에서 나옵니다. 하지만 ITE 추정 문제에서는 이 가정이 미묘하게 깨집니다.\n우리가 비교해야 할 두 가지 대상은 다음과 같습니다.\n\nPseudo-outcome Conformity Score (\\(V_{\\varphi}\\)): 우리가 실제로 계산하는 값. \\[V_{\\varphi}(\\hat{\\tau}) = |\\hat{\\tau}(X) - \\tilde{Y}_{\\varphi}|\\]\n\n\n이는 Nuisance parameter \\(\\hat{\\varphi}\\)를 통해 변환된 Pseudo-outcome을 사용합니다.\n\n\nOracle Conformity Score (\\(V^*\\)): 우리가 알고 싶은 이상적인 값. \\[V^*(\\hat{\\tau}) = |\\hat{\\tau}(X) - (Y(1) - Y(0))|\\]\n\n\n이는 실제 ITE를 사용합니다.\n\n문제점:\n\n비록 Pseudo-outcome이 동일한 공변량 분포에서 나왔다 하더라도, \\(V_{\\varphi}\\)와 \\(V^*\\)는 서로 다른 변수입니다.\n따라서 \\(V_{\\varphi}\\)에 대해 CP를 적용해 얻은 커버리지 보장(\\(1-\\alpha\\))이 \\(V^*\\)에 그대로 적용된다는 보장이 없습니다.\n\n저자들은 이 간극을 메우기 위해 “우리의 점수(\\(V_{\\varphi}\\))가 Oracle 점수(\\(V^*\\))보다 확률적으로 더 크거나 넓게 퍼져 있다면, 구간도 더 넓어질 것이므로 안전하다”라는 논리를 펼칩니다."
  },
  {
    "objectID": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#stochastic-ordering-framework",
    "href": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#stochastic-ordering-framework",
    "title": "[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "section": "Stochastic Ordering Framework",
    "text": "Stochastic Ordering Framework\n\n두 확률 변수의 크기나 변동성을 비교하기 위해 Stochastic Dominance(확률적 지배) 개념을 도입합니다.\n\\(F\\)와 \\(G\\)를 각각 두 확률 변수의 누적 분포 함수(CDF)라고 합시다.\n\n\nDefinition 1.1: First-order Stochastic Dominance (FOSD)\n\\[F \\ge_{(1)} G \\iff F(x) \\le G(x), \\quad \\forall x\\]\n\n의미: \\(F\\)의 CDF가 \\(G\\)보다 항상 아래에 있습니다. 이는 \\(F\\)에서 추출한 샘플이 \\(G\\)보다 확률적으로 더 큼을 의미합니다.\n직관: 모든 의사결정자가 \\(G\\)보다 \\(F\\)를 선호하는 상황입니다.\n\n\n\nDefinition 1.2: Second-order Stochastic Dominance (SOSD)\n\\[F \\ge_{(2)} G \\iff \\int_{-\\infty}^{x} [G(t) - F(t)] dt \\ge 0, \\quad \\forall x\\]\n\n의미: 위험 회피적(Risk-averse)인 관점에서 \\(F\\)가 \\(G\\)보다 선호되지 않는 상황입니다. 통계적으로는 \\(F\\)가 \\(G\\)보다 평균은 같더라도 분산(Spread)이 더 큼을 의미할 수 있습니다.\n\n\n\nDefinition 2: Monotone Convex Dominance (MCX)\n\n두 확률분포 \\(F\\)와 \\(G\\) 사이의 Monotone Convex Dominance (MCX) 관계는 다음과 같이 정의됩니다.\n\n\\[F \\ge_{mcx} G \\iff \\mathbb{E}_{X \\sim F}[u(X)] \\ge \\mathbb{E}_{X \\sim G}[u(X)]\\]\n\n여기서 \\(u: \\mathbb{R} \\to \\mathbb{R}\\)는 모든 비감소 볼록 함수(non-decreasing convex function)를 의미합니다.\n\n\n\\(u(X)\\)의 역할과 직관적 의미\n\n이 정의에서 \\(u(X)\\)는 단순한 함수가 아니라, 분포의 성질을 테스트하는 ‘극단값 감지기(Extreme Value Detector)’로 이해해야 합니다.\n\n“비감소 (Non-decreasing)”의 의미:\n\n\n\\(u(x)\\)는 \\(x\\)가 커질수록 값도 커집니다.\n이는 분포가 전체적으로 오른쪽(큰 값)으로 치우쳐 있는지를 검사합니다.\n\n\n“볼록 (Convex)”의 의미 (핵심):\n\n\n\\(u(x)\\)는 기울기가 점점 가파라지는 형태(예: \\(x^2, e^x\\))를 띱니다.\n이는 평범한 값보다 꼬리 부분의 극단적인 값(Extreme outliers)에 훨씬 더 큰 가중치(Penalty)를 부여함을 뜻합니다.\n\n따라서, 모든 \\(u\\)에 대해 위 부등식이 성립한다는 것은 다음을 시사합니다:\n\n“\\(F\\)는 \\(G\\)에 비해 ’엄청나게 큰 값’이 튀어나올 확률(Risk)이 더 높다.”\n\n\n\n\nCP에서의 함의: Heavier Tails & Safer Intervals\n\n이 수학적 정의는 Conformal Prediction에서 안전 장치가 됩니다.\n\n꼬리가 두껍다 (Heavier Tails): \\(F\\)(Pseudo-outcome 점수)는 \\(G\\)(실제 ITE 점수)보다 극단적인 오차가 발생할 빈도가 높습니다.\n분위수가 더 크다: 따라서 \\(F\\)의 상위 10% 지점(Quantile)은 \\(G\\)의 상위 10% 지점보다 더 멀리(크게) 형성됩니다.\n결론: \\(F\\)를 기준으로 설정한 예측 구간은 실제 분포 \\(G\\)를 커버하기에 충분히 넓고 보수적(Conservative)임이 보장됩니다.\n\n\n\n\n\nFigure 2: 확률적 지배의 개념적 도식. (a) FOSD는 분포 자체가 오른쪽(큰 값)으로 이동한 형태이고, (b) SOSD/MCX는 분포가 더 넓게 퍼져 불확실성이 큰 형태를 띤다. [cite: 279]"
  },
  {
    "objectID": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#theorem-1-general-validity-condition",
    "href": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#theorem-1-general-validity-condition",
    "title": "[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "section": "Theorem 1: General Validity Condition",
    "text": "Theorem 1: General Validity Condition\n\n이 정의들을 바탕으로 저자들은 Conformal Meta-learner가 유효하기 위한 충분 조건을 제시합니다.\n\n\nTheorem 1. 만약 Pseudo-outcome Conformity Score \\(V_{\\varphi}\\)가 Oracle Score \\(V^*\\)에 대해 다음 중 하나를 만족한다면:\n\n\\(V_{\\varphi} \\ge_{(1)} V^*\\) (FOSD)\n\\(V_{\\varphi} \\le_{(2)} V^*\\) (SOSD의 역방향 조건)\n\\(V_{\\varphi} \\ge_{mcx} V^*\\) (MCX)\n\n특정 범위의 \\(\\alpha \\in (0, \\alpha^*)\\)에 대하여, 다음 커버리지 보장이 성립한다. \\[\\mathbb{P}(\\text{ITE} \\in \\hat{C}_{\\varphi}(X)) \\ge 1 - \\alpha\\]\n\n\n해석:\n\n우리가 사용하는 점수 \\(V_{\\varphi}\\)가 Oracle 점수 \\(V^*\\)보다 더 크거나(FOSD), 더 변동성이 크다면(MCX), 우리가 설정한 분위수(Quantile) \\(Q_{V_{\\varphi}}\\)는 Oracle 분위수 \\(Q_{V^*}\\)보다 크게 됩니다.\n결과적으로 생성된 구간의 폭이 실제 필요한 폭보다 넓어지므로, 보수적인 관점에서 실제 ITE를 안전하게 포함하게 됩니다.\n\n\n\n\n\nFigure 3: Theorem 1의 시각적 설명. Pseudo-score(점선)의 CDF가 Oracle-score(실선)보다 아래에 위치하거나 꼬리가 두꺼우면, 같은 \\(1-\\alpha\\) 레벨에서 더 큰 Threshold 값을 가지게 되어 Validity Region에 들어간다."
  },
  {
    "objectID": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#theorem-2-which-meta-learners-are-valid",
    "href": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#theorem-2-which-meta-learners-are-valid",
    "title": "[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "section": "Theorem 2: Which Meta-learners are Valid?",
    "text": "Theorem 2: Which Meta-learners are Valid?\n\n그렇다면 우리가 앞서 살펴본 3가지 Meta-learner(IPW, X, DR) 중 어떤 것이 이 조건을 만족할까요? 이것이 논문의 핵심 발견입니다.\n\n\nTheorem 2. Propensity score \\(\\pi(x)\\)가 정확히 알려져 있다고 가정할 때:\n\nX-learner: \\(V_{\\varphi}\\)와 \\(V^*\\) 사이에 모델이나 분포와 무관한(Model-free distribution-free) 확률적 순서가 존재하지 않는다.\nIPW-learner & DR-learner: 모든 데이터 분포와 Nuisance estimate에 대해 다음을 만족한다. \\[V_{\\varphi} \\ge_{mcx} V^*\\] 즉, Monotone Convex Dominance를 만족하여 유효성을 보장한다.\n\n\n\nWhy IPW & DR satisfy MCX?\n\nIPW와 DR-learner가 MCX(\\(\\ge_{mcx}\\)) 조건을 만족하여 유효한 예측 구간을 생성할 수 있는 핵심 이유는 이들이 생성하는 Pseudo-outcome의 통계적 성질에 있습니다.\n\n\n1. 구조적 비편향성 (Structural Unbiasedness)\n\n이 두 모델의 가장 강력한 특징은 Nuisance parameter(\\(\\hat{\\mu}\\))의 추정이 불안정하더라도, Propensity Score가 정확하다면 Pseudo-outcome \\(\\tilde{Y}_{\\varphi}\\)가 CATE에 대해 비편향(Unbiased)이라는 점입니다.\n\n\\[\\mathbb{E}[\\tilde{Y}_{\\varphi} \\mid X=x] = \\tau(x)\\]\n\n즉, \\(\\tilde{Y}_{\\varphi}\\)는 실제 효과 \\(\\tau(x)\\)를 중심으로 하는 분포를 가집니다. 이를 수식으로 분해하면 다음과 같습니다.\n\n\\[\n\\tilde{Y}_{\\varphi} = \\tau(x) + \\varepsilon, \\quad \\text{where } \\mathbb{E}[\\varepsilon \\mid X] = 0\n\\]\n\n여기서 \\(\\varepsilon\\)은 Propensity weighting(\\(1/\\pi\\))에 의해 증폭된 노이즈입니다.\n\n\n\n2. 젠센 부등식을 통한 MCX 유도 (Derivation via Jensen’s Inequality)\n\n이 비편향성 덕분에 우리는 젠센 부등식(Jensen’s Inequality)을 적용하여 MCX를 증명할 수 있습니다.\n가정: \\(u(\\cdot)\\)를 임의의 비감소 볼록 함수(Non-decreasing Convex Function)라고 합시다.\n비교: 우리의 목표는 가짜 점수(\\(\\tilde{Y}_{\\varphi}\\))의 기대 손실이 진짜 점수(\\(Y(1)-Y(0)\\))보다 큼을 보이는 것입니다.\nPseudo-outcome은 구조적으로 “평균 보존 확산(Mean-Preserving Spread)”의 형태를 띱니다. 즉, 중심(Mean)은 진짜 효과 \\(\\tau(x)\\)에 고정된 채로, 인위적인 노이즈 \\(\\varepsilon\\)이 더해져 분산만 커진 상태입니다.\n볼록 함수 \\(u\\)의 성질에 의해, 변동성(Spread)이 커질수록 기댓값은 증가합니다.\n\n\\[\n\\begin{aligned}\n\\mathbb{E}[u(\\tilde{Y}_{\\varphi}) \\mid X] &= \\mathbb{E}[u(\\tau(x) + \\varepsilon) \\mid X] \\\\\n&\\ge u(\\mathbb{E}[\\tau(x) + \\varepsilon \\mid X]) \\quad (\\because \\text{Jensen's Inequality}) \\\\\n&= u(\\tau(x))\n\\end{aligned}\n\\]\n\n논문의 증명(Theorem 2 Proof)에 따르면, IPW/DR의 구조적 노이즈 분산은 실제 ITE의 분산보다 크거나 같습니다. 따라서 다음이 성립합니다.\n\n\\[\n\\mathbb{E}_{X \\sim \\text{Pseudo}}[u(\\text{Score})] \\ge \\mathbb{E}_{X \\sim \\text{True}}[u(\\text{Score})]\n\\]\n\n\n\nWhy X-learner fails?\n\n반면 X-learner의 Pseudo-outcome은 다음과 같습니다. \\[\\tilde{Y}_{\\varphi} = W(Y-\\hat{\\mu}_0) + (1-W)(\\hat{\\mu}_1-Y)\\]\n이 식은 \\(\\hat{\\mu}_0, \\hat{\\mu}_1\\) 추정이 완벽하지 않다면 \\(\\mathbb{E}[\\tilde{Y}_{\\varphi}|X] \\neq \\tau(x)\\)일 수 있습니다.\n또한 Propensity score를 이용해 이 오차를 보정하는 구조가 아니기 때문에, 분포에 따라 \\(V_{\\varphi}\\)가 \\(V^*\\)보다 작아질 위험(Under-coverage)이 존재합니다.\n\n\n\n\nMeta-learner\nConformity Score Order\nValidity Guarantee\n\n\n\n\nX-learner\nNo stochastic order\n❌ Not Guaranteed\n\n\nIPW-learner\n\\(V_{\\varphi} \\ge_{mcx} V^*\\)\n✅ Valid\n\n\nDR-learner\n\\(V_{\\varphi} \\ge_{mcx} V^*\\)\n✅ Valid"
  },
  {
    "objectID": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#limitations-and-discussion",
    "href": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#limitations-and-discussion",
    "title": "[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "section": "Limitations and Discussion",
    "text": "Limitations and Discussion\n\n이 이론은 강력하지만, 저자들은 두 가지 현실적인 한계를 솔직하게 인정합니다.\n\n\nLimitation 1: Known Propensity Score Assumption\n\nTheorem 2의 보장은 Propensity score \\(\\pi(x)\\)를 정확히 알고 있다는 가정하에 성립합니다.\nRCT(무작위 대조 실험) 데이터라면 \\(\\pi(x)\\)가 설계에 의해 주어지므로 문제가 없습니다.\n하지만 관측 데이터(Observational Data)라면 \\(\\pi(x)\\)를 추정해야 하며, 추정 오차가 발생할 경우 이론적 보장이 약화될 수 있습니다. (다만 이는 Weighted CP 등 다른 방법론들도 공유하는 문제입니다)\n\n\n\nLimitation 2: Unknown \\(\\alpha^*\\)\n\nTheorem 1은 “특정 \\(\\alpha^*\\) 이하의 \\(\\alpha\\)에 대해 유효하다”라고 말합니다.\n하지만 이 임계값 \\(\\alpha^*\\)가 정확히 얼마인지는 데이터 분포에 따라 다르며 사전에 알기 어렵습니다.\n저자들은 이를 이론적으로 유도하는 것을 Future Work로 남겨두고, 실험적으로 이를 검증하는 방식을 택했습니다."
  },
  {
    "objectID": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#experimental-setup",
    "href": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#experimental-setup",
    "title": "[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "section": "5.1. Experimental Setup",
    "text": "5.1. Experimental Setup\n\n인과추론 실험의 가장 큰 어려움은 Ground Truth (실제 ITE)를 관측할 수 없다는 점입니다.\n따라서 저자들은 실제 공변량을 사용하되 결과값은 시뮬레이션하는 방식 등을 도입했습니다.\n\n\nDatasets\n\n실험은 크게 두 가지 환경에서 진행되었습니다.\n\nSynthetic Datasets (완전 합성 데이터):\n\n\n공변량 \\(X\\)와 처치 \\(W\\)를 모두 생성.\nHeteroscedastic Noise Model: 오차의 분산이 공변량에 따라 달라지는 \\(\\sigma^2(x) = -\\log(x_1)\\) 모델을 사용하여 불확실성 추정의 난이도를 높였습니다.\nSetup A: 처치 효과가 없는 경우 (\\(\\zeta=1\\)).\nSetup B: 이질적 처치 효과(Heterogeneous effects)가 존재하는 경우 (\\(\\zeta=0\\)).\n\n\nSemi-synthetic Datasets (준합성 데이터):\n\n\nIHDP: 영유아 건강 발달 프로그램 데이터.\nNLSM: 국립 학습 사고 방식 연구 데이터.\n실제 공변량을 사용하되, 결과 변수(Outcome)는 시뮬레이션하여 \\(Y(1)\\)과 \\(Y(0)\\)를 모두 알 수 있게 설정했습니다.\n\n\n\n\nBaselines (비교 모델)\n\nConformal Meta-learner(CM)와 비교할 대상은 Weighted Conformal Prediction (WCP) 계열의 방법론들입니다.\nNaïve WCP: \\(Y(0)\\)와 \\(Y(1)\\) 각각에 대해 구간을 구한 뒤, Bonferroni correction을 이용해 결합합니다. (보수적임)\nExact Nested WCP: ITE의 Plug-in 추정치에 대해 WCP를 적용하고, 2차 CP 절차를 수행합니다. (유효성 보장됨)\nInexact Nested WCP: Exact 방식에서 2차 CP 대신 Quantile Regression을 사용합니다. (유효성 보장 안 됨)\nCM Variants: 본 논문의 제안 방법론 (CM-IPW, CM-DR, CM-X).\n모든 모델은 기본 예측기(Base Learner)로 Gradient Boosting을 사용했습니다."
  },
  {
    "objectID": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#results-and-discussion",
    "href": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#results-and-discussion",
    "title": "[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "section": "5.2. Results and Discussion",
    "text": "5.2. Results and Discussion\n\nKey Result 1: Empirical Stochastic Orders\n\n가장 먼저 확인해야 할 것은 Theorem 1 & 2의 이론적 예측이 실제 데이터 분포에서 성립하는지 여부입니다.\n우리는 Pseudo-outcome Conformity Score (\\(V_{\\varphi}\\))의 누적 분포 함수(CDF)가 Oracle Score (\\(V^*\\))의 CDF보다 아래에 위치(FOSD)하거나, 더 완만하게 증가(MCX)하기를 기대합니다.\n\n\n\n\nFigure 4: 합성 데이터 실험 결과. (a) Conformity Score들의 CDF 비교. 파란색 실선(\\(V_{\\varphi}\\))이 빨간색 점선(\\(V^*\\))보다 우측에 위치하면 확률적으로 더 큰 값(FOSD)임을 의미한다. DR과 IPW는 이를 만족하지만, X-learner는 반대 경향을 보인다.\n\n\n\n분석 결과\n\nIPW & DR-learner:\n\n그래프 (a)에서 파란색 선(\\(V_{\\varphi}\\))이 빨간색 선(\\(V^*\\))보다 항상 우측 하단에 위치합니다.\n이는 First-Order Stochastic Dominance (FOSD)를 만족함을 보여줍니다.\nFOSD는 이론적으로 요구되었던 MCX보다 훨씬 강력한 조건입니다. 즉, 이 모델들은 매우 안정적으로 유효한 구간을 생성합니다.\n\nX-learner:\n\n반대로 파란색 선이 빨간색 선보다 좌측 상단에 위치합니다.\n이는 Pseudo-score가 실제 오차보다 과소평가됨을 의미하며, Under-coverage(커버리지 미달)로 이어질 것임을 예고합니다.\n\n\n\n\n\nKey Result 2: Performance Comparison\n\n이제 실제 커버리지(Coverage), 구간 길이(Efficiency), 정확도(RMSE) 측면에서 성능을 비교해봅시다.\n\n\n\n\nFigure 5: 준합성 데이터(IHDP, NLSM)에서의 확률적 지배 양상. DR-learner와 IPW-learner는 Oracle Score를 지배(Dominance)하는 패턴을 유지한다.\n\n\n\nCoverage (유효성)\n\nCM-DR, CM-IPW: 목표 수준인 90% (\\(1-\\alpha=0.9\\))를 안정적으로 달성하거나 상회했습니다.\nCM-X: 예상대로 목표 커버리지에 도달하지 못했습니다 (Under-coverage).\nBaselines: Naïve와 Exact WCP는 유효했으나, Inexact WCP는 커버리지를 보장하지 못했습니다.\n\n\n\nEfficiency (구간 길이) & RMSE\n\nCM-DR (Winner): DR-learner는 유효한 모델들 중에서 가장 짧은 구간 길이(Interval Length)와 가장 낮은 RMSE를 기록했습니다. 즉, “정답을 포함하면서도 가장 타이트한 구간”을 제공했습니다.\nNaïve WCP: 유효하지만 구간이 너무 넓어 실용성이 떨어집니다.\nCM-X: RMSE는 가장 낮았으나(점 추정은 정확함), 구간 추정이 틀렸기 때문에 신뢰할 수 없습니다.\n\n\n\nWhy is DR better than IPW?\n\nCM-IPW와 CM-DR 모두 유효하지만, CM-DR의 구간이 더 좁고 효율적입니다. 그 이유는 CDF의 차이(Gap)에 있습니다.\nIPW의 Pseudo-outcome은 분산이 매우 큽니다. 이로 인해 Conformity score가 지나치게 커져, Oracle score와의 격차(Gap)가 벌어집니다.\n반면, DR-learner는 Regression adjustment 항 덕분에 Pseudo-outcome의 분산이 상대적으로 작습니다. 결과적으로 \\(V_{\\varphi}\\)의 분포가 \\(V^*\\)의 분포에 더 가깝게 밀착(Tight bound)되어, 불필요하게 넓은 구간을 만들지 않습니다."
  },
  {
    "objectID": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#핵심-요약",
    "href": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#핵심-요약",
    "title": "[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "section": "핵심 요약",
    "text": "핵심 요약\n\n\nFramework: Pseudo-outcome을 정의하여 CATE 추정 문제를 회귀 문제로 변환하고, 그 위에 CP를 적용하여 모델에 구애받지 않는(Model-agnostic) 구간 추정 방법을 제시했습니다.\n\n\nTheory: Pseudo-score와 Oracle-score 간의 Stochastic Ordering (확률적 지배) 조건을 정립하여, 어떤 상황에서 구간이 유효한지 수학적으로 증명했습니다.\n\n\nFindings:\n\n\nDR-learner와 IPW-learner는 이론적/실험적으로 유효성(Validity)이 보장됩니다.\n특히 DR-learner는 가장 효율적인(좁은) 구간을 제공하여 실용적으로 가장 우수합니다.\nX-learner는 점 추정 성능은 좋으나, 불확실성 추정에는 적합하지 않을 수 있습니다."
  },
  {
    "objectID": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#future-work",
    "href": "posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/index.html#future-work",
    "title": "[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects",
    "section": "Future Work",
    "text": "Future Work\n\nPropensity score를 모를 때의 불확실성 반영.\n이론적인 최적 \\(\\alpha^*\\) 값의 유도.\nStochastic order를 유지하면서도 효율성을 극대화하는 새로운 Pseudo-outcome 변환법 연구."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-02/index.html",
    "href": "posts/lecture/L08/causal-inference-08-part-02/index.html",
    "title": "[Causal Inference] 08. Partial Identification (Part 2)",
    "section": "",
    "text": "지난 포스트에서는 가장 일반적인 형태의 비관측 교란 상황에서 Natural Bounds를 구하는 법을 배웠습니다.\n이번에는 인과추론에서 매우 중요한 환경인 도구 변수(Instrumental Variable, IV)가 주어졌을 때, 인과 효과의 범위를 어떻게 더 좁힐 수 있는지 알아봅니다.\n특히, 이 문제를 해결하기 위해 Canonical Type Models (CTM)을 도입하고, 이를 선형 계획법(Linear Programming) 문제로 변환하여 최적의 범위(Tight Bounds)를 찾아내는 과정을 다룹니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-02/index.html#natural-bounds-iv-모델",
    "href": "posts/lecture/L08/causal-inference-08-part-02/index.html#natural-bounds-iv-모델",
    "title": "[Causal Inference] 08. Partial Identification (Part 2)",
    "section": "2.1 Natural Bounds (IV 모델)",
    "text": "2.1 Natural Bounds (IV 모델)\n\n관측 분포 \\(P(X, Y|Z)\\)가 주어졌을 때, 인과 효과 \\(P(y|do(x))\\)는 구간 \\([a(y, x), b(y, x)]\\) 안에 존재합니다. 여기서 각 경계값은 다음과 같습니다.\n\n\\[\na(y, x) = \\max_z P(y, x|z)\n\\] \\[\nb(y, x) = \\min_z [P(y, x|z) + 1 - P(x|z)]\n\\]\n\n모델 \\(\\mathcal{M}_z\\)에 Natural Bounds를 적용하면 아래와 같습니다.\n\n우선 Natural Bounds 식에서 시작합니다. \\[\nP(y, x) \\le P(y|do(x)) \\le P(y, x) + 1 - P(x)\n\\]\n\\(do(z)\\)를 한 그래프에서도 Natural Bounds는 성립하므로, \\[\nP(y, x|do(z)) \\le P(y|do(x,z)) \\le P(y, x|do(z)) + 1 - P(x|do(z))\n\\]\nRule 2에 의해 \\(Z\\)에 대한 개입은 관찰과 같으므로 특정 \\(z\\)값에 대해 다음 부등식이 성립합니다.\n추가로 \\(X\\)에 대한 개입이 이루어진 상황에서 도구변수 \\(Z\\)가 \\(Y\\)에 직접적인 영향을 주지 않으므로 \\(P(y∣do(x),z)=P(y∣do(x))\\) 입니다.\n어떤 \\(z\\)값을 택하든 인과 효과는 동일해야 한다는 것입니다. \\[\nP(y, x|z) \\le P(y|do(x)) \\le P(y, x|z) + 1 - P(x|z)\n\\]\n따라서 도구변수 값에 따른 Bounds의 교집합(intersection)이 Natural Bounds가 됩니다.\n\n\n\n\n\nFigure 2: Natural Bounds of IV Model. 도구변수의 값에 따른 인과효과 범위의 교집합이 Natural Bounds가 됩니다.\n\n\n\n하지만 Natural Bounds는 이론적 한계까지 좁혀지지 않은 상태(Not Tight)입니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-02/index.html#모델-집합-정의-model-definition",
    "href": "posts/lecture/L08/causal-inference-08-part-02/index.html#모델-집합-정의-model-definition",
    "title": "[Causal Inference] 08. Partial Identification (Part 2)",
    "section": "3.1 모델 집합 정의 (Model Definition)",
    "text": "3.1 모델 집합 정의 (Model Definition)\n\n주어진 그래프 구조와 호환되는 모든 구조적 인과 모델(SCM)의 집합을 \\(\\mathbf{M}\\)이라고 합시다.\n모델 \\(\\mathscr{M}\\)은 다음과 같이 정의됩니다.\n\n\\[\n\\mathscr{M} = \\begin{cases}\nU \\sim P(U) \\\\\nZ \\leftarrow f_Z(U_Z) \\\\\nX \\leftarrow f_X(Z, U) \\\\\nY \\leftarrow f_Y(X, U)\n\\end{cases}\n\\]"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-02/index.html#최적화-문제-optimization-problem",
    "href": "posts/lecture/L08/causal-inference-08-part-02/index.html#최적화-문제-optimization-problem",
    "title": "[Causal Inference] 08. Partial Identification (Part 2)",
    "section": "3.2 최적화 문제 (Optimization Problem)",
    "text": "3.2 최적화 문제 (Optimization Problem)\n\n관측 데이터 \\(P(x, y|z)\\)가 주어졌을 때, 참(True) 인과 효과 \\(P(y|do(x))\\)는 다음 최적화 문제로 정의된 구간 \\([a(y; x), b(y; x)]\\) 내에 존재해야 합니다.\n\n\\[\na(y; x) = \\min_{\\mathscr{M} \\in \\mathbf{M} \\mid P_{\\mathscr{M}}(y,x|z) = P(x,y|z)} P_{\\mathscr{M}}(y|do(x))\n\\]\n\\[\nb(y; x) = \\max_{\\mathscr{M} \\in \\mathbf{M} \\mid P_{\\mathscr{M}}(y,x|z) = P(x,y|z)} P_{\\mathscr{M}}(y|do(x))\n\\]\n\n\\(\\mathscr{M} \\in \\mathbf{M} \\mid P_{\\mathscr{M}}(y,x|z) = P(x,y|z)\\)는 가상 모델(\\(\\mathscr{M}\\)) 중, 그 모델이 만들어내는 통계(\\(P_{\\mathscr{M}}\\))가 실제 관측된 데이터(\\(P\\))와 정확히 일치하는 모델만을 고려함을 의미합니다.\nDifficulty: 이 최적화 문제를 해결하는 것은 다음과 같은 이유로 어렵습니다.\n\n\n함수 집합 \\(\\mathbf{F}\\) (\\(f_X, f_Y\\) 등)의 모수적 형태(parametric form)가 주어지지 않았습니다.\n\n\n잠재 변수의 분포 \\(P(U)\\)를 알 수 없습니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-02/index.html#반응-변수-response-variables",
    "href": "posts/lecture/L08/causal-inference-08-part-02/index.html#반응-변수-response-variables",
    "title": "[Causal Inference] 08. Partial Identification (Part 2)",
    "section": "4.1 반응 변수 (Response Variables)",
    "text": "4.1 반응 변수 (Response Variables)\n\n변수 \\(X\\)와 \\(Y\\)가 부모 변수의 값에 따라 어떻게 반응하는지를 결정하는 잠재적 특성을 \\(R_X, R_Y\\)라고 정의합시다.\n\n\n4.1.1 \\(R_X\\): 배정(\\(Z\\))에 대한 순응 유형\n\n\\(Z\\)가 \\(0\\) 또는 \\(1\\)일 때, \\(X\\)가 어떻게 반응하는지에 따라 총 4가지 유형(\\(2^2\\))이 존재합니다.\n\nNever-taker (\\(R_X=0\\)): 배정과 상관없이 처치를 받지 않음 (\\(Z=0 \\to X=0, Z=1 \\to X=0\\))\nComplier (\\(R_X=1\\)): 배정된 대로 따름 (\\(Z=0 \\to X=0, Z=1 \\to X=1\\))\nDefier (\\(R_X=2\\)): 배정과 반대로 행동함 (\\(Z=0 \\to X=1, Z=1 \\to X=0\\))\nAlways-taker (\\(R_X=3\\)): 배정과 상관없이 무조건 처치를 받음 (\\(Z=0 \\to X=1, Z=1 \\to X=1\\))\n\n\n\n\n4.1.2 \\(R_Y\\): 처치(\\(X\\))에 대한 반응 유형\n\n마찬가지로 \\(X\\)가 \\(0\\) 또는 \\(1\\)일 때, 결과 \\(Y\\)가 어떻게 나오는지에 따라 4가지 유형이 있습니다.\n\nNever-recover (\\(R_Y=0\\)): 약을 먹든 안 먹든 낫지 않음.\nHelped (\\(R_Y=1\\)): 약을 먹으면 낫고, 안 먹으면 안 나음 (인과 효과 있음).\nHurt (\\(R_Y=2\\)): 약을 먹으면 오히려 아프고, 안 먹어야 나음.\nAlways-recover (\\(R_Y=3\\)): 약을 먹든 안 먹든 항상 나음.\n\n\n\n\n\nFigure 3: Partition of U. U의 공간이 Rx와 Ry의 조합(총 16가지)에 의해 분할되는 모습을 나타낸 그림.\n\n\n\nNote: \\(U\\)는 \\(R_X\\)(4가지)와 \\(R_Y\\)(4가지)의 조합인 총 16개의 영역으로 나뉩니다.*\n\n\n\n4.1.3 동치 정리 (Equivalence Theorem)\n\n\n\nFigure 4: IV Model and Canonical Model. IV 모델에 대응되는 Canonical 모델의 모습.\n\n\n\nTheorem: 모든 IV 모델은 그에 상응하는 Canonical Type Model로 변환될 수 있으며, 동일한 관측 분포와 인과 효과를 가집니다.\n\n\nFor any IV model \\(\\mathscr{M}_{1}\\), there exists a canonical type model \\(\\mathscr{M}_{2}\\) such that \\(P_{\\mathscr{M}_{1}}(x,y|z) = P_{\\mathscr{M}_{2}}(x,y|z)\\), \\(P_{\\mathscr{M}_{1}}(y|do(x)) = P_{\\mathscr{M}_{2}}(y|do(x))\\)\n\n\n이 정리는 우리가 복잡하고 무한한 형태의 \\(U\\)를 고려할 필요 없이, 유한한 16개의 파라미터(\\(R_X, R_Y\\)의 결합 분포)만 최적화하면 된다는 것을 보장합니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-02/index.html#파라미터-정의-r_x-r_y-rightarrow-q_j-k",
    "href": "posts/lecture/L08/causal-inference-08-part-02/index.html#파라미터-정의-r_x-r_y-rightarrow-q_j-k",
    "title": "[Causal Inference] 08. Partial Identification (Part 2)",
    "section": "5.1 파라미터 정의 (\\((R_{x}, R_{y}) \\rightarrow q_{j, k}\\))",
    "text": "5.1 파라미터 정의 (\\((R_{x}, R_{y}) \\rightarrow q_{j, k}\\))\n\n우리가 찾아야 할 미지수는 \\(R_X\\)와 \\(R_Y\\)의 결합 확률분포입니다.\n\n\\[\nq_{j,k} = P(R_X=j, R_Y=k), \\quad j,k \\in \\{0,1,2,3\\}\n\\]\n\n총 16개의 \\(q_{j,k}\\)가 있으며, 이들의 합은 1이어야 합니다.\n\n\\[\n\\sum_{j} \\sum_{k} q_{j,k} = 1\n\\]"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-02/index.html#관측-데이터와의-연결-q_jk-rightarrow-px-x-y-y-z-z",
    "href": "posts/lecture/L08/causal-inference-08-part-02/index.html#관측-데이터와의-연결-q_jk-rightarrow-px-x-y-y-z-z",
    "title": "[Causal Inference] 08. Partial Identification (Part 2)",
    "section": "5.2 관측 데이터와의 연결 (\\(q_{jk} \\rightarrow P(X = x, Y = y | Z = z)\\))",
    "text": "5.2 관측 데이터와의 연결 (\\(q_{jk} \\rightarrow P(X = x, Y = y | Z = z)\\))\n\n관측된 데이터 \\(P_{yx.z} = P(X=x, Y=y | Z=z)\\)는 \\(q_{j,k}\\)들의 선형 결합으로 표현됩니다.\n예를 들어, \\(P(Y=0, X=0 | Z=0)\\)인 경우를 봅시다.\n\n\\(Z=0\\)일 때 \\(X=0\\)이 되려면: Never-taker(\\(R_{x}=0\\)) 또는 Complier(\\(R_{x}=1\\))여야 합니다.\n\\(X=0\\)일 때 \\(Y=0\\)이 되려면: 처치를 안 받았을 때 안 나아야 하므로 Never-recover(\\(R_{y}=0\\)) 또는 Helped(\\(R_{y}=1\\))여야 합니다.\n\n따라서 해당 \\(q_{j,k}\\)들을 모두 더하면: \\[\nP_{00.0} = q_{00} + q_{01} + q_{10} + q_{11}\n\\]\n이와 같은 방식으로 8개의 관측 확률(\\(P_{yx.z}\\))을 모두 \\(q\\)에 대한 선형 방정식으로 만들 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-02/index.html#인과-효과-q_j-k-rightarrow-py-dox",
    "href": "posts/lecture/L08/causal-inference-08-part-02/index.html#인과-효과-q_j-k-rightarrow-py-dox",
    "title": "[Causal Inference] 08. Partial Identification (Part 2)",
    "section": "5.3 인과 효과 (\\(q_{j, k} \\rightarrow P(Y | do(x))\\))",
    "text": "5.3 인과 효과 (\\(q_{j, k} \\rightarrow P(Y | do(x))\\))\n\n우리가 알고 싶은 인과 효과 \\(P(Y=1 | do(X=1))\\) 또한 \\(q_{j,k}\\)의 합으로 표현됩니다.\n\n\\[\n\\begin{aligned}\nP(Y=1 | do(X=1)) &= P(R_Y \\in \\{\\text{Helped, Always-recover}\\}) \\\\\n&= P(R_Y=1) + P(R_Y=3) \\\\\n&= \\sum_{j=0}^3 (q_{j1} + q_{j3})\n\\end{aligned}\n\\]\n\n\\(do(x)\\)의 의미\n\n\\(do(X=x)\\)는 \\(R_X\\)의 성향을 무시하고(무력화하고) 강제로 처치를 가하는 것입니다.\n따라서 인과 효과를 계산할 때는 \\(R_X\\)에 대한 조건 없이, 오직 \\(Y\\)가 처치 \\(x\\)에 어떻게 반응하는지(\\(R_Y\\))만 고려하면 됩니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-02/index.html#해결-및-결과",
    "href": "posts/lecture/L08/causal-inference-08-part-02/index.html#해결-및-결과",
    "title": "[Causal Inference] 08. Partial Identification (Part 2)",
    "section": "5.4 해결 및 결과",
    "text": "5.4 해결 및 결과\n\nCanonical Type Model을 도입함으로써, 우리는 무한한 차원의 문제를 16개의 변수(\\(q_{j,k}\\))를 가진 선형 계획법(Linear Programming) 문제로 변환했습니다.\n이를 구체적인 수식으로 살펴보겠습니다.\n\n\n5.4.1 최적화 문제 정의 (Optimization Setup)\n\n목표: 관측 데이터(\\(P\\))와 확률의 공리(\\(\\sum q = 1, q \\ge 0\\))를 만족하면서, 인과 효과를 최소화/최대화하는 \\(q\\)의 조합을 찾는 것입니다.\n\n\n5.4.1.1 목적 함수 (Objective Function):\n\n예를 들어, \\(P(Y=1 | do(X=0))\\)의 범위를 구한다고 가정해 봅시다.\n\\(X=0\\)으로 처치를 고정했을 때 \\(Y=1\\)이 나오는 반응 유형은 Hurt(\\(R_{y}=2\\))와 Always-recover(\\(R_{y}=3\\))입니다.\n따라서 목적 함수는 다음과 같습니다.\n\n\\[\n\\min_\\mathbf{q} \\sum_{j=0}^3 (q_{j2} + q_{j3}) \\quad \\text{또는} \\quad \\max_\\mathbf{q} \\sum_{j=0}^3 (q_{j2} + q_{j3})\n\\]\n\n\n5.4.1.2 제약 조건 (Constraints):\n\n관측확률에 대한 선형 등식: \\[\n\\begin{aligned}\np_{00.0} &= q_{00} + q_{01} + q_{10} + q_{11} \\\\\np_{00.1} &= q_{00} + q_{01} + q_{20} + q_{21} \\\\\n&\\vdots \\\\\np_{11.1} &= q_{12} + q_{13} + q_{32} + q_{33}\n\\end{aligned}\n\\]\n확률의 공리: \\(\\sum_{j,k} q_{j,k} = 1\\), \\(q_{j,k} \\ge 0\\)\n\n\n\n5.4.1.3 Closed-form Solution\n\n이 선형 계획법 문제를 심플렉스 알고리즘 등으로 풀면, Closed-form Solution를 얻을 수 있습니다.\n인과 효과 \\(P(Y=1 | do(X=0))\\)의 하한(Lower Bound)은 다음 값들 중 최댓값(\\(\\max\\))으로 결정됩니다.\n\n\\[\nP(Y=1 | do(X=0)) \\ge \\max \\begin{cases}\np_{10.0} \\\\\np_{10.1} \\\\\np_{10.0} + p_{11.0} - p_{00.1} - p_{11.1} \\\\\np_{01.0} + p_{10.0} - p_{00.1} - p_{01.1} \\\\\n\\end{cases}\n\\]\n\\[\nP(Y=1 | do(X=0)) \\le \\min \\begin{cases}\n1 - p_{00.0} \\\\\n1 - p_{00.1} \\\\\np_{10.0} + p_{11.0} + p_{01.1} + p_{10.1} \\\\\np_{01.0} + p_{10.0} + p_{10.1} + p_{11.1} \\\\\n\\end{cases}\n\\]\n\n\n\n5.4.2 결과의 의미\n\n위 수식은 복잡해 보이지만 중요한 함의를 갖습니다.\n\n\n데이터만으로 계산 가능: 우변의 모든 항(\\(p_{yx.z}\\))은 관측 데이터로부터 바로 구할 수 있는 값들입니다.\n\n\nTightness: 이 범위는 IV 모델의 가정(\\(Z \\perp U\\) 등)을 수학적으로 완벽하게 반영한 결과입니다. 따라서 추가적인 가정이 없다면 이보다 더 좁은 범위를 찾는 것은 불가능합니다.\n\n\nNote: Natural Bounds는 단순히 관측된 확률의 교집합만 고려하지만, Balke-Pearl Bounds(LP)는 도구 변수의 구조적 정보를 최적화 과정에 반영하여 훨씬 더 정보가 풍부한(Informative) 결과를 제공합니다.*"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-04/index.html",
    "href": "posts/lecture/L08/causal-inference-08-part-04/index.html",
    "title": "[Causal Inference] 08. Partial Identification (Part 4)",
    "section": "",
    "text": "이번 포스트에서는 실험 설계에서 흔히 발생하는 비순응(Non-compliance) 문제를 다룹니다.\n할당된 처치(\\(Z\\))와 실제 받은 처치(\\(X\\))가 일치하지 않는 상황에서, 인과 효과(ATE)를 식별하고 추정하는 다양한 방법들을 코드로 구현하고 비교해 봅니다.\n주요 내용은 다음과 같습니다.\n\n\n데이터 생성 (Data Generation): Compliance Type과 Response Type을 기반으로 가상 데이터 생성\n점 추정 (Point Estimate): 도구변수(IV)를 활용한 LATE 추정 (DoWhy 라이브러리 활용)\n구간 추정 (Interval Estimate):\n\nNatural Bounds (Manski): 가정 없이 관측 데이터만으로 도출한 구간\nIV Natural Bounds: 도구변수 가정을 추가했을 때의 구간\nBalke-Pearl Bounds (LP): 선형 계획법(Linear Programming)을 이용한 최적 구간\n\n결과 비교 및 시각화"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-04/index.html#왜-점-추정이-가능한가-단조성-가정-the-role-of-monotonicity",
    "href": "posts/lecture/L08/causal-inference-08-part-04/index.html#왜-점-추정이-가능한가-단조성-가정-the-role-of-monotonicity",
    "title": "[Causal Inference] 08. Partial Identification (Part 4)",
    "section": "왜 점 추정이 가능한가? (단조성 가정, The Role of Monotonicity)",
    "text": "왜 점 추정이 가능한가? (단조성 가정, The Role of Monotonicity)\n\n일반적인 도구변수 추정량(Wald Estimator)은 다음과 같습니다.\n\n\\[\n\\beta_{IV} = \\frac{E[Y|Z=1] - E[Y|Z=0]}{E[X|Z=1] - E[X|Z=0]}\n\\]\n\n이 수식이 인과 효과로 해석되려면 Defiers가 없어야 합니다.\n즉, (처방)일 때 (미복용)이고, (미처방)일 때 (복용)인 사람이 없다는 단조성 가정(\\(X_{i}(1) \\ge X_{i}(0)\\))이 필요합니다.\n이 가정이 성립할 때, 추정량은 Compliers(순응자) 집단의 평균 처치 효과로 식별됩니다.\n\n\n\nCode\n# ==============================================================================\n# 2. Point Estimate: DoWhy를 이용한 LATE 추정\n# ==============================================================================\ndef point_estimate(df):\n    \"\"\"\n    DoWhy 라이브러리를 사용하여 IV(도구변수) 추정량을 계산합니다.\n    \"\"\"\n    # 1. Causal Model 정의 (Graph)\n    # Z -&gt; X -&gt; Y, U -&gt; X, U -&gt; Y (U는 Unobserved Confounder)\n    model = CausalModel(\n        data=df,            # 데이터\n        treatment='X',      # 원인 변수 (약 복용 여부)\n        outcome='Y',        # 결과 변수 (완치 여부)\n        instruments=['Z'],  # 도구 변수 (의사 처방)\n        common_causes=[]    # 공통 원인 (교란 변수 U)\n    )\n    \n    # 2. 식별 (Identification)\n    identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n    \n    # 3. 추정 (Estimation) - Wald Estimator (IV 방식)\n    estimate = model.estimate_effect(\n        identified_estimand,\n        method_name=\"iv.instrumental_variable\"\n    )\n    \n    return estimate.value"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-04/index.html#linear-programming-formulation-the-matrix-view",
    "href": "posts/lecture/L08/causal-inference-08-part-04/index.html#linear-programming-formulation-the-matrix-view",
    "title": "[Causal Inference] 08. Partial Identification (Part 4)",
    "section": "Linear Programming Formulation: The Matrix View",
    "text": "Linear Programming Formulation: The Matrix View\n\n우리가 작성한 solve_lp 함수는 수학적으로 거대한 연립방정식(\\(A\\mathbf{x} = \\mathbf{b}\\))을 조립하여 푸는 과정입니다.\n이를 행렬식으로 시각화하면 다음과 같습니다.\n\n\\[\n\\underbrace{\n\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n\\hdashline\n1 & 0 & 0 & \\dots & 0 \\\\\n0 & 1 & 1 & \\dots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & 0 & \\dots & 1\n\\end{bmatrix}\n}_{A_{eq} \\; (9 \\times 16)}\n\\times\n\\underbrace{\n\\begin{bmatrix}\nq_{00} \\\\\nq_{01} \\\\\nq_{02} \\\\\n\\vdots \\\\\nq_{33}\n\\end{bmatrix}\n}_{\\mathbf{q} \\; (16 \\times 1)}\n=\n\\underbrace{\n\\begin{bmatrix}\n1 \\\\\n\\hdashline\nP(y=0, x=0 | z=0) \\\\\nP(y=0, x=0 | z=1) \\\\\n\\vdots \\\\\nP(y=1, x=1 | z=1)\n\\end{bmatrix}\n}_{\\mathbf{b}_{eq} \\; (9 \\times 1)}\n\\]"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-04/index.html#구성-요소-상세-설명",
    "href": "posts/lecture/L08/causal-inference-08-part-04/index.html#구성-요소-상세-설명",
    "title": "[Causal Inference] 08. Partial Identification (Part 4)",
    "section": "구성 요소 상세 설명",
    "text": "구성 요소 상세 설명\n\n1. 미지수 벡터 \\(\\mathbf{q}\\) (The Unknowns)\n우리가 찾고 싶은 16가지 잠재 유형(Canonical Types)의 비율입니다. \\[\\mathbf{q} = [q_{00}, q_{01}, \\dots, q_{33}]^T\\] 현실에서는 관측할 수 없지만, 이 값들이 모여서 실제 데이터를 만들어냅니다.\n\n\n2. 계수 행렬 \\(A_{eq}\\) (The Logic)\n우리가 세운 Canonical Model의 논리를 담고 있는 “출석부”입니다. \\[A_{eq} \\in \\{0, 1\\}^{9 \\times 16}\\]\n\n1행 (Sum Constraint): “모든 \\(q\\)의 합은 1이어야 한다.” (모두 1)\n2~9행 (Model Constraint): “특정 관측 상황(\\(Z, X, Y\\))을 만들어내는 유형(\\(q\\))들만 1로 표시한다.”\n\n예: \\(Z=0\\)일 때 \\(X=0, Y=0\\)이 되려면, \\(q_{00}\\) (Never-taker & Never-recover) 등이 참여해야 함.\n\n\n\n\n3. 상수 벡터 \\(\\mathbf{b}_{eq}\\) (The Data)\n우리가 수집한 실제 관측 데이터(Observed Probabilities)입니다. \\[\\mathbf{b}_{eq} = [1, \\hat{P}_{00.0}, \\dots, \\hat{P}_{11.1}]^T\\] 이 값들이 연립방정식의 “정답지(Target)” 역할을 하여, 미지수 \\(\\mathbf{q}\\)가 현실과 동떨어지지 않게 붙잡아줍니다.\n\n\n최적화 목표 (Objective Function)\n이 제약조건(\\(A_{eq}\\mathbf{q} = \\mathbf{b}_{eq}\\))을 만족하는 수많은 \\(\\mathbf{q}\\) 중에서, 다음을 최소화(또는 최대화)하는 조합을 찾습니다.\n\\[\\min_{\\mathbf{q}} \\; ( \\mathbf{c}^T \\mathbf{q} ) = \\min \\sum_{j,k} c_{jk} q_{jk}\\]\n여기서 \\(\\mathbf{c}\\)는 인과 효과(ATE)를 계산하는 가중치 벡터입니다. \\[\\mathbf{c} = [\\dots, \\underbrace{+1}_{\\text{Helped}}, \\dots, \\underbrace{-1}_{\\text{Hurt}}, \\dots]\\]\n\n\nCode\n# ==============================================================================\n# 3. Interval Estimate: Linear Programming (Balke-Pearl Bounds)\n# ==============================================================================\ndef lp_bounds(df):\n    # 1. 관측 확률 계산\n    # p_yx.z = P(X = x, Y = y | Z = z) 가 계산됨.\n    p_obs = df.groupby(['Y', 'X', 'Z']).size() / df.groupby('Z').size()\n    p_obs_dict = {idx: val for idx, val in p_obs.items()}\n    \n    # 2. 최적화 함수 정의 (앞서 작성한 로직)\n    def solve_lp(objective_coef):\n        num_vars = 16\n        \n        # 제약조건 A_eq(좌변), b_eq(우변) 생성\n        A_eq = []\n        b_eq = []\n        \n        # (1) 확률 총합 = 1\n        A_eq.append([1] * num_vars)\n        b_eq.append(1)\n        \n        # (2) 관측 데이터 정합성 (8개 방정식)\n        for z in [0, 1]:\n            for x in [0, 1]:\n                for y in [0, 1]:\n                    row = [0] * num_vars\n                    target_prob = p_obs_dict.get((y, x, z), 0)\n                    \n                    # 16개 유형에 대해 Canonical Model 매핑\n                    for j in range(4): # Compliance\n                        for k in range(4): # Response\n                            rx = [j//2, j%2] # [X|Z=0, X|Z=1]\n                            ry = [k//2, k%2] # [Y|X=0, Y|X=1]\n                            if (rx[z] == x) and (ry[x] == y) :\n                                row[4 * j + k] = 1\n                                \n                    A_eq.append(row)\n                    b_eq.append(target_prob)\n                    \n        # LP 실행\n        bounds = [(0, 1) for _ in range(num_vars)]\n        res = linprog(objective_coef, A_eq=A_eq, b_eq=b_eq, bounds=bounds)\n        return res.fun\n\n    # 3. 목적 함수 설정 (ATE = Helped - Hurt)\n    # ATE = P(Y = 1 | do(X = 1)) - P(Y = 1 | do(X = 0))\n    #     = {P(Helped) + P(Always-recover)} - {P(Hurt) + P(Always-recover)}\n    #     = P(Helped) - P(Hurt)\n    coef_ate_min = []\n    coef_ate_max = []\n    for j in range(4):\n        for k in range(4):\n            val = 1 if k==1 else (-1 if k==2 else 0)\n            coef_ate_min.append(val)\n            coef_ate_max.append(-val)\n            \n    # 4. 결과 도출\n    min_ate = solve_lp(coef_ate_min)\n    max_ate = -solve_lp(coef_ate_max) # 부호 원복\n    \n    return min_ate, max_ate"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-04/index.html#natural-bounds",
    "href": "posts/lecture/L08/causal-inference-08-part-04/index.html#natural-bounds",
    "title": "[Causal Inference] 08. Partial Identification (Part 4)",
    "section": "5. Natural Bounds",
    "text": "5. Natural Bounds\n비교를 위해 더 넓은 구간을 가지는 Natural Bounds를 계산합니다.\n\nIV Natural Bounds: 도구변수가 있을 때의 최악의 경우(Worst-case) 구간\nPure Manski Bounds: 도구변수 없이 관측 데이터 \\(P(Y, X)\\)만으로 계산한 구간 (가장 넓음)\n\n\n\nCode\n# ==============================================================================\n# 4.1 Natural Bounds\n# ==============================================================================\ndef calculate_natural_bounds_iv(df):\n    p_xy_z = df.groupby(['Y', 'X', 'Z']).size() / df.groupby('Z').size()\n    \n    def get_p_xy_z(y, x, z):\n        return p_xy_z.get((y, x, z), 0)\n    \n    def get_p_x_z(x, z):\n        return get_p_xy_z(0, x, z) + get_p_xy_z(1, x, z)\n\n    # 1. P(Y=1 | do(X=1)) Bounds \n    # a = max_z P(y, x | z)\n    # b = min_z P(y, x | z) + 1 - P(x | z)\n    lower_do1 = max(get_p_xy_z(1, 1, 0), get_p_xy_z(1, 1, 1))\n    upper_do1 = min(get_p_xy_z(1, 1, 0) + 1 - get_p_x_z(1, 0), \n                    get_p_xy_z(1, 1, 1) + 1 - get_p_x_z(1, 1))\n    \n    # 2. P(Y=1 | do(X=0)) Bounds\n    lower_do0 = max(get_p_xy_z(1, 0, 0), get_p_xy_z(1, 0, 1))\n    upper_do0 = min(get_p_xy_z(1, 0, 0) + 1 - get_p_x_z(0, 0), \n                    get_p_xy_z(1, 0, 1) + 1 - get_p_x_z(0, 1))\n    \n    # 3. ATE Bounds (Worst Case)\n    # ATE = do(1) - do(0)\n    # Min ATE = Min(do1) - Max(do0)\n    # Max ATE = Max(do1) - Min(do0)\n    nat_min = lower_do1 - upper_do0\n    nat_max = upper_do1 - lower_do0\n    \n    return nat_min, nat_max\n\n# ==============================================================================\n# 4.2 Natural Bounds\n# ==============================================================================\ndef calculate_natural_bounds(df):\n    p_xy = df.groupby(['Y', 'X']).size() / len(df)\n    \n    def get_p_xy(y, x):\n        return p_xy.get((y, x), 0)\n\n    def get_p_x(x):\n        return get_p_xy(0, x) + get_p_xy(1, x)\n        \n    # 1. P(Y=1 | do(X=1)) Bounds \n    # a = P(y, x)\n    # b = P(y, x) + 1 - P(x)\n    lower_do1 = get_p_xy(1, 1)\n    upper_do1 = get_p_xy(1, 1) + 1 - get_p_x(1)\n    # 2. P(Y=1 | do(X=0)) Bounds \n    lower_do0 = get_p_xy(1, 0)\n    upper_do0 = get_p_xy(1, 0) + 1 - get_p_x(0)\n    \n    # 3. ATE Bounds (Worst Case)\n    # ATE = do(1) - do(0)\n    # Min ATE = Min(do1) - Max(do0)\n    # Max ATE = Max(do1) - Min(do0)\n    nat_min = lower_do1 - upper_do0\n    nat_max = upper_do1 - lower_do0\n    \n    return nat_min, nat_max"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-04/index.html#strong-iv-scenario",
    "href": "posts/lecture/L08/causal-inference-08-part-04/index.html#strong-iv-scenario",
    "title": "[Causal Inference] 08. Partial Identification (Part 4)",
    "section": "7.1 Strong IV Scenario",
    "text": "7.1 Strong IV Scenario\n\n첫 번째는 Strong IV 상황입니다.\nComplier의 비율이 약 80%로 매우 높고, Never-taker나 Defier의 비율이 낮습니다.\n즉, 의사의 처방(Z)이 실제 복용 여부(X)를 매우 강력하게 결정합니다.\n\n\n\nCode\n# 1. Data Generation\nprobs = np.array([\n    # Ry=0(Never) Ry=1(Helped) Ry=2(Hurt) Ry=3(Always)\n    # -------------------------------------------------------\n    [0.05,        0.05,        0.00,      0.00],   # Never-taker (Rx=0)\n    [0.10,        0.60,        0.05,      0.05],   # Complier (Rx=1)\n    [0.00,        0.00,        0.00,      0.00],   # Defier (Rx=2)\n    [0.05,        0.05,        0.00,      0.00]    # Always-taker (Rx=3)\n])\n\ndf, true_ate, probs = generate_class_scenario_data(probs) \n\n# 2. Point Estimate\npoint_est = point_estimate(df)\n\n# 3. Interval Estimate (LP)\nlp_min, lp_max = lp_bounds(df)\n\n# 4. Natural Bounds\nnat_min, nat_max = calculate_natural_bounds_iv(df)\nmanski_min, manski_max = calculate_natural_bounds(df)\n\n# 5. Visualization\ncompare_and_visualize(\n    df=df, \n    true_ate=true_ate, \n    point_est=point_est, \n    lp_bounds=(lp_min, lp_max), \n    nat_bounds=(nat_min, nat_max), \n    manski_bounds=(manski_min, manski_max),\n    probs_matrix=probs\n)\n\n\n\n\n\n\n\n\n\nTrue ATE      : 0.6500\nDoWhy Estimate: 0.6853\n------------------------------\n1. Pure Manski (No Z) : [-0.1769, 0.8231] (Width: 1.0000)\n2. IV Natural (With Z) : [0.4991, 0.6972] (Width: 0.1981)\n3. Balke-Pearl (LP)   : [0.4991, 0.6972] (Width: 0.1981)\n\n\n\n해석\n\nComplier 비중: 약 80%로, 도구변수 \\(Z\\)가 \\(X\\)를 강력하게 설명합니다.\nLP Bounds: 너비가 약 0.20으로 매우 좁게 형성되었습니다. 이는 관측 데이터만으로도 True ATE의 범위를 상당히 좁힐 수 있음을 의미합니다.\nEstimates: Point Estimate (LATE)가 True ATE에 매우 근접해 있습니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-04/index.html#weak-iv-scenario",
    "href": "posts/lecture/L08/causal-inference-08-part-04/index.html#weak-iv-scenario",
    "title": "[Causal Inference] 08. Partial Identification (Part 4)",
    "section": "7.2 Weak IV Scenario",
    "text": "7.2 Weak IV Scenario\n\n두 번째는 Weak IV 상황입니다.\nComplier의 비율이 5%로 극히 낮고, Never-taker(약 35%)와 Always-taker(약 40%)의 비율이 매우 높습니다.\n즉, 의사가 처방을 하든 말든(Z), 사람들은 대부분 자기 맘대로 행동하므로 도구변수가 무력합니다.\n\n\n\nCode\n# 1. Data Generation\nprobs = np.array([\n    # Ry=0(Never) Ry=1(Helped) Ry=2(Hurt) Ry=3(Always)\n    # -------------------------------------------------------\n    [0.10,        0.10,        0.05,      0.10],   # Never-taker (Rx=0)\n    [0.01,        0.02,        0.01,      0.01],   # Complier (Rx=1)\n    [0.05,        0.05,        0.05,      0.05],   # Defier (Rx=2)\n    [0.10,        0.10,        0.10,      0.10]    # Always-taker (Rx=3)\n])\n\ndf, true_ate, probs = generate_class_scenario_data(probs) \n\n# 2. Point Estimate\npoint_est = point_estimate(df)\n\n# 3. Interval Estimate (LP)\nlp_min, lp_max = lp_bounds(df)\n\n# 4. Natural Bounds\nnat_min, nat_max = calculate_natural_bounds_iv(df)\nmanski_min, manski_max = calculate_natural_bounds(df)\n\n# 5. Visualization\ncompare_and_visualize(\n    df=df, \n    true_ate=true_ate, \n    point_est=point_est, \n    lp_bounds=(lp_min, lp_max), \n    nat_bounds=(nat_min, nat_max), \n    manski_bounds=(manski_min, manski_max),\n    probs_matrix=probs\n)\n\n\n\n\n\n\n\n\n\nTrue ATE      : 0.0600\nDoWhy Estimate: -0.1393\n------------------------------\n1. Pure Manski (No Z) : [-0.4769, 0.5231] (Width: 1.0000)\n2. IV Natural (With Z) : [-0.4082, 0.4322] (Width: 0.8404)\n3. Balke-Pearl (LP)   : [-0.4082, 0.4322] (Width: 0.8404)\n\n\n\n해석\n\nComplier 비중: 5%에 불과하여 \\(Z\\)와 \\(X\\)의 상관관계가 매우 약합니다.\nLP Bounds: 너비가 0.84로 매우 넓습니다. 이는 1.0(전체 가능한 범위)에 가까운 수치로, 도구변수 가정을 도입했음에도 불구하고 ATE에 대해 “거의 아무것도 모르는 상태”와 다를 바 없습니다.\nEstimates: Point Estimate (LATE)가 True ATE와 큰 차이를 보이고, 부호가 다르다. 이는 분모(\\(E[X∣Z=1]−E[X∣Z=0]\\))가 0에 가까워지면서 추정량이 불안정해지기 때문입니다."
  },
  {
    "objectID": "posts/lecture/L06/part-02/index.html",
    "href": "posts/lecture/L06/part-02/index.html",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 2)",
    "section": "",
    "text": "이전 포스트들에서 우리는 Back-door와 Front-door 기준을 통해 특정 그래프 구조에서 인과 효과를 식별하는 방법을 배웠습니다. 하지만 모든 인과 모형이 이러한 표준적인 형태를 띠는 것은 아닙니다. 더욱 복잡한 그래프 구조에서 인과 효과 \\(P(y|do(x))\\)를 식별하기 위해서는 보다 일반화된 규칙이 필요합니다.\n이번 포스트에서는 Judea Pearl의 Do-Calculus가 등장하게 된 배경과, 이를 구성하는 세 가지 핵심 통찰(Three Insights)에 대해 다룹니다. [cite_start]이는 인과적 질문(Query)을 관측 가능한 통계적 추정량(Estimand)으로 변환하는 체계적인(Systematic) 접근법의 기초가 됩니다[cite: 147]."
  },
  {
    "objectID": "posts/lecture/L06/part-02/index.html#the-problem-definition",
    "href": "posts/lecture/L06/part-02/index.html#the-problem-definition",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 2)",
    "section": "2.1. The Problem Definition",
    "text": "2.1. The Problem Definition\nBack-door와 Front-door 설정 모두에서 우리의 목표는 하나였습니다. [cite_start]바로 개입(Intervention)에 의한 확률 분포 \\(Q = P(y|do(x))\\)를 관측 데이터의 분포 \\(P(v)\\)만으로 계산 가능한 식(expression)으로 환원(reduce)하는 것입니다[cite: 152, 160]."
  },
  {
    "objectID": "posts/lecture/L06/part-02/index.html#two-approaches",
    "href": "posts/lecture/L06/part-02/index.html#two-approaches",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 2)",
    "section": "2.2. Two Approaches",
    "text": "2.2. Two Approaches\n이 목표를 달성하기 위한 방법은 크게 두 가지로 나뉩니다.\n\nAlgebraic Approach (Truncated Factorization): [cite_start]구조적 인과 모델(SCM)의 Truncated Factorization 공식을 사용하여, 잠재 변수 \\(U\\)가 포함되지 않은(U-free) 표현식을 유도하는 방법입니다[cite: 156, 161]. 이는 앞서 Back-door/Front-door 공식을 유도할 때 사용했던 방식입니다.\nAxiomatic Approach (Do-Calculus): [cite_start]잠재 변수 \\(U\\)를 직접 다루거나 매번 적분을 수행하는 대신, \\(do(\\cdot)\\) 연산자를 포함한 식을 \\(do(\\cdot)\\)가 없는 식(do-free expression)으로 변환하는 일련의 규칙(rules) 또는 공리(axioms)를 사용하는 방법입니다[cite: 157, 162].\n\n[cite_start]우리는 이 두 번째 접근법, 즉 타겟 효과(Target Effect)와의 등가성을 유지하면서 \\(do\\) 표현식을 체계적으로 변환할 수 있는 규칙에 관심을 가질 것입니다[cite: 163]."
  },
  {
    "objectID": "posts/lecture/L06/part-02/index.html#submodel-mathcalh_x-and-graph-mathcalg_overlinex",
    "href": "posts/lecture/L06/part-02/index.html#submodel-mathcalh_x-and-graph-mathcalg_overlinex",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 2)",
    "section": "3.1. Submodel \\(\\mathcal{H}_x\\) and Graph \\(\\mathcal{G}_{\\overline{X}}\\)",
    "text": "3.1. Submodel \\(\\mathcal{H}_x\\) and Graph \\(\\mathcal{G}_{\\overline{X}}\\)\n[cite_start]\\(do(X=x)\\)라는 행위는 모델 내에서 \\(X\\)를 결정하는 구조적 함수 \\(f_X\\)를 상수 \\(x\\)로 대체하는 것을 의미합니다[cite: 189, 201]. \\[\nX \\leftarrow x\n\\] [cite_start]이를 그래프 관점에서 보면, 변수 \\(X\\)가 더 이상 다른 변수(부모 변수)들의 영향을 받지 않음을 의미합니다[cite: 196, 202]. 따라서 원래 그래프 \\(\\mathcal{G}\\)에서 \\(X\\)로 들어오는 모든 화살표(incoming edges)를 제거한 그래프를 생각할 수 있으며, 이를 \\(\\mathcal{G}_{\\overline{X}}\\)라고 표기합니다.\n\n\n\nFigure 1: Submodel Graph \\(\\mathcal{G}_{\\overline{X}}\\). 점선 화살표는 원래 그래프 \\(\\mathcal{G}\\)에는 존재했으나, 개입 \\(do(X)\\)로 인해 \\(X\\)가 상수로 고정되면서 제거된 경로를 나타냅니다. \\(X\\)는 이제 외부 변수의 영향을 받지 않는 고립된 노드(부모가 없는 노드)처럼 행동합니다."
  },
  {
    "objectID": "posts/lecture/L06/part-02/index.html#independence-condition",
    "href": "posts/lecture/L06/part-02/index.html#independence-condition",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 2)",
    "section": "3.2. Independence Condition",
    "text": "3.2. Independence Condition\n개입된 세상 \\(\\mathcal{H}_x\\)에서의 조건부 독립성은 그래프 \\(\\mathcal{G}_{\\overline{X}}\\)에서의 d-separation으로 해석할 수 있습니다. [cite_start]특히, \\(X\\)는 이제 상수 \\(x\\)로 고정되었으므로, 이는 \\(\\mathcal{G}_{\\overline{X}}\\)에서 \\(X=x\\)로 조건부(conditioning)를 건 것과 유사하게 동작합니다[cite: 203, 219].\n[cite_start]따라서, \\(do(x)\\) 하에서의 조건부 독립성 \\((A \\perp\\!\\!\\!\\perp B | C)\\)는 \\(\\mathcal{G}_{\\overline{X}}\\) 그래프상에서의 분리(separation)와 동치입니다[cite: 220, 221]."
  },
  {
    "objectID": "posts/lecture/L06/part-02/index.html#insight-1-addingremoving-observations",
    "href": "posts/lecture/L06/part-02/index.html#insight-1-addingremoving-observations",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 2)",
    "section": "4.1. Insight 1: Adding/Removing Observations",
    "text": "4.1. Insight 1: Adding/Removing Observations\n첫 번째 통찰은 “언제 관측 변수 \\(Z\\)를 무시해도 되는가?”에 대한 것입니다.\n[cite_start]원래 모델에서는 \\(Z\\)와 \\(Y\\)가 서로 연관되어 있어 분리할 수 없다고 가정해 봅시다(예: \\(Z \\not\\perp\\!\\!\\!\\perp Y | X\\))[cite: 226]. [cite_start]하지만 \\(X\\)에 개입을 가한 \\(do(X)\\) 세상(즉, \\(\\mathcal{G}_{\\overline{X}}\\))에서 \\(Y\\)와 \\(Z\\)가 \\(X\\)에 의해 d-separated 된다면, \\(Z\\)를 관측하는 것은 \\(Y\\)의 확률 분포에 아무런 추가 정보를 주지 않습니다[cite: 228, 229].\n\nThe Rule\n\\[\n(Y \\perp\\!\\!\\!\\perp Z | X)_{\\mathcal{G}_{\\overline{X}}} \\implies P(y|do(x), z) = P(y|do(x))\n\\] 즉, 개입된 그래프 \\(\\mathcal{G}_{\\overline{X}}\\)에서 조건부 독립이 성립하면, \\(do(x)\\) 식에서 조건절의 \\(z\\)를 제거할 수 있습니다.\n\n\n\nFigure 2: Insight 1 Graph Structure. \\(X\\)에 개입하여 \\(X\\)로 들어오는 화살표가 제거된 상황(\\(\\mathcal{G}_{\\overline{X}}\\))입니다. 이 그래프에서 \\(X\\)가 주어졌을 때 \\(Z\\)와 \\(Y\\) 사이의 모든 경로가 차단된다면(d-separated), \\(Z\\)는 \\(Y\\)에 대한 추가적인 정보를 제공하지 않습니다.\n\n\n\n\nDerivation\nTruncated Factorization을 이용해 이를 증명할 수 있습니다. 개입 분포 \\(P(y,z|do(x))\\)는 다음과 같이 주어집니다. \\[\nP(y,z|do(x)) = \\sum_{u} P(z|u_z) P(y|x, u_y, u') P(u) = P(z) \\sum_{u'} P(y|x, u') P(u')\n\\] [cite_start][cite: 240]\n이때 조건부 확률의 정의에 따라: \\[\nP(y|do(x), z) = \\frac{P(y,z|do(x))}{P(z|do(x))}\n\\] [cite_start]분모인 \\(P(z|do(x))\\)를 계산해보면 \\(P(z)\\)가 나옵니다(모든 \\(y\\)에 대해 합을 취함)[cite: 252]. \\[\nP(z|do(x)) = \\sum_{y} P(z) \\sum_{u'} P(y|x, u') P(u') = P(z) \\cdot 1 = P(z)\n\\] [cite_start]따라서 분자와 분모의 \\(P(z)\\)가 약분되어 다음을 얻습니다[cite: 263]. \\[\nP(y|do(x), z) = \\sum_{u'} P(y|x, u') P(u') = P(y|do(x))\n\\]"
  },
  {
    "objectID": "posts/lecture/L06/part-02/index.html#insight-2-actionobservation-exchange",
    "href": "posts/lecture/L06/part-02/index.html#insight-2-actionobservation-exchange",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 2)",
    "section": "4.2. Insight 2: Action/Observation Exchange",
    "text": "4.2. Insight 2: Action/Observation Exchange\n두 번째 통찰은 “언제 개입(Action)을 단순 관측(Observation)으로 바꿀 수 있는가?”입니다. [cite_start]이는 Back-door 기준의 핵심 논리와 맞닿아 있습니다[cite: 273, 286].\n[cite_start]만약 \\(Z\\)를 관측한 상태에서, \\(X\\)가 \\(Y\\)에 미치는 영향이 오직 인과적 경로(causal paths)를 통해서만 전달되고 교란 요인(confounders)에 의한 영향이 없다면, \\(see(X=x)\\)는 \\(do(X=x)\\)와 동일한 효과를 갖습니다[cite: 284, 285].\n\nThe Rule\n[cite_start]이 조건은 그래프 \\(\\mathcal{G}_{\\underline{X}}\\) (X에서 나가는 화살표를 제거한 그래프)에서 확인합니다[cite: 288, 308]. \\[\n(Y \\perp\\!\\!\\!\\perp X | Z)_{\\mathcal{G}_{\\underline{X}}} \\implies P(y|do(x), z) = P(y|x, z)\n\\] [cite_start]이것이 성립하면 \\(do(x)\\)를 일반 조건부 확률 \\(x\\)로 바꿀 수 있습니다 (Exchange of Action & Observation)[cite: 294, 295].\n\n\n\nFigure 3: Insight 2 Graph Structure (\\(\\mathcal{G}_{\\underline{X}}\\)). \\(X\\)에서 \\(Y\\)로 가는 직접적인 인과 경로(outgoing edge)를 제거한 그래프입니다. 이 상태에서 \\(Z\\)를 조건부로 했을 때 \\(X\\)와 \\(Y\\)가 독립이라면(d-separated), \\(X\\)와 \\(Y\\) 사이의 Back-door path가 모두 차단된 것입니다.\n\n\n\n\nDerivation\nBack-door adjustment가 성립하는 구조(\\(Z\\)가 Back-door path를 차단)를 가정합니다. \\[\nP(y, z|do(x)) = \\sum_{u} P(z|u_z) P(y|x, z, u_y) P(u) = P(z) P(y|x, z)\n\\] [cite_start][cite: 297] [cite_start]마찬가지로 \\(P(z|do(x)) = P(z)\\)입니다[cite: 305, 306]. 따라서 비율을 계산하면: \\[\nP(y|do(x), z) = \\frac{P(z)P(y|x, z)}{P(z)} = P(y|x, z)\n\\] [cite_start][cite: 307]."
  },
  {
    "objectID": "posts/lecture/L06/part-02/index.html#insight-3-addingremoving-actions",
    "href": "posts/lecture/L06/part-02/index.html#insight-3-addingremoving-actions",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 2)",
    "section": "4.3. Insight 3: Adding/Removing Actions",
    "text": "4.3. Insight 3: Adding/Removing Actions\n세 번째 통찰은 “언제 개입(Action) 자체가 결과에 아무런 영향을 주지 않아 무시할 수 있는가?”입니다.\n[cite_start]매우 직관적인 사실은, 만약 \\(X\\)에서 \\(Z\\)로 가는 인과적 경로(causal path)가 전혀 없다면, \\(X\\)에 어떤 개입을 하더라도 \\(Z\\)의 분포는 변하지 않는다는 것입니다[cite: 311].\n\nThe Rule\n\\[\n(Z \\perp\\!\\!\\!\\perp X)_{\\mathcal{G}_{\\overline{X}}} \\implies P(z|do(x)) = P(z)\n\\] [cite_start]개입된 그래프 \\(\\mathcal{G}_{\\overline{X}}\\)에서 \\(X\\)와 \\(Z\\)가 독립이라면(즉, 연결된 경로가 없다면), \\(do(x)\\)라는 행위 자체를 식에서 제거할 수 있습니다[cite: 319, 321].\n\n\n\nFigure 4: Insight 3 Graph Structure. \\(X\\)와 \\(Z\\) 사이에 인과적 연결이 없는 상황을 묘사합니다. \\(\\mathcal{G}_{\\overline{X}}\\)에서 \\(X\\)에서 \\(Z\\)로 가는 경로가 없다면, \\(X\\)에 대한 조작은 \\(Z\\)의 분포에 영향을 미치지 않습니다.\n\n\n\n\nDerivation\n개입 분포 \\(P(z|do(x))\\)를 주변화(marginalization)를 통해 전개하면: \\[\nP(z|do(x)) = \\sum_{y} \\sum_{u} P(z|u_{zy}, u_{zx}) P(y|x, u_{zy}) P(u)\n\\] [cite_start]여기서 \\(Z\\)의 결정 식에는 \\(x\\)가 관여하지 않으므로, \\(u\\)에 대한 합을 정리하면 \\(P(z)\\)가 그대로 유도됩니다[cite: 332]. \\[\n= \\sum_{u} P(z|u) P(u) = P(z)\n\\] (상세 유도 과정에서 \\(y\\)와 관련된 항들은 합쳐져서 1이 됩니다)."
  },
  {
    "objectID": "posts/lecture/L06/part-03/index.html",
    "href": "posts/lecture/L06/part-03/index.html",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 3)",
    "section": "",
    "text": "이전 포스트에서 우리는 Do-Calculus의 직관적인 배경인 ’Three Insights’를 살펴보았습니다. 이번 포스트에서는 이를 일반화하여 Judea Pearl(1995)이 정립한 Do-Calculus의 3가지 공식 규칙을 정의하고, 이를 통해 인과 효과를 식별하는 과정을 단계별로 유도해 보겠습니다. [cite_start]또한, 모든 인과 효과가 식별 가능한 것은 아니며, 특정 그래프 구조(예: Bow-arc)에서는 식별이 불가능하다는 이론적 한계에 대해서도 다룹니다[cite: 334, 340].\n우리의 최종적인 구문론적 목표(Syntactical Goal)는 여전히 동일합니다. \\[Q = P(y|do(x))\\] [cite_start]위 식을 확률 공리(Probability Axioms)와 Do-Calculus 규칙을 적용하여, \\(do(\\cdot)\\) 연산자가 없는(do-free) 표현식으로 변환하는 것입니다[cite: 577, 578]."
  },
  {
    "objectID": "posts/lecture/L06/part-03/index.html#rule-1-addingremoving-observations",
    "href": "posts/lecture/L06/part-03/index.html#rule-1-addingremoving-observations",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 3)",
    "section": "Rule 1: Adding/Removing Observations",
    "text": "Rule 1: Adding/Removing Observations\n관측 변수 \\(Z\\)가 개입된 그래프에서 \\(Y\\)와 독립이라면, 조건부 확률에서 \\(Z\\)를 제거하거나 추가할 수 있습니다.\n\\[P(y|do(x), z, w) = P(y|do(x), w)\\]\n\n[cite_start]조건: \\((Y \\perp\\!\\!\\!\\perp Z | X, W)_{\\mathcal{G}_{\\overline{X}}}\\) [cite: 373, 378]\n해석: \\(X\\)에 개입하여 \\(X\\)로 들어오는 화살표가 제거된 그래프(\\(\\mathcal{G}_{\\overline{X}}\\))에서, \\(W\\)가 주어졌을 때 \\(Y\\)와 \\(Z\\)가 d-separated 되어 있다면 \\(Z\\)는 \\(Y\\)에 대한 추가 정보를 제공하지 않습니다."
  },
  {
    "objectID": "posts/lecture/L06/part-03/index.html#rule-2-actionobservation-exchange",
    "href": "posts/lecture/L06/part-03/index.html#rule-2-actionobservation-exchange",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 3)",
    "section": "Rule 2: Action/Observation Exchange",
    "text": "Rule 2: Action/Observation Exchange\n특정 조건하에서 개입(Action) \\(do(z)\\)를 단순 관측(Observation) \\(z\\)로 교체하거나 그 반대로 바꿀 수 있습니다.\n\\[P(y|do(x), do(z), w) = P(y|do(x), z, w)\\]\n\n[cite_start]조건: \\((Y \\perp\\!\\!\\!\\perp Z | X, W)_{\\mathcal{G}_{\\overline{X}\\underline{Z}}}\\) [cite: 375, 379]\n해석: 그래프 \\(\\mathcal{G}_{\\overline{X}\\underline{Z}}\\)는 \\(X\\)로 들어오는 화살표를 제거하고(\\(\\overline{X}\\)), \\(Z\\)에서 나가는 화살표를 제거한(\\(\\underline{Z}\\)) 그래프입니다. 이 구조에서 \\(Y\\)와 \\(Z\\)가 독립이라면, \\(Z\\)가 \\(Y\\)에 미치는 영향은 오직 \\(Z\\)의 부모를 통한 Back-door path뿐이므로, Back-door criterion에 의해 \\(do(z)\\)와 \\(z\\)가 등가입니다."
  },
  {
    "objectID": "posts/lecture/L06/part-03/index.html#rule-3-addingremoving-actions",
    "href": "posts/lecture/L06/part-03/index.html#rule-3-addingremoving-actions",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 3)",
    "section": "Rule 3: Adding/Removing Actions",
    "text": "Rule 3: Adding/Removing Actions\n개입 \\(do(z)\\)가 \\(Y\\)의 확률 분포에 아무런 영향을 주지 않는다면, 식에서 \\(do(z)\\)를 제거할 수 있습니다.\n\\[P(y|do(x), do(z), w) = P(y|do(x), w)\\]\n\n[cite_start]조건: \\((Y \\perp\\!\\!\\!\\perp Z | X, W)_{\\mathcal{G}_{\\overline{X}\\overline{Z(W)}}}\\) [cite: 377, 380]\n해석: 여기서 \\(Z(W)\\)는 \\(Z\\)의 노드 중 \\(W\\)의 조상(Ancestor)이 아닌 노드들의 집합입니다. 해당 그래프에서 \\(Y\\)와 \\(Z\\)가 독립이라면, \\(Z\\)에 대한 개입은 \\(Y\\)에 인과적 영향을 주지 않습니다."
  },
  {
    "objectID": "posts/lecture/L06/part-03/index.html#logic-of-rule-2-regime-indicator",
    "href": "posts/lecture/L06/part-03/index.html#logic-of-rule-2-regime-indicator",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 3)",
    "section": "3.1. Logic of Rule 2 (Regime Indicator)",
    "text": "3.1. Logic of Rule 2 (Regime Indicator)\nRule 2는 근본적으로 “우리가 보는 것(Seeing)”과 “우리가 하는 것(Doing)”이 언제 같은지를 묻습니다. [cite_start]이를 이해하기 위해 \\(Z\\)의 상태를 결정하는 Regime Indicator \\(F_Z\\)를 도입할 수 있습니다[cite: 404, 418].\n\n\\(F_Z = 0\\): 자연스러운 관측 모드 (\\(Z \\leftarrow f_Z(W, U_Z)\\))\n\\(F_Z = 1\\): 개입 모드 (\\(Z \\leftarrow z\\))\n\n[cite_start]Rule 2가 성립한다는 것은 \\(F_Z\\)의 값이 0이든 1이든 \\(Y\\)의 분포가 변하지 않는다는 뜻입니다[cite: 473]. \\[P(y|z, w, F_Z=1) = P(y|z, w, F_Z=0)\\] 이는 그래프상에서 \\(F_Z\\)와 \\(Y\\)가 조건부 독립 \\((F_Z \\perp\\!\\!\\!\\perp Y | Z, W)\\)임을 의미합니다. \\(Z\\)가 조건부로 주어졌으므로 \\(Z\\)를 통과하는 경로는 차단되고, 남은 것은 \\(Z\\)로 들어오는 Back-door path뿐입니다. [cite_start]따라서 Rule 2는 본질적으로 \\(Z\\)에 대한 Back-door path가 차단되었는지를 확인하는 것입니다[cite: 497].\n\n\n\nFigure 1: Rule 2와 Regime Indicator. \\(F_Z\\) 노드는 \\(Z\\)가 관측(idle) 상태인지 개입(do) 상태인지를 결정합니다. \\(Z\\)와 \\(W\\)가 주어졌을 때 \\(F_Z\\)에서 \\(Y\\)로 가는 경로가 없다면(d-separated), 개입 여부는 결과 \\(Y\\)에 영향을 주지 않습니다."
  },
  {
    "objectID": "posts/lecture/L06/part-03/index.html#logic-of-rule-3-zw-and-ancestry",
    "href": "posts/lecture/L06/part-03/index.html#logic-of-rule-3-zw-and-ancestry",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 3)",
    "section": "3.2. Logic of Rule 3 (\\(Z(W)\\) and Ancestry)",
    "text": "3.2. Logic of Rule 3 (\\(Z(W)\\) and Ancestry)\nRule 3에서 \\(Z(W)\\)라는 복잡한 표기법을 사용하는 이유는 무엇일까요? 우리가 \\(W\\)를 조건부로 하고 있을 때, \\(Z\\)가 \\(W\\)의 조상(Ancestor)이라면 \\(Z\\)에 개입하는 것이 \\(W\\)의 분포를 바꾸고, 이것이 다시 \\(Y\\)에 영향을 줄 수 있기 때문입니다.\n\n만약 \\(Z\\)가 \\(W\\)의 조상이 아니라면(\\(Z \\notin An(W)\\)), \\(Z\\)에 개입해도 \\(W\\)는 변하지 않습니다. 따라서 \\(Z \\to Y\\) 경로만 없다면 개입을 제거할 수 있습니다.\n만약 \\(Z\\)가 \\(W\\)의 조상이라면, \\(Z\\)에 대한 개입은 \\(W\\)를 변화시키므로 함부로 제거할 수 없습니다.\n\n[cite_start]따라서 Rule 3은 \\(Z\\)가 \\(Y\\)에 미치는 직접적인 효과가 없을 뿐만 아니라, \\(W\\)를 통해 간접적으로 미치는 효과도 통제되었을 때만 적용 가능합니다[cite: 541, 546]."
  },
  {
    "objectID": "posts/lecture/L06/part-03/index.html#the-fair-coin-counter-example",
    "href": "posts/lecture/L06/part-03/index.html#the-fair-coin-counter-example",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 3)",
    "section": "5.1. The “Fair Coin” Counter-example",
    "text": "5.1. The “Fair Coin” Counter-example\n[cite_start]동일한 관측 분포 \\(P(v)\\)를 가지지만, 서로 다른 개입 분포 \\(P(y|do(x))\\)를 갖는 두 모델이 존재한다면, 해당 인과 효과는 식별 불가능합니다[cite: 616].\n\nModel 1: \\(X \\leftarrow U, Y \\leftarrow f_Y(X, U)\\)\nModel 2: \\(X \\leftarrow U\\), \\(Y\\)는 \\(X=U\\)일 때만 \\(f_Y\\)를 따르고 그 외엔 상수 출력.\n\n관측 데이터상에서는 항상 \\(X=U\\)이므로 두 모델을 구별할 수 없습니다(\\(P^{(1)}(v) = P^{(2)}(v)\\)). [cite_start]하지만 \\(do(X=x)\\)로 개입하면 \\(X \\neq U\\)인 상황이 발생하고, 이때 두 모델은 서로 다른 \\(Y\\) 값을 출력합니다(\\(P^{(1)}(y|do(x)) \\neq P^{(2)}(y|do(x))\\))[cite: 626, 641]. 이는 데이터만으로는 인과 구조를 완벽히 파악할 수 없음을 시사합니다."
  },
  {
    "objectID": "posts/lecture/L06/part-03/index.html#graphical-criterion-tian-and-pearl-2002",
    "href": "posts/lecture/L06/part-03/index.html#graphical-criterion-tian-and-pearl-2002",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 3)",
    "section": "5.2. Graphical Criterion (Tian and Pearl, 2002)",
    "text": "5.2. Graphical Criterion (Tian and Pearl, 2002)\n그래프 구조만 보고 식별 불가능성을 판단할 수 있는 기준이 있습니다.\nTheorem (Bow-arc Criterion): [cite_start]그래프 \\(\\mathcal{G}\\)에서 \\(X\\)와 그 자식 노드(children) 중 하나 사이에 양방향 화살표(bidirected edge, 점선)가 존재한다면, 즉 \\(X \\leftrightarrow \\dots \\leftrightarrow Y\\) 형태의 교란 경로가 존재하고 직접 경로 \\(X \\to Y\\)가 있다면, \\(P(v'|do(x))\\)는 식별 불가능합니다[cite: 650].\n이러한 구조를 Bow-arc Graph라고 부릅니다. 활(Bow) 모양처럼 직접 경로와 교란 경로가 동시에 존재하기 때문입니다.\n\n\n\nFigure 3: 식별 불가능한 그래프 패턴들. (a)와 같은 Bow-arc 구조(X에서 Y로 가는 화살표와 점선 양방향 화살표가 병존)가 가장 대표적인 식별 불가능 패턴입니다. 이 경우 Do-Calculus를 아무리 적용해도 do 연산자를 제거할 수 없습니다."
  },
  {
    "objectID": "posts/lecture/L01/index.html",
    "href": "posts/lecture/L01/index.html",
    "title": "[Causal Inference] 01. Introduction",
    "section": "",
    "text": "통계학 수업을 들었다면 누구나 한 번쯤 들어봤을 문장입니다.\n하지만 실제 데이터 분석에서 우리는 이 함정에 너무나 쉽게 빠집니다.\n재미있는 예시들을 살펴봅시다.\n\n\n\n\n미국 내 자폐증(Autism) 진단 수와 유기농 식품 판매량의 추이를 그린 그래프입니다.\n\n\n\n\nAutism vs Organic Food Sales\n\n\n\n두 변수의 상관계수(\\(r\\))는 무려 0.9971입니다.\n그렇다면 유기농 식품이 자폐증의 원인일까요? 당연히 아닙니다. 단순히 시간이 흐르며 두 지표가 같이 상승했을 뿐입니다.\n이를 허위 상관(Spurious Correlation)이라고 합니다.\n\n\n\n\n\n데이터를 보면 투입된 소방관의 수(\\(X\\))와 화재의 크기(\\(Y\\))는 아주 강한 양의 상관관계를 가집니다.\n\n\\[Y = \\beta X + \\beta_0\\]\n\n단순 회귀분석을 돌리면 \\(\\beta\\)(기울기)는 양수가 나옵니다.\n그렇다면 화재 피해를 줄이기 위해 소방관을 줄여야 할까요?\n상식적으로 말이 안 됩니다. 사실은 화재가 크기 때문에(Cause) 소방관이 많이 출동한 것(Effect)이거나, 건물의 크기 같은 제3의 요인이 작용했을 것입니다.\n데이터(\\(X, Y\\))만 봐서는 이 인과의 방향을 알 수 없습니다."
  },
  {
    "objectID": "posts/lecture/L01/index.html#자폐증과-유기농-식품-판매량",
    "href": "posts/lecture/L01/index.html#자폐증과-유기농-식품-판매량",
    "title": "[Causal Inference] 01. Introduction",
    "section": "",
    "text": "미국 내 자폐증(Autism) 진단 수와 유기농 식품 판매량의 추이를 그린 그래프입니다.\n\n\n\n\nAutism vs Organic Food Sales\n\n\n\n두 변수의 상관계수(\\(r\\))는 무려 0.9971입니다.\n그렇다면 유기농 식품이 자폐증의 원인일까요? 당연히 아닙니다. 단순히 시간이 흐르며 두 지표가 같이 상승했을 뿐입니다.\n이를 허위 상관(Spurious Correlation)이라고 합니다."
  },
  {
    "objectID": "posts/lecture/L01/index.html#소방관이-많으면-불이-커진다",
    "href": "posts/lecture/L01/index.html#소방관이-많으면-불이-커진다",
    "title": "[Causal Inference] 01. Introduction",
    "section": "",
    "text": "데이터를 보면 투입된 소방관의 수(\\(X\\))와 화재의 크기(\\(Y\\))는 아주 강한 양의 상관관계를 가집니다.\n\n\\[Y = \\beta X + \\beta_0\\]\n\n단순 회귀분석을 돌리면 \\(\\beta\\)(기울기)는 양수가 나옵니다.\n그렇다면 화재 피해를 줄이기 위해 소방관을 줄여야 할까요?\n상식적으로 말이 안 됩니다. 사실은 화재가 크기 때문에(Cause) 소방관이 많이 출동한 것(Effect)이거나, 건물의 크기 같은 제3의 요인이 작용했을 것입니다.\n데이터(\\(X, Y\\))만 봐서는 이 인과의 방향을 알 수 없습니다."
  },
  {
    "objectID": "posts/lecture/L01/index.html#상황-1-전체-데이터-total",
    "href": "posts/lecture/L01/index.html#상황-1-전체-데이터-total",
    "title": "[Causal Inference] 01. Introduction",
    "section": "상황 1: 전체 데이터 (Total)",
    "text": "상황 1: 전체 데이터 (Total)\n\n\n\n\n회복(Y)\n미회복(\\(\\neg Y\\))\n회복률(Rate)\n\n\n\n\n약 복용 (Drug)\n20\n20\n50%\n\n\n미복용 (No Drug)\n16\n24\n40%\n\n\n\n\n전체로 보면 약을 먹었을 때 회복률이 더 높습니다(50% &gt; 40%).\n의사는 약을 처방해야 할 것 같습니다."
  },
  {
    "objectID": "posts/lecture/L01/index.html#상황-2-성별로-나누어-본-데이터-stratified-by-sex",
    "href": "posts/lecture/L01/index.html#상황-2-성별로-나누어-본-데이터-stratified-by-sex",
    "title": "[Causal Inference] 01. Introduction",
    "section": "상황 2: 성별로 나누어 본 데이터 (Stratified by Sex)",
    "text": "상황 2: 성별로 나누어 본 데이터 (Stratified by Sex)\n\n하지만 남성과 여성으로 데이터를 쪼개서 보면 이야기가 달라집니다.\n\n남성 (Male): 약 복용(60%) &lt; 미복용(70%)\n여성 (Female): 약 복용(20%) &lt; 미복용(30%)\n\n남성 그룹에서도, 여성 그룹에서도 약을 안 먹는 게 회복률이 더 높습니다. & 전체 데이터에서는 약이 좋다고 하는데, 쪼개보니 약이 나쁘다고 합니다.\n도대체 의사는 어떤 테이블을 믿어야 할까요?"
  },
  {
    "objectID": "posts/lecture/L01/index.html#결론-인과-그래프causal-graph가-필요하다",
    "href": "posts/lecture/L01/index.html#결론-인과-그래프causal-graph가-필요하다",
    "title": "[Causal Inference] 01. Introduction",
    "section": "결론: 인과 그래프(Causal Graph)가 필요하다",
    "text": "결론: 인과 그래프(Causal Graph)가 필요하다\n\n정답은 “데이터만으로는 알 수 없다”입니다.\n성별(\\(F\\)), 약 복용(\\(X\\)), 회복(\\(Y\\)) 사이의 인과 구조가 어떻게 그려지느냐에 따라 우리가 봐야 할 테이블이 달라집니다.\n이것이 바로 우리가 단순히 데이터(\\(P(Y|X)\\))를 보는 것을 넘어, 인과 구조(Structure)를 고민해야 하는 이유입니다."
  },
  {
    "objectID": "posts/lecture/L01/index.html#level-1-관찰-association-seeing",
    "href": "posts/lecture/L01/index.html#level-1-관찰-association-seeing",
    "title": "[Causal Inference] 01. Introduction",
    "section": "Level 1: 관찰 (Association / Seeing)",
    "text": "Level 1: 관찰 (Association / Seeing)\n\n질문: “What is?” (만약 \\(X\\)를 본다면, \\(Y\\)는 어떨까?)\n수식: \\(P(y|x)\\)\n특징: 기존의 머신러닝(Deep Learning, Decision Tree 등)이 가장 잘하는 영역입니다. 데이터의 상관성을 파악합니다."
  },
  {
    "objectID": "posts/lecture/L01/index.html#level-2-개입-intervention-doing",
    "href": "posts/lecture/L01/index.html#level-2-개입-intervention-doing",
    "title": "[Causal Inference] 01. Introduction",
    "section": "Level 2: 개입 (Intervention / Doing)",
    "text": "Level 2: 개입 (Intervention / Doing)\n\n질문: “What if I do?” (만약 내가 \\(X\\)를 강제로 시킨다면, \\(Y\\)는 어떻게 될까?)\n수식: \\(P(y | do(x))\\)\n특징: 여기서부터 진짜 인과추론의 영역입니다. 단순히 \\(X\\)를 관찰하는 것(\\(x\\))과, 실험자가 개입하여 값을 바꾸는 것(\\(do(x)\\))은 다릅니다. 강화학습(RL)이나 A/B 테스트가 여기에 속합니다."
  },
  {
    "objectID": "posts/lecture/L01/index.html#level-3-반사실-counterfactuals-imagining",
    "href": "posts/lecture/L01/index.html#level-3-반사실-counterfactuals-imagining",
    "title": "[Causal Inference] 01. Introduction",
    "section": "Level 3: 반사실 (Counterfactuals / Imagining)",
    "text": "Level 3: 반사실 (Counterfactuals / Imagining)\n\n질문: “What if I had acted differently?” (그때 내가 다른 선택을 했더라면, 결과는 달라졌을까?)\n수식: \\(P(y_x | x', y')\\)\n특징: 이미 일어난 일(\\(x', y'\\))을 바탕으로, 일어나지 않은 가상의 세계(\\(y_x\\))를 추론합니다. 인간만이 가진 고도의 추론 능력인 회고(Retrospection)와 상상(Imagining)의 영역입니다."
  },
  {
    "objectID": "posts/lecture/L07/part-03/index.html",
    "href": "posts/lecture/L07/part-03/index.html",
    "title": "[Causal Inference] 07. An Algorithmic Approach to Identification (Part 3)",
    "section": "",
    "text": "이전 포스트들에서는 C-Factor (\\(Q[C]\\)) 의 개념을 도입하고, Back-door, Front-door, 그리고 Napkin 문제와 같은 구체적인 사례들을 통해 인과 효과를 식별하는 방법을 살펴보았습니다.\n하지만 현실의 인과 그래프는 교과서적인 예제보다 훨씬 복잡할 수 있습니다. 수십 개의 변수와 복잡하게 얽힌 교란 요인(Unobserved Confounder)이 존재하는 상황에서, 매번 직관이나 특수한 기법에 의존할 수는 없습니다.\n이번 포스트에서는 Shpitser and Pearl에 의해 정립된 일반화된 식별 알고리즘(General Identification Algorithm)을 다룹니다. 이 알고리즘은 임의의 인과 그래프 \\(G\\)와 쿼리 \\(P(y|do(x))\\)가 주어졌을 때, 해당 효과가 식별 가능한지(Identifiable) 판별하고, 가능하다면 관측 데이터 \\(P(v)\\)의 함수로 표현된 식을 도출해냅니다."
  },
  {
    "objectID": "posts/lecture/L07/part-03/index.html#ancestral-reduction",
    "href": "posts/lecture/L07/part-03/index.html#ancestral-reduction",
    "title": "[Causal Inference] 07. An Algorithmic Approach to Identification (Part 3)",
    "section": "2.1 Ancestral Reduction",
    "text": "2.1 Ancestral Reduction\n우리가 관심 있는 결과 변수 \\(Y\\)에 인과적인 영향을 줄 수 있는 변수들은 \\(Y\\)의 조상(Ancestors) 들뿐입니다. 따라서 전체 그래프 \\(G\\)에서 \\(Y\\)의 조상이 아닌 변수들은 인과 효과 계산에서 제거(Marginalize out)해도 무방합니다.\n\\[\nD = An(Y)_{G_{\\overline{X}}}\n\\]\n여기서 \\(G_{\\overline{X}}\\)는 \\(X\\)로 들어오는 엣지를 끊은 그래프(Intervention Graph)를 의미하며, \\(An(Y)\\)는 \\(Y\\) 자신을 포함한 \\(Y\\)의 조상 집합을 의미합니다. 즉, \\(D\\)는 \\(do(x)\\) 상황에서 \\(Y\\)와 인과적으로 연관된 모든 변수의 집합입니다."
  },
  {
    "objectID": "posts/lecture/L07/part-03/index.html#identification-formula-via-c-factors",
    "href": "posts/lecture/L07/part-03/index.html#identification-formula-via-c-factors",
    "title": "[Causal Inference] 07. An Algorithmic Approach to Identification (Part 3)",
    "section": "2.2 Identification Formula via C-Factors",
    "text": "2.2 Identification Formula via C-Factors\nC-Factor 이론에 따르면, 개입 후의 분포 \\(P(v|do(x))\\)는 \\(X\\)를 제외한 나머지 변수들의 메커니즘(\\(Q\\) 팩터)은 유지되고 \\(X\\)의 메커니즘만 제거된 상태입니다. 즉, 전체 변수 \\(V\\)에 대해 다음이 성립합니다.\n\\[\nP(v \\setminus x | do(x)) = Q[V \\setminus X]\n\\]\n따라서 우리가 구하고자 하는 \\(P(y|do(x))\\)는 \\(Q[V \\setminus X]\\)에서 \\(Y\\)를 제외한 나머지 변수들을 합(Summation)으로 제거하여 구할 수 있습니다.\n\\[\nP(y|do(x)) = \\sum_{v \\setminus (x \\cup y)} Q[V \\setminus X]\n\\]\n여기서 앞서 정의한 Ancestral Reduction을 적용하면, 합을 구해야 하는 범위가 전체 \\(V\\)에서 \\(D\\)(관심 있는 조상 집합)로 축소됩니다.\n\\[\nP(y|do(x)) = \\sum_{d \\setminus y} Q[D]\n\\]"
  },
  {
    "objectID": "posts/lecture/L07/part-03/index.html#step-1-ancestral-reduction-변수-범위-축소",
    "href": "posts/lecture/L07/part-03/index.html#step-1-ancestral-reduction-변수-범위-축소",
    "title": "[Causal Inference] 07. An Algorithmic Approach to Identification (Part 3)",
    "section": "Step 1: Ancestral Reduction (변수 범위 축소)",
    "text": "Step 1: Ancestral Reduction (변수 범위 축소)\n가장 먼저, 분석 대상을 \\(Y\\)의 조상 집합 \\(D\\)로 제한합니다. \\[\nD = An(Y)_{G_{\\overline{X}}}\n\\] 이 단계는 불필요한 변수를 제거하여 계산 복잡도를 줄이고 문제의 본질에 집중하게 합니다."
  },
  {
    "objectID": "posts/lecture/L07/part-03/index.html#step-2-c-component-decomposition-그래프-분해",
    "href": "posts/lecture/L07/part-03/index.html#step-2-c-component-decomposition-그래프-분해",
    "title": "[Causal Inference] 07. An Algorithmic Approach to Identification (Part 3)",
    "section": "Step 2: C-Component Decomposition (그래프 분해)",
    "text": "Step 2: C-Component Decomposition (그래프 분해)\n축소된 변수 집합 \\(D\\)로 구성된 서브그래프 \\(G[D]\\)를 고려합니다. 이 그래프 내에서 양방향 엣지(Bidirected edges, \\(\\leftrightarrow\\))로 연결된 요소들을 찾아 C-Component들로 분해합니다. 만약 \\(G[D]\\)가 \\(k\\)개의 C-Component \\(D_1, D_2, \\dots, D_k\\)로 나뉜다면, 전체 \\(Q\\) 팩터는 각 컴포넌트의 \\(Q\\) 팩터의 곱으로 표현됩니다.\n\\[\nQ[D] = \\prod_{i=1}^{k} Q[D_i]\n\\]\n이 성질은 Tian’s Factorization Lemma에 기반합니다."
  },
  {
    "objectID": "posts/lecture/L07/part-03/index.html#step-3-compute-target-quantity-최종-식별",
    "href": "posts/lecture/L07/part-03/index.html#step-3-compute-target-quantity-최종-식별",
    "title": "[Causal Inference] 07. An Algorithmic Approach to Identification (Part 3)",
    "section": "Step 3: Compute Target Quantity (최종 식별)",
    "text": "Step 3: Compute Target Quantity (최종 식별)\n위의 두 단계를 결합하면, 최종적인 인과 효과 \\(P(y|do(x))\\)는 각 C-Component (\\(D_i\\))에 해당하는 \\(Q[D_i]\\)들의 곱을 \\(Y\\)를 제외한 나머지 변수들(\\(D \\setminus Y\\))에 대해 합(Sum)한 것과 같습니다.\n\\[\nP(y|do(x)) = \\sum_{d \\setminus y} \\prod_{i=1}^{k} Q[D_i]\n\\]\n여기서 각 \\(Q[D_i]\\)는 관측 데이터 \\(P(v)\\)로부터 계산 가능(Computable)합니다. (Part 1에서 다룬 위상 정렬을 이용한 계산법 적용)"
  },
  {
    "objectID": "posts/lecture/L09/part-02/index.html",
    "href": "posts/lecture/L09/part-02/index.html",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 2)",
    "section": "",
    "text": "인과추론(Causal Inference)을 처음 공부할 때 가장 먼저 마주하는 충격적인 사실은 “우리가 배운 회귀분석(Regression)은 인과관계를 보장하지 않는다”는 점입니다. 데이터 사이언스나 통계학 수업에서 우리는 \\(X\\)가 \\(Y\\)에 미치는 영향을 알기 위해 회귀분석을 돌리고 \\(\\beta\\) 값을 해석하라고 배웁니다. 하지만 인과적 관점에서 이 접근은 심각한 오류를 범할 수 있습니다.\n강의 자료에 소개된 ’의학 연구자’의 예시를 통해 이 문제를 직관적으로 살펴보겠습니다.\n\n\n우리는 새로운 약물이 질병 치료에 도움이 되는지 확인하려는 연구자입니다. 데이터를 수집하여 약물 복용량(\\(X\\))과 혈액 내 바이오마커 수치(\\(Y\\), 높을수록 좋음) 사이의 관계를 시각화했습니다.\n\n\n\nFigure 1: 약물 복용량(X)과 바이오마커(Y)의 산점도. 언뜻 보기에 양의 상관관계를 보인다.\n\n\n데이터에 대해 단순 선형 회귀분석(\\(Y = \\beta X + e\\))을 수행한 결과, \\(\\beta = 0.375\\)라는 양의 계수를 얻었습니다. 즉, “약물을 많이 복용할수록 바이오마커 수치가 높아진다”고 결론 내리고 약물 사용을 승인합니다.\n그러나, 이 약물이 실제 환자들에게 투여되자 바이오마커 수치가 오히려 떨어지는 부정적인 결과가 나타납니다. 약물이 실제로 사람을 해치고 있었던 것입니다.\n\n\n\nFigure 2: 전체 모집단에 약물을 투여했을 때의 실제 인과 효과(녹색 선). 실제 기울기는 음수(-1)로, 약물은 해롭다. 붉은색 회귀선은 데이터의 편향을 반영한 잘못된 추정이다.\n\n\n\n\n왜 처음의 회귀분석은 양의 관계를 보여주었을까요? 이는 교란 요인(Confounder)을 고려하지 않았기 때문입니다. 예를 들어, 건강 상태가 나쁜 환자들이 생존을 위해 약물을 더 많이 복용했을 수 있고, 그들의 신체 특성이 바이오마커 수치와 관련이 있었을 수 있습니다.\n이 현상은 우리가 구한 회귀 계수(Regression Coefficient, \\(r_{yx}\\))와 실제 구조적 계수(Structural Coefficient, \\(\\lambda_{xy}\\))가 다르다는 것을 보여줍니다."
  },
  {
    "objectID": "posts/lecture/L09/part-02/index.html#the-medical-researcher-paradox",
    "href": "posts/lecture/L09/part-02/index.html#the-medical-researcher-paradox",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 2)",
    "section": "",
    "text": "우리는 새로운 약물이 질병 치료에 도움이 되는지 확인하려는 연구자입니다. 데이터를 수집하여 약물 복용량(\\(X\\))과 혈액 내 바이오마커 수치(\\(Y\\), 높을수록 좋음) 사이의 관계를 시각화했습니다.\n\n\n\nFigure 1: 약물 복용량(X)과 바이오마커(Y)의 산점도. 언뜻 보기에 양의 상관관계를 보인다.\n\n\n데이터에 대해 단순 선형 회귀분석(\\(Y = \\beta X + e\\))을 수행한 결과, \\(\\beta = 0.375\\)라는 양의 계수를 얻었습니다. 즉, “약물을 많이 복용할수록 바이오마커 수치가 높아진다”고 결론 내리고 약물 사용을 승인합니다.\n그러나, 이 약물이 실제 환자들에게 투여되자 바이오마커 수치가 오히려 떨어지는 부정적인 결과가 나타납니다. 약물이 실제로 사람을 해치고 있었던 것입니다.\n\n\n\nFigure 2: 전체 모집단에 약물을 투여했을 때의 실제 인과 효과(녹색 선). 실제 기울기는 음수(-1)로, 약물은 해롭다. 붉은색 회귀선은 데이터의 편향을 반영한 잘못된 추정이다.\n\n\n\n\n왜 처음의 회귀분석은 양의 관계를 보여주었을까요? 이는 교란 요인(Confounder)을 고려하지 않았기 때문입니다. 예를 들어, 건강 상태가 나쁜 환자들이 생존을 위해 약물을 더 많이 복용했을 수 있고, 그들의 신체 특성이 바이오마커 수치와 관련이 있었을 수 있습니다.\n이 현상은 우리가 구한 회귀 계수(Regression Coefficient, \\(r_{yx}\\))와 실제 구조적 계수(Structural Coefficient, \\(\\lambda_{xy}\\))가 다르다는 것을 보여줍니다."
  },
  {
    "objectID": "posts/lecture/L09/part-02/index.html#what-regression-computes",
    "href": "posts/lecture/L09/part-02/index.html#what-regression-computes",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 2)",
    "section": "2.1 What Regression Computes",
    "text": "2.1 What Regression Computes\n회귀분석은 오차의 제곱합(Mean Squared Error)을 최소화하는 기계적인 과정입니다. 단순 회귀식 \\(Y = \\beta X + e\\)에서 최소자승법(OLS)은 다음을 최소화합니다.\n\\[\n\\min_\\beta \\mathbb{E}[(Y - \\beta X)^2]\n\\]\n이를 \\(\\beta\\)에 대해 미분하고 0으로 두면 다음과 같은 결과를 얻습니다 (변수들이 중심화(centered)되어 있다고 가정할 때):\n\\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial \\beta} \\mathbb{E}[Y^2 - 2\\beta XY + \\beta^2 X^2] &= -2\\mathbb{E}[XY] + 2\\beta\\mathbb{E}[X^2] = 0 \\\\\n\\therefore \\beta &= \\frac{\\mathbb{E}[XY]}{\\mathbb{E}[X^2]} = \\frac{Cov(X, Y)}{Var(X)}\n\\end{aligned}\n\\]\n만약 변수들의 분산이 1로 정규화되어 있다면, \\(\\beta = \\mathbb{E}[XY] = \\sigma_{xy}\\)가 됩니다. 즉, 회귀 계수는 단순히 \\(X\\)와 \\(Y\\) 사이의 공분산(상관관계)일 뿐입니다. 여기에는 어떠한 인과적 방향성도 포함되어 있지 않습니다. 강의 자료에서는 이를 “Confusion of the Century”라고 부릅니다."
  },
  {
    "objectID": "posts/lecture/L09/part-02/index.html#the-structural-view-ground-truth",
    "href": "posts/lecture/L09/part-02/index.html#the-structural-view-ground-truth",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 2)",
    "section": "2.2 The Structural View (Ground-Truth)",
    "text": "2.2 The Structural View (Ground-Truth)\n반면, 구조적 인과 모형(SCM)은 변수 간의 생성 메커니즘을 정의합니다.\n\\[\nY \\leftarrow \\lambda_{xy} X + \\epsilon_y\n\\]\n여기서 \\(\\lambda_{xy}\\)는 \\(X\\)를 1단위 변화시켰을 때 \\(Y\\)가 변하는 인과적 효과(Causal Effect), 즉 \\(\\mathbb{E}[Y | do(X)]\\)를 의미합니다.\n만약 \\(X\\)와 \\(Y\\) 사이에 교란 요인(Confounder)이 존재한다면, 그래프는 다음과 같습니다.\n\n\n\nFigure 3: 교란 요인이 존재하는 상황의 인과 그래프. X와 Y는 직접적인 인과 경로(실선) 외에도 교란 요인에 의한 뒷문 경로(점선, Back-door path)로 연결되어 있다.\n\n\n이때 관측되는 공분산 \\(\\sigma_{xy}\\)는 다음과 같이 분해됩니다.\n\\[\n\\sigma_{xy} = \\mathbb{E}[XY] = \\mathbb{E}[X(\\lambda_{xy}X + \\epsilon_y)] = \\lambda_{xy}\\mathbb{E}[X^2] + \\mathbb{E}[X\\epsilon_y]\n\\]\n\\(\\mathbb{E}[X^2]=1\\)이라고 가정하더라도, 교란 요인 때문에 \\(X\\)와 \\(\\epsilon_y\\)가 상관관계를 가지므로(\\(\\mathbb{E}[X\\epsilon_y] \\neq 0\\)),\n\\[\n\\sigma_{xy} = \\lambda_{xy} + \\text{Bias}(\\epsilon_{xy})\n\\]\n가 됩니다. 즉, 단순 회귀 계수(\\(\\beta = \\sigma_{xy}\\))는 인과 계수(\\(\\lambda_{xy}\\))에 편향(Bias)이 더해진 값이므로, 인과 효과를 올바르게 추정할 수 없습니다. 이것이 \\(\\lambda_{xy}\\)가 식별 불가능(Not Identifiable)한 상황입니다."
  },
  {
    "objectID": "posts/lecture/L09/part-02/index.html#the-single-door-criterion",
    "href": "posts/lecture/L09/part-02/index.html#the-single-door-criterion",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 2)",
    "section": "3.1 The Single-Door Criterion",
    "text": "3.1 The Single-Door Criterion\nSingle-Door Criterion은 특정 조건 하에서 보조 변수 \\(Z\\)를 사용하여 \\(X \\to Y\\)의 직접 효과를 식별하는 방법입니다.\n\nThe Setup\n다음과 같은 그래프를 가정해 봅시다.\n\n\n\nFigure 4: Single-Door Criterion을 설명하기 위한 그래프. Z는 X의 원인이고, X는 Y의 원인이다. Z와 Y 사이에는 점선으로 표시된 교란 관계(상관성)가 존재한다.\n\n\n\n\\(Z \\to X\\) (\\(\\lambda_{zx}\\))\n\\(X \\to Y\\) (\\(\\lambda_{xy}\\))\n\\(Z\\)와 \\(Y\\) 사이에는 직접적인 인과 관계는 없지만, 교란 요인 \\(\\epsilon_{zy}\\)에 의해 상관관계가 있음 (dashed line).\n\n이 모형의 구조적 방정식은 다음과 같습니다: 1. \\(X = \\lambda_{zx} Z + \\epsilon_x\\) 2. \\(Y = \\lambda_{xy} X + \\epsilon_y\\) (단, \\(\\epsilon_y\\)와 \\(Z\\)는 correlated)\n\n\nDerivation using Regression\n우리는 \\(Y\\)를 \\(X\\)와 \\(Z\\)에 대해 다중 회귀분석(Multiple Regression)을 수행합니다.\n\\[\nY = \\alpha X + \\beta Z + e\n\\]\n이 회귀분석의 계수 \\(\\alpha\\)와 \\(\\beta\\)가 구조적 파라미터와 어떤 관계가 있는지 유도해 보겠습니다. 최소자승법은 다음 목적함수를 최소화합니다.\n\\[\n\\mathcal{L} = \\mathbb{E}[(Y - \\alpha X - \\beta Z)^2]\n\\]\n이 식을 전개하면: \\[\n\\mathbb{E}[Y^2] - 2\\alpha\\sigma_{xy} - 2\\beta\\sigma_{yz} + 2\\alpha\\beta\\sigma_{xz} + \\alpha^2\\mathbb{E}[X^2] + \\beta^2\\mathbb{E}[Z^2]\n\\] (편의상 모든 변수의 분산 \\(\\mathbb{E}[X^2], \\mathbb{E}[Z^2]\\) 등을 1로 가정)\n각 계수에 대해 편미분하여 0으로 둡니다.\n\n\\(\\frac{\\partial \\mathcal{L}}{\\partial \\alpha} = -2\\sigma_{xy} + 2\\alpha + 2\\beta\\sigma_{xz} = 0 \\implies \\sigma_{xy} = \\alpha + \\beta\\sigma_{xz}\\)\n\\(\\frac{\\partial \\mathcal{L}}{\\partial \\beta} = -2\\sigma_{yz} + 2\\beta + 2\\alpha\\sigma_{xz} = 0 \\implies \\sigma_{yz} = \\beta + \\alpha\\sigma_{xz}\\)\n\n이것은 회귀분석의 정규 방정식(Normal Equations)입니다. 이제 구조적 모형(SCM) 관점에서 공분산 \\(\\sigma_{xy}\\)와 \\(\\sigma_{yz}\\)를 써보면:\n\n\\(\\sigma_{xy} = \\lambda_{xy} + \\lambda_{zx}\\sigma_{zy}\\) (Path rule 적용)\n\\(\\sigma_{yz} = \\lambda_{xy}\\lambda_{zx} + \\sigma_{zy}\\)\n\n이 두 시스템(회귀 계수 시스템과 구조적 파라미터 시스템)을 매칭해보면 놀라운 결과를 얻게 됩니다.\n\\[\n\\begin{cases}\n\\alpha = \\lambda_{xy} \\\\\n\\beta = \\sigma_{zy} (\\text{or } \\epsilon_{zy})\n\\end{cases}\n\\]\n결론: 위와 같은 그래프 구조가 성립한다면, \\(Y\\)를 \\(X\\)와 \\(Z\\)에 대해 회귀분석했을 때 \\(X\\)의 회귀 계수 \\(\\alpha\\)는 실제 인과 효과 \\(\\lambda_{xy}\\)와 일치합니다. \\(Z\\)를 통제함으로써 \\(Z\\)와 연관된 교란 경로(Back-door path)가 차단되었기 때문입니다.\n\n\nTheorem: Single-Door Criterion\n강의 자료에 제시된 정리를 요약하면 다음과 같습니다.\n\\(G\\)가 인과 그래프일 때, \\(X \\to Y\\)의 계수 \\(\\lambda_{xy}\\)는 다음 조건을 만족하는 변수 집합 \\(Z\\)가 존재하면 식별 가능합니다.\n\n\\(Z\\)는 \\(Y\\)의 자손(descendant)을 포함하지 않는다.\n\\(Z\\)는 \\(X \\to Y\\) 링크를 제거한 그래프 \\(G_{\\underline{X}}\\)에서 \\(X\\)와 \\(Y\\)를 d-separation 한다.\n\n이 경우, \\(\\lambda_{xy}\\)는 \\(Y\\)를 \\(X\\)와 \\(Z\\)에 대해 회귀분석했을 때 \\(X\\)의 계수(\\(r_{yx \\cdot z}\\))와 같습니다."
  },
  {
    "objectID": "posts/lecture/L09/part-02/index.html#the-back-door-criterion",
    "href": "posts/lecture/L09/part-02/index.html#the-back-door-criterion",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 2)",
    "section": "3.2 The Back-Door Criterion",
    "text": "3.2 The Back-Door Criterion\nSingle-Door가 선형 모형의 특정 구조에 집중했다면, Back-Door Criterion은 더 일반적이고 강력한 도구입니다. 이는 선형뿐만 아니라 비선형 모형에서도 적용됩니다.\n\nDefinition\n변수 집합 \\(Z\\)가 다음 두 조건을 만족하면, \\(X\\)에서 \\(Y\\)로 가는 인과 효과를 식별하기 위한 Back-Door Set이라고 합니다.\n\n\\(Z\\)의 어떤 원소도 \\(X\\)의 자손(descendant)이 아니다. (인과적 후행 변수가 아님)\n\\(Z\\)는 \\(X\\)와 \\(Y\\) 사이의 모든 Back-Door Path(화살표가 \\(X\\)로 들어오는 경로)를 차단(block)한다.\n\n\n\nExample Application\n강의 자료의 예제 그래프를 봅시다.\n\n\n\nFigure 5: Back-Door Criterion 예제 그래프. X와 Y 사이에는 직접 경로 외에도 Z를 거치는 뒷문 경로(X &lt;- Z -&gt; Y)가 존재한다. W는 교란 요인이지만 Z를 통해 통제 가능하다.\n\n\n\n우리는 \\(X \\to Y\\)의 총 효과(Total Effect)를 알고 싶습니다.\n그래프 상에서 \\(X \\leftarrow Z \\to Y\\) 경로가 존재하므로, 단순 회귀는 편향됩니다.\n이때 \\(W\\)를 조건부로 넣으면 어떻게 될까요?\n\n\\(W\\)는 \\(X\\)의 부모인 \\(Z\\)와 \\(X\\) 사이의 경로 상에 있거나, 혹은 또 다른 교란 요인으로 작용할 수 있습니다.\n만약 \\(W\\)가 모든 Back-door path를 막는다면, 우리는 \\(Y\\)를 \\(X\\)와 \\(W\\)에 대해 회귀분석하여 \\(X\\)의 계수를 취함으로써 인과 효과를 얻을 수 있습니다.\n\n\n선형 모형에서 Back-door criterion을 만족하는 집합 \\(Z\\)를 찾았다면, 인과 효과는 다음과 같이 간단히 구해집니다.\n\\[\n\\text{Total Effect } = r_{yx \\cdot z}\n\\]\n즉, 교란 요인 \\(Z\\)들을 모두 회귀식에 포함(\\(Control\\))시켰을 때의 \\(X\\)의 편회귀 계수가 바로 인과 효과가 됩니다."
  },
  {
    "objectID": "posts/lecture/L09/part-04/index.html",
    "href": "posts/lecture/L09/part-04/index.html",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 4)",
    "section": "",
    "text": "지난 포스트에서는 \\(X \\to Y\\) 관계에서 교란 요인이 존재할 때, 도구 변수(Instrumental Variable, IV) \\(Z\\)를 사용하여 인과 효과 \\(\\lambda_{xy}\\)를 식별하는 방법을 배웠습니다. 핵심은 \\(\\lambda_{xy} = \\sigma_{zy} / \\sigma_{zx}\\)라는 간단한 비율 식이었습니다.\n하지만 현실의 인과 모형은 훨씬 복잡합니다. 1. Multiple Causes: \\(Y\\)에 영향을 주는 변수가 \\(X_1, X_2, \\dots, X_k\\)로 여러 개일 수 있습니다. 2. Entangled Instruments: 도구 변수 \\(Z_1, Z_2\\)가 각각 하나의 \\(X\\)에만 영향을 주는 것이 아니라, 서로 얽혀서(cross-paths) 영향을 줄 수 있습니다.\n이런 상황에서는 단일 IV 공식을 사용할 수 없습니다. 이번 포스트에서는 이를 해결하기 위한 Instrumental Sets의 개념과, 이를 그래프 이론적으로 풀어내는 Match-Block 알고리즘에 대해 알아봅니다."
  },
  {
    "objectID": "posts/lecture/L09/part-04/index.html#the-problem-of-entanglement",
    "href": "posts/lecture/L09/part-04/index.html#the-problem-of-entanglement",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 4)",
    "section": "2.1 The Problem of Entanglement",
    "text": "2.1 The Problem of Entanglement\n아래와 같은 상황을 가정해 봅시다.\n\n\n\nFigure 1: 두 개의 도구 변수(Z1, Z2)와 두 개의 원인 변수(X1, X2)가 서로 얽혀 있는 인과 그래프. Z1은 X1, X2 모두에 영향을 주고, Z2 역시 X1, X2 모두에 영향을 준다. Y로 가는 모든 경로는 X를 통과한다.\n\n\n[cite_start]이 그래프에서 \\(Z_1\\)은 \\(X_1\\)과 \\(X_2\\) 모두의 부모이고, \\(Z_2\\) 역시 마찬가지입니다[cite: 1674]. 따라서 \\(Z_1\\)을 \\(X_1\\)만을 위한 도구 변수로 사용할 수 없습니다. \\(X_2\\)를 통해 \\(Y\\)에 영향을 미치는 경로가 존재하기 때문입니다."
  },
  {
    "objectID": "posts/lecture/L09/part-04/index.html#linear-system-formulation",
    "href": "posts/lecture/L09/part-04/index.html#linear-system-formulation",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 4)",
    "section": "2.2 Linear System Formulation",
    "text": "2.2 Linear System Formulation\n하지만 우리에게는 \\(Z_1, Z_2\\)라는 두 개의 외생 변수(Exogenous Variables)와 \\(X_1, X_2\\)라는 두 개의 내생 변수(Endogenous Variables)가 있습니다. [cite_start]이를 연립방정식(Linear System)으로 세워볼 수 있습니다[cite: 1700].\n\\(Z\\)에서 \\(Y\\)로 가는 공분산 \\(\\sigma_{z_i y}\\)는 \\(Z\\)에서 \\(X\\)를 거쳐 \\(Y\\)로 가는 모든 경로의 합으로 표현됩니다 (Wright’s Path Rule).\n\\[\n\\begin{aligned}\n\\sigma_{z_1 y} &= \\sigma_{z_1 x_1}\\lambda_{x_1 y} + \\sigma_{z_1 x_2}\\lambda_{x_2 y} \\\\\n\\sigma_{z_2 y} &= \\sigma_{z_2 x_1}\\lambda_{x_1 y} + \\sigma_{z_2 x_2}\\lambda_{x_2 y}\n\\end{aligned}\n\\] [cite_start][cite: 1718]\n여기서 \\(\\sigma_{z_i x_j}\\)와 \\(\\sigma_{z_i y}\\)는 데이터로부터 계산 가능한 값들입니다. 우리가 구하고 싶은 미지수는 \\(\\lambda_{x_1 y}, \\lambda_{x_2 y}\\) 두 개입니다. 식도 2개, 미지수도 2개이므로 행렬 형태로 풀 수 있습니다.\n\\[\n\\begin{pmatrix} \\sigma_{z_1 y} \\\\ \\sigma_{z_2 y} \\end{pmatrix} =\n\\begin{pmatrix} \\sigma_{z_1 x_1} & \\sigma_{z_1 x_2} \\\\ \\sigma_{z_2 x_1} & \\sigma_{z_2 x_2} \\end{pmatrix}\n\\begin{pmatrix} \\lambda_{x_1 y} \\\\ \\lambda_{x_2 y} \\end{pmatrix}\n\\]\n만약 공분산 행렬 \\(\\Sigma_{ZX}\\)가 역행렬을 가진다면(Invertible), 우리는 \\(\\Lambda_{XY}\\)를 유일하게 구할 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L09/part-04/index.html#the-problem-of-collinearity",
    "href": "posts/lecture/L09/part-04/index.html#the-problem-of-collinearity",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 4)",
    "section": "3.1 The Problem of Collinearity",
    "text": "3.1 The Problem of Collinearity\n만약 경로들이 서로 “겹친다면” 방정식들이 선형 종속(Linearly Dependent) 관계가 되어 풀 수 없게 됩니다.\n\n\n\nFigure 2: Z1에서 Z2를 거쳐 X로 가는 구조. Z1에서 Y로 가는 경로는 Z2에서 Y로 가는 경로의 상수배가 되어버려 시스템이 퇴화(Degenerate)된다.\n\n\n위 그림과 같은 경우, \\(Z_1\\)에서 \\(Y\\)로 가는 영향력은 전적으로 \\(Z_2\\)를 경유합니다. 수식으로 보면: \\[\n\\sigma_{z_1 y} = \\lambda_{z_1 z_2} \\sigma_{z_2 y}\n\\] [cite_start]즉, 첫 번째 식은 두 번째 식의 상수배(\\(\\lambda_{z_1 z_2}\\))에 불과하므로, 새로운 정보를 주지 못합니다[cite: 1720]. 이를 Degenerate System이라고 합니다."
  },
  {
    "objectID": "posts/lecture/L09/part-04/index.html#the-non-intersecting-path-theorem",
    "href": "posts/lecture/L09/part-04/index.html#the-non-intersecting-path-theorem",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 4)",
    "section": "3.2 The Non-Intersecting Path Theorem",
    "text": "3.2 The Non-Intersecting Path Theorem\n이 문제를 해결하기 위한 그래프 이론적 조건은 다음과 같습니다.\n\n[cite_start]Theorem: 선형 시스템이 Non-degenerate(Full Rank)하기 위한 필요충분조건은, \\(\\{Z_1, Z_2\\}\\)에서 \\(\\{X_1, X_2\\}\\)로 가는 서로 교차하지 않는 경로(Non-intersecting paths)들의 매칭(Matching)이 존재하는 것이다[cite: 1723].\n\n\n\n\nFigure 3: Z1 -&gt; X1, Z2 -&gt; X2 경로가 서로 교차하지 않고 독립적으로 연결된 그래프. 이 경우 행렬은 Full Rank를 가지며 식별 가능하다.\n\n\n[cite_start]이 조건은 Max-Flow Algorithm을 통해 효율적으로 검증할 수 있습니다[cite: 1734]. \\(Z\\)들을 소스(Source), \\(X\\)들을 싱크(Sink)로 보고, 각 노드의 용량을 1로 설정했을 때 흐름(Flow)의 크기가 \\(|X|\\)와 같다면 식별 가능합니다."
  },
  {
    "objectID": "posts/lecture/L09/part-04/index.html#concept",
    "href": "posts/lecture/L09/part-04/index.html#concept",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 4)",
    "section": "4.1 Concept",
    "text": "4.1 Concept\n만약 \\(X = \\{X_1, X_2, X_3\\}\\)인데, \\(X_3\\)를 위한 적절한 도구 변수가 없다면 어떻게 해야 할까요? 전체 시스템을 풀 수는 없지만, 부분적으로 \\(\\{X_1, X_2\\}\\)의 인과 효과만이라도 식별할 수 있지 않을까요? [cite_start]이를 Instrumental Subset (IS) 문제라고 합니다[cite: 1752]."
  },
  {
    "objectID": "posts/lecture/L09/part-04/index.html#definition",
    "href": "posts/lecture/L09/part-04/index.html#definition",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 4)",
    "section": "4.2 Definition",
    "text": "4.2 Definition\n[cite_start]변수 집합 \\(Z\\)가 \\(X \\subseteq Pa(Y)\\)에 대한 Instrumental Set이 되기 위한 조건은 다음과 같습니다 [cite: 1738-1742]: 1. \\(|Z| = |X| = n\\) (변수 개수가 같아야 함) 2. \\(Z\\)의 원소들은 \\(X\\)의 자손이 아님. 3. \\(Z\\)에서 \\(Y\\)로 가는 모든 Trek(경로)은 \\(X\\)를 통과해야 함. 4. 경로들이 서로 꼬이지 않고 명확히 매칭되어야 함 (Trek condition)."
  },
  {
    "objectID": "posts/lecture/L09/part-04/index.html#algorithm-overview",
    "href": "posts/lecture/L09/part-04/index.html#algorithm-overview",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 4)",
    "section": "5.1 Algorithm Overview",
    "text": "5.1 Algorithm Overview\n이 알고리즘은 반복적으로 Max-Flow를 수행하며 후보군을 좁혀나가는 방식입니다.\n\nInitialize: 모든 \\(Z\\)와 모든 \\(X\\)를 후보로 둡니다.\nMax-Flow: \\(Z\\)에서 \\(X\\)로 가는 Max-Flow를 계산합니다.\nPruning (Block): Flow를 받지 못한 \\(X\\) 노드들은 식별 불가능하므로 제거합니다. 또한, 제거된 \\(X\\)의 조상(Ancestor)이 되는 \\(Z\\)들도 더 이상 유효하지 않을 수 있으므로 검토합니다.\nRepeat: 더 이상 제거되는 노드가 없을 때까지 반복합니다."
  },
  {
    "objectID": "posts/lecture/L09/part-04/index.html#visual-walkthrough",
    "href": "posts/lecture/L09/part-04/index.html#visual-walkthrough",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 4)",
    "section": "5.2 Visual Walkthrough",
    "text": "5.2 Visual Walkthrough\n강의 자료의 예시를 통해 단계를 따라가 봅시다.\nStep 1: Initial Setup 복잡한 그래프가 주어집니다. \\(X_1, \\dots, X_5\\)와 \\(Z_1, \\dots, Z_5\\)가 얽혀 있습니다.\n\n\n\nFigure 4: 복잡한 인과 그래프 예시. X3는 Z로부터 직접적인 경로가 부족해 보인다.\n\n\nStep 2: First Max-Flow & Pruning [cite_start]\\(Z\\) 전체에서 \\(X\\) 전체로 Max-Flow를 돌렸더니, \\(X_4\\)로 가는 유량(Flow)이 0임이 밝혀졌습니다[cite: 1786]. \\(\\to\\) Action: \\(X_4\\)를 비활성화(Disable)합니다. \\(\\to\\) Chain Reaction: \\(X_4\\)가 제거됨에 따라, \\(X_4\\)의 조상이었던 노드들이나 연관된 경로들이 영향을 받습니다. [cite_start]특히 \\(Z_3, Z_5\\)가 영향을 받습니다[cite: 1786].\nStep 3: Iteration \\(X_4\\)를 뺀 상태에서 다시 Max-Flow를 돌립니다. [cite_start]이번에는 \\(X_3\\)로 가는 Flow가 부족해집니다[cite: 1814]. \\(\\to\\) Action: \\(X_3\\)를 비활성화합니다.\nStep 4: Final Set [cite_start]\\(X_3, X_4\\)가 제거된 후 남은 노드들(\\(X_1, X_2, X_5\\))에 대해 Max-Flow를 돌리면, \\(\\{Z_1, Z_2, Z_4\\}\\)와 완벽한 매칭(비교차 경로)이 형성됨을 확인할 수 있습니다[cite: 1828].\n\n\n\nFigure 5: 최종적으로 식별된 Instrumental Subset. 붉은색 실선으로 표시된 경로들이 X1, X2, X5를 식별 가능하게 한다.\n\n\nConclusion: 최종적으로 식별 가능한 부분 집합은 \\(\\{X_1, X_2, X_5\\}\\)이며, 이를 위한 도구 변수 집합은 \\(\\{Z_1, Z_2, Z_4\\}\\)입니다. 우리는 전체를 다 알 수는 없었지만, 이 알고리즘을 통해 “알 수 있는 것”을 최대한 찾아냈습니다."
  },
  {
    "objectID": "posts/lecture/L09/part-01/index.html",
    "href": "posts/lecture/L09/part-01/index.html",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 1)",
    "section": "",
    "text": "[cite_start]본 포스트는 서울대학교 데이터사이언스 대학원 이상학 교수님의 “Linear Structural Causal Models” 강의 자료를 바탕으로 작성되었습니다[cite: 1, 2, 3]. Causal Inference의 핵심 도구인 SCM(Structural Causal Model)을 선형(Linear) 가정하에 두었을 때 발생하는 수학적 성질과, 이를 통해 인과 효과를 식별(Identification)하는 방법론인 Wright’s Rules를 중점적으로 다룹니다."
  },
  {
    "objectID": "posts/lecture/L09/part-01/index.html#linear-scm의-정의",
    "href": "posts/lecture/L09/part-01/index.html#linear-scm의-정의",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 1)",
    "section": "1.1 Linear SCM의 정의",
    "text": "1.1 Linear SCM의 정의\n일반적인 Non-parametric SCM에서 변수 \\(V_i\\)는 부모 변수 \\(Pa_i\\)와 외생 변수(Exogenous variable) \\(U_i\\)의 임의의 함수 \\(f_i\\)로 결정됩니다 (\\(V_i \\leftarrow f_i(Pa_i, U_i)\\)). [cite_start]Linear SCM은 이 함수 \\(f\\)가 선형 방정식(Linear Equation)의 형태를 띤다고 가정합니다[cite: 11, 20].\n\\[\nV_j \\leftarrow \\sum_{k \\in Pa_j} \\lambda_{kj} V_k + \\epsilon_j\n\\]\n여기서 각 요소의 의미는 다음과 같습니다:\n\nStructural Coefficient (\\(\\lambda_{kj}\\)): \\(V_k\\)가 \\(V_j\\)에 미치는 직접적인 인과 효과(Direct Cause)를 나타냅니다. [cite_start]즉, \\(V_k\\)가 1단위 변할 때 \\(V_j\\)의 변화량을 의미합니다[cite: 14, 21].\n[cite_start]Error Term (\\(\\epsilon_j\\)): 기존 Non-parametric 모델의 \\(U_j\\)에 대응하며, 선형 모델에서는 관습적으로 \\(\\epsilon\\) (또는 \\(\\sigma^\\circ\\))으로 표기합니다[cite: 20, 22]."
  },
  {
    "objectID": "posts/lecture/L09/part-01/index.html#주요-가정-및-데이터-정규화",
    "href": "posts/lecture/L09/part-01/index.html#주요-가정-및-데이터-정규화",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 1)",
    "section": "1.2 주요 가정 및 데이터 정규화",
    "text": "1.2 주요 가정 및 데이터 정규화\n[cite_start]수식의 간결함을 위해, 우리는 데이터가 정규화(Normalized)되어 있다고 가정합니다[cite: 15]. \\[\n\\mathbb{E}[X] = 0, \\quad \\mathbb{E}[X^2] = 1\n\\] [cite_start]또한, 에러 항 \\(\\epsilon\\)은 다변량 정규분포(Multivariate Gaussian)를 따르며, 이는 공분산 행렬 \\(\\Sigma\\)에 의해 분포가 완전히 결정됨을 의미합니다[cite: 16]."
  },
  {
    "objectID": "posts/lecture/L09/part-01/index.html#그래프-표현-graphical-representation",
    "href": "posts/lecture/L09/part-01/index.html#그래프-표현-graphical-representation",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 1)",
    "section": "1.3 그래프 표현 (Graphical Representation)",
    "text": "1.3 그래프 표현 (Graphical Representation)\nLinear SCM의 그래프 표현은 Non-parametric 모델과 두 가지 중요한 차이점이 있습니다.\n\n[cite_start]Directed Edge (화살표): 변수 간의 관계를 나타내는 화살표 위에 해당 구조적 계수(Structural Coefficient, \\(\\lambda\\))를 명시합니다[cite: 39].\nBidirected Edge (양방향 점선): 에러 항 간의 공분산을 나타냅니다.\n\n[cite_start]\\(\\epsilon_{xy} = \\mathbb{E}[\\epsilon_x \\epsilon_y] = \\text{cov}(\\epsilon_x, \\epsilon_y)\\)[cite: 50].\n[cite_start]Non-parametric 모델에서는 양방향 화살표가 명시적인 잠재 변수(Latent Variable) \\(U\\)의 존재를 암시하는 반면, Linear SCM에서는 에러 항 간의 공분산(Covariance) 그 자체를 의미하여 수학적으로 유용한 도구가 됩니다 [cite: 51-53].\n\n\n\n\n\nFigure 1: Linear SCM의 그래프 표현 방식. 좌측은 Non-parametric 모델로 에러 항이 명시적 노드로 표현되지만, 우측 Linear SCM에서는 구조적 계수 \\(\\lambda\\)가 엣지에 부여되고, 에러 항 간의 상관관계는 \\(\\epsilon_{xy}\\)라는 양방향 점선(Bidirected edge)으로 축약되어 표현된다."
  },
  {
    "objectID": "posts/lecture/L09/part-01/index.html#derivation-of-intervention-effect",
    "href": "posts/lecture/L09/part-01/index.html#derivation-of-intervention-effect",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 1)",
    "section": "2.1 Derivation of Intervention Effect",
    "text": "2.1 Derivation of Intervention Effect\n\\(X \\to Y\\) 관계를 가진 간단한 모델 \\(Y = \\lambda X + \\epsilon_y\\)를 가정해 봅시다. [cite_start]여기서 \\(do(X=x)\\)를 수행했을 때 \\(Y\\)의 기댓값은 다음과 같이 유도됩니다 [cite: 65-74].\n\nDefinition: \\[\\mathbb{E}[Y|do(X=x)] = \\int y P(Y=y|do(x)) dy\\]\nSubstitution: \\(Y\\)의 구조 방정식 대입 \\[= \\int y P(\\lambda x + \\epsilon_y = y) dy\\]\nVariable Change: \\(e = y - \\lambda x\\)로 치환하면, \\(de = dy\\)이고 \\(y = e + \\lambda x\\)가 됩니다. \\[= \\int (\\lambda x + e) P(\\epsilon_y = e) de\\]\nLinearity of Expectation: \\[= \\lambda x \\int P(\\epsilon_y = e) de + \\int e P(\\epsilon_y = e) de\\]\nResult: 첫 번째 항의 적분은 확률밀도함수의 전체 합이므로 1, 두 번째 항은 에러 항의 기댓값(\\(\\mathbb{E}[\\epsilon_y]\\))이므로 가정에 의해 0이 됩니다. \\[= \\lambda x + 0 = \\lambda x\\]\n\n[cite_start]결론적으로, 선형 모델에서 \\(X\\)에 \\(x\\)만큼의 개입을 가했을 때 \\(Y\\)의 기댓값은 구조적 계수 \\(\\lambda\\)와 \\(x\\)의 곱인 \\(\\lambda x\\)가 됩니다[cite: 74, 81]."
  },
  {
    "objectID": "posts/lecture/L09/part-01/index.html#case-study-direct-effect-vs.-confounding",
    "href": "posts/lecture/L09/part-01/index.html#case-study-direct-effect-vs.-confounding",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 1)",
    "section": "3.1 Case Study: Direct Effect vs. Confounding",
    "text": "3.1 Case Study: Direct Effect vs. Confounding\n가장 기본적인 관계부터 공분산 \\(\\sigma_{xy}\\)를 구조적 계수로 분해해 봅시다.\n\nCase 1: Direct Effect (\\(X \\to Y\\))\n가장 단순한 인과 관계입니다. \\[\n\\begin{aligned}\n\\sigma_{xy} &= \\mathbb{E}[XY] \\\\\n&= \\mathbb{E}[X(\\lambda X + \\epsilon_y)] \\\\\n&= \\lambda \\mathbb{E}[XX] + \\mathbb{E}[X\\epsilon_y]\n\\end{aligned}\n\\] 데이터가 정규화되어 있으므로 \\(\\mathbb{E}[XX]=1\\)이고, 원인(\\(X\\))과 결과의 에러(\\(\\epsilon_y\\))는 독립이므로 \\(\\mathbb{E}[X\\epsilon_y]=0\\)입니다. \\[\\therefore \\sigma_{xy} = \\lambda\\] [cite_start]즉, 교란 요인이 없을 때 관측된 상관관계는 인과 효과와 같습니다[cite: 109].\n\n\nCase 2: Confounded Relationship (\\(X \\leftrightarrow Y\\))\n[cite_start]만약 \\(X\\)와 \\(Y\\) 사이에 관측되지 않은 공통 원인(Latent Confounder)이 있어 에러 항 간의 공분산 \\(\\epsilon_{xy}\\)가 존재한다면 어떻게 될까요? [cite: 129-134].\n\n\n\nFigure 2: Confounding이 존재하는 상황. \\(X\\)에서 \\(Y\\)로 가는 직접 경로(\\(\\lambda\\)) 외에, 에러 항 간의 공분산(\\(\\epsilon_{xy}\\))으로 표현된 뒷문 경로(backdoor path)가 존재한다.\n\n\n\\[\n\\begin{aligned}\n\\sigma_{xy} &= \\mathbb{E}[XY] \\\\\n&= \\mathbb{E}[X(\\lambda X + \\epsilon_y)] \\\\\n&= \\lambda \\mathbb{E}[XX] + \\mathbb{E}[X\\epsilon_y] \\\\\n&= \\lambda + \\mathbb{E}[\\epsilon_x \\epsilon_y] \\quad (\\because X \\leftarrow \\epsilon_x) \\\\\n&= \\lambda + \\epsilon_{xy}\n\\end{aligned}\n\\]\n여기서 중요한 통찰을 얻을 수 있습니다: &gt; Correlation = Causal Effect + Confounding Bias &gt; \\[\\sigma_{xy} = \\lambda + \\epsilon_{xy}\\]\n[cite_start]관측된 상관관계(\\(\\sigma_{xy}\\))는 “진짜 인과 효과(\\(\\lambda\\))”와 “교란 요인(\\(\\epsilon_{xy}\\))”의 합으로 구성됩니다[cite: 134]."
  },
  {
    "objectID": "posts/lecture/L09/part-01/index.html#path-decomposition-경로-분해",
    "href": "posts/lecture/L09/part-01/index.html#path-decomposition-경로-분해",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 1)",
    "section": "3.2 Path Decomposition (경로 분해)",
    "text": "3.2 Path Decomposition (경로 분해)\n조금 더 복잡한 구조로 확장해 보겠습니다. [cite_start]공분산이 그래프상의 “경로(Path)”와 어떻게 연결되는지 주목해야 합니다[cite: 179].\n\nCase 3: Chain Structure (\\(X \\to Z \\to Y\\)) with Confounding (\\(X \\leftrightarrow Z\\))\n[cite_start]\\(X\\)가 \\(Z\\)에 영향을 주고, \\(Z\\)가 \\(Y\\)에 영향을 주는데, \\(X\\)와 \\(Z\\) 사이에 교란 요인이 있는 상황입니다 [cite: 163-171].\n구조 방정식: * \\(Z = \\lambda_{xz}X + \\epsilon_z\\) * \\(Y = \\lambda_{zy}Z + \\epsilon_y\\)\n\\(X\\)와 \\(Y\\)의 공분산 \\(\\sigma_{xy}\\)를 구해봅시다.\n\\[\n\\begin{aligned}\n\\sigma_{xy} &= \\mathbb{E}[XY] \\\\\n&= \\mathbb{E}[X(\\lambda_{zy}Z + \\epsilon_y)] \\\\\n&= \\lambda_{zy}\\mathbb{E}[XZ] \\quad (\\because \\mathbb{E}[X\\epsilon_y]=0)\n\\end{aligned}\n\\]\n여기서 \\(\\mathbb{E}[XZ]\\) (즉, \\(\\sigma_{xz}\\))를 먼저 구해야 합니다. \\[\n\\begin{aligned}\n\\mathbb{E}[XZ] &= \\mathbb{E}[X(\\lambda_{xz}X + \\epsilon_z)] \\\\\n&= \\lambda_{xz}\\mathbb{E}[XX] + \\mathbb{E}[X\\epsilon_z] \\\\\n&= \\lambda_{xz} + \\epsilon_{xz} \\quad (\\because X=\\epsilon_x, \\mathbb{E}[\\epsilon_x \\epsilon_z]=\\epsilon_{xz})\n\\end{aligned}\n\\]\n이를 원래 식에 대입하면: \\[\n\\sigma_{xy} = \\lambda_{zy}(\\lambda_{xz} + \\epsilon_{xz}) = \\lambda_{zy}\\lambda_{xz} + \\lambda_{zy}\\epsilon_{xz}\n\\]\n[cite_start]이 결과는 그래프 상에서 \\(X\\)에서 \\(Y\\)로 가는 두 가지 경로의 합으로 해석될 수 있습니다 [cite: 172-177]. 1. Causal Path: \\(X \\xrightarrow{\\lambda_{xz}} Z \\xrightarrow{\\lambda_{zy}} Y\\) (계수의 곱: \\(\\lambda_{xz}\\lambda_{zy}\\)) 2. Confounded Path: \\(X \\stackrel{\\epsilon_{xz}}{\\leftrightarrow} Z \\xrightarrow{\\lambda_{zy}} Y\\) (계수의 곱: \\(\\epsilon_{xz}\\lambda_{zy}\\))"
  },
  {
    "objectID": "posts/lecture/L09/part-01/index.html#wrights-rules-1921",
    "href": "posts/lecture/L09/part-01/index.html#wrights-rules-1921",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 1)",
    "section": "3.3 Wright’s Rules (1921)",
    "text": "3.3 Wright’s Rules (1921)\n위의 예시들을 일반화한 것이 바로 Wright’s Rules입니다. [cite_start]비순환 모델(Acyclic Models)에서 두 변수 \\(X, Y\\) 사이의 공분산 \\(\\sigma_{xy}\\)는 다음과 같이 계산됩니다 [cite: 235-244].\n\nWright’s Rule: \\(\\sigma_{xy}\\)는 \\(X\\)와 \\(Y\\) 사이의 모든 Open Path에 대해, 각 경로를 구성하는 계수(Path Coefficient)들의 곱의 합이다.\n\n여기서 Open Path란: 1. Non-self-intersecting: 같은 노드를 두 번 지나지 않아야 함. 2. [cite_start]No Colliders: 화살표가 서로 충돌하는 지점(\\(\\rightarrow V \\leftarrow\\))이 없어야 함 (Active path여야 함)[cite: 205].\n\n적용 예제 (Complex Graph)\n다음과 같은 복잡한 그래프를 생각해 봅시다. [cite_start]\\(W, X, Y, Z\\) 변수가 얽혀 있습니다 [cite: 223, 230-233].\n\n\n\nFigure 3: Wright’s Rule 적용 예제. \\(X\\)와 \\(Y\\) 사이의 공분산을 구하기 위해 가능한 모든 유효한 경로(Treks)를 식별하고 각 경로의 계수 곱을 합산한다.\n\n\n위 그래프에서 \\(X\\)와 \\(Y\\) 사이의 공분산 \\(\\sigma_{xy}\\)를 구성하는 경로는 3가지가 있습니다:\n\nDirect Causal Path: \\(X \\xrightarrow{\\lambda_{xy}} Y\\)\n\n값: \\(\\lambda_{xy}\\)\n\nBackdoor Path via \\(W\\): \\(X \\xleftarrow{\\lambda_{wx}} W \\stackrel{\\epsilon_{wy}}{\\leftrightarrow} Y\\)\n\n값: \\(\\lambda_{wx}\\epsilon_{wy}\\)\n(주의: 화살표 방향을 거스르는 \\(X \\leftarrow W\\) 이동이 포함됨)\n\nComplex Path via \\(W, Z\\): \\(X \\xleftarrow{\\lambda_{zx}} Z \\xleftarrow{\\lambda_{wz}} W \\stackrel{\\epsilon_{wy}}{\\leftrightarrow} Y\\)\n\n값: \\(\\lambda_{zx}\\lambda_{wz}\\epsilon_{wy}\\)\n\n\n[cite_start]따라서 전체 공분산은 이들의 합이 됩니다[cite: 233]. \\[\\sigma_{xy} = \\lambda_{xy} + \\lambda_{wx}\\epsilon_{wy} + \\lambda_{zx}\\lambda_{wz}\\epsilon_{wy}\\]"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-03/index.html",
    "href": "posts/lecture/L13/causal-inference-13-part-03/index.html",
    "title": "[Causal Inference] 13. IV (Part 3)",
    "section": "",
    "text": "데이터를 다루다 보면 선형(Linear) 모델로는 설명하기 힘든 복잡한 인과관계를 마주하게 됩니다.\n전통적인 2단계 최소제곱법(2SLS)은 강력한 도구이지만, 다음과 같은 한계가 있습니다.\n\n\n처치(Treatment)와 결과(Outcome)의 관계를 선형으로 가정합니다.\n\n\n공변량(Covariate)과 처치 변수 간의 복잡한 상호작용을 포착하기 어렵습니다.\n\n\n이번 포스트에서는 Hartford et al.(2017)이 제안한 Deep IV 방법론을 소개하고, 가격(\\(P\\))과 판매량(\\(Y\\))의 비선형적 관계를 시뮬레이션 데이터를 통해 추정해보겠습니다.\n\n\n\n\n우리가 해결하고자 하는 인과추론 문제는 다음과 같은 구조적 방정식(Structural Equation)으로 정의됩니다.\n\n\\[Y = g(P, X) + \\epsilon\\]\n\n이 수식이 실제 현실에서 어떤 의미를 갖는지, 논문에서 제시한 항공권 가격 결정 시나리오를 통해 살펴보겠습니다.\n\n\n\n\n\n항공사가 티켓 가격(\\(P\\))을 책정하고 그에 따른 판매량(\\(Y\\))을 분석한다고 가정해 봅시다.\n우리의 목표는 “가격을 올렸을 때 판매량이 실제로 얼마나 줄어드는가?”(인과 효과)를 알아내는 것입니다.\n하지만 단순히 데이터를 관찰하면 내생성(Endogeneity) 문제로 인해 잘못된 결론에 도달하게 됩니다.\n교란 변수 (\\(E\\), Confounder):\n\n예를 들어 ‘비즈니스 컨퍼런스’나 ’휴가철’ 같은 수요 급증 요인이 있다고 합시다.\n이 요인은 가격(\\(P\\))을 높이게 만들고(항공사가 가격을 올림), 동시에 판매량(\\(Y\\))도 높입니다(사람들이 비싸도 삼).\n그 결과, 데이터상으로는 “가격이 비싼데도 판매량이 높네?”라는 양의 상관관계가 나타나, 가격의 부정적 효과를 과소평가하게 됩니다.\n\n이 고리를 끊기 위해 우리는 도구 변수 (\\(Z\\), Instrument)를 도입합니다.\n\n\n\n\nFigure: Causal Graph (DAG) 인과 관계를 도식화하면 다음과 같습니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-03/index.html#the-problem-formulation",
    "href": "posts/lecture/L13/causal-inference-13-part-03/index.html#the-problem-formulation",
    "title": "[Causal Inference] 13. IV (Part 3)",
    "section": "",
    "text": "우리가 해결하고자 하는 인과추론 문제는 다음과 같은 구조적 방정식(Structural Equation)으로 정의됩니다.\n\n\\[Y = g(P, X) + \\epsilon\\]\n\n이 수식이 실제 현실에서 어떤 의미를 갖는지, 논문에서 제시한 항공권 가격 결정 시나리오를 통해 살펴보겠습니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-03/index.html#motivating-example-airline-ticket-pricing",
    "href": "posts/lecture/L13/causal-inference-13-part-03/index.html#motivating-example-airline-ticket-pricing",
    "title": "[Causal Inference] 13. IV (Part 3)",
    "section": "",
    "text": "항공사가 티켓 가격(\\(P\\))을 책정하고 그에 따른 판매량(\\(Y\\))을 분석한다고 가정해 봅시다.\n우리의 목표는 “가격을 올렸을 때 판매량이 실제로 얼마나 줄어드는가?”(인과 효과)를 알아내는 것입니다.\n하지만 단순히 데이터를 관찰하면 내생성(Endogeneity) 문제로 인해 잘못된 결론에 도달하게 됩니다.\n교란 변수 (\\(E\\), Confounder):\n\n예를 들어 ‘비즈니스 컨퍼런스’나 ’휴가철’ 같은 수요 급증 요인이 있다고 합시다.\n이 요인은 가격(\\(P\\))을 높이게 만들고(항공사가 가격을 올림), 동시에 판매량(\\(Y\\))도 높입니다(사람들이 비싸도 삼).\n그 결과, 데이터상으로는 “가격이 비싼데도 판매량이 높네?”라는 양의 상관관계가 나타나, 가격의 부정적 효과를 과소평가하게 됩니다.\n\n이 고리를 끊기 위해 우리는 도구 변수 (\\(Z\\), Instrument)를 도입합니다.\n\n\n\n\nFigure: Causal Graph (DAG) 인과 관계를 도식화하면 다음과 같습니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-03/index.html#mathematical-intuition-why-two-stages",
    "href": "posts/lecture/L13/causal-inference-13-part-03/index.html#mathematical-intuition-why-two-stages",
    "title": "[Causal Inference] 13. IV (Part 3)",
    "section": "Mathematical Intuition: Why Two Stages?",
    "text": "Mathematical Intuition: Why Two Stages?\n\n우리의 목표는 인과 함수 \\(g(P, X)\\)를 찾는 것입니다.\n하지만 앞서 보았듯 \\(Y = g(P, X) + \\epsilon\\) 식에서 바로 회귀분석을 할 수 없습니다.\n오차항 \\(\\epsilon\\)이 \\(P\\)와 상관관계가 있기 때문입니다.\n이 문제를 해결하기 위해, 우리는 식의 양변에 도구 변수 \\(Z\\)와 공변량 \\(X\\)에 대한 조건부 기댓값(Conditional Expectation)을 취합니다.\n\n\\[E[Y | X, Z] = E[g(P, X) + \\epsilon | X, Z]\\]\n\n기댓값의 선형성(Linearity)에 의해 우변을 분리할 수 있습니다.\n\n\\[E[Y | X, Z] = E[g(P, X) | X, Z] + \\underbrace{E[\\epsilon | X, Z]}_{= 0}\\]\n\n도구 변수의 정의(외생성)에 의해, 도구 변수는 오차항과 공변량이 주어진 경우 독립입니다.\n따라서 \\(z \\perp \\epsilon | x \\Longrightarrow E[\\epsilon | X, Z] = 0\\)이 되어 오차항이 사라집니다.\n이제 남은 식을 적분 형태로 풀어서 쓰면 다음과 같습니다.\n\n\\[E[Y | X, Z] = \\int g(p, x) dF(p | x, z)\\]\n\n이 식은 Deep IV 모델의 청사진이 됩니다.\n\n\n\\(F(p | x, z)\\): 우변의 적분을 계산하려면, \\(Z\\)와 \\(X\\)가 주어졌을 때 \\(P\\)가 어떻게 분포하는지 알아야 합니다. \\(\\rightarrow\\) Stage 1 (Treatment Network)\n\n\n\\(g(p, x)\\): 위 등식을 만족시키는 미지의 함수 \\(g\\)를 찾아야 합니다. \\(\\rightarrow\\) Stage 2 (Outcome Network)\n\n\n결국 Deep IV는 “1단계에서 추정한 분포(\\(F\\))를 이용해 2단계 함수(\\(g\\))를 적분했을 때, 그 결과가 실제 관측된 \\(Y\\)의 평균과 일치하도록” 학습하는 과정입니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-03/index.html#stage-1-mixture-density-network-mdn",
    "href": "posts/lecture/L13/causal-inference-13-part-03/index.html#stage-1-mixture-density-network-mdn",
    "title": "[Causal Inference] 13. IV (Part 3)",
    "section": "Stage 1: Mixture Density Network (MDN)",
    "text": "Stage 1: Mixture Density Network (MDN)\n\nDeep IV의 첫 번째 단계는 ’Treatment Network’를 구축하는 것입니다.\n이 단계의 핵심은 전통적인 방식과의 차이점을 이해하는 데 있습니다.\n\n\n1.1. Why Density Estimation? (Point vs. Distribution)\n\n전통적인 Linear 2SLS 1단계에서는 도구변수(\\(Z\\))와 공변량(\\(X\\))을 사용하여 처치 변수의 평균(Mean)을 예측합니다. \\[\\hat{P}_{2SLS} = E[P | Z, X] \\approx \\alpha Z + \\beta X\\]\n이는 \\(P\\)와 \\(Z\\)의 관계가 선형적이고, 오차가 등분산(Homoscedastic)을 가진다는 강력한 가정을 전제로 합니다.\n하지만 논문(Hartford et al., 2017)에서는 현실 데이터가 이보다 훨씬 복잡하다고 지적합니다.\n가격(\\(P\\)) 결정 과정은 다봉형(Multimodal)일 수도 있고, 시기(\\(X\\))에 따라 변동성(Variance)이 달라질 수도 있습니다.\n따라서 단순한 평균값 하나로는 정보 손실이 발생합니다.\nDeep IV의 1단계 목표는 \\(P\\)의 값을 하나로 예측하는 것이 아니라, \\(Z\\)와 \\(X\\)가 주어졌을 때 \\(P\\)가 가질 수 있는 조건부 확률 분포(Conditional Probability Distribution) 전체를 추정하는 것입니다.\n\n\n\n1.2. The Mixture Density Network (MDN)\n\n복잡한 분포를 유연하게 추정하기 위해, Deep IV는 MDN(Mixture Density Network) 구조를 사용합니다.\n이는 신경망의 출력을 이용해 가우시안 혼합 모델(Gaussian Mixture Model, GMM)의 파라미터를 구성하는 방식입니다.\n\n\\[\\hat{F}(p|z,x) = \\sum_{k=1}^{K} \\pi_k(z,x) \\mathcal{N}(p ; \\mu_k(z,x), \\sigma_k^2(z,x))\\]\n\n이 수식의 의미는 다음과 같습니다.\n\\(\\mathcal{N}\\) (Normal Distribution): \\(K\\)개의 정규분포를 섞어서 복잡한 분포를 표현합니다.\n신경망의 역할: 입력(\\(Z, X\\))을 받아 각 정규분포의 파라미터 3가지를 출력합니다.\n\n\\(\\pi_k\\) (Mixing Coefficient): \\(k\\)번째 정규분포가 선택될 확률 (가중치, \\(\\sum \\pi_k = 1\\))\n\\(\\mu_k\\) (Mean): \\(k\\)번째 정규분포의 중심 (평균)\n\\(\\sigma_k\\) (Standard Deviation): \\(k\\)번째 정규분포의 퍼짐 정도 (분산)\n\n\n\n\n1.3. Deep IV Architecture: Treatment Network\n\n논문에서 제시하는 네트워크 구조를 도식화하면 다음과 같습니다.\n\n\nInput: 도구변수(\\(Z\\))와 공변량(\\(X\\))이 신경망에 들어갑니다.\n\n\nHidden Layers: 데이터의 비선형적인 패턴을 학습합니다.\n\n\nOutput Heads: 마지막 층은 세 갈래로 나뉩니다.\n\n\nSoftmax \\(\\rightarrow\\) \\(\\pi\\) (가중치)\nLinear \\(\\rightarrow\\) \\(\\mu\\) (평균)\nSoftplus \\(\\rightarrow\\) \\(\\sigma\\) (표준편차, 양수 제약)\n\n\n\n\n\nCode\nclass FirstStageMDN(nn.Module):\n    def __init__(self, input_dim, num_gaussians=5):\n        super().__init__()\n        self.shared_layer = nn.Sequential(\n            nn.Linear(input_dim, 64),\n            nn.ReLU(),\n            nn.Linear(64, 64),\n            nn.ReLU()\n        )\n        self.pi_head = nn.Linear(64, num_gaussians)     # 혼합 계수\n        self.mu_head = nn.Linear(64, num_gaussians)     # 평균\n        self.sigma_head = nn.Linear(64, num_gaussians)  # 표준편차\n\n    def forward(self, x, z):\n        # 1. 입력 결합\n        # Shape: (Batch, x_dim) + (Batch, z_dim) -&gt; (Batch, input_dim)\n        inputs = torch.cat([x, z], dim=1)\n        \n        # 2. 특징 추출\n        # Shape: (Batch, input_dim) -&gt; (Batch, 64)\n        features = self.shared_layer(inputs)\n        \n        # 3. 파라미터 추정 (K=num_gaussians)\n        # Pi: (Batch, K)\n        pi = F.softmax(self.pi_head(features), dim=1)\n        # Mu: (Batch, K)\n        mu = self.mu_head(features)\n        # Sigma: (Batch, K)\n        sigma = F.softplus(self.sigma_head(features)) + 1e-5\n        \n        return pi, mu, sigma\n\n    def sample(self, pi, mu, sigma, n_samples=1):\n        mix = D.Categorical(probs=pi)\n        comp = D.Normal(loc=mu, scale=sigma)\n        gmm = D.MixtureSameFamily(mix, comp)\n        \n        # 샘플링 수행\n        if n_samples == 1:\n            # Shape: (Batch) -&gt; (Batch, 1)\n            return gmm.sample().unsqueeze(-1)\n        else:\n            # Shape: (n_samples, Batch) -&gt; (Batch, n_samples)\n            return gmm.sample((n_samples,)).permute(1, 0)\n\n\n\n\n1.4. Optimization Objective (Negative Log-Likelihood)\n\n이 신경망을 학습시키기 위해 사용하는 손실 함수는 음의 로그 우도(Negative Log-Likelihood, NLL)입니다.\n\n\\[\\mathcal{L}_1(\\phi) = - \\sum_{i=1}^{N} \\log \\left( \\sum_{k=1}^{K} \\pi_k(z_i, x_i) \\cdot \\frac{1}{\\sqrt{2\\pi}\\sigma_k(z_i, x_i)} \\exp \\left( -\\frac{(p_i - \\mu_k(z_i, x_i))^2}{2\\sigma_k^2(z_i, x_i)} \\right) \\right)\\]\n\n쉽게 말해, “실제 관측된 가격 데이터(\\(p_i\\))가 우리 모델의 확률 분포에서 등장할 확률을 최대화하라”는 뜻입니다.\n이를 통해 신경망은 데이터가 뭉쳐 있는 곳(Mode)과 퍼져 있는 정도(Variance)를 정확하게 학습하게 됩니다.\n\n\n\nCode\ndef first_stage_loss_fn(pi, mu, sigma, p):\n    # 1. 로그 확률 밀도 계산 (Log Probability)\n    # Shape: (Batch, K)\n    m = D.Normal(loc=mu, scale=sigma)\n    log_probs_component = m.log_prob(p)\n    \n    # 2. 가중치 반영 및 Log-Sum-Exp\n    # Shape: (Batch, K) -&gt; (Batch,)\n    weighted_log_probs = torch.log(pi + 1e-8) + log_probs_component\n    log_likelihood = torch.logsumexp(weighted_log_probs, dim=1)\n    \n    # 3. NLL 평균 (Scalar)\n    return -torch.mean(log_likelihood)"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-03/index.html#stage-2-outcome-network",
    "href": "posts/lecture/L13/causal-inference-13-part-03/index.html#stage-2-outcome-network",
    "title": "[Causal Inference] 13. IV (Part 3)",
    "section": "Stage 2: Outcome Network",
    "text": "Stage 2: Outcome Network\n\n1단계에서 우리는 가격(\\(P\\))이 형성되는 확률 분포 \\(\\hat{F}(P|Z,X)\\)를 얻었습니다.\n이제 두 번째 단계에서는 이를 바탕으로 진짜 인과 함수(Causal Function) \\(g(P, X)\\)를 찾아낼 차례입니다.\n\n\n2.1. The Structural Equation\n\n우리의 목표는 다음 식을 만족하는 함수 \\(g\\)를 찾는 것입니다.\n\n\\[E[Y | Z, X] = \\int g(p, x) dF(p | z, x)\\]\n\n이 식은 “도구변수(\\(Z\\))와 공변량(\\(X\\))이 주어졌을 때, 예상되는 판매량(\\(Y\\))의 평균은, 가능한 모든 가격(\\(p\\))에 대해 해당 가격일 확률과 그 때의 판매량을 곱해서 더한(적분한) 것과 같다”는 의미입니다.\n여기서 중요한 점은 우리가 1단계 모델(MDN)을 통해 분포 \\(F\\)를 이미 알고 있다는 것입니다.\n따라서 남은 미지수인 함수 \\(g\\)를 신경망으로 근사할 수 있습니다.\n\n\n\n2.2. The Loss Function (Inverse Problem)\n\n2단계 신경망(Outcome Network)을 학습시키기 위한 손실 함수는 다음과 같이 정의됩니다. \\[L(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} \\left( y_i - \\int g_{\\theta}(p, x_i) d\\hat{F}_{\\phi}(p | z_i, x_i) \\right)^2\\]\n\n\\(y_i\\): 실제 관측된 결과 (Target)\n\\(\\int g_{\\theta} d\\hat{F}_{\\phi}\\): 1단계 모델의 분포를 반영한 예측값 (Prediction)\n\n이 손실 함수의 핵심 아이디어는 “내생성이 있는 개별 \\(P\\)값 하나를 믿는 대신, 1단계 모델이 예측한 \\(P\\)의 ’분포 전체’를 믿겠다”는 것입니다.\n분포를 적분하여 얻은 기댓값이 실제 \\(Y\\)와 일치하도록 강제함으로써, 오차항(\\(\\epsilon\\))의 영향을 상쇄시킵니다.\n\n\n\n2.3. Deep IV Architecture: Outcome Network\n\n2단계 네트워크의 작동 방식은 다음과 같습니다.\n\n\nInput: 1단계 분포에서 샘플링된 \\(\\hat{P}\\)와 공변량 \\(X\\)를 입력받습니다.\n\n\nHidden Layers: 인과 함수 \\(g(P,X)\\)의 형태(예: 비선형 S자 곡선)를 학습합니다.\n\n\nOutput: 예측된 \\(Y\\)값을 출력합니다.\n\n\n\n\n\nCode\nclass SecondStageH(nn.Module):\n    def __init__(self, x_dim, p_dim=1, output_dim=1):\n        super().__init__()\n        input_dim = x_dim + p_dim\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, 128),\n            nn.ReLU(),\n            nn.Linear(128, 128),\n            nn.ReLU(),\n            nn.Linear(128, output_dim)\n        )\n        \n    def forward(self, p, x):\n        # 입력 결합\n        # Shape: (Batch, S, p_dim) + (Batch, S, x_dim) -&gt; (Batch, S, input_dim)\n        inputs = torch.cat([p, x], dim=-1) \n        return self.net(inputs)\n\n\n\n\n2.4. Monte Carlo Approximation\n\n현실적으로 딥러닝 학습 중에 복잡한 적분(\\(\\int\\))을 매번 계산하는 것은 불가능에 가깝습니다.\n따라서 Deep IV는 몬테카를로 샘플링(Monte Carlo Sampling)을 사용하여 적분을 근사합니다. \\[\\int g_{\\theta}(p, x_i) d\\hat{F}_{\\phi}(p | z_i, x_i) \\approx \\frac{1}{S} \\sum_{s=1}^{S} g_{\\theta}(\\hat{p}^{(s)}, x_i)\\]\n\n여기서 \\(\\hat{p}^{(s)}\\)는 1단계 MDN 모델에서 샘플링한 값들입니다 (\\(\\hat{p}^{(s)} \\sim \\hat{F}_{\\phi}\\)).\n\\(S\\)는 샘플 개수입니다 (보통 10~30개 사용).\n\n즉, “1단계 모델이 시뮬레이션한 가상의 가격들(\\(\\hat{p}\\))을 2단계 모델에 넣어보고, 그 평균값이 실제 판매량(\\(y\\))과 비슷해지도록” 학습하는 것입니다.\n\n\n\nCode\ndef second_stage_loss_fn(treatment_net, outcome_net, pi, mu, sigma, x, y, num_samples=32):\n    # 1. 몬테카를로 샘플링\n    # Shape: (Batch, S) -&gt; (Batch, S, 1)\n    p_samples = treatment_net.sample(pi, mu, sigma, n_samples=num_samples).unsqueeze(-1).detach()\n    \n    # 2. 공변량 차원 확장\n    # Shape: (Batch, x_dim) -&gt; (Batch, S, x_dim)\n    batch_size, x_dim = x.shape\n    x_expanded = x.unsqueeze(1).expand(-1, num_samples, -1)\n    \n    # 3. 결과 예측 (Outcome Network Forward)\n    # Shape: (Batch, S, 1) + (Batch, S, x_dim) -&gt; (Batch, S, 1)\n    y_pred_samples = outcome_net(p_samples, x_expanded)\n    \n    # 4. 기댓값 근사 (Sample Mean)\n    # Shape: (Batch, S, 1) -&gt; (Batch, 1)\n    y_pred_expectation = y_pred_samples.mean(dim=1)\n    \n    # 5. 손실 계산 (MSE)\n    # Shape: (Batch, 1) vs (Batch, 1) -&gt; Scalar\n    loss = F.mse_loss(y_pred_expectation, y.view(-1, 1))\n    \n    return loss"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-03/index.html#training-procedure",
    "href": "posts/lecture/L13/causal-inference-13-part-03/index.html#training-procedure",
    "title": "[Causal Inference] 13. IV (Part 3)",
    "section": "Training Procedure",
    "text": "Training Procedure\n\nDeep IV의 학습은 일반적인 지도 학습(Supervised Learning)과는 다르게, 순차적인 두 단계(Sequential Two-Stage Process)로 진행됩니다.\n\n\nPhase 1: Distribution Learning (Treatment Network)\n\n첫 번째 단계에서는 Treatment Network만을 학습시킵니다.\n\n목표: 도구변수(\\(Z\\))와 공변량(\\(X\\))을 보고, 처치변수(\\(P\\))가 어떻게 분포하는지 완벽하게 모사하는 것입니다.\n학습 방법: NLL Loss를 최소화하여 실제 데이터 \\(P\\)가 모델의 확률 분포 안에 위치할 확률을 높입니다.\n주의점: 이때 결과변수 \\(Y\\)는 전혀 사용하지 않습니다.\n\n\n\n\nTransition: The Freeze\n\n1단계 학습이 끝나면 Treatment Network의 파라미터(\\(\\phi\\))를 동결(Freeze)합니다.\n이제 1단계 모델은 더 이상 학습 대상이 아니라, 내생성이 제거된 가상의 처치값 \\(\\hat{P}\\)를 생성해내는 시뮬레이터(Generator) 역할을 수행합니다.\n\n\n\nPhase 2: Causal Learning (Outcome Network)\n\n두 번째 단계에서는 Outcome Network를 학습시킵니다.\n\n입력: 실제 관측된 \\(P\\)를 사용하는 것이 아니라, 동결된 1단계 모델에서 샘플링한 \\(\\hat{P}\\)를 사용합니다.\n목표: \\(\\hat{P}\\)를 입력받았을 때의 예측값 평균이 실제 \\(Y\\)와 가까워지도록 합니다.\n학습 방법: MSE Loss를 최소화하여 인과 함수 \\(g(P, X)\\)를 근사합니다.\n\n\n\n\nCode\n# -----------------------------------------------------\n# [Stage 1] Treatment Network Training (Z + X -&gt; P distribution)\n# -----------------------------------------------------\ntreatment_net = FirstStageMDN(\n    input_dim=X.shape[-1] + Z.shape[-1], \n    num_gaussians=5\n)\n\nopt1 = optim.Adam(treatment_net.parameters(), lr=1e-4)\nepochs_stage1 = 1000\n\nprint(f\"Starting Stage 1 Training (Epochs: {epochs_stage1})...\")\n\ntreatment_net.train()\nfor epoch in range(epochs_stage1):\n    # 1. Forward Pass\n    pi, mu, sigma = treatment_net(X, Z)\n    # 2. Loss Calculation (Negative Log Likelihood)\n    loss1 = first_stage_loss_fn(pi, mu, sigma, P)\n    # 3. Optimization\n    opt1.zero_grad()\n    loss1.backward()\n    opt1.step()\n    \n    if (epoch + 1) % 100 == 0:\n        print(f\"[Stage 1] Epoch [{epoch+1}/{epochs_stage1}] | Loss: {loss1:.4f} | Avg Sigma: {sigma.mean().item():.4f}\")\n\n# -----------------------------------------------------\n# [Transition] Freeze Stage 1\n# -----------------------------------------------------\ntreatment_net.eval()\nfor param in treatment_net.parameters():\n    param.requires_grad = False\nprint(\"Stage 1 Freezed.\")\n\n# -----------------------------------------------------\n# [Stage 2] Outcome Network Training (Resampled P + X -&gt; Y)\n# -----------------------------------------------------\noutcome_net = SecondStageH(\n    x_dim=X.shape[-1], \n    p_dim=1, \n    output_dim=1\n)\n\nopt2 = optim.Adam(outcome_net.parameters(), lr=1e-4)\nepochs_stage2 = 1000\n\nprint(f\"\\nStarting Stage 2 Training (Epochs: {epochs_stage2})...\")\n\noutcome_net.train()\nfor epoch in range(epochs_stage2):\n    total_loss = 0\n\n    with torch.no_grad():\n        pi, mu, sigma = treatment_net(X, Z)\n    \n    # 2단계 Loss 계산\n    loss2 = second_stage_loss_fn(\n        treatment_net=treatment_net,\n        outcome_net=outcome_net, \n        pi=pi, \n        mu=mu, \n        sigma=sigma, \n        x=X, \n        y=Y, \n        num_samples=20 \n    )\n    # Optimization\n    opt2.zero_grad()\n    loss2.backward()\n    opt2.step()\n\n    \n    if (epoch + 1) % 100 == 0:\n        print(f\"[Stage 2] Epoch [{epoch+1}/{epochs_stage2}] | Loss: {loss2:.4f}\")\n   \nprint(\"Deep IV Training Complete.\")\n\n\nStarting Stage 1 Training (Epochs: 1000)...\n[Stage 1] Epoch [100/1000] | Loss: 1.2246 | Avg Sigma: 0.7426\n[Stage 1] Epoch [200/1000] | Loss: 0.8651 | Avg Sigma: 0.6943\n[Stage 1] Epoch [300/1000] | Loss: 0.4267 | Avg Sigma: 0.5430\n[Stage 1] Epoch [400/1000] | Loss: 0.0645 | Avg Sigma: 0.3683\n[Stage 1] Epoch [500/1000] | Loss: -0.1064 | Avg Sigma: 0.2715\n[Stage 1] Epoch [600/1000] | Loss: -0.4534 | Avg Sigma: 0.1886\n[Stage 1] Epoch [700/1000] | Loss: -0.7542 | Avg Sigma: 0.1364\n[Stage 1] Epoch [800/1000] | Loss: -0.9869 | Avg Sigma: 0.1000\n[Stage 1] Epoch [900/1000] | Loss: -1.2780 | Avg Sigma: 0.0781\n[Stage 1] Epoch [1000/1000] | Loss: -1.1258 | Avg Sigma: 0.0643\nStage 1 Freezed.\n\nStarting Stage 2 Training (Epochs: 1000)...\n[Stage 2] Epoch [100/1000] | Loss: 0.1575\n[Stage 2] Epoch [200/1000] | Loss: 0.0995\n[Stage 2] Epoch [300/1000] | Loss: 0.0867\n[Stage 2] Epoch [400/1000] | Loss: 0.0775\n[Stage 2] Epoch [500/1000] | Loss: 0.0773\n[Stage 2] Epoch [600/1000] | Loss: 0.0631\n[Stage 2] Epoch [700/1000] | Loss: 0.0811\n[Stage 2] Epoch [800/1000] | Loss: 0.0609\n[Stage 2] Epoch [900/1000] | Loss: 0.0585\n[Stage 2] Epoch [1000/1000] | Loss: 0.0580\nDeep IV Training Complete."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-03/index.html#result-visualization",
    "href": "posts/lecture/L13/causal-inference-13-part-03/index.html#result-visualization",
    "title": "[Causal Inference] 13. IV (Part 3)",
    "section": "Result Visualization",
    "text": "Result Visualization\n\n학습된 모델이 실제 인과 효과 곡선(Ground Truth)을 얼마나 잘 복원했는지 확인합니다.\n테스트는 성수기와 비성수기의 중간(\\(X=0.5\\)) 조건을 가정합니다.\n\n\n\nCode\n# ===========================================================\n# 1. 테스트 데이터 생성\n# ===========================================================\np_min, p_max = P_data.min(), P_data.max()\np_test = np.linspace(p_min, p_max, 200).reshape(-1, 1)\n\nfixed_x_val = 0.5\nx_test = np.full_like(p_test, fixed_x_val)\n\ndef true_structural_function(p_val, x_val):\n    threshold = 35 + (40 * x_val)\n    base_effect = 150 / (1 + np.exp(0.8 * (p_val - threshold)))\n    return base_effect + (50 * x_val)\n        \ntrue_y = true_structural_function(p_test, x_test)\n\n# ===========================================================\n# 2. Linear 2SLS 예측\n# ===========================================================\npx_test_linear = np.concatenate((p_test, x_test), axis=1)\nlinear_pred = stage2_model.predict(px_test_linear)\n\n# ===========================================================\n# 3. DeepIV 예측\n# ===========================================================\noutcome_net.eval()\n\np_test_scaled = scaler_p.transform(p_test)\nx_test_scaled = scaler_x.transform(x_test)\np_tensor = torch.tensor(p_test_scaled, dtype=torch.float32)\nx_tensor = torch.tensor(x_test_scaled, dtype=torch.float32)\n\nwith torch.no_grad():\n    y_pred_scaled = outcome_net(p_tensor, x_tensor)    \n    deep_pred = scaler_y.inverse_transform(y_pred_scaled.numpy())\n\n# ===========================================================\n# 4. 최종 시각화\n# ===========================================================\nplt.figure(figsize=(12, 8))\n\n# 배경: 관측 데이터\nplt.scatter(P_data, Y_data, color='gray', alpha=0.1, s=10, label='Observed Data')\n\n# 1. Ground Truth (검은 실선)\nplt.plot(p_test, true_y, 'k-', linewidth=3, label='Ground Truth')\n\n# 2. Linear 2SLS (빨간 점선)\nplt.plot(p_test, linear_pred, 'r--', linewidth=2.5, label='Linear 2SLS')\n\n# 3. Deep IV (파란 실선)\nplt.plot(p_test, deep_pred, 'b-', linewidth=2.5, label='Deep IV')\n\nplt.title(f\"Causal Effect Estimation: Non-linear Pricing (at Seasonality X={fixed_x_val})\", fontsize=16, weight='bold')\nplt.xlabel(\"Treatment: Ticket Price (P)\", fontsize=13)\nplt.ylabel(\"Outcome: Sales (Y)\", fontsize=13)\nplt.legend(fontsize=12, loc='upper right', framealpha=0.9)\nplt.grid(True, alpha=0.3, linestyle='--')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nComparison of Causal Effect Estimation"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-03/index.html#conclusion",
    "href": "posts/lecture/L13/causal-inference-13-part-03/index.html#conclusion",
    "title": "[Causal Inference] 13. IV (Part 3)",
    "section": "Conclusion",
    "text": "Conclusion\n\n결과 그래프에서 볼 수 있듯이:\n\n\nLinear 2SLS는 데이터의 비선형성을 무시하고 단순한 직선으로 효과를 추정하여, 가격 임계값 근처에서의 급격한 수요 변화를 포착하지 못합니다.\n\n\nDeep IV는 실제 인과 곡선(Ground Truth)인 S자 형태를 매우 정확하게 복원해냈습니다.\n\n\n이는 비선형성이 강하게 의심될 때, 딥러닝 기반의 인과추론 방법론이 강력한 대안이 될 수 있음을 시사합니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "",
    "text": "인과추론에서 우리가 관심을 가지는 것은 처치(Treatment, \\(X\\))가 결과(Outcome, \\(Y\\))에 미치는 인과적 효과(\\(\\beta_1\\))를 추정하는 것입니다.\n하지만 많은 경우 관찰되지 않은 교란 요인(Unobserved Confounder)이 존재하여 단순한 회귀분석(OLS)으로는 편향된 추정치를 얻게 됩니다.\n이때 사용할 수 있는 강력한 도구가 바로 도구변수(Instrumental Variable, IV)입니다.\n이 글에서는 선형 가정(Linear Assumption) 하에서의 IV, 특히 2SLS (Two-Stage Least Squares) 접근법과 그 유도 과정을 다룹니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#인과-모형-causal-graph",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#인과-모형-causal-graph",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "2.1. 인과 모형 (Causal Graph)",
    "text": "2.1. 인과 모형 (Causal Graph)\n\n우선 변수들 간의 관계를 DAG(Directed Acyclic Graph)로 표현하면 다음과 같습니다.\n\n\n\n\nFigure 1: IV Causal Graph. Z는 도구변수, X는 처치, Y는 결과, W는 공변량, ε는 관찰되지 않은 오차항을 의미합니다.\n\n\n\n\\(Z\\): 도구변수 (Instrument)\n\\(X\\): 처치변수 (Treatment) - Endogenous (내생적)\n\\(Y\\): 결과변수 (Outcome)\n\\(W\\): 공변량 (Covariates) - Exogenous (외생적)\n\\(\\epsilon\\): 오차항 (Error term/Unobserved Confounders)"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#선형-모형과-ols의-한계",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#선형-모형과-ols의-한계",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "2.2. 선형 모형과 OLS의 한계",
    "text": "2.2. 선형 모형과 OLS의 한계\n\n전통적인 선형 모형은 다음과 같이 설정됩니다.\n\n\\[Y_i = \\beta_0 + \\beta_1 X_i + \\beta_2 W_i + \\epsilon_i\\]\n\n여기서 우리의 관심 추정량(estimand)은 \\(X_i\\)의 계수인 \\(\\beta_1\\)입니다.\n하지만 Challenge가 발생합니다.\n오차항 \\(\\epsilon_i\\)가 처치 변수 \\(X_i\\)와 상관관계를 가질 때(Dependent/Confounded), 이를 내생성(Endogeneity)이 있다고 합니다.\n\n\nNote:\n\nEndogenous (내생변수): \\(Y\\)와 관련된 교란요인(confounder)과 상관관계가 있는 변수 (\\(X\\))\nExogenous (외생변수): 교란요인과 상관관계가 없는 변수 (\\(W\\))\n\n\n\n만약 \\(X\\)가 내생적이라면, \\(\\beta_1\\)에 대한 직접적인 OLS(Ordinary Least Squares) 추정량은 편향(Biased)됩니다.\n즉, \\(Cov(X, \\epsilon) \\neq 0\\)인 상황입니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#iv의-조건",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#iv의-조건",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "3.1. IV의 조건",
    "text": "3.1. IV의 조건\n\n이 문제를 해결하기 위해 도입하는 도구변수 벡터 \\(Z\\) (\\(K\\)차원)는 다음 두 가지 조건을 만족해야 합니다.\n\n\nRelevance (관련성): 도구변수 \\(Z\\)는 처치 \\(X\\)와 관련이 있어야 합니다. (그래프 상에서 \\(Z \\rightarrow X\\) 경로 존재)\nExclusion Restriction (배제 제약) & Independence: 도구변수 \\(Z\\)는 오직 \\(X\\)를 통해서만 \\(Y\\)에 영향을 미쳐야 하며, 교란요인 \\(\\epsilon\\)과 독립이어야 합니다.\n\n\\(\\epsilon_i \\perp W_i\\)\n\\(\\epsilon_i \\perp Z_i | W_i\\)\n즉, \\(\\epsilon_i \\perp (Z_i, W_i)\\)"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#식별-identification",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#식별-identification",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "3.2. 식별 (Identification)",
    "text": "3.2. 식별 (Identification)\n도구변수의 개수(\\(K\\))와 내생변수의 개수에 따라 모델의 식별 상태가 달라집니다.\n\nOver-identified (과잉 식별): \\(K &gt; 1\\) (도구변수가 내생변수보다 많음)\nJust-identified (적정 식별): \\(K = 1\\) (도구변수와 내생변수 개수가 같음)"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#just-indentified-no-covariates",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#just-indentified-no-covariates",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "4.1. Just-indentified, No Covariates",
    "text": "4.1. Just-indentified, No Covariates\n\nJust-identified 케이스 (\\(K=1\\))를 기준으로 세 가지 해석 방식을 살펴보겠습니다.\n이때 공변량(W)는 없다고 가정합니다.\n결론적으로 이 세 가지는 모두 동일한 \\(\\beta_1\\) 값을 도출합니다.\n\n\n4.1.1. 공분산의 비율 (Ratio of Covariance)\n\n가장 직관적인 IV 추정량은 \\(Y\\)와 \\(Z\\)의 공분산을 \\(X\\)와 \\(Z\\)의 공분산으로 나눈 것입니다.\n\n\\[\\hat{\\beta}_{1, iv} = \\frac{\\widehat{Cov}(Y_i, Z_i)}{\\widehat{Cov}(X_i, Z_i)} = \\frac{\\frac{1}{N}\\sum(Y_i - \\bar{Y})(Z_i - \\bar{Z})}{\\frac{1}{N}\\sum(X_i - \\bar{X})(Z_i - \\bar{Z})}\\]\n\nWald Estimator (Binary IV의 경우):\n\n만약 도구변수 \\(Z\\)가 0과 1만 가지는 이진 변수라면, 이는 Wald Estimator가 됩니다. \\[\\hat{\\beta}_{1, iv} = \\frac{\\bar{Y}_1 - \\bar{Y}_0}{\\bar{X}_1 - \\bar{X}_0}\\]\n여기서 \\(\\bar{Y}_z, \\bar{X}_z\\)는 \\(Z=z\\)인 그룹 내에서의 평균을 의미합니다.\n\n\n\n\n4.1.2. 간접 최소제곱법 (Indirect Least Squares, ILS)\n\nILS는 두 개의 축약형(Reduced form) 회귀식을 이용하는 방식입니다.\n\n\nReduced Form 1 (\\(Y\\) on \\(Z\\)): \\(Y_i = \\pi_{10} + \\pi_{11} Z_i + \\epsilon_{1i}\\)\nReduced Form 2 (\\(X\\) on \\(Z\\)): \\(X_i = \\pi_{20} + \\pi_{21} Z_i + \\epsilon_{2i}\\)\n\n\nILS 추정량은 두 회귀계수의 비율로 정의됩니다.\n\n\\[\\hat{\\beta}_{1, ils} = \\frac{\\hat{\\pi}_{11}}{\\hat{\\pi}_{21}}\\]\n\n\n4.1.3. 2단계 최소제곱법 (Two Stage Least Squares, 2SLS)\n\n가장 널리 쓰이는 직관적인 방법으로, \\(X\\)에서 내생성을 제거한 후 회귀분석을 수행하는 방식입니다.\nStage 1: 내생변수 \\(X\\)를 도구변수 \\(Z\\)로 예측합니다. (OLS 수행) \\[X_i = \\pi_0 + \\pi_1 Z_i + \\epsilon_i\\] \\[\\Longrightarrow \\hat{X}_i = \\hat{\\pi}_0 + \\hat{\\pi}_1 Z_i\\]\nStage 2: 원래의 \\(X\\) 대신 예측된 \\(\\hat{X}\\)를 사용하여 결과 모형을 추정합니다. \\[Y_i = \\pi_2 + \\pi_3 \\hat{X}_i + \\epsilon_i\\] 여기서 구해진 \\(\\hat{\\pi}_3\\)가 바로 2SLS 추정량 \\(\\hat{\\beta}_{1, 2sls}\\)입니다.\n\n\nIntuition:\n1단계를 통해 \\(X\\)의 변동 중 \\(Z\\)에 의해 설명되는 부분(즉, 오차항 \\(\\epsilon\\)과 상관없는 “unconfounded portion”)만을 추출하여 2단계에서 인과 효과를 추정하는 것입니다.\n\n\n\n4.1.4. 결론\n\n위의 세 방식에 따른 추정치는 모두 동일합니다.\n\n\\[\\hat{\\beta}_{1, iv} = \\hat{\\beta}_{1, ils} = \\hat{\\beta}_{1, 2sls}\\]"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#just-indentified-with-covariates",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#just-indentified-with-covariates",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "4.2. Just-indentified, With Covariates",
    "text": "4.2. Just-indentified, With Covariates\n\nJust-identified 케이스 (\\(K=1\\))를 기준으로 두 가지 해석 방식을 살펴보겠습니다.\n이때 공변량(W)을 함께 고려합니다.\n결론적으로 이 두 가지는 모두 동일한 \\(\\beta_1\\) 값을 도출합니다.\n\n\n4.2.2. 간접 최소제곱법 (Indirect Least Squares, ILS)\n\nILS는 두 개의 축약형(Reduced form) 회귀식을 이용하는 방식입니다.\n\n\nReduced Form 1 (\\(Y\\) on \\(Z\\)): \\(Y_i = \\pi_{10} + \\pi_{11} Z_i + \\pi_{12} W_i + \\epsilon_{1i}\\)\nReduced Form 2 (\\(X\\) on \\(Z\\)): \\(X_i = \\pi_{20} + \\pi_{21} Z_i + \\pi_{22} Z_i + \\epsilon_{2i}\\)\n\n\nILS 추정량은 두 회귀계수의 비율로 정의됩니다.\n\n\\[\\hat{\\beta}_{1, ils} = \\frac{\\hat{\\pi}_{11}}{\\hat{\\pi}_{21}}\\]\n\n\n4.2.2. 2단계 최소제곱법 (Two Stage Least Squares, 2SLS)\n\n가장 널리 쓰이는 직관적인 방법으로, \\(X\\)에서 내생성을 제거한 후 회귀분석을 수행하는 방식입니다.\nStage 1: 내생변수 \\(X\\)를 도구변수 \\(Z\\)로 예측합니다. (OLS 수행) \\[X_i = \\pi_0 + \\pi_1 Z_i + \\pi_2 W_i + \\epsilon_{1i}\\] \\[\\Longrightarrow \\hat{X}_i = \\hat{\\pi}_0 + \\hat{\\pi}_1 Z_i + \\hat{\\pi}_2 W_i \\]\nStage 2: 원래의 \\(X\\) 대신 예측된 \\(\\hat{X}\\)를 사용하여 결과 모형을 추정합니다. \\[Y_i = \\beta_0 + \\beta_1 \\hat{X}_i + \\beta_2 W_i + \\epsilon_{2i}\\] 여기서 구해진 \\(\\hat{\\beta}_1\\)이 바로 2SLS 추정량 \\(\\hat{\\beta}_{1, 2sls}\\)입니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#설정-setup",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#설정-setup",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "5.1. 설정 (Setup)",
    "text": "5.1. 설정 (Setup)\n\n우리는 다음 두 식을 관찰할 수 있습니다.\n\n\nFirst Stage (X에 대한 식): \\[X_i = \\pi_0 + \\pi_1 Z_i + \\pi_2 W_i + \\epsilon_{1i}\\]\nStructural Model (Y에 대한 식): \\[Y_i = \\beta_0 + \\beta_1 {X}_i + \\underbrace{\\beta_2 {W}_i + \\epsilon_{2i}}_{\\eta_{i}}\\]\n\n\n가정: \\(Cov[X_i, \\eta_i] \\neq 0\\) (내생성 존재), 하지만 \\(Cov[\\eta_i, Z_i] = 0\\) (도구변수의 외생성)."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#iv-estimator-유도-ratio-방식",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#iv-estimator-유도-ratio-방식",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "5.2. IV Estimator 유도 (Ratio 방식)",
    "text": "5.2. IV Estimator 유도 (Ratio 방식)\n\n\\(Y_i\\) 식의 양변과 \\(Z_i\\)의 공분산을 취해봅시다.\n\n\\[\n\\begin{aligned}\nCov[Y_i, Z_i] &= Cov[\\beta_0 + \\beta_1 X_i + \\eta_i, \\; Z_i] \\\\\n&= \\beta_1 Cov[X_i, Z_i] + \\underbrace{Cov[\\eta_i, Z_i]}_{0 \\text{ (by assumption)}} \\\\\n&= \\beta_1 Cov[X_i, Z_i]\n\\end{aligned}\n\\]\n\n따라서, \\(\\beta_1\\)에 대해 정리하면 다음과 같습니다.\n\n\\[\\beta_1 = \\frac{Cov[Y_i, Z_i]}{Cov[X_i, Z_i]} = \\frac{Cov[Y_i, Z_i] / Var[Z_i]}{Cov[X_i, Z_i] / Var[Z_i]} = \\frac{\\text{Reduced form slope}}{\\text{First stage slope}}\\]\n\n이 유도 과정은 ILS 방식(\\(\\pi_{11}/\\pi_{21}\\))과 정확히 일치함을 보여줍니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#sls-estimator-유도-substitution-방식",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#sls-estimator-유도-substitution-방식",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "5.3. 2SLS Estimator 유도 (Substitution 방식)",
    "text": "5.3. 2SLS Estimator 유도 (Substitution 방식)\n\n2SLS가 어떻게 작동하는지 수식 대입을 통해 확인해 봅시다.\n\\(Y\\) 식의 \\(X_i\\) 자리에 First Stage 식(\\(\\pi_0 + \\pi_1 Z_i + \\pi_2 W_i + \\epsilon_{1i}\\))을 대입합니다.\n\n\\[\n\\begin{aligned}\nY_i &= \\beta_0 + \\beta_1 {X}_i + \\beta_2 {W}_i + \\epsilon_{2i} \\\\\n&= \\beta_0 + \\beta_1(\\pi_0 + \\pi_1 Z_i + \\pi_2 W_i + \\epsilon_{1i}) + \\beta_2 {W}_i + \\epsilon_{2i} \\\\\n&= \\beta_0 + \\beta_1 (\\pi_0 + \\pi_1 Z_i + \\pi_2 {W}_i) + \\beta_2 {W}_i + \\underbrace{\\beta_1 \\epsilon_{1i} + \\epsilon_{2i}}_{\\xi_i} \\\\\n\\end{aligned}\n\\]\n\n이를 다시 정리하면, \\(\\pi_0 + \\pi_1 Z_i + \\pi_2 {W}_i\\) 부분은 \\(E[X_i | W_i, Z_i]\\) 즉, \\(\\hat{X}_i\\)의 핵심 부분임을 알 수 있습니다.\n\n\\[Y_i = \\beta_0 + \\underbrace{\\beta_1 E[X_i | W_i, Z_i]}_{\\hat{X_i}} + \\beta_2 W_i + \\xi_i\\]\n\n결국 \\(Y\\)를 \\(\\hat{X}\\)와 \\(W\\)에 대해 회귀분석하는 형태가 되며, 이때 \\(\\hat{X}\\)의 계수는 원래 식의 \\(\\beta_1\\)이 됩니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#recap-matrix-notation-for-ols-regression",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#recap-matrix-notation-for-ols-regression",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "6.1. Recap (Matrix Notation for OLS Regression)",
    "text": "6.1. Recap (Matrix Notation for OLS Regression)\n\n6.1.1. 선형 회귀 모형의 행렬 표현\n\n먼저, 선형 회귀 모형을 행렬 형태로 정의해 봅시다. 기본 식은 다음과 같습니다.\n\n\\[\ny = X\\beta + u\n\\]\n\n여기서 각 변수가 의미하는 바를 구체적인 행렬로 풀어서 쓰면 다음과 같습니다. \\(X\\)는 \\(n \\times k\\) 행렬(matrix)입니다.\n\n\\[\ny = \\begin{pmatrix} y_1 \\\\ \\vdots \\\\ y_n \\end{pmatrix}, \\quad\nX = \\begin{pmatrix} x'_1 \\\\ \\vdots \\\\ x'_n \\end{pmatrix}\n= \\begin{pmatrix}\n1 & x_{12} & \\cdots & x_{1k} \\\\\n\\vdots & \\vdots & \\vdots & \\vdots \\\\\n1 & x_{n2} & \\cdots & x_{nk}\n\\end{pmatrix}, \\quad\nu = \\begin{pmatrix} u_1 \\\\ \\vdots \\\\ u_n \\end{pmatrix}\n\\]\n\n\n\n6.1.2. 최소자승법(OLS) 추정량\n\n우리의 목표는 오차의 제곱합을 최소화하는 \\(\\beta\\)의 추정량, 즉 \\(b\\)를 찾는 것입니다.\n이를 위해 목적 함수 \\(S(b)\\)를 다음과 같이 정의합니다.\n이는 관측값(\\(y\\))과 예측값(\\(Xb\\)) 차이의 제곱합입니다.\n\n\\[\nS(b) = (y - Xb)'(y - Xb)\n\\]\n\nOLS 추정량 \\(\\hat{\\beta}\\)는 이 \\(S(b)\\)를 최소화하는 값입니다.\n\n\\[\n\\hat{\\beta} = \\underset{b \\in \\mathbb{R}^k}{\\arg \\min} \\, S(b) = (X'X)^{-1}X'y\n\\]\n\n\n6.1.3. 유도 과정 (Derivation)\n\n\\(S(b)\\)를 최소화하기 위해 \\(b\\)에 대해 미분을 수행합니다.\n\n\n1단계: 1계 조건 (First Order Condition, FOC)\n\n목적 함수를 \\(b\\)로 미분했을 때 0이 되어야 합니다.\n행렬 미분 공식을 적용하면 다음과 같습니다.\n\n\\[\n\\begin{aligned}\n\\text{FOC : } \\quad \\frac{\\partial S(b)}{\\partial b} &= -2X'y + 2X'Xb \\\\\n&= -2X'(y - Xb) = 0\n\\end{aligned}\n\\]\n\n\n2단계: 정규 방정식 (Normal Equation)과 해 구하기\n\n1계 조건(FOC)에 따라, 최적의 추정량 \\(\\hat{\\beta}\\)는 다음의 정규 방정식(Normal Equation)을 만족해야 합니다.\n\n\\[\nX'(y - X\\hat{\\beta}) = 0\n\\]\n\n이 식을 \\(\\hat{\\beta}\\)에 대해 정리해 봅시다.\n\\(X\\)가 Full Rank를 가진다고 가정하면, 역행렬이 존재하므로 유일한 해(unique solution)를 구할 수 있습니다.\n\n\\[\n\\begin{aligned}\nX'y - X'X\\hat{\\beta} &= 0 \\\\\nX'X\\hat{\\beta} &= X'y \\\\\n\\therefore \\quad \\hat{\\beta} &= (X'X)^{-1}X'y\n\\end{aligned}\n\\]\n\n\n\n6.1.4 기하학적 해석 (Geometric Interpretation)\n\n행렬 \\(X\\)를 열 벡터(column vector)들의 집합으로 생각해보겠습니다.\n\n\\[\nX = (x_1, ..., x_k)\n\\]\n\n여기서 \\(x_i\\)는 \\(X\\)의 \\(i\\)번째 열 벡터를 의미합니다.\n이때 종속변수 벡터 \\(y\\)와 설명변수 벡터들 \\(x_1, ..., x_k\\)는 모두 \\(n\\)차원 유클리드 공간 \\(\\mathbb{R}^n\\) 상의 점(혹은 벡터)들입니다.\n\n\n1. Range Space (열공간)의 정의\n\n\\(X\\)의 Range Space (또는 Column Space, 열공간)인 \\(\\mathcal{R}(X)\\)는 다음과 같이 정의됩니다.\n\n\\[\n\\begin{aligned}\n\\mathcal{R}(X) &= \\{ c \\in \\mathbb{R}^n : c = Xb \\text{ for } b \\in \\mathbb{R}^k \\} \\\\\n&= \\{ c \\in \\mathbb{R}^n : c = x_1b_1 + \\cdots + x_kb_k, \\quad b = (b_1, ..., b_k)' \\in \\mathbb{R}^k \\}\n\\end{aligned}\n\\]\n\n즉, \\(\\mathcal{R}(X)\\)는 \\(X\\)의 열 벡터(\\(x_1, ..., x_k\\))들의 선형 결합(linear combination)으로 만들 수 있는 모든 가능한 벡터들의 집합을 의미합니다.\n수학적으로는 \\(X\\)의 열들에 의해 생성(span)된 \\(\\mathbb{R}^n\\)의 선형 부분공간(linear subspace)입니다.\n\n\n\n2. 회귀분석(Regression)에서의 의미\n\n이 기하학적 정의는 회귀분석의 목표를 명확하게 보여줍니다.\n우리가 구하고자 하는 예측값 \\(\\hat{y} = Xb\\)는 정의상 반드시 \\(\\mathcal{R}(X)\\) 안에 존재해야 합니다.\n하지만 실제 관측값 \\(y\\)는 오차(error) 때문에 일반적으로 \\(\\mathcal{R}(X)\\) 바깥에 위치합니다.\n따라서 회귀분석(Regression Problem)은 기하학적으로 다음과 같이 해석됩니다:\n\n\n“\\(\\mathcal{R}(X)\\) 공간 안에 있는 수많은 점들 중에서, 실제 데이터 \\(y\\)와 가장 가까운 점(closest point)을 찾는 과정”\n\n\n이 ’가장 가까운 점’을 찾기 위해 우리는 수직 투영(Orthogonal Projection)을 사용하게 되며, 이것이 바로 최소자승법(OLS)의 원리입니다.\n\n\n\n\nFigure 2: Geometric Interpretation."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#estimating-2sls-models",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#estimating-2sls-models",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "6.2. Estimating 2SLS Models",
    "text": "6.2. Estimating 2SLS Models\n\n1. 모형 설정 및 변수 정의\n\n2SLS(Two-Stage Least Squares) 모형을 추정하기 위해 변수들을 다음과 같이 정의합니다.\n\\(\\mathbf{y}\\): 종속 변수 벡터 (\\(n \\times 1\\))\n\\(\\mathbf{X}\\): 내생 변수(Endogenous variables) 행렬 (\\(n \\times k_1\\))\n\\(\\mathbf{W}\\): 외생 변수(Exogenous regressors) 행렬 (\\(n \\times k_2\\))\n\\(\\mathbf{Z}\\): 도구 변수(Instruments) 행렬. 여기에는 외생 변수 \\(\\mathbf{W}\\)가 포함됩니다. (\\(\\mathbf{Z} = [\\mathbf{Z}_1 \\; \\mathbf{W}]\\))\n우리의 목표는 아래의 2SLS 추정량을 유도하는 것입니다.\n\n\\[\n\\hat{\\Gamma}_{2SLS} = \\left( [\\hat{\\mathbf{X}}\\; \\mathbf{W}]' [\\hat{\\mathbf{X}}\\; \\mathbf{W}] \\right)^{-1} [\\hat{\\mathbf{X}}\\; \\mathbf{W}]' \\mathbf{y}\n\\]\n\n여기서 \\([\\hat{\\mathbf{X}}\\; \\mathbf{W}]\\)는 1단계 회귀분석을 통해 예측된 내생변수 \\(\\hat{\\mathbf{X}}\\)와 기존의 외생변수 \\(\\mathbf{W}\\)를 합친 새로운 설명변수 행렬 (\\(n \\times (k_1 + k_2)\\))입니다.\n이를 원소별로 풀어서 쓰면 다음과 같습니다. \\[\n[\\hat{\\mathbf{X}}\\; \\mathbf{W}] =\n\\begin{pmatrix}\n\\hat{x}_{1,1} & \\cdots & \\hat{x}_{1,k_1} & w_{1,1} & \\cdots & w_{1,k_2} \\\\\n\\vdots & \\ddots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\hat{x}_{n,1} & \\cdots & \\hat{x}_{n,k_1} & w_{n,1} & \\cdots & w_{n,k_2}\n\\end{pmatrix}\n\\]\n\n좌측 블록(\\(\\hat{\\mathbf{X}}\\))은 도구변수(\\(\\mathbf{Z}\\))로 예측된 값들로 구성되어 있고, 우측 블록(\\(\\mathbf{W}\\))은 원래의 외생변수 값들이 그대로 들어갑니다.\n\n\n\n\n\n2. 사영 행렬(Projection Matrix) \\(P_Z\\) 의 도입\n\n도구변수 \\(\\mathbf{Z}\\)에 의한 사영 행렬(Projection Matrix)을 \\(P_Z\\)라고 표기하겠습니다.\n\n\\[\nP_Z = \\mathbf{Z}(\\mathbf{Z}'\\mathbf{Z})^{-1}\\mathbf{Z}'\n\\]\n\n이 행렬 \\(P_Z\\)은 다음과 같은 매우 중요한 두 가지 성질을 가집니다.\n\n\n대칭성 (Symmetric): \\(P_Z' = P_Z\\)\n\n\n멱등성 (Idempotent): \\(P_ZP_Z = P_Z\\)"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#a-부분의-유도-행렬의-곱",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#a-부분의-유도-행렬의-곱",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "3. A 부분의 유도 (행렬의 곱)",
    "text": "3. A 부분의 유도 (행렬의 곱)\n\n추정량의 앞부분인 역행렬 내부, 즉 \\(A = [\\hat{\\mathbf{X}}\\; \\mathbf{W}]' [\\hat{\\mathbf{X}}\\; \\mathbf{W}]\\)를 정리해 봅시다.\n1단계 예측값 \\(\\hat{\\mathbf{X}}\\)는 \\(\\mathbf{X}\\)를 투영한 것이므로 \\(\\hat{\\mathbf{X}} = P_Z\\mathbf{X}\\)입니다.\n외생변수 \\(\\mathbf{W}\\)는 도구변수 \\(\\mathbf{Z}\\)에 포함되므로 \\(R(W) \\subset R(Z)\\) 투영해도 자신이 됩니다. 즉, \\(P_Z\\mathbf{W} = \\mathbf{W}\\)입니다.\n따라서 전체 설명변수 행렬은 \\(P_Z\\)를 묶어 다음과 같이 쓸 수 있습니다.\n\n\\[\n\\begin{aligned} \\\\\n[\\hat{\\mathbf{X}} \\quad \\mathbf{W}] &= [P_Z\\mathbf{X} \\quad P_Z\\mathbf{W}] \\\\\n&= P_Z [\\mathbf{X} \\quad \\mathbf{W}]\n\\end{aligned}\n\\]\n\n이제 편의상 전체 설명변수 행렬을 \\(\\mathbf{R} = [\\mathbf{X} \\quad \\mathbf{W}]\\)라 정의하고 \\(A\\)를 다시 쓰면: \\[A = (P_Z\\mathbf{R})' (P_Z\\mathbf{R})\\]\n\n이때 \\(P_Z\\mathbf{R}\\)는 원래의 변수 행렬(\\(\\mathbf{R}\\))을 도구변수 공간에 투영(\\(P_Z\\))시킨 결과라고 해석할 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#b-부분의-유도-y와의-곱",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#b-부분의-유도-y와의-곱",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "4. B 부분의 유도 (\\(y\\)와의 곱)",
    "text": "4. B 부분의 유도 (\\(y\\)와의 곱)\n\n추정량의 뒷부분인 \\(B = [\\hat{\\mathbf{X}}\\; \\mathbf{W}]' \\mathbf{y}\\) 도 동일한 방식으로 작성합니다.\n\n\\[B = (P_Z\\mathbf{R})' \\mathbf{y}\\]"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#최종-결과-2sls-추정량",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#최종-결과-2sls-추정량",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "5. 최종 결과: 2SLS 추정량",
    "text": "5. 최종 결과: 2SLS 추정량\n\n위의 \\(A\\)와 \\(B\\) 결과를 합치면 다음과 같습니다.\n\n\\[\n\\begin{aligned}\n\\hat{\\Gamma}_{2SLS} &= A^{-1} B \\\\\n&= [(P_Z\\mathbf{R})' (P_Z\\mathbf{R})]^{-1} (P_Z\\mathbf{R})' \\mathbf{y}\n\\end{aligned}\n\\]\n\n이 식은 “원래의 변수 행렬(\\(\\mathbf{R}\\))을 도구변수 공간에 투영(\\(P_Z\\))시킨 뒤, 그 투영된 변수들을 사용하여 OLS를 수행하는 것”과 수학적으로 동일함을 보여줍니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "",
    "text": "이번 포스트에서는 인과추론의 가장 강력하고 널리 쓰이는 도구 중 하나인 이중차분법(Differences in Differences, DiD)에 대해 다룹니다.\n특히 잠재적 결과(Potential Outcomes) 프레임워크를 기반으로 DiD 추정량이 도출되는 과정을 수학적으로 엄밀하게 살펴보겠습니다.\n\n\n참고 자료: 본 포스트는 이상학 교수님의 “Differences in Differences & Synthetic Control Method” 강의 자료를 바탕으로 재구성되었습니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html#basic-setup",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html#basic-setup",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "1.1 Basic Setup",
    "text": "1.1 Basic Setup\n\n두 개의 그룹과 두 개의 시점이 있다고 가정해 봅시다.\n집단 (Groups):\n\n\\(G_i = 1\\): 처치 집단 (Treated Group, 예: 최저임금이 인상된 뉴저지주)\n\\(G_i = 0\\): 통제 집단 (Control Group, 예: 최저임금이 동결된 펜실베이니아주)\n\n시점 (Time Periods):\n\n\\(t = 0\\): 개입 이전 (Pre-period)\n\\(t = 1\\): 개입 이후 (Post-period)"
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html#potential-outcomes",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html#potential-outcomes",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "1.2 Potential Outcomes",
    "text": "1.2 Potential Outcomes\n\n\\(Y_{it}(x)\\)를 시점 \\(t\\)에서 처치 상태가 \\(x\\)일 때 개인 \\(i\\)의 잠재적 결과라고 정의합니다.\n우리가 실제로 관찰하는 결과 \\(Y_{it}\\)는 일치성(Consistency) 가정에 의해 다음과 같이 표현됩니다.\n\n\\[\nY_{it} = G_{it}Y_{it}(1) + (1-G_{it})Y_{it}(0)\n\\]\n\n아래 테이블은 DiD 디자인에서 관측되는 잠재적 결과(Potential Outcomes)의 기댓값을 나타냅니다.\n\n\n\n\n\n\n\n\n\n\nPre-period (\\(t=0\\))\nPost-period (\\(t=1\\))\n\n\n\n\nTreated group (\\(G_i=1\\))\n\\(\\color{purple}{\\mathbb{E}[Y_{i0}(0) \\mid G_i=1]}\\)\n\\(\\color{green}{\\mathbb{E}[Y_{i1}(1) \\mid G_i=1]}\\)\n\n\nControl group (\\(G_i=0\\))\n\\(\\color{orange}{\\mathbb{E}[Y_{i0}(0) \\mid G_i=0]}\\)\n\\(\\color{blue}{\\mathbb{E}[Y_{i1}(0) \\mid G_i=0]}\\)"
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html#att",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html#att",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "1.3 ATT",
    "text": "1.3 ATT\n\n우리의 목표는 처치 집단에 대한 평균 처치 효과(ATT: Average Treatment Effect on the Treated)를 구하는 것입니다.\n\n\\[\n\\tau_{ATT} = \\mathbb{E}[{\\color{green}{Y_{i1}(1)}} - {\\color{red}{Y_{i1}(0)}} | G_i=1]\n\\]\n\n이 식을 풀면 다음과 같습니다. \\[\n\\tau_{ATT} = \\underbrace{\\color{green}{\\mathbb{E}[Y_{i0}(1) \\mid G_i=1]}}_{\\text{(a) 관찰 가능}} - \\underbrace{\\color{red}{\\mathbb{E}[Y_{i1}(0) | G_i=1]}}_{\\text{(b) 반사실 (관찰 불가)}}\n\\]\n\n(a): 처치를 받은 집단의 처치 후 결과이므로 데이터에서 관찰할 수 있습니다.\n(b):\n\n문제의 핵심입니다.\n처치를 받은 집단이 만약 처치를 받지 않았더라면 겪었을 결과입니다.\n이는 현실에 존재하지 않으므로, 적절한 대조군을 통해 추정해야 합니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html#three-control-strategies",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html#three-control-strategies",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "2. Three Control Strategies",
    "text": "2. Three Control Strategies\n\n반사실 \\(\\mathbb{E}[Y_{i1}(0) | G_i=1]\\)을 대체하기 위해 우리는 어떤 전략을 취할 수 있을까요?\n\n\n\n\nFigure: \\(x\\)축은 시간(Time), \\(y\\)축은 평균 결과(Average Outcome)를 나타내며, 처치 집단과 통제 집단의 변화 추이를 시각화한 그래프입니다.\n\n\n\n전략 1: 전후 비교 (Before-and-After Design)\n\n처치 집단의 개입 이전 시점(\\(t=0\\)) 결과를 반사실로 사용하는 방법입니다.\n\n\\[\n{\\color{red}{\\mathbb{E}[Y_{i1}(0) | G_i=1]}} \\approx {\\color{purple}{\\mathbb{E}[Y_{i0}(0) | G_i=1]}}\n\\]\n\n가정: 시간이 지나도 결과에 자연적인 변화(Trend)가 없어야 합니다.\n한계: 경기 변동이나 계절적 요인 등 시간의 흐름에 따른 변화를 무시합니다.\n\n\n\n전략 2: 횡단면 비교 (Cross-sectional Design)\n\n가장 단순한 접근은 처치 후 시점(\\(t=1\\))에서 통제 집단의 결과를 반사실로 사용하는 것입니다.\n\n\\[\n{\\color{red}{\\mathbb{E}[Y_{i1}(0) | G_i=1]}} \\approx {\\color{blue}{\\mathbb{E}[Y_{i1}(0) | G_i=0]}}\n\\]\n\n가정: 처치 여부가 결과와 독립적이어야 합니다 (Selection Bias가 없어야 함).\n한계: 두 집단은 처치 여부 외에도 원래부터 다른 특성을 가질 수 있습니다. 예를 들어, 뉴저지와 펜실베이니아는 경제 상황이 다를 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html#평행-추세-가정-parallel-trends-assumption",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html#평행-추세-가정-parallel-trends-assumption",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "3.1 평행 추세 가정 (Parallel Trends Assumption)",
    "text": "3.1 평행 추세 가정 (Parallel Trends Assumption)\n\nDiD의 핵심 가정입니다.\n“처치가 없었더라면, 처치 집단의 평균 결과 변화량은 통제 집단의 변화량과 같았을 것”이라는 가정입니다.\n수식으로는 다음과 같습니다: \\[\n\\mathbb{E}[{\\color{red}{Y_{i1}(0)}} - {\\color{purple}{Y_{i0}(0)}} | G_i=1] = \\mathbb{E}[{\\color{blue}{Y_{i1}(0)}} -  {\\color{orange}{Y_{i0}(0)}} | G_i=0]\n\\]\n이 가정을 이용해 우리가 모르는 반사실을 유도해 봅시다.\n위 식을 이항하면 반사실 \\(\\mathbb{E}[Y_{i1}(0) | G_i=1]\\)은 다음과 같이 표현됩니다.\n\n\\[\n\\underbrace{{\\color{red}{\\mathbb{E}[Y_{i1}(0) | G_i=1]}}}_{\\text{반사실}} = \\underbrace{{\\color{purple}{\\mathbb{E}[Y_{i0}(0) | G_i=1]}}}_{\\text{처치집단 초기값}} + \\underbrace{({\\color{blue}{\\mathbb{E}[Y_{i1}(0) | G_i=0]}} - {\\color{orange}{\\mathbb{E}[Y_{i0}(0) | G_i=0]}})}_{\\text{통제집단의 시간 추세}}\n\\]\n\n즉, 처치 집단의 초기값에 통제 집단에서 관찰된 ’시간에 따른 변화분(Trend)’을 더해주면, 처치 집단이 처치를 받지 않았을 때의 결과를 추정할 수 있습니다.\n\n\n\n\nFigure: 점선으로 표시된 부분은 평행 추세 가정에 기반하여 생성된 Counterfactual 지점입니다. 처치 집단(빨간색)의 실제 결과와 점선(Counterfactual)의 차이가 바로 인과 효과입니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html#did-identification-result",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html#did-identification-result",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "3.2 DiD Identification Result",
    "text": "3.2 DiD Identification Result\n\n이제 ATT 식에 위에서 구한 반사실을 대입해 보겠습니다.\n\n\\[\n\\begin{aligned}\n\\tau_{ATT} &= {\\color{green}{\\mathbb{E}[Y_{i1} | G_i=1]}} - {\\color{red}{\\mathbb{E}[Y_{i1}(0) | G_i=1]}} \\\\\n&= {\\color{green}{\\mathbb{E}[Y_{i1} | G_i=1]}} - \\left({\\color{purple}{\\mathbb{E}[Y_{i0} | G_i=1]}} + ({\\color{blue}{\\mathbb{E}[Y_{i1} | G_i=0]}} - {\\color{orange}{\\mathbb{E}[Y_{i0} | G_i=0]}}) \\right) \\\\\n&= \\left( {\\color{green}{\\mathbb{E}[Y_{i1} | G_i=1]}} - {\\color{purple}{\\mathbb{E}[Y_{i0} | G_i=1]}} \\right) - \\left( {\\color{blue}{\\mathbb{E}[Y_{i1} | G_i=0]}} - {\\color{orange}{\\mathbb{E}[Y_{i0} | G_i=0]}} \\right)\n\\end{aligned}\n\\]\n\n이 수식이 의미하는 바는 명확합니다:\n\n\nFirst Difference: 처치 집단의 전후 차이를 구합니다 (시간 효과 + 처치 효과).\n\n\nSecond Difference: 통제 집단의 전후 차이를 구합니다 (순수 시간 효과).\n\n\nDifference-in-Differences: 1번에서 2번을 빼면 순수한 처치 효과(Treatment Effect)만 남습니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html#이원-고정-효과-모형-two-way-fixed-effects-model",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html#이원-고정-효과-모형-two-way-fixed-effects-model",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "4.1 이원 고정 효과 모형 (Two-way Fixed Effects Model)",
    "text": "4.1 이원 고정 효과 모형 (Two-way Fixed Effects Model)\n\n단순한 평균의 차감 계산이 아니라, 회귀분석을 이용하면 표준오차(Standard Error)를 계산하고 다른 공변량을 통제하기 용이합니다.\n\n\n4.1.1 회귀식의 정의\n\n패널 데이터(혹은 반복 횡단면 데이터)에 대해 다음과 같은 선형 회귀식을 설정합니다.\n\n\\[\nY_{it} = \\alpha + \\gamma G_i + \\beta t + \\tau X_{it} + \\epsilon_{it}\n\\]\n\n여기서 변수들의 정의는 다음과 같습니다.\n\n\\(G_i\\): 집단 더미 (Group Dummy). 처치 집단이면 1, 통제 집단이면 0.\n\\(t\\): 시점 더미 (Time Dummy). 개입 이후(Post)면 1, 이전(Pre)이면 0.\n\\(X_{it}\\): 상호작용항 (Interaction Term). \\(G_i \\times t\\)와 동일하며, ‘처치 집단이면서 동시에 개입 이후인 경우’에만 1을 갖습니다.\n\n\n\n\n4.1.2 계수의 유도 과정 (Derivation)\n\n이 식을 이용해 4가지 경우의 수(처치/통제 \\(\\times\\) 전/후)에 대한 기댓값 \\(E[Y_{it}]\\)를 계산해보면 각 계수의 의미가 명확해집니다.\n\n\n\n\n\n\n\n\n\n\n\n\n구분\n시점 (\\(t\\))\n집단 (\\(G_i\\))\n상호작용 (\\(X_{it}\\))\n기댓값 \\(E[Y_{it}]\\)\n의미\n\n\n\n\n통제 집단 / 전\n0\n0\n0\n\\(\\alpha\\)\n베이스라인\n\n\n통제 집단 / 후\n1\n0\n0\n\\(\\alpha + \\beta\\)\n시간의 흐름에 따른 자연적 변화 (\\(\\beta\\)) 반영\n\n\n처치 집단 / 전\n0\n1\n0\n\\(\\alpha + \\gamma\\)\n집단 간의 고유한 차이 (\\(\\gamma\\)) 반영\n\n\n처치 집단 / 후\n1\n1\n1\n\\(\\alpha + \\gamma + \\beta + \\tau\\)\n시간(\\(\\beta\\)) + 집단(\\(\\gamma\\)) + 정책효과(\\(\\tau\\))\n\n\n\n\n\n4.1.3 이중차분 (Difference-in-Differences) 계산\n\n위의 표를 바탕으로 DiD 연산을 수행해 봅시다.\n\n시간 전후 차이 (After - Before):\n\n\n통제 집단의 변화: \\((\\alpha + \\beta) - \\alpha = \\mathbf{\\beta}\\) (순수 시간 효과)\n처치 집단의 변화: \\((\\alpha + \\gamma + \\beta + \\tau) - (\\alpha + \\gamma) = \\mathbf{\\beta + \\tau}\\) (시간 효과 + 처치 효과)\n\n\n집단 간 차이 (Treated - Control):\n\n\n변화량의 차이: \\((\\beta + \\tau) - \\beta = \\mathbf{\\tau}\\)\n\n결론적으로 회귀계수 \\(\\tau\\)는 우리가 구하고자 하는 이중차분 추정량(ATT)과 정확히 일치합니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html#실제-사례-card-krueger-1994",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html#실제-사례-card-krueger-1994",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "4.2 실제 사례: Card & Krueger (1994)",
    "text": "4.2 실제 사례: Card & Krueger (1994)\n\n최저임금 인상이 고용에 미치는 영향을 분석한 고전적인 연구입니다.\nQuestion: 최저임금을 올리면 고용이 감소하는가?\nSetting: 1992년 뉴저지(NJ)는 최저임금을 $4.25에서 $5.05로 인상(처치 집단), 펜실베이니아(PA)는 동결(통제 집단).\nResult: 두 주(State)의 패스트푸드점 고용 변화를 DiD로 분석한 결과, 통념과 달리 고용 감소 효과가 뚜렷하지 않음을 보였습니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html#ashenfelters-dip",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html#ashenfelters-dip",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "5.1 Ashenfelter’s Dip",
    "text": "5.1 Ashenfelter’s Dip\n\n직업 훈련 프로그램 등의 효과를 분석할 때 자주 나타나는 현상입니다.\n처치를 받기 직전에 소득이 일시적으로 급락하는 현상을 말합니다.\n이 경우 처치 이전의 추세가 평행하지 않을 수 있으므로 주의해야 합니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html#위조-검증-falsification-test",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html#위조-검증-falsification-test",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "5.2 위조 검증 (Falsification Test)",
    "text": "5.2 위조 검증 (Falsification Test)\n\n평행 추세 가정을 간접적으로 검증하기 위해 개입 이전 시점(Pre-treatment period)들의 데이터를 사용합니다.\n개입이 없었던 과거 기간 동안에도 두 집단의 추세가 평행했는지 확인하는 것입니다. 만약 과거에도 추세가 달랐다면, 미래에도 달랐을 가능성이 높습니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-02/index.html",
    "href": "posts/lecture/L15/causal-inference-15-part-02/index.html",
    "title": "[Causal Inference] 15. DiD & SCM (Part 2)",
    "section": "",
    "text": "표준 이중차분법(Standard DiD)은 강력하지만, 중요한 가정을 전제로 합니다.\n바로 “평행 추세(Parallel Trends)” 가정입니다.\n하지만 이 가정은 결과 변수(\\(Y\\))의 선형성(Linearity)에 의존적이라는 한계가 있습니다.\n예를 들어, 소득(\\(Y\\))에 대해서는 평행 추세가 성립하더라도, 로그 소득(\\(\\log Y\\))에 대해서는 성립하지 않을 수 있습니다(Not invariant to nonlinear transformations).\n만약 정책 효과가 소득 구간별로 다르게 나타난다면(예: 저소득층에게 더 큰 효과), 평균값의 변화만 보는 선형 DiD는 이러한 분포의 변화를 놓치게 됩니다.\n이번 포스트에서는 이러한 선형성 가정을 완화하고, 분포 전체의 변화를 추정할 수 있는 비선형 이중차분법(Nonlinear DiD), 일명 Changes-in-Changes (CiC) 모델에 대해 알아봅니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-02/index.html#시각적-설명",
    "href": "posts/lecture/L15/causal-inference-15-part-02/index.html#시각적-설명",
    "title": "[Causal Inference] 15. DiD & SCM (Part 2)",
    "section": "시각적 설명",
    "text": "시각적 설명\n\n아래 그림은 통제 집단(Control)과 처치 집단(Treated)의 누적 분포 함수(CDF)가 시간이 지남에 따라 어떻게 변하는지를 보여줍니다.\n\n\n\n\nFigure: \\(x\\)축은 결과값, \\(y\\)축은 확률(0~1)을 나타냅니다. \\(r_0(q)\\)와 \\(r_1(q)\\)는 각각 통제 집단과 처치 집단에서 특정 분위수 \\(q\\)에 해당하는 값의 시간적 변화(매핑)를 의미합니다.\n\n\n\n통제 집단의 변화 (\\(r_0(q)\\)): \\(t=0\\) 시점의 \\(q\\) 분위수 값이 \\(t=1\\) 시점에 어떻게 변했는지 보여줍니다.\n가정: 처치 집단이 처치를 받지 않았더라면, “시간에 따른 분위수의 변화 양상”이 통제 집단과 동일했을 것이라고 가정합니다.\n즉, 통제 집단에서의 매핑(화살표)을 처치 집단에 그대로 적용하여 반사실(Counterfactual)을 구성합니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-02/index.html#분포-함수-distribution-functions",
    "href": "posts/lecture/L15/causal-inference-15-part-02/index.html#분포-함수-distribution-functions",
    "title": "[Causal Inference] 15. DiD & SCM (Part 2)",
    "section": "2.1 분포 함수 (Distribution Functions)",
    "text": "2.1 분포 함수 (Distribution Functions)\n\n우선, 각 집단(\\(G_i=g\\))과 시점(\\(t\\))에서의 잠재적 결과(Potential Outcome) \\(Y(0)\\)(처치받지 않음)의 누적 분포 함수를 정의합니다. \\[\nF_{gt}(y) = P(Y_{it}(0) \\le y | G_i = g)\n\\]\n\n\\(g \\in \\{0, 1\\}\\textit{(0: 통제, 1: 처치)}\\)\n\\(t \\in \\{0, 1\\}\\textit{(0: 전, 1: 후)}\\)\n\n우리가 관찰할 수 있는 분포들은 \\(F_{00}, F_{01}, F_{10}\\)입니다.\n처치 집단의 사후 결과인 \\(F_{11}\\)은 처치(\\(Y(1)\\))를 받은 상태이므로, 처치를 받지 않았을 상태(\\(Y(0)\\))인 \\(F_{11}\\)은 반사실(Counterfactual)로서 식별해야 할 대상입니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-02/index.html#분위수-처치-효과-quantile-treatment-effect-qte",
    "href": "posts/lecture/L15/causal-inference-15-part-02/index.html#분위수-처치-효과-quantile-treatment-effect-qte",
    "title": "[Causal Inference] 15. DiD & SCM (Part 2)",
    "section": "2.2 분위수 처치 효과 (Quantile Treatment Effect, QTE)",
    "text": "2.2 분위수 처치 효과 (Quantile Treatment Effect, QTE)\n\n우리의 목표는 특정 분위수 \\(q\\)에서의 처치 효과 \\(\\tau(q)\\)를 구하는 것입니다. \\[\n\\tau(q) = \\underbrace{\\tilde{F}_{11}^{-1}(q)}_{\\text{관측값}} - \\underbrace{F_{11}^{-1}(q)}_{\\text{반사실(추정값)}}\n\\]\n\n\\(\\tilde{F}_{11}(y) = P(Y_{i1}(1) \\le y | G_i = 1)\\):\n\n실제로 관측된 처치 집단의 사후 결과 분포 (\\(Y(1)\\)).\n\n\\(F_{11}(y)\\):\n\n우리가 추정해야 할 처치 집단의 반사실적 사후 결과 분포 (\\(Y(0)\\))."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-02/index.html#식별-가정-identification-assumption",
    "href": "posts/lecture/L15/causal-inference-15-part-02/index.html#식별-가정-identification-assumption",
    "title": "[Causal Inference] 15. DiD & SCM (Part 2)",
    "section": "3.1 식별 가정 (Identification Assumption)",
    "text": "3.1 식별 가정 (Identification Assumption)\n\n모든 분위수 \\(q \\in [0, 1]\\)에 대하여 다음이 성립한다고 가정합니다.\n\n\\[\nF_{01}(F_{00}^{-1}(q)) = F_{11}(F_{10}^{-1}(q))\n\\]\n\n이 수식의 의미를 단계별로 풀어보겠습니다.\n\n\n좌변 (\\(F_{01}(F_{00}^{-1}(q))\\)):\n\n\n통제 집단에서 시점 0에 \\(q\\) 분위수에 해당하는 값(\\(F_{00}^{-1}(q)\\))을 찾습니다.\n그 값이 시점 1의 분포(\\(F_{01}\\))에서 차지하는 위치(확률)를 봅니다.\n즉, 통제 집단에서 시간이 흐름에 따라 순위(Rank)가 어떻게 변했는지를 나타냅니다.\n\n\n우변 (\\(F_{11}(F_{10}^{-1}(q))\\)):\n\n\n처치 집단에서도 동일하게, 시점 0에 \\(q\\) 분위수에 해당하는 값(\\(F_{10}^{-1}(q)\\))을 찾습니다.\n그 값이 시점 1의 반사실 분포(\\(F_{11}\\))에서 갖게 될 위치를 나타냅니다.\n\n\n결론: “시간에 따른 상대적 위치(Rank)의 변화 함수”는 두 집단 간에 동일하다는 것입니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-02/index.html#반사실-분포-f_11y의-유도-과정",
    "href": "posts/lecture/L15/causal-inference-15-part-02/index.html#반사실-분포-f_11y의-유도-과정",
    "title": "[Causal Inference] 15. DiD & SCM (Part 2)",
    "section": "3.2 반사실 분포 \\(F_{11}(y)\\)의 유도 과정",
    "text": "3.2 반사실 분포 \\(F_{11}(y)\\)의 유도 과정\n\n우리는 \\(F_{11}(y)\\)를 구하고 싶습니다. 위 식별 가정을 이용하여 이를 \\(y\\)에 대한 함수로 정리해 봅시다.\n단계 1: 목표 변수 설정\n\n우변의 \\(F_{11}(\\cdot)\\) 안에 있는 \\(F_{10}^{-1}(q)\\)를 \\(y\\)라고 둡니다.\n즉, 어떤 결과값 \\(y\\)가 처치 집단의 사전 시점(\\(t=0\\))에서 갖는 누적 확률(분위수)을 \\(q'\\)라고 합시다.\n\n\n\\[\ny = F_{10}^{-1}(q') \\iff q' = F_{10}(y)\n\\]\n\n단계 2: 가정식에 대입\n\n식별 가정 식의 \\(q\\) 자리에 \\(q' = F_{10}(y)\\)를 대입합니다. \\[\nF_{01}(F_{00}^{-1}(q')) = F_{11}(F_{10}^{-1}(q'))\n\\]\n여기에 \\(q'\\)와 \\(y\\)의 관계를 적용하면: \\[\nF_{01}(F_{00}^{-1}(F_{10}(y))) = F_{11}(y)\n\\]\n\n단계 3: 결과 도출\n따라서, 처치 집단이 처치를 받지 않았을 때(\\(t=1\\))의 잠재적 분포 \\(F_{11}(y)\\)는 관찰 가능한 데이터(\\(F_{01}, F_{00}, F_{10}\\))만으로 다음과 같이 식별됩니다.\n\n\\[\nF_{11}(y) = F_{01}\\left[ F_{00}^{-1} \\{ F_{10}(y) \\} \\right]\n\\]"
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-02/index.html#해석",
    "href": "posts/lecture/L15/causal-inference-15-part-02/index.html#해석",
    "title": "[Causal Inference] 15. DiD & SCM (Part 2)",
    "section": "3.3 해석",
    "text": "3.3 해석\n\n이 최종 수식은 다음과 같은 알고리즘으로 이해할 수 있습니다.\n\n\n\\(F_{10}(y)\\): 처치 집단의 \\(t=0\\) 시점에서 결과값 \\(y\\)의 분위수(Rank)를 찾습니다.\n\n\n\\(F_{00}^{-1}(\\cdot)\\): 통제 집단의 \\(t=0\\) 시점에서 동일한 분위수를 가진 결과값을 찾습니다. (집단 간 비교 기준점 확보)\n\n\n\\(F_{01}(\\cdot)\\): 그 결과값이 통제 집단의 \\(t=1\\) 시점에서 갖는 새로운 분위수를 확인합니다. (시간 효과 반영)\n\n\n\\(F_{11}(y)\\): 이 “변환된 분위수”가 바로 처치 집단(\\(t=1\\))에서 \\(y\\)가 가질 누적 확률입니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-02/index.html#요약-및-시사점",
    "href": "posts/lecture/L15/causal-inference-15-part-02/index.html#요약-및-시사점",
    "title": "[Causal Inference] 15. DiD & SCM (Part 2)",
    "section": "4. 요약 및 시사점",
    "text": "4. 요약 및 시사점\n\n비선형 DiD(CiC)는 평균값 비교에 그치는 기존 DiD의 한계를 넘어, 정책이 전체 소득 분포나 특정 분위수(예: 하위 10%)에 미치는 영향을 정밀하게 분석할 수 있게 해줍니다.\n장점:\n\n로그 변환 등 결과 변수의 비선형 변환에 영향을 받지 않습니다(Invariant).\n평균뿐만 아니라 분포 전체의 처치 효과(QTE)를 추정할 수 있습니다.\n\n조건:\n\n연속적인 결과 변수에 적합하며, 역함수(\\(F^{-1}\\))가 존재해야 하므로 분포 함수가 강단조증가(strictly increasing)해야 한다는 조건이 필요할 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L15A/SDiD/part-02/index.html",
    "href": "posts/lecture/L15A/SDiD/part-02/index.html",
    "title": "[Causal Inference] 15A. SDiD (Part 2)",
    "section": "",
    "text": "인과 추론(Causal Inference)에서 가장 널리 쓰이는 이중차분법(DiD)은 ’평행 추세 가정(Parallel Trends Assumption)’에 크게 의존합니다.\n하지만 현실 데이터에서는 처치군과 대조군의 추세가 평행하지 않은 경우가 많습니다.\n이를 보완하기 위해 Synthetic Control Method (SCM)이 등장했지만, SCM 역시 제약이 있습니다.\nSynthetic Difference in Differences (SDiD)는 DiD와 SCM의 장점을 결합하여, 평행 추세가 위배되는 상황에서도 더욱 강건한(robust) 추정치를 제공합니다.\n이번 포스트에서는 파이썬을 사용하여 SDiD를 직접 구현해보고, 평행 추세가 위배되는 시뮬레이션 데이터를 통해 DiD, SCM과 성능을 비교해 봅니다."
  },
  {
    "objectID": "posts/lecture/L15A/SDiD/part-02/index.html#초기화-initialization",
    "href": "posts/lecture/L15A/SDiD/part-02/index.html#초기화-initialization",
    "title": "[Causal Inference] 15A. SDiD (Part 2)",
    "section": "초기화 (Initialization)",
    "text": "초기화 (Initialization)\n\n입력된 데이터를 처치 시점(\\(T_{pre}\\))을 기준으로 Pre-period와 Post-period로 분리하고, 행렬 연산에 적합한 형태로 변환합니다.\n\nInputs: \\(Y_{co}\\) (Control Data), \\(Y_{tr}\\) (Treated Data), \\(T_{pre}\\) (Intervention Time)\nSplit: \\(Y_{pre, co}, Y_{pre, tr}\\) 등으로 데이터를 슬라이싱합니다."
  },
  {
    "objectID": "posts/lecture/L15A/SDiD/part-02/index.html#단위-가중치-unit-weights-계산",
    "href": "posts/lecture/L15A/SDiD/part-02/index.html#단위-가중치-unit-weights-계산",
    "title": "[Causal Inference] 15A. SDiD (Part 2)",
    "section": "단위 가중치 (Unit Weights) 계산",
    "text": "단위 가중치 (Unit Weights) 계산\n\n처치 유닛의 처치 전 추세(Pre-trend)를 가장 잘 모방하는 합성 통제군을 만들기 위해 유닛 가중치 \\(\\omega\\)를 계산합니다.\n\n\n핵심 구현 사항\n\nIntercept (\\(\\omega_0\\)) 허용:\n\nget_unit_weights(intercept=True) 옵션을 통해 절편을 포함합니다.\n이는 기존 SCM과 달리 처치 유닛이 통제 유닛들의 볼록 껍질(Convex Hull) 밖에 있어도 평행 이동을 통해 맞출 수 있게 합니다.\n\nRegularization (\\(\\zeta\\)):\n\n가중치가 특정 유닛에 쏠리는 것을 방지하고 분산시키기 위해 Ridge Penalty(\\(\\zeta^2 ||\\omega||^2\\))를 적용합니다.\n\n\n\n\n최적화 수식\n\\[\n(\\hat{\\omega}_0, \\hat{\\omega}) = \\underset{\\omega_0, \\omega}{\\arg\\min} \\sum_{t=1}^{T_{pre}} \\left( Y_{tr,t} - \\omega_0 - \\sum_{i=1}^{N_{co}} \\omega_i Y_{it} \\right)^2 + \\zeta^2 ||\\omega||_2^2\n\\]\n\\[\n\\text{subject to } \\sum_{i=1}^{N_{co}} \\omega_i = 1, \\quad \\omega_i \\ge 0\n\\]"
  },
  {
    "objectID": "posts/lecture/L15A/SDiD/part-02/index.html#시간-가중치-time-weights-계산",
    "href": "posts/lecture/L15A/SDiD/part-02/index.html#시간-가중치-time-weights-계산",
    "title": "[Causal Inference] 15A. SDiD (Part 2)",
    "section": "시간 가중치 (Time Weights) 계산",
    "text": "시간 가중치 (Time Weights) 계산\n\n처치 전 기간(Pre-period) 중, 처치 후 기간(Post-period)과 가장 유사한 패턴을 보이는 시점들에 더 큰 비중을 두기 위해 시간 가중치 \\(\\lambda\\)를 계산합니다.\n\n\n핵심 구현 사항\n\nTarget: 각 통제 유닛(Control Unit)의 처치 후 평균값(\\(\\bar{Y}_{post, co}\\))을 타겟으로 설정합니다.\nIntercept (\\(\\lambda_0\\)) 허용: 시점 간의 레벨 차이를 보정하기 위해 절편을 포함합니다.\n\n\n\n최적화 수식\n\\[\n(\\hat{\\lambda}_0, \\hat{\\lambda}) = \\underset{\\lambda_0, \\lambda}{\\arg\\min} \\sum_{i=1}^{N_{co}} \\left( \\bar{Y}_{i, post} - \\lambda_0 - \\sum_{t=1}^{T_{pre}} \\lambda_t Y_{it} \\right)^2\n\\]\n\\[\n\\text{subject to } \\sum_{t=1}^{T_{pre}} \\lambda_t = 1, \\quad \\lambda_t \\ge 0\n\\]"
  },
  {
    "objectID": "posts/lecture/L15A/SDiD/part-02/index.html#추정-estimation-closed-form-solution",
    "href": "posts/lecture/L15A/SDiD/part-02/index.html#추정-estimation-closed-form-solution",
    "title": "[Causal Inference] 15A. SDiD (Part 2)",
    "section": "추정 (Estimation: Closed-form Solution)",
    "text": "추정 (Estimation: Closed-form Solution)\n\n복잡한 가중 회귀분석(Weighted TWFE)을 수행하는 대신, 구해진 가중치(\\(\\hat{\\omega}, \\hat{\\lambda}\\))를 사용하여 가중 이중차분(Weighted DID) 형태로 직접 \\(\\tau_{sdid}\\)를 계산합니다.\n\n\n구현 로직 (estimate 메서드)\n\n다음의 4가지 항을 계산하여 최종 효과를 도출합니다.\n\n\nTreated Post: \\(\\bar{Y}_{tr, post}\\) (단순 평균)\nTreated Pre (Time-weighted): \\(\\bar{Y}_{tr, pre}^{\\lambda} = \\sum \\hat{\\lambda}_t Y_{tr,t}\\)\nControl Post (Unit-weighted): \\(\\bar{Y}_{co, post}^{\\omega} = \\sum \\hat{\\omega}_i \\bar{Y}_{i, post}\\)\nControl Pre (Double-weighted): \\(\\bar{Y}_{co, pre}^{\\omega, \\lambda} = \\sum \\hat{\\omega}_i (\\sum \\hat{\\lambda}_t Y_{it})\\)\n\n\n\n최종 추정식\n\\[\n\\hat{\\tau}^{SDiD} = \\underbrace{(\\bar{Y}_{tr, post} - \\bar{Y}_{tr, pre}^{\\lambda})}_{\\text{Treated Change}} - \\underbrace{\\sum_{i=1}^{N_{co}} \\hat{\\omega}_i (\\bar{Y}_{i, post} - \\bar{Y}_{i, pre}^{\\lambda})}_{\\text{Synthetic Control Change}}\n\\]\n\n\nCode\nclass SyntheticDiD:\n    def __init__(self, Y_co, Y_tr, T_pre):\n        self.Y_co = Y_co  # Control Data (N_co x T)\n        self.Y_tr = Y_tr  # Treated Data (1 x T)\n        self.T_pre = T_pre\n        \n        # Split Pre/Post\n        self.Y_pre_co = Y_co[:, :T_pre]\n        self.Y_pre_tr = Y_tr[:, :T_pre]\n        \n        self.N_co = Y_co.shape[0]\n        \n    def get_unit_weights(self, zeta=None, intercept=True):\n        \"\"\"\n        Step 1: Compute Unit Weights (omega)\n        SDiD Eq: argmin || mean(Y_tr) - (w0 + w @ Y_co) ||^2 + zeta^2 ||w||^2\n        \"\"\"\n        # Variables\n        w = cp.Variable(self.N_co)\n        w0 = cp.Variable(1) if intercept else 0 # SCM은 intercept=False\n        \n        # Target (Treated Pre-trend)\n        target = self.Y_pre_tr.flatten()\n        \n        # Prediction (Weighted Control Pre-trend)\n        prediction = w0 + w @ self.Y_pre_co\n        \n        # Regularization (Zeta)\n        # 논문의 zeta 계산식 간소화 (표준편차 * N_tr 등)\n        if zeta is None:\n            # Simple heuristic for tutorial: std of first differences\n            diffs = np.diff(self.Y_pre_co, axis=1)\n            sigma = np.std(diffs)\n            zeta = (self.N_co * (self.Y_co.shape[1] - self.T_pre))**(1/4) * sigma\n        \n        # Objective Function\n        error_term = cp.sum_squares(target - prediction)\n        reg_term = cp.sum_squares(w) * (zeta**2)\n        objective = cp.Minimize(error_term + reg_term)\n        \n        # Constraints: Sum to 1, Non-negative (Simplex)\n        constraints = [cp.sum(w) == 1, w &gt;= 0]\n        \n        # Solve\n        prob = cp.Problem(objective, constraints)\n        prob.solve()\n        \n        return w.value, (w0.value if intercept else 0)\n\n    def get_time_weights(self, lambda_reg=1e-6):\n        \"\"\"\n        Step 2: Compute Time Weights (lambda)\n        SDiD Eq: argmin || mean(Y_post_co) - (lam0 + Y_pre_co @ lam) ||^2\n        \"\"\"\n        T_pre = self.T_pre\n        lam = cp.Variable(T_pre)\n        lam0 = cp.Variable(1)\n        \n        # Target: Control Units' Post-treatment Average (Vector of size N_co)\n        # 각 Control Unit의 처치 후 평균값\n        target = np.mean(self.Y_co[:, T_pre:], axis=1)\n        \n        # Prediction: Weighted sum of Pre-treatment values for each unit\n        prediction = lam0 + self.Y_pre_co @ lam\n        \n        # Objective\n        # Ridge penalty slightly added for numerical stability\n        objective = cp.Minimize(cp.sum_squares(target - prediction) + lambda_reg * cp.sum_squares(lam))\n        \n        # Constraints\n        constraints = [cp.sum(lam) == 1, lam &gt;= 0]\n        \n        prob = cp.Problem(objective, constraints)\n        prob.solve()\n        \n        return lam.value, lam0.value\n\n    def estimate(self):\n        # 1. Unit Weights (SDiD)\n        self.omega, self.omega0 = self.get_unit_weights(intercept=True)\n        \n        # 2. Unit Weights (SCM - for comparison)\n        # SCM: No intercept, No regularization (or small) in classic form, but usually L2 used.\n        # Here we mimic SCM by forcing intercept=0\n        self.omega_sc, _ = self.get_unit_weights(intercept=False, zeta=0) \n\n        # 3. Time Weights (SDiD)\n        self.lam, self.lam0 = self.get_time_weights()\n        \n        # 4. SDiD Estimator (Weighted TWFE)\n        # 간단한 구현을 위해 Weighted Diff-in-Diff 공식을 직접 적용합니다.\n        # tau_sdid = (Y_tr_post - Y_tr_pre_weighted) - (Y_co_post_weighted - Y_co_pre_weighted)\n        \n        # Apply Time Weights to Pre-periods\n        y_tr_post = np.mean(self.Y_tr[:, self.T_pre:])\n        y_tr_pre = np.dot(self.Y_tr[:, :self.T_pre].flatten(), self.lam)\n        \n        # Apply Unit Weights to Control Units\n        y_co_post_series = np.mean(self.Y_co[:, self.T_pre:], axis=1)\n        y_co_pre_matrix = self.Y_co[:, :self.T_pre]\n        \n        # Double Weighted Control\n        # Control Term = Sum( omega_i * ( Mean_Post_i - Sum(lambda_t * Y_it_pre) ) )\n        control_term = 0\n        for i in range(self.N_co):\n            y_i_post = y_co_post_series[i]\n            y_i_pre = np.dot(y_co_pre_matrix[i], self.lam)\n            control_term += self.omega[i] * (y_i_post - y_i_pre)\n            \n        self.tau_sdid = (y_tr_post - y_tr_pre) - control_term\n        \n        return self.tau_sdid"
  },
  {
    "objectID": "posts/lecture/L15A/SDiD/part-02/index.html#data-generation",
    "href": "posts/lecture/L15A/SDiD/part-02/index.html#data-generation",
    "title": "[Causal Inference] 15A. SDiD (Part 2)",
    "section": "1. Data Generation",
    "text": "1. Data Generation\n\n데이터 생성 모형 (DGP)\n\n데이터는 다음과 같은 수식을 따릅니다. \\[\nY_{it} = \\underbrace{\\alpha_i}_{\\text{Unit FE}} + \\underbrace{\\beta_t}_{\\text{Time FE}} + \\underbrace{\\gamma_i f_t}_{\\text{Latent Structure}} + \\tau D_{it} + \\varepsilon_{it}\n\\]\n\n\\(\\alpha_i, \\beta_t\\): 일반적인 개체 및 시간 고정 효과입니다.\n\\(f_t\\): 시간에 따라 선형적으로 증가하는 공통의 잠재 요인입니다. (\\(f_t \\propto t\\))\n\\(\\gamma_i\\): 잠재 요인 \\(f_t\\)에 반응하는 개체별 민감도(Factor Loading)입니다.\n\n\n\n\nNon-Parallel Trend\n\n평행 추세를 깨뜨리기 위해, 처치 여부(\\(D_i\\))가 무작위가 아니라 추세 민감도(\\(\\gamma_i\\))에 따라 결정되도록 설정합니다.\n\n\\[\nD_i = 1 \\quad \\text{if } \\gamma_i \\text{ is in top } 10\\%, \\quad \\text{else } 0\n\\]\n\n\nCode\ndef generate_nonparallel_data(N=100, T=50, T_pre=40, treated_ratio=0.1, true_tau=10, seed=None):\n    if seed: np.random.seed(seed)\n    \n    # 1. Fixed Effects\n    alpha = np.random.normal(0, 5, size=N)      # Unit FE\n    beta = np.random.normal(0, 5, size=T) + np.linspace(0, 10, T) # Time FE (Trend)\n    \n    # 2. Latent Factor (Time-varying Confounder) causing Non-parallel trends\n    # 시간(t)에 따라 증가하는 패턴 (Trend Factor)\n    f_t = np.linspace(0, 15, T)\n    \n    # 유닛별 민감도 (Loadings)\n    # 처치군이 될 확률이 높은 유닛들이 더 가파른 기울기를 갖도록 설정\n    gamma = np.random.uniform(0, 2, size=N)\n    \n    # 3. Treatment Assignment (Selection on Trends)\n    # gamma(기울기)가 큰 상위 유닛들을 처치군으로 선정 -&gt; 평행 추세 위배\n    N_tr = int(N * treated_ratio)\n    treated_indices = np.argsort(gamma)[-N_tr:]\n    is_treated = np.zeros(N, dtype=bool)\n    is_treated[treated_indices] = True\n    \n    # 4. Generate Outcome Y\n    Y = np.zeros((N, T))\n    for i in range(N):\n        for t in range(T):\n            # Base Model\n            y_val = alpha[i] + beta[t] + gamma[i] * f_t[t] + np.random.normal(0, 1)\n            \n            # Add Treatment Effect\n            if is_treated[i] and t &gt;= T_pre:\n                y_val += true_tau\n            \n            Y[i, t] = y_val\n            \n    # Prepare Output\n    # 처치군 데이터를 맨 뒤로 보내거나 인덱스를 반환해야 하지만, \n    # 여기서는 편의상 SyntheticDiD 클래스 입력 형식에 맞춰 정리\n    \n    # Sort: Control first, Treated last\n    sorted_idx = np.concatenate([np.where(~is_treated)[0], np.where(is_treated)[0]])\n    Y_sorted = Y[sorted_idx, :]\n    \n    # Split\n    N_co = N - N_tr\n    Y_co = Y_sorted[:N_co, :]\n    # SDiD 클래스는 현재 1개의 Treated Unit을 가정하므로, 평균을 내서 1개로 만듭니다.\n    Y_tr = np.mean(Y_sorted[N_co:, :], axis=0).reshape(1, -1)\n    \n    return Y_co, Y_tr, true_tau\n\n\n\n\nCode\n# -------------------------------------------------------\n# 1. 단일 시뮬레이션 데이터 생성\n# -------------------------------------------------------\nY_co, Y_tr, true_tau = generate_nonparallel_data(seed=42, N=100, treated_ratio=0.1)\nT_pre = 40\ntime_axis = np.arange(Y_co.shape[1])\n\n# -------------------------------------------------------\n# 2. Counterfactuals 계산\n# -------------------------------------------------------\n# (1) True Counterfactual (Unobserved Truth)\nY_tr_true_cf = Y_tr.flatten().copy()\nY_tr_true_cf[T_pre:] -= true_tau \n\n# (2) Naive DiD Counterfactual (What DiD assumes)\nmean_tr_pre = np.mean(Y_tr.flatten()[:T_pre])\nmean_co_pre = np.mean(np.mean(Y_co, axis=0)[:T_pre])\nlevel_gap = mean_tr_pre - mean_co_pre\nY_did_naive_cf = np.mean(Y_co, axis=0) + level_gap\n\n# -------------------------------------------------------\n# 3. 시각화\n# -------------------------------------------------------\nplt.figure(figsize=(12, 6))\n\n# (1) Control Units\nplt.plot(time_axis, np.mean(Y_co, axis=0), color='navy', linewidth=2, linestyle='--', label='Average Control')\n\n# (2) Treated Unit (Observed)\nplt.plot(time_axis, Y_tr.flatten(), color='firebrick', linewidth=3, label='Treated (Observed)')\n\n# (3) True Counterfactual (Unobserved Truth) - RED Dotted\nplt.plot(time_axis, Y_tr_true_cf, color='firebrick', linestyle=':', linewidth=2, alpha=0.7, label='True Counterfactual (Target)')\n\n# (4) Naive DiD Counterfactual - GREEN Dashed\nplt.plot(time_axis, Y_did_naive_cf, color='green', linestyle='--', linewidth=2, label='Naive DiD Counterfactual (Biased)')\n\n# Settings\nplt.axvline(x=T_pre, color='black', linestyle='-', label='Intervention')\nplt.title(\"Why DiD Fails: True Counterfactual vs Naive DiD Projection\", fontsize=14)\nplt.xlabel(\"Time\")\nplt.ylabel(\"Outcome Y\")\nplt.legend(loc='upper left')\nplt.grid(True, alpha=0.3)\nplt.show()"
  },
  {
    "objectID": "posts/lecture/L15A/SDiD/part-02/index.html#simulation",
    "href": "posts/lecture/L15A/SDiD/part-02/index.html#simulation",
    "title": "[Causal Inference] 15A. SDiD (Part 2)",
    "section": "2. Simulation",
    "text": "2. Simulation\n\n앞서 정의한 데이터 생성 함수(generate_data)와 SyntheticDiD 클래스를 사용하여 몬테카를로 시뮬레이션을 수행합니다.\n총 50회의 반복 시행을 통해 SDiD, SCM, Standard DID의 성능을 비교합니다.\n\n\n\nCode\n# -------------------------------------------------------\n# Simulation Run\n# -------------------------------------------------------\nN_SIMULATIONS = 50\nresults = {'did': [], 'scm': [], 'sdid': []}\n\nprint(f\"Starting Monte Carlo Simulation ({N_SIMULATIONS} runs)...\")\n\nfor i in range(N_SIMULATIONS):\n    # 1. Generate Data (Non-parallel trends)\n    Y_co, Y_tr, true_tau = generate_nonparallel_data(seed=i)\n    T_pre = 40\n    \n    # 2. Run Models\n    model = SyntheticDiD(Y_co, Y_tr, T_pre)\n    \n    # (1) SDiD\n    est_sdid = model.estimate()\n    \n    # (2) SCM (Intercept=False, Zeta=0)\n    w_scm, _ = model.get_unit_weights(intercept=False, zeta=0)\n    # SCM Estimator Calculation\n    y_tr_post = np.mean(Y_tr[:, T_pre:])\n    y_sc_post = np.mean(w_scm @ Y_co[:, T_pre:])\n    est_scm = y_tr_post - y_sc_post\n    \n    # (3) DiD (Simple TWFE)\n    # Tau = (Tr_post - Tr_pre) - (Co_post - Co_pre)\n    diff_tr = np.mean(Y_tr[:, T_pre:]) - np.mean(Y_tr[:, :T_pre])\n    diff_co = np.mean(Y_co[:, T_pre:]) - np.mean(Y_co[:, :T_pre]) # Mean of all controls\n    est_did = diff_tr - diff_co\n    \n    # Save\n    results['sdid'].append(est_sdid)\n    results['scm'].append(est_scm)\n    results['did'].append(est_did)\n\n# -------------------------------------------------------\n# Result Visualization\n# -------------------------------------------------------\ndf_res = pd.DataFrame(results)\ntrue_tau = 10\n\nplt.figure(figsize=(10, 6))\nsns.boxplot(data=df_res)\nplt.axhline(y=true_tau, color='r', linestyle='--', label='True Effect (10)')\nplt.title(f\"Simulation Results (N={N_SIMULATIONS}): Bias Comparison\")\nplt.ylabel(\"Estimated Effect\")\nplt.legend()\nplt.show()\n\n# Calculate Metrics\nbias = df_res.mean() - true_tau\nrmse = np.sqrt(((df_res - true_tau)**2).mean())\n\nprint(\"=== Performance Metrics ===\")\nprint(f\"{'Method':&lt;10} | {'Bias':&lt;10} | {'RMSE':&lt;10}\")\nprint(\"-\" * 35)\nfor method in ['did', 'scm', 'sdid']:\n    print(f\"{method.upper():&lt;10} | {bias[method]:.4f}     | {rmse[method]:.4f}\")\n\n\nStarting Monte Carlo Simulation (50 runs)...\n\n\n/opt/anaconda3/envs/causal-inference-study/lib/python3.9/site-packages/cvxpy/problems/problem.py:1539: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n  warnings.warn(\n\n\n\n\n\n\n\n\n\n=== Performance Metrics ===\nMethod     | Bias       | RMSE      \n-----------------------------------\nDID        | 7.5670     | 7.5781\nSCM        | 1.3289     | 1.3910\nSDID       | 0.6798     | 0.7493\n\n\n\n결과\n\nDiD: 평행 추세 가정이 깨졌기 때문에(처치군이 더 가파른 추세를 가짐), 처치 효과를 과대평가(Bias 발생)하게 됩니다.\nSCM: 대조군을 합성하여 추세를 맞추려 노력하지만, 정규화(Regularization)나 시간 가중치(Time weights)의 부재로 인해 SDiD보다는 성능이 떨어질 수 있습니다.\nSDiD: Unit weights로 추세 차이를 보정하고, Time weights로 시간적 변동성까지 잡아내어 가장 낮은 편향(Bias)과 오차(RMSE)를 보여줍니다."
  },
  {
    "objectID": "posts/lecture/L15A/SDiD/part-02/index.html#data-generation-1",
    "href": "posts/lecture/L15A/SDiD/part-02/index.html#data-generation-1",
    "title": "[Causal Inference] 15A. SDiD (Part 2)",
    "section": "1. Data Generation",
    "text": "1. Data Generation\n\n데이터 생성 모형 (DGP)\n\\[\nY_{it} = \\underbrace{\\alpha_i}_{\\text{Unit FE}} + \\underbrace{\\beta_t}_{\\text{Time FE}} + \\underbrace{\\gamma_i f_t}_{\\text{Trend Factor}} + \\tau D_{it} + \\varepsilon_{it}\n\\]\n\n\nThe Trap\n\nConvex Hull 위배\n\n처치 유닛의 고정 효과(\\(\\alpha_{tr}\\))를 통제 유닛들의 최댓값보다 훨씬 크게 설정합니다.\n\n\\[\n\\alpha_{tr} \\gg \\max_{j \\in Co}(\\alpha_j) \\quad (\\text{Code: } \\max + 30)\n\\]\n\nSCM의 가중치는 \\(\\sum \\omega_i = 1, \\omega_i \\ge 0\\) 제약을 따르므로, 합성 통제군은 결코 통제 유닛 중 가장 큰 값보다 커질 수 없습니다. \\[\n\\hat{Y}_{tr}^{SCM} = \\sum \\omega_i Y_{i} \\le \\max(Y_{co}) &lt; Y_{tr}\n\\]\n즉, 절편 보정이 없는 SCM은 처치 유닛의 높은 레벨을 절대 따라잡을 수 없습니다.\n\n\n\nCode\ndef generate_level_shifted_data(N=50, T=50, T_pre=40, true_tau=10, seed=None):\n    if seed: np.random.seed(seed)\n    \n    # 1. Base Components\n    # Control Units의 Alpha는 작게 설정 (0 ~ 10)\n    alpha = np.random.uniform(0, 10, size=N)\n    \n    # Time Trend (Common)\n    beta = np.linspace(0, 5, T)\n    \n    # 2. Level Shift (Make Treated Unit an Outlier)\n    # 처치 유닛의 Alpha를 대조군 최댓값보다 훨씬 크게 설정 (+30)\n    # -&gt; SCM은 가중치 합이 1이라서 죽었다 깨어나도 이 레벨을 못 맞춤\n    treated_idx = N - 1  # 마지막 유닛을 처치군으로 지정\n    alpha[treated_idx] = np.max(alpha[:-1]) + 30 \n    \n    # 3. Non-Parallel Trend Factor (Optional but good for killing DiD too)\n    # 처치 유닛에게만 추가적인 성장 추세 부여\n    trend_factor = np.linspace(0, 5, T)\n    gamma = np.zeros(N)\n    gamma[treated_idx] = 1.0 # 처치 유닛만 더 가파르게 성장\n    \n    # 4. Generate Y\n    Y = np.zeros((N, T))\n    for i in range(N):\n        # Y = Alpha + Beta + (Gamma * Trend) + Noise\n        Y[i, :] = alpha[i] + beta + (gamma[i] * trend_factor) + np.random.normal(0, 1, T)\n        \n        # Add Treatment Effect (Post-period)\n        if i == treated_idx:\n            Y[i, T_pre:] += true_tau\n            \n    # Output Split\n    Y_co = Y[:-1, :]                 # (N-1) x T\n    Y_tr = Y[-1, :].reshape(1, -1)   # 1 x T\n    \n    return Y_co, Y_tr, true_tau\n\n\n\n\nCode\nY_co, Y_tr, true_tau = generate_level_shifted_data(seed=42)\nT_pre = 40\nyears = np.arange(50)\n\n# Run Models to get fitted values\nmodel = SyntheticDiD(Y_co, Y_tr, T_pre)\n\n# (1) SCM Fit (Constrained)\nw_scm, _ = model.get_unit_weights(intercept=False, zeta=0)\nY_scm_fit = w_scm @ Y_co\n\n# (2) SDiD Fit (Intercept Allowed)\nw_sdid, w0_sdid = model.get_unit_weights(intercept=True)\nY_sdid_fit = w0_sdid + w_sdid @ Y_co\n\nplt.figure(figsize=(12, 6))\n\n# Raw Data\nplt.plot(years, Y_co.T, color='gray', alpha=0.15)\nplt.plot(years, Y_tr.flatten(), color='firebrick', linewidth=3, label='Treated (Observed)')\n\n# SCM Fit (Failure)\nplt.plot(years, Y_scm_fit, color='blue', linestyle='--', linewidth=2, label='SCM Fit (No Intercept)')\n\n# SDiD Fit (Success)\nplt.plot(years, Y_sdid_fit, color='green', linestyle='--', linewidth=2, label='SDiD Fit (With Intercept)')\n\nplt.axvline(x=T_pre, color='black', linestyle=':', label='Intervention')\nplt.title(\"SCM Limitation: Convex Hull Condition Failure\", fontsize=14)\nplt.xlabel(\"Time\")\nplt.ylabel(\"Outcome Y\")\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n\n\n/opt/anaconda3/envs/causal-inference-study/lib/python3.9/site-packages/cvxpy/problems/problem.py:1539: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n  warnings.warn("
  },
  {
    "objectID": "posts/lecture/L15A/SDiD/part-02/index.html#simulation-1",
    "href": "posts/lecture/L15A/SDiD/part-02/index.html#simulation-1",
    "title": "[Causal Inference] 15A. SDiD (Part 2)",
    "section": "2. Simulation",
    "text": "2. Simulation\n\n앞서 정의한 Level Shift 데이터(Convex Hull 위배)를 사용하여 50회 반복 시뮬레이션을 수행합니다.\n\n\n\nCode\n# -------------------------------------------------------\n# Settings\n# -------------------------------------------------------\nN_SIM = 50\nresults = {'did': [], 'scm': [], 'sdid': []}\n\nprint(f\"Starting Level-Shift Simulation ({N_SIM} runs)...\")\n\n# -------------------------------------------------------\n# Simulation Loop\n# -------------------------------------------------------\nfor i in range(N_SIM):\n    # 1. Generate Data (Outlier Treated Unit)\n    Y_co, Y_tr, true_tau = generate_level_shifted_data(seed=i)\n    T_pre = 40\n    \n    # 2. Initialize Model\n    model = SyntheticDiD(Y_co, Y_tr, T_pre)\n    \n    # (1) SDiD Estimate (Intercept Allowed)\n    est_sdid = model.estimate()\n    \n    # (2) SCM Estimate (Intercept False)\n    w_scm, _ = model.get_unit_weights(intercept=False, zeta=0)\n    \n    # Counterfactual: w * Y_co (No intercept adjustment)\n    y_tr_post = np.mean(Y_tr[:, T_pre:])\n    y_sc_post = np.mean(w_scm @ Y_co[:, T_pre:]) \n    est_scm = y_tr_post - y_sc_post\n    \n    # (3) DiD Estimate (Standard TWFE)\n    diff_tr = np.mean(Y_tr[:, T_pre:]) - np.mean(Y_tr[:, :T_pre])\n    diff_co = np.mean(Y_co[:, T_pre:]) - np.mean(Y_co[:, :T_pre])\n    est_did = diff_tr - diff_co\n    \n    # Save\n    results['sdid'].append(est_sdid)\n    results['scm'].append(est_scm)\n    results['did'].append(est_did)\n\n# -------------------------------------------------------\n# Visualization\n# -------------------------------------------------------\ndf_res = pd.DataFrame(results)\n\nplt.figure(figsize=(10, 6))\nsns.boxplot(data=df_res)\n\n# 참값(True Tau) 표시\nplt.axhline(y=true_tau, color='r', linestyle='--', linewidth=2, label=f'True Effect ({true_tau})')\n\nplt.title(f\"Simulation Results (N={N_SIM}): Level-Shift & Trend Failure\")\nplt.ylabel(\"Estimated Treatment Effect\")\nplt.xlabel(\"Method\")\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n\n# -------------------------------------------------------\n# Performance Metrics\n# -------------------------------------------------------\nbias = df_res.mean() - true_tau\nrmse = np.sqrt(((df_res - true_tau)**2).mean())\n\nprint(\"\\n=== Performance Metrics (SCM Limitation Scenario) ===\")\nprint(f\"{'Method':&lt;10} | {'Bias':&lt;10} | {'RMSE':&lt;10}\")\nprint(\"-\" * 35)\nfor method in ['did', 'scm', 'sdid']:\n    print(f\"{method.upper():&lt;10} | {bias[method]:.4f}     | {rmse[method]:.4f}\")\n\n\nStarting Level-Shift Simulation (50 runs)...\n\n\n\n\n\n\n\n\n\n\n=== Performance Metrics (SCM Limitation Scenario) ===\nMethod     | Bias       | RMSE      \n-----------------------------------\nDID        | 2.5843     | 2.6168\nSCM        | 34.6187     | 34.6213\nSDID       | 2.6393     | 2.7111\n\n\n\n결과\n\nSCM: Bias와 RMSE가 매우 큽니다. 이는 SCM이 처치 유닛의 높은 초기값(Level)을 합성해내지 못했기 때문입니다. 즉, “Convex Hull Condition”이 위배되면 SCM은 신뢰할 수 없습니다.\nDID: 레벨 차이가 커도 차분 과정에서 사라지므로 SCM보다는 훨씬 나은 성능을 보입니다. 단, 미세한 추세 차이로 인한 편향은 남아 있습니다.\nSDiD: 절편()으로 레벨 차이를 완벽히 잡고, 가중치로 추세까지 보정하여 Bias와 RMSE 모두 가장 낮습니다."
  },
  {
    "objectID": "posts/lecture/L02/part-02/index.html",
    "href": "posts/lecture/L02/part-02/index.html",
    "title": "[Causal Inference] 02. Causal Models and Graphs (Part 2)",
    "section": "",
    "text": "기존의 통계학이나 머신러닝의 추론(Inference)은 주로 결합 확률 분포(Joint Distribution) \\(P(v)\\)를 파악하는 데 집중합니다. [cite_start]“고객이 A를 샀을 때 B도 살 확률은?”(\\(P(B|A)\\))과 같은 질문은 데이터의 상관관계(Association)만으로도 충분히 답할 수 있습니다. [cite: 2412-2419]\n하지만 “가격을 두 배로 올리면 판매량은 어떻게 변할까?”와 같은 개입(Intervention)이나 반사실적(Counterfactual) 질문에 답하기 위해서는 데이터 그 자체(\\(P\\))를 넘어, 데이터가 생성되는 현실의 메커니즘(Reality)을 이해해야 합니다. [cite_start]이를 위해 우리는 구조적 인과 모델(Structural Causal Model, SCM)이라는 새로운 언어를 배웁니다. [cite: 2421-2449]\n\n\n[cite_start]강의에서는 의사결정의 어려움을 보여주기 위해 가상의 전염병과 치료제 시나리오를 제시합니다. [cite: 2236-2246]\n\n상황: 특정 도시에 전염병이 돌고 있고, 치료제(Drug)가 있습니다.\n숨겨진 진실(Reality - Unknown to physicians):\n\n부유층(Rich): 생활 환경이 좋아 약물 복용 여부와 상관없이 생존합니다.\n빈곤층(Poor):\n\n유전 인자(Gene)가 없는 경우: 자연 치유력이 없어 사망합니다.\n유전 인자가 있는 경우: 약을 먹으면 알레르기 반응으로 사망하고, 안 먹으면 생존합니다.\n\n현재 처방 관행: 약값이 비싸서 의사들은 부유층에게만 약을 처방합니다.\n\n\n이 상황에서 데이터만 관측하면(\\(P(r, d, a)\\)), 약을 먹은 사람(주로 부유층)은 생존율이 높고, 안 먹은 사람(주로 빈곤층)은 생존율이 낮게 나옵니다. 머신러닝 모델은 “약을 먹는 것이 생존에 유리하다”고 잘못된 결론을 내릴 수 있습니다. [cite_start]하지만 실제 메커니즘(SCM)을 안다면, “누구에게도 약을 주지 말아야 한다(빈곤층에게는 치명적, 부유층에게는 무의미)”는 정반대의 결론에 도달합니다. [cite: 2340-2402]\n즉, 데이터(\\(P\\))는 현실(\\(M\\))의 그림자일 뿐이며, 올바른 인과 추론을 위해서는 \\(M\\)을 모델링해야 합니다.\n\n\n\nFigure: 기존 통계적 추론과 인과 추론의 패러다임 비교. 통계적 추론은 데이터 P 내에서의 성질 Q(P)를 찾지만, 인과 추론은 데이터 생성 모델 M을 통해 현실을 이해하고 P’를 추정한다."
  },
  {
    "objectID": "posts/lecture/L02/part-02/index.html#motivation-simpsons-paradox-example",
    "href": "posts/lecture/L02/part-02/index.html#motivation-simpsons-paradox-example",
    "title": "[Causal Inference] 02. Causal Models and Graphs (Part 2)",
    "section": "",
    "text": "[cite_start]강의에서는 의사결정의 어려움을 보여주기 위해 가상의 전염병과 치료제 시나리오를 제시합니다. [cite: 2236-2246]\n\n상황: 특정 도시에 전염병이 돌고 있고, 치료제(Drug)가 있습니다.\n숨겨진 진실(Reality - Unknown to physicians):\n\n부유층(Rich): 생활 환경이 좋아 약물 복용 여부와 상관없이 생존합니다.\n빈곤층(Poor):\n\n유전 인자(Gene)가 없는 경우: 자연 치유력이 없어 사망합니다.\n유전 인자가 있는 경우: 약을 먹으면 알레르기 반응으로 사망하고, 안 먹으면 생존합니다.\n\n현재 처방 관행: 약값이 비싸서 의사들은 부유층에게만 약을 처방합니다.\n\n\n이 상황에서 데이터만 관측하면(\\(P(r, d, a)\\)), 약을 먹은 사람(주로 부유층)은 생존율이 높고, 안 먹은 사람(주로 빈곤층)은 생존율이 낮게 나옵니다. 머신러닝 모델은 “약을 먹는 것이 생존에 유리하다”고 잘못된 결론을 내릴 수 있습니다. [cite_start]하지만 실제 메커니즘(SCM)을 안다면, “누구에게도 약을 주지 말아야 한다(빈곤층에게는 치명적, 부유층에게는 무의미)”는 정반대의 결론에 도달합니다. [cite: 2340-2402]\n즉, 데이터(\\(P\\))는 현실(\\(M\\))의 그림자일 뿐이며, 올바른 인과 추론을 위해서는 \\(M\\)을 모델링해야 합니다.\n\n\n\nFigure: 기존 통계적 추론과 인과 추론의 패러다임 비교. 통계적 추론은 데이터 P 내에서의 성질 Q(P)를 찾지만, 인과 추론은 데이터 생성 모델 M을 통해 현실을 이해하고 P’를 추정한다."
  },
  {
    "objectID": "posts/lecture/L02/part-02/index.html#definition",
    "href": "posts/lecture/L02/part-02/index.html#definition",
    "title": "[Causal Inference] 02. Causal Models and Graphs (Part 2)",
    "section": "2.1 Definition",
    "text": "2.1 Definition\n[cite_start]SCM \\(\\mathcal{M}\\)은 4개의 요소 \\(\\langle V, U, F, P(U) \\rangle\\)로 구성된 튜플입니다. [cite: 2548-2554]\n\n\\(V = \\{V_1, ..., V_n\\}\\) (Endogenous Variables): 모델 내부에서 결정되며, 우리가 관측할 수 있는 변수들입니다.\n\\(U = \\{U_1, ..., U_m\\}\\) (Exogenous Variables): 모델 외부에서 결정되는 변수들로, 관측되지 않는 배경 요인(Background factors)이나 노이즈를 의미합니다.\n\\(F = \\{f_1, ..., f_n\\}\\) (Structural Functions): 각 내생 변수 \\(V_i\\)가 어떻게 결정되는지를 정의하는 함수 집합입니다. \\[v_i \\leftarrow f_i(pa_i, u_i)\\] 여기서 \\(pa_i \\subseteq V \\setminus \\{V_i\\}\\)는 \\(V_i\\)의 부모 변수(직접적인 원인)들이고, \\(u_i \\subseteq U\\)는 관련된 외생 변수입니다.\n\\(P(U)\\): 외생 변수 \\(U\\)에 대한 확률 분포입니다."
  },
  {
    "objectID": "posts/lecture/L02/part-02/index.html#properties-of-scm",
    "href": "posts/lecture/L02/part-02/index.html#properties-of-scm",
    "title": "[Causal Inference] 02. Causal Models and Graphs (Part 2)",
    "section": "2.2 Properties of SCM",
    "text": "2.2 Properties of SCM\n[cite_start]SCM은 다음과 같은 중요한 성질을 가집니다. [cite: 2572-2637]\n\nInduces \\(P(V)\\): 외생 변수의 분포 \\(P(U)\\)와 함수 \\(F\\)를 통해 관측 변수들의 결합 확률 분포 \\(P(V)\\)가 결정됩니다.\nInduces Causal Diagram: 변수 간의 함수적 관계(\\(f_i\\))를 통해 인과 그래프(DAG)를 그릴 수 있습니다.\n\n\n\n\nFigure: SCM의 개념도. 외생 변수 U가 확률 분포 P(U)를 따르고, 함수 F를 통해 내생 변수 V의 값을 결정하여 관측 데이터 분포 P(V)를 유도한다."
  },
  {
    "objectID": "posts/lecture/L02/part-02/index.html#markovian-condition",
    "href": "posts/lecture/L02/part-02/index.html#markovian-condition",
    "title": "[Causal Inference] 02. Causal Models and Graphs (Part 2)",
    "section": "4.1 Markovian Condition",
    "text": "4.1 Markovian Condition\n[cite_start]만약 모든 외생 변수 \\(U_i\\)들이 서로 독립(Jointly Independent)이라면, 즉 그래프에 양방향 엣지(\\(\\leftrightarrow\\))가 하나도 없다면, 이 모델을 Markovian이라고 합니다. [cite: 2988-2991]"
  },
  {
    "objectID": "posts/lecture/L02/part-02/index.html#mathematical-derivation",
    "href": "posts/lecture/L02/part-02/index.html#mathematical-derivation",
    "title": "[Causal Inference] 02. Causal Models and Graphs (Part 2)",
    "section": "4.2 Mathematical Derivation",
    "text": "4.2 Mathematical Derivation\n[cite_start]Markovian 가정 하에서 결합 확률 분포 \\(P(\\mathbf{v})\\)가 어떻게 분해되는지 단계별로 유도해 보겠습니다. [cite: 2992-2993]\nStep 1: Law of Total Probability 모든 변수 \\(V\\)의 결합 확률은 외생 변수 \\(U\\)를 포함한 전체 확률에서 \\(U\\)를 합(Summing out)하여 얻습니다. SCM에서 \\(v_i\\)는 \\(pa_i\\)와 \\(u_i\\)에 의해 결정되므로(\\(P(v_i|pa_i, u_i)\\)는 0 또는 1), 다음과 같이 쓸 수 있습니다. \\[P(\\mathbf{v}) = \\sum_{\\mathbf{u}} P(\\mathbf{u}) \\prod_{V_i \\in V} P(v_i \\mid pa_i, u_i)\\]\nStep 2: Independence of Exogenous Variables Markovian 가정에 의해 \\(U\\)들이 서로 독립이므로, \\(P(\\mathbf{u}) = \\prod P(u_i)\\)가 됩니다. \\[= \\sum_{\\mathbf{u}} \\prod_{V_i \\in V} P(v_i \\mid pa_i, u_i) P(u_i)\\]\nStep 3: Independence of \\(U_i\\) and \\(Pa_i\\) 외생 변수 \\(U_i\\)는 시스템 외부에서 결정되므로 내생 변수인 부모 \\(Pa_i\\)와 독립입니다. 따라서 \\(P(u_i) = P(u_i \\mid pa_i)\\)로 쓸 수 있습니다. 이를 식에 대입하고, 확률의 곱셈 법칙(\\(P(A|B)P(B) = P(A,B)\\))을 적용합니다. \\[= \\sum_{\\mathbf{u}} \\prod_{V_i \\in V} P(v_i \\mid pa_i, u_i) P(u_i \\mid pa_i)\\] \\[= \\sum_{\\mathbf{u}} \\prod_{V_i \\in V} P(v_i, u_i \\mid pa_i)\\]\nStep 4: Commutativity of Sum and Product 각 항은 자신에게 해당되는 \\(u_i\\)에만 의존하므로, 전체 합(\\(\\sum_{\\mathbf{u}}\\))을 개별 합(\\(\\sum_{u_i}\\))의 곱으로 바꿀 수 있습니다. \\[= \\prod_{V_i \\in V} \\left( \\sum_{u_i} P(v_i, u_i \\mid pa_i) \\right)\\]\nStep 5: Marginalization (Final Result) 괄호 안의 식은 결합 확률에서 \\(u_i\\)를 마지널라이즈(Marginalize)한 것과 같으므로 최종적으로 다음 식이 성립합니다. \\[\\boxed{P(\\mathbf{v}) = \\prod_{V_i \\in V} P(v_i \\mid pa_i)}\\]\n이 결과는 관측 불가능한 \\(U\\)를 모르더라도, 오직 부모-자식 간의 관계(Local Information)만으로 전체 시스템의 분포를 설명할 수 있음을 의미합니다."
  },
  {
    "objectID": "posts/lecture/L02/part-02/index.html#the-three-basic-structures-triplets",
    "href": "posts/lecture/L02/part-02/index.html#the-three-basic-structures-triplets",
    "title": "[Causal Inference] 02. Causal Models and Graphs (Part 2)",
    "section": "5.1 The Three Basic Structures (Triplets)",
    "text": "5.1 The Three Basic Structures (Triplets)\n\n1. Chain (Causal Chain)\n\n구조: \\(X \\rightarrow Z \\rightarrow Y\\)\n해석: \\(X\\)가 \\(Z\\)를 유발하고, \\(Z\\)가 \\(Y\\)를 유발합니다. (예: 공부 습관 \\(\\to\\) 수능 점수 \\(\\to\\) 대학 합격)\n독립성:\n\n\\(Z\\)를 모를 때: \\(X\\)와 \\(Y\\)는 종속적입니다.\n\\(Z\\)를 알 때 (Given \\(Z\\)): \\(X\\)가 \\(Y\\)에 미치는 영향은 \\(Z\\)에 의해 차단(Blocked)되므로 \\(X \\perp Y \\mid Z\\) (독립)입니다.\n\n\n\n\n\nFigure: Causal Chain 구조. 중간 변수 Z를 관측하면 X와 Y의 정보 흐름이 차단되어 독립이 된다.\n\n\n\n\n2. Fork (Common Cause)\n\n구조: \\(X \\leftarrow Z \\rightarrow Y\\)\n해석: \\(Z\\)가 \\(X\\)와 \\(Y\\)의 공통 원인입니다. (예: 비 \\(\\to\\) 교통체증, 비 \\(\\to\\) 우산 사용)\n독립성:\n\n\\(Z\\)를 모를 때: 공통 원인에 의해 \\(X\\)와 \\(Y\\)는 상관관계를 가집니다(Spurious Correlation).\n\\(Z\\)를 알 때 (Given \\(Z\\)): 공통 원인을 통제했으므로 \\(X \\perp Y \\mid Z\\) (독립)입니다.\n\n\n\n\n\nFigure: Common Cause (Fork) 구조. 공통 원인 Z를 통제하면 X와 Y 사이의 허위 상관관계가 사라진다.\n\n\n\n\n3. Collider (Common Effect)\n\n구조: \\(X \\rightarrow Z \\leftarrow Y\\)\n해석: 서로 독립인 \\(X\\)와 \\(Y\\)가 공통 결과 \\(Z\\)를 유발합니다. (예: 감기 \\(\\to\\) 결석, 휴일 \\(\\to\\) 결석)\n독립성:\n\n\\(Z\\)를 모를 때: \\(X\\)와 \\(Y\\)는 서로 독립입니다. (\\(P(X,Y) = P(X)P(Y)\\))\n\\(Z\\)를 알 때 (Given \\(Z\\)): \\(X \\not\\perp Y \\mid Z\\) (종속)이 됩니다. 이를 “Explaining Away” 현상이라고 합니다. 결석(\\(Z=1\\))했는데 휴일이 아니라면(\\(Y=0\\)), 감기일 확률(\\(X=1\\))이 높아지기 때문입니다.\n주의: Collider 본인뿐만 아니라 Collider의 자손(Descendant)을 관측해도 경로가 열립니다.\n\n\n\n\n\nFigure: Common Effect (Collider) 구조. 두 독립적인 원인이 공통 결과 Z를 조건부로 알게 되었을 때 종속적으로 변하는 Explaining Away 현상을 보여준다."
  },
  {
    "objectID": "posts/lecture/L02/part-02/index.html#d-separation-rule",
    "href": "posts/lecture/L02/part-02/index.html#d-separation-rule",
    "title": "[Causal Inference] 02. Causal Models and Graphs (Part 2)",
    "section": "5.2 d-separation Rule",
    "text": "5.2 d-separation Rule\n[cite_start]이 세 가지 규칙을 일반화하여 그래프상의 두 노드 \\(X, Y\\)가 조건부 집합 \\(Z\\)에 대해 독립인지 판별하는 규칙을 d-separation이라고 합니다. [cite: 3224-3228]\n\n두 노드 사이의 모든 경로가 차단(Blocked)되면 d-separated 되었다고 합니다.\n경로가 차단되는 조건:\n\n경로 상에 \\(Z\\)에 포함된 Chain이나 Fork 노드가 있을 때.\n경로 상에 Collider가 있으면서, 그 Collider와 자손들이 하나도 \\(Z\\)에 포함되지 않았을 때."
  },
  {
    "objectID": "posts/lecture/L05/part-02/index.html",
    "href": "posts/lecture/L05/part-02/index.html",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 2)",
    "section": "",
    "text": "이전 포스트(Part 1)에서 우리는 Back-door Criterion이 인과 효과 식별을 위한 충분조건(Sufficient condition)이지만, 필요조건(Necessary condition)은 아님을 확인했습니다. 즉, Back-door Criterion을 만족하지 못하더라도 변수들의 구조적 위치에 따라 여전히 조정(Adjustment)을 통해 인과 효과를 구할 수 있는 경우가 존재합니다.\n이번 포스트에서는 인과 효과 \\(P(y|do(x))\\)를 표준 조정 공식(Standard Adjustment Formula)으로 식별하기 위한 필요충분조건(Necessary and Sufficient Condition)인 Adjustment Criterion에 대해 다룹니다.\n\\[\nZ \\text{ satisfies Adjustment Criterion} \\iff P(y|do(x)) = \\sum_{z} P(y|x,z)P(z)\n\\]\n[cite_start]이를 위해 Proper Causal Path라는 개념을 도입하고, 복잡한 그래프에서 유효한 조정 집합 \\(Z\\)를 찾아내는 알고리즘과 명시적 구성(Explicit Construction) 방법을 살펴봅니다[cite: 131, 134]."
  },
  {
    "objectID": "posts/lecture/L05/part-02/index.html#definition",
    "href": "posts/lecture/L05/part-02/index.html#definition",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 2)",
    "section": "2.1. Definition",
    "text": "2.1. Definition\n[cite_start]Proper Causal Path (진인과경로)는 \\(X\\)에서 출발하여 \\(Y\\)로 향하는 인과 경로(Directed path) 중, 시작점인 \\(X\\)를 제외하고는 \\(X\\) 집합의 다른 노드를 거치지 않는 경로를 의미합니다[cite: 138, 139].\n\nCausal Path: 화살표의 방향이 일관되게 \\(X\\)에서 \\(Y\\)로 흐르는 경로.\nProper: 경로상에 \\(X\\)의 다른 원소가 포함되지 않음.\n\n [cite_start](그림 설명: \\(X=\\{X_1, X_2\\}\\)인 상황. \\(X_1 \\to W_3 \\to Y\\)는 \\(X\\)의 다른 원소를 거치지 않으므로 Proper Causal Path이다. 반면 \\(X_1 \\to W_1 \\to X_2 \\to W_2 \\to Y\\)는 경로 중간에 \\(X_2(\\in X)\\)가 포함되므로 Non-proper Causal Path이다.) [cite: 146, 148]"
  },
  {
    "objectID": "posts/lecture/L05/part-02/index.html#why-proper-causal-paths-matter",
    "href": "posts/lecture/L05/part-02/index.html#why-proper-causal-paths-matter",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 2)",
    "section": "2.2. Why Proper Causal Paths Matter?",
    "text": "2.2. Why Proper Causal Paths Matter?\n우리가 구하고자 하는 것은 \\(X\\)가 \\(Y\\)에 미치는 총 효과(Total Effect)입니다. [cite_start]따라서 \\(X\\)에서 \\(Y\\)로 흐르는 인과적 흐름을 담고 있는 Proper Causal Path를 차단해서는 안 됩니다[cite: 160].\n만약 Proper Causal Path 상에 있는 변수(Mediator)나 그 변수의 후손(Descendant)을 조정 집합 \\(Z\\)에 포함하면 어떻게 될까요? 간단한 체인 구조 \\(X \\to W \\to Y\\)와 \\(W \\to Z\\)가 있는 그래프를 가정해 봅시다. [cite_start]여기서 \\(P(y|do(x)) = P(y|x)\\)입니다 (Back-door 경로가 없음)[cite: 152, 161].\n하지만 우리가 \\(Z\\)(Mediator의 후손)에 대해 조정(Adjustment)을 수행하면 편향이 발생합니다. 이를 수식으로 확인해 봅시다.\n\\[\n\\begin{aligned}\n\\sum_{z} P(y|x,z)P(z) &= \\sum_{z,w} P(y|x,z,w)P(w|x,z)P(z) \\quad (\\text{Law of Total Probability}) \\\\\n&= \\sum_{z,w} P(y|w)P(w|x,z)P(z) \\quad (Y \\perp\\!\\!\\perp X, Z | W) \\\\\n&= \\sum_{w} P(y|w) \\sum_{z} P(w|x,z)P(z)\n\\end{aligned}\n\\] [cite_start][cite: 162-165]\n진정한 인과 효과는 \\(P(y|do(x)) = \\sum_w P(y|w)P(w|x)\\)입니다. 하지만 위 식의 두 번째 항 \\(\\sum_{z} P(w|x,z)P(z)\\)는 일반적으로 \\(P(w|x)\\)와 다릅니다. [cite_start]이는 \\(P(z) \\neq P(z|x)\\)이기 때문입니다[cite: 172, 174].\n[cite_start]결국, Proper Causal Path 상의 변수나 그 후손을 조정하면 인과 효과 추정치가 왜곡(disturbed)됩니다[cite: 175]."
  },
  {
    "objectID": "posts/lecture/L05/part-02/index.html#condition-i-preserve-causal-paths",
    "href": "posts/lecture/L05/part-02/index.html#condition-i-preserve-causal-paths",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 2)",
    "section": "3.1. Condition (i): Preserve Causal Paths",
    "text": "3.1. Condition (i): Preserve Causal Paths\n\nCondition (i): \\(Z\\)의 어떤 원소도 \\(X\\)에서 \\(Y\\)로 가는 Proper Causal Path 상에 있는 변수(\\(X\\) 제외)의 후손(descendant)이 아니어야 한다.\n\n\\[\nZ \\cap De(W \\setminus X) = \\emptyset, \\quad \\text{for any } W \\text{ on a proper causal path}\n\\]\n[cite_start]이 조건은 우리가 인과 경로를 실수로 차단하거나 왜곡하는 것을 방지합니다[cite: 180, 186]. 즉, “미래의 변수”를 통제하지 말라는 원칙을 더 엄밀하게 정의한 것입니다."
  },
  {
    "objectID": "posts/lecture/L05/part-02/index.html#condition-ii-block-spurious-paths",
    "href": "posts/lecture/L05/part-02/index.html#condition-ii-block-spurious-paths",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 2)",
    "section": "3.2. Condition (ii): Block Spurious Paths",
    "text": "3.2. Condition (ii): Block Spurious Paths\n\nCondition (ii): \\(Z\\)는 \\(X\\)와 \\(Y\\) 사이의 모든 Proper Non-causal Path를 차단(block)해야 한다.\n\n\\[\n(Y \\perp\\!\\!\\perp X | Z)_{\\mathcal{G}'}\n\\]\n여기서 Proper Non-causal Path란 \\(X\\)에서 시작하지만 인과 경로가 아닌(화살표가 \\(X\\)로 들어오거나 중간에 꺾이는) 경로들을 의미합니다. [cite_start]이것들은 교란(Confounding) 요인이므로 반드시 막아야 합니다[cite: 190, 197].\n\n[cite_start]Note: 초기 논문에서는 단순히 ’non-causal paths’라고 했으나, 이후 ’proper non-causal paths’로 수정되었습니다[cite: 198, 199]."
  },
  {
    "objectID": "posts/lecture/L05/part-03/index.html",
    "href": "posts/lecture/L05/part-03/index.html",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 3)",
    "section": "",
    "text": "이전 포스트들에서 우리는 Adjustment Criterion의 이론적 배경과 정의를 살펴보았습니다. 우리는 특정 변수 집합 \\(Z\\)가 주어졌을 때, 그것이 인과 효과 \\(P(y|do(x))\\)를 식별(Identification)하기 위해 유효한지(Admissible) 판별하는 방법을 알고 있습니다.\n하지만 현실적인 인과 추론 문제에서는 단순히 “이 \\(Z\\)가 유효한가?”를 묻는 것을 넘어, “유효한 \\(Z\\)들을 어떻게 모두 찾을 것인가?” 또는 “어떤 \\(Z\\)를 선택하는 것이 최선인가?”라는 질문에 직면하게 됩니다.\n\n\n[cite_start]일반적으로 주어진 인과 그래프 \\(\\mathcal{G}\\)에서 Admissible Set은 하나가 아니라 여러 개 존재할 수 있습니다. [cite: 439] 그렇다면 우리는 왜 여러 집합을 고려해야 할까요?\n\nMeasurement Cost (측정 비용): 어떤 변수는 측정하기 매우 비싸거나 위험할 수 있습니다.\nVariance (분산): 어떤 조정 집합은 다른 집합보다 추정량의 분산을 더 줄여줄 수 있습니다.\n[cite_start]Availability & Ethics: 개인정보 보호나 공정성 이슈로 특정 변수를 사용할 수 없을 수 있습니다. [cite: 444]\n\n\nExample: 어떤 질병(\\(X\\))과 결과(\\(Y\\)) 사이의 인과 효과를 추정할 때, 유전적 조건(\\(A\\))과 두통(\\(B\\))이 모두 각각 유효한 조정 집합이라고 가정해 봅시다 (\\(\\{A\\}\\) is admissible, \\(\\{B\\}\\) is admissible). * \\(A\\) (유전자): 검사 비용이 비쌈, 개인정보 이슈. * \\(B\\) (두통): 설문으로 쉽게 확인 가능.\n이 경우, 이론적으로는 둘 다 유효하지만 현실적으로는 \\(B\\)를 선택하는 것이 훨씬 유리합니다. [cite_start]따라서 우리는 가능한 모든 Admissible Set을 나열하고, 그중 비용-효율적인 것을 선택할 필요가 있습니다. [cite: 446-454]"
  },
  {
    "objectID": "posts/lecture/L05/part-03/index.html#motivation-why-find-all-sets",
    "href": "posts/lecture/L05/part-03/index.html#motivation-why-find-all-sets",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 3)",
    "section": "",
    "text": "[cite_start]일반적으로 주어진 인과 그래프 \\(\\mathcal{G}\\)에서 Admissible Set은 하나가 아니라 여러 개 존재할 수 있습니다. [cite: 439] 그렇다면 우리는 왜 여러 집합을 고려해야 할까요?\n\nMeasurement Cost (측정 비용): 어떤 변수는 측정하기 매우 비싸거나 위험할 수 있습니다.\nVariance (분산): 어떤 조정 집합은 다른 집합보다 추정량의 분산을 더 줄여줄 수 있습니다.\n[cite_start]Availability & Ethics: 개인정보 보호나 공정성 이슈로 특정 변수를 사용할 수 없을 수 있습니다. [cite: 444]\n\n\nExample: 어떤 질병(\\(X\\))과 결과(\\(Y\\)) 사이의 인과 효과를 추정할 때, 유전적 조건(\\(A\\))과 두통(\\(B\\))이 모두 각각 유효한 조정 집합이라고 가정해 봅시다 (\\(\\{A\\}\\) is admissible, \\(\\{B\\}\\) is admissible). * \\(A\\) (유전자): 검사 비용이 비쌈, 개인정보 이슈. * \\(B\\) (두통): 설문으로 쉽게 확인 가능.\n이 경우, 이론적으로는 둘 다 유효하지만 현실적으로는 \\(B\\)를 선택하는 것이 훨씬 유리합니다. [cite_start]따라서 우리는 가능한 모든 Admissible Set을 나열하고, 그중 비용-효율적인 것을 선택할 필요가 있습니다. [cite: 446-454]"
  },
  {
    "objectID": "posts/lecture/L05/part-03/index.html#exponential-search-space",
    "href": "posts/lecture/L05/part-03/index.html#exponential-search-space",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 3)",
    "section": "2.1. Exponential Search Space",
    "text": "2.1. Exponential Search Space\n변수가 \\(n\\)개일 때, 가능한 변수 조합은 \\(2^n\\)개입니다. [cite_start]만약 우리가 “Magic Function” \\(f\\)를 가지고 있어서 모든 Admissible Set을 \\(O(1)\\) 시간에 찾는다고 해도, 출력해야 할 집합의 개수 자체가 지수적으로 많다면 전체 실행 시간은 엄청나게 길어질 것입니다. [cite: 457]\n따라서 우리의 목표는 “전체 실행 시간을 줄이는 것”이 아니라(이는 불가능할 수 있음), “첫 번째 답을 찾을 때까지, 그리고 하나의 답을 찾고 다음 답을 찾을 때까지 걸리는 시간”을 합리적으로 유지하는 것입니다."
  },
  {
    "objectID": "posts/lecture/L05/part-03/index.html#polynomial-delay",
    "href": "posts/lecture/L05/part-03/index.html#polynomial-delay",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 3)",
    "section": "2.2. Polynomial Delay",
    "text": "2.2. Polynomial Delay\n우리는 Polynomial Delay 알고리즘을 목표로 합니다. 알고리즘이 \\(O(n^d)\\) (단, \\(d\\)는 상수) 시간 내에 다음 작업을 수행한다면 Polynomial Delay를 가진다고 합니다.\n\n프로그램 시작 후 첫 번째 출력을 내놓을 때까지.\n하나의 출력을 내놓고 다음 출력을 내놓을 때까지.\n마지막 출력을 내놓고 종료할 때까지.\n\n [cite_start](그림 설명: 시간 축 위에서 알고리즘이 해(solution) \\(s_1, s_2, \\dots\\)를 출력하는 시점을 나타냄. 각 간격이 너무 길어지지 않도록 보장하는 것이 핵심임.) [cite: 470-479]"
  },
  {
    "objectID": "posts/lecture/L05/part-03/index.html#the-lemma",
    "href": "posts/lecture/L05/part-03/index.html#the-lemma",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 3)",
    "section": "3.1. The Lemma",
    "text": "3.1. The Lemma\n우리가 찾고자 하는 분리 집합(Separating Set) \\(Z\\)가 다음 조건을 만족한다고 가정해 봅시다. \\[I \\subseteq Z \\subseteq R\\] 즉, \\(Z\\)는 반드시 \\(I\\)를 포함(Include)해야 하고, \\(R\\)에 포함(Restrict)되어야 합니다.\n이때, \\(X\\)와 \\(Y\\)를 분리하는 유효한 \\(Z\\)가 범위 \\([I, R]\\) 내에 존재하는지 확인하는 방법은 다음과 같습니다.\n\nLemma (Existence of Separator in Range): 범위 \\(I \\subseteq Z \\subseteq R\\) 내에 \\(X\\)와 \\(Y\\)를 분리하는 집합 \\(Z\\)가 존재한다면, 특수하게 구성된 집합 \\(Z_0\\) 또한 \\(X\\)와 \\(Y\\)를 분리한다.\n\\[Z_0 = An(X \\cup Y \\cup I) \\cap R\\]\n[cite_start]반대로, \\(Z_0\\)가 \\(X\\)와 \\(Y\\)를 분리하지 못한다면, 해당 범위 내에 분리 집합은 존재하지 않는다. [cite: 493-498]\n\n [cite_start](그림 설명: \\(I\\)를 포함하고 \\(R\\)에 속하는 \\(Z\\)들의 공간. \\(Z_0\\)는 \\(X, Y, I\\)의 조상(\\(An\\))이면서 \\(R\\)에 속하는 교집합으로 정의됨.) [cite: 492]"
  },
  {
    "objectID": "posts/lecture/L05/part-03/index.html#significance",
    "href": "posts/lecture/L05/part-03/index.html#significance",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 3)",
    "section": "3.2. Significance",
    "text": "3.2. Significance\n이 Lemma가 중요한 이유는 탐색의 가지치기(Pruning)를 가능하게 하기 때문입니다. 우리는 \\(Z_0\\)를 구성하고 d-separation을 검사하는 것을 \\(O(n+m)\\) (그래프 탐색 시간) 내에 수행할 수 있습니다. [cite_start]만약 \\(Z_0\\)가 실패하면, 그 하위의 모든 조합을 일일이 확인하지 않고 즉시 탐색을 중단할 수 있습니다. [cite: 508-509]"
  },
  {
    "objectID": "posts/lecture/L05/part-03/index.html#setup",
    "href": "posts/lecture/L05/part-03/index.html#setup",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 3)",
    "section": "4.1. Setup",
    "text": "4.1. Setup\n먼저, Adjustment Criterion의 조건 (i)(Proper Causal Path 보존)을 만족하기 위해, 절대 조정하면 안 되는 변수들의 집합 \\(F\\)를 정의합니다. 그리고 알고리즘 내부적으로 사용할 \\(F^+\\)를 정의합니다.\n\\[F^+ = X \\cup Y \\cup F\\]\n\n\\(F\\): \\(X\\)를 제외한 Proper Causal Path 상의 변수들과 그들의 후손.\n\\(G'\\): Proper Causal Path의 첫 번째 엣지를 모두 제거한 그래프. (Part 2에서 배운 내용)\n\n이제 우리는 \\(G'\\)에서 \\(X\\)와 \\(Y\\)를 분리하되, \\(F^+\\)의 원소는 포함하지 않는 \\(Z\\)를 찾으면 됩니다. [cite_start]이는 초기 조건 \\(I=\\emptyset\\), \\(R=V \\setminus F^+\\)로 설정하여 해결할 수 있습니다. [cite: 529-533]"
  },
  {
    "objectID": "posts/lecture/L05/part-03/index.html#algorithm-structure-divide-and-conquer",
    "href": "posts/lecture/L05/part-03/index.html#algorithm-structure-divide-and-conquer",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 3)",
    "section": "4.2. Algorithm Structure (Divide and Conquer)",
    "text": "4.2. Algorithm Structure (Divide and Conquer)\n[cite_start]함수 list-seps(G, X, Y, I, R)은 다음과 같이 재귀적으로 동작합니다. [cite: 596-602, 696-704]\n\nExistence Check: 먼저 exist-sep(G, X, Y, I, R)을 호출합니다. (앞서 배운 Lemma 사용).\n\n만약 False라면, 이 범위에 해가 없으므로 즉시 Return (가지치기).\n\nOutput Check: 만약 \\(I = R\\)이라면, 더 이상 선택의 여지가 없습니다. \\(I\\)가 유효한 집합이므로 Output \\(I\\).\nBranching: 아직 결정되지 않은 변수 \\(W \\in R \\setminus I\\)를 하나 선택합니다.\n\nCase 1 (Include W): \\(W\\)를 조정 집합에 포함시킵니다. \\(\\rightarrow\\) list-seps(G, X, Y, I \\(\\cup\\) {W}, R)\nCase 2 (Exclude W): \\(W\\)를 조정 집합에서 배제합니다. \\(\\rightarrow\\) list-seps(G, X, Y, I, R \\(\\setminus\\) {W})\n\n\n이 과정을 통해 유효한 집합이 있는 경로만 탐색하며(Polynomial Delay), 모든 해를 나열할 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L05/part-03/index.html#step-1-initialize",
    "href": "posts/lecture/L05/part-03/index.html#step-1-initialize",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 3)",
    "section": "Step 1: Initialize",
    "text": "Step 1: Initialize\n\nForbidden Set (\\(F\\)): \\(C\\)는 Proper Causal Path 위에 있으므로 금지됩니다. \\(X, Y\\)도 포함할 수 없습니다.\n\\(F^+\\): \\(\\{X, Y, C\\}\\)\nInitial Range:\n\n\\(I = \\emptyset\\)\n\\(R = V \\setminus F^+ = \\{A, B, D\\}\\)\n\n[cite_start]Graph \\(G'\\): \\(X \\to C\\) 엣지를 제거하여 Proper Causal Path를 끊습니다. [cite: 546-547]"
  },
  {
    "objectID": "posts/lecture/L05/part-03/index.html#step-2-recursion-tree-trace",
    "href": "posts/lecture/L05/part-03/index.html#step-2-recursion-tree-trace",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 3)",
    "section": "Step 2: Recursion Tree Trace",
    "text": "Step 2: Recursion Tree Trace\n알고리즘은 변수를 하나씩 선택하며 \\(I\\)에 넣을지(\\(I \\cup W\\)), \\(R\\)에서 뺄지(\\(R \\setminus W\\)) 결정합니다.\n\nStart: \\(I=\\{\\}, R=\\{A, B, D\\}\\). exist-sep 통과(True).\nPick D:\n\nBranch Left (Include D): \\(I=\\{D\\}, R=\\{A, B, D\\}\\).\n\nPick A:\n\nInclude A: \\(I=\\{A, D\\}, R=\\{A, B, D\\}\\). … \\(\\rightarrow\\) Output \\(\\{A, B, D\\}, \\{A, D\\}\\)…\nExclude A: \\(R=\\{B, D\\}\\). …\n\n\nBranch Right (Exclude D): \\(R=\\{A, B\\}\\).\n\n여기서 만약 \\(D\\)가 없으면 \\(X\\)와 \\(Y\\)를 분리할 수 없다고 가정해 봅시다.\n[cite_start]그러면 exist-sep이 False를 반환하고, 이 가지(branch)는 더 이상 탐색하지 않고 Pruning 됩니다. [cite: 561-591]"
  },
  {
    "objectID": "posts/lecture/L05/part-03/index.html#step-3-result",
    "href": "posts/lecture/L05/part-03/index.html#step-3-result",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 3)",
    "section": "Step 3: Result",
    "text": "Step 3: Result\n결과적으로 트리의 리프 노드(Leaf Node) 중에서 \\(I=R\\)인 지점들이 Admissible Set으로 출력됩니다. 예를 들어 \\(\\{A, B, D\\}, \\{A, D\\}, \\{B, D\\}\\) 등이 출력될 수 있습니다. (구체적인 출력은 그래프의 d-separation 구조에 따라 결정됨)."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-01/index.html",
    "href": "posts/lecture/L04/causal-inference-04-part-01/index.html",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 1)",
    "section": "",
    "text": "이번 포스트에서는 인과추론에서 가장 핵심적인 개념 중 하나인 교란(Confounding)과 이를 해결하기 위한 백도어 기준(Back-door Criterion)으로 나아가기 전, 식별 가능성(Identification Problem)에 대해 다시 한번 짚어보고자 합니다.\n강의 자료는 서울대학교 데이터사이언스대학원 이상학 교수님의 “Confounding and Backdoor” 수업 자료를 바탕으로 합니다\n\n\n\nRecap(Identification Problem) and Example of Identifiable and Non-identifiable Effects\nConfounding Bias\nBack-door Criterion\nEvaluation"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-01/index.html#목차",
    "href": "posts/lecture/L04/causal-inference-04-part-01/index.html#목차",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 1)",
    "section": "",
    "text": "Recap(Identification Problem) and Example of Identifiable and Non-identifiable Effects\nConfounding Bias\nBack-door Criterion\nEvaluation"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-01/index.html#설정-setup",
    "href": "posts/lecture/L04/causal-inference-04-part-01/index.html#설정-setup",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 1)",
    "section": "4.1 설정 (Setup)",
    "text": "4.1 설정 (Setup)\n아래와 같은 “Bow-tie” 형태의 그래프를 고려합니다. 여기서 \\(U_{XY}\\)는 \\(X\\)와 \\(Y\\)에 동시에 영향을 주는 관측되지 않은 교란 변수(Unobserved Confounder)입니다.\n\n\n\nFigure 3. Causal Graph with Unobserved Confounder\n\n\n두 모델 \\(\\mathcal{H}^{(1)}\\)과 \\(\\mathcal{H}^{(2)}\\)는 다음과 같은 구조적 방정식(Structural Equations)을 갖습니다. 여기서 \\(U_Y, U_{XY}\\)는 모두 베르누이 분포(동전 던지기, \\(p=0.5\\))를 따릅니다.\n\n4.1.1 Model 1 (\\(\\mathcal{H}^{(1)}\\))\n\\[\n\\begin{cases}\nX \\leftarrow U_{XY} \\\\\nY \\leftarrow (X \\oplus U_{XY}) \\lor U_Y\n\\end{cases}\n\\] * 여기서 \\(\\oplus\\)는 XOR 연산, \\(\\lor\\)는 OR 연산을 의미합니다.\n\n\n4.1.2 Model 2 (\\(\\mathcal{H}^{(2)}\\))\n\\[\n\\begin{cases}\nX \\leftarrow U_{XY} \\\\\nY \\leftarrow U_Y\n\\end{cases}\n\\] * 모델 2에서는 \\(X\\)가 \\(Y\\)에 아무런 영향을 주지 않습니다 (끊어진 인과 관계)."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-01/index.html#관측-분포의-일치-observational-equivalence",
    "href": "posts/lecture/L04/causal-inference-04-part-01/index.html#관측-분포의-일치-observational-equivalence",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 1)",
    "section": "4.2 관측 분포의 일치 (Observational Equivalence)",
    "text": "4.2 관측 분포의 일치 (Observational Equivalence)\n놀랍게도 두 모델은 관측 데이터 상으로는 완벽하게 동일합니다.\n\nModel 1의 경우: 구조 방정식을 보면 \\(X\\)는 \\(U_{XY}\\)와 같습니다. 따라서 \\(X \\oplus U_{XY}\\)는 항상 \\(0\\)이 됩니다 (\\(X\\)와 \\(U_{XY}\\)가 같으므로). \\[Y = 0 \\lor U_Y = U_Y\\] 결국 관측 환경에서는 \\(Y\\)가 오직 \\(U_Y\\)에 의해서만 결정됩니다\nModel 2의 경우: 정의상 \\(Y \\leftarrow U_Y\\)이므로, 역시 \\(Y\\)는 \\(U_Y\\)에 의해 결정됩니다.\n\n결과적으로 두 모델 모두 \\(P(Y=1) = P(U_Y=1) = 0.5\\)이며, \\(X\\)와 \\(Y\\)의 결합 분포 표(Truth Table)도 완전히 일치합니다\n\n\n\n\n\n\n\n\n\n\n\\(U_Y\\)\n\\(U_{XY}\\) (\\(=X\\))\n\\(Y^{(1)}\\) (Model 1)\n\\(Y^{(2)}\\) (Model 2)\n\\(P(u)\\)\n\n\n\n\n0\n0\n0\n0\n1/4\n\n\n0\n1\n0\n0\n1/4\n\n\n1\n0\n1\n1\n1/4\n\n\n1\n1\n1\n1\n1/4"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-01/index.html#인과-효과의-불일치-interventional-differences",
    "href": "posts/lecture/L04/causal-inference-04-part-01/index.html#인과-효과의-불일치-interventional-differences",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 1)",
    "section": "4.3 인과 효과의 불일치 (Interventional Differences)",
    "text": "4.3 인과 효과의 불일치 (Interventional Differences)\n이제 \\(do(x)\\) 연산을 통해 실제로 인과 효과를 계산해 보면 두 모델의 차이가 드러납니다. \\(do(x)\\)는 \\(X\\)를 강제로 특정 값으로 고정하는 것이므로, 더 이상 \\(X\\)는 \\(U_{XY}\\)의 영향을 받지 않습니다.\n\n\n\nFigure 4. Causal Graph with Unobserved Confounder\n\n\n우리는 \\(P(y=1 | do(x=0))\\)을 계산해 보겠습니다\n\n4.3.1 Case 1: Model \\(\\mathcal{H}^{(1)}\\)\n구조 방정식: \\(Y \\leftarrow (x \\oplus U_{XY}) \\lor U_Y\\). 여기서 \\(x=0\\)으로 고정했습니다.\n\n\\(U_{XY}=0, U_Y=0 \\Rightarrow Y = (0 \\oplus 0) \\lor 0 = 0\\)\n\\(U_{XY}=0, U_Y=1 \\Rightarrow Y = (0 \\oplus 0) \\lor 1 = 1\\) (\\(U_Y=1\\) 이면 어차피 \\(Y=1\\))\n\\(U_{XY}=1, U_Y=0 \\Rightarrow Y = (0 \\oplus 1) \\lor 0 = 1\\) (\\(U_{XY}=1 \\nRightarrow X=1\\) 이므로, 여기서 차이 발생!)\n\\(U_{XY}=1, U_Y=1 \\Rightarrow Y = (0 \\oplus 1) \\lor 1 = 1\\) (\\(U_Y=1\\) 이면 어차피 \\(Y=1\\))\n\n4가지 경우 중 3가지 경우에 \\(Y=1\\)이 됩니다. \\[\\therefore P^{(1)}(y=1|do(x=0)) = \\frac{3}{4}\\]\n\n\n4.3.2 Case 2: Model \\(\\mathcal{H}^{(2)}\\)\n구조 방정식: \\(Y \\leftarrow U_Y\\). \\(X\\)의 값과 상관없이 \\(Y\\)는 \\(U_Y\\)를 따릅니다.\n\n\\(U_Y=0 \\Rightarrow Y=0\\)\n\\(U_Y=1 \\Rightarrow Y=1\\)\n\n\\[\\therefore P^{(2)}(y=1|do(x=0)) = \\frac{1}{2}\\]"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-01/index.html#결론",
    "href": "posts/lecture/L04/causal-inference-04-part-01/index.html#결론",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 1)",
    "section": "4.4 결론",
    "text": "4.4 결론\n\n\n\n\\(Y\\)\n\\(P^{(1)}(Y|do(x))\\)\n\\(P^{(2)}(Y|do(x))\\)\n\n\n\n\n0\n\\(\\frac{1}{4}\\)\n\\(\\frac{1}{2}\\)\n\n\n1\n\\(\\frac{3}{4}\\)\n\\(\\frac{1}{2}\\)\n\n\n\n두 모델은 동일한 인과 그래프와 동일한 관측 분포 \\(P(v)\\)를 가지지만, 계산된 인과 효과 \\(P(y|do(x))\\)는 \\(\\frac{3}{4}\\)와 \\(\\frac{1}{2}\\)로 서로 다릅니다\n\nEven though both models induce \\(I\\) (Graph) and have the same \\(P(v)\\), the effect \\(P^{(1)}(y|do(x)) \\neq P^{(2)}(y|do(x))\\).\n\n이는 주어진 그래프 구조(Unobserved Confounder가 존재하는 경우)만으로는 데이터에서 인과 효과를 유일하게 식별해낼 수 없음을(Non-identifiable) 의미합니다. 이러한 경우, 추가적인 가정이나 데이터를 통한 식별 전략이 필요합니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-02/index.html",
    "href": "posts/lecture/L04/causal-inference-04-part-02/index.html",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 2)",
    "section": "",
    "text": "지난 포스트에서는 인과 효과의 식별 가능성(Identifiability)에 대해 다루었습니다. 이번에는 현실 데이터 분석에서 가장 빈번하게 마주치는 문제이자, 인과추론이 필요한 가장 큰 이유 중 하나인 교란 편향(Confounding Bias)에 대해 구체적인 예시를 통해 알아보겠습니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-02/index.html#단순-관측-직관과-반대되는-결과",
    "href": "posts/lecture/L04/causal-inference-04-part-02/index.html#단순-관측-직관과-반대되는-결과",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 2)",
    "section": "2.1 1. 단순 관측: 직관과 반대되는 결과",
    "text": "2.1 1. 단순 관측: 직관과 반대되는 결과\n\n수집한 데이터를 단순히 산점도(Scatter Plot)로 그려보았더니 놀라운 결과가 나타났습니다.\n\n\n\n\nFigure 1. Observed Correlation between Exercise and Cholesterol\n\n\n\n관측 결과: 운동을 많이 하는 사람일수록 콜레스테롤 수치가 더 높게 나타납니다.\n의문: \\(P(\\text{cholesterol} | \\text{exercise})\\)를 보면, 운동이 콜레스테롤을 높이는 것처럼 보입니다. 과연 “더 많은 운동 \\(\\Rightarrow\\) 콜레스테롤 증가”라고 결론 내릴 수 있을까요?"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-02/index.html#교란-변수의-발견-나이age",
    "href": "posts/lecture/L04/causal-inference-04-part-02/index.html#교란-변수의-발견-나이age",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 2)",
    "section": "2.2 2. 교란 변수의 발견: 나이(Age)",
    "text": "2.2 2. 교란 변수의 발견: 나이(Age)\n\n이 이상한 현상을 이해하기 위해, 우리는 데이터에 숨겨진 제3의 변수인 ‘나이(Age)’를 색상으로 구분하여 다시 시각화해보았습니다.\n\n\n\n\nFigure 2. Scatter Plot Stratified by Age\n\n\n\n그래프를 자세히 보면 다음과 같은 패턴이 드러납니다:\n\n나이와 운동: 나이가 많은 사람(노란색 계열)들이 건강 관리를 위해 운동을 더 많이 하는 경향이 있습니다.\n나이와 콜레스테롤: 동시에, 나이가 많을수록 자연적으로 콜레스테롤 수치가 높습니다.\n\n즉, ‘나이’가 운동량(\\(X\\))과 콜레스테롤(\\(Y\\)) 모두에 영향을 미치는 교란 변수(Confounder)로 작용하고 있었던 것입니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-02/index.html#계층별-분석-인과-효과의-확인",
    "href": "posts/lecture/L04/causal-inference-04-part-02/index.html#계층별-분석-인과-효과의-확인",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 2)",
    "section": "2.3 3. 계층별 분석: 인과 효과의 확인",
    "text": "2.3 3. 계층별 분석: 인과 효과의 확인\n\n이제 나이(Age)를 고정한 상태에서 운동과 콜레스테롤의 관계를 다시 살펴봅시다.\n\n\n\n\nFigure 3. True Causal Effect within Age Groups\n\n\n\n각 연령대 그룹(같은 색깔) 내부를 들여다보면, 운동을 많이 할수록 콜레스테롤 수치가 낮아지는 것을 명확히 볼 수 있습니다.\n결론: 운동의 진짜 인과 효과는 콜레스테롤을 낮추는 것입니다. (\\(More\\ exercise \\Rightarrow Lower\\ Cholesterol\\))"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-02/index.html#복잡한-인과-그래프에서의-문제",
    "href": "posts/lecture/L04/causal-inference-04-part-02/index.html#복잡한-인과-그래프에서의-문제",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 2)",
    "section": "4.1 복잡한 인과 그래프에서의 문제",
    "text": "4.1 복잡한 인과 그래프에서의 문제\n\n다음과 같이 복잡한 인과 그래프를 고려해 봅시다.\n\n\n\n\nFigure 4. A Complex Causal Graph\n\n\n\nGoal: 변수 \\(Z_1, ..., Z_k\\)가 측정되었을 때, \\(X\\)가 \\(Y\\)에 미치는 인과 효과 \\(Q = P(y|do(x))\\)를 찾아내는 것.\n여기서 중요한 질문이 생깁니다.\n\n“부모 변수(Parents) 중 일부만 관측되었을 때, 타겟 인과 효과 \\(Q\\)를 식별할 수 있는가?”"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-02/index.html#주의해야-할-구조-collider",
    "href": "posts/lecture/L04/causal-inference-04-part-02/index.html#주의해야-할-구조-collider",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 2)",
    "section": "4.2 주의해야 할 구조: Collider",
    "text": "4.2 주의해야 할 구조: Collider\n\n그래프 분석 시 주의해야 할 점은 단순히 모든 변수를 통제(Conditioning)한다고 좋은 것이 아니라는 점입니다.\n예를 들어 위 그래프에서 \\(Z_4\\)와 같은 변수를 살펴봅시다.\n\n\nNote: \\(Z_4\\)는 \\(Z_1\\)과 \\(Z_2\\)의 화살표를 동시에 받는 Collider (\\(Z_1 \\rightarrow Z_4 \\leftarrow Z_2\\))입니다. \\(Z_4\\)를 조건부(given)로 잡을 경우, 오히려 \\(Z_1\\)과 \\(Z_2\\) 사이에 길이 뚫리는 현상이 발생하여 새로운 편향을 만들 수 있습니다.\n\n\n따라서 우리는 어떤 변수를 조정 집합(Adjustment Set)에 넣어야 편향을 제거하고 올바른 인과 효과를 구할 수 있는지 판단하는 체계적인 기준이 필요합니다. 이것이 바로 다음 포스트에서 다룰 Back-door Criterion입니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-04/index.html",
    "href": "posts/lecture/L04/causal-inference-04-part-04/index.html",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 4)",
    "section": "",
    "text": "지난 포스트에서는 Back-door Criterion을 통해 어떤 공변량 집합 \\(Z\\)를 보정(Adjustment)해야 인과 효과 \\(P(y|do(x))\\)를 식별할 수 있는지 알아보았습니다.\n\n\\[P(y|do(x)) = \\sum_{z} P(y|x,z)P(z)\\]\n\n이번 포스트에서는 이 식을 실제 데이터(Practice)에서 어떻게 평가하고 계산하는지, 특히 계산 복잡도 문제를 해결하기 위한 Inverse Probability Weighting (IPW) 기법에 대해 다룹니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-04/index.html#derivation",
    "href": "posts/lecture/L04/causal-inference-04-part-04/index.html#derivation",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 4)",
    "section": "3.1 Derivation",
    "text": "3.1 Derivation\n\n기존의 Back-door Adjustment 식을 베이즈 정리와 결합 확률 법칙을 이용해 재구성해 봅시다.\n\n\\[\n\\begin{align}\nP(y|do(x)) &= \\sum_{z} P(y|x,z)P(z) \\\\\n&= \\sum_{z} \\frac{P(y,x,z)}{P(x,z)} P(z) \\\\\n&= \\sum_{z} \\frac{P(y,x,z)}{P(x|z)P(z)} P(z) \\\\\n&= \\sum_{z} \\frac{P(y,x,z)}{P(x|z)} \\quad\n\\end{align}\n\\]\n\n이제 우리는 \\(P(z)\\)를 따로 추정하거나 모든 \\(z\\)에 대해 합을 구할 필요 없이, 결합 확률 \\(P(y,x,z)\\)를 \\(P(x|z)\\)로 나눈 형태로 식을 단순화했습니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-04/index.html#propensity-score-gz",
    "href": "posts/lecture/L04/causal-inference-04-part-04/index.html#propensity-score-gz",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 4)",
    "section": "3.2 Propensity Score \\(g(z)\\)",
    "text": "3.2 Propensity Score \\(g(z)\\)\n\n위 식의 분모에 있는 \\(P(x|z)\\)는 공변량 \\(Z\\)가 주어졌을 때 원인 변수 \\(X\\)가 할당될 확률을 의미하며, 이를 Propensity Score라고 부릅니다.\n보통 \\(g(z)\\)로 표기하며 로지스틱 회귀(Logistic Regression) 등의 모델을 사용하여 추정합니다.\n\n\\[g(z) = P(X=x|Z=z)\\]"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-04/index.html#핵심-포인트",
    "href": "posts/lecture/L04/causal-inference-04-part-04/index.html#핵심-포인트",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 4)",
    "section": "4.1 핵심 포인트",
    "text": "4.1 핵심 포인트\n\n\\(\\mathbb{1}(\\cdot)\\) (Indicator Function): 조건이 참이면 1, 거짓이면 0을 반환하는 함수입니다.\n시간 복잡도 \\(O(N)\\): 가장 마지막 식을 보면, 더 이상 \\(Z\\)의 모든 조합에 대해 합을 구할 필요가 없습니다. 단순히 관측된 \\(N\\)개의 데이터 샘플을 한 번씩만 순회하며 가중치(\\(1/g(z_i)\\))를 더하면 계산이 끝납니다. 이것이 IPW가 강력한 이유입니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-04/index.html#시간-복잡도의-개선",
    "href": "posts/lecture/L04/causal-inference-04-part-04/index.html#시간-복잡도의-개선",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 4)",
    "section": "4.2 시간 복잡도의 개선",
    "text": "4.2 시간 복잡도의 개선\n\n이 방식의 가장 큰 장점은 계산 효율성입니다.\n고차원 \\(Z\\)에 대해 적분하거나 합을 구하는 대신, 샘플 수 \\(N\\)에 비례하는 선형 시간(\\(O(N)\\)) 만에 계산이 가능합니다."
  },
  {
    "objectID": "posts/lecture/L10/part-02/index.html",
    "href": "posts/lecture/L10/part-02/index.html",
    "title": "[Causal Inference] 10. Potential Outcome Framework (Part 2)",
    "section": "",
    "text": "이전 포스트에서는 Potential Outcome Framework의 기본 개념과 “관찰되지 않은 반사실(Counterfactual)”이라는 근본적인 문제에 대해 다루었습니다. 이번 포스트에서는 이 개념을 확장하여, 실제 데이터로부터 인과 효과를 식별(Identification)하고 추정(Estimation)하는 구체적인 방법론을 살펴봅니다.\n특히, 이상적인 상황인 무작위 대조군 실험(RCT)에서부터, 현실적으로 더 빈번한 관찰 연구(Observational Study)에서의 가정들(Unconfoundedness, Positivity), 그리고 머신러닝을 활용해 이질적 처치 효과(CATE)를 정교하게 추정하는 X-Learner 알고리즘까지 심도 있게 다룹니다."
  },
  {
    "objectID": "posts/lecture/L10/part-02/index.html#unconfounded-assignment",
    "href": "posts/lecture/L10/part-02/index.html#unconfounded-assignment",
    "title": "[Causal Inference] 10. Potential Outcome Framework (Part 2)",
    "section": "2.1. Unconfounded Assignment",
    "text": "2.1. Unconfounded Assignment\n처치 할당 메커니즘(Assignment Mechanism)이 잠재적 결과(Potential Outcomes)와 무관하게 결정될 때, 이를 Unconfounded Assignment라고 합니다.\n\\[\np(X_i = 1 \\mid Z_i, Y_i(0), Y_i(1)) = p(X_i = 1 \\mid Z_i)\n\\]\n여기서 \\(p(X_i=1|Z_i)\\)는 공변량 \\(Z_i\\)가 주어졌을 때 처치를 받을 확률로, 성향 점수(Propensity Score)라고도 부릅니다 (Rosenbaum and Rubin, 1983)."
  },
  {
    "objectID": "posts/lecture/L10/part-02/index.html#the-role-of-randomization",
    "href": "posts/lecture/L10/part-02/index.html#the-role-of-randomization",
    "title": "[Causal Inference] 10. Potential Outcome Framework (Part 2)",
    "section": "2.2. The Role of Randomization",
    "text": "2.2. The Role of Randomization\n무작위 실험(RCT)에서는 연구자가 할당 확률을 직접 통제하므로 Unconfoundedness가 보장됩니다. 무작위화는 다음과 같은 중요한 역할을 수행합니다.\n\nBalance Observed Covariates: 관찰된 공변량 \\(Z\\)의 분포를 실험군과 대조군 사이에서 균형 잡히게 합니다 (\\(X \\perp Z\\)).\nBalance Unobserved Covariates: 더욱 중요한 것은, 관찰되지 않은 공변량 \\(U\\)까지도 균형을 맞춘다는 점입니다 (\\(X \\perp U\\)).\nGuarantee Ignorability: 결과적으로 처치 \\(X\\)는 잠재적 결과와 독립이 됩니다.\n\n\\[\n\\{Y(1), Y(0)\\} \\perp X\n\\]\n이 독립성이 성립하면, 인과 관계는 상관 관계와 같아지며 식별이 가능해집니다.\n\\[\n\\begin{aligned}\nP(Y(x)) &= P(Y(x) \\mid X=x) \\quad (\\because \\text{Independence}) \\\\\n&= P(Y \\mid X=x) \\quad (\\because \\text{Consistency})\n\\end{aligned}\n\\]\n\nGraph Interpretation\n\n\n\nFigure 1: 무작위 할당(Randomization)과 관찰 연구(Observational)의 인과 그래프 비교. 왼쪽(Observational)에서는 교란 변수 \\(Z\\)가 \\(X\\)와 \\(Y\\) 모두에 영향을 미치지만, 오른쪽(Intervened/Randomized)에서는 \\(X\\)가 외부의 무작위 기제(동전 던지기 등)에 의해 결정되므로 \\(Z\\)에서 오는 화살표가 제거되어 \\(X \\perp Y(x)\\)가 성립한다.\n\n\n위 그림에서 보듯이, 무작위 실험은 \\(Z\\)가 \\(X\\)에 미치는 영향을 차단(수술)함으로써 \\(X\\)와 \\(Y(x)\\) 사이의 연결 고리를 끊어냅니다."
  },
  {
    "objectID": "posts/lecture/L10/part-02/index.html#assumption-1-unconfoundedness-no-unmeasured-confounding",
    "href": "posts/lecture/L10/part-02/index.html#assumption-1-unconfoundedness-no-unmeasured-confounding",
    "title": "[Causal Inference] 10. Potential Outcome Framework (Part 2)",
    "section": "3.1. Assumption 1: Unconfoundedness (No Unmeasured Confounding)",
    "text": "3.1. Assumption 1: Unconfoundedness (No Unmeasured Confounding)\n처치 할당이 관찰된 공변량 \\(Z\\)에 조건부로 잠재적 결과와 독립이어야 합니다.\n\\[\n\\{Y_i(1), Y_i(0)\\} \\perp X_i \\mid Z_i\n\\]\n이를 Conditional Ignorability, Selection on Observables라고도 합니다. 즉, 우리가 수집한 데이터 \\(Z\\)만 통제하면, 마치 무작위 실험을 한 것과 같은 상태가 된다는 가정입니다."
  },
  {
    "objectID": "posts/lecture/L10/part-02/index.html#assumption-2-positivity-overlap",
    "href": "posts/lecture/L10/part-02/index.html#assumption-2-positivity-overlap",
    "title": "[Causal Inference] 10. Potential Outcome Framework (Part 2)",
    "section": "3.2. Assumption 2: Positivity (Overlap)",
    "text": "3.2. Assumption 2: Positivity (Overlap)\n모든 공변량 \\(Z\\) 값에 대해, 처치를 받을 확률과 받지 않을 확률이 0이나 1이 아니어야 합니다.\n\\[\n0 &lt; P(X_i=1 \\mid Z_i) &lt; 1\n\\]\n만약 특정 \\(Z\\) 집단(예: 80세 이상 노인)이 모두 처치를 받지 않는다면(\\(P(X=1|Z)=0\\)), 해당 집단에서 처치를 받았을 때의 결과(\\(Y(1)\\))를 추정할 데이터가 전혀 없으므로 비교가 불가능합니다.\n\n\n\nFigure 2: 조건부 독립성의 그래프 표현. \\(Z\\)는 \\(X\\)와 \\(Y\\) 사이의 백도어 경로(Backdoor Path)를 형성하는 교란 변수이다. \\(Z\\)를 조건부로 통제(Conditioning)하면 이 경로가 차단되어 \\(X\\)와 \\(Y(x)\\)는 독립이 된다."
  },
  {
    "objectID": "posts/lecture/L10/part-02/index.html#derivation",
    "href": "posts/lecture/L10/part-02/index.html#derivation",
    "title": "[Causal Inference] 10. Potential Outcome Framework (Part 2)",
    "section": "4.1. Derivation",
    "text": "4.1. Derivation\n우리의 목표는 \\(\\tau = \\mathbb{E}[Y(1) - Y(0)]\\)입니다.\n\nLaw of Iterated Expectations: \\[\\mathbb{E}[Y(1)] = \\mathbb{E}_Z [ \\mathbb{E}[Y(1) \\mid Z] ]\\]\nUnconfoundedness (\\(Y(1) \\perp X \\mid Z\\)): 조건부 독립성에 의해 \\(X=1\\) 조건을 추가해도 기댓값은 변하지 않습니다. \\[\\mathbb{E}[Y(1) \\mid Z] = \\mathbb{E}[Y(1) \\mid X=1, Z]\\]\nConsistency (\\(Y = Y(1) \\text{ if } X=1\\)): \\[\\mathbb{E}[Y(1) \\mid X=1, Z] = \\mathbb{E}[Y \\mid X=1, Z]\\]\n\n이 과정을 \\(Y(0)\\)에도 동일하게 적용하여 합치면 다음과 같은 최종 식을 얻습니다.\n\\[\n\\tau^{ATE} = \\mathbb{E}_Z \\left\\{ \\underbrace{\\mathbb{E}[Y \\mid X=1, Z]}_{\\mu_1(Z)} - \\underbrace{\\mathbb{E}[Y \\mid X=0, Z]}_{\\mu_0(Z)} \\right\\}\n\\]\n여기서 \\(\\mu_1(z)\\)와 \\(\\mu_0(z)\\)는 데이터로부터 회귀분석 등을 통해 추정 가능한 함수입니다."
  },
  {
    "objectID": "posts/lecture/L10/part-02/index.html#regression-estimation",
    "href": "posts/lecture/L10/part-02/index.html#regression-estimation",
    "title": "[Causal Inference] 10. Potential Outcome Framework (Part 2)",
    "section": "4.2. Regression Estimation",
    "text": "4.2. Regression Estimation\n가장 기본적인 추정 방법은 각 집단에 대해 별도의 회귀 모델을 적합하는 것입니다.\n\nEstimate: \\(\\hat{\\mu}_1(z)\\) (처치군 데이터만 사용), \\(\\hat{\\mu}_0(z)\\) (대조군 데이터만 사용)\nPredict: 모든 데이터 포인트에 대해 \\(X=1\\)일 때와 \\(X=0\\)일 때의 값을 예측\nAverage: 예측된 차이의 평균을 계산\n\n\\[\n\\hat{\\tau}_{reg} = \\frac{1}{n} \\sum_{i=1}^{n} (\\hat{\\mu}_1(Z_i) - \\hat{\\mu}_0(Z_i))\n\\]\n\nNote: 처치 변수 \\(X\\)를 단순히 하나의 Feature로 넣는 것보다(\\(Y \\sim X + Z\\)), 위처럼 그룹별로 별도의 모델을 만드는 것이 안전합니다(Safest practice). \\(X\\)와 \\(Z\\) 사이의 상호작용이나 비선형성을 놓칠 수 있기 때문입니다."
  },
  {
    "objectID": "posts/lecture/L10/part-02/index.html#motivation",
    "href": "posts/lecture/L10/part-02/index.html#motivation",
    "title": "[Causal Inference] 10. Potential Outcome Framework (Part 2)",
    "section": "5.1. Motivation",
    "text": "5.1. Motivation\n단순히 \\(\\hat{\\mu}_1(z) - \\hat{\\mu}_0(z)\\)를 사용하는 방식(T-Learner)은 한쪽 집단의 데이터가 적을 때 문제가 발생합니다. 예를 들어 대조군의 데이터는 풍부하여 \\(\\hat{\\mu}_0\\)가 정교하지만, 실험군은 데이터가 적어 \\(\\hat{\\mu}_1\\)이 단순한 선형으로 과소적합(Underfitting)된다면, 둘의 차이인 CATE 추정치는 왜곡될 수 있습니다.\n\n\n\nFigure 3: T-Learner의 한계와 X-Learner의 필요성. 파란색 점(처치군)은 데이터가 적고, 빨간색 점(대조군)은 데이터가 많다. 단순 회귀(직선)로 적합할 경우, 실제 처치 효과의 복잡한 패턴(Step function)을 잡아내지 못한다(왼쪽). X-Learner는 이를 보정한다."
  },
  {
    "objectID": "posts/lecture/L10/part-02/index.html#algorithm-steps",
    "href": "posts/lecture/L10/part-02/index.html#algorithm-steps",
    "title": "[Causal Inference] 10. Potential Outcome Framework (Part 2)",
    "section": "5.2. Algorithm Steps",
    "text": "5.2. Algorithm Steps\nX-Learner는 다음 3단계로 구성됩니다.\n\nStep 1: Estimate Response Functions (Base Learners)\n각 집단 별로 결과 변수 \\(Y\\)를 예측하는 모델을 학습합니다. \\[\\hat{\\mu}_0(z) \\approx \\mathbb{E}[Y(0)|Z=z], \\quad \\hat{\\mu}_1(z) \\approx \\mathbb{E}[Y(1)|Z=z]\\]\n\n\nStep 2: Impute Treatment Effects\n관찰된 \\(Y\\)와 추정된 반사실을 이용하여, 개별 개체 수준의 처치 효과(Imputed Treatment Effect) \\(\\tilde{D}\\)를 생성합니다.\n\nFor Treated (\\(X_i=1\\)): 실제 관찰값 \\(Y_i\\)에서 \\(\\hat{\\mu}_0\\)로 예측한 반사실을 뺍니다. \\[\\tilde{D}_i^1 = Y_i - \\hat{\\mu}_0(Z_i)\\]\nFor Control (\\(X_i=0\\)): \\(\\hat{\\mu}_1\\)로 예측한 반사실에서 실제 관찰값 \\(Y_i\\)를 뺍니다. \\[\\tilde{D}_i^0 = \\hat{\\mu}_1(Z_i) - Y_i\\]\n\n\n\n\nFigure 4: Imputed Treatment Effects. \\(\\tilde{D}^1\\)과 \\(\\tilde{D}^0\\)를 계산하여 CATE 추정을 위한 새로운 종속변수를 생성하는 과정.\n\n\n\n\nStep 3: Estimate CATEs and Weighting\n이제 \\(\\tilde{D}^1\\)과 \\(\\tilde{D}^0\\)를 종속변수로 하여 \\(Z\\)에 대해 다시 회귀 모델(Second Stage)을 학습합니다. \\[\\hat{\\tau}_1(z) \\approx \\mathbb{E}[\\tilde{D}^1|Z=z], \\quad \\hat{\\tau}_0(z) \\approx \\mathbb{E}[\\tilde{D}^0|Z=z]\\]\n마지막으로, 성향 점수 \\(g(z) = P(X=1|Z=z)\\)를 가중치로 사용하여 두 추정치를 결합합니다.\n\\[\n\\hat{\\tau}(z) = g(z)\\hat{\\tau}_0(z) + (1 - g(z))\\hat{\\tau}_1(z)\n\\]"
  },
  {
    "objectID": "posts/lecture/L10/part-02/index.html#intuition",
    "href": "posts/lecture/L10/part-02/index.html#intuition",
    "title": "[Causal Inference] 10. Potential Outcome Framework (Part 2)",
    "section": "5.3. Intuition",
    "text": "5.3. Intuition\n왜 가중 평균을 할까요? * 만약 \\(g(z) \\approx 0\\)이라면(대조군이 압도적으로 많음), \\(\\hat{\\mu}_0\\) 모델이 \\(\\hat{\\mu}_1\\)보다 훨씬 정확합니다. * 따라서 \\(\\hat{\\mu}_0\\)를 사용하여 만든 \\(\\tilde{D}^1\\) (\\(Y_{treated} - \\hat{\\mu}_0\\)) 정보가, \\(\\hat{\\mu}_1\\)을 사용한 \\(\\tilde{D}^0\\)보다 더 신뢰할 수 있습니다(불확실성이 덜 함). * 공식에서 \\(g(z) \\approx 0\\)이면 \\(1-g(z) \\approx 1\\)이 되어 \\(\\hat{\\tau}_1(z)\\)(즉, \\(\\tilde{D}^1\\)을 학습한 모델)에 더 큰 가중치를 줍니다. * 즉, “데이터가 더 풍부한 집단의 모델을 사용하여 반사실을 추정한 값”을 더 신뢰하겠다는 전략입니다.\n\n\n\nFigure 5: X-Learner의 최종 결과. 가중 결합을 통해 데이터가 희소한 영역에서도 안정적이고 정확한 CATE 추정선을 그려낸다(검은 실선)."
  },
  {
    "objectID": "posts/lecture/L17/part-02/index.html",
    "href": "posts/lecture/L17/part-02/index.html",
    "title": "[Causal Inference] 17. Causal Data Science (Part 2)",
    "section": "",
    "text": "이전 포스트에서는 Causal Data Science가 다루는 4가지 차원(Dimensions)에 대해 개괄적으로 살펴보았습니다.\n이번 포스트에서는 그 첫 번째이자 가장 기초가 되는 문제인 Experimental Conditions와 General Identifiability (g-ID)에 대해 깊이 있게 다룹니다.\n우리가 \\(do(x)\\)에 대한 인과 효과 \\(P(y|do(x))\\)를 알고 싶을 때, 이상적인 상황은 \\(X\\)에 대한 무작위 대조군 실험(RCT) 데이터가 있는 것입니다.\n하지만 현실에서는 다음과 같은 제약이 따릅니다:\n\n\n윤리적/비용적 문제: \\(X\\)(예: 흡연, 유해 물질 노출)를 직접 실험할 수 없음.\n\n\n대리 실험(Surrogate Experiments): \\(X\\) 대신 \\(Z\\)(예: 식이요법, 보조 약물)에 대한 실험 데이터만 존재함.\n\n\n이질적 데이터의 결합: 여러 개의 서로 다른 실험 결과(\\(do(x_1), do(x_2)\\))를 결합하여 새로운 개입(\\(do(x_1, x_2)\\))의 효과를 추정해야 함.\n\n\n이 문제는 “우리가 가진 다양한 실험 및 관찰 데이터(\\(\\mathbb{P}\\))를 활용하여, 타겟 질의(\\(Q\\))를 식별할 수 있는가?”라는 General Identifiability 문제로 귀결됩니다."
  },
  {
    "objectID": "posts/lecture/L17/part-02/index.html#motivation-diet-cholesterol-and-heart-attack",
    "href": "posts/lecture/L17/part-02/index.html#motivation-diet-cholesterol-and-heart-attack",
    "title": "[Causal Inference] 17. Causal Data Science (Part 2)",
    "section": "2.1. Motivation: Diet, Cholesterol, and Heart Attack",
    "text": "2.1. Motivation: Diet, Cholesterol, and Heart Attack\n\n가장 단순한 형태의 대리 실험 문제를 살펴보겠습니다.\n우리의 목표는 콜레스테롤 수치(\\(X\\))가 심장마비(\\(Y\\))에 미치는 인과 효과 \\(P(y|do(x))\\)를 알아내는 것입니다.\n\n\n\n\nFigure 1: z-ID의 기본 모티베이션 그래프. Z(식이요법)는 X(콜레스테롤)에 영향을 주고, X는 Y(심장마비)에 영향을 준다. 점선 화살표는 측정되지 않은 교란 변수(Confounder)를 의미한다. Z와 Y 사이의 직접적인 화살표가 없다는 점(Exclusion Restriction)이 중요하다.\n\n\n\nQuery: \\(Q = P(y|do(x))\\)\nProblem: \\(X\\)와 \\(Y\\) 사이에 관측되지 않은 교란 요인(Confounder)이 존재하여(위 그림의 \\(X \\leftrightarrow Y\\) 점선), 관찰 데이터 \\(P(x,y,z)\\)만으로는 \\(Q\\)를 식별할 수 없습니다.\nAvailable Data:\n\nObservational: \\(P(x,y,z)\\)\nExperimental (Surrogate): \\(P(x,y|do(z))\\) — 식이요법(\\(Z\\))은 실험 가능함.\n\n이 경우, \\(Z\\)에 대한 실험 데이터를 사용하여 \\(X\\)의 효과를 식별할 수 있을까요? 이를 z-ID 문제라고 합니다."
  },
  {
    "objectID": "posts/lecture/L17/part-02/index.html#instrumental-variable-formula-derived-from-experiments",
    "href": "posts/lecture/L17/part-02/index.html#instrumental-variable-formula-derived-from-experiments",
    "title": "[Causal Inference] 17. Causal Data Science (Part 2)",
    "section": "2.2. Instrumental Variable Formula derived from Experiments",
    "text": "2.2. Instrumental Variable Formula derived from Experiments\n만약 \\(Z\\)가 \\(X\\)를 통해서만 \\(Y\\)에 영향을 미친다면(즉, \\(Z \\to Y\\) 직접 경로가 없고, \\(Z\\)와 \\(Y\\) 사이의 교란이 없다면), 우리는 다음 식을 유도할 수 있습니다.\n\\[\nP(y|do(x)) = \\frac{P(x,y|do(z))}{P(x|do(z))} = P(y|x, do(z))\n\\]\n\nDerivation\n\n이 식은 Do-Calculus 규칙을 적용하여 단계적으로 유도할 수 있습니다.\n핵심은 \\(do(x)\\)라는 가상의 개입을 \\(do(z)\\)라는 실제 가능한 실험으로 변환하는 것입니다.\n\n\\[\nP(y|do(x)) \\xrightarrow{\\text{Step 1}} P(y|do(x), do(z)) \\xrightarrow{\\text{Step 2}} P(y|x, do(z))\n\\]\n\nStep 1: 배제 제약 (Exclusion Restriction) 적용\n\\[P(y|do(x)) = P(y|do(x), do(z))\\]\n\n논리: 도구변수의 핵심 가정에 따르면 \\(Z\\)는 오직 \\(X\\)를 통해서만 \\(Y\\)에 영향을 줍니다.\n해석: 이미 \\(X\\)를 \\(do(x)\\)로 고정하여 \\(Y\\)에 대한 \\(X\\)의 영향력을 통제하고 있다면, \\(Z\\)를 추가로 \\(do(z)\\)로 고정하더라도 \\(Y\\)의 분포에는 아무런 변화가 없습니다. (\\(Z \\to Y\\) 직접 경로 부재)\n\n\n\nStep 2: 관측과 개입의 교환 (Rule 2)\n\\[P(y|do(x), do(z)) = P(y|x, do(z))\\]\n\n논리: \\(do(z)\\)가 수행된 실험적 환경에서는 \\(Z\\)가 무작위로 할당되므로, \\(Z\\)로 인해 \\(X\\)와 \\(Y\\) 사이의 교란(confounding) 경로가 차단됩니다.\n해석: 교란 요인이 없는 환경(\\(do(z)\\)) 하에서는, \\(X\\)를 강제로 고정(\\(do(x)\\))했을 때의 결과나, 자연스럽게 \\(X=x\\)가 된 것을 관측했을 때의 결과가 동일합니다. 즉, \\(do(x)\\)를 조건부 확률 \\(x\\)로 바꿀 수 있습니다.\n\n\n\nStep 3: 조건부 확률 정의 (Bayes’ Rule)\n\n최종적으로 조건부 확률의 정의에 따라 우변을 다시 씁니다.\n\n\\[P(y|x, do(z)) = \\frac{P(x,y|do(z))}{P(x|do(z))}\\]\n\n이로써 우리가 실험 데이터(\\(do(z)\\))를 통해 \\(X\\)가 \\(Y\\)에 미치는 인과적 효과(\\(do(x)\\))를 식별(Identify)할 수 있음이 증명됩니다."
  },
  {
    "objectID": "posts/lecture/L17/part-02/index.html#subtleties-of-z-id",
    "href": "posts/lecture/L17/part-02/index.html#subtleties-of-z-id",
    "title": "[Causal Inference] 17. Causal Data Science (Part 2)",
    "section": "2.3. Subtleties of z-ID",
    "text": "2.3. Subtleties of z-ID\n\n모든 경우에 대리 실험이 유효한 것은 아닙니다. 그래프 구조에 따라 식별 가능 여부가 달라집니다.\n\n\n\n\nFigure 2: z-ID 가능 그래프와 불가능 그래프의 비교. 상단 그래프들은 Z에 대한 실험으로 X의 효과를 식별할 수 있는 경우(z-ID)이고, 하단 그래프들은 식별 불가능한 경우(non-z-ID)이다. 핵심은 Z의 개입이 X와 Y 사이의 교란 요인을 통제하거나 우회할 수 있는지 여부이다.\n\n\n\n위 그림에서 z-ID가 가능한 경우와 그렇지 않은 경우(non-z-ID)를 구분하는 것은, \\(Z\\)에 대한 개입이 \\(X \\to Y\\) 관계를 교란하는 뒷문 경로(Back-door path)를 차단하거나, \\(X\\)의 변동을 충분히 설명할 수 있는지와 관련이 있습니다."
  },
  {
    "objectID": "posts/lecture/L17/part-02/index.html#problem-definition-goal",
    "href": "posts/lecture/L17/part-02/index.html#problem-definition-goal",
    "title": "[Causal Inference] 17. Causal Data Science (Part 2)",
    "section": "1. Problem Definition & Goal",
    "text": "1. Problem Definition & Goal\n\nTarget: \\(P(y|do(x))\\)\nChallenge: 그래프에 존재하는 많은 교란 경로(Bi-directed arcs) 때문에, 관측 데이터 \\(P(\\mathbf{V})\\)만으로는 이 효과를 식별할 수 없습니다 (Non-identifiable from \\(P(\\mathbf{V})\\)).\nSolution: \\(Z\\)에 대한 실험 데이터, 즉 \\(P(\\mathbf{V}|do(z))\\)가 가용하다면(Available), 이를 활용해 타겟 효과를 계산할 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L17/part-02/index.html#derivation-step-1-decomposition-c-component",
    "href": "posts/lecture/L17/part-02/index.html#derivation-step-1-decomposition-c-component",
    "title": "[Causal Inference] 17. Causal Data Science (Part 2)",
    "section": "2. Derivation Step 1: Decomposition (C-Component)",
    "text": "2. Derivation Step 1: Decomposition (C-Component)\n\n우선 \\(P(y|do(x))\\)를 중간 매개변수 \\(W\\)를 이용하여 두 개의 부분 문제(\\(Q[Y]\\)와 \\(Q[W]\\))로 분해합니다.\n\n\\[\n\\begin{aligned}\nP(y|do(x)) &= \\sum_{w} P(y|do(x), w) P(w|do(x)) \\quad \\text{(Law of Total Probability)} \\\\\n&= \\sum_{w} P(y|do(x), do(w)) P(w|do(x)) \\quad \\text{(Rule 2: Action/Observation Exchange of W)} \\\\\n&= \\sum_{w} \\underbrace{P(y|do(w))}_{Q[Y]} \\underbrace{P(w|do(x))}_{Q[W]} \\quad \\text{(Rule 3: Removing Action of } X \\text{)}\n\\end{aligned}\n\\]\n\n해석: \\(X\\)가 \\(Y\\)에 미치는 영향은 \\(W\\)를 통하는 경로밖에 없으므로(\\(X \\to W \\to Y\\)), \\(Y\\)에 대해 \\(W\\)를 직접 조작(\\(do(w)\\))한다면 \\(X\\)의 조작(\\(do(x)\\)) 여부는 \\(Y\\)에 영향을 주지 않습니다.\n이제 우리는 두 가지 항 \\(Q[Y]\\)와 \\(Q[W]\\)를 각각 \\(P(\\mathbf{V}|do(z))\\)로 표현하면 됩니다."
  },
  {
    "objectID": "posts/lecture/L17/part-02/index.html#derivation-step-2-identification-from-pmathbfvdoz",
    "href": "posts/lecture/L17/part-02/index.html#derivation-step-2-identification-from-pmathbfvdoz",
    "title": "[Causal Inference] 17. Causal Data Science (Part 2)",
    "section": "3. Derivation Step 2: Identification from \\(P(\\mathbf{V}|do(z))\\)",
    "text": "3. Derivation Step 2: Identification from \\(P(\\mathbf{V}|do(z))\\)\n\n이미지의 유도 과정을 따라 각 항을 실험 분포 \\(P(\\cdot|do(z))\\)로 변환합니다.\n\n\nA. Identifying \\(Q[Y] = P(y|do(w))\\)\n\n\\(Y\\)에 대한 \\(W\\)의 효과를 구하는 과정입니다. \\(W\\)와 \\(Y\\) 사이에도 교란이 있으므로 \\(Z\\)를 도구로 사용합니다.\n\n\\[\n\\begin{aligned}\nQ[Y] &= P(y|do(w)) \\\\\n&= P(y|do(w, z)) \\quad \\text{(Rule 3: Adding Action of } Z \\text{)} \\\\\n&= \\sum_{x} P(y|do(w, z), x) P(x|do(w, z)) \\quad \\text{(Law of Total Probability on } X \\text{)} \\\\\n&= \\sum_{x} P(y|do(w, z), x) P(x|do(z)) \\quad \\text{(Rule 3: Removing Action of } W \\text{)} \\\\\n&= \\sum_{x} \\underbrace{P(y|do(z), w, x)}_{\\text{Available in Data}} \\underbrace{P(x|do(z))}_{\\text{Available in Data}} \\quad \\text{(Rule 2: Action/Observation Exchange of } W \\text{)}\n\\end{aligned}\n\\]\n\n핵심: \\(P(y|do(z), w, x)\\)는 \\(do(z)\\) 실험 데이터에서 관측 가능한 조건부 확률입니다. 즉, \\(do(w)\\)라는 가상의 개입을 관측값 \\(w\\)로 치환하는 데 성공했습니다.\n\n\n\nB. Identifying \\(Q[W] = P(w|do(x))\\)\n\n\\(X\\)가 \\(W\\)에 미치는 효과를 구하는 과정입니다.\n\n\\[\n\\begin{aligned}\nQ[W] &= P(w|do(x)) \\\\\n&= P(w|do(x, z)) \\quad \\text{(Rule 3: Adding Action of } Z \\text{)} \\\\\n&= \\underbrace{P(w|do(z), x)}_{\\text{Available in Data}} \\quad \\text{(Rule 2: Action/Observation Exchange of } X \\text{)}\n\\end{aligned}\n\\]\n\n핵심: \\(do(z)\\) 환경에서는 \\(X\\)에서 \\(W\\)로 가는 경로의 교란이 해결되므로, \\(do(x)\\)를 관측값 \\(x\\)로 바꿀 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L17/part-02/index.html#final-formula",
    "href": "posts/lecture/L17/part-02/index.html#final-formula",
    "title": "[Causal Inference] 17. Causal Data Science (Part 2)",
    "section": "4. Final Formula",
    "text": "4. Final Formula\n\n위의 두 결과를 결합하면 최종적으로 \\(P(y|do(x))\\)를 실험 데이터 \\(do(z)\\)만으로 계산하는 식(calculus)이 완성됩니다.\n\n\\[\nP(y|do(x)) = \\sum_{w} \\left[ \\left( \\sum_{x'} P(y|do(z), w, x')P(x'|do(z)) \\right) \\times P(w|do(z), x) \\right]\n\\]\n\n결론: 이처럼 복잡한 인과 그래프에서도 문제를 더 작은 단위(C-component)로 쪼개고, 각 단위를 가용한 실험 데이터(\\(do(z)\\))로 환원(Reduce)시킴으로써 인과 효과를 식별해 낼 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L17/part-02/index.html#problem-setup",
    "href": "posts/lecture/L17/part-02/index.html#problem-setup",
    "title": "[Causal Inference] 17. Causal Data Science (Part 2)",
    "section": "4.1. Problem Setup",
    "text": "4.1. Problem Setup\n\nVariables:\n\n\\(X_1\\): 고혈압 치료제 (Anti-hypertensive drug)\n\\(X_2\\): 당뇨 치료제 (Anti-diabetic drug)\n\\(B\\): 혈압 (Blood pressure)\n\\(Y\\): 심혈관 질환 (CVD)\n\nData Sources:\n\nStudy 1: \\(X_1\\)에 대한 RCT \\(\\rightarrow P(v|do(x_1))\\)\nStudy 2: \\(X_2\\)에 대한 RCT \\(\\rightarrow P(v|do(x_2))\\)\n\nTarget Query:\n\nJoint Intervention: \\(P(y|do(x_1, x_2))\\)\n\n\n\n\n\nFigure 4: 약물 상호작용 인과 그래프. X1은 B에 영향을 주고, B는 Y에 영향을 준다. X2는 Y에 직접 영향을 준다. X1과 B, X2와 Y, X1와 X2 사이에는 교란 요인(점선)이 존재한다. 목표는 X1과 X2를 동시에 개입했을 때 Y의 분포를 구하는 것이다."
  },
  {
    "objectID": "posts/lecture/L17/part-02/index.html#derivation-1",
    "href": "posts/lecture/L17/part-02/index.html#derivation-1",
    "title": "[Causal Inference] 17. Causal Data Science (Part 2)",
    "section": "4.2. Derivation",
    "text": "4.2. Derivation\n\n우리는 \\(P(y|do(x_1, x_2))\\)를 구해야 합니다. 혈압 \\(B\\)가 \\(X_1\\)과 \\(Y\\) 사이의 매개체 역할을 한다는 점에 착안하여 식을 전개합니다.\n\n\nTotal Probability Theorem over B: \\[P(y|do(x_1, x_2)) = \\sum_{b} P(y|do(x_1, x_2), b) P(b|do(x_1, x_2))\\]\nFactor 1: \\(P(y|do(x_1, x_2), b)\\)\n\n그래프에서 \\(X_1\\)은 \\(B\\)로 가는 화살표를 제외하면 \\(Y\\)에 직접 영향을 주지 않습니다(Block).\n따라서 \\(X_1\\)을 조건부에서 제거할 수 있습니다(Rule 3). \\[P(y|do(x_1, x_2), b) = P(y|do(x_2), b)\\]\n이 항은 Study 2 (\\(do(x_2)\\)) 데이터에서 \\(B\\)를 관측함으로써 얻을 수 있습니다 (\\(P_{x_2}(y|b)\\)).\n\nFactor 2: \\(P(b|do(x_1, x_2))\\)\n\n그래프에서 \\(X_2\\)는 \\(B\\)에 영향을 주지 않습니다 (\\(Y\\)에만 영향).\n따라서 \\(X_2\\)를 제거할 수 있습니다. \\[P(b|do(x_1, x_2)) = P(b|do(x_1))\\]\n이 항은 Study 1 (\\(do(x_1)\\)) 데이터에서 바로 얻을 수 있습니다 (\\(P_{x_1}(b)\\)).\n\n\n\n4.3. Final Formula\n\\[\nP(y|do(x_1, x_2)) = \\sum_{b} P_{x_1}(b) P_{x_2}(y|b)\n\\]\n\n이 결과는 매우 강력합니다.\n두 약물을 동시에 사용하는 실험을 한 번도 수행하지 않았음에도, 개별 약물 실험 데이터를 수학적으로 결합하여 그 효과를 정확히 예측할 수 있기 때문입니다."
  },
  {
    "objectID": "posts/lecture/L17/part-02/index.html#the-g-id-algorithm-flow",
    "href": "posts/lecture/L17/part-02/index.html#the-g-id-algorithm-flow",
    "title": "[Causal Inference] 17. Causal Data Science (Part 2)",
    "section": "The g-ID Algorithm Flow",
    "text": "The g-ID Algorithm Flow\n\nDecomposition (분해):\n\n주어진 쿼리 \\(Q = P_x(y)\\)를 Causal Graph의 구조(C-components)를 이용하여 더 작은 Factors (요인들)의 곱과 합(\\(\\sum \\prod\\))으로 분해합니다. \\[Q = \\sum \\prod P_{\\bullet}(\\bullet)\\]\n\nIdentification (식별):\n\n분해된 각 Factor가 가용한 데이터 소스 집합 \\(\\mathbb{P} = \\{ P(obs), P(do(z_1)), P(do(z_2)), \\dots \\}\\) 중 하나로부터 식별 가능한지 확인합니다.\n\n\n\n\nFigure 5: g-ID 알고리즘의 도식화. 쿼리(좌측)가 여러 Factor로 분해되고, 각 Factor가 우측의 가용 데이터 소스(P_z1, P_zm…) 중 하나와 매칭되어 식별되는 과정을 보여준다.\n\n\nConclusion:\n\n만약 모든 Factor가 데이터 소스로부터 식별 가능하다면 \\(\\rightarrow\\) Identifiable.\n하나라도 식별 불가능한 Factor가 남는다면 \\(\\rightarrow\\) Fail."
  },
  {
    "objectID": "posts/lecture/L17/part-02/index.html#significance",
    "href": "posts/lecture/L17/part-02/index.html#significance",
    "title": "[Causal Inference] 17. Causal Data Science (Part 2)",
    "section": "Significance",
    "text": "Significance\n\n이 알고리즘과 Do-calculus는 Experimental Identifiability 문제에 대해 Completeness(완전성)를 가집니다.\n즉, 이 알고리즘으로 식별할 수 없다면, 그 인과 효과는 주어진 데이터와 그래프 가정하에서는 이론적으로 식별이 불가능한 것입니다."
  },
  {
    "objectID": "posts/lecture/L17/part-04/index.html",
    "href": "posts/lecture/L17/part-04/index.html",
    "title": "[Causal Inference] 17. Causal Data Science (Part 4)",
    "section": "",
    "text": "데이터 과학에서 우리는 종종 “데이터가 스스로 말하게 하라(Let the data speak)”는 격언을 듣습니다.\n하지만 데이터가 수집되는 과정에서 이미 입이 막혀 있거나, 왜곡된 목소리만 내고 있다면 어떨까요? 이것이 바로 선택 편향(Selection Bias)의 문제입니다.\n선택 편향은 데이터 샘플링 과정에서 특정 개체가 우선적으로 포함되거나 배제됨으로써 발생합니다.\n이는 단순한 통계적 오차를 넘어, 인과 추론의 타당성을 근본적으로 위협하는 주요 장애물입니다.\n\n\n\n\n우리는 앞서 교란(Confounding)에 대해 다뤘습니다. 두 편향은 근본적으로 다릅니다.\nConfounding:\n\n자연(Nature)적으로 발생하는 Treatment와 Outcome 사이의 정보 흐름(Common Cause)입니다.\n“치료를 받은 사람이 더 건강해서 결과가 좋은가?”의 문제입니다.\n\nSelection Bias:\n\n인간(Man-made)에 의해, 혹은 측정 장비에 의해 발생하는 데이터 수집 과정의 편향입니다.\n“특정 조건을 만족하는 사람만 설문에 응답했는가?”의 문제입니다.\n\n\n\n\n\nFigure 1: Confounding vs Selection Bias. 왼쪽은 Z가 X와 Y에 영향을 주는 교란(Confounding) 구조이고, 오른쪽은 X와 Y가 S(선택 여부)에 영향을 주는 선택 편향(Selection Bias) 구조이다. S=1인 샘플만 관측됨으로써 X와 Y 사이에 허위 상관관계(Spurious Correlation)가 발생한다.\n\n\n\n이 포스트에서는 선택 편향이 있는 데이터(\\(S=1\\))만 관측 가능한 상황에서, 어떻게 전체 모집단의 분포(\\(P(y|x)\\))나 인과 효과(\\(P(y|do(x))\\))를 복원(Recover)할 수 있는지 다룹니다."
  },
  {
    "objectID": "posts/lecture/L17/part-04/index.html#confounding-vs.-selection-bias",
    "href": "posts/lecture/L17/part-04/index.html#confounding-vs.-selection-bias",
    "title": "[Causal Inference] 17. Causal Data Science (Part 4)",
    "section": "",
    "text": "우리는 앞서 교란(Confounding)에 대해 다뤘습니다. 두 편향은 근본적으로 다릅니다.\nConfounding:\n\n자연(Nature)적으로 발생하는 Treatment와 Outcome 사이의 정보 흐름(Common Cause)입니다.\n“치료를 받은 사람이 더 건강해서 결과가 좋은가?”의 문제입니다.\n\nSelection Bias:\n\n인간(Man-made)에 의해, 혹은 측정 장비에 의해 발생하는 데이터 수집 과정의 편향입니다.\n“특정 조건을 만족하는 사람만 설문에 응답했는가?”의 문제입니다.\n\n\n\n\n\nFigure 1: Confounding vs Selection Bias. 왼쪽은 Z가 X와 Y에 영향을 주는 교란(Confounding) 구조이고, 오른쪽은 X와 Y가 S(선택 여부)에 영향을 주는 선택 편향(Selection Bias) 구조이다. S=1인 샘플만 관측됨으로써 X와 Y 사이에 허위 상관관계(Spurious Correlation)가 발생한다.\n\n\n\n이 포스트에서는 선택 편향이 있는 데이터(\\(S=1\\))만 관측 가능한 상황에서, 어떻게 전체 모집단의 분포(\\(P(y|x)\\))나 인과 효과(\\(P(y|do(x))\\))를 복원(Recover)할 수 있는지 다룹니다."
  },
  {
    "objectID": "posts/lecture/L17/part-06/index.html",
    "href": "posts/lecture/L17/part-06/index.html",
    "title": "[Causal Inference] 17. Causal Data Science (Part 6)",
    "section": "",
    "text": "현대 데이터 과학, 특히 사회과학과 공학이 교차하는 지점에서는 “모든 변수가 완벽하게 측정된 단 하나의 데이터셋”을 확보하는 것이 거의 불가능합니다. 현실에서는 다음과 같은 상황이 빈번하게 발생합니다.\n\n실험 연구(Experimental Study): 핵심적인 처치(Treatment)와 주요 결과 변수만 측정하며, 비용 문제로 많은 공변량을 측정하지 못함.\n관찰 연구(Observational Study): 방대한 공변량과 결과 변수가 존재하지만, 처치 변수가 없거나 무작위 배정(Randomization)이 되어 있지 않음.\n\n이러한 상황에서, 서로 다른 변수 집합(\\(V_i \\subseteq V\\))을 포함하는 이질적인 데이터셋들을 결합하여, 전체 시스템의 인과 효과(Causal Effect)를 추정할 수 있을까요? 이번 포스트에서는 General Identifiability with Partial Observation (GID-PO) 개념을 통해 이 문제를 해결하는 과정을 다룹니다."
  },
  {
    "objectID": "posts/lecture/L17/part-06/index.html#introduction-데이터-융합data-fusion의-필요성",
    "href": "posts/lecture/L17/part-06/index.html#introduction-데이터-융합data-fusion의-필요성",
    "title": "[Causal Inference] 17. Causal Data Science (Part 6)",
    "section": "",
    "text": "현대 데이터 과학, 특히 사회과학과 공학이 교차하는 지점에서는 “모든 변수가 완벽하게 측정된 단 하나의 데이터셋”을 확보하는 것이 거의 불가능합니다. 현실에서는 다음과 같은 상황이 빈번하게 발생합니다.\n\n실험 연구(Experimental Study): 핵심적인 처치(Treatment)와 주요 결과 변수만 측정하며, 비용 문제로 많은 공변량을 측정하지 못함.\n관찰 연구(Observational Study): 방대한 공변량과 결과 변수가 존재하지만, 처치 변수가 없거나 무작위 배정(Randomization)이 되어 있지 않음.\n\n이러한 상황에서, 서로 다른 변수 집합(\\(V_i \\subseteq V\\))을 포함하는 이질적인 데이터셋들을 결합하여, 전체 시스템의 인과 효과(Causal Effect)를 추정할 수 있을까요? 이번 포스트에서는 General Identifiability with Partial Observation (GID-PO) 개념을 통해 이 문제를 해결하는 과정을 다룹니다."
  },
  {
    "objectID": "posts/lecture/L17/part-06/index.html#problem-setup-gid-po",
    "href": "posts/lecture/L17/part-06/index.html#problem-setup-gid-po",
    "title": "[Causal Inference] 17. Causal Data Science (Part 6)",
    "section": "2. Problem Setup: GID-PO",
    "text": "2. Problem Setup: GID-PO\n우리가 관심을 가지는 전체 변수 집합을 \\(\\mathbb{V}\\)라고 합시다. 하지만 우리는 \\(\\mathbb{V}\\) 전체를 관측한 데이터가 없습니다. 대신, \\(\\mathbb{V}\\)의 부분집합인 \\(V_i\\)만을 관측한 여러 개의 데이터셋(실험 또는 관찰) 모음 \\(\\mathbb{P}=\\{P_{Z_{i}}(V_{i})\\}_{i}\\)를 가지고 있습니다.\n이때 우리의 목표는 타겟 인과 효과 \\(P_x(y)\\) (처치 \\(X\\)가 결과 \\(Y\\)에 미치는 효과)를 식별(Identify)하는 것입니다.\n\n2.1 예시 시나리오: 운동이 뇌졸중에 미치는 영향\n강의 자료에서 제시된 구체적인 예시를 통해 문제를 정의해 봅시다. 우리는 운동(Exercise, \\(X\\))이 뇌졸중(Stroke, \\(Y\\))에 미치는 인과적 효과를 알고 싶습니다.\n관련된 변수들은 다음과 같습니다: * \\(A\\): 나이 (Age) * \\(X\\): 운동 (Exercise) - 처치 변수 * \\(B\\): BMI * \\(C\\): 혈압 (Blood Pressure) * \\(Y\\): 뇌졸중 (Stroke) - 결과 변수\n이 변수들의 인과 관계는 아래의 Causal Graph(DAG)로 표현됩니다.\n\n\n\nFigure 1: Exercise & Stroke Causal Graph. A(Age)는 X(Exercise)와 B(BMI)에 영향을 줌. X는 B에 영향을 줌. B는 C(Blood Pressure)에 영향을 줌. C는 Y(Stroke)에 영향을 줌. 점선(Dashed Line)은 X와 Y 사이에 관측되지 않은 교란 요인(Unobserved Confounder)이 존재함을 암시함.\n\n\n\n\n2.2 주어진 데이터의 한계\n우리는 \\(P(A, X, B, C, Y)\\) 전체를 포함하는 데이터가 없습니다. 대신 두 가지의 불완전한 연구 결과만 가지고 있다고 가정해 봅시다.\n\n연구 1 (Experimental Study):\n\n운동(\\(X\\))에 대해 무작위 배정(Intervention)을 수행했습니다.\n측정 변수: 나이(\\(A\\)), 혈압(\\(C\\)). (BMI와 뇌졸중은 측정하지 않음)\n확보된 분포: \\(P_X(A, C)\\)\n\n연구 2 (Observational Study):\n\n단순 관찰 연구입니다.\n측정 변수: BMI(\\(B\\)), 혈압(\\(C\\)), 뇌졸중(\\(Y\\)). (나이와 운동 여부는 데이터에 없음)\n확보된 분포: \\(P(B, C, Y)\\)\n\n\nTask: 이 두 가지 부분적인 분포 \\(P_X(A, C)\\)와 \\(P(B, C, Y)\\)만을 사용하여, 타겟 인과 효과 \\(P_X(Y)\\)를 계산할 수 있는가?"
  },
  {
    "objectID": "posts/lecture/L17/part-06/index.html#mathematical-derivations",
    "href": "posts/lecture/L17/part-06/index.html#mathematical-derivations",
    "title": "[Causal Inference] 17. Causal Data Science (Part 6)",
    "section": "3. Mathematical Derivations",
    "text": "3. Mathematical Derivations\n이 문제는 단순히 데이터를 합치는(Merge) 것으로는 해결되지 않습니다. 공통 변수가 \\(C\\)밖에 없으며, 연구 1은 실험 데이터, 연구 2는 관찰 데이터라는 성격의 차이가 있기 때문입니다. 우리는 확률 분포의 분해(Factorization) 법칙과 인과 그래프의 구조를 이용해야 합니다.\n\n3.1 Step 1: Target Distribution의 정의\n우리가 구하고자 하는 것은 \\(X\\)에 개입했을 때 \\(Y\\)의 주변 확률 분포(Marginal Distribution)입니다. \\[P_x(y) = \\sum_{a,b,c} P_x(a, b, c, y)\\]\n\n\n3.2 Step 2: C-Component Factorization\n인과 그래프(Figure 1)의 구조에 따라 결합 확률 분포(Joint Distribution)를 분해해 봅시다. 특히 \\(do(X)\\) 연산이 적용된 개입 분포(Interventional Distribution) \\(P_x(\\cdot)\\)를 고려합니다.\n일반적인 베이지안 네트워크 분해 법칙과 \\(do\\)-calculus의 원리에 따라, \\(X\\)로 들어오는 화살표를 제거한 그래프에서의 분해를 생각할 수 있습니다. 강의 자료의 유도 과정(Slide 8-10)에 따르면, 이 시스템은 다음과 같은 형태로 분해(Factorization)될 수 있습니다.\n\\[P_x(a, b, c, y) = P(a) \\cdot P_{a,x}(b) \\cdot P_b(c) \\cdot P_c(y)\\]\n이 식의 각 항이 의미하는 바는 다음과 같습니다: * \\(P(a)\\): 나이의 분포 (외생 변수). * \\(P_{a,x}(b)\\): \\(A\\)와 \\(X\\)가 주어졌을 때(또는 개입했을 때) \\(B\\)의 분포. * \\(P_b(c)\\): \\(B\\)가 주어졌을 때 \\(C\\)의 분포. * \\(P_c(y)\\): \\(C\\)가 주어졌을 때 \\(Y\\)의 분포.\n\n\n\n\n\n\nNote\n\n\n\nWhy this factorization? 이 분해는 그래프의 c-component 구조에 기반합니다. \\(X\\)와 \\(Y\\) 사이에는 직접적인(또는 confounding에 의한) 경로가 존재하지만, \\(A \\to B \\to C \\to Y\\)와 같은 매개 경로들이 존재합니다. 이 식은 전체 효과를 각 메커니즘의 결합으로 쪼갠 것입니다.\n\n\n\n\n3.3 Step 3: 수식의 재구성 (Regrouping)\n이제 위에서 얻은 식을 우리가 가진 데이터 \\(P_X(A, C)\\)와 \\(P(B, C, Y)\\)와 연결하기 위해 \\(\\sum\\)의 순서를 조정하여 재구성합니다.\n\\[\n\\begin{aligned}\nP_x(y) &= \\sum_{a,b,c} P(a) P_{a,x}(b) P_b(c) P_c(y) \\\\\n&= \\sum_{a,c} P(a) \\left( \\sum_{b} P_{a,x}(b) P_b(c) \\right) P_c(y)\n\\end{aligned}\n\\]\n여기서 괄호 안의 부분 \\(\\sum_{b} P_{a,x}(b) P_b(c)\\)를 살펴봅시다. 이는 \\(A\\)와 \\(X\\)가 결정되었을 때, \\(B\\)를 거쳐 \\(C\\)가 결정되는 과정의 확률, 즉 \\(P_{a,x}(c)\\)로 해석할 수 있습니다 (Chain Rule of Intervention).\n따라서 식은 다음과 같이 간소화됩니다.\n\\[P_x(y) = \\sum_{a,c} P(a) P_{a,x}(c) P_c(y)\\]\n이 식은 매우 중요한 의미를 가집니다. 서로 다른 출처의 정보를 결합할 수 있는 연결고리가 되기 때문입니다."
  },
  {
    "objectID": "posts/lecture/L17/part-06/index.html#mapping-to-data-sources-the-puzzle",
    "href": "posts/lecture/L17/part-06/index.html#mapping-to-data-sources-the-puzzle",
    "title": "[Causal Inference] 17. Causal Data Science (Part 6)",
    "section": "4. Mapping to Data Sources (The Puzzle)",
    "text": "4. Mapping to Data Sources (The Puzzle)\n이제 최종 유도된 식의 각 구성 요소가 우리가 가진 두 개의 데이터셋 중 어디에서 올 수 있는지 확인해 봅시다.\n\\[P_x(y) = \\sum_{a,c} \\underbrace{P(a) P_{a,x}(c)}_{\\text{Source 1}} \\cdot \\underbrace{P_c(y)}_{\\text{Source 2}}\\]\n\n4.1 Source 1: Experimental Study (\\(P_X(A, C)\\))\n첫 번째 데이터셋은 운동(\\(X\\))에 개입한 실험 데이터이며 \\(A\\)와 \\(C\\)를 관측합니다. 즉, \\(P_X(A, C)\\) 분포를 온전히 가지고 있습니다.\n\n\\(P(a)\\): \\(X\\)는 무작위 배정되었으므로 \\(A\\)와 독립입니다. 따라서 \\(P_x(a) = P(a)\\). 실험군 내의 나이 분포에서 얻을 수 있습니다.\n\\(P_{a,x}(c)\\): \\(A\\)와 \\(X\\)가 주어졌을 때 \\(C\\)의 분포입니다. 실험 데이터 \\(P_X(A, C)\\)에서 조건부 확률 등을 통해 도출할 수 있습니다. (엄밀히는 \\(P_x(c|a)\\) 형태)\n\n따라서 식의 앞부분 \\(P(a)P_{a,x}(c)\\)는 연구 1에서 식별 가능합니다.\n\n\n4.2 Source 2: Observational Study (\\(P(B, C, Y)\\))\n두 번째 데이터셋은 \\(B, C, Y\\)를 관측합니다. 우리가 필요한 마지막 조각은 \\(P_c(y)\\)입니다.\n\n그래프 구조상 \\(C\\)에서 \\(Y\\)로 가는 길목에 \\(B\\)가 교란 요인으로 작용하지 않고(앞단의 변수임), \\(X\\)와 \\(Y\\) 사이의 Confounding path는 존재하지만, \\(C\\) 자체에 대한 개입(\\(P_c(y)\\))을 고려할 때 \\(P(B, C, Y)\\) 데이터 내에서 이를 추정할 수 있는 구조적 조건이 성립합니다.\n즉, \\(P_c(y)\\)는 연구 2의 관찰 데이터로부터 복원해낼 수 있습니다.\n\n\n\n\nFigure 2: The Puzzle of Data Fusion. 보라색 퍼즐 조각(\\(P_c(y)\\), \\(P_{a,x}(b)\\) 등)과 초록색 퍼즐 조각(\\(P(a)\\), \\(P_b(c)\\))이 서로 다른 데이터셋에서 추출되어 하나의 완성된 그림(\\(P_x(y)\\))을 맞추는 과정을 시각화함.\n\n\n\n\n4.3 Final Formula\n결과적으로 우리는 타겟 효과를 다음과 같이 계산할 수 있습니다.\n\\[P_x(y) = \\sum_{a,c} P_x(a, c) \\times P_c(y)\\]\n(참고: 위 식은 직관적인 매핑을 보여주며, 실제 계산 시에는 \\(P_c(y)\\)를 \\(P(B,C,Y)\\)에서 도출하기 위한 추가적인 adjustment formula가 적용될 수 있습니다. 강의 자료 Slide 10 하단에는 다음과 같은 GID 공식이 제시되어 있습니다.)\n\\[\\text{GID} = \\sum_{a,c} P_{x'}(a) P_x(c|a) \\left( \\sum_b P(y|b,c)P(b) \\right)\\]\n이 공식은 각 데이터 소스에서 얻을 수 있는 확률값들의 곱과 합으로 타겟 인과 효과를 완벽하게 재구성합니다."
  },
  {
    "objectID": "posts/lecture/L17/part-06/index.html#conclusions",
    "href": "posts/lecture/L17/part-06/index.html#conclusions",
    "title": "[Causal Inference] 17. Causal Data Science (Part 6)",
    "section": "5. Conclusions",
    "text": "5. Conclusions\n이번 GID-PO 프레임워크가 시사하는 바는 단순히 수식을 푸는 것 이상입니다.\n\nData Fusion의 이론적 토대: 서로 다른 변수를 측정하는 이질적인 데이터셋들도, 그 기저에 있는 인과 메커니즘(Causal Mechanism)을 공유한다면 논리적으로 결합될 수 있습니다.\n데이터 과학의 새로운 패러다임: 빅데이터 시대에는 “모든 것을 측정한 스몰 데이터”보다 “부분적으로 측정한 빅 데이터”가 더 흔합니다. GID-PO는 이러한 환경에서 선택 편향(Selection Bias), 교란 편향(Confounding Bias), 그리고 데이터 결측(Missing Data) 문제를 통합적으로 해결할 수 있는 충분조건과 알고리즘을 제공합니다.\nParsimonious Representation: 인과 그래프는 현상을 설명하는 가장 간결하고(coarse and parsimonious) 효율적인 표현 방식이며, 이를 통해 데이터 통합의 복잡성을 관리할 수 있습니다.\n\n\n\nAppendix: Checklist\n본 포스트 작성을 위해 검토한 강의 자료 체크리스트입니다.\n\nGID-PO 개념 정의: 부분 관측(Partial Observation) 하에서의 식별 가능성 문제 정의 완료.\nCausal Graph & Variables: Exercise-Stroke 예시의 변수(\\(A, X, B, C, Y\\)) 및 그래프 구조 반영 완료.\nData Sources: 실험 연구(\\(P_X(A,C)\\))와 관찰 연구(\\(P(B,C,Y)\\))의 차이 명시 완료.\nMathematical Derivation: \\(P_x(y)\\)의 분해 과정(Factorization) 및 단계별 유도(\\(\\sum\\) regrouping) 포함 완료.\nData Mapping: 유도된 수식의 각 항이 어느 데이터셋에서 식별 가능한지 설명 완료.\nVisuals: 인과 그래프 및 퍼즐 비유 이미지에 대한 설명(Alt text) 포함 완료.\nConclusion: 인과 데이터 과학(Causal Data Science) 관점에서의 의의 서술 완료."
  },
  {
    "objectID": "posts/lecture/L16/part-02/index.html",
    "href": "posts/lecture/L16/part-02/index.html",
    "title": "[Causal Inference] 16. Causal Discovery (Part 2)",
    "section": "",
    "text": "이전 포스트에서는 Causal Discovery를 위한 핵심 가정인 Faithfulness에 대해 다루었습니다.\n이번 포스트에서는 이 가정을 바탕으로 실제 데이터에서 인과 그래프(DAG)를 찾아내는 대표적인 방법론인 Constraint-Based Structure Learning을 다룹니다.\n이 방법론의 핵심 아이디어는 다음과 같습니다:\n\n\n데이터에서 성립하는 제약 조건(Constraints), 즉 조건부 독립성(Conditional Independencies, CIs)을 찾아냅니다.\n\n\n이 제약 조건들과 모순되는 그래프들을 후보군에서 제거합니다.\n\n\n남은 그래프(또는 그래프들의 집합)를 결과로 반환합니다.\n\n\n이 과정의 가장 대표적인 알고리즘인 PC Algorithm을 통해, 어떻게 데이터만으로 인과 구조를 복원할 수 있는지 단계별로 살펴보겠습니다."
  },
  {
    "objectID": "posts/lecture/L16/part-02/index.html#the-true-model-target",
    "href": "posts/lecture/L16/part-02/index.html#the-true-model-target",
    "title": "[Causal Inference] 16. Causal Discovery (Part 2)",
    "section": "2.1 The True Model (Target)",
    "text": "2.1 The True Model (Target)\n\n우리가 찾고자 하는 정답(True DAG)은 다음과 같은 구조라고 가정합니다.\n\n\n\n\nFigure 1: True Generating DAG. W는 X와 Y의 공통 원인이며(Fork), X와 Y는 Z의 원인이다(Collider). 이 그래프는 Diamond 형태를 띤다.\n\n\n\n이 그래프 구조 \\(\\mathcal{G}\\)가 암시하는 조건부 독립성(Conditional Independencies)은 무엇일까요?\n\\(d\\)-separation 기준을 적용해보면 크게 두 가지 중요한 독립성을 발견할 수 있습니다.\n\n\n\\(X\\)와 \\(Y\\)의 관계 (\\(X \\perp\\!\\!\\!\\perp Y \\mid W\\))\n\n\n\\(X\\)와 \\(Y\\)는 \\(W\\)를 통해 연결(Fork: \\(X \\leftarrow W \\rightarrow Y\\))되어 있고, \\(Z\\)를 통해 연결(Collider: \\(X \\rightarrow Z \\leftarrow Y\\))되어 있습니다.\nCollider인 \\(Z\\)를 조건부로 주지 않으면 \\(Z\\) 경로는 막힙니다.\nFork인 \\(W\\)를 조건부로 주면 \\(W\\) 경로는 막힙니다.\n따라서 \\(W\\)만 주어졌을 때 두 변수는 독립입니다.\n\n\n\\(W\\)와 \\(Z\\)의 관계 (\\(W \\perp\\!\\!\\!\\perp Z \\mid \\{X, Y\\}\\))\n\n\n\\(W\\)에서 \\(Z\\)로 가는 두 경로(\\(W \\rightarrow X \\rightarrow Z\\) 및 \\(W \\rightarrow Y \\rightarrow Z\\))는 모두 Chain 구조입니다.\nChain 구조의 중간 노드인 \\(X\\)와 \\(Y\\)가 조건부로 주어지면(Observed), 정보의 흐름이 차단됩니다(Blocked).\n따라서 \\(X\\)와 \\(Y\\)가 모두 주어졌을 때 \\(W\\)와 \\(Z\\)는 독립입니다.\n\n\n결론적으로, 이 그래프가 강제하는 조건부 독립성(CI) 목록은 다음과 같습니다: \\[X \\perp\\!\\!\\!\\perp Y \\mid W\\] \\[W \\perp\\!\\!\\!\\perp Z \\mid \\{X, Y\\}\\]"
  },
  {
    "objectID": "posts/lecture/L16/part-02/index.html#finding-the-skeleton-adjacency-search",
    "href": "posts/lecture/L16/part-02/index.html#finding-the-skeleton-adjacency-search",
    "title": "[Causal Inference] 16. Causal Discovery (Part 2)",
    "section": "2.2 Finding the Skeleton (Adjacency Search)",
    "text": "2.2 Finding the Skeleton (Adjacency Search)\n\n이제 우리는 그래프를 모른 채, 데이터로부터 앞선 조건부 독립성만을 발견했다고 가정합니다.\n\n\nStep 1: Start with a Complete Graph\n\n아무런 정보가 없을 때, 우리의 최선의 추측은 모든 변수가 서로 연결된 완전 무방향 그래프(Undirected Complete Graph)입니다."
  },
  {
    "objectID": "posts/lecture/L16/part-02/index.html#step-2-remove-edges-based-on-ci-skeleton-learning",
    "href": "posts/lecture/L16/part-02/index.html#step-2-remove-edges-based-on-ci-skeleton-learning",
    "title": "[Causal Inference] 16. Causal Discovery (Part 2)",
    "section": "Step 2: Remove Edges based on CI (Skeleton Learning)",
    "text": "Step 2: Remove Edges based on CI (Skeleton Learning)\n\n인과 구조 학습의 첫 번째 단계는 완전 연결 그래프(Complete Graph)에서 시작하여, 데이터에서 발견된 조건부 독립성(CI)을 바탕으로 엣지를 하나씩 제거해 나가는 것입니다.\n이 예제에서는 두 가지 주요한 독립성이 엣지 제거에 활용됩니다.\n\n\n1. 첫 번째 엣지 제거: \\(X\\)와 \\(Y\\)\n\n우리는 데이터에서 \\(X \\perp\\!\\!\\!\\perp Y \\mid W\\)를 관측했습니다.\n이는 \\(W\\)라는 공통 원인(Common Cause)을 통제했을 때 \\(X\\)와 \\(Y\\)가 독립이 됨을 의미합니다.\n따라서 \\(X\\)와 \\(Y\\) 사이에는 직접적인 인과관계가 없으므로, \\(X - Y\\) 엣지를 제거합니다.\n\n\n\n2. 두 번째 엣지 제거: \\(W\\)와 \\(Z\\)\n\n또한, 우리는 \\(W \\perp\\!\\!\\!\\perp Z \\mid \\{X, Y\\}\\)를 관측했습니다.\n이는 \\(X\\)와 \\(Y\\)가 모두 주어졌을 때, \\(W\\)와 \\(Z\\) 사이의 정보 흐름이 차단됨을 의미합니다.\n따라서 \\(W\\)와 \\(Z\\) 사이에도 직접적인 엣지가 없으므로, \\(W - Z\\) 엣지를 제거합니다.\n\n\n\n3. 결과: Skeleton (뼈대)\n\n위 과정을 통해 통계적으로 독립인 변수 쌍들의 연결이 모두 끊어졌습니다.\n남은 그래프는 방향성이 없는 Skeleton(뼈대) 형태가 됩니다.\n남은 엣지: \\(W-X, W-Y, X-Z, Y-Z\\)\n\n\n\n\nFigure 2: Skeleton Learning Process. 완전 연결 그래프로 시작해서 조건부 독립성(\\(X \\perp\\!\\!\\!\\perp Y \\mid W\\) and \\(W \\perp\\!\\!\\!\\perp Z \\mid \\{X, Y\\}\\))에 따라 간선을 지우면 뼈대를 추출할 수 있다."
  },
  {
    "objectID": "posts/lecture/L16/part-02/index.html#orienting-edges-finding-v-structures",
    "href": "posts/lecture/L16/part-02/index.html#orienting-edges-finding-v-structures",
    "title": "[Causal Inference] 16. Causal Discovery (Part 2)",
    "section": "2.3 Orienting Edges (Finding V-structures)",
    "text": "2.3 Orienting Edges (Finding V-structures)\n\n뼈대(Skeleton)를 찾았으니 이제 화살표의 방향을 찾을 차례입니다.\n이 과정의 핵심은 “두 변수가 독립이 되기 위해 어떤 변수를 조건부로 걸었는가(Seperating Set)?”를 확인하는 것입니다.\n\n\n1. Unshielded Triple 식별\n\n먼저 그래프에서 Unshielded Triple을 찾습니다.\n이는 \\(X - Z - Y\\) 처럼 서로 연결되어 있지만, 양 끝의 \\(X\\)와 \\(Y\\)는 직접 연결되지 않은(\\(X \\not\\sim Y\\)) 구조를 말합니다.\n\n\n\n2. Collider Test (V-structure 찾기)\n\n이제 \\(X\\)와 \\(Y\\) 사이의 엣지를 제거하게 만든(즉, 독립이 되게 만든) 조건부 집합(Separating Set, \\(S\\))을 확인합니다.\n일반적인 경우 (Chain/Fork):\n\n만약 \\(Z\\)가 Chain (\\(X \\rightarrow Z \\rightarrow Y\\))이나 Fork (\\(X \\leftarrow Z \\rightarrow Y\\))의 중심이라면, 정보의 흐름을 막기 위해 \\(Z\\)를 반드시 조건부로 걸어야 합니다.\n즉, \\(X \\perp\\!\\!\\!\\perp Y \\mid Z\\) 이어야 하므로, \\(Z \\in S\\) 입니다.\n\nCollider의 경우 (V-structure):\n\n만약 \\(Z\\)가 Collider (\\(X \\rightarrow Z \\leftarrow Y\\))라면, \\(Z\\)를 조건부로 걸면 오히려 경로가 열려버립니다(d-connected).\n따라서 \\(X\\)와 \\(Y\\)가 독립이 되려면 \\(Z\\)를 조건부 집합에 포함하지 않아야 합니다.\n즉, \\(X \\perp\\!\\!\\!\\perp Y \\mid S\\) 일 때, \\(Z \\notin S\\) 입니다.\n\n\n\n\n3. 예제 적용\n\n우리의 예시 데이터(True DAG)를 살펴봅시다.\n우리는 Skeleton 단계에서 \\(X\\)와 \\(Y\\)가 \\(W\\)를 통해 독립임을 확인했습니다 (\\(S = \\{W\\}\\)).\n구조는 \\(X - Z - Y\\) 형태의 Unshielded Triple입니다.\n이때, 가운데 낀 노드 \\(Z\\)는 \\(S\\)에 포함되지 않습니다 (\\(Z \\notin \\{W\\}\\)).\n결론:\n\n\\(Z\\)가 조건부 집합에 없는데도 \\(X\\)와 \\(Y\\)가 독립이라는 것은, \\(Z\\)가 정보를 막고 있는 Collider임을 의미합니다.\n따라서 우리는 다음과 같이 방향을 확정할 수 있습니다. \\[X \\rightarrow Z \\leftarrow Y\\]\n\n\n\n\n\nFigure 3: Orientation Step. X와 Y 사이의 엣지는 제거되었고, Z가 X와 Y를 독립시키는 조건 집합에 포함되지 않았으므로 Z 방향으로 모이는 V-structure(Collider)를 형성한다."
  },
  {
    "objectID": "posts/lecture/L16/part-02/index.html#propagating-directions-no-new-v-structures",
    "href": "posts/lecture/L16/part-02/index.html#propagating-directions-no-new-v-structures",
    "title": "[Causal Inference] 16. Causal Discovery (Part 2)",
    "section": "2.4 Propagating Directions (No New V-structures)",
    "text": "2.4 Propagating Directions (No New V-structures)\n\n이제 \\(Z\\)와 관련된 엣지는 방향이 정해졌습니다.\n남은 것은 \\(W\\)와 연결된 엣지들(\\(W-X, W-Y\\))입니다.\n여기서 가장 중요한 논리는 “우리가 발견하지 못한 V-structure를 새로 만들면 안 된다”는 것입니다.\n가설 검증 (\\(W\\)가 Collider인가?):\n\n만약 \\(X \\rightarrow W\\)이고 \\(Y \\rightarrow W\\)라면, \\(W\\)는 새로운 Collider (\\(X \\rightarrow W \\leftarrow Y\\))가 됩니다.\nCollider의 특징은 두 부모 변수(\\(X, Y\\))가 \\(W\\)를 모를 땐 독립이지만, \\(W\\)를 알게 되면 종속이 된다는 점입니다.\n하지만 우리는 데이터 탐색 단계에서 \\(X \\perp\\!\\!\\!\\perp Y \\mid W\\)임을 확인했습니다. 즉, \\(W\\)를 알 때 오히려 독립이 되었습니다.\n따라서, \\(W\\)는 절대로 Collider가 될 수 없습니다.\n\n결론 (방향의 제약):\n\n\\(W\\)가 Collider가 되는 경우(\\(X \\rightarrow W \\leftarrow Y\\))는 불가능하므로 제외해야 합니다.\n남은 가능성은 Fork (\\(X \\leftarrow W \\rightarrow Y\\))이거나 Chain (\\(X \\rightarrow W \\rightarrow Y\\) 등)입니다.\n데이터만으로는 이 중에서 하나를 특정할 수 없으나(Markov Equivalence Class), “Collider가 아니다”라는 강력한 제약 조건을 통해 오답을 소거했습니다.\n참고: 우리가 찾고자 하는 True DAG는 이 중 Fork 형태인 \\(W \\rightarrow X, W \\rightarrow Y\\) 였습니다.\n\n\n\n\n\nFigure 4: Orientation Step. W가 Collider가 될 수 없으므로, 3가지 경우의 수만 남는다."
  },
  {
    "objectID": "posts/lecture/L16/part-02/index.html#step-1-skeleton-identification",
    "href": "posts/lecture/L16/part-02/index.html#step-1-skeleton-identification",
    "title": "[Causal Inference] 16. Causal Discovery (Part 2)",
    "section": "Step 1: Skeleton Identification",
    "text": "Step 1: Skeleton Identification\n\n\n완전 무방향 그래프로 시작합니다.\n\n\n인접한 모든 변수 쌍 \\((A, B)\\)에 대해 조건부 독립성 검사(CI Test)를 수행합니다.\n\n\n조건 집합 \\(S\\)의 크기(\\(i\\))를 0부터 시작하여 하나씩 늘려갑니다.\n\n\n만약 어떤 \\(S\\)에 대해 \\((A \\perp\\!\\!\\!\\perp B \\mid S)\\)가 성립하면, 엣지 \\(A-B\\)를 제거합니다.\n이때의 \\(S\\)를 \\(sepset(\\{A, B\\})\\)로 저장해둡니다.\n\\(S\\)는 \\(A\\)와 \\(B\\)의 인접 노드(neighbors) 중에서 선택합니다."
  },
  {
    "objectID": "posts/lecture/L16/part-02/index.html#step-2-v-structure-identification-collider",
    "href": "posts/lecture/L16/part-02/index.html#step-2-v-structure-identification-collider",
    "title": "[Causal Inference] 16. Causal Discovery (Part 2)",
    "section": "Step 2: V-Structure Identification (Collider)",
    "text": "Step 2: V-Structure Identification (Collider)\n\n\nSkeleton에서 서로 인접하지 않은 \\(A, B\\)와, 둘 다와 인접한 공통 이웃 \\(C\\)를 찾습니다 (\\(A - C - B\\)).\n\n\n만약 \\(C\\)가 \\(sepset(\\{A, B\\})\\)에 포함되지 않는다면, \\(C\\)는 Collider입니다.\n\n\n따라서 \\(A \\rightarrow C \\leftarrow B\\)로 방향을 설정합니다.\n\n\n\nStep 3: Orientation Propagation (Meek’s Rules)\n\nV-structure로 밝혀진 방향들을 기반으로, 논리적으로 가능한 나머지 방향들을 확정합니다.\n이때 Meek’s Rules라고 불리는 4가지 규칙을 반복 적용합니다.\n이 규칙들은 Cycle을 생성하지 않고 새로운 V-structure를 만들지 않는다는 원칙하에 작동합니다.\n\n\nRule 1: Avoid New Collider\n\n상황: \\(A \\rightarrow B - C\\) 이고 \\(A, C\\)는 연결되지 않음.\n조치: \\(B \\rightarrow C\\) 로 방향 설정.\n이유: 만약 \\(C \\rightarrow B\\)라면 \\(A \\rightarrow B \\leftarrow C\\)가 되어 새로운 V-structure가 생기는데, 이는 Step 2에서 발견되지 않았으므로 모순입니다.\n\n\n\n\nFigure 5: Meek’s Rule 1. A-&gt;B-C 상황에서 B-&gt;C로 방향을 주지 않으면 새로운 Collider가 형성되므로 B-&gt;C로 강제한다.\n\n\n\n\nRule 2: Avoid Cycle\n\n상황: \\(A \\rightarrow C \\rightarrow B\\) (Chain)가 있고 \\(A - B\\)가 연결됨.\n조치: \\(A \\rightarrow B\\) 로 방향 설정.\n이유: 만약 \\(B \\rightarrow A\\)라면 \\(A \\rightarrow C \\rightarrow B \\rightarrow A\\)로 이어지는 Cycle이 형성되므로 불가능합니다.\n\n\n\n\nFigure 6: Meek’s Rule 2. A-&gt;C-&gt;B 경로가 존재할 때 A-B 엣지는 A-&gt;B여야 한다. 그렇지 않으면 Cycle이 발생한다.\n\n\n\n\nRule 3: Double Triangle\n\n상황: \\(A - C \\rightarrow B\\), \\(A - D \\rightarrow B\\)가 있고 \\(A - B\\)가 연결됨 (\\(C, D\\)는 비연결).\n조치: \\(A \\rightarrow B\\) 로 방향 설정.\n이유: 만약 \\(B \\rightarrow A\\)라면, Rule 1이나 Cycle 문제 등에 의해 \\(C, D\\)와의 관계에서 모순이 발생하여 Cycle이 형성됩니다.\n\n\n\n\nFigure 7: Meek’s Rule 3. B-&gt;A라고 가정하면 A가 Collider가 되거나 B-&gt;A-&gt;C 혹은 B-&gt;A-&gt;D Cycle이 발생하므로 모순이다. 따라서 A-&gt;B이다.\n\n\n\n\nRule 4: Complex Cycle\n\n상황: \\(A - C \\rightarrow D\\) 및 \\(C \\rightarrow D \\rightarrow B\\) 등의 복잡한 구조.\n조치: \\(A \\rightarrow B\\) 로 방향 설정.\n\n\n\n\nFigure 8: Meek’s Rule 4. B-&gt;A라고 가정하면 A는 Collider가 아니므로 A-&gt;C이다. 이때 Cycle이 발생하므로 모순이고, A-&gt;B이다."
  },
  {
    "objectID": "posts/lecture/L16/part-04/index.html",
    "href": "posts/lecture/L16/part-04/index.html",
    "title": "[Causal Inference] 16. Causal Discovery (Part 4)",
    "section": "",
    "text": "이전 포스트들에서 다룬 Constraint-based Approach (PC 알고리즘 등)는 데이터의 조건부 독립성(Conditional Independence) 검정을 통해 그래프를 깎아나가는 방식이었습니다.\n이 방법은 직관적이지만, 독립성 검정의 오류가 누적될 수 있고 데이터가 적을 때 불안정하다는 단점이 있습니다.\n이번 포스트에서는 완전히 다른 접근 방식인 Score-based Approach를 다룹니다.\n이 방법은 인과 구조 학습을 최적화 문제(Optimization Problem)로 바라봅니다.\n\nGoal: 데이터(\\(D\\))와 그래프 구조(\\(\\mathcal{G}\\))가 얼마나 잘 맞는지를 평가하는 Score Function을 정의하고,\nSearch: 이 점수를 최대화(혹은 최소화)하는 그래프 구조를 탐색합니다.\n\n또한, 이산적인 그래프 탐색의 한계를 극복하기 위해 최근 제안된 연속 최적화 기반의 NOTEARS 알고리즘까지 다뤄보겠습니다."
  },
  {
    "objectID": "posts/lecture/L16/part-04/index.html#the-concept-of-scoring",
    "href": "posts/lecture/L16/part-04/index.html#the-concept-of-scoring",
    "title": "[Causal Inference] 16. Causal Discovery (Part 4)",
    "section": "2.1 The Concept of Scoring",
    "text": "2.1 The Concept of Scoring\n\n데이터셋 \\(D\\)가 주어졌을 때, 각 후보 그래프 \\(\\mathcal{G}\\)에 대해 점수를 매깁니다.\n\n\n\n\nFigure 1: Score-based Learning의 직관. 여러 후보 그래프(DAG)들이 주어졌을 때, 데이터와 가장 잘 부합하는 그래프에 높은 점수를 부여하고 선택하는 과정을 보여준다.\n\n\n\nMissing Arcs: 실제 존재하는 인과관계를 놓치면 데이터의 패턴을 설명하지 못하므로 점수가 낮아져야 합니다.\nExtra Arcs: 불필요한 엣지를 추가하면 과적합(Overfitting)이 발생하므로 패널티를 받아야 합니다."
  },
  {
    "objectID": "posts/lecture/L16/part-04/index.html#likelihood-as-a-measure-of-fit",
    "href": "posts/lecture/L16/part-04/index.html#likelihood-as-a-measure-of-fit",
    "title": "[Causal Inference] 16. Causal Discovery (Part 4)",
    "section": "2.2 Likelihood as a Measure of Fit",
    "text": "2.2 Likelihood as a Measure of Fit\n가장 먼저 떠올릴 수 있는 점수는 우도(Likelihood)입니다. DAG 모델의 결합 확률 분포는 다음과 같이 분해(Factorization)됩니다.\n\\[P(\\mathbf{V}) = \\prod_{i=1}^{d} P(V_i \\mid Pa_{\\mathcal{G}}(V_i))\\]\n\n이에 대한 로그 우도(Log-Likelihood) 함수는 다음과 같습니다:\n\n\\[l(\\theta; D) = \\sum_{j=1}^{n} \\sum_{i=1}^{d} \\log P_{\\theta_i}(v_i^{(j)} \\mid pa_i^{(j)})\\]\n\n여기서 \\(n\\)은 샘플 수, \\(d\\)는 변수의 개수입니다.\n이 식은 각 변수별로 독립적으로 계산하여 합산할 수 있다는 Decomposable 특성을 가집니다."
  },
  {
    "objectID": "posts/lecture/L16/part-04/index.html#the-overfitting-problem",
    "href": "posts/lecture/L16/part-04/index.html#the-overfitting-problem",
    "title": "[Causal Inference] 16. Causal Discovery (Part 4)",
    "section": "3.1 The Overfitting Problem",
    "text": "3.1 The Overfitting Problem\n\n다음 두 그래프를 비교해 봅시다.\n\nTrue Graph (Left): \\(A \\rightarrow B \\leftarrow C\\) (V-structure). 여기서 \\(A \\perp\\!\\!\\!\\perp C\\)입니다.\n\n\nProposed Graph (Right): \\(A \\rightarrow B \\leftarrow C\\) 에 \\(A \\rightarrow C\\) 엣지가 추가된 완전 그래프(Fully connected).\n\n\n\n\n\nFigure 2: Likelihood 비교의 문제점. 왼쪽의 True Graph(Sparse)와 오른쪽의 Fully Connected Graph를 비교할 때, 오른쪽 그래프는 왼쪽 그래프의 모든 독립성 조건을 포함(Submodel)하므로 Likelihood는 항상 오른쪽이 더 높거나 같다.\n\n\n\n오른쪽 그래프(Complete Graph)는 왼쪽 그래프(True Graph)를 포함하는 Supermodel입니다. 즉, 파라미터 수가 더 많고 표현력이 더 큽니다.\n따라서 최대 우도 추정(MLE)을 수행하면, 항상 엣지가 많은 그래프의 우도가 더 높게 나옵니다.\n결국 Likelihood만을 점수로 사용하면 항상 완전 그래프(Complete Graph)가 선택되는 과적합 문제가 발생합니다."
  },
  {
    "objectID": "posts/lecture/L16/part-04/index.html#bayesian-information-criterion-bic",
    "href": "posts/lecture/L16/part-04/index.html#bayesian-information-criterion-bic",
    "title": "[Causal Inference] 16. Causal Discovery (Part 4)",
    "section": "3.2 Bayesian Information Criterion (BIC)",
    "text": "3.2 Bayesian Information Criterion (BIC)\n\n이 문제를 해결하기 위해 모델의 복잡도(파라미터 수)에 벌점(Penalty)을 부과하는 BIC 점수를 사용합니다. \\[BIC(\\mathcal{G}) = -2 \\cdot l(\\hat{\\theta}; D) + m \\cdot \\log(n)\\]\n\n\\(-2 \\cdot l(\\hat{\\theta}; D)\\): 데이터 적합도 (낮을수록 좋음, 즉 우도가 높을수록 좋음)\n\\(m\\): 그래프의 파라미터(엣지) 수\n\\(\\log(n)\\): 샘플 크기에 따른 가중치\n\nBIC는 낮을수록 좋은 점수입니다.\n\\(m \\cdot \\log(n)\\) 항이 일종의 정규화(Regularization) 역할을 하여 불필요한 엣지 추가를 억제합니다."
  },
  {
    "objectID": "posts/lecture/L16/part-04/index.html#search-space-markov-equivalence-class",
    "href": "posts/lecture/L16/part-04/index.html#search-space-markov-equivalence-class",
    "title": "[Causal Inference] 16. Causal Discovery (Part 4)",
    "section": "4.1 Search Space: Markov Equivalence Class",
    "text": "4.1 Search Space: Markov Equivalence Class\n\nGES의 가장 큰 특징은 개별 DAG가 아니라 Markov Equivalence Class (MEC) 단위로 탐색을 수행한다는 점입니다.\n이는 통계적으로 구별 불가능한 그래프들을 묶어서 처리함으로써 탐색 효율을 높입니다."
  },
  {
    "objectID": "posts/lecture/L16/part-04/index.html#algorithm-steps",
    "href": "posts/lecture/L16/part-04/index.html#algorithm-steps",
    "title": "[Causal Inference] 16. Causal Discovery (Part 4)",
    "section": "4.2 Algorithm Steps",
    "text": "4.2 Algorithm Steps\n\nGES는 크게 두 단계로 구성됩니다.\n\n\nPhase 1: Forward Equivalence Search (Addition)\n\n시작: 엣지가 하나도 없는 그래프(Empty Graph)에서 시작합니다.\n동작: 현재 상태에서 엣지를 하나 추가하여 만들 수 있는 모든 Equivalence Class 중, BIC 점수를 가장 많이 개선(감소)시키는 클래스로 이동합니다.\n종료: 더 이상 점수가 개선되지 않을 때까지 반복합니다.\n\n\n\nPhase 2: Backward Equivalence Search (Removal)\n\n시작: Phase 1에서 얻은 그래프에서 시작합니다.\n동작: 현재 상태에서 엣지를 하나 제거하여 만들 수 있는 클래스 중, 점수를 가장 많이 개선시키는 곳으로 이동합니다.\n종료: 점수 개선이 멈추면 종료하고 최종 클래스를 반환합니다."
  },
  {
    "objectID": "posts/lecture/L16/part-04/index.html#understanding-the-move",
    "href": "posts/lecture/L16/part-04/index.html#understanding-the-move",
    "title": "[Causal Inference] 16. Causal Discovery (Part 4)",
    "section": "4.3 Understanding the Move",
    "text": "4.3 Understanding the Move\n\n“엣지를 추가한다”는 것은 단순히 선을 긋는 것보다 복잡합니다.\n시작 DAG에 따라 도착하는 Equivalence Class가 달라질 수 있기 때문입니다.\n\n\n예시:\n\n현재 상태가 \\(\\{A \\rightarrow B, C\\}\\) (엣지 \\(A-B\\)만 존재)라고 합시다.\n여기에 \\(C\\)와 \\(B\\)를 연결하는 엣지를 추가한다고 할 때:\n\n\n\\(A \\rightarrow B \\leftarrow C\\) (V-structure) 클래스로 이동할 수도 있고,\n\n\n\\(\\{A \\leftarrow B \\leftarrow C, A \\rightarrow B \\rightarrow C, \\dots\\}\\) 와 같은 Non-collider 클래스로 이동할 수도 있습니다."
  },
  {
    "objectID": "posts/lecture/L16/part-04/index.html#theoretical-guarantee",
    "href": "posts/lecture/L16/part-04/index.html#theoretical-guarantee",
    "title": "[Causal Inference] 16. Causal Discovery (Part 4)",
    "section": "4.4 Theoretical Guarantee",
    "text": "4.4 Theoretical Guarantee\n\nChickering (2002)은 데이터가 무한히 많아지면(\\(n \\rightarrow \\infty\\)) GES가 True Equivalence Class를 정확하게 찾아냄(Consistent)을 증명했습니다."
  },
  {
    "objectID": "posts/lecture/L16/part-04/index.html#formulation",
    "href": "posts/lecture/L16/part-04/index.html#formulation",
    "title": "[Causal Inference] 16. Causal Discovery (Part 4)",
    "section": "5.1 Formulation",
    "text": "5.1 Formulation\n\n목표는 데이터 \\(X\\)를 선형 변환 \\(W\\)로 설명하는 것입니다 (\\(X \\approx XW\\)).\n여기서 \\(W\\)는 인접 행렬(Adjacency Matrix) 역할을 합니다.\n기존의 문제는 다음과 같습니다: \\[\\min_{W} \\ell(W; X) + \\lambda \\|W\\|_1 \\quad \\text{subject to } W \\in \\text{DAGs}\\]\nDAG 제약조건은 이산적이라 미분이 불가능했습니다."
  },
  {
    "objectID": "posts/lecture/L16/part-04/index.html#the-trace-constraint",
    "href": "posts/lecture/L16/part-04/index.html#the-trace-constraint",
    "title": "[Causal Inference] 16. Causal Discovery (Part 4)",
    "section": "5.2 The Trace Constraint",
    "text": "5.2 The Trace Constraint\n\nNOTEARS의 핵심 기여는 DAG 제약조건을 미분 가능한 등식 제약조건으로 바꾼 것입니다. \\[\\text{Subject to: } h(W) = \\text{tr}(e^{W \\circ W}) - d = 0\\]\n\\(W \\circ W\\): 행렬의 원소별 제곱(Hadamard product)을 통해 음수 가중치도 양수로 처리합니다.\n\\(e^A\\): 행렬 지수 함수 (Matrix Exponential) \\(e^A = I + A + \\frac{A^2}{2!} + \\dots\\)\n직관:\n\n인접 행렬 \\(A\\)의 \\(k\\)승(\\(A^k\\))의 대각 성분(trace)은 길이가 \\(k\\)인 사이클(Cycle)의 개수와 관련이 있습니다.\n만약 그래프가 DAG라면 어떠한 길이의 사이클도 없어야 하므로, 모든 \\(k\\)에 대해 trace가 0이어야 합니다 (대각 성분이 0).\n\n이 식은 \\(W\\)가 DAG일 때만 정확히 0이 되고, 사이클이 있으면 양수가 됩니다.\n\n\n5.3 Final Optimization Problem\n\n이제 문제는 표준적인 제약 최적화 문제가 됩니다.\n\n\\[\\min_{W \\in \\mathbb{R}^{d \\times d}} \\frac{1}{2n} \\|X - XW\\|_F^2 + \\lambda \\|W\\|_1\\] \\[\\text{subject to } \\text{tr}(e^{W \\circ W}) - d = 0\\]\n\n이 문제는 Augmented Lagrangian Method 등의 일반적인 최적화 기법을 사용하여 효율적으로 풀 수 있습니다.\n\n\n\n\nFigure 3: NOTEARS의 아이디어. 이산적인 그래프 공간을 탐색하는 대신, 연속적인 가중치 행렬 W 공간에서 Loss를 최소화하며, Trace 제약조건을 통해 Cycle이 없는 방향으로 최적화를 수행한다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html",
    "href": "posts/lecture/L16/part-06/index.html",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "",
    "text": "시계열 데이터(Time Series Data)는 유전체학(mRNA 발현), 신경심리학(fMRI 신호), 금융, 기상학 등 수많은 과학적 탐구의 기반이 됩니다. 인과추론(Causal Inference) 관점에서 시계열 데이터는 “원인은 결과보다 시간적으로 선행한다(Temporal Precedence)”는 강력한 단서를 제공하기 때문에 매력적입니다.\n하지만 동시에 시계열 데이터는 다음과 같은 고유한 난제들을 안고 있습니다.\n\nTime lags & Spurious Associations: 시차(Time lag)가 존재하며, 과거의 변수들이 현재의 여러 변수에 동시에 영향을 미칠 때 허위 상관(Spurious Association)이 발생하기 쉽습니다.\nSampling Rate: 실제 인과 과정보다 데이터 수집 속도가 느릴 경우, 인과 관계가 왜곡되어 보일 수 있습니다.\nNon-stationarity: 데이터의 분포나 인과 구조 자체가 시간에 따라 변할 수 있습니다.\n\n\n\n\nFigure: 시계열 인과 구조와 허위 상관의 예시. X1, X2, X3, X4가 시간 축을 따라 전개될 때, 검은색 화살표(Causal links)는 실제 인과관계를 나타내며, 회색 점선 화살표(Spurious associations)는 공통된 과거 원인 등에 의해 관측되는 허위 상관을 의미한다.\n\n\n이번 포스트에서는 시계열 데이터에서 인과 구조를 발견(Causal Discovery)하는 대표적인 방법론인 Granger Causality, PCMCI, TiMINo, 그리고 DYNOTEARS에 대해 심도 있게 다룹니다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#definition-and-intuition",
    "href": "posts/lecture/L16/part-06/index.html#definition-and-intuition",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "2.1. Definition and Intuition",
    "text": "2.1. Definition and Intuition\nGranger Causality는 시계열 인과추론의 가장 고전적이고 기초적인 개념입니다. Clive Granger는 인과성을 예측 가능성(Predictability)의 관점에서 정의했습니다.\n\nGranger Causality의 정의: 어떤 시계열 \\(X\\)의 과거 정보를 포함했을 때, \\(Y\\)의 미래를 예측하는 오차(Prediction Error)가 줄어든다면, \\(X\\)는 \\(Y\\)를 “Granger-cause” 한다고 말합니다.\n\n수식으로 엄밀하게 정의하면 다음과 같습니다. 전체 정보 집합 \\(V = \\{X, Y\\} \\cup Z\\)에 대하여, 다음 조건이 성립하면 \\(X\\)는 \\(Y\\)에 대해 Granger Non-causal입니다.\n\\[\nY_{t+1} \\perp\\!\\!\\perp X^t \\mid Y^t, Z^t\n\\]\n여기서 \\(X^t = \\{X_1, X_2, \\dots, X_t\\}\\)는 시점 \\(t\\)까지의 \\(X\\)의 모든 과거 정보를 의미합니다. 즉, \\(Y\\)와 \\(Z\\)의 과거를 모두 알고 있는 상태에서 \\(X\\)의 과거 정보가 \\(Y_{t+1}\\)의 확률 분포에 아무런 추가 정보를 주지 못한다면 인과관계가 없다고 봅니다. 반대의 경우, \\(X\\)는 \\(Y\\)를 Granger-cause 한다고 합니다.\n\n\n\nFigure: Granger Causality의 기본 아이디어 도식. N과 B라는 두 시계열이 있을 때, 과거의 N값들이 현재의 B값을 설명하는 데 유의미한지, 혹은 그 반대인지를 시차(Lag)를 고려하여 파악하는 구조를 보여준다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#vector-autoregressive-var-models",
    "href": "posts/lecture/L16/part-06/index.html#vector-autoregressive-var-models",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "2.2. Vector Autoregressive (VAR) Models",
    "text": "2.2. Vector Autoregressive (VAR) Models\n실증 분석에서 Granger Causality는 주로 벡터 자기회귀(Vector Autoregressive, VAR) 모형을 통해 검정됩니다.\n\\(p\\)차 VAR 모형, 즉 \\(VAR(p)\\)는 다음과 같이 표현됩니다.\n\nUnivariate Case\n\\[\nX_t = c + A_1 X_{t-1} + A_2 X_{t-2} + \\dots + A_p X_{t-p} + e_t\n\\]\n\n\nMultivariate Case\n다변량 시계열 \\(X_t = (X_{1,t}, \\dots, X_{d,t})^T\\)에 대하여: \\[\nX_{j,t} = \\sum_{u=1}^{\\infty} \\sum_{k=1}^{d} A_{jk,u} X_{k, t-u} + \\epsilon_{j,t}\n\\]\n여기서 \\(A_{jk,u}\\)는 시차 \\(u\\)에서 변수 \\(k\\)가 변수 \\(j\\)에 미치는 영향력을 나타내는 계수입니다.\n\n\nTesting for Causality\nVAR 모형에서 \\(X_i\\)가 \\(X_j\\)를 Granger-cause 하지 않는다는 조건은 다음과 동치입니다.\n\\[\nA_{ji, u} = 0 \\quad \\text{for all lags } u &gt; 0\n\\]\n즉, \\(X_j\\)를 예측하는 식에서 \\(X_i\\)의 모든 과거 항들의 계수가 0이어야 합니다. 이는 \\(X_j\\)를 전체 과거 정보 \\(X^{t-1}\\)로 예측했을 때의 평균제곱오차(MSE)와, \\(X_i\\)를 제외한 정보 \\(X_{-i}^{t-1}\\)로 예측했을 때의 MSE를 비교하여 검정할 수 있습니다.\n\\[\n\\text{var}(X_{j,t} \\mid X^{t-1}) = \\text{var}(X_{j,t} \\mid X_{-i}^{t-1})\n\\]\n\n\n\n\n\n\nWarning\n\n\n\n주의사항: Granger Causality는 “인과(Causality)”라는 용어를 사용하지만, 근본적으로는 예측 유용성에 관한 개념입니다. 잠재 변수(Confounder)가 존재하거나 시간 집계(Temporal aggregation)가 발생할 경우, 실제 인과관계와 다른 결론을 낼 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#motivation",
    "href": "posts/lecture/L16/part-06/index.html#motivation",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "3.1. Motivation",
    "text": "3.1. Motivation\n전통적인 PC 알고리즘(Peter-Clark algorithm)을 시계열에 그대로 적용하면 문제가 발생합니다. 변수의 수가 많고 시차(Lag)가 길어지면 조건부 독립성 검정(Conditional Independence Test)을 수행해야 할 조건부 집합(Conditioning set)의 크기가 지나치게 커집니다. 이는 통계적 검정력(Power)을 떨어뜨리고, 결과적으로 False Positives(잘못된 인과 발견)를 양산합니다.\nPCMCI 알고리즘은 조건부 집합을 최적화하여 검정력은 높이고 False Discovery Rate는 제어하기 위해 고안되었습니다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#two-stage-algorithm",
    "href": "posts/lecture/L16/part-06/index.html#two-stage-algorithm",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "3.2. Two-Stage Algorithm",
    "text": "3.2. Two-Stage Algorithm\nPCMCI는 이름에서 알 수 있듯이 PC 단계(\\(PC_1\\))와 MCI(Momentary Conditional Independence) 단계로 구성됩니다.\n\nStep 1: \\(PC_1\\) Stage (Parent Selection)\n이 단계의 목표는 각 변수 \\(X_t^j\\)에 대한 잠정적인 부모 집합(Superset of parents) \\(\\hat{Pa}(X_t^j)\\)를 찾는 것입니다. * 표준 PC 알고리즘의 변형을 사용하되, 인접성(Adjacency)만 파악합니다. * 모든 가능한 분리 집합(Separator)을 테스트하는 대신, 상관관계가 가장 강한 \\(k\\)개의 변수만을 조건부로 사용하여 효율성을 높입니다. * 이 단계가 끝나면 실제 부모 변수들이 포함되지만, 일부 허위 부모(Spurious parents)들도 포함되어 있을 수 있습니다.\n\n\nStep 2: MCI Stage (Refining)\n\\(PC_1\\) 단계에서 구한 잠정적 부모 집합을 이용하여, 정밀한 조건부 독립성 검정을 수행합니다. 이를 Momentary Conditional Independence (MCI) 검정이라고 합니다.\n검정하고자 하는 관계가 \\(X_{t-\\tau}^i \\to X_t^j\\)일 때, 다음의 조건부 독립성을 검정합니다.\n\\[\nX_t^j \\perp\\!\\!\\perp X_{t-\\tau}^i \\mid \\hat{Pa}(X_t^j) \\setminus \\{X_{t-\\tau}^i\\}, \\hat{Pa}(X_{t-\\tau}^i)\n\\]\n여기서 주목할 점은 조건부 집합에 \\(X_t^j\\)의 부모뿐만 아니라 원인 변수인 \\(X_{t-\\tau}^i\\)의 부모 \\(\\hat{Pa}(X_{t-\\tau}^i)\\)까지 포함시킨다는 것입니다. 이는 시계열 데이터의 자기상관(Autocorrelation)으로 인한 허위 발견을 억제하는 데 핵심적인 역할을 합니다.\n\n\n\nFigure: PCMCI의 MCI 단계 도식. X^j_t에 대한 인과를 검정할 때, 단순히 X^j의 과거값만 조건부로 거는 것이 아니라, 잠재적 원인 변수인 X^i_{t-tau}의 부모 변수들까지 함께 조건부로 걸어줌으로써(Double Conditioning) 시계열의 자기상관 효과를 제거하는 과정을 보여준다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#algorithm-detail",
    "href": "posts/lecture/L16/part-06/index.html#algorithm-detail",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "3.3. Algorithm Detail",
    "text": "3.3. Algorithm Detail\nMCI 단계에서의 구체적인 절차는 다음과 같습니다.\n\n모든 \\(i, j\\)와 시차 \\(\\tau\\)에 대해 \\(X_{t-\\tau}^i\\)가 \\(X_t^j\\)의 잠정 부모 집합 \\(\\hat{Pa}(X_t^j)\\)에 속하는지 확인합니다.\n속한다면, MCI 조건부 독립성 검정을 수행하여 p-value를 계산합니다.\np-value가 유의수준 \\(\\alpha\\)보다 크다면(독립이라면), \\(X_{t-\\tau}^i\\)를 부모 집합에서 제거합니다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#key-idea-independent-noise",
    "href": "posts/lecture/L16/part-06/index.html#key-idea-independent-noise",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "4.1. Key Idea: Independent Noise",
    "text": "4.1. Key Idea: Independent Noise\nGranger Causality나 PC 알고리즘은 주로 조건부 독립성에 의존하지만, TiMINo (Time Series Models with Independent Noise)는 함수적 인과 모형(Functional Causal Model)의 구조적 가정을 활용합니다.\n핵심 아이디어는 “올바른 인과 방향으로 모델을 적합(Fit)했을 때만 잔차(Residual)가 독립적인 노이즈가 된다”는 것입니다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#timino-definition",
    "href": "posts/lecture/L16/part-06/index.html#timino-definition",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "4.2. TiMINo Definition",
    "text": "4.2. TiMINo Definition\n시계열 \\(X_t = (X_t^i)_{i \\in V}\\)가 TiMINo를 만족한다는 것은, 각 변수 \\(X_t^i\\)가 자신의 부모 변수들의 함수와 독립적인 노이즈의 결합으로 표현됨을 의미합니다.\n\\[\nX_t^i = f_i \\left( (Pa_p^i)_{t-p}, \\dots, (Pa_0^i)_t, N_t^i \\right)\n\\]\n여기서 \\(N_t^i\\)는 모든 \\(i\\)와 \\(t\\)에 대해 결합 독립(Jointly Independent)입니다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#timino-theorem-algorithm",
    "href": "posts/lecture/L16/part-06/index.html#timino-theorem-algorithm",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "4.3. TiMINo Theorem & Algorithm",
    "text": "4.3. TiMINo Theorem & Algorithm\nPeters et al.은 함수 \\(f_i\\)가 식별 가능한 함수 클래스(예: Linear non-Gaussian, Additive Noise Model 등)에 속하거나 시간 구조가 명확할 때, 전체 인과 그래프(Full Time Graph)를 복원할 수 있음을 증명했습니다.\n알고리즘은 다음과 같은 절차를 따릅니다 (Counter-intuitive하지만 효과적임):\n\n모든 변수 \\(k \\in S\\)에 대해, 나머지 변수들을 입력으로 하는 TiMINo 모델을 적합합니다.\n잔차(Residual)가 입력 변수들과 독립인지 검정합니다.\n가장 의존성이 약한(Weakest dependence), 즉 독립성 가정에 가장 가까운 변수 \\(k^*\\)를 선택합니다. (이 변수는 인과 구조상 가장 하위(Sink)에 위치할 가능성이 높습니다.)\n\\(k^*\\)를 집합 \\(S\\)에서 제거하고, 순서(Order)를 기록합니다.\n이 과정을 반복하여 변수들의 위상학적 순서(Topological Order)를 찾고, 불필요한 부모를 제거(Pruning)합니다.\n\n논문에서는 모델 \\(f_i\\)로 GAM(Generalized Additive Model), Gaussian Processes 등을 고려했으며, 선형 모형을 사용할 경우 TS-LiNGAM은 TiMINo의 특수한 형태가 됩니다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#from-notears-to-dynotears",
    "href": "posts/lecture/L16/part-06/index.html#from-notears-to-dynotears",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "5.1. From NOTEARS to DYNOTEARS",
    "text": "5.1. From NOTEARS to DYNOTEARS\nNOTEARS는 인과 구조 학습(Structure Learning)을 조합 최적화 문제(Combinatorial Optimization)가 아닌 연속 최적화 문제(Continuous Optimization)로 변환하여 획기적인 발전을 이룬 알고리즘입니다. DYNOTEARS는 이를 시계열 데이터로 확장한 버전입니다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#structural-vector-autoregression-svar",
    "href": "posts/lecture/L16/part-06/index.html#structural-vector-autoregression-svar",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "5.2. Structural Vector Autoregression (SVAR)",
    "text": "5.2. Structural Vector Autoregression (SVAR)\nDYNOTEARS는 구조적 벡터 자기회귀(SVAR) 모형을 가정합니다. \\(Y_1, \\dots, Y_p\\)를 \\(X\\)의 시차(Lagged) 버전 데이터라고 할 때:\n\\[\nX = XW + Y_1 A_1 + \\dots + Y_p A_p + Z\n\\]\n\n\\(W\\): 동시간대(Contemporaneous) 인과 관계 행렬 (Acyclicity 제약 필요)\n\\(A_k\\): 시차 \\(k\\)에서의 인과 관계 행렬 (제약 없음)\n\\(Z\\): 노이즈"
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#optimization-problem",
    "href": "posts/lecture/L16/part-06/index.html#optimization-problem",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "5.3. Optimization Problem",
    "text": "5.3. Optimization Problem\n목표는 데이터 적합도(Data fidelity)를 높이면서, \\(W\\)가 DAG(Directed Acyclic Graph) 조건을 만족하도록 하는 \\(W\\)와 \\(A\\)를 찾는 것입니다.\n\\[\n\\min_{W, A} F(W, A) = \\underbrace{l(W, A)}_{\\text{Loss}} + \\underbrace{\\lambda_W \\|W\\|_1 + \\lambda_A \\|A\\|_1}_{\\text{Sparsity}} + \\underbrace{\\frac{\\rho}{2} h(W)^2 + \\alpha h(W)}_{\\text{Augmented Lagrangian for Acyclicity}}\n\\]\n\nLoss Function: \\(l(W, A) = \\frac{1}{2n} \\| X - XW - YA \\|_F^2\\) (Frobenius norm, 최소제곱오차)\nAcyclicity Constraint: \\(h(W) = \\text{tr}(e^{W \\circ W}) - d = 0\\). 이 값이 0이면 \\(W\\)는 사이클이 없는 그래프입니다.\n\nDYNOTEARS는 시차 데이터(\\(Y\\))를 포함하되, 비순환성(Acyclicity) 제약은 동시간대 행렬 \\(W\\)에만 적용한다는 점이 핵심입니다 (과거가 현재에 영향을 주는 것은 사이클이 아니기 때문입니다)."
  },
  {
    "objectID": "posts/lecture/L11/part-02/index.html",
    "href": "posts/lecture/L11/part-02/index.html",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 2)",
    "section": "",
    "text": "[cite_start]인과 추론의 핵심 목표는 교란 변수(Confounding, \\(Z\\))의 영향을 제거하여 처치(\\(X\\))와 결과(\\(Y\\)) 사이의 인과관계를 밝혀내는 것입니다[cite: 241]. 이를 위해 우리는 지금까지 두 가지 주요 접근법을 배웠습니다.\n\n[cite_start]Outcome Regression (OR): 결과 변수와 공변량의 관계(\\(Y \\sim Z\\))를 모델링하는 방법[cite: 242].\n[cite_start]Propensity Score Weighting (IPW): 처치 변수와 공변량의 관계(\\(X \\sim Z\\))를 모델링하는 방법[cite: 243].\n\n각각의 방법은 강력하지만 치명적인 약점이 있습니다. 모델이 잘못 설정(Misspecification)되면 추정 결과에 편향(Bias)이 발생한다는 점입니다. 그렇다면, 이 두 방법을 결합하여 둘 중 하나만이라도 맞으면 올바른 결과를 얻을 수 있는 방법은 없을까요? [cite_start]이것이 바로 Doubly Robust (DR) Estimation의 핵심 아이디어입니다[cite: 243, 271].\n Figure 1: Doubly Robust Estimation은 Outcome Regression 모델과 Propensity Score 모델을 결합합니다. 두 모델 중 하나만 정확하게 명시(Correctly Specified)되어도 ATE(Average Treatment Effect)를 일관성 있게(Consistently) 추정할 수 있음을 보여줍니다."
  },
  {
    "objectID": "posts/lecture/L11/part-02/index.html#outcome-regression-or-estimator",
    "href": "posts/lecture/L11/part-02/index.html#outcome-regression-or-estimator",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 2)",
    "section": "2.1. Outcome Regression (OR) Estimator",
    "text": "2.1. Outcome Regression (OR) Estimator\n[cite_start]잠재적 결과(Potential Outcomes)의 실제 평균 모델을 \\(m_x(Z) = \\mathbb{E}(Y(x)|Z)\\)라고 정의합니다[cite: 247]. 회귀 분석 등을 통해 이를 추정한 값을 \\(\\hat{m}_x(Z)\\)라고 할 때, ATE에 대한 OR 추정량 \\(\\hat{\\tau}_{adj}\\)는 다음과 같습니다.\n\\[\n\\hat{\\tau}_{adj} = \\frac{1}{N} \\sum_{i=1}^{N} \\{ \\hat{m}_1(Z_i) - \\hat{m}_0(Z_i) \\}\n\\]\n[cite_start]또는 관측된 데이터를 활용하여 다음과 같이 표현할 수도 있습니다(Imputation 관점)[cite: 252].\n\\[\n\\hat{\\tau}_{adj} = \\frac{1}{N} \\sum_{i=1}^{N} \\left\\{ X_i(Y_i - \\hat{m}_0(Z_i)) + (1-X_i)(\\hat{m}_1(Z_i) - Y_i) \\right\\}\n\\]\n[cite_start]만약 회귀 모델 \\(\\hat{m}_x(Z)\\)가 참(True)이라면, 이 추정량은 일치 추정량(Consistent)이며 효율적(Efficient)입니다[cite: 256]."
  },
  {
    "objectID": "posts/lecture/L11/part-02/index.html#ipw-estimator",
    "href": "posts/lecture/L11/part-02/index.html#ipw-estimator",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 2)",
    "section": "2.2. IPW Estimator",
    "text": "2.2. IPW Estimator\n[cite_start]성향 점수(Propensity Score) \\(e(Z) = P(X=1|Z)\\)를 추정한 값을 \\(\\hat{e}(Z)\\)라고 할 때, IPW 추정량은 다음과 같습니다[cite: 262].\n\\[\n\\hat{\\tau}_{ipw} = \\sum_{i=1}^{N} \\frac{Y_i X_i}{\\hat{e}(Z_i)} - \\sum_{i=1}^{N} \\frac{Y_i (1-X_i)}{1-\\hat{e}(Z_i)}\n\\]\n[cite_start]성향 점수 모델이 참이라면 일치 추정량이지만, 가중치의 분산 문제로 인해 비효율적일 수 있습니다[cite: 263]."
  },
  {
    "objectID": "posts/lecture/L11/part-02/index.html#expectation-analysis",
    "href": "posts/lecture/L11/part-02/index.html#expectation-analysis",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 2)",
    "section": "4.1. Expectation Analysis",
    "text": "4.1. Expectation Analysis\n[cite_start]대표본(Large Sample)에서 표본 평균을 기댓값으로 대체하고 정리하면 다음과 같습니다[cite: 333, 339].\n\\[\n\\begin{aligned}\n\\mathbb{E}[\\hat{\\mu}_{1,dr}] &= \\mathbb{E} \\left[ \\frac{XY}{e(Z)} - \\frac{X-e(Z)}{e(Z)}m_1(Z) \\right] \\\\\n&= \\mathbb{E} \\left[ \\frac{X Y(1)}{e(Z)} \\right] - \\mathbb{E} \\left[ \\frac{X-e(Z)}{e(Z)} m_1(Z) \\right] \\\\\n&= \\mathbb{E}[Y(1)] + \\underbrace{\\mathbb{E} \\left[ \\frac{X-e(Z)}{e(Z)} \\{ Y(1) - m_1(Z) \\} \\right]}_{\\text{Error Term } R}\n\\end{aligned}\n\\]\n위 식에서 첫 번째 항은 우리가 원하는 참값 \\(\\mathbb{E}[Y(1)]\\)이 되고, 두 번째 항은 오차항(Error Term) \\(R\\)이 됩니다. Doubly Robust 성질이 성립하려면, 두 가지 시나리오 중 하나라도 만족할 때 \\(R=0\\)이 되어야 합니다."
  },
  {
    "objectID": "posts/lecture/L11/part-02/index.html#scenario-1-ps-incorrect-or-correct",
    "href": "posts/lecture/L11/part-02/index.html#scenario-1-ps-incorrect-or-correct",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 2)",
    "section": "4.2. Scenario 1: PS Incorrect, OR Correct",
    "text": "4.2. Scenario 1: PS Incorrect, OR Correct\n[cite_start]가정: 성향 점수 모델 \\(e(Z)\\)는 틀렸지만(\\(e(Z) \\neq e_{true}(Z)\\)), 결과 회귀 모델 \\(m_1(Z)\\)는 정확하다(\\(m_1(Z) = m_{1,true}(Z)\\))[cite: 347].\n반복 기댓값의 법칙(Law of Iterated Expectations)을 사용하여 \\(Z\\)에 대해 조건부 기댓값을 취합니다.\n\\[\n\\begin{aligned}\nR &= \\mathbb{E} \\left[ \\mathbb{E} \\left\\{ \\frac{X-e(Z)}{e(Z)} \\{ Y(1) - m_1(Z) \\} \\Bigg| Z \\right\\} \\right] \\\\\n&= \\mathbb{E} \\left[ \\frac{e_{true}(Z) - e(Z)}{e(Z)} \\underbrace{\\mathbb{E} \\{ Y(1) - m_1(Z) | Z \\}}_{(*)} \\right]\n\\end{aligned}\n\\]\n[cite_start]여기서 \\((*)\\) 부분을 보면, \\(m_1(Z)\\)가 정확한 모델(True Outcome Model)이므로 \\(\\mathbb{E}[Y(1)|Z] - m_{1,true}(Z) = 0\\)이 됩니다[cite: 349, 350]. 따라서 \\(R = 0\\) 입니다."
  },
  {
    "objectID": "posts/lecture/L11/part-02/index.html#scenario-2-ps-correct-or-incorrect",
    "href": "posts/lecture/L11/part-02/index.html#scenario-2-ps-correct-or-incorrect",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 2)",
    "section": "4.3. Scenario 2: PS Correct, OR Incorrect",
    "text": "4.3. Scenario 2: PS Correct, OR Incorrect\n[cite_start]가정: 성향 점수 모델 \\(e(Z)\\)는 정확하지만(\\(e(Z) = e_{true}(Z)\\)), 결과 회귀 모델 \\(m_1(Z)\\)는 틀렸다(\\(m_1(Z) \\neq m_{1,true}(Z)\\))[cite: 354].\n다시 반복 기댓값의 법칙을 적용합니다.\n\\[\n\\begin{aligned}\nR &= \\mathbb{E} \\left[ \\mathbb{E} \\left\\{ \\frac{X-e(Z)}{e(Z)} \\{ Y(1) - m_1(Z) \\} \\Bigg| Z \\right\\} \\right] \\\\\n&= \\mathbb{E} \\left[ \\frac{\\{ Y(1) - m_1(Z) \\}}{e(Z)} \\underbrace{\\mathbb{E} \\{ X - e(Z) | Z \\}}_{(**)} \\right]\n\\end{aligned}\n\\]\n[cite_start]여기서 \\((**)\\) 부분을 보면, \\(e(Z)\\)가 정확한 모델(True Propensity Score)이므로 \\(\\mathbb{E}[X|Z] - e_{true}(Z) = 0\\)이 됩니다[cite: 356]. 따라서 \\(R = 0\\) 입니다."
  },
  {
    "objectID": "posts/lecture/L11/part-02/index.html#conclusion",
    "href": "posts/lecture/L11/part-02/index.html#conclusion",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 2)",
    "section": "4.4. Conclusion",
    "text": "4.4. Conclusion\n두 시나리오 모두에서 오차항 \\(R\\)은 0으로 수렴합니다. [cite_start]즉, PS 모델이나 OR 모델 중 하나만이라도 맞으면 \\(\\hat{\\tau}_{dr}\\)은 ATE에 대한 일치 추정량(Consistent Estimator)이 됩니다[cite: 359, 360, 364]."
  },
  {
    "objectID": "posts/lecture/L11/part-02/index.html#advantages",
    "href": "posts/lecture/L11/part-02/index.html#advantages",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 2)",
    "section": "5.1. Advantages",
    "text": "5.1. Advantages\n\n[cite_start]Model Misspecification에 대한 보호: 분석가에게 “두 번의 기회(Double chances to get it right)”를 제공합니다[cite: 366].\n[cite_start]Efficiency: 두 모델이 모두 정확하다면, DR 추정량은 단순 IPW 추정량보다 분산이 작습니다(More efficient)[cite: 367]."
  },
  {
    "objectID": "posts/lecture/L11/part-02/index.html#limitations-warnings",
    "href": "posts/lecture/L11/part-02/index.html#limitations-warnings",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 2)",
    "section": "5.2. Limitations & Warnings",
    "text": "5.2. Limitations & Warnings\n\n[cite_start]Large Sample Property: DR의 성질은 표본이 충분히 클 때(Asymptotic) 성립합니다[cite: 365].\nVariance Trade-off: 만약 Outcome Regression 모델이 완벽하게 맞다면, DR 추정량은 단순 OR 추정량보다 분산이 큽니다. [cite_start]불필요한 가중치 보정이 노이즈를 추가하기 때문입니다[cite: 368].\nKang and Schafer (2007)의 경고: 실제 상황에서 두 모델이 모두 “적당히” 틀린 경우(Moderate Misspecification), DR 추정량의 편향과 분산이 오히려 매우 커질 수 있습니다. [cite_start]경험적으로는 Outcome Model의 정확도가 PS Model보다 더 중요한 역할을 하는 경향이 있습니다[cite: 371, 372, 375]."
  },
  {
    "objectID": "posts/lecture/L11/part-01/index.html",
    "href": "posts/lecture/L11/part-01/index.html",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 1)",
    "section": "",
    "text": "인과 추론(Causal Inference)에서 관측 연구(Observational Study)의 가장 큰 난관은 교란 변수(Confounder)에 의한 선택 편향(Selection Bias)입니다. 이를 해결하기 위해 우리는 앞서 Back-door criterion 등을 배웠지만, 실제 데이터에서 이를 추정(Estimation)하는 것은 또 다른 문제입니다.\n이번 포스트에서는 Propensity Score(성향 점수)를 활용한 대표적인 추정 방법인 IPW(Inverse Probability Weighting)에 대해 다룹니다. [cite_start]IPW의 이론적 배경부터 수식 유도, 그리고 실제 적용 시 발생하는 분산 문제를 해결하기 위한 Hajek Estimator와 Trimming 기법, 더 나아가 최신 논의인 Balancing Weight까지 폭넓게 정리합니다[cite: 1, 8]."
  },
  {
    "objectID": "posts/lecture/L11/part-01/index.html#definition",
    "href": "posts/lecture/L11/part-01/index.html#definition",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 1)",
    "section": "2.1. Definition",
    "text": "2.1. Definition\n[cite_start]Propensity Score(성향 점수)는 공변량(Covariates) \\(Z\\)가 주어졌을 때, 개체가 처치(Treatment, \\(X=1\\))를 받을 조건부 확률로 정의됩니다[cite: 9].\n\\[\ne(Z) = P(X=1 | Z) = \\mathbb{E}[X | Z]\n\\]\n[cite_start]여기서 \\(Z = (Z_1, ..., Z_p)\\)는 관측된 \\(p\\)개의 공변량 집합입니다[cite: 11]. [cite_start]성향 점수는 고차원의 공변량 \\(Z\\)를 1차원의 확률 값으로 요약(Summary score)한 것으로 볼 수 있습니다[cite: 64].\n Figure 1: 공변량 벡터 \\(Z\\)가 처치 여부 \\(X\\)를 결정하는 확률적 과정을 나타냅니다. \\(e(Z)\\)는 이 복잡한 관계를 단일 스칼라 값인 확률로 축소합니다."
  },
  {
    "objectID": "posts/lecture/L11/part-01/index.html#key-properties",
    "href": "posts/lecture/L11/part-01/index.html#key-properties",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 1)",
    "section": "2.2. Key Properties",
    "text": "2.2. Key Properties\nRosenbaum and Rubin (1983)은 Propensity Score가 가진 두 가지 중요한 성질을 증명했습니다.\n\nProperty 1: Balancing Property\n성향 점수 \\(e(Z)\\)가 같다면, 처치 집단(\\(X=1\\))과 대조 집단(\\(X=0\\)) 사이에서 공변량 \\(Z\\)의 분포는 균형을 이룹니다. [cite_start]즉, 성향 점수를 조건부로 하면 처치 변수 \\(X\\)와 공변량 \\(Z\\)는 독립입니다[cite: 19, 20].\n\\[\nX \\perp\\!\\!\\perp Z \\mid e(Z)\n\\]\n[cite_start]이 성질은 성향 점수가 가장 거친(coarsest) Balancing Score임을 의미합니다[cite: 58]. \\(Z\\) 자체도 Balancing Score이지만(\\(X \\perp Z | Z\\)는 자명하므로), 성향 점수는 차원을 획기적으로 줄여줍니다.\n Figure 2: 성향 점수 \\(e(Z)\\)로 층화(stratification)했을 때, 각 층 내부에서는 처치군과 대조군의 공변량(예: 나이, 운동 성향) 분포가 유사해짐을 보여줍니다. [cite_start]즉, \\(e(Z)=0.7\\)인 그룹 내에서는 30대 미만의 비율이 처치 여부와 무관하게 동일해집니다 [cite: 21-48].\n\n\nProperty 2: Unconfoundedness given PS\n[cite_start]만약 공변량 \\(Z\\)를 통제했을 때 잠재적 결과(Potential Outcomes)와 처치가 독립이라면(Unconfoundedness given \\(Z\\)), 성향 점수 \\(e(Z)\\)만 통제해도 이 독립성이 유지됩니다[cite: 61, 62].\n\\[\n\\{Y(1), Y(0)\\} \\perp\\!\\!\\perp X \\mid Z \\implies \\{Y(1), Y(0)\\} \\perp\\!\\!\\perp X \\mid e(Z)\n\\]\n[cite_start]이 성질 덕분에 우리는 고차원의 \\(Z\\) 대신 1차원의 \\(e(Z)\\)만을 조정하여 편향을 제거할 수 있습니다[cite: 63].\n\nProof Sketch (Derivation)\n[cite_start]이 성질을 증명하기 위해 반복 기댓값의 법칙(Law of Iterated Expectations)을 사용해 \\(E[X|e(Z)]\\)가 \\(e(Z)\\)와 같음을 먼저 보입니다 [cite: 71-73].\n\\[\n\\begin{aligned}\n\\mathbb{E}[X \\mid e(Z)] &= \\mathbb{E}[\\mathbb{E}[X \\mid e(Z), Z] \\mid e(Z)] \\\\\n&= \\mathbb{E}[\\mathbb{E}[X \\mid Z] \\mid e(Z)] \\quad (\\because e(Z) \\text{ is a function of } Z) \\\\\n&= \\mathbb{E}[e(Z) \\mid e(Z)] \\\\\n&= e(Z)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "posts/lecture/L11/part-01/index.html#identification-strategy",
    "href": "posts/lecture/L11/part-01/index.html#identification-strategy",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 1)",
    "section": "3.1. Identification Strategy",
    "text": "3.1. Identification Strategy\n우리의 목표는 Average Treatment Effect (ATE), 즉 \\(\\tau^{ATE} = \\mathbb{E}[Y(1) - Y(0)]\\)를 추정하는 것입니다. 관측 데이터에서는 \\(Y(1)\\)과 \\(Y(0)\\) 중 하나만 관찰되므로(Fundamental Problem of Causal Inference), 이를 해결하기 위해 가중치(Weighting)를 사용합니다.\n[cite_start]IPW의 핵심 아이디어는 각 개체가 표본에 포함될 확률의 역수(Inverse Probability)를 가중치로 부여하여, 전체 모집단을 대표하는 가상 모집단(Pseudo-population)을 생성하는 것입니다[cite: 151]."
  },
  {
    "objectID": "posts/lecture/L11/part-01/index.html#derivation-of-ipw-estimator",
    "href": "posts/lecture/L11/part-01/index.html#derivation-of-ipw-estimator",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 1)",
    "section": "3.2. Derivation of IPW Estimator",
    "text": "3.2. Derivation of IPW Estimator\n가정(Identification Assumptions): 1. Consistency: \\(Y = XY(1) + (1-X)Y(0)\\) 2. Exchangeability (Unconfoundedness): \\(Y(x) \\perp X | Z\\) 3. Positivity: \\(0 &lt; P(X=1|Z) &lt; 1\\)\n우리는 \\(\\mathbb{E}[Y(1)]\\)을 관측된 데이터 \\((X, Y, Z)\\)로 표현하고자 합니다. [cite_start]다음 식을 살펴봅시다[cite: 83].\n\\[\n\\mathbb{E}\\left[ \\frac{XY}{e(Z)} \\right]\n\\]\n[cite_start]이 식을 반복 기댓값의 법칙을 사용하여 전개하면 다음과 같습니다[cite: 83, 84].\n\\[\n\\begin{aligned}\n\\mathbb{E}\\left[ \\frac{XY}{e(Z)} \\right] &= \\mathbb{E}\\left[ \\mathbb{E}\\left[ \\frac{XY}{e(Z)} \\Bigg| Z \\right] \\right] \\\\\n&= \\mathbb{E}\\left[ \\frac{1}{e(Z)} \\mathbb{E}[XY \\mid Z] \\right] \\quad (\\because e(Z) \\text{ is constant given } Z) \\\\\n&= \\mathbb{E}\\left[ \\frac{1}{e(Z)} \\mathbb{E}[X Y(1) \\mid Z] \\right] \\quad (\\because Y = Y(1) \\text{ when } X=1) \\\\\n&= \\mathbb{E}\\left[ \\frac{1}{e(Z)} \\mathbb{E}[X \\mid Z] \\mathbb{E}[Y(1) \\mid Z] \\right] \\quad (\\because Y(1) \\perp X \\mid Z \\text{ by Exchangeability}) \\\\\n&= \\mathbb{E}\\left[ \\frac{1}{e(Z)} e(Z) \\mathbb{E}[Y(1) \\mid Z] \\right] \\quad (\\because \\mathbb{E}[X \\mid Z] = e(Z)) \\\\\n&= \\mathbb{E}\\left[ \\mathbb{E}[Y(1) \\mid Z] \\right] \\\\\n&= \\mathbb{E}[Y(1)]\n\\end{aligned}\n\\]\n동일한 논리로 \\(\\mathbb{E}[Y(0)] = \\mathbb{E}\\left[ \\frac{(1-X)Y}{1-e(Z)} \\right]\\) 임을 보일 수 있습니다.\n[cite_start]따라서 ATE는 다음과 같이 식별됩니다[cite: 91].\n\\[\n\\tau^{ATE} = \\mathbb{E}\\left[ \\frac{XY}{e(Z)} - \\frac{(1-X)Y}{1-e(Z)} \\right]\n\\]"
  },
  {
    "objectID": "posts/lecture/L11/part-01/index.html#horvitz-thompson-estimator",
    "href": "posts/lecture/L11/part-01/index.html#horvitz-thompson-estimator",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 1)",
    "section": "3.3. Horvitz-Thompson Estimator",
    "text": "3.3. Horvitz-Thompson Estimator\n[cite_start]위 식별 식을 표본 평균으로 대치하면 Horvitz-Thompson (HT) Estimator (또는 standard IPW estimator)를 얻습니다[cite: 99].\n\\[\n\\hat{\\tau}_{ipw,1} = \\frac{1}{N} \\sum_{i=1}^{N} \\left\\{ \\frac{Y_i X_i}{e(Z_i)} - \\frac{Y_i (1-X_i)}{1-e(Z_i)} \\right\\}\n\\]\n[cite_start]이때 가중치는 다음과 같이 정의됩니다[cite: 94]. \\[\nw_1(Z_i) = \\frac{1}{e(Z_i)}, \\quad w_0(Z_i) = \\frac{1}{1-e(Z_i)}\n\\]"
  },
  {
    "objectID": "posts/lecture/L11/part-01/index.html#the-problem-with-standard-ipw",
    "href": "posts/lecture/L11/part-01/index.html#the-problem-with-standard-ipw",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 1)",
    "section": "4.1. The Problem with Standard IPW",
    "text": "4.1. The Problem with Standard IPW\n\\(\\hat{\\tau}_{ipw,1}\\)은 비편향 추정량(Unbiased Estimator)이지만, 유한 표본(Finite Sample)에서는 분산이 매우 클 수 있습니다. [cite_start]특히 성향 점수 \\(e(Z)\\)가 0이나 1에 가까우면 가중치가 폭발적으로 커집니다[cite: 104, 168].\n[cite_start]또한, 이론적으로 가중치의 평균은 1이어야 합니다[cite: 106, 107]. \\[\n\\mathbb{E}\\left[ \\frac{X}{e(Z)} \\right] = \\mathbb{E}\\left[ \\frac{\\mathbb{E}[X|Z]}{e(Z)} \\right] = 1\n\\] [cite_start]하지만 실제 표본에서는 \\(\\frac{1}{N} \\sum \\frac{X_i}{\\hat{e}(Z_i)}\\)가 정확히 1이 되지 않을 수 있습니다[cite: 114]."
  },
  {
    "objectID": "posts/lecture/L11/part-01/index.html#hajek-estimator",
    "href": "posts/lecture/L11/part-01/index.html#hajek-estimator",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 1)",
    "section": "4.2. Hajek Estimator",
    "text": "4.2. Hajek Estimator\n[cite_start]이 문제를 해결하기 위해 가중치의 합으로 나누어 정규화(Normalize)하는 방법, 즉 Hajek Estimator를 사용합니다[cite: 121, 122].\n\\[\n\\hat{\\tau}_{ipw,2} = \\frac{\\sum_{i=1}^{n} Y_i X_i w_1(Z_i)}{\\sum_{i=1}^{n} X_i w_1(Z_i)} - \\frac{\\sum_{i=1}^{n} Y_i (1-X_i) w_0(Z_i)}{\\sum_{i=1}^{n} (1-X_i) w_0(Z_i)}\n\\]\n이 방식은 가중치의 합이 1이 되도록 강제합니다. [cite_start]\\(\\hat{\\tau}_{ipw,2}\\)는 약간의 편향(Bias)이 생길 수 있지만, 일반적으로 분산(Variance)이 더 작아 평균 제곱 오차(MSE) 측면에서 \\(\\hat{\\tau}_{ipw,1}\\)보다 우수하고 안정적인 추정을 가능하게 합니다[cite: 125, 127]. [cite_start]이를 Stabilized Weights라고도 부릅니다[cite: 128].\n\nDigression: Why not both? [cite_start]최근 연구(Johan Ugander et al.)에서는 HT와 Hajek 중 하나를 선택하는 대신, 두 추정량을 결합하는 방법(\\(\\lambda\\)-estimator)에 대한 논의도 진행되고 있습니다 [cite: 130-146]."
  },
  {
    "objectID": "posts/lecture/L11/part-01/index.html#symmetric-trimming",
    "href": "posts/lecture/L11/part-01/index.html#symmetric-trimming",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 1)",
    "section": "5.1. Symmetric Trimming",
    "text": "5.1. Symmetric Trimming\n성향 점수가 특정 범위 \\([\\alpha, 1-\\alpha]\\)를 벗어나는 개체들을 분석에서 제외합니다. [cite_start]일반적으로 \\(\\alpha=0.1\\) 또는 \\(0.05\\)를 사용합니다[cite: 171, 172].\n\\[\n\\text{Exclude if } e(Z) \\notin [0.05, 0.95]\n\\]"
  },
  {
    "objectID": "posts/lecture/L11/part-01/index.html#asymmetric-trimming",
    "href": "posts/lecture/L11/part-01/index.html#asymmetric-trimming",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 1)",
    "section": "5.2. Asymmetric Trimming",
    "text": "5.2. Asymmetric Trimming\n[cite_start]처치군과 대조군의 성향 점수 분포가 겹치지 않는(non-overlap) 영역을 제거합니다[cite: 173]. * 처치군의 분포에서 너무 낮은 성향 점수를 가진 개체 제외 (대조군과 비교 불가) * [cite_start]대조군의 분포에서 너무 높은 성향 점수를 가진 개체 제외[cite: 175, 176]."
  },
  {
    "objectID": "posts/lecture/L11/part-01/index.html#truncation-winsorizing",
    "href": "posts/lecture/L11/part-01/index.html#truncation-winsorizing",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 1)",
    "section": "5.3. Truncation (Winsorizing)",
    "text": "5.3. Truncation (Winsorizing)\n데이터를 제외하는 대신, 가중치의 상한/하한을 설정합니다. [cite_start]성향 점수가 \\(\\alpha\\)보다 작으면 \\(\\alpha\\)로, \\(1-\\alpha\\)보다 크면 \\(1-\\alpha\\)로 대체하여 가중치가 무한히 커지는 것을 막습니다[cite: 177, 178].\n Figure 3: 처치군(실선)과 대조군(점선)의 성향 점수 분포. [cite_start]겹치지 않는(Non-overlap) 영역이나 밀도가 낮은 꼬리(Tail) 부분의 데이터를 제거(Trimming)하거나 제한(Restriction)하여 비교 가능성을 확보하는 과정을 보여줍니다 [cite: 181-188]."
  },
  {
    "objectID": "posts/lecture/L11/part-01/index.html#optimization-problem",
    "href": "posts/lecture/L11/part-01/index.html#optimization-problem",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 1)",
    "section": "6.1. Optimization Problem",
    "text": "6.1. Optimization Problem\n[cite_start]목표는 다음 제약 조건을 만족하면서 가중치 \\(w_i\\)의 변동(예: 분산, 엔트로피)을 최소화하는 것입니다[cite: 213, 214].\n\\[\n\\frac{1}{N_1} \\sum_{i=1}^{N} w_i X_i Z_i = \\frac{1}{N_0} \\sum_{i=1}^{N} w_i (1-X_i) Z_i \\quad \\text{(Balance Constraint)}\n\\]"
  },
  {
    "objectID": "posts/lecture/L11/part-01/index.html#notable-methods",
    "href": "posts/lecture/L11/part-01/index.html#notable-methods",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 1)",
    "section": "6.2. Notable Methods",
    "text": "6.2. Notable Methods\n\n[cite_start]Entropy Balancing (Hainmueller, 2011) [cite: 219]\n[cite_start]Covariate Balancing Propensity Score (CBPS) (Imai and Ratkovic, 2014) [cite: 220]\n[cite_start]Stabilized Balancing Weights (Zubizarreta, 2015) [cite: 221]"
  },
  {
    "objectID": "posts/lecture/L11/part-01/index.html#caution",
    "href": "posts/lecture/L11/part-01/index.html#caution",
    "title": "[Causal Inference] 11. IPW and Its Variants (Part 1)",
    "section": "6.3. Caution",
    "text": "6.3. Caution\nBalancing 방법은 분석가가 명시한 공변량의 함수(예: 평균, 분산)에 대해서만 균형을 맞춥니다. [cite_start]만약 결과 모델(Outcome Model)에 중요한 상호작용 항(Interaction Term, \\(Z_1 Z_2\\))이 포함되어 있는데, 균형 제약 조건에는 이를 포함하지 않았다면(\\(Z_1, Z_2\\)만 균형 맞춤), 여전히 편향(Bias)이 남을 수 있습니다[cite: 236]."
  },
  {
    "objectID": "posts/lecture/L16/part-01/index.html",
    "href": "posts/lecture/L16/part-01/index.html",
    "title": "[Causal Inference] 16. Causal Discovery (Part 1)",
    "section": "",
    "text": "인과추론(Causal Inference)의 세계는 크게 두 가지 연구 주제로 나뉩니다.\n우리가 흔히 접하는 인과추론은 인과 그래프(Causal Diagram, \\(\\mathcal{G}\\))가 이미 주어져 있다고 가정하고, 특정 개입(Intervention, \\(do(x)\\))이 결과에 미치는 확률분포 \\(P_x(y)\\)를 추정하는 문제입니다.\n하지만 현실에서는 인과 그래프 자체를 알 수 없는 경우가 많습니다.\nCausal Discovery (혹은 Structure Learning)는 이 역문제(Inverse Problem)를 다룹니다.\n즉, 관측된 데이터의 확률분포 \\(P(\\mathbf{V})\\)로부터 데이터 생성 과정을 가장 잘 설명하는 인과 그래프 \\(\\mathcal{G}\\)를 찾아내는 과정입니다.\n\n\n\n\nFigure 1: Causal Inference와 Causal Discovery의 차이. 왼쪽(Causal Inference)은 그래프 \\(G\\)가 주어졌을 때 \\(P(V)\\) 혹은 \\(P_x(y)\\)를 구하는 과정이고, 오른쪽(Causal Discovery)은 데이터 \\(P(V)\\)로부터 미지의 그래프 \\(G\\)를 귀납적으로 추론하는 과정이다.\n\n\n\n\n\n“상관관계는 인과관계를 의미하지 않는다”는 명제는 Causal Discovery가 왜 어려운지를 단적으로 보여줍니다.\n예를 들어, ’수탉의 울음(Rooster)’과 ’일출(Sun)’이라는 두 변수가 완벽하게 상관관계를 갖는 데이터가 있다고 가정해 봅시다.\n데이터 테이블이 아래와 같이 주어졌을 때:\n\n\\[\n\\begin{array}{cc}\n\\text{Rooster} & \\text{Sun} \\\\\n0 & 0 \\\\\n1 & 1 \\\\\n0 & 0 \\\\\n\\vdots & \\vdots\n\\end{array}\n\\]\n\n이 데이터만으로는 \\(Rooster \\rightarrow Sun\\)인지, \\(Sun \\rightarrow Rooster\\)인지, 아니면 제3의 요인이 둘 다를 유발하는지 구별할 수 없습니다.\n데이터 \\(P(\\mathbf{V})\\)와 호환(Consistent)되는 그래프의 후보는 여러 개가 존재할 수 있으며, Causal Discovery의 목표는 이 후보군(Equivalence Class)을 찾아내는 것입니다."
  },
  {
    "objectID": "posts/lecture/L16/part-01/index.html#the-difficulty-correlation-is-not-causation",
    "href": "posts/lecture/L16/part-01/index.html#the-difficulty-correlation-is-not-causation",
    "title": "[Causal Inference] 16. Causal Discovery (Part 1)",
    "section": "",
    "text": "“상관관계는 인과관계를 의미하지 않는다”는 명제는 Causal Discovery가 왜 어려운지를 단적으로 보여줍니다.\n예를 들어, ’수탉의 울음(Rooster)’과 ’일출(Sun)’이라는 두 변수가 완벽하게 상관관계를 갖는 데이터가 있다고 가정해 봅시다.\n데이터 테이블이 아래와 같이 주어졌을 때:\n\n\\[\n\\begin{array}{cc}\n\\text{Rooster} & \\text{Sun} \\\\\n0 & 0 \\\\\n1 & 1 \\\\\n0 & 0 \\\\\n\\vdots & \\vdots\n\\end{array}\n\\]\n\n이 데이터만으로는 \\(Rooster \\rightarrow Sun\\)인지, \\(Sun \\rightarrow Rooster\\)인지, 아니면 제3의 요인이 둘 다를 유발하는지 구별할 수 없습니다.\n데이터 \\(P(\\mathbf{V})\\)와 호환(Consistent)되는 그래프의 후보는 여러 개가 존재할 수 있으며, Causal Discovery의 목표는 이 후보군(Equivalence Class)을 찾아내는 것입니다."
  },
  {
    "objectID": "posts/lecture/L16/part-01/index.html#definition-causal-structure",
    "href": "posts/lecture/L16/part-01/index.html#definition-causal-structure",
    "title": "[Causal Inference] 16. Causal Discovery (Part 1)",
    "section": "Definition: Causal Structure",
    "text": "Definition: Causal Structure\n\n변수 집합 \\(\\mathbf{V}\\)의 인과 구조는 DAG로 표현되며, 각 노드는 변수에 대응하고 방향성이 있는 엣지(Edge)는 변수 간의 직접적인 함수적 관계(Direct functional relationship)를 나타냅니다."
  },
  {
    "objectID": "posts/lecture/L16/part-01/index.html#assumption-causal-sufficiency",
    "href": "posts/lecture/L16/part-01/index.html#assumption-causal-sufficiency",
    "title": "[Causal Inference] 16. Causal Discovery (Part 1)",
    "section": "Assumption: Causal Sufficiency",
    "text": "Assumption: Causal Sufficiency\n\n가장 강력하면서도 기본적인 가정은 Causal Sufficiency입니다.\n이는 우리가 분석하는 변수 집합 \\(\\mathbf{V}\\) 내의 변수들에 영향을 미치는 관측되지 않은 교란 변수(Unmeasured Confounder)가 존재하지 않는다는 가정입니다.\n만약 이 가정이 위배된다면(즉, Latent Confounder가 있다면), 우리는 DAG 대신 양방향 엣지가 포함된 더 복잡한 그래프 모델(예: ADMG)을 고려해야 합니다."
  },
  {
    "objectID": "posts/lecture/L16/part-01/index.html#factorization",
    "href": "posts/lecture/L16/part-01/index.html#factorization",
    "title": "[Causal Inference] 16. Causal Discovery (Part 1)",
    "section": "1. Factorization",
    "text": "1. Factorization\n\n확률분포 \\(P(\\mathbf{V})\\)는 그래프상의 부모 노드(Parents) 조건부 확률들의 곱으로 표현될 수 있습니다. \\[P(A, B, C, D, E) = P(E|D)P(D|B,C)P(C|A)P(B|A)P(A)\\]"
  },
  {
    "objectID": "posts/lecture/L16/part-01/index.html#local-markov-property",
    "href": "posts/lecture/L16/part-01/index.html#local-markov-property",
    "title": "[Causal Inference] 16. Causal Discovery (Part 1)",
    "section": "2. Local Markov Property",
    "text": "2. Local Markov Property\n\nDAG의 각 변수는 자신의 부모가 주어졌을 때, 자신의 자손(Descendants)이 아닌 모든 변수와 조건부 독립입니다.\n\n\\[(C \\perp\\!\\!\\!\\perp B \\mid A), \\quad (D \\perp\\!\\!\\!\\perp A \\mid B, C), \\quad (E \\perp\\!\\!\\!\\perp A, B, C \\mid D)\\]"
  },
  {
    "objectID": "posts/lecture/L16/part-01/index.html#global-markov-property-d-separation",
    "href": "posts/lecture/L16/part-01/index.html#global-markov-property-d-separation",
    "title": "[Causal Inference] 16. Causal Discovery (Part 1)",
    "section": "3. Global Markov Property (\\(d\\)-separation)",
    "text": "3. Global Markov Property (\\(d\\)-separation)\n\n가장 일반적인 성질로, 그래프상에서 \\(d\\)-separation된 두 변수 집합은 확률분포상에서도 조건부 독립(Conditional Independence)이어야 함을 의미합니다.\n\n\\[\\text{A is } d\\text{-separated from B given C in } \\mathcal{G} \\implies (A \\perp\\!\\!\\!\\perp B \\mid C) \\text{ in } P(\\mathbf{V})\\]\n\n이 성질은 그래프의 구조적 분리(\\(d\\)-separation)가 데이터의 통계적 독립성으로 나타난다는 것을 보장합니다."
  },
  {
    "objectID": "posts/lecture/L16/part-01/index.html#definition-faithfulness",
    "href": "posts/lecture/L16/part-01/index.html#definition-faithfulness",
    "title": "[Causal Inference] 16. Causal Discovery (Part 1)",
    "section": "Definition: Faithfulness",
    "text": "Definition: Faithfulness\n\\[A \\text{ is } d\\text{-separated from } B \\text{ given } C \\text{ in } \\mathcal{G} \\iff (A \\perp\\!\\!\\!\\perp B \\mid C) \\text{ in } P(\\mathbf{V})\\]\n\n즉, 그래프에서의 \\(d\\)-separation과 확률분포에서의 조건부 독립이 필요충분조건이 된다고 가정하는 것입니다.\n이 가정이 있다면:\n\n데이터에서 관측된 독립성 \\(\\rightarrow\\) 그래프에서의 엣지 제거 (\\(d\\)-separation)\n데이터에서 관측된 종속성 \\(\\rightarrow\\) 그래프에서의 엣지 연결 (\\(d\\)-connection)"
  },
  {
    "objectID": "posts/lecture/L16/part-01/index.html#justification-limitations",
    "href": "posts/lecture/L16/part-01/index.html#justification-limitations",
    "title": "[Causal Inference] 16. Causal Discovery (Part 1)",
    "section": "Justification & Limitations",
    "text": "Justification & Limitations\n\nFaithfulness는 얼마나 타당한 가정일까요?\n이론적으로, 무작위로 생성된 확률분포 \\(P(\\mathbf{V})\\)가 Unfaithful할 확률은 0(measure zero)입니다.\n즉, 대부분의 분포는 Faithful 합니다.\n하지만 현실적인 문제들이 존재합니다:\n\n\nFinite Samples: 데이터가 유한할 때, 실제로는 연결되어 있지만 효과가 매우 미미한 경우(Nearly Unfaithful)를 통계적으로 독립과 구별하기 어렵습니다.\n\n\nHomeostasis (항상성): 자연계, 특히 생물학적 시스템에서는 진화적 이유로 상쇄 효과(Cancellation)가 발달하여 Unfaithful한 상황이 드물지 않게 발생할 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L16/part-01/index.html#model-setup",
    "href": "posts/lecture/L16/part-01/index.html#model-setup",
    "title": "[Causal Inference] 16. Causal Discovery (Part 1)",
    "section": "Model Setup",
    "text": "Model Setup\n\nGraph: \\(X \\rightarrow Z\\), \\(X \\rightarrow Y\\), \\(Z \\rightarrow Y\\) (Triangle structure)\nParameters:\n\n\\(X \\rightarrow Z\\): 계수 \\(+1\\)\n\\(Z \\rightarrow Y\\): 계수 \\(-1\\)\n\\(X \\rightarrow Y\\): 계수 \\(+1\\) (Direct effect)\n\n\n\n\n\nFigure 3: Faithfulness 위배 예시 그래프. X는 Y에 직접 영향을 미치고(계수 +1), Z를 통해서도 영향을 미친다(X-&gt;Z 계수 +1, Z-&gt;Y 계수 -1).\n\n\n\n수식으로 표현하면: \\[\n\\begin{align}\nX &= \\epsilon_X \\\\\nZ &= 1 \\cdot X + \\epsilon_Z \\\\\nY &= 1 \\cdot X - 1 \\cdot Z + \\epsilon_Y\n\\end{align}\n\\]\n여기서 오차항 \\(\\epsilon\\)들은 서로 독립입니다."
  },
  {
    "objectID": "posts/lecture/L16/part-01/index.html#derivation-of-cancellation",
    "href": "posts/lecture/L16/part-01/index.html#derivation-of-cancellation",
    "title": "[Causal Inference] 16. Causal Discovery (Part 1)",
    "section": "Derivation of Cancellation",
    "text": "Derivation of Cancellation\n\n이제 \\(Y\\)를 \\(X\\)와 \\(\\epsilon\\)들에 대해 정리해 봅시다. \\[\n\\begin{align}\nY &= X - Z + \\epsilon_Y \\\\\n&= X - (X + \\epsilon_Z) + \\epsilon_Y \\\\\n&= X - X - \\epsilon_Z + \\epsilon_Y \\\\\n&= -\\epsilon_Z + \\epsilon_Y\n\\end{align}\n\\]\n결과적으로 \\(Y\\)는 \\(X\\)라는 항을 포함하지 않게 됩니다.\n따라서 \\(Cov(X, Y) = 0\\)이 되고, 만약 가우시안 분포를 따른다면 \\(X\\)와 \\(Y\\)는 통계적으로 독립입니다."
  },
  {
    "objectID": "posts/lecture/L16/part-01/index.html#conclusion",
    "href": "posts/lecture/L16/part-01/index.html#conclusion",
    "title": "[Causal Inference] 16. Causal Discovery (Part 1)",
    "section": "Conclusion",
    "text": "Conclusion\n\nData (\\(P(\\mathbf{V})\\)): \\(X \\perp\\!\\!\\!\\perp Y\\) (독립)\nGraph (\\(\\mathcal{G}\\)): \\(X\\)와 \\(Y\\)는 \\(d\\)-connected (연결됨)\n데이터만 보면 \\(X\\)와 \\(Y\\) 사이에 아무런 관계가 없어 보여 엣지를 제거하게 되지만, 실제로는 두 개의 경로(\\(X \\to Y\\)와 \\(X \\to Z \\to Y\\))가 서로를 완벽하게 상쇄하고 있었던 것입니다.\n이것이 바로 Faithfulness 위배 사례입니다."
  },
  {
    "objectID": "posts/lecture/L16/part-03/index.html",
    "href": "posts/lecture/L16/part-03/index.html",
    "title": "[Causal Inference] 16. Causal Discovery (Part 3)",
    "section": "",
    "text": "이전 포스트에서 다룬 PC Algorithm은 Causal Discovery의 기념비적인 알고리즘이지만, 현실 데이터에 적용할 때는 몇 가지 강력한 가정과 구조적 한계에 부딪힙니다.\n\n\nFaithfulness Violation: 데이터가 완벽하게 Faithful 하지 않다면 잘못된 V-structure를 학습할 수 있습니다.\n\n\nOrder Dependency: 변수의 입력 순서에 따라 결과 그래프가 달라지는 불안정성이 존재합니다.\n\n\nCausal Sufficiency: 관측되지 않은 교란 변수(Latent Confounder)가 존재할 경우, DAG 모델로 이를 표현할 수 없습니다.\n\n\n이번 포스트에서는 이러한 문제들을 해결하기 위해 제안된 PC 알고리즘의 확장판들(Conservative PC, Order-Independent PC)과, Causal Sufficiency 가정을 완화한 FCI 알고리즘에 대해 다룹니다."
  },
  {
    "objectID": "posts/lecture/L16/part-03/index.html#decomposition-of-faithfulness",
    "href": "posts/lecture/L16/part-03/index.html#decomposition-of-faithfulness",
    "title": "[Causal Inference] 16. Causal Discovery (Part 3)",
    "section": "2.1 Decomposition of Faithfulness",
    "text": "2.1 Decomposition of Faithfulness\n\nCPC는 Faithfulness 가정을 두 가지로 세분화하여 접근합니다.\n\nAdjacency Faithfulness:\n\n\n두 변수가 인접해 있다면(Adjacent), 어떠한 조건부 집합(Separator)으로도 독립이 되지 않는다.\n위배 시: 실제로는 엣지가 있는데 데이터상에서 독립으로 나타나 엣지가 사라지는 문제 발생.\n\n\nOrientation Faithfulness:\n\n\n만약 \\(X \\rightarrow Z \\leftarrow Y\\) (Unshielded Collider)라면, \\(Z\\)를 포함하는 \\(V \\setminus \\{X, Y\\}\\)의 모든 부분집합에 대해 \\(X\\)와 \\(Y\\)는 종속적이어야 한다.\n그렇지 않다면(Non-collider), \\(Z\\)를 포함하는 어떠한 분리 집합(Separator)도 \\(X\\)와 \\(Y\\)를 분리하지 못해야 한다(즉, 분리 집합은 \\(Z\\)를 포함해서는 안 된다)."
  },
  {
    "objectID": "posts/lecture/L16/part-03/index.html#algorithm-logic",
    "href": "posts/lecture/L16/part-03/index.html#algorithm-logic",
    "title": "[Causal Inference] 16. Causal Discovery (Part 3)",
    "section": "2.2 Algorithm Logic",
    "text": "2.2 Algorithm Logic\n\n기존 PC 알고리즘은 \\(X-Z-Y\\) 구조에서 \\(X\\)와 \\(Y\\)를 분리하는 단 하나의 Separator \\(S\\)만 찾으면, \\(Z \\notin S\\) 여부만 확인하고 즉시 Collider 여부를 결정했습니다.\n이는 데이터에 노이즈가 있거나 Faithfulness가 약하게 위배될 때 오류를 범할 수 있습니다.\nCPC는 이를 보완하기 위해 모든 가능한 부분집합을 확인합니다.\n\n\\(X\\)와 \\(Y\\)의 잠재적 부모(neighbors)들의 모든 부분집합을 검사하여 \\(X\\)와 \\(Y\\)를 독립시키는 집합들을 찾습니다.\n\n\nDecision Rule:\n\n\nCollider (\\(X \\rightarrow Z \\leftarrow Y\\)): 발견된 모든 Separator \\(S\\)가 \\(Z\\)를 포함하지 않는 경우.\nNon-Collider: 발견된 모든 Separator \\(S\\)가 \\(Z\\)를 포함하는 경우.\nUnfaithful (Ambiguous): 어떤 Separator는 \\(Z\\)를 포함하고, 어떤 것은 포함하지 않는 경우. 이 경우 해당 Triple은 “Unfaithful”로 마킹하고 방향을 결정하지 않습니다.\n\n\n\n\n\nFigure 1: CPC의 결과 예시. 그래프상의 밑줄(또는 X표시)된 부분은 알고리즘이 “Unfaithful”하다고 판단하여 방향을 결정하지 않고 남겨둔 Unshielded Triple을 나타낸다.\n\n\n\n이러한 보수적인 접근을 통해 CPC는 방향성 결정 오류를 줄이고 더 신뢰할 수 있는 골격(Skeleton)과 방향을 제시합니다."
  },
  {
    "objectID": "posts/lecture/L16/part-03/index.html#the-problem-variable-ordering",
    "href": "posts/lecture/L16/part-03/index.html#the-problem-variable-ordering",
    "title": "[Causal Inference] 16. Causal Discovery (Part 3)",
    "section": "3.1 The Problem: Variable Ordering",
    "text": "3.1 The Problem: Variable Ordering\n\n표준 PC 알고리즘은 변수의 순서(Variable Ordering)에 민감합니다.\n알고리즘이 \\(X_1, X_2, \\dots, X_n\\) 순서로 엣지 삭제를 검토한다고 할 때, 초기에 \\(X_1\\) 관련 엣지가 삭제되면 \\(X_1\\)은 더 이상 다른 변수의 Separator 후보가 될 수 없습니다.\n즉, 엣지를 즉시 삭제(Remove immediately)하는 방식 때문에, 변수를 어떤 순서로 입력하느냐에 따라 최종 그래프의 골격(Skeleton)이 달라질 수 있습니다.\n이로 인해 잘못된 독립성 검정 결과(False Negative)가 발생하면 오류가 파급될 수 있습니다.\n\n\n\n\nFigure 2: 변수 순서에 따른 PC 알고리즘 결과의 불안정성. y축은 서로 다른 변수 정렬(ordering)을 나타내며, x축은 엣지의 존재 여부이다. 동일한 데이터임에도 변수 순서만 바꾸면 검은색 띠(발견된 엣지)의 패턴이 달라지는 것을 볼 수 있다."
  },
  {
    "objectID": "posts/lecture/L16/part-03/index.html#solution-pc-stable-majority-rule",
    "href": "posts/lecture/L16/part-03/index.html#solution-pc-stable-majority-rule",
    "title": "[Causal Inference] 16. Causal Discovery (Part 3)",
    "section": "3.2 Solution: PC-Stable & Majority Rule",
    "text": "3.2 Solution: PC-Stable & Majority Rule\n\nColombo와 Maathuis (2014)는 이를 해결하기 위해 Order-Independent PC (PC-Stable)를 제안했습니다.\n\nPC-Stable (Stable Edge Removal):\n\n\n특정 단계(Separation set 크기 \\(k\\))가 진행되는 동안에는, 발견된 독립성에 의해 엣지를 삭제하더라도 즉시 그래프에서 지우지 않고 마킹만 해둡니다.\n\\(k\\) 단계의 모든 변수 쌍에 대한 검사가 끝난 뒤에 일괄적으로 엣지를 삭제합니다.\n이렇게 하면 해당 단계 내에서는 모든 변수가 동등한 Separator 후보 자격을 유지하므로 순서 의존성이 사라집니다.\n\n\nMajority Rule:\n\n\nCPC가 너무 보수적(Restrictive)이라 방향을 거의 결정하지 못하는 경우를 대비해, “Unfaithful”로 마킹하는 대신 다수결 원칙(Majority-rule)을 적용하여 더 많이 지지되는 쪽으로 방향을 결정하는 방법도 제안되었습니다."
  },
  {
    "objectID": "posts/lecture/L16/part-03/index.html#latent-confounders-example",
    "href": "posts/lecture/L16/part-03/index.html#latent-confounders-example",
    "title": "[Causal Inference] 16. Causal Discovery (Part 3)",
    "section": "4.1 Latent Confounders Example",
    "text": "4.1 Latent Confounders Example\n\n다음과 같은 실제 인과 구조(True Graph)가 있다고 가정해 봅시다. \\[X \\rightarrow Y \\leftarrow U \\rightarrow Z \\leftarrow W\\]\n여기서 \\(U\\)는 관측되지 않는 Latent Variable입니다.\n\n\n\n\nFigure 3: Latent Confounder가 존재할 때의 구조 학습. (A) 실제 그래프에는 관측되지 않은 U가 Y와 Z에 영향을 미친다. (B) 조건부 독립성 테스트 결과로 엣지가 제거된 상태. (C) FCI 알고리즘의 결과물로, 양방향 화살표 등이 포함된 PAG 형태를 띤다.\n\n\n\nObservation: \\(Y\\)와 \\(Z\\)는 \\(U\\) 때문에 종속적입니다. 하지만 \\(U\\)를 관측할 수 없으므로, \\(Y\\)와 \\(Z\\)를 분리할 수 있는 관측 변수 집합은 존재하지 않습니다.\nResult: PC 알고리즘은 \\(Y-Z\\) 사이에 엣지가 있다고 판단할 것입니다(False Positive)."
  },
  {
    "objectID": "posts/lecture/L16/part-03/index.html#fci-output-pags",
    "href": "posts/lecture/L16/part-03/index.html#fci-output-pags",
    "title": "[Causal Inference] 16. Causal Discovery (Part 3)",
    "section": "4.2 FCI Output: PAGs",
    "text": "4.2 FCI Output: PAGs\n\nFCI 알고리즘은 이러한 상황을 처리하여 PAG (Partial Ancestral Graph)를 출력합니다.\nPAG는 단순한 DAG보다 더 풍부한 엣지 정보를 담고 있습니다.\n\n\nEdge Meanings in PAGs (Partial Ancestral Graphs)\n\nFCI 알고리즘의 결과물인 PAG는 관측되지 않은 잠재 변수(Latent Confounder)의 존재 가능성까지 포함하여 인과관계를 표현합니다.\n엣지의 양 끝 모양(Mark)이 의미하는 바는 다음과 같습니다.\n\n\n\n\nFigure 4: Types of Edges in Partial Ancestral Graphs (PAG). 각 엣지는 조건부 독립성, 인과적 조상 관계, 잠재적 교란 요인의 존재, 또는 정보 부족에 따른 불확실성을 나타낸다.\n\n\n\n\nNo Edge (Independence):\n\n\n두 변수 \\(X_1\\)과 \\(X_2\\) 사이에 엣지가 없다는 것은, 두 변수를 독립으로 만드는 조건부 집합(Separating Set)이 존재함을 의미합니다.\n즉, 두 변수는 인과적으로 직접적인 관련이 없습니다.\n\n\nDirected Edge (\\(X_1 \\rightarrow X_2\\)):\n\n\n의미: Ancestral Relationship.\n\\(X_1\\)은 \\(X_2\\)의 원인(Ancestor)이며, 반대로 \\(X_2\\)는 \\(X_1\\)의 원인이 아닙니다.\n잠재 변수가 존재하더라도 \\(X_1\\)이 \\(X_2\\)에 영향을 준다는 사실은 명확합니다.\n\n\nBi-directed Edge (\\(X_1 \\leftrightarrow X_2\\)):\n\n\n의미: Latent Confounding.\n\\(X_1\\)이 \\(X_2\\)의 원인이 아니고, \\(X_2\\)도 \\(X_1\\)의 원인이 아닙니다.\n대신, 두 변수에 동시에 영향을 미치는 관측되지 않은 공통 원인(Latent Common Cause, \\(L\\))이 존재합니다 (\\(X_1 \\leftarrow L \\rightarrow X_2\\)).\n\n\nCircle Edge (\\(X_1 \\circ \\!\\! - \\!\\! \\circ X_2\\) or \\(X_1 \\circ \\!\\! \\rightarrow X_2\\)):\n\n\n의미: Uncertainty (Indeterminacy).\n엣지의 끝이 원(\\(\\circ\\))으로 표시된 것은 데이터만으로는 해당 방향이 꼬리(Tail, 원인)인지 화살표(Arrowhead, 결과)인지 확신할 수 없음을 나타냅니다.\n추가적인 배경지식이나 데이터 없이는 이 관계를 2번(\\(\\rightarrow\\))이나 3번(\\(\\leftrightarrow\\)) 중 하나로 확정할 수 없는 상태입니다.\n\n\n\n\nFCI Application\n\n앞선 예시에 FCI 알고리즘을 적용하면, \\(Y\\)와 \\(Z\\) 사이의 관계가 \\(Y \\leftrightarrow Z\\)로 추론될 수 있습니다.\n이는 \\(Y\\)와 \\(Z\\) 사이에 직접적인 인과관계가 있는 것이 아니라, 우리가 측정하지 못한 숨겨진 요인(Hidden Confounder)이 두 변수를 동시에 조절하고 있음을 시사합니다."
  },
  {
    "objectID": "posts/lecture/L16/part-05/index.html",
    "href": "posts/lecture/L16/part-05/index.html",
    "title": "[Causal Inference] 16. Causal Discovery (Part 5)",
    "section": "",
    "text": "인과 추론(Causal Inference)에서 가장 근본적인 질문 중 하나는 “상관관계는 인과관계가 아니다”라는 명제에서 출발합니다.\n두 변수 \\(X\\)와 \\(Y\\)가 통계적으로 종속되어 있을 때, 우리는 이것이 \\(X \\to Y\\) 때문인지, \\(Y \\to X\\) 때문인지, 혹은 잠재적 교란 변수(confounder) 때문인지 데이터만으로는 완벽하게 구분하기 어렵습니다.\n기존의 Constraint-based approach (예: PC algorithm)는 조건부 독립성 검정(Conditional Independence Test)을 통해 인과 그래프의 뼈대(Skeleton)와 V-structure를 찾아내지만, Markov Equivalence Class에 속하는 그래프들(같은 조건부 독립성을 가지는 그래프들) 사이에서는 방향을 결정할 수 없다는 한계가 있습니다.\n이번 포스트에서는 이러한 한계를 극복하기 위해 함수적 인과 모델(Functional Causal Models, FCM)을 다룹니다.\n이 방법론들은 데이터 생성 과정(Data Generating Process)에 대한 추가적인 가정(비선형성 또는 비정규성)을 도입하여, \\(X \\to Y\\)와 \\(Y \\to X\\)의 비대칭성(Asymmetry)을 찾아냅니다."
  },
  {
    "objectID": "posts/lecture/L16/part-05/index.html#identifiability-via-anm",
    "href": "posts/lecture/L16/part-05/index.html#identifiability-via-anm",
    "title": "[Causal Inference] 16. Causal Discovery (Part 5)",
    "section": "Identifiability via ANM",
    "text": "Identifiability via ANM\n\n변수의 분포가 비가우시안(Non-Gaussian)이거나 함수가 비선형(Non-linear)인 경우, 우리는 인과관계의 방향을 식별할 수 있습니다.\n이를 이해하기 위해 두 변수 \\(X, Y\\)에 대한 가법 잡음 모델(Additive Noise Model, ANM)을 살펴봅시다.\n\n\\[y = f_y(x) + u_y \\quad \\text{where} \\quad x \\perp\\!\\!\\perp u_y\\]\n\n핵심 아이디어는 “올바른 인과 방향으로 모델을 적합하면 잔차(Residual)가 원인 변수와 독립이지만, 반대 방향으로 적합하면 독립성이 깨진다”는 것입니다.\n\n\n\n\nFigure 1: Asymmetry in Additive Noise Models. 왼쪽(올바른 방향)에서는 설명변수 \\(X\\)와 노이즈 \\(U_y\\)가 독립이지만, 오른쪽(틀린 방향)에서는 설명변수 \\(Y\\)와 노이즈 \\(U_x\\) 사이에 종속성(붉은 점선)이 발생한다."
  },
  {
    "objectID": "posts/lecture/L16/part-05/index.html#가설-검증-프로세스",
    "href": "posts/lecture/L16/part-05/index.html#가설-검증-프로세스",
    "title": "[Causal Inference] 16. Causal Discovery (Part 5)",
    "section": "가설 검증 프로세스",
    "text": "가설 검증 프로세스\n\n만약 실제 데이터 생성 과정이 \\(X \\to Y\\)라면, 우리는 데이터를 양방향으로 피팅해보고 독립성 검정을 통해 방향을 결정할 수 있습니다.\n\n\n1. Hypothesis 1 (Forward: \\(X \\to Y\\)):\n\n\\(y = \\hat{f}(x) + \\hat{u}_y\\) 로 회귀분석을 수행합니다.\n잔차 \\(\\hat{u}_y\\)와 입력 \\(x\\)의 독립성을 검정합니다.\n결과: 독립성이 성립합니다 (\\(x \\perp\\!\\!\\perp \\hat{u}_y\\)).\n\n\n\n2. Hypothesis 2 (Backward: \\(Y \\to X\\)):\n\n반대로 \\(x = \\hat{g}(y) + \\hat{u}_x\\) 로 회귀분석을 수행합니다.\n이 경우, \\(f\\)가 비선형이라면 수학적으로 잔차 \\(\\hat{u}_x\\)가 \\(y\\)와 얽히게 됩니다.\n결과: 독립성이 기각됩니다 (\\(y \\not\\perp\\!\\!\\!\\perp \\hat{u}_x\\)).\n\n\n\n왜 이런 현상이 발생하나요?\n\n위 그림의 오른쪽 경우를 보면, 우리가 억지로 \\(Y \\to X\\) 모델을 만들었지만, 실제 데이터 \\(Y\\)는 \\(X\\)와 \\(U_y\\)의 결합으로 만들어졌습니다.\n따라서 \\(Y\\)를 설명변수로 사용하여 \\(X\\)를 예측하려 하면, 남은 잔차(\\(U_x\\)) 안에 \\(Y\\)에 대한 정보가 섞여 들어갈 수밖에 없습니다.\n이를 “정보의 누수(Information Leakage)” 또는 “비대칭성(Asymmetry)”이라고 합니다."
  },
  {
    "objectID": "posts/lecture/L16/part-05/index.html#algorithm",
    "href": "posts/lecture/L16/part-05/index.html#algorithm",
    "title": "[Causal Inference] 16. Causal Discovery (Part 5)",
    "section": "Algorithm",
    "text": "Algorithm\n\nANM을 이용한 인과 발견 알고리즘은 다음과 같이 수행됩니다:\n\n\nFit Forward: 데이터 \\((x_i, y_i)\\)에 대해 \\(y\\)를 \\(x\\)의 함수로 회귀분석하여 \\(\\hat{f}_y\\)를 구합니다.\n\n\nCompute Residuals: \\(\\hat{u}_y = y - \\hat{f}_y(x)\\)를 계산합니다.\n\n\nTest Independence: \\(\\hat{u}_y\\)와 \\(x\\)가 독립인지 검정합니다.\n\n\nFit Backward: 반대로 \\(x\\)를 \\(y\\)의 함수로 회귀분석하여 \\(\\hat{f}_x\\)를 구하고, 잔차 \\(\\hat{u}_x = x - \\hat{f}_x(y)\\)를 계산합니다.\n\n\nTest Independence: \\(\\hat{u}_x\\)와 \\(y\\)가 독립인지 검정합니다.\n\n\nDecide: 한쪽 방향만 독립성이 성립하면 그 방향을 인과 방향으로 채택합니다."
  },
  {
    "objectID": "posts/lecture/L16/part-05/index.html#extension-post-nonlinear-pnl-model",
    "href": "posts/lecture/L16/part-05/index.html#extension-post-nonlinear-pnl-model",
    "title": "[Causal Inference] 16. Causal Discovery (Part 5)",
    "section": "Extension: Post-Nonlinear (PNL) Model",
    "text": "Extension: Post-Nonlinear (PNL) Model\n\nANM은 관측된 변수에 노이즈가 직접 더해진다고 가정합니다. 이를 더 일반화한 것이 Post-Nonlinear Model (PNL)입니다.\n\n\\[x_2 = f_2(f_1(x_1) + e_2)\\]\n\n여기서 \\(f_2\\)는 역함수가 존재하는(invertible) 함수라고 가정합니다. 이 경우 노이즈 \\(e_2\\)는 다음과 같이 표현됩니다:\n\n\\[e_2 = f_2^{-1}(x_2) - f_1(x_1)\\]\n\n이 모델의 식별(Identifiability)은 \\(x_1\\)과 추정된 잔차 \\(\\hat{e}_2\\) 사이의 상호정보량(Mutual Information)을 최소화하는 문제, 즉 Constrained Nonlinear ICA 문제로 귀결됩니다.\n\n\\[I(x_1, \\hat{e}_2) = -\\mathbb{E}\\log p_{\\hat{e}_2}(\\hat{e}_2) - \\mathbb{E}\\log|l'_2(x_2)| + H(x_1) - H(x_1, x_2)\\]\n\n여기서 \\(l_2\\)는 \\(f_2^{-1}\\)에 대응하는 함수입니다. Zhang and Hyvarinen (2009)은 아주 특수한 경우를 제외하고는 PNL 모델이 식별 가능함을 보였습니다."
  },
  {
    "objectID": "posts/lecture/L16/part-05/index.html#why-non-gaussian",
    "href": "posts/lecture/L16/part-05/index.html#why-non-gaussian",
    "title": "[Causal Inference] 16. Causal Discovery (Part 5)",
    "section": "Why Non-Gaussian?",
    "text": "Why Non-Gaussian?\n\n선형 모델 \\(Y = bX + \\epsilon\\)과 \\(X = b_Y Y + \\epsilon_Y\\)를 생각해 봅시다.\n만약 \\(X\\)와 \\(\\epsilon\\)이 모두 Gaussian(정규분포)이라면, 결합 분포 \\(P(X, Y)\\)는 다변량 정규분포가 됩니다.\n다변량 정규분포는 대칭적인 타원 형태를 띠기 때문에, \\(X\\)축을 기준으로 보나 \\(Y\\)축을 기준으로 보나 구조적 차이를 발견할 수 없습니다.\n즉, Gaussian case는 식별 불가능(Unidentifiable)합니다.\n하지만 변수들이 Non-Gaussian(예: Uniform, Super-Gaussian)이라면 이야기가 달라집니다.\n결합 분포의 형태가 한쪽 방향으로는 독립성을 유지하지만, 역방향으로는 찌그러지거나 종속적인 패턴을 보이게 됩니다.\n\n\n\n\nFigure 3: Gaussian vs Non-Gaussian의 식별 가능성. (Case 1) 데이터가 Gaussian일 때는 회귀선을 어느 방향으로 그어도 잔차 분포가 대칭적이라 구별이 불가능하다. (Case 2, 3) 데이터가 Uniform이나 Super-Gaussian일 때는, 올바른 인과 방향(\\(X \\to Y\\))에서의 잔차는 독립적이지만, 역방향의 잔차는 명확한 종속성을 보인다."
  },
  {
    "objectID": "posts/lecture/L16/part-05/index.html#cramers-decomposition-theorem",
    "href": "posts/lecture/L16/part-05/index.html#cramers-decomposition-theorem",
    "title": "[Causal Inference] 16. Causal Discovery (Part 5)",
    "section": "Cramer’s Decomposition Theorem",
    "text": "Cramer’s Decomposition Theorem\n\nLiNGAM(Linear Non-Gaussian Acyclic Model)이 왜 작동하는지, 그리고 왜 데이터가 반드시 비정규분포(Non-Gaussian)여야 하는지를 이해하기 위해서는 Cramer의 분해 정리를 먼저 알아야 합니다.\n\n\n1. The Theorem\n\n하랄드 크라메르(Harald Cramér, 1936)가 증명한 이 정리는 다음과 같습니다.\n가정: 두 개의 독립적인(independent) 확률변수 \\(X\\)와 \\(Y\\)가 있습니다.\n조건: 만약 이 둘의 합인 확률변수 \\(Z = X + Y\\)가 정규분포(Gaussian Distribution)를 따른다면,\n결론: \\(X\\)와 \\(Y\\) 또한 반드시 정규분포를 따라야 합니다.\n\n\\[\nX \\perp\\!\\!\\!\\perp Y \\quad \\text{and} \\quad (X + Y) \\sim \\mathcal{N} \\implies X \\sim \\mathcal{N}, \\quad Y \\sim \\mathcal{N}\n\\]\n\n\n2. Implication for Causal Discovery (핵심 의미)\n\n이 정리는 인과추론, 특히 구조 식별성(Identifiability) 관점에서 매우 중요한 시사점을 가집니다.\n대우 명제 (Contrapositive):\n\n“만약 \\(X\\)와 \\(Y\\) 중 하나라도 비정규분포(Non-Gaussian)라면, 그 합 \\(X+Y\\)는 결코 (완벽한) 정규분포가 될 수 없다.”\n\n왜 LiNGAM에서 중요한가?\n\n선형 모델 \\(E = C + N\\) (결과 = 원인 + 노이즈)에서, 만약 원인(\\(C\\))과 노이즈(\\(N\\))가 모두 정규분포라면, 결과(\\(E\\))도 정규분포가 됩니다.\n이 경우, 역방향 모델 \\(C = E - N\\)을 만들어도 모든 변수가 정규분포이므로, 수학적으로 정방향과 역방향을 구별할 수 없습니다 (Unidentifiable).\n하지만 비정규분포 데이터라면, 이 정리에 의해 결합 분포의 모양이 찌그러지거나 뾰족해지는 등 고유한 특징이 남게 되어 방향 식별이 가능해집니다."
  },
  {
    "objectID": "posts/lecture/L16/part-05/index.html#linear-non-gaussian-acyclic-models-lingam",
    "href": "posts/lecture/L16/part-05/index.html#linear-non-gaussian-acyclic-models-lingam",
    "title": "[Causal Inference] 16. Causal Discovery (Part 5)",
    "section": "Linear Non-Gaussian Acyclic Models (LiNGAM)",
    "text": "Linear Non-Gaussian Acyclic Models (LiNGAM)\n\nMathematical Formulation\n\nLiNGAM은 전체 변수들의 관계를 선형 연립방정식 형태의 행렬로 모델링합니다.\n변수 벡터를 \\(x = [x_1, \\dots, x_p]^T\\),\n인접 행렬(Adjacency Matrix)을 \\(B\\),\n외생 잡음(Exogenous Noise) 벡터를 \\(e = [e_1, \\dots, e_p]^T\\)라고 할 때:\n\n\\[x = Bx + e\\]\n\n이 식을 \\(x\\)에 대해 정리하면 다음과 같이 표현할 수 있습니다.\n\n\\[(I - B)x = e \\implies x = (I - B)^{-1}e\\]\n\n여기서 가장 중요한 특징은, 변수들을 인과적 순서(Topological Order)대로 재배열하면 행렬 \\(B\\)가 순수 하삼각 행렬(Strictly Lower Triangular Matrix)이 된다는 점입니다.\n\n\n\nExample: 3-Variable DAG Representation\n\n이를 예시를 통해 살펴봅시다.\n다음과 같은 간단한 인과 구조 (\\(x_1 \\to x_2 \\to x_3\\), 그리고 \\(x_1 \\to x_3\\))를 가정해 봅시다.\n\n\n\n\nFigure 4: A simple DAG with 3 variables in topological order (\\(x_1, x_2, x_3\\)).\n\n\n\n변수들이 위상학적 순서(Topological Order)인 \\(x_1, x_2, x_3\\) 순으로 정렬되어 있다고 가정하고, 다음과 같은 인과 구조를 생각해 봅시다.\n\n\\(x_1 \\rightarrow x_2\\)\n\\(x_1 \\rightarrow x_3\\)\n\\(x_2 \\rightarrow x_3\\)\n\n이 그래프를 구조방정식(Structural Equation)으로 하나씩 풀어서 쓰면 다음과 같습니다.\n\n\\(x_1\\): 부모 변수가 없으므로, 외생 잡음(Error term)만으로 결정됩니다. \\[x_1 = e_1\\]\n\n\n\\(x_2\\): \\(x_1\\)의 영향을 받습니다. \\[x_2 = b_{21}x_1 + e_2\\]\n\n\n\\(x_3\\): \\(x_1\\)과 \\(x_2\\) 모두의 영향을 받습니다. \\[x_3 = b_{31}x_1 + b_{32}x_2 + e_3\\]\n\n이제 이 연립방정식을 행렬 (\\(x = Bx + e\\)) 형태로 한 번에 묶어서 표현해 보겠습니다.\n\n\\[\n\\underbrace{\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}}_{x} =\n\\underbrace{\\begin{bmatrix} 0 & 0 & 0 \\\\ b_{21} & 0 & 0 \\\\ b_{31} & b_{32} & 0 \\end{bmatrix}}_{B}\n\\underbrace{\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}}_{x} +\n\\underbrace{\\begin{bmatrix} e_1 \\\\ e_2 \\\\ e_3 \\end{bmatrix}}_{e}\n\\]\n\n행렬 \\(B\\)의 구조적 특징 (Strictly Lower Triangular):\n대각 성분 0 (\\(B_{ii} = 0\\)): 자기 자신에게 영향을 주는 \\(x_i \\to x_i\\) (Self-loop)가 없음을 의미합니다.\n대각 윗부분 0 (\\(B_{ij} = 0 \\text{ where } j &gt; i\\)): 순서상 뒤에 있는 변수가 앞에 있는 변수의 원인이 되지 않음(No Cycle)을 의미합니다.\n이러한 형태 덕분에 \\(\\det(I-B) = 1\\)이 되어, \\(I-B\\)는 항상 역행렬을 가집니다.\n\n\n\nThe ICA Connection (The “Trick”)\n\n위에서 유도한 식 \\(x = (I - B)^{-1}e\\)를 자세히 보면, 이는 신호 처리 분야의 독립 성분 분석(Independent Component Analysis, ICA) 문제와 수학적으로 완전히 동일한 구조입니다.\n\n\n1. ICA와의 매핑 (Mapping)\n\nICA는 관측된 신호 \\(x\\)가 “서로 독립인 원천 신호 \\(s\\)”들의 선형 결합(\\(x = As\\))으로 이루어져 있다고 가정하고, 역으로 \\(s\\)와 \\(A\\)를 찾아냅니다.\nLiNGAM은 이 프레임워크를 인과추론에 그대로 가져옵니다.\n\n\n\n\n\n\n\n\n\nICA Concept\nLiNGAM Mapping\n의미\n\n\n\n\nObserved Signals (\\(x\\))\nData (\\(x\\))\n우리가 관측한 변수들 (원인과 결과가 섞여 있음)\n\n\nSource Signals (\\(s\\))\nError Terms (\\(e\\))\n외생 잡음 (서로 독립이어야 함, \\(e_i \\perp e_j\\))\n\n\nMixing Matrix (\\(A\\))\n\\((I - B)^{-1}\\)\n원인이 결과에 섞여 들어가는 인과적 메커니즘\n\n\n\n\n\n2. ICA의 한계와 LiNGAM의 해결책 (Identifiability)\n\n일반적인 ICA 알고리즘(FastICA 등)을 돌리면 Unmixing Matrix \\(W\\) (즉, \\(A\\)의 역행렬)를 얻게 됩니다.\n이상적으로는 \\(W\\)가 \\(I-B\\)와 같아야 합니다 (\\(e = Wx\\)).\n일반적인 ICA 알고리즘을 통해 얻은 Unmixing Matrix \\(W\\)는 \\(I-B\\)와 유사하지만, 두 가지 고유한 불확정성(Indeterminacy)이 존재합니다.\n\n순서 불확정 (Permutation): 원천 신호의 순서를 알 수 없습니다. (\\(e_1, e_2\\)의 순서가 바뀔 수 있음) \\[W_{ICA} = P \\cdot (I-B)\\]\n\n\n스케일 불확정 (Scaling): 신호의 크기를 알 수 없습니다. (\\(e_1\\)인지 \\(2e_1\\)인지 모름) \\[W_{ICA} = S \\cdot (I-B)\\]\n\nLiNGAM은 “DAG 구조”라는 제약을 이용해 이 문제를 해결합니다.\n\\(B\\)가 Strictly Lower Triangular Matrix가 되도록 행과 열을 재배열(Permutation)하고, 대각 성분이 1이 되도록 크기(Scaling)를 조정합니다.\n이 과정을 통해 유일한 인과 그래프 \\(B\\)를 복원할 수 있습니다.\n\n\n왜 비정규분포(Non-Gaussian)여야 하나요?\n\n만약 데이터(오차항)가 정규분포(Gaussian)를 따른다면, Mixing Matrix \\(A\\)를 회전(Rotation)시켜도 분포가 똑같은 원 모양이라 구별할 수 없습니다.\n데이터가 찌그러져 있는 등 비정규적 특징이 있어야만 축을 찾아서 역산을 수행할 수 있습니다. 이것이 LiNGAM의 핵심 가정입니다.\n\n\n\n\n3. Concrete Example (Matrix Calculation)\n\n이해를 돕기 위해 2변수 인과관계 \\(X_1 \\to X_2\\)를 가정해 봅시다.\n\nTrue Model: \\[\n  \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} =\n  \\underbrace{\\begin{bmatrix} 1 & 0 \\\\ 0.5 & 1 \\end{bmatrix}}_{(I-B)^{-1}}\n  \\begin{bmatrix} e_1 \\\\ e_2 \\end{bmatrix}\n  \\]\n\n\n여기서 \\(B = \\begin{bmatrix} 0 & 0 \\\\ 0.5 & 0 \\end{bmatrix}\\) 입니다.\n\n\nICA Result (\\(W_{ICA}\\)):\n\n\nICA 알고리즘은 순서와 스케일이 뒤섞인 행렬을 반환할 수 있습니다. 예를 들어: \\[\n  W_{ICA} \\approx \\begin{bmatrix} -0.5 & 1 \\\\ 2 & 0 \\end{bmatrix}\n  \\]\n이 상태로는 \\(I-B\\) 처럼 보이지 않습니다.\n\n\nPermutation & Scaling (LiNGAM Step):\n\n\nRow Permutation: 두 번째 행(\\([2, 0]\\))이 \\(x_1\\)에 해당하고, 첫 번째 행(\\([-0.5, 1]\\))이 \\(x_2\\)에 해당하도록 순서를 바꿉니다. \\[\\rightarrow \\begin{bmatrix} 2 & 0 \\\\ -0.5 & 1 \\end{bmatrix}\\]\nScaling: 대각 성분을 1로 맞추기 위해 첫 행을 2로 나눕니다. \\[\\rightarrow \\begin{bmatrix} 1 & 0 \\\\ -0.5 & 1 \\end{bmatrix}\\]\n이제 이 행렬은 \\(I - B\\) 형태가 되었습니다.\n여기서 \\(B\\)를 추출하면 \\(b_{21} = 0.5\\), 즉 \\(X_1 \\to X_2\\) 관계를 찾아낼 수 있습니다.\n\n\n\n\n\nLiNGAM Algorithm Steps\n\nShimizu (2006)가 제안한 LiNGAM 알고리즘의 핵심 단계는 다음과 같습니다:\n\n\nICA Execution: 데이터 행렬 \\(X\\)에 대해 ICA를 수행하여 \\(X = W_{ICA}^{-1} S\\) 꼴의 분해를 얻습니다. 여기서 \\(S\\)는 독립 성분(오차항 추정치)입니다.\n\n\nPermutation & Scaling: ICA는 성분의 순서(Permutation)와 스케일(Scaling)을 결정하지 못하는 불확정성이 있습니다.\n\n\n\\(W_{ICA}\\)의 행을 재배열(Permute)하고 스케일링하여, 대각 성분이 모두 0이 아닌 행렬 \\(\\tilde{W}\\)를 만듭니다.\nLiNGAM의 가정(\\(x = Bx + e\\))에 맞추기 위해, \\(I - B\\) 형태가 되도록 정규화합니다.\n\n\nRecover B: 최종적으로 \\(B = I - W_{final}\\)을 계산합니다.\n\n\nCausal Order: \\(B\\)가 하삼각행렬(Lower Triangular)에 가깝도록 변수 순서를 재배열하면 인과 순서(Causal Order)를 얻을 수 있습니다.\n\n\n\n\n\n\nFigure 5: LiNGAM의 도식적 이해. 관측된 변수 \\(x_1, x_2, x_3\\)는 독립적인 에러 \\(e_1, e_2, e_3\\)들의 선형 결합으로 표현된다. ICA를 통해 섞여 있는 에러들을 분리해냄으로써 원래의 인과 구조인 화살표 방향을 역추적한다."
  },
  {
    "objectID": "posts/lecture/L16/part-05/index.html#score-matching-and-leaf-identification",
    "href": "posts/lecture/L16/part-05/index.html#score-matching-and-leaf-identification",
    "title": "[Causal Inference] 16. Causal Discovery (Part 5)",
    "section": "Score Matching and Leaf Identification",
    "text": "Score Matching and Leaf Identification\n\nMontagna et al. (2023)은 Score Matching 기법을 사용하여 잎 노드(Leaf node, 자식이 없는 노드)를 식별하는 방법을 제안했습니다.\nKey Idea: ANM \\(X_i = f_i(PA_i) + N_i\\) 에서, 어떤 노드 \\(X_i\\)가 Leaf라면, 해당 노드의 잡음 \\(N_i\\)는 해당 노드의 점수 함수(Score function, \\(\\nabla \\log p(X)\\))와 직접적인 관련이 있습니다.\n구체적으로, \\(X_i\\)가 Leaf일 필요충분조건은 다음과 관련된 기댓값이 0이 되는 것입니다: \\[X_i \\text{ is a leaf} \\iff \\mathbb{E}[(h^*(R_i) - s_i(X))^2] = 0\\]\n\n여기서 \\(s_i(X)\\)는 Score function의 성분이며, \\(R_i\\)는 회귀 잔차입니다.\n\n이 성질을 이용하면 전체 그래프에서 Leaf를 하나씩 찾아 제거(peeling)해 나가는 방식으로 인과 순서(Topological Sort)를 복원할 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L17/part-01/index.html",
    "href": "posts/lecture/L17/part-01/index.html",
    "title": "[Causal Inference] 17. Causal Data Science (Part 1)",
    "section": "",
    "text": "현대의 데이터 과학(Data Science)은 수많은 데이터를 다루지만, 이 데이터들이 모두 동일한 가치를 지니거나 같은 방식으로 생성된 것은 아닙니다.\n“All data is not created equal”이라는 명제는 Causal Data Science의 가장 핵심적인 출발점입니다.\n우리가 현실에서 마주하는 데이터는 거의 예외 없이 다음과 같은 문제점들을 안고 있습니다:\n\n\n상이한 실험 조건 (Different Experimental Conditions): 관찰 데이터(Observational)인가, 실험 데이터(Experimental)인가?\n\n\n상이한 모집단 (Different Underlying Populations): 데이터가 수집된 집단이 우리가 알고자 하는 대상과 같은가?\n\n\n비무작위 표본 추출 (Non-random Sampling): 샘플링 과정에서 편향(Bias)이 발생했는가?\n\n\n비무작위 처치 할당 (Non-random Treatment Assignment): 처치(Treatment)가 무작위로 배정되었는가, 아니면 선택 편향이 있는가?\n\n\n측정되지 않은 변수 (Unmeasured Variables): 인과 관계를 파악하는 데 필요한 변수가 누락되었는가?\n\n\n이러한 문제들로 인해 수집된 데이터는 “지저분(messy)”하며, 우리가 추론하고자 하는 Target과 완벽하게 일치하는 경우는 매우 드뭅니다.\nCausal Data Science의 목표는 이러한 이질적인(Heterogeneous) 데이터셋들을 결합하여 과학적이고 원칙적인(principled) 방법으로 인과 추론을 수행하는 것입니다."
  },
  {
    "objectID": "posts/lecture/L17/part-01/index.html#genetics-transportability",
    "href": "posts/lecture/L17/part-01/index.html#genetics-transportability",
    "title": "[Causal Inference] 17. Causal Data Science (Part 1)",
    "section": "2.1. Genetics (Transportability)",
    "text": "2.1. Genetics (Transportability)\n\n쥐(Rats)를 대상으로 한 실험 연구에서 특정 물질이 발암성(Carcinogenic)이라는 결과가 나왔다고 가정해 봅시다.\n우리의 질문은 다음과 같습니다.\n\n“이 결과가 인간에게도 그대로 적용될 것인가?”\n\n이는 동물 모델에서 얻은 지식을 인간이라는 다른 모집단으로 옮길 수 있는지(Transportability)의 문제입니다."
  },
  {
    "objectID": "posts/lecture/L17/part-01/index.html#advertisement-transfer-learning",
    "href": "posts/lecture/L17/part-01/index.html#advertisement-transfer-learning",
    "title": "[Causal Inference] 17. Causal Data Science (Part 1)",
    "section": "2.2. Advertisement (Transfer Learning)",
    "text": "2.2. Advertisement (Transfer Learning)\n\n어떤 회사에서 ’제품 A’의 판매량을 높이기 위해 다양한 광고 전략의 효과를 분석했습니다. 이제 새로운 ’제품 B’를 출시하려고 합니다.\n\n“제품 A에서 얻은 데이터를 제품 B의 광고 전략 수립에 활용할 수 있는가?”\n\n이는 기존 도메인의 지식을 새로운 도메인으로 전이(Transfer)하는 문제입니다."
  },
  {
    "objectID": "posts/lecture/L17/part-01/index.html#robotics-domain-adaptation",
    "href": "posts/lecture/L17/part-01/index.html#robotics-domain-adaptation",
    "title": "[Causal Inference] 17. Causal Data Science (Part 1)",
    "section": "2.3. Robotics (Domain Adaptation)",
    "text": "2.3. Robotics (Domain Adaptation)\n\n캘리포니아 사막에서 암석을 채굴하도록 훈련된 화성 탐사 로봇(Rover)이 있습니다.\n\n“지구에서 학습한 내용을 바탕으로, 화성에서의 비용 소모적인 탐색을 최소화할 수 있는가?”\n\n환경이 급격히 변화했을 때, 에이전트가 어떻게 적응해야 하는지에 대한 문제입니다."
  },
  {
    "objectID": "posts/lecture/L17/part-01/index.html#classic-causal-inference-engine",
    "href": "posts/lecture/L17/part-01/index.html#classic-causal-inference-engine",
    "title": "[Causal Inference] 17. Causal Data Science (Part 1)",
    "section": "4.1. Classic Causal Inference Engine",
    "text": "4.1. Classic Causal Inference Engine\n\n전통적인 접근법(예: Pearl의 프레임워크)은 단일 모집단 내에서의 식별(Identifiability) 문제에 집중했습니다.\n\n\nQuery: \\(P(y|do(x))\\)\n\n\nCausal Diagram (Knowledge): 변수들 간의 인과 구조 (DAG).\n\n\nData: 관찰된 데이터 분포 \\(P(V)\\).\n\n\nEngine: 주어진 다이어그램에서 데이터만으로 쿼리를 계산할 수 있는지 판별(Yes/No)하고, 가능하다면 추정식(Estimand)을 도출."
  },
  {
    "objectID": "posts/lecture/L17/part-01/index.html#causal-data-science-framework",
    "href": "posts/lecture/L17/part-01/index.html#causal-data-science-framework",
    "title": "[Causal Inference] 17. Causal Data Science (Part 1)",
    "section": "4.2. Causal Data Science Framework",
    "text": "4.2. Causal Data Science Framework\n\n하지만 현실은 더 복잡합니다.\n우리가 목표로 하는 Target Population (\\(\\Pi^*\\))과 데이터가 수집되는 Source Populations (a, b, c, …)이 다르기 때문입니다 [cite: 104-135].\n\n\n\n\nFigure 2: Causal Data Science의 전체 그림. 중앙의 Target Population(US)에 대한 인과 효과를 추정하고 싶지만, 가용 데이터는 구조적으로 상이한 여러 지역(NY, LA, Boston, Texas 등)에서 수집되었다. 각 지역은 Causal Graph 상에서 화살표가 추가되거나(Selection Bias), 노드가 회색으로 처리되는(Missingness) 등의 구조적 차이를 보인다.\n\n\n\n위 그림(Figure 2)에서 볼 수 있듯이, 각 소스 데이터는 구조적 차이를 가집니다.\n\nTarget (US): \\(X \\rightarrow W \\rightarrow Y\\)와 같은 기본 구조.\nNY: \\(W\\)가 측정되지 않음 (Grey Node).\nLA: \\(Z\\)가 선택 편향의 원인이 됨 (Selection Node \\(S\\)의 개입).\nUtah: \\(Z\\)가 \\(X\\)에 영향을 주지 않는 실험적 환경(Randomized).\n\nCausal Data Science의 목표는 이러한 Multiple, Heterogeneous Datasets를 융합(Fusion)하여 Automated Scientist처럼 타겟 질의에 답하는 것입니다."
  },
  {
    "objectID": "posts/lecture/L17/part-01/index.html#task-1-causal-inference-from-observational-studies",
    "href": "posts/lecture/L17/part-01/index.html#task-1-causal-inference-from-observational-studies",
    "title": "[Causal Inference] 17. Causal Data Science (Part 1)",
    "section": "Task 1: Causal Inference (from Observational Studies)",
    "text": "Task 1: Causal Inference (from Observational Studies)\n\nTransition: \\((d_1, \\text{Obs}, d_3, d_4) \\longrightarrow (d_1, do(x), d_3, d_4)\\)\nDescription: 가장 고전적인 인과 추론의 영역입니다. 관찰 데이터(\\(P(y|x)\\))로부터 실험적 결론(\\(P(y|do(x))\\))을 도출합니다. 교란 요인(Confounding Bias)을 통제하는 것이 핵심입니다."
  },
  {
    "objectID": "posts/lecture/L17/part-01/index.html#task-2-experimental-inference-generalized-ivs",
    "href": "posts/lecture/L17/part-01/index.html#task-2-experimental-inference-generalized-ivs",
    "title": "[Causal Inference] 17. Causal Data Science (Part 1)",
    "section": "Task 2: Experimental Inference (Generalized IVs)",
    "text": "Task 2: Experimental Inference (Generalized IVs)\n\nTransition: \\((d_1, do(z), d_3, d_4) \\longrightarrow (d_1, do(x), d_3, d_4)\\)\nDescription: 우리가 원하는 것은 \\(X\\)에 대한 개입(\\(do(x)\\))의 효과인데, 실제 데이터는 도구 변수(Instrumental Variable, \\(Z\\))에 대한 개입(\\(do(z)\\))만 있는 경우입니다. 불완전한 순응(Imperfect Compliance) 문제를 다룹니다."
  },
  {
    "objectID": "posts/lecture/L17/part-01/index.html#task-3-sampling-selection-bias",
    "href": "posts/lecture/L17/part-01/index.html#task-3-sampling-selection-bias",
    "title": "[Causal Inference] 17. Causal Data Science (Part 1)",
    "section": "Task 3: Sampling Selection Bias",
    "text": "Task 3: Sampling Selection Bias\n\nTransition: \\((d_1, d_2, \\text{Select}(Age), d_4) \\longrightarrow (d_1, d_2, \\{\\}, d_4)\\)\nDescription: 데이터가 특정 조건(예: 나이, 소득)에 따라 편향되게 수집되었을 때, 이를 전체 모집단(Random Sample)의 분포로 복원하는 문제입니다."
  },
  {
    "objectID": "posts/lecture/L17/part-01/index.html#task-4-transportability-external-validity",
    "href": "posts/lecture/L17/part-01/index.html#task-4-transportability-external-validity",
    "title": "[Causal Inference] 17. Causal Data Science (Part 1)",
    "section": "Task 4: Transportability (External Validity)",
    "text": "Task 4: Transportability (External Validity)\n\nTransition: \\((\\text{Bonobos}, d_2, d_3, d_4) \\longrightarrow (\\text{Humans}, d_2, d_3, d_4)\\)\nDescription: 소스 모집단(예: 보노보 원숭이, LA)에서 얻은 지식을 타겟 모집단(예: 인간, US 전체)으로 이송(Transport)하는 문제입니다. 환경적 조건의 차이를 극복해야 합니다."
  },
  {
    "objectID": "posts/lecture/L17/part-01/index.html#summary-of-dimensions",
    "href": "posts/lecture/L17/part-01/index.html#summary-of-dimensions",
    "title": "[Causal Inference] 17. Causal Data Science (Part 1)",
    "section": "Summary of Dimensions",
    "text": "Summary of Dimensions\n\n\n\nDimension\nProblem Domain\nKey Challenge\n\n\n\n\n1. Experimental Cond.\nCausal Identification\nConfounding Bias\n\n\n2. Environmental Cond.\nTransportability\nExternal Validity\n\n\n3. Sampling Cond.\nSelection Bias\nSample Selection\n\n\n4. Responding Cond.\nMissing Data\nRecovering from Missingness\n\n\n\n\n과거의 문헌들은 이 문제들을 각각 고립된 상태에서 특수한 모수적(parametric) 가정하에 다루었습니다.\n하지만 Causal Data Science는 이 4가지 차원이 현실에서 복합적으로 나타난다는 점을 인식하고, 이를 통합적으로 해결하기 위한 일반화된 알고리즘과 조건을 연구합니다."
  },
  {
    "objectID": "posts/lecture/L17/part-03/index.html",
    "href": "posts/lecture/L17/part-03/index.html",
    "title": "[Causal Inference] 17. Causal Data Science (Part 3)",
    "section": "",
    "text": "데이터 과학과 인과 추론에서 가장 빈번하면서도 어려운 질문 중 하나는 “어떤 환경(Source)에서 얻은 지식을 다른 환경(Target)에 적용할 수 있는가?”입니다.\n예를 들어:\n\n미국의 교육 정책 효과를 한국에 그대로 적용할 수 있는가?\nLA에서 수행된 임상 시험 결과를 NYC의 환자들에게 적용할 수 있는가?\n통제된 실험실 환경(Lab)의 로봇 학습 데이터를 실제 도로(Real-World)에 쓸 수 있는가?\n\n이 문제는 사회과학에서는 외부 타당성(External Validity), 통계학에서는 일반화(Generalizability), 머신러닝에서는 도메인 적응(Domain Adaptation) 등으로 불려왔습니다.\nCausal Data Science는 이 문제를 Transportability(이송 가능성)라는 수학적 프레임워크로 정의하고, Selection Diagram이라는 도구를 통해 데이터가 언제, 어떻게 이송 가능한지를 공식화합니다."
  },
  {
    "objectID": "posts/lecture/L17/part-03/index.html#trivial-vs.-non-trivial-cases",
    "href": "posts/lecture/L17/part-03/index.html#trivial-vs.-non-trivial-cases",
    "title": "[Causal Inference] 17. Causal Data Science (Part 3)",
    "section": "2.1. Trivial vs. Non-Trivial Cases",
    "text": "2.1. Trivial vs. Non-Trivial Cases\n\n가장 단순한 가정(\\(H_0\\))은 Source와 Target의 모든 조건이 동일하다는 것입니다.\n이 경우 결과는 자명하게 이식 가능합니다(Trivially Transportable).\n하지만 현실(\\(H_a\\))에서는 두 도메인 간에 차이가 존재합니다.\n\n분포의 차이: \\(f_z \\neq f^*_z\\) (예: LA와 NYC의 연령 분포가 다름)\n메커니즘의 차이: \\(f_y \\neq f^*_y\\) (예: 동일한 치료제라도 인종적 특성에 따라 반응률이 다름)\n\n\n\n\n\nFigure 1: Source Domain과 Target Domain의 차이. 모든 구조적 방정식(Structural Equations) f가 동일하다면(H0) 문제는 간단하지만, 현실(Ha)에서는 변수들의 분포나 메커니즘이 다르다. 이를 ’Spectrum’으로 표현할 수 있다.\n\n\n\n위 그림(Figure 1)은 Source와 Target 사이에 구조적 불일치가 존재할 때, 단순한 데이터 결합이 불가능함을 보여줍니다."
  },
  {
    "objectID": "posts/lecture/L17/part-03/index.html#definition",
    "href": "posts/lecture/L17/part-03/index.html#definition",
    "title": "[Causal Inference] 17. Causal Data Science (Part 3)",
    "section": "Definition",
    "text": "Definition\n\nSelection Diagram은 기존의 Causal Graph \\(G\\)에 Selection Node (\\(S\\))를 추가한 확장된 그래프입니다.\nSelection Node (Yellow Square): 특정 변수의 메커니즘이 도메인 간에 차이가 있음을 나타냅니다.\n만약 변수 \\(V\\)에 대해 \\(f_V \\neq f^*_V\\)라면, \\(S \\to V\\) 화살표를 추가합니다.\n반대로, \\(S\\)가 가리키지 않는 변수는 도메인 간에 메커니즘이 동일(Invariant)하다고 가정합니다.\n\n\n\n\nFigure 2: Selection Diagram의 예시. 상단 그래프(G)는 일반적인 인과 그래프이고, 하단 우측 그래프(D)는 Selection Diagram이다. Z와 Y에 노란색 사각형(Selection Node)이 화살표를 보내고 있다. 이는 Z의 분포와 Y를 결정하는 메커니즘이 도메인 간에 다르다는 것을 의미한다. 반면 X와 W는 Selection Node가 없으므로 두 도메인에서 동일한 메커니즘을 가진다."
  },
  {
    "objectID": "posts/lecture/L17/part-03/index.html#the-general-theorem-reduction-to-calculus",
    "href": "posts/lecture/L17/part-03/index.html#the-general-theorem-reduction-to-calculus",
    "title": "[Causal Inference] 17. Causal Data Science (Part 3)",
    "section": "4.1. The General Theorem: Reduction to Calculus",
    "text": "4.1. The General Theorem: Reduction to Calculus\n\nPearl & Bareinboim은 Transportability 문제를 해결하기 위한 일반적인 정리를 제시했습니다.\n\n\nTheorem: A causal relation \\(Q\\) is transportable from \\(\\Pi\\) to \\(\\Pi^*\\) if and only if there exists a do-calculus reduction of \\(Q(\\Pi^*)\\) to an estimand that is a function of the observed distributions.\n즉, 타겟 도메인의 인과 효과 \\(Q\\)가 관측 가능한 분포들의 함수로 변환(Reduction)될 수 있을 때만, 해당 효과는 이전(Transportable) 가능합니다.\n\n\n\n\nFigure 3: Transportability의 일반화된 유도 과정. Selection Node(노란색 사각형)가 \\(Z\\)에 영향을 미치는 구조에서 \\(P^*(y|do(x))\\)를 유도하고 있다.\n\n\n\nDerivation Step-by-Step\n\n위의 그래프(DAG)는 Selection Node(■)가 \\(Z\\)에만 영향을 미치고(\\(S \\to Z\\)), \\(Z \\to W \\to Y\\)의 경로를 가지는 상황을 보여줍니다.\n이 경우 타겟 도메인의 효과 \\(P^*(y|do(x))\\)는 다음과 같이 유도됩니다.\n\nDefinition of Target Quantity:\n\n\n타겟 도메인(\\(\\Pi^*\\))에서의 효과는 Selection Node(\\(S\\))가 켜진 조건부 확률(\\(S=\\blacksquare\\))과 같습니다. \\[Q = P^*(y|do(x)) = P(y|do(x), S)\\]\n\n\nProbability Axioms (Conditioning on W):\n\n\n중간 변수 \\(W\\)에 대해 전체 확률의 법칙을 적용합니다. \\[= \\sum_{w} P(y|do(x), S, w)P(w|do(x), S)\\]\n\n\nRule 1 & Graph Properties (Removal of S):\n\n\n그래프에서 \\(W\\)가 주어졌을 때, \\(Y\\)는 Selection Node(\\(S\\))와 분리(d-separated)됩니다(\\(S \\to Z \\to W \\to Y\\)).\n따라서 첫 번째 항에서 \\(S\\)를 제거할 수 있습니다. \\[= \\sum_{w} P(y|do(x), w)P(w|do(x), S)\\]\n\n\nRule 3 (Removal of do(x)):\n\n\n\\(X\\)에 대한 개입(\\(do(x)\\))은 \\(W\\)에 영향을 주지 않습니다(그래프상 \\(X\\)와 \\(W\\) 사이의 경로는 \\(Z\\)를 통하거나 교란 경로뿐인데, 개입 시 차단됨).\n따라서 두 번째 항에서 \\(do(x)\\)를 제거할 수 있습니다. \\[= \\sum_{w} P(y|do(x), w)P(w|S)\\]\n\n\nFinal Transport Formula:\n\n\n\\(P(w|S)\\)는 타겟 도메인에서의 \\(W\\) 분포인 \\(P^*(w)\\)와 같습니다. \\[= \\sum_{w} P(y|do(x), w)P^*(w)\\]\n\n해석: 이 식은 타겟 도메인에서 \\(Y\\)나 \\(Z\\)에 대한 실험을 할 필요 없이, 소스 도메인의 실험 결과(\\(P(y|do(x), w)\\))와 타겟 도메인의 관측 데이터(\\(P^*(w)\\))만 결합하면 타겟의 인과 효과를 계산할 수 있음을 보여줍니다."
  },
  {
    "objectID": "posts/lecture/L17/part-03/index.html#specific-cases-derived-from-graph-structure",
    "href": "posts/lecture/L17/part-03/index.html#specific-cases-derived-from-graph-structure",
    "title": "[Causal Inference] 17. Causal Data Science (Part 3)",
    "section": "4.2. Specific Cases derived from Graph Structure",
    "text": "4.2. Specific Cases derived from Graph Structure\n\n이제 그래프 구조(Causal Story)에 따라 공식이 어떻게 달라지는지 구체적인 세 가지 사례를 살펴보겠습니다.\n\n\n\n\nFigure 4: 세 가지 다른 인과 구조에 따른 Transportability. (a) Z가 교란 변수(Confounder)인 경우, (b) Z가 결과의 결과(Outcome’s outcome)인 경우, (c) Z가 매개 변수(Mediator)인 경우. 각 경우마다 Selection Node(노란색 사각형)의 위치가 다르며, 이에 따라 유도되는 공식도 다르다.\n\n\n\nCase (a): Z represents Age (Confounder)\n\nScenario: \\(Z\\)(나이)는 \\(X\\)(치료)와 \\(Y\\)(결과) 모두에 영향을 미치는 교란 요인입니다. 나이 분포(\\(P(z)\\))는 도메인마다 다릅니다(\\(S \\to Z\\)).\nFormula: \\[P^*(y|do(x)) = \\sum_{z} P(y|do(x), z) P^*(z)\\]\nInterpretation: Source에서 \\(Z\\)별 인과 효과(\\(P(y|do(x),z)\\))를 구한 뒤, 이를 Target의 나이 분포(\\(P^*(z)\\))에 맞춰 가중 평균(Re-weighting)합니다. 이것이 표준적인 Adjustment Formula입니다.\n\n\n\nCase (b): Z represents Language Skill (Proxy)\n\nScenario: \\(Z\\)(언어 능력)는 \\(Y\\)의 결과물일 뿐, \\(X\\)나 \\(Y\\)의 원인이 아닙니다. \\(Z\\)의 메커니즘이 도메인마다 다릅니다.\nFormula: \\[P^*(y|do(x)) = P(y|do(x))\\]\nInterpretation: \\(Z\\)는 인과 경로에 개입하지 않으므로, \\(Z\\)의 차이는 \\(X \\to Y\\) 효과에 영향을 주지 않습니다. 즉, Source의 결과를 그대로 Target에 적용할 수 있습니다.\n\n\n\nCase (c): Z represents Bio-marker (Mediator)\n\nScenario: \\(Z\\)는 \\(X\\)와 \\(Y\\) 사이의 매개 변수입니다. \\(X\\)가 \\(Z\\)에 미치는 영향은 동일하지만, \\(Z\\)의 기저 분포나 측정 방식이 다를 수 있습니다(\\(S \\to Z\\)).\nFormula: \\[P^*(y|do(x)) = \\sum_{z} P(y|do(x), z) P^*(z|x)\\]\nInterpretation: \\(X \\to Z\\) 메커니즘이 다르다면, Target 도메인에서의 조건부 확률 \\(P^*(z|x)\\) 정보를 사용하여 보정해야 합니다."
  },
  {
    "objectID": "posts/lecture/L17/part-03/index.html#input-output",
    "href": "posts/lecture/L17/part-03/index.html#input-output",
    "title": "[Causal Inference] 17. Causal Data Science (Part 3)",
    "section": "5.1. Input & Output",
    "text": "5.1. Input & Output\n\nINPUT: Selection Node(노란색 사각형, \\(\\blacksquare\\))가 표시된 인과 그래프(Annotated Causal Graph).\nOUTPUT:\n\n판단(Decision): 타겟 도메인의 인과 효과 \\(P^*(y|do(x))\\)가 이전을 통해 식별 가능한가(Transportable)?\n공식(Formula): 식별 가능하다면, 다음 두 가지 데이터를 결합한 수식:\n\n소스 도메인의 실험 데이터 (Measurements from Source experiments)\n타겟 도메인의 관측 데이터 (Measurements from Target observations)"
  },
  {
    "objectID": "posts/lecture/L17/part-03/index.html#the-logic-handling-non-identifiable-factors",
    "href": "posts/lecture/L17/part-03/index.html#the-logic-handling-non-identifiable-factors",
    "title": "[Causal Inference] 17. Causal Data Science (Part 3)",
    "section": "5.2. The Logic: Handling Non-Identifiable Factors",
    "text": "5.2. The Logic: Handling Non-Identifiable Factors\n\n이 알고리즘의 핵심은 전체 문제를 Q-factor(C-component) 단위로 쪼개고, 각 조각을 어디서 가져올지 결정하는 것입니다.\n\n\nKey Logic: “Any \\(Q\\)-factors non-identifiable from \\(P^*(\\mathbf{V})\\) should be identified from experiments in the source domain. This corresponds to checking no \\(\\blacksquare\\) points to the variables in the non-identified \\(Q\\)-factor!”\n\n\n\nTarget Priority:\n\n\n먼저 타겟 도메인의 관측 데이터 \\(P^*(\\mathbf{V})\\)만으로 계산 가능한 요소인지 확인합니다. 가능하다면 \\(P^*\\)를 그대로 사용합니다.\n\n\nSource Fallback:\n\n\n타겟 데이터만으로 식별 불가능한(Non-identifiable) 요소가 있다면, 소스 도메인의 실험 결과(\\(P(v|do(x))\\))를 가져와야 합니다.\n\n\nTransportability Condition:\n\n\n이때 소스 데이터를 가져오기 위해서는 “해당 요소에 영향을 주는 Selection Node(\\(\\blacksquare\\))가 없어야 한다”는 조건이 붙습니다.\n만약 Selection Node가 가리키고 있다면, 메커니즘이 다르다는 뜻이므로 소스 데이터를 타겟에 대입할 수 없습니다. (즉, Transportable 하지 않음)"
  },
  {
    "objectID": "posts/lecture/L17/part-03/index.html#derivation-example",
    "href": "posts/lecture/L17/part-03/index.html#derivation-example",
    "title": "[Causal Inference] 17. Causal Data Science (Part 3)",
    "section": "5.3. Derivation Example",
    "text": "5.3. Derivation Example\n\n하단의 수식은 이 알고리즘을 적용한 결과입니다. 그래프의 각 부분(변수)이 어떻게 처리되었는지 분석해 봅시다.\n\n\\[\nP^*(y|do(x)) = \\sum_{z} P(y|do(x),z) \\sum_{w} P^*(z|w) \\sum_{t} P(w|do(x),t)P^*(t)\n\\]\n\n이 식은 크게 네 부분으로 나뉩니다.\n\n\\(P^*(t)\\) (Target Data):\n\n\n변수 \\(T\\)에는 Selection Node가 없습니다. 또한 \\(T\\)는 외생 변수이므로 타겟 도메인의 분포를 그대로 사용합니다.\n\n\n\\(P(w|do(x),t)\\) (Source Experiment):\n\n\n변수 \\(W\\)를 구하는 부분입니다. \\(W\\)에는 직접적인 Selection Node가 붙어있지 않으므로, 소스 도메인의 실험 결과(\\(X\\)에 개입했을 때의 \\(W\\))를 가져와서 사용합니다.\n\n\n\\(P^*(z|w)\\) (Target Observation):\n\n\n변수 \\(Z\\)에는 Selection Node(\\(\\blacksquare \\to Z\\))가 붙어 있습니다. 즉, 소스와 타겟 간에 메커니즘 차이가 있습니다.\n따라서 소스 데이터를 쓰면 안 됩니다. 다행히 \\(Z\\)는 \\(W\\)가 주어졌을 때 타겟 도메인의 관측 데이터(\\(P^*\\))만으로 식별이 가능하므로, \\(P^*(z|w)\\)를 직접 측정하여 사용합니다.\n\n\n\\(P(y|do(x),z)\\) (Source Experiment):\n\n\n결과 변수 \\(Y\\)에는 Selection Node가 없습니다. 따라서 소스 도메인에서 \\(X\\)에 개입했을 때 \\(Z\\)에 따른 \\(Y\\)의 반응을 측정한 실험 데이터를 그대로 가져옵니다.\n\n결론:\n\n이 공식은 타겟 도메인에서 직접 실험을 하지 않고도(\\(do(x)\\) in Target), 소스의 실험 결과(1, 4번 항)와 타겟의 관측 결과(2, 3번 항)를 정교하게 조립하여 타겟의 인과 효과를 계산해 낸 것입니다."
  },
  {
    "objectID": "posts/lecture/L17/part-03/index.html#motivation-the-la-nyc-example",
    "href": "posts/lecture/L17/part-03/index.html#motivation-the-la-nyc-example",
    "title": "[Causal Inference] 17. Causal Data Science (Part 3)",
    "section": "Motivation: The LA & NYC Example",
    "text": "Motivation: The LA & NYC Example\n\nGoal: 타겟 도메인(Target)에서의 인과 효과 \\(Q = P^*(y|do(x))\\)를 구하고 싶습니다.\nProblem: 그 어떤 도메인도 타겟과 완벽하게 일치하지 않습니다.\n\nSource A (LA, \\(\\Pi^a\\)): \\(X\\)와 \\(Y\\)에 Selection Node(\\(\\blacksquare\\))가 있습니다. 즉, \\(Y\\)가 생성되는 메커니즘이 타겟과 다릅니다. (하지만 \\(Z\\)는 타겟과 동일)\nSource B (NYC, \\(\\Pi^b\\)): \\(X\\)와 \\(Z\\)에 Selection Node(\\(\\blacksquare\\))가 있습니다. 즉, \\(Z\\)가 생성되는 메커니즘이 타겟과 다릅니다. (하지만 \\(Y\\)는 타겟과 동일)\n\n\n\n\n\nFigure 6: 다중 도메인 데이터 융합(Data Fusion). 좌측(LA)은 Y와 X에, 우측(NYC)은 Z와 X에 구조적 차이(Selection Node)가 있다. 이 두 불완전한 소스를 결합하여 타겟의 효과를 추정해야 한다."
  },
  {
    "objectID": "posts/lecture/L17/part-03/index.html#derivation-steps-reduced-to-calculus",
    "href": "posts/lecture/L17/part-03/index.html#derivation-steps-reduced-to-calculus",
    "title": "[Causal Inference] 17. Causal Data Science (Part 3)",
    "section": "Derivation Steps (Reduced to Calculus)",
    "text": "Derivation Steps (Reduced to Calculus)\n\n우리는 do-calculus와 확률의 법칙을 사용하여, 타겟 쿼리를 각 소스 도메인에서 식별 가능한(Transportable) 부분들로 분해하고 매핑합니다.\n\n\nDefinition & Axioms (Decomposition): 먼저 타겟의 Selection Node 집합(\\(\\blacksquare_{xzy}\\))을 조건부에 포함시킨 뒤, \\(Z\\)에 대해 전체 확률의 법칙을 적용합니다. \\[Q = P^*(y|do(x)) = P(y|do(x), \\blacksquare_{xzy})\\] \\[= \\sum_{z} P(y|do(x), z, \\blacksquare_{xzy}) P(z|do(x), \\blacksquare_{xzy})\\]\nRule 2 (Action/Observation Exchange): 첫 번째 항에서 \\(Z\\)가 \\(X \\to Y\\) 경로를 차단하므로, 관측된 \\(z\\)를 개입 \\(do(z)\\)로 바꿀 수 있습니다. \\[= \\sum_{z} P(y|do(x), do(z), \\blacksquare_{xzy}) P(z|do(x), \\blacksquare_{xzy})\\]\nRule 3 (Deletion of Action): 첫 번째 항에서 \\(Z\\)를 고정(\\(do(z)\\))하면 \\(X\\)가 \\(Y\\)에 미치는 영향은 사라집니다. 따라서 \\(do(x)\\)를 제거합니다. \\[= \\sum_{z} P(y|do(z), \\blacksquare_{xzy}) P(z|do(x), \\blacksquare_{xzy})\\]\nRule 1 (Removal of Irrelevant Selection Nodes)\n\n논리: “이 변수(\\(Y\\) 또는 \\(Z\\))를 결정하는 데 있어, 관련 없는 Selection Node는 지울 수 있다.” (d-separation)\n(Term 1) \\(Y\\)에 대한 분석:\n\n\\(Y\\)는 \\(Z\\)가 주어졌을 때, \\(Z\\)나 \\(X\\)에 붙은 Selection Node(\\(\\blacksquare_z, \\blacksquare_x\\))와는 독립적입니다. (그래프상 \\(Y\\)로 오는 화살표가 없음)\n따라서 \\(\\blacksquare_y\\)만 남기고 나머지는 지웁니다. \\[P(y|do(z), \\blacksquare_{x,z,y}) \\xrightarrow{\\text{Rule 1}} P(y|do(z), \\blacksquare_y)\\]\n\n(Term 2) \\(Z\\)에 대한 분석:\n\n\\(Z\\)는 \\(X\\)가 주어졌을 때, \\(Y\\)에 붙은 Selection Node(\\(\\blacksquare_x, \\blacksquare_y\\))와 독립적입니다.\n따라서 \\(\\blacksquare_z\\)만 남기고 \\(\\blacksquare_x, \\blacksquare_y\\)는 지웁니다. \\[P(z|do(x), \\blacksquare_{x,z,y}) \\xrightarrow{\\text{Rule 1}} P(z|do(x), \\blacksquare_{z})\\]\n\n\nDefinition (Mapping to Sources)\n\n논리: “남아있는 Selection Node 구성과 일치하는 도메인(도시)을 찾아 연결한다.”\n(Term 1) \\(P(y|do(z), \\blacksquare_y)\\) 매핑:\n\n우리는 \\(Y\\)에 대한 메커니즘이 타겟과 동일한(즉, \\(\\blacksquare_y\\)가 없는/영향을 안 주는) 도메인을 찾아야 합니다.\nLA (\\(\\Pi^a\\)): \\(Y\\)에 \\(\\blacksquare\\)가 있음 (Bad).\nNYC (\\(\\Pi^b\\)): \\(Y\\)에 \\(\\blacksquare\\)가 없음 (Good).\n\\(\\rightarrow\\) 따라서 NYC 데이터(\\(P^{(b)}\\))를 사용합니다. \\[P(y|do(z), \\blacksquare_y) \\rightarrow P^{(b)}(y|do(z))\\]\n\n(Term 2) \\(P(z|do(x), \\blacksquare_{z,x})\\) 매핑:\n\n우리는 \\(Z\\)에 대한 메커니즘이 타겟과 동일한(즉, \\(\\blacksquare_z\\)가 없는) 도메인을 찾아야 합니다.\nNYC (\\(\\Pi^b\\)): \\(Z\\)에 \\(\\blacksquare\\)가 있음 (Bad).\nLA (\\(\\Pi^a\\)): \\(Z\\)에 \\(\\blacksquare\\)가 없음 (Good).\n\\(\\rightarrow\\) 따라서 LA 데이터(\\(P^{(a)}\\))를 사용합니다. \\[P(z|do(x), \\blacksquare_{z}) \\rightarrow P^{(a)}(z|do(x))\\]"
  },
  {
    "objectID": "posts/lecture/L17/part-03/index.html#final-transport-formula",
    "href": "posts/lecture/L17/part-03/index.html#final-transport-formula",
    "title": "[Causal Inference] 17. Causal Data Science (Part 3)",
    "section": "Final Transport Formula",
    "text": "Final Transport Formula\n최종적으로 두 도메인의 데이터를 결합한 공식은 다음과 같습니다.\n\\[\nP^*(y|do(x)) = \\sum_{z} \\underbrace{P^{(b)}(y|do(z))}_{\\text{from NYC}} \\underbrace{P^{(a)}(z|do(x))}_{\\text{from LA}}\n\\]\n\n의미:\n\nLA 데이터에서는 \\(X\\)가 \\(Z\\)에 미치는 효과를 가져옵니다 (\\(X \\to Z\\) 메커니즘 공유).\nNYC 데이터에서는 \\(Z\\)가 \\(Y\\)에 미치는 효과를 가져옵니다 (\\(Z \\to Y\\) 메커니즘 공유).\n이들을 결합함으로써, 그 어떤 도시에서도 수행된 적 없는 전체 실험(\\(X \\to Y\\))의 결과를 정확하게 예측해 낼 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L17/part-05/index.html",
    "href": "posts/lecture/L17/part-05/index.html",
    "title": "[Causal Inference] 17. Causal Data Science (Part 5)",
    "section": "",
    "text": "데이터 분석, 특히 사회과학이나 의료 데이터를 다룰 때 결측치(Missing Data)는 피할 수 없는 현실입니다. [cite_start]설문조사에서 응답자가 특정 문항을 건너뛰거나, 센서가 오작동하거나, 환자가 과거 기록을 기억하지 못하는 등 다양한 이유로 발생합니다[cite: 13, 14, 15].\n통계학 문헌, 특히 Rubin의 선구적인 연구 이후 대부분의 결측치 처리 방식은 MAR(Missing At Random) 가정을 기반으로 합니다. [cite_start]이는 Maximum Likelihood나 Multiple Imputation의 수렴성을 보장하기 위한 필수적인 가정이지만, 실제 데이터에서 이 가정이 성립하는지 검증하는 것은 매우 어렵습니다[cite: 19, 20, 21, 23].\nMohan과 Pearl(2021)은 결측치 문제를 통계적 문제(Statistical Problem)가 아닌 인과적 문제(Causal Problem)로 재정의합니다. 데이터가 왜 비었는지에 대한 “이유(Reason)”는 데이터 생성 과정(Data Generating Process)의 일부이기 때문입니다. [cite_start]본 포스트에서는 그래프 모형(Graphical Models), 특히 m-graphs를 통해 결측 메커니즘을 시각화하고, 데이터의 복원 가능성(Recoverability)을 판단하는 방법을 정리합니다[cite: 31, 32]."
  },
  {
    "objectID": "posts/lecture/L17/part-05/index.html#introduction-missingness-is-a-causal-concept",
    "href": "posts/lecture/L17/part-05/index.html#introduction-missingness-is-a-causal-concept",
    "title": "[Causal Inference] 17. Causal Data Science (Part 5)",
    "section": "",
    "text": "데이터 분석, 특히 사회과학이나 의료 데이터를 다룰 때 결측치(Missing Data)는 피할 수 없는 현실입니다. [cite_start]설문조사에서 응답자가 특정 문항을 건너뛰거나, 센서가 오작동하거나, 환자가 과거 기록을 기억하지 못하는 등 다양한 이유로 발생합니다[cite: 13, 14, 15].\n통계학 문헌, 특히 Rubin의 선구적인 연구 이후 대부분의 결측치 처리 방식은 MAR(Missing At Random) 가정을 기반으로 합니다. [cite_start]이는 Maximum Likelihood나 Multiple Imputation의 수렴성을 보장하기 위한 필수적인 가정이지만, 실제 데이터에서 이 가정이 성립하는지 검증하는 것은 매우 어렵습니다[cite: 19, 20, 21, 23].\nMohan과 Pearl(2021)은 결측치 문제를 통계적 문제(Statistical Problem)가 아닌 인과적 문제(Causal Problem)로 재정의합니다. 데이터가 왜 비었는지에 대한 “이유(Reason)”는 데이터 생성 과정(Data Generating Process)의 일부이기 때문입니다. [cite_start]본 포스트에서는 그래프 모형(Graphical Models), 특히 m-graphs를 통해 결측 메커니즘을 시각화하고, 데이터의 복원 가능성(Recoverability)을 판단하는 방법을 정리합니다[cite: 31, 32]."
  },
  {
    "objectID": "posts/lecture/L17/part-05/index.html#formalism-the-m-graph",
    "href": "posts/lecture/L17/part-05/index.html#formalism-the-m-graph",
    "title": "[Causal Inference] 17. Causal Data Science (Part 5)",
    "section": "2. Formalism: The m-graph",
    "text": "2. Formalism: The m-graph\n결측 데이터 문제를 그래프로 표현하기 위해, 우리는 변수를 관측 여부와 역할에 따라 분류하고 Proxy Variable이라는 개념을 도입합니다.\n\n2.1. Variables Classification\n[cite_start]Causal DAG \\(G\\)의 노드들은 다음 다섯 가지 카테고리로 분류됩니다[cite: 115, 116]:\n\n\\(U\\): Latent Variables (관측되지 않는 잠재 변수)\n\\(V_o\\): Fully Observed Variables (모든 레코드에서 관측된 변수)\n\\(V_m\\): Missing Variables (적어도 하나의 레코드에서 결측이 발생한 변수)\n\\(R\\): Missingness Mechanisms (결측을 유발하는 인과적 메커니즘을 나타내는 변수)\n\\(V^*\\): Proxy Variables (실제로 관측된 변수)\n\n\n\n2.2. The Proxy Variable Mechanism\n[cite_start]변수 \\(X\\)가 결측될 수 있다면, 우리는 실제 값 \\(X\\)와 결측 여부를 결정하는 스위치 \\(R_X\\)를 통해 관측된 값 \\(X^*\\)를 다음과 같이 정의합니다[cite: 49, 50].\n\\[\nX^* = f(R_X, X) = \\begin{cases}\nX & \\text{if } R_X = 0 \\quad (\\text{Observed}) \\\\\nm & \\text{if } R_X = 1 \\quad (\\text{Missing})\n\\end{cases}\n\\]\n여기서 \\(m\\)은 결측(missing value)을 나타내는 기호입니다. [cite_start]\\(R_X=1\\)이면 변수의 값은 가려지고(masked), \\(R_X=0\\)이면 드러납니다(revealed)[cite: 54, 55].\n\n\n\nFigure 1: 비만도(Obesity) 예시를 통한 m-graph의 기본 구조. G(성별), A(나이)는 완전히 관측되지만, O(비만도)는 결측 메커니즘 \\(R_O\\)에 의해 \\(O^*\\)로 관측된다.\n\n\n\nFigure 1 설명: 위 그림은 학교 데이터 예시를 보여줍니다. \\(G\\)(Gender)와 \\(A\\)(Age)는 학교 기록부에 있어 완전히 관측되지만(\\(V_o\\)), \\(O\\)(Obesity)는 학생이 응답을 거부할 수 있어 결측이 발생합니다(\\(V_m\\)). [cite_start]\\(R_O\\)는 \\(O\\)가 결측될지 여부를 결정하는 변수이며, 실제로 우리가 데이터셋에서 보는 것은 \\(O^*\\)(\\(V^*\\))입니다[cite: 39, 44, 45, 49]."
  },
  {
    "objectID": "posts/lecture/L17/part-05/index.html#categories-of-missingness-in-graphs",
    "href": "posts/lecture/L17/part-05/index.html#categories-of-missingness-in-graphs",
    "title": "[Causal Inference] 17. Causal Data Science (Part 5)",
    "section": "3. Categories of Missingness in Graphs",
    "text": "3. Categories of Missingness in Graphs\nRubin의 분류법인 MCAR, MAR, MNAR을 m-graph 상에서의 조건부 독립성(Conditional Independence)으로 명확히 정의할 수 있습니다. [cite_start]그래프 구조를 통해 데이터가 어떤 결측 유형에 속하는지 시각적으로 판별(Inspection)이 가능해집니다[cite: 34].\n\n3.1. MCAR (Missing Completely At Random)\n결측이 완전히 무작위로 발생하는 경우입니다. [cite_start]설문지를 잃어버리는 등의 상황이 이에 해당합니다[cite: 69].\n\n정의: 결측 메커니즘 \\(R\\)이 데이터의 모든 변수(\\(V_m, V_o, U\\))와 독립입니다.\n[cite_start]그래프 조건: \\(R\\) 변수들과 \\(V_o \\cup V_m\\) 사이에 엣지가 없습니다[cite: 138, 143].\n\n\\[\nV_m, V_o, U \\perp \\mathbb{R}\n\\]\n\n\n\nFigure 2: MCAR의 그래프 구조. \\(R_O\\)로 들어오는 화살표가 없다. 즉, 나이(A)나 성별(G), 실제 비만도(O)가 결측 여부(\\(R_O\\))에 영향을 주지 않는다.\n\n\n\n\n3.2. MAR (Missing At Random)\n결측이 완전히 관측된 변수(\\(V_o\\))에만 의존하여 발생하는 경우입니다. [cite_start]예를 들어, 10대(\\(A\\))들이 반항심에 몸무게를 보고하지 않는 경우 등입니다[cite: 77].\n\n[cite_start]정의: 관측된 변수 \\(V_o\\)가 주어졌을 때, 결측 메커니즘 \\(R\\)은 나머지 변수들과 독립입니다[cite: 146].\n[cite_start]그래프 조건: (i) \\(R\\)과 부분적으로 관측된 변수(\\(V_m\\)) 사이에 엣지가 없고, (ii) \\(R\\)과 \\(V_o\\) 사이에 양방향 엣지(bidirected edge, Latent confounder)가 없어야 합니다[cite: 147].\n\n\\[\nV_m, U \\perp \\mathbb{R} \\mid V_o\n\\]\n\n\n\nFigure 3: MAR의 그래프 구조. 나이(A)가 결측 메커니즘(\\(R_O\\))에 영향을 준다(\\(A \\rightarrow R_O\\)). 즉, 결측 여부는 관측된 나이에 따라 달라진다.\n\n\n\n\n3.3. MNAR (Missing Not At Random)\n데이터가 MCAR나 MAR이 아닌 모든 경우입니다. 특히, 결측된 변수 그 자체가 결측 원인이 되는 경우가 포함됩니다. [cite_start]예를 들어, 비만인 학생(\\(O\\))이 부끄러워서 몸무게를 숨기는 경우입니다[cite: 87, 112].\n\n특징: \\(R\\) 변수로 들어오는 화살표가 결측 변수(\\(V_m\\))나 잠재 변수(\\(U\\))에서 시작됩니다.\n\n\n\n\nFigure 4: MNAR의 그래프 구조. 실제 비만도(O)가 결측 여부(\\(R_O\\))에 직접 영향을 준다(\\(O \\rightarrow R_O\\)). 비만일수록 응답하지 않을 확률이 높아지는 메커니즘이다."
  },
  {
    "objectID": "posts/lecture/L17/part-05/index.html#recoverability-can-we-restore-the-truth",
    "href": "posts/lecture/L17/part-05/index.html#recoverability-can-we-restore-the-truth",
    "title": "[Causal Inference] 17. Causal Data Science (Part 5)",
    "section": "4. Recoverability: Can We Restore the Truth?",
    "text": "4. Recoverability: Can We Restore the Truth?\n[cite_start]Recoverability(복원 가능성)란, 결측이 포함된 관측 데이터(\\(V^*, V_o, R\\))의 분포로부터 우리가 알고 싶은 원래 분포(Target Distribution, \\(P(V_o, V_m)\\))를 일관되게(consistently) 추정할 수 있는지에 대한 문제입니다[cite: 35].\n\n4.1. Recoverability of MCAR\nMCAR의 경우, \\(R_O\\)는 모든 변수와 독립이므로, 데이터를 삭제(List-wise deletion)하고 남은 데이터만 써도 편향(Bias)이 없습니다.\n\\[\nP(G, O, A) = P(G, O, A \\mid R_O = 0)\n\\]\n\\(R_O = 0\\)인 조건 하에서는 \\(O = O^*\\)이므로,\n\\[\n= P(G, O^*, A \\mid R_O = 0)\n\\]\n[cite_start]즉, 관측된 데이터만으로 원래 분포를 완벽히 복원할 수 있습니다[cite: 187, 189].\n\n\n4.2. Recoverability of MAR\nMAR의 경우, 단순 삭제는 편향을 낳지만, 조건부 확률을 이용해 복원할 수 있습니다. 예를 들어 \\(A \\rightarrow R_O\\)인 상황(Figure 3)을 봅시다.\n[cite_start]우리는 결합 확률 \\(P(G, O, A)\\)를 다음과 같이 분해(Factorization)할 수 있습니다[cite: 198]: \\[\nP(G, O, A) = P(G, O \\mid A)P(A)\n\\]\n그래프에서 \\(A\\)는 \\(R_O\\)와 \\(\\{G, O\\}\\) 사이를 d-separation 합니다. [cite_start]따라서 \\(R_O\\)에 조건을 걸어도 확률은 변하지 않습니다[cite: 199]. \\[\nP(G, O \\mid A) = P(G, O \\mid A, R_O = 0)\n\\]\n\\(R_O=0\\)일 때 \\(O=O^*\\)이므로, 최종적으로 관측 가능한 변수들로 표현됩니다: \\[\nP(G, O, A) = P(G, O^* \\mid A, R_O = 0)P(A)\n\\]\n[cite_start]이것이 MAR 상황에서 데이터를 복원하는 핵심 논리입니다[cite: 202].\n\n\n4.3. The Challenge of MNAR\nMNAR, 예를 들어 \\(O \\rightarrow R_O\\)인 경우(Figure 4), 위와 같은 분해나 d-separation을 사용할 수 없습니다. [cite_start]\\(O\\)를 관측하지 못했는데 \\(O\\)가 결측 원인이 되므로, 일반적으로 복원이 불가능(Non-recoverable)합니다[cite: 218, 224].\n하지만 모든 MNAR이 복원 불가능한 것은 아닙니다. m-graph 구조에 따라 MNAR임에도 복원 가능한 특수한 케이스들이 존재합니다."
  },
  {
    "objectID": "posts/lecture/L17/part-05/index.html#advanced-recoverability-theorems",
    "href": "posts/lecture/L17/part-05/index.html#advanced-recoverability-theorems",
    "title": "[Causal Inference] 17. Causal Data Science (Part 5)",
    "section": "5. Advanced Recoverability Theorems",
    "text": "5. Advanced Recoverability Theorems\nMNAR 상황에서도 복원 가능한 조건을 다루는 두 가지 중요한 정리가 있습니다.\n\n5.1. Sequential Factorization (순차적 분해)\n[cite_start]타겟 분포 \\(Q\\)를 인수분해했을 때, 각 인수가 \\(P(Y_i | X_i)\\) 꼴을 띠고, 각각의 \\(Y_i\\)가 \\(X_i\\)가 주어졌을 때 자신의 결측 메커니즘 \\(R_{Y_i}\\)과 독립이라면 복원 가능합니다[cite: 247].\n\\[\nP(Y_i \\mid X_i) = P(Y_i^* \\mid X_i^*, R_{Y_i}=0, R_{X_i}=0)\n\\]\n\n\n5.2. R-Factorization Theorem\n전체 결합 분포 \\(P(V)\\)의 복원 가능성에 대한 필요충분조건입니다. [cite_start]\\(R\\) 변수들 간에 엣지가 없다고 가정할 때, 다음 두 조건에 해당하는 변수 \\(X \\in V_m\\)이 없다면 복원 가능합니다[cite: 254, 255, 256].\n\n\\(X\\)와 \\(R_X\\)가 이웃(neighbor)함.\n\\(X\\)와 \\(R_X\\)가 \\(V_m \\cup V_o\\) 내의 collider들로만 이루어진 경로로 연결됨.\n\n[cite_start]복원 가능하다면, 분포는 다음과 같이 주어집니다[cite: 258]:\n\\[\nP(V) = \\frac{P(R=0, V^*)}{\\prod_i P(R_i=0 \\mid Mb_{R_i}^o, Mb_{R_i}^m, R_{Mb_{R_i}^m}=0)}\n\\]\n여기서 \\(Mb_{R_i}\\)는 \\(R_i\\)의 Markov Blanket을 의미합니다."
  },
  {
    "objectID": "posts/lecture/L17/part-05/index.html#case-study-recovering-causal-effect-pydoz",
    "href": "posts/lecture/L17/part-05/index.html#case-study-recovering-causal-effect-pydoz",
    "title": "[Causal Inference] 17. Causal Data Science (Part 5)",
    "section": "6. Case Study: Recovering Causal Effect (\\(P(y|do(z))\\))",
    "text": "6. Case Study: Recovering Causal Effect (\\(P(y|do(z))\\))\n[cite_start]마지막으로, 결측 데이터가 있는 상황에서 인과 효과(Causal Effect)를 추정하는 예제를 살펴보겠습니다[cite: 261].\n\n\n\nFigure 5: Causal Effect 복원 예시 그래프. \\(W \\rightarrow Z \\rightarrow Y\\)의 인과 경로가 있고, \\(W\\)가 \\(Y\\)의 결측(\\(R_Y\\))에 영향을 주며, \\(W\\)와 \\(Y\\) 사이에 잠재적 교란 요인(dashed bidirectional edge)이 존재하는 복잡한 MNAR 상황이다.\n\n\n\nFigure 5 설명: 이 그래프에서 우리는 \\(Z\\)가 \\(Y\\)에 미치는 인과 효과 \\(P(y|do(z))\\)를 알고 싶습니다. 하지만 \\(Y\\)에는 결측이 있고, 결측 메커니즘 \\(R_Y\\)는 \\(W\\)에 의존합니다(\\(W \\rightarrow R_Y\\)). 또한 \\(W\\)와 \\(Y\\) 사이에는 Confounder가 있습니다.\n\n유도 과정:\n\nBackdoor Adjustment: \\(W\\)가 \\(Z \\rightarrow Y\\) 관계의 confounder 역할을 하므로, \\(W\\)에 대해 조정(adjustment)을 수행합니다. \\[P(y \\mid do(z)) = \\sum_w P(y \\mid w, z) P(w)\\] [cite_start](주의: 슬라이드 수식 [cite: 269]에서는 \\(P(y|do(z))\\)를 바로 전개하지만, 여기서는 이해를 돕기 위해 Backdoor 기준을 적용한 형태를 풀어서 설명합니다. 슬라이드의 전개는 do-calculus와 결측 매커니즘 분해를 결합한 것입니다.)\n슬라이드의 유도 과정을 따라가면: \\[P(y \\mid do(z)) = P(y \\mid do(z), r_y) \\quad \\text{($R_y$는 개입 이후 변수가 아님)}\\]\n\\(R_y\\)가 조건부에 포함되면, 우리는 \\(Y\\) 대신 \\(Y^*\\)를 사용할 수 있습니다 (\\(Y = Y^*\\) when \\(R_Y=0\\) or implicit context). \\[= P(y^* \\mid do(z), r_y)\\]\n이 확률을 \\(W\\)를 통해 분해합니다: \\[= \\sum_w P(y^* \\mid w, do(z), r_y) P(w \\mid do(z), r_y)\\]\n그래프 상의 독립성을 활용합니다. \\(Z\\)에 개입(\\(do(z)\\))하면 \\(W\\)에서 오는 화살표는 무시되거나, \\(W\\)가 \\(Z\\)의 부모이므로 \\(do(z)\\)와 독립일 수 있습니다. 중요한 점은 \\(Y^*\\)가 관측 가능해진다는 것입니다.\n[cite_start]최종적으로 슬라이드는 다음과 같은 형태의 복원식을 제시합니다[cite: 269]: \\[= \\sum_w P(y^* \\mid w, z, r_y) P(w \\mid r_y)\\]\n이 식의 의미는, 결측이 있는 상태(\\(Y^*\\))에서도, 결측 메커니즘(\\(R_Y\\))과 관련된 변수(\\(W\\))들을 적절히 통제하면 원래의 인과 효과를 계산해낼 수 있다는 것입니다."
  },
  {
    "objectID": "posts/lecture/L17/part-05/index.html#conclusion",
    "href": "posts/lecture/L17/part-05/index.html#conclusion",
    "title": "[Causal Inference] 17. Causal Data Science (Part 5)",
    "section": "7. Conclusion",
    "text": "7. Conclusion\n이번 포스트에서는 결측 데이터 문제를 인과적 관점에서 바라보는 m-graph 프레임워크를 다뤘습니다.\n\n[cite_start]Transparency: 그래프 모델은 결측의 원인(Missingness Mechanism)을 명시적으로 표현하여, MAR/MCAR 가정을 시각적으로 검증(Testability)할 수 있게 해줍니다[cite: 32, 36].\nRecoverability: 단순히 데이터를 삭제하거나 평균을 채워 넣는 것이 아니라, 그래프 구조에 기반하여 이론적으로 타당한 복원 공식을 유도할 수 있습니다.\n[cite_start]Beyond MAR: 기존 통계학에서 다루기 어려웠던 MNAR 상황에서도, 구조적 특성을 이용해(Sequential Factorization 등) 편향 없는 추정이 가능함을 확인했습니다[cite: 24, 253].\n\n[cite_start]통계학자와 데이터 과학자는 결측치를 단순한 “전처리 대상”이 아니라, 데이터 생성 과정의 일부로 보고 모델링해야 합니다[cite: 272].\n\n\n누락 방지 검증 체크리스트\n\n포함된 내용:\n\n결측 데이터의 동기 및 기존 방법론(Rubin)의 한계\nm-graph의 정의 및 구성 요소 (\\(V^*, R\\) 등)\nMCAR, MAR, MNAR의 그래프적 정의 및 예시\nMCAR, MAR, MNAR 상황별 복원 가능성(Recoverability) 유도 과정\n고급 정리: Sequential Factorization, R-Factorization Theorem 수식\nCausal Effect (\\(P(y|do(z))\\)) 복원 예제\n\n생략된 내용:\n\n슬라이드 24의 복잡한 MNAR 예제 (\\(Z_1, Z_2, X, Y\\))에 대한 세부 유도 과정은 R-Factorization Theorem의 일반론으로 갈음하고, 대신 Causal Effect 예제를 상세히 다루었습니다. (흐름상 핵심 정리를 보여주는 것이 더 중요하다고 판단)\nJASA 논문 원문의 증명(Proof) 등은 슬라이드 범위를 벗어나므로 제외했습니다."
  },
  {
    "objectID": "posts/lecture/L10/part-01/index.html",
    "href": "posts/lecture/L10/part-01/index.html",
    "title": "[Causal Inference] 10. Potential Outcome Framework (Part 1)",
    "section": "",
    "text": "사회과학, 의학, 정책학 등 다양한 분야에서 우리는 단순히 현상을 서술하는 것을 넘어, “무엇이 무엇을 야기했는가?”라는 인과적 질문에 답하고자 합니다. 하지만 직관적인 인과관계를 수학적이고 통계적인 언어로 형식화(formalize)하는 것은 쉽지 않은 문제입니다.\n인과추론(Causal Inference)을 위한 프레임워크는 크게 두 가지 주류가 존재합니다.\n\nPotential Outcome Framework (Neyman-Rubin Causal Model): 인과추론을 ‘결측 데이터(Missing Data)’의 문제로 바라보는 관점입니다. Neyman(1923)과 Rubin(1974)에 의해 정립되었으며, 사회과학과 의학 분야에서 가장 널리 사용됩니다.\nCausal Diagram Framework (Pearl): 그래프 이론(DAGs)을 기반으로 변수 간의 구조적 관계를 도식화하는 관점입니다 (Pearl, 2009).\n\n이 포스트에서는 첫 번째 접근법인 Potential Outcome (PO) Framework를 다룹니다. 이 프레임워크는 관찰된 데이터가 생성되는 과정(Assignment Mechanism)을 명시적으로 모델링함으로써, 우리가 관찰하지 못한 ’반사실(Counterfactual)’을 어떻게 추론할 것인지에 대한 통계적 토대를 제공합니다."
  },
  {
    "objectID": "posts/lecture/L10/part-01/index.html#unit-개체",
    "href": "posts/lecture/L10/part-01/index.html#unit-개체",
    "title": "[Causal Inference] 10. Potential Outcome Framework (Part 1)",
    "section": "2.1. Unit (개체)",
    "text": "2.1. Unit (개체)\nUnit은 처치(Treatment)가 적용되는 대상(사람, 장소, 사물 등)을 의미합니다. 중요한 점은 “특정 시점(at a particular time)”이 정의에 포함된다는 것입니다. * 예: 동일한 사람이라도 2024년의 나와 2025년의 나는 다른 Unit으로 취급될 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L10/part-01/index.html#treatment-처치",
    "href": "posts/lecture/L10/part-01/index.html#treatment-처치",
    "title": "[Causal Inference] 10. Potential Outcome Framework (Part 1)",
    "section": "2.2. Treatment (처치)",
    "text": "2.2. Treatment (처치)\n연구자가 그 효과를 평가하고자 하는 개입(Intervention)입니다. * \\(X=1\\): 처치를 받은 상태 (Active Treatment) * \\(X=0\\): 처치를 받지 않은 상태 (Control)"
  },
  {
    "objectID": "posts/lecture/L10/part-01/index.html#potential-outcomes-잠재적-결과",
    "href": "posts/lecture/L10/part-01/index.html#potential-outcomes-잠재적-결과",
    "title": "[Causal Inference] 10. Potential Outcome Framework (Part 1)",
    "section": "2.3. Potential Outcomes (잠재적 결과)",
    "text": "2.3. Potential Outcomes (잠재적 결과)\n이 프레임워크의 핵심입니다. 각 Unit에 대해 처치 여부에 따라 잠재적으로 존재할 수 있는 두 가지 결과를 정의합니다.\n\n\\(Y(1)\\): 처치를 받았을 때(\\(X=1\\)) 관찰되었을 결과\n\\(Y(0)\\): 처치를 받지 않았을 때(\\(X=0\\)) 관찰되었을 결과\n\n여기서 \\(Y(1)\\)과 \\(Y(0)\\)는 처치가 실제로 일어났는지와 무관하게, 사전에 결정되어 있는(pre-existing) 값으로 간주합니다. 이를 Counterfactuals(반사실)이라고도 부릅니다."
  },
  {
    "objectID": "posts/lecture/L10/part-01/index.html#causal-effect-인과-효과",
    "href": "posts/lecture/L10/part-01/index.html#causal-effect-인과-효과",
    "title": "[Causal Inference] 10. Potential Outcome Framework (Part 1)",
    "section": "2.4. Causal Effect (인과 효과)",
    "text": "2.4. Causal Effect (인과 효과)\n개별 Unit \\(i\\)에 대한 인과 효과(Individual Causal Effect)는 두 잠재적 결과의 차이로 정의됩니다.\n\\[\n\\tau_i = Y_i(1) - Y_i(0)\n\\]\n즉, “내가 약을 먹었을 때의 혈압”과 “내가 약을 먹지 않았을 때의 혈압”의 차이가 바로 약의 인과 효과입니다."
  },
  {
    "objectID": "posts/lecture/L10/part-01/index.html#neymans-urn-model",
    "href": "posts/lecture/L10/part-01/index.html#neymans-urn-model",
    "title": "[Causal Inference] 10. Potential Outcome Framework (Part 1)",
    "section": "3.1. Neyman’s Urn Model",
    "text": "3.1. Neyman’s Urn Model\n이 상황은 통계학자 Neyman이 제안한 Urn Model(항아리 모델)로 비유할 수 있습니다.\n\n\n\nFigure 2: Neyman의 Urn Model 도식. 각 상자(Unit) 안에는 두 개의 표(\\(Y_1, Y_0\\))가 들어있지만, 우리가 관찰할 수 있는 것은 그중 선택된 하나뿐이다. 그림자 처리된 부분은 관찰되지 않은 잠재적 결과(Missing Data)를 의미한다.\n\n\n우리의 데이터셋은 마치 여러 개의 상자(Unit)들이 있고, 각 상자 안에 두 개의 티켓(\\(Y(1), Y(0)\\))이 들어있는 것과 같습니다. 우리는 각 상자에서 오직 하나의 티켓만 뽑아볼 수 있습니다. 인과추론은 뽑지 않은 나머지 티켓의 값을 추론하는 문제입니다."
  },
  {
    "objectID": "posts/lecture/L10/part-01/index.html#assumption-sutva",
    "href": "posts/lecture/L10/part-01/index.html#assumption-sutva",
    "title": "[Causal Inference] 10. Potential Outcome Framework (Part 1)",
    "section": "4.1. Assumption: SUTVA",
    "text": "4.1. Assumption: SUTVA\nSUTVA는 크게 두 가지 하위 가정으로 구성됩니다 (Rubin, 1980).\n\nNo Interference (상호 간섭 없음): 한 Unit의 잠재적 결과는 다른 Unit의 처치 여부에 영향을 받지 않습니다. 즉, 나의 결과는 오직 나의 처치 여부에만 달려있어야 합니다.\n\n위반 사례: 백신 접종 (내 친구가 백신을 맞으면, 내가 안 맞아도 감염 확률이 낮아짐), 소셜 네트워크 효과, 광고 효과 등.\n\nNo Hidden Variations of Treatment (처치의 일관성): 처치는 단일한 버전만 존재해야 합니다. “처치를 받았다”는 상태가 Unit마다 다르지 않아야 합니다.\n\n위반 사례: 수술(의사의 숙련도에 따라 같은 수술도 결과가 다름), 약의 복용량 차이 등."
  },
  {
    "objectID": "posts/lecture/L10/part-01/index.html#mathematical-connection",
    "href": "posts/lecture/L10/part-01/index.html#mathematical-connection",
    "title": "[Causal Inference] 10. Potential Outcome Framework (Part 1)",
    "section": "4.2. Mathematical Connection",
    "text": "4.2. Mathematical Connection\nSUTVA가 성립할 때, 관찰된 결과 \\(Y_i\\)는 처치 상태 \\(X_i\\)에 따라 다음과 같이 Consistency Assumption으로 연결됩니다.\n\\[\n\\text{If } X_i = 1 \\text{, then } Y_i = Y_i(1) \\\\\n\\text{If } X_i = 0 \\text{, then } Y_i = Y_i(0)\n\\]\n이를 하나의 수식으로 표현하면 다음과 같은 Switching Equation을 얻을 수 있습니다.\n\\[\nY_i = X_i Y_i(1) + (1 - X_i) Y_i(0)\n\\]\n이 식은 인과추론의 수리적 전개에서 가장 기초가 되는 항등식입니다. \\(X_i\\)가 1이면 앞의 항만 남고, 0이면 뒤의 항만 남아 관찰된 \\(Y_i\\)가 결정됩니다."
  },
  {
    "objectID": "posts/lecture/L10/part-01/index.html#difference-based-estimands-차이-기반",
    "href": "posts/lecture/L10/part-01/index.html#difference-based-estimands-차이-기반",
    "title": "[Causal Inference] 10. Potential Outcome Framework (Part 1)",
    "section": "5.1. Difference-based Estimands (차이 기반)",
    "text": "5.1. Difference-based Estimands (차이 기반)\n가장 일반적으로 사용되는 척도입니다.\n\nAverage Treatment Effect (ATE)\n전체 모집단(Population)에 대한 평균적인 처치 효과입니다.\n\\[\n\\tau_{ATE} = \\mathbb{E}[Y_i(1) - Y_i(0)] = \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)]\n\\]\n\n\nAverage Treatment Effect for the Treated (ATT)\n실제로 처치를 받은 집단(\\(X=1\\))에 한정된 평균 처치 효과입니다. 정책 평가 등에서 “실제 수혜자가 얻은 이득”을 측정할 때 유용합니다.\n\\[\n\\tau_{ATT} = \\mathbb{E}[Y_i(1) - Y_i(0) \\mid X_i = 1]\n\\] 여기서 \\(\\mathbb{E}[Y_i(0) \\mid X_i = 1]\\)은 Counterfactual입니다. (실제로는 처치를 받았지만, 만약 안 받았다면 어땠을까에 대한 기댓값)\n\n\nConditional Average Treatment Effect (CATE)\n특정 공변량(Covariate) \\(Z\\)를 가진 하위 집단에서의 평균 효과입니다. 이질적인 처치 효과(Heterogeneous Treatment Effect)를 분석할 때 사용합니다. * 예: “30대 남성”에게 미치는 약의 효과\n\\[\n\\tau(z) = \\mathbb{E}[Y_i(1) - Y_i(0) \\mid Z = z]\n\\]"
  },
  {
    "objectID": "posts/lecture/L10/part-01/index.html#ratio-based-estimands-비율-기반",
    "href": "posts/lecture/L10/part-01/index.html#ratio-based-estimands-비율-기반",
    "title": "[Causal Inference] 10. Potential Outcome Framework (Part 1)",
    "section": "5.2. Ratio-based Estimands (비율 기반)",
    "text": "5.2. Ratio-based Estimands (비율 기반)\n결과변수가 연속형(Continuous)인 경우 차이를 많이 쓰지만, 의학이나 보건학에서 이진(Binary) 결과변수를 다룰 때는 비율 척도도 자주 사용됩니다.\n\nIndividual Relative Effect: \\(r_i = Y_i(1) / Y_i(0)\\)\nPopulation Relative Risk: \\(RR = \\mathbb{E}[Y_i(1)] / \\mathbb{E}[Y_i(0)]\\)\nRelative Causal Effect (Lift): \\[\n  \\text{Lift} = \\frac{\\mathbb{E}[Y_i(1) - Y_i(0)]}{\\mathbb{E}[Y_i(0)]} = \\frac{\\mathbb{E}[Y_i(1)]}{\\mathbb{E}[Y_i(0)]} - 1\n  \\]\n\n주의: 인과 효과가 모든 개인에게 일정(Homogeneous)하지 않다면, 개인별 비율의 평균(\\(\\mathbb{E}[r_i]\\))과 모집단 평균의 비율(\\(RR\\))은 같지 않습니다."
  },
  {
    "objectID": "posts/lecture/L03/index.html",
    "href": "posts/lecture/L03/index.html",
    "title": "[Causal Inference] 03. Identification of Causal Effects",
    "section": "",
    "text": "[cite_start]Note: 본 포스트는 서울대학교 GSDS 이상학 교수님의 “Identification of Causal Effects” 강의 자료를 바탕으로 작성되었습니다. [cite: 1, 2]"
  },
  {
    "objectID": "posts/lecture/L03/index.html#real-world-vs.-hypothetical-world",
    "href": "posts/lecture/L03/index.html#real-world-vs.-hypothetical-world",
    "title": "[Causal Inference] 03. Identification of Causal Effects",
    "section": "2.1. Real World vs. Hypothetical World",
    "text": "2.1. Real World vs. Hypothetical World\n인과 효과를 정의하기 위해 우리는 두 개의 세계를 비교해야 합니다.\n\nReal World (Observational World): 변수들이 자연스러운 인과 구조에 따라 값을 갖는 세계. 결합 확률 분포 \\(P(z, x, w, y)\\)로 표현됩니다.\nHyphetical World (Interventional World): 우리가 변수 \\(X\\)를 강제로 특정 값 \\(x\\)로 고정(\\(do(X=x)\\))했을 때의 세계. [cite_start]분포 \\(P(z, w, y | do(x))\\)로 표현됩니다 [cite: 33-44].\n\n\n\n\nFigure: Real world vs. Hypothetical world. 왼쪽(Real world)에서는 Z가 X에 영향을 주지만, 오른쪽(Hyphetical world)에서는 X에 대한 개입(do(X))으로 인해 Z에서 X로 가는 화살표가 끊어진(Mutilated) 것을 볼 수 있다.\n\n\n위 그림에서 볼 수 있듯이, 개입 \\(do(X=x)\\)는 모델 내에서 \\(X\\)를 결정하는 모든 방정식(화살표)을 삭제하고, \\(X=x\\)라는 상수로 대체하는 연산입니다. [cite_start]이를 통해 \\(Z\\)(교란 변수)가 \\(X\\)에 미치는 영향을 차단합니다 [cite: 52-71]."
  },
  {
    "objectID": "posts/lecture/L03/index.html#causal-effect의-정의",
    "href": "posts/lecture/L03/index.html#causal-effect의-정의",
    "title": "[Causal Inference] 03. Identification of Causal Effects",
    "section": "2.2. Causal Effect의 정의",
    "text": "2.2. Causal Effect의 정의\n수학적으로, \\(X\\)가 \\(Y\\)에 미치는 인과 효과(Causal Effect) \\(P(y|do(x))\\)는 다음과 같이 정의됩니다.\n\\[P(y|do(x)) = P_x(y)\\]\n여기서 \\(P_x(y)\\)는 서브모델(Submodel) \\(\\mathcal{M}_x\\)에서 \\(Y=y\\)일 확률을 의미합니다. [cite_start]\\(\\mathcal{M}_x\\)는 원래 모델 \\(\\mathcal{M}\\)에서 \\(X\\)에 관련된 모든 방정식을 삭제하고 \\(X=x\\)를 대입하여 얻은 모델입니다 [cite: 96-98]."
  },
  {
    "objectID": "posts/lecture/L03/index.html#시나리오-및-그래프",
    "href": "posts/lecture/L03/index.html#시나리오-및-그래프",
    "title": "[Causal Inference] 03. Identification of Causal Effects",
    "section": "3.1. 시나리오 및 그래프",
    "text": "3.1. 시나리오 및 그래프\n다음과 같은 변수와 인과 관계가 있다고 가정합니다. * Season (\\(Sn\\)): 계절 (모든 변수의 근원) * Sprinkler (\\(Sp\\)): 스프링클러 가동 여부 (계절에 영향 받음) * Rain (\\(Rn\\)): 비 옴 여부 (계절에 영향 받음) * Wet (\\(Wt\\)): 땅이 젖음 (스프링클러와 비에 영향 받음) * Slippery (\\(Sl\\)): 미끄러움 (땅이 젖음에 영향 받음)\n전체 결합 확률 분포(Markovian factorization)는 다음과 같습니다: \\[P(v) = P(Sn)P(Sp|Sn)P(Rn|Sn)P(Wt|Sp, Rn)P(Sl|Wt)\\] [cite_start][cite: 127]\n\n\n\nFigure: Sprinkler Example Causal Graph. Season이 Sprinkler와 Rain의 공통 원인(Confounder)으로 작용하고 있으며, Sprinkler와 Rain은 Wet의 원인이 된다."
  },
  {
    "objectID": "posts/lecture/L03/index.html#query-1-observation-pwtspon",
    "href": "posts/lecture/L03/index.html#query-1-observation-pwtspon",
    "title": "[Causal Inference] 03. Identification of Causal Effects",
    "section": "3.2. Query 1: Observation (\\(P(Wt|Sp=on)\\))",
    "text": "3.2. Query 1: Observation (\\(P(Wt|Sp=on)\\))\n우리가 단순히 “스프링클러가 켜진 것을 목격했을 때(\\(Sp=on\\))”, 땅이 젖어 있을 확률은 조건부 확률의 정의에 따라 다음과 같습니다.\n\\[\nQ_1 = P(Wt | Sp=\\text{on}) = \\frac{\\sum_{sn, rn} P(sn) \\mathbf{P(Sp=\\text{on}|sn)} P(rn|sn) P(wt|Sp=\\text{on}, rn)}{\\sum_{sn} \\mathbf{P(Sp=\\text{on}|sn)} P(sn)}\n\\] [cite_start][cite: 148]\n\n해석: 여기서 \\(P(Sp=\\text{on}|sn)\\) 항이 살아있습니다. 즉, 계절에 따라 스프링클러를 켜는 경향성(Selection Bias)이 결과에 반영됩니다."
  },
  {
    "objectID": "posts/lecture/L03/index.html#query-2-intervention-pwtdospon",
    "href": "posts/lecture/L03/index.html#query-2-intervention-pwtdospon",
    "title": "[Causal Inference] 03. Identification of Causal Effects",
    "section": "3.3. Query 2: Intervention (\\(P(Wt|do(Sp=on))\\))",
    "text": "3.3. Query 2: Intervention (\\(P(Wt|do(Sp=on))\\))\n이제 우리가 “스프링클러를 강제로 켰을 때(\\(do(Sp=on)\\))”, 땅이 젖어 있을 확률을 구해보겠습니다. 개입이 일어나면 \\(Sn \\rightarrow Sp\\)의 화살표가 끊어지므로, \\(Sp\\)는 더 이상 \\(Sn\\)의 함수가 아닙니다. 따라서 분해 식에서 \\(P(Sp|Sn)\\) 항이 제거(Truncated) 됩니다.\n\\[\nQ_2 = P(Wt | do(Sp=\\text{on})) = \\sum_{sn, rn} P(sn) P(rn|sn) P(wt|Sp=\\text{on}, rn)\n\\] [cite_start][cite: 165]\n\n중요한 차이: 관측 식(\\(Q_1\\))과 달리, \\(Q_2\\)에서는 \\(P(Sp|Sn)\\) 항이 사라졌습니다. 대신 자연적인 계절의 분포 \\(P(Sn)\\)과 비의 분포 \\(P(Rn|Sn)\\)에 따라 가중 평균을 구하게 됩니다.\n[cite_start]이것은 관측 분포와 개입 분포 사이의 변환을 재가중(Re-weighting) 과정으로 해석할 수 있음을 보여줍니다[cite: 211]."
  },
  {
    "objectID": "posts/lecture/L03/index.html#theorem-manipulation-theorem",
    "href": "posts/lecture/L03/index.html#theorem-manipulation-theorem",
    "title": "[Causal Inference] 03. Identification of Causal Effects",
    "section": "4.1. Theorem (Manipulation Theorem)",
    "text": "4.1. Theorem (Manipulation Theorem)\n마르코프 모형 \\(M\\)에서 개입 \\(do(X=x)\\)에 의해 생성된 확률 분포는 다음과 같이 주어집니다.\n\\[P(v \\setminus x | do(x)) = \\prod_{V_i \\in V \\setminus X} P(v_i | pa_i)\\] [cite_start][cite: 173]\n즉, 전체 결합 확률 \\(P(v) = \\prod P(v_i|pa_i)\\)에서 개입된 변수 \\(X\\)에 해당하는 항 \\(P(x|pa_x)\\)만 제거한 형태입니다."
  },
  {
    "objectID": "posts/lecture/L03/index.html#re-weighting-관점",
    "href": "posts/lecture/L03/index.html#re-weighting-관점",
    "title": "[Causal Inference] 03. Identification of Causal Effects",
    "section": "4.2. Re-weighting 관점",
    "text": "4.2. Re-weighting 관점\n이 식은 관측 데이터의 분포 \\(P(v)\\)를 이용해 다음과 같이 다시 쓸 수 있습니다.\n\\[\nP(v \\setminus x | do(x)) = \\frac{P(v)}{\\prod_{X \\in X} P(x|pa_X)}\n\\]\n만약 \\(X\\)가 단일 변수라면(Singleton), 이는 다음과 같이 표현됩니다.\n\\[\nP(v \\setminus x | do(x)) = \\frac{P(v)}{P(x|pa_X)} = P(v'' | x, pa_X)P(pa_X)\n\\] (여기서 \\(V'' = V \\setminus Pa_X \\setminus \\{X\\}\\)) [cite_start][cite: 200, 209].\n이 공식은 인과 추론 문제를 “어떻게 \\(P(x|pa_x)\\)(Propensity Score)로 관측 데이터를 역가중(Inverse weighting)할 것인가”의 문제로 연결해 줍니다."
  },
  {
    "objectID": "posts/lecture/L03/index.html#식별-가능성-identifiability-정의",
    "href": "posts/lecture/L03/index.html#식별-가능성-identifiability-정의",
    "title": "[Causal Inference] 03. Identification of Causal Effects",
    "section": "5.1. 식별 가능성 (Identifiability) 정의",
    "text": "5.1. 식별 가능성 (Identifiability) 정의\n[cite_start]인과 효과 \\(P(y|do(x))\\)가 인과 그래프 \\(G\\)로부터 식별 가능하다(Identifiable)는 것은, 관측 가능한 변수들의 확률 분포 \\(P(v)\\) (\\(P(v)&gt;0\\))만으로 \\(P(y|do(x))\\)를 유일하게(Uniquely) 계산해낼 수 있다는 뜻입니다[cite: 219].\n\\[P^{M_1}(v) = P^{M_2}(v) \\implies P^{M_1}(y|do(x)) = P^{M_2}(y|do(x))\\]\n\n\n\nFigure: Identifiability Venn Diagram. 관측 분포 P(v)와 그래프 G를 공유하는 모든 모델(M1, M2)이 동일한 인과 효과 P(y|do(x))를 내놓는다면, 그 효과는 식별 가능하다. 만약 그렇지 않다면(빨간 교집합 영역), 식별 불가능하다.\n\n\n[cite_start]즉, 데이터(\\(P(v)\\))와 가정(\\(G\\))이 같다면, 내부 파라미터가 달라도 결론(\\(Q\\))은 같아야 한다는 것입니다 [cite: 302-304]."
  },
  {
    "objectID": "posts/lecture/L03/index.html#general-theorem",
    "href": "posts/lecture/L03/index.html#general-theorem",
    "title": "[Causal Inference] 03. Identification of Causal Effects",
    "section": "6.1. General Theorem",
    "text": "6.1. General Theorem\n[cite_start]모든 변수 \\(V\\)가 측정된 마르코프 모형의 인과 그래프 \\(G\\)가 주어졌을 때, 임의의 집합 \\(X, Y\\)에 대한 인과 효과 \\(P(y|do(x))\\)는 식별 가능하며, 다음 두 단계로 계산됩니다 [cite: 361-364].\n\nTruncated Factorization: 전체 시스템의 개입 후 분포를 구합니다. \\[P(v' | do(x)) = \\prod_{V_i \\in V \\setminus X} P(v_i | pa_i)\\]\nMarginalization (Hence step): 관심 있는 결과 변수 \\(Y\\)를 제외한 나머지 변수(\\(V' \\setminus Y\\))를 합(Summation)하여 제거합니다. \\[P(y | do(x)) = \\sum_{V' \\setminus Y} \\prod_{V_i \\in V \\setminus X} P(v_i | pa_i)\\]"
  },
  {
    "objectID": "posts/lecture/L03/index.html#adjustment-by-direct-parents-singleton",
    "href": "posts/lecture/L03/index.html#adjustment-by-direct-parents-singleton",
    "title": "[Causal Inference] 03. Identification of Causal Effects",
    "section": "7.1. Adjustment by Direct Parents (Singleton)",
    "text": "7.1. Adjustment by Direct Parents (Singleton)\n[cite_start]단일 변수 \\(X\\)에 대해, 그 부모 변수들 \\(Pa_X\\)가 모두 관측되었다면, 인과 효과는 다음과 같이 부모 변수를 조정(Conditioning)하여 계산할 수 있습니다 [cite: 368-369].\n\\[\nP(y|do(x)) = \\sum_{pa_X} P(y|x, pa_X)P(pa_X)\n\\]\n이 공식은 “원인의 직접적인 원인(Parents)”을 통제하면 교란 요인을 차단할 수 있다는 직관을 수식화한 것입니다."
  },
  {
    "objectID": "posts/lecture/L03/index.html#adjustment-by-direct-parents-set-of-treatments---advanced",
    "href": "posts/lecture/L03/index.html#adjustment-by-direct-parents-set-of-treatments---advanced",
    "title": "[Causal Inference] 03. Identification of Causal Effects",
    "section": "7.2. Adjustment by Direct Parents (Set of Treatments) - Advanced",
    "text": "7.2. Adjustment by Direct Parents (Set of Treatments) - Advanced\n만약 \\(X\\)가 단일 변수가 아니라 변수들의 집합 \\(X = \\{X_1, ..., X_k\\}\\)라면 어떻게 될까요? [cite_start]변수들이 위상학적 순서(Topological order)로 정렬되어 있다고 가정할 때, 다음 조건이 만족되면 일반화된 조정 공식을 사용할 수 있습니다 [cite: 374-379].\nTheorem: 만약 모든 \\(i &lt; j\\)에 대해, \\(Pa_{X_j} \\setminus (X_{&lt;j} \\cup Pa_{X_{&lt;j}}^-)\\)가 \\(X_i\\)의 자손(Descendant)이 아니라면:\n\\[P(y|do(x)) = \\sum_{pa_X^-} P(y|x, pa_X^-)P(pa_X^-)\\] (여기서 \\(Pa_X^- = Pa_X \\setminus X\\))\n[cite_start]Proof Sketch (by Induction): [cite: 382-401]\n이 증명은 \\(P(x_{\\le i} | pa_{X_{\\le i}}^-)\\)가 \\(\\prod_{X \\in X_{\\le i}} P(x|pa_X)\\)와 같음을 보이는 귀납법을 사용합니다. 1. Base case: \\(i=1\\)일 때 성립함은 자명합니다. 2. Hypothesis: \\(i-1\\)까지 성립한다고 가정하고, \\(i\\)번째 단계에서 조건부 독립(d-separation)과 연쇄 법칙(Chain rule)을 사용하여 식을 전개합니다. 3. 핵심은 \\(P(pa_{X_i}' | x_{&lt;i}, pa_{X_{&lt;i}}^-)\\) 항이 \\(P(pa_{X_i}' | pa_{X_{&lt;i}}^-)\\)로 단순화되는 과정에 있으며, 이는 가정된 그래프 구조(자손이 아님) 덕분에 성립합니다.\n[cite_start]이 정리는 복잡한 다중 처치(Multiple Treatments) 상황에서도 부모 변수들을 적절히 조정하면 인과 효과를 식별할 수 있음을 보장합니다[cite: 414]."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-03/index.html",
    "href": "posts/lecture/L04/causal-inference-04-part-03/index.html",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 3)",
    "section": "",
    "text": "지난 포스트에서는 교란 편향(Confounding Bias)이 인과 효과 추정을 방해하는 주된 요인임을 살펴보았습니다.\n그렇다면 우리는 복잡한 인과 그래프(DAG)에서 어떤 변수들의 집합(\\(Z\\))을 조절(Control/Adjustment)해야 이 편향을 제거할 수 있을까요?\n이번 포스트에서는 그 해답이 되는 Back-door Criterion(백도어 기준)의 정의와 이를 이용한 보정 공식을 다룹니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-03/index.html#definition",
    "href": "posts/lecture/L04/causal-inference-04-part-03/index.html#definition",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 3)",
    "section": "2.1 Definition",
    "text": "2.1 Definition\n\n주어진 인과 그래프 \\(G\\)에서 변수 \\(X\\)와 \\(Y\\)에 대해, 변수들의 집합 \\(Z\\)가 다음 두 가지 조건을 만족할 때, \\(Z\\)는 Back-door Criterion을 만족한다고 정의합니다.\n\n\n(i) No node in \\(Z\\) is a descendant of \\(X\\). (\\(Z\\)에 속한 어떤 변수도 \\(X\\)의 자손이 아니어야 합니다.)\n(ii) \\(Z\\) blocks every path between \\(X\\) and \\(Y\\) that contains an arrow into \\(X\\). (\\(Z\\)는 \\(X\\)로 들어오는 화살표를 포함하는 \\(X\\)와 \\(Y\\) 사이의 모든 경로를 차단해야 합니다.)"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-03/index.html#의미-해석",
    "href": "posts/lecture/L04/causal-inference-04-part-03/index.html#의미-해석",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 3)",
    "section": "2.2 의미 해석",
    "text": "2.2 의미 해석\n\n조건 (i)은 \\(X\\)의 결과(Effect)로 나타나는 변수를 통제하지 말라는 뜻입니다. \\(X\\)의 자손을 통제하면 \\(X\\)가 \\(Y\\)에 미치는 실제 인과 경로를 막아버리거나 새로운 편향을 만들 수 있기 때문입니다.\n조건 (ii)의 “arrow into \\(X\\)”는 소위 백도어 경로(Back-door Path)를 의미합니다. 이는 \\(X\\)의 원인이 되는 변수들에 의해 생성되는 비인과적 상관관계(Spurious Correlation)의 경로입니다. 이 경로를 차단함으로써 우리는 \\(X\\)에서 \\(Y\\)로 나가는 순수한 인과적 경로만 남길 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-03/index.html#분석-포인트",
    "href": "posts/lecture/L04/causal-inference-04-part-03/index.html#분석-포인트",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 3)",
    "section": "5.1 분석 포인트",
    "text": "5.1 분석 포인트\n\n이 그래프에서 \\(X\\)와 \\(Y\\) 사이의 백도어 경로를 차단해야 합니다. \\(X\\)에서 나가는 화살표를 지운 그래프(\\(G_{\\underline{X}}\\))를 상상했을 때 \\(X\\)와 \\(Y\\)가 d-separation 되는지 확인하는 것과 같습니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-03/index.html#가능한-z-집합의-예시",
    "href": "posts/lecture/L04/causal-inference-04-part-03/index.html#가능한-z-집합의-예시",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 3)",
    "section": "5.2 가능한 \\(Z\\) 집합의 예시",
    "text": "5.2 가능한 \\(Z\\) 집합의 예시\n\n\\(Z = \\{Z_4, Z_2\\}\\)\n\\(Z = \\{Z_4, Z_5\\}\\)\n\\(Z = \\{Z_4, Z_2, Z_5\\}\\)"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-03/index.html#주의할-점-collider-z_4",
    "href": "posts/lecture/L04/causal-inference-04-part-03/index.html#주의할-점-collider-z_4",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 3)",
    "section": "5.3 주의할 점: Collider (\\(Z_4\\))",
    "text": "5.3 주의할 점: Collider (\\(Z_4\\))\n\n위 그래프에서 \\(Z_4\\)는 \\(Z_1 \\to Z_4 \\leftarrow Z_2\\) 구조를 갖는 Collider입니다.\n만약 \\(Z_4\\)를 집합에 포함하지 않으면, \\(Z_1 - Z_4 - Z_2\\) 경로는 자연스럽게 막혀(Blocked) 있습니다.\n하지만 \\(Z_4\\)를 집합에 포함시켜 조건부로 잡으면(Conditioning), 오히려 \\(Z_1\\)과 \\(Z_2\\) 사이의 경로가 열리게 됩니다\n따라서 \\(Z_4\\)를 조정 변수로 사용할 때는, 이로 인해 열리는 다른 경로(\\(Z_1 \\dots Z_2\\))를 막아줄 추가적인 변수(\\(Z_2\\) 등)를 함께 포함해야 합니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-03/index.html#case-z-emptyset-no-confounding",
    "href": "posts/lecture/L04/causal-inference-04-part-03/index.html#case-z-emptyset-no-confounding",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 3)",
    "section": "5.4 Case: \\(Z = \\emptyset\\) (No Confounding)",
    "text": "5.4 Case: \\(Z = \\emptyset\\) (No Confounding)\n\n만약 \\(X\\)로 들어오는 백도어 경로가 아예 없는 그래프라면 어떨까요?\n\n\n\n\nFigure 3. Case where no adjustment is needed\n\n\n\n이 경우 공집합 \\(Z = \\emptyset\\)도 Back-door Criterion을 만족합니다.\n즉, 별도의 조정 없이 관측된 조건부 확률이 곧 인과 효과가 됩니다.\n\n\\[P(y|x) = P(y|do(x))\\]\n\n이것이 바로 “교란이 없으면 상관관계는 인과관계이다(Correlation is Causation)”가 성립하는 유일한 순간입니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-03/index.html#recap-adjustment-by-direct-parents",
    "href": "posts/lecture/L04/causal-inference-04-part-03/index.html#recap-adjustment-by-direct-parents",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 3)",
    "section": "6.1 Recap: Adjustment by Direct Parents",
    "text": "6.1 Recap: Adjustment by Direct Parents\n\n일반적으로 \\(X\\)의 모든 직접적인 부모(Direct Parents, \\(Pa_X\\))를 통제하면 Back-door Criterion을 항상 만족합니다.\n\n\\[P(y|do(x)) = \\sum_{pa_X} P(y | x, pa_X) P(pa_X)\\]\n\n하지만 모든 부모 변수를 관측하는 것은 현실적으로 어려울 수 있습니다.\n그렇다면, 부모가 아닌 Back-door Criterion을 만족하는 임의의 집합 \\(Z\\)를 통제해도 왜 동일한 결과가 나올까요?\n아래 증명은 Direct Parents Adjustment 공식에서 시작하여 Back-door Adjustment 공식으로 유도되는 과정을 보여줍니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-03/index.html#가정-assumptions",
    "href": "posts/lecture/L04/causal-inference-04-part-03/index.html#가정-assumptions",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 3)",
    "section": "6.2 가정 (Assumptions)",
    "text": "6.2 가정 (Assumptions)\n\n집합 \\(Z\\)가 Back-door criterion을 만족한다고 가정합시다.\nLet \\(Z^- = Z \\setminus Pa_X\\) (부모 변수를 제외한 나머지 \\(Z\\)의 요소들).\n\n\nCondition (i): \\(Z\\)의 어떤 노드도 \\(X\\)의 자손이 아님. \\[\\Rightarrow X \\perp (Z \\setminus Pa_X) \\mid Pa_X\\] \\[\\Rightarrow P(z^{-} | x, pa_{X}) = P(z^{-} | pa_{X})\\]\n\n“미래는 과거를 바꿀 수 없다”는 원리입니다.\n인과 그래프에서 부모(\\(Pa_{X}\\))와 \\(Z\\)는 \\(X\\)보다 먼저 일어난 일(또는 원인)이고, \\(X\\)는 그 결과입니다.\n이미 부모(\\(Pa_{X}\\))의 상태를 다 알고 있다면, 결과인 \\(X\\)가 무엇이든 간에 그 원인이나 별개의 사건인 \\(Z\\)의 확률은 변하지 않습니다.\n\nCondition (ii): \\(Z\\)는 \\(X\\)로 들어오는 모든 뒷문 경로를 차단함. \\[\\Rightarrow Y \\perp (Pa_X \\setminus Z) \\mid Z, X\\] \\[\\Rightarrow P(y | x, pa_{X}, z^{-}) = P(y | x, z)\\] (\\(Z\\)와 \\(X\\)가 주어졌을 때, \\(Y\\)는 \\(Z\\)에 포함되지 않은 나머지 부모들과 독립이다)\n\n“Z가 이미 충분한 정보를 담고 있다”는 원리입니다.\n원래 \\(Y\\)를 예측하려면 교란 요인인 모든 부모들(\\(Pa_{X}\\))을 다 봐야 합니다. 하지만 \\(Z\\)가 ’백도어 기준’을 만족한다는 것은, \\(Z\\)가 부모들이 \\(Y\\)에 미치는 교란을 대신해서 다 막아주고 있다는 뜻입니다.\n따라서 일단 \\(Z\\)를 알고 나면, 굳이 \\(Z\\)에 포함되지 않은 나머지 부모들(\\(Pa_{X}\\))을 추가로 더 안다고 해서 \\(Y\\)에 대한 예측이 달라지지 않습니다. \\(Z\\)가 그 역할을 완벽히 대체했기 때문입니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-03/index.html#증명-derivation",
    "href": "posts/lecture/L04/causal-inference-04-part-03/index.html#증명-derivation",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 3)",
    "section": "6.3 증명 (Derivation)",
    "text": "6.3 증명 (Derivation)\n\n부모 변수를 통한 조정(Adjustment by Direct Parents) 공식에서 시작합니다.\n\n\\[\n\\begin{aligned}\nP(y|do(x)) &= \\sum_{pa_X} P(y|x, pa_X)P(pa_X) \\\\\n&= \\sum_{z^-, pa_X} P(y|x, pa_X, z^-)P(z^-|x, pa_X)P(pa_X) && \\because \\text{Expand by } Z^- \\text{ (Total Probability)} \\\\\n&= \\sum_{z^-, pa_X} P(y|x, z)P(z^-|pa_X)P(pa_X) && \\because \\text{Apply Assumptions Condition (i) \\& (ii)} \\\\\n&= \\sum_{z^-, pa_X} P(y|x, z)P(z^-, pa_X) && \\because \\text{Chain Rule } P(A|B)P(B) = P(A,B) \\\\\n&= \\sum_{z} P(y|x, z) \\sum_{pa_X \\setminus z} P(z^-, pa_X) && \\because \\text{Rearrange Summation } (Z \\cup (Pa_X \\setminus Z) = \\{Z, Pa_X\\}) \\\\\n&= \\sum_{z} P(y|x, z)P(z) && \\because \\text{Marginalize out } Pa_X \\setminus Z\n\\end{aligned}\n\\]\n\n결론: \n\n\nAdjustment by \\(Z\\) is equivalent to adjustment by direct parents whenever \\(Z\\) is back-door admissible.\n\n\n즉, \\(Z\\)가 Back-door criterion만 만족한다면, 직접적인 부모를 모두 측정하지 못하더라도 \\(Z\\)를 통해 인과 효과를 정확히 계산할 수 있음이 수학적으로 증명됩니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-05/index.html",
    "href": "posts/lecture/L04/causal-inference-04-part-05/index.html",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 5)",
    "section": "",
    "text": "이전 포스트들에서 배운 교란(Confounding)과 Back-door Criterion을 실제 코드로 구현해 보는 시간입니다.\n특히 심슨의 역설(Simpson’s Paradox) 상황을 시뮬레이션하고, DoWhy 라이브러리의 성향 점수 층화(Propensity Score Stratification) 방법을 통해 올바른 인과 효과를 추정해 봅니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-05/index.html#모델-정의-및-식별-modeling-identification",
    "href": "posts/lecture/L04/causal-inference-04-part-05/index.html#모델-정의-및-식별-modeling-identification",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 5)",
    "section": "5.1 모델 정의 및 식별 (Modeling & Identification)",
    "text": "5.1 모델 정의 및 식별 (Modeling & Identification)\n\n인과 그래프(Graph)를 정의하고 Back-door 기준을 통해 식별 가능성을 확인합니다.\n\n\n\nCode\n# 단계 1: 모델 정의 (Causal Graph 생성)\nmodel = CausalModel(\n    data=df,\n    treatment='Exercise',\n    outcome='Cholesterol',\n    common_causes=['Age'] # 교란 변수 지정\n)\n\n# 단계 2: 식별 (Identification)\nidentified_estimand = model.identify_effect()\nprint(identified_estimand)\n\n\nEstimand type: EstimandType.NONPARAMETRIC_ATE\n\n### Estimand : 1\nEstimand name: backdoor\nEstimand expression:\n     d                         \n───────────(E[Cholesterol|Age])\nd[Exercise]                    \nEstimand assumption 1, Unconfoundedness: If U→{Exercise} and U→Cholesterol then P(Cholesterol|Exercise,Age,U) = P(Cholesterol|Exercise,Age)\n\n### Estimand : 2\nEstimand name: iv\nNo such variable(s) found!\n\n### Estimand : 3\nEstimand name: frontdoor\nNo such variable(s) found!"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-05/index.html#인과-효과-추정-estimation-stratification",
    "href": "posts/lecture/L04/causal-inference-04-part-05/index.html#인과-효과-추정-estimation-stratification",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 5)",
    "section": "5.2 인과 효과 추정 (Estimation: Stratification)",
    "text": "5.2 인과 효과 추정 (Estimation: Stratification)\n\n여기서는 성향 점수 층화(Propensity Score Stratification) 방법을 사용합니다. 나이가 비슷하여 운동할 확률(성향 점수)이 유사한 사람들끼리 묶어서 비교하는 방식입니다.\n\n\n\nCode\n# 단계 3: 추정 (Estimation)\n# num_strata=5: 데이터를 성향 점수에 따라 5개 구간으로 나눔\nestimate = model.estimate_effect(\n    identified_estimand,\n    method_name=\"backdoor.propensity_score_stratification\",\n    method_params={'num_strata': 5, 'clipping_threshold': 5}\n)\n\nprint(\"=\"*50)\nprint(f\"2. 인과 효과 추정 (Causal Estimate): {estimate.value:.4f}\")\nprint(f\"   -&gt; 실제 효과 (-10.0)에 매우 근접함\")\nprint(\"=\"*50)\n\n\n==================================================\n2. 인과 효과 추정 (Causal Estimate): -9.1264\n   -&gt; 실제 효과 (-10.0)에 매우 근접함\n=================================================="
  },
  {
    "objectID": "posts/lecture/L05/part-01/index.html",
    "href": "posts/lecture/L05/part-01/index.html",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 1)",
    "section": "",
    "text": "인과 추론(Causal Inference)의 핵심 목표 중 하나는 관찰된 데이터 분포 \\(P(V)\\)로부터 개입 분포(Interventional Distribution) \\(P(Y|do(X))\\)를 식별(Identification)하는 것입니다. 이를 위한 가장 강력하고 널리 알려진 도구는 Back-door Criterion입니다.\n하지만 Back-door Criterion은 충분조건(sufficient condition)일 뿐 필요조건(necessary condition)은 아닙니다. 즉, Back-door Criterion을 만족하지 못하더라도 \\(P(Y|do(X))\\)를 식별할 수 있는 경우가 존재합니다. [cite_start]이번 포스트에서는 Back-door Criterion을 복습하고, 왜 더 일반화된 Adjustment Criterion이 필요한지 그 동기(Motivation)와 한계(Tightness)를 구체적인 그래프 예시를 통해 살펴봅니다[cite: 5, 8, 13].\n\n[cite_start]Note: 본 포스트는 서울대학교 데이터사이언스 대학원 이상학 교수님의 “인과추론 및 실습” 강의 자료를 바탕으로 작성되었습니다[cite: 1, 2, 3]."
  },
  {
    "objectID": "posts/lecture/L05/part-01/index.html#definition",
    "href": "posts/lecture/L05/part-01/index.html#definition",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 1)",
    "section": "2.1. Definition",
    "text": "2.1. Definition\n[cite_start]어떤 변수 집합 \\(Z\\)가 변수 쌍 \\((X, Y)\\)에 대해 Back-door Criterion을 만족하려면 다음 두 가지 조건을 충족해야 합니다[cite: 18, 23, 32].\n\n[cite_start]Condition (i) - No Descendants: \\(Z\\)의 어떤 노드도 \\(X\\)의 후손(descendant)이 아니어야 합니다[cite: 19, 24, 34].\n[cite_start]Condition (ii) - Blocking Paths: \\(Z\\)는 \\(X\\)로 들어가는 화살표를 포함하는 \\(X\\)와 \\(Y\\) 사이의 모든 경로(path)를 차단(block)해야 합니다[cite: 26, 35]."
  },
  {
    "objectID": "posts/lecture/L05/part-01/index.html#identification-formula",
    "href": "posts/lecture/L05/part-01/index.html#identification-formula",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 1)",
    "section": "2.2. Identification Formula",
    "text": "2.2. Identification Formula\n[cite_start]만약 집합 \\(Z\\)가 위 조건을 만족한다면, \\(Y\\)에 대한 \\(X\\)의 인과 효과는 다음과 같이 식별 가능합니다[cite: 27, 36, 37].\n\\[\nP(y|do(x)) = \\sum_{z} P(y|x,z)P(z)\n\\]\n이 식은 우리가 \\(do\\)-calculus나 가상의 실험 없이, 관찰된 데이터의 조건부 확률 \\(P(y|x,z)\\)와 주변 확률 \\(P(z)\\)만으로 인과 효과를 계산할 수 있음을 의미합니다."
  },
  {
    "objectID": "posts/lecture/L05/part-01/index.html#counter-example-graph",
    "href": "posts/lecture/L05/part-01/index.html#counter-example-graph",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 1)",
    "section": "5.1. Counter-Example Graph",
    "text": "5.1. Counter-Example Graph\n다음과 같은 인과 그래프를 고려해 봅시다. [cite_start]여기서 \\(X = \\{X_1, X_2\\}\\)이고 \\(Y\\)는 결과 변수입니다[cite: 76, 78].\n [cite_start](그림 설명: \\(X_1 \\to Z_1 \\to Z_2 \\to X_2 \\to Y\\), \\(X_1 \\to Y\\). 그리고 \\(Z_2 \\leftrightarrow Y\\) (점선) 관계가 존재함. \\(X = \\{X_1, X_2\\}\\)가 처리 변수 집합임[cite: 76, 79, 80, 81, 82, 83].)"
  },
  {
    "objectID": "posts/lecture/L05/part-01/index.html#why-back-door-fails-here",
    "href": "posts/lecture/L05/part-01/index.html#why-back-door-fails-here",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 1)",
    "section": "5.2. Why Back-door Fails here?",
    "text": "5.2. Why Back-door Fails here?\n이 그래프에서 가능한 모든 조정 변수 후보는 \\(\\{Z_1, Z_2\\}\\)입니다. [cite_start]그러나 \\(Z_1\\)과 \\(Z_2\\)는 모두 \\(X_1\\)의 후손(descendant)입니다[cite: 86].\n\nBack-door Criterion의 Condition (i): “\\(Z\\)의 어떤 노드도 \\(X\\)의 후손이면 안 된다.”\n[cite_start]이 그래프에서는 \\(X=\\{X_1, X_2\\}\\)이므로, \\(X_1\\)의 후손인 \\(Z_1, Z_2\\)를 조정 집합에 포함하는 순간 조건 (i)을 위반하게 됩니다[cite: 78].\n\n따라서, 이 그래프에서는 Back-door Admissible Set이 존재하지 않습니다."
  },
  {
    "objectID": "posts/lecture/L05/part-01/index.html#but-adjustment-is-possible",
    "href": "posts/lecture/L05/part-01/index.html#but-adjustment-is-possible",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 1)",
    "section": "5.3. But Adjustment IS Possible!",
    "text": "5.3. But Adjustment IS Possible!\n[cite_start]놀랍게도, \\(do\\)-calculus나 다른 방법을 통해 유도해보면 이 그래프에서 \\(P(y|do(x))\\)는 여전히 표준 조정 공식(Standard Adjustment Formula) 형태로 식별 가능합니다[cite: 93, 94].\n\\[\nP(y|do(x)) = \\sum_{z} P(y|x,z)P(z)\n\\]\n이것이 시사하는 바는 명확합니다.\n\nBack-door Criterion은 너무 보수적(strict)입니다.\n[cite_start]\\(X\\)의 후손(descendant)이라 할지라도, 조정을 위해 사용될 수 있으며 심지어 필요한 경우도 있습니다[cite: 102].\n[cite_start]특히, \\(X\\)의 후손이면서 동시에 \\(X\\)의 조상(ancestor)인 변수(예: \\(X_1\\)의 후손이면서 \\(X_2\\)의 조상인 \\(Z_2\\))들은 인과 경로를 방해하지 않으면서 교란을 제거하는 데 사용될 수 있습니다[cite: 103]."
  },
  {
    "objectID": "posts/lecture/L05/part-01/index.html#conclusion-motivation-for-adjustment-criterion",
    "href": "posts/lecture/L05/part-01/index.html#conclusion-motivation-for-adjustment-criterion",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 1)",
    "section": "5.4. Conclusion: Motivation for Adjustment Criterion",
    "text": "5.4. Conclusion: Motivation for Adjustment Criterion\n결국 우리는 Back-door Criterion보다 더 일반화된 기준이 필요합니다. [cite_start]“무조건 후손은 안 된다”가 아니라, “정말 피해야 할 변수는 무엇인가?”(What are the variables that we really need to avoid?)를 정의해야 합니다[cite: 104].\n[cite_start]Condition (i)의 원래 목적은 인과 경로(Causal Path)를 보존(preserve)하는 것입니다[cite: 99, 100]. 따라서 후손이더라도 인과 경로를 막지 않는다면 조정 집합에 포함시킬 수 있어야 합니다. 이것이 바로 다음 포스트에서 다룰 Adjustment Criterion의 등장 배경입니다."
  },
  {
    "objectID": "posts/lecture/L05/part-04/index.html",
    "href": "posts/lecture/L05/part-04/index.html",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 4)",
    "section": "",
    "text": "지금까지 우리는 Judea Pearl의 SCM(Structural Causal Model) 관점에서 인과 효과를 식별(Identification)하는 과정을 살펴보았습니다. Back-door Criterion부터 시작해, 더 일반화된 Adjustment Criterion, 그리고 유효한 조정 집합(Admissible Set)을 찾는 알고리즘까지 다루었습니다.\n이번 마지막 포스트에서는 이 그래프 기반의 접근법이 통계학 및 경제학에서 널리 쓰이는 Rubin의 Potential Outcome Framework와 어떻게 연결되는지 설명합니다. 특히, 인과 추론의 핵심 가정인 Conditional Ignorability가 그래프 상에서 어떻게 정당화되는지 알아보고, Adjustment Criterion 전체 내용을 요약합니다."
  },
  {
    "objectID": "posts/lecture/L05/part-04/index.html#definition",
    "href": "posts/lecture/L05/part-04/index.html#definition",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 4)",
    "section": "2.1. Definition",
    "text": "2.1. Definition\nConditional Ignorability는 반사실적(Counterfactual) 표기법을 사용하여 다음과 같이 정의됩니다.\n\\[\nY_{x} \\perp\\!\\!\\perp X \\mid Z\n\\]\n[cite_start][cite: 723-724, 733]\n여기서: * \\(Y_{x}\\): 처리가 \\(X=x\\)로 고정되었을 때의 잠재적 결과 (Potential Outcome) * \\(X\\): 실제 관찰된 처리 (Treatment) * \\(Z\\): 공변량 집합 (Covariates)\n이 식의 의미는 “공변량 \\(Z\\)를 통제(Conditioning)했을 때, 잠재적 결과 \\(Y_x\\)는 처리 \\(X\\)의 할당과 독립적이다”라는 것입니다. 즉, \\(Z\\)가 주어지면, 처리를 받은 그룹과 받지 않은 그룹 간에 체계적인 차이(교란 요인에 의한 편향)가 사라져 마치 무작위 할당(Random Assignment)된 것과 같아짐을 의미합니다."
  },
  {
    "objectID": "posts/lecture/L05/part-04/index.html#mathematical-equivalence",
    "href": "posts/lecture/L05/part-04/index.html#mathematical-equivalence",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 4)",
    "section": "2.2. Mathematical Equivalence",
    "text": "2.2. Mathematical Equivalence\n이 가정은 SCM의 \\(do\\)-calculus 관점에서 다음과 같은 확률적 동치로 표현됩니다.\n\\[\nP(y \\mid do(x), z) = P(y \\mid x, z)\n\\]\n[cite_start][cite: 729, 734]\n이 등식은 개입(Intervention) 후의 확률 분포가 관찰(Observation) 된 조건부 확률 분포와 같아짐을 보여줍니다. 즉, \\(Z\\)가 교란 요인을 모두 차단했다면, 단순히 데이터를 \\(Z\\)로 층화하여 \\(X\\)와 \\(Y\\)의 관계를 보는 것만으로 인과 효과를 계산할 수 있다는 뜻입니다."
  },
  {
    "objectID": "posts/lecture/L05/part-04/index.html#the-role-of-adjustment-criterion",
    "href": "posts/lecture/L05/part-04/index.html#the-role-of-adjustment-criterion",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 4)",
    "section": "2.3. The Role of Adjustment Criterion",
    "text": "2.3. The Role of Adjustment Criterion\nPotential Outcome 프레임워크에서는 연구자가 “우리는 필요한 모든 교란 요인 \\(Z\\)를 측정했다”고 가정(Assume)하고 분석을 시작하는 경우가 많습니다.\n하지만 “그 가정이 타당한가?”, “어떤 \\(Z\\)를 포함해야 이 가정이 성립하는가?”라는 질문에 대해 Potential Outcome 프레임워크 자체만으로는 답하기 어려울 때가 있습니다.\n여기서 Adjustment Criterion이 강력한 이론적 도구(Theoretical Tool)가 됩니다.\n\n[cite_start]“While this is usually ‘assumed’ to hold in the PO framework, the adjustment criterion provides a justification under what conditions such set exists based on a given model of reality.” [cite: 735]\n\n즉, 우리가 현실 세계에 대한 모델(Causal Graph)을 그릴 수 있다면, Adjustment Criterion은 Conditional Ignorability 가정이 성립하기 위한 \\(Z\\)의 조건을 수학적으로 증명해 줍니다. 그래프 상에서 \\(Z\\)가 Back-door/Adjustment Criterion을 만족한다면, \\(Y_x \\perp\\!\\!\\perp X | Z\\)는 가정이 아니라 정리(Theorem)로서 성립하게 됩니다.\n\n\n\nFigure 1: The bridge between SCM and PO Frameworks. 그래프(Graph)를 통해 현실을 모델링하면, Adjustment Criterion이 Ignorability 가정을 정당화(Justify)해주고, 이를 통해 통계적 추정(Estimation)이 가능해진다."
  },
  {
    "objectID": "posts/lecture/L05/part-04/index.html#why-adjustment",
    "href": "posts/lecture/L05/part-04/index.html#why-adjustment",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 4)",
    "section": "3.1. Why Adjustment?",
    "text": "3.1. Why Adjustment?\n[cite_start]조정(Adjustment)은 데이터 과학 전반에서 인과 효과를 식별하기 위해 가장 널리 사용되는 기법입니다. [cite: 738, 744, 750, 756] 관찰 데이터에서 혼란 변수(Confounder)의 영향을 제거하여 인과적 결론을 도출하는 표준적인 방법론입니다."
  },
  {
    "objectID": "posts/lecture/L05/part-04/index.html#identification-principle",
    "href": "posts/lecture/L05/part-04/index.html#identification-principle",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 4)",
    "section": "3.2. Identification Principle",
    "text": "3.2. Identification Principle\n[cite_start]Back-door Criterion과 이를 일반화한 Adjustment Criterion은 어떤 변수 집합 \\(Z\\)를 조정해야 타당한지(validity)를 판단하는 원칙적인 조건(Principled condition)을 제공합니다. [cite: 739, 745, 751, 757]\n\nBack-door Criterion: \\(X\\)의 후손을 제외하고, 모든 Back-door Path를 차단하라.\nAdjustment Criterion: \\(X\\)의 후손이라도 인과 경로(Proper Causal Path)를 방해하지 않으면 사용 가능하다. (Back-door의 Tightness 문제 해결)"
  },
  {
    "objectID": "posts/lecture/L05/part-04/index.html#algorithmic-discovery",
    "href": "posts/lecture/L05/part-04/index.html#algorithmic-discovery",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 4)",
    "section": "3.3. Algorithmic Discovery",
    "text": "3.3. Algorithmic Discovery\n[cite_start]우리는 그래프와 목표 인과 효과가 주어졌을 때, 유효한 조정 집합(Admissible sets)을 체계적이고 효율적으로(Systematically and Efficiently) 찾을 수 있습니다. [cite: 740, 746, 752, 758]\n\nConstructive Method: \\(Z_0 = An(X \\cup Y \\cup I) \\cap R\\) 등의 공식을 통해 존재 여부를 즉시 확인 가능.\nPolynomial Delay Algorithm: 가능한 모든 유효 집합을 합리적인 시간 복잡도 내에서 나열 가능."
  },
  {
    "objectID": "posts/lecture/L05/part-04/index.html#from-identification-to-estimation",
    "href": "posts/lecture/L05/part-04/index.html#from-identification-to-estimation",
    "title": "[Causal Inference] 05. Adjustment Criterion (Part 4)",
    "section": "3.4. From Identification to Estimation",
    "text": "3.4. From Identification to Estimation\n식별(Identification)은 인과 추론의 첫 단계일 뿐입니다. [cite_start]유효한 조정 집합 \\(Z\\)를 찾았다면(Identification 단계 완료), 이제 유한한 샘플(Finite samples)로부터 목표 효과를 계산하는 추정(Estimation) 단계로 넘어가야 합니다. [cite: 741, 747, 753, 759]\n대표적인 추정 기법은 다음과 같습니다: * IPW (Inverse Probability Weighting): 성향 점수(Propensity Score)를 이용한 가중치 부여. * Standardization (G-computation): 조건부 평균을 모델링하여 전체 평균 계산. * Doubly Robust Estimators: 위 두 방법을 결합하여 강건성 확보.\n결국 Adjustment Criterion은 “무엇을 측정하고 모델링에 포함해야 하는가?”에 대한 명확한 가이드라인을 제시함으로써, 이후의 통계적 추정이 편향 없이 수행될 수 있는 기반을 마련해 줍니다."
  },
  {
    "objectID": "posts/lecture/L02/part-01/index.html",
    "href": "posts/lecture/L02/part-01/index.html",
    "title": "[Causal Inference] 02. Causal Models and Graphs (Part 1)",
    "section": "",
    "text": "전통적인 통계학이나 머신러닝의 추론(Inference) 패러다임은 데이터의 결합 확률 분포(Joint Distribution) \\(P(\\mathbf{v})\\)를 찾아내는 것에 집중합니다. 예를 들어, “상품 A를 산 고객이 상품 B도 살 확률은 얼마인가?”(\\(P(B|A)\\))와 같은 질문은 관측된 데이터의 패턴(Association)만으로 충분히 답할 수 있습니다.\n하지만 현실의 문제 해결은 종종 “만약 우리가 X를 변화시킨다면, Y는 어떻게 변할까?”라는 질문을 던집니다. * 가격을 두 배로 올리면 판매량은 어떻게 될까? * 흡연을 금지하면 암 발병률은 낮아질까?\n이러한 질문은 데이터 자체(\\(P\\))가 아니라 데이터가 생성되는 현실의 메커니즘(Reality)에 대한 이해를 요구합니다. 이번 포스트에서는 인과 추론의 핵심 언어인 구조적 인과 모델(Structural Causal Model, SCM)과 이를 시각화한 인과 그래프(Causal Graph)에 대해 다룹니다.\n\n\n\nFigure: 통계적 추론과 인과적 추론의 차이. 통계적 추론은 데이터 \\(P\\) 내에서의 성질 \\(Q(P)\\)를 찾지만, 인과 추론은 데이터 생성 모델 \\(M\\)을 통해 현실의 메커니즘을 이해하고, 개입 후의 분포 \\(P'\\)를 추정하려 한다.\n\n\n\n\n왜 데이터만으로는 충분하지 않을까요? 강의 자료에 제시된 ‘약물 투여와 생존율’ 예시를 봅시다.\n\n상황: 특정 도시에 전염병이 돌고 있고, 치료제(Drug)가 있습니다.\n숨겨진 진실(Reality):\n\n부유층(Rich)은 약물 복용 여부와 상관없이 생존합니다 (좋은 생활 환경).\n빈곤층(Poor)은 약물을 복용하면 알레르기 반응으로 사망하고, 복용하지 않으면 생존합니다(자연 면역).\n의사들은 부유층에게만 주로 약을 처방합니다(비용 문제).\n\n\n이 경우 데이터만 보면 “약물을 복용한 집단(대부분 부유층)”의 생존율이 높게 나타납니다. 알고리즘은 “약을 먹어라”라고 추천할 것입니다. 하지만 실제 메커니즘(빈곤층에게는 치명적)을 안다면 빈곤층에게 약을 주면 안 된다는 정반대의 결론에 도달해야 합니다. 즉, 데이터 생성 과정(Data Generating Process)을 모델링하지 않으면 잘못된 의사결정을 내리게 됩니다."
  },
  {
    "objectID": "posts/lecture/L02/part-01/index.html#motivation-simpsons-paradox-example",
    "href": "posts/lecture/L02/part-01/index.html#motivation-simpsons-paradox-example",
    "title": "[Causal Inference] 02. Causal Models and Graphs (Part 1)",
    "section": "",
    "text": "왜 데이터만으로는 충분하지 않을까요? 강의 자료에 제시된 ‘약물 투여와 생존율’ 예시를 봅시다.\n\n상황: 특정 도시에 전염병이 돌고 있고, 치료제(Drug)가 있습니다.\n숨겨진 진실(Reality):\n\n부유층(Rich)은 약물 복용 여부와 상관없이 생존합니다 (좋은 생활 환경).\n빈곤층(Poor)은 약물을 복용하면 알레르기 반응으로 사망하고, 복용하지 않으면 생존합니다(자연 면역).\n의사들은 부유층에게만 주로 약을 처방합니다(비용 문제).\n\n\n이 경우 데이터만 보면 “약물을 복용한 집단(대부분 부유층)”의 생존율이 높게 나타납니다. 알고리즘은 “약을 먹어라”라고 추천할 것입니다. 하지만 실제 메커니즘(빈곤층에게는 치명적)을 안다면 빈곤층에게 약을 주면 안 된다는 정반대의 결론에 도달해야 합니다. 즉, 데이터 생성 과정(Data Generating Process)을 모델링하지 않으면 잘못된 의사결정을 내리게 됩니다."
  },
  {
    "objectID": "posts/lecture/L02/part-01/index.html#definition",
    "href": "posts/lecture/L02/part-01/index.html#definition",
    "title": "[Causal Inference] 02. Causal Models and Graphs (Part 1)",
    "section": "2.1 Definition",
    "text": "2.1 Definition\nSCM \\(\\mathcal{M}\\)은 다음 4가지 요소의 튜플 \\(\\langle V, U, F, P(U) \\rangle\\)로 정의됩니다.\n\n\\(V = \\{V_1, ..., V_n\\}\\): 내생 변수(Endogenous variables). 우리가 관측할 수 있는 변수들입니다. (예: 흡연 여부, 폐암 발병 여부)\n\\(U = \\{U_1, ..., U_m\\}\\): 외생 변수(Exogenous variables). 모델 내부의 다른 변수에 의해 설명되지 않는, 시스템 외부에서 결정되는 변수들입니다. (예: 유전적 요인, 미관측 환경 요인)\n\\(F = \\{f_1, ..., f_n\\}\\): 구조적 함수(Structural functions). 각 내생 변수 \\(V_i\\)가 어떻게 결정되는지를 나타내는 함수입니다. \\[v_i \\leftarrow f_i(pa_i, u_i)\\] 여기서 \\(pa_i \\subseteq V \\setminus \\{V_i\\}\\)는 \\(V_i\\)의 부모(Parents) 변수 집합이고, \\(u_i \\subseteq U\\)는 관련된 외생 변수입니다.\n\\(P(U)\\): 외생 변수 \\(U\\)에 대한 확률 분포입니다.\n\n\nKey Idea: SCM에서 자연(Nature)은 결정론적(Deterministic) 함수 \\(F\\)와 확률적(Probabilistic) 노이즈 \\(P(U)\\)의 결합으로 세상을 정의합니다.\n\n\n\n\nFigure: SCM의 개념적 도식. 외생 변수 U가 확률 분포 P(U)를 따르고, 함수 F를 통해 내생 변수 V의 값을 결정하여 관측 데이터 분포 P(V)를 유도한다."
  },
  {
    "objectID": "posts/lecture/L02/part-01/index.html#scm-induces-a-distribution-pv",
    "href": "posts/lecture/L02/part-01/index.html#scm-induces-a-distribution-pv",
    "title": "[Causal Inference] 02. Causal Models and Graphs (Part 1)",
    "section": "2.2 SCM Induces a Distribution \\(P(V)\\)",
    "text": "2.2 SCM Induces a Distribution \\(P(V)\\)\nSCM은 단순히 변수 간의 관계만 정의하는 것이 아니라, 관측 가능한 변수 \\(V\\)의 결합 확률 분포 \\(P(V)\\)를 유도(Induce)합니다.\n\\[P(\\mathbf{v}) = \\sum_{\\mathbf{u} : Y(\\mathbf{u}) = \\mathbf{v}} P(\\mathbf{u})\\]\n즉, 우리가 관측하는 데이터의 분포는 외생 변수의 불확실성(\\(P(U)\\))이 함수 \\(F\\)를 통과하여 내생 변수 \\(V\\)로 전파된 결과입니다."
  },
  {
    "objectID": "posts/lecture/L02/part-01/index.html#construction-rules",
    "href": "posts/lecture/L02/part-01/index.html#construction-rules",
    "title": "[Causal Inference] 02. Causal Models and Graphs (Part 1)",
    "section": "3.1 Construction Rules",
    "text": "3.1 Construction Rules\nSCM \\(\\mathcal{M}\\)으로부터 인과 그래프 \\(\\mathcal{G}\\)를 그리는 규칙은 다음과 같습니다.\n\nNodes: 각 내생 변수 \\(V_i\\)를 노드(Vertex)로 그립니다.\nDirected Edges (\\(\\rightarrow\\)): 함수 \\(f_i\\)에서 \\(V_j\\)가 \\(V_i\\)의 입력(\\(pa_i\\))으로 사용된다면, \\(V_j \\to V_i\\) 화살표를 그립니다.\nBidirected Edges (\\(\\leftrightarrow\\)): 두 변수 \\(V_i, V_j\\)에 영향을 주는 외생 변수 \\(U_i, U_j\\)가 서로 상관관계가 있거나(Correlated), 같은 외생 변수를 공유한다면 점선 양방향 화살표로 연결합니다. 이는 미관측 교란 요인(Unobserved Confounder)의 존재를 의미합니다.\n\n\n\n\nFigure: SCM에서 인과 그래프로의 변환 예시. (좌) 수식으로 표현된 SCM, (우) 이에 대응하는 DAG. 외생 변수 U는 보통 그래프에서 생략되거나 점선으로 표현된다."
  },
  {
    "objectID": "posts/lecture/L02/part-01/index.html#terminology",
    "href": "posts/lecture/L02/part-01/index.html#terminology",
    "title": "[Causal Inference] 02. Causal Models and Graphs (Part 1)",
    "section": "3.2 Terminology",
    "text": "3.2 Terminology\n\nParents (\\(Pa_i\\)): \\(V_i\\)로 직접 화살표를 보내는 변수들.\nChildren (\\(Ch_i\\)): \\(V_i\\)로부터 직접 화살표를 받는 변수들.\nAncestors / Descendants: 화살표를 따라 거슬러 올라가거나 내려갈 수 있는 변수들."
  },
  {
    "objectID": "posts/lecture/L02/part-01/index.html#the-markovian-condition",
    "href": "posts/lecture/L02/part-01/index.html#the-markovian-condition",
    "title": "[Causal Inference] 02. Causal Models and Graphs (Part 1)",
    "section": "4.1 The Markovian Condition",
    "text": "4.1 The Markovian Condition\n만약 외생 변수들 \\(U\\)가 서로 독립(Jointly Independent)이라면, 즉 그래프 상에 양방향 엣지(\\(\\leftrightarrow\\))가 하나도 없다면, 이 모델을 Markovian이라고 부릅니다."
  },
  {
    "objectID": "posts/lecture/L02/part-01/index.html#derivation-of-bayesian-factorization",
    "href": "posts/lecture/L02/part-01/index.html#derivation-of-bayesian-factorization",
    "title": "[Causal Inference] 02. Causal Models and Graphs (Part 1)",
    "section": "4.2 Derivation of Bayesian Factorization",
    "text": "4.2 Derivation of Bayesian Factorization\n우리의 목표는 \\(P(\\mathbf{v})\\)를 \\(\\prod P(v_i | pa_i)\\) 형태로 만드는 것입니다. 이를 Bayesian Factorization이라 합니다.\nStep 1: Law of Total Probability 모든 변수 \\(V\\)의 결합 확률은 외생 변수 \\(U\\)를 포함한 결합 확률에서 \\(U\\)를 합(Summing out)하여 얻을 수 있습니다. \\[P(\\mathbf{v}) = \\sum_{\\mathbf{u}} P(\\mathbf{v}, \\mathbf{u})\\]\nSCM에서 \\(V\\)는 \\(Pa\\)와 \\(U\\)에 의해 결정되므로(\\(v_i = f_i(pa_i, u_i)\\)), \\(P(v_i | pa_i, u_i)\\)는 결정론적입니다(0 또는 1). 이를 이용하여 식을 전개하면: \\[P(\\mathbf{v}) = \\sum_{\\mathbf{u}} P(\\mathbf{u}) \\prod_{V_i \\in V} P(v_i \\mid \\mathbf{pa}_i, \\mathbf{u}_i)\\]\nStep 2: Independence of Exogenous Variables Markovian 가정에 의해 \\(U\\)들이 서로 독립이므로, \\(P(\\mathbf{u}) = \\prod P(\\mathbf{u}_i)\\)가 성립합니다. 이를 대입합니다. \\[= \\sum_{\\mathbf{u}} \\left( \\prod_{V_i \\in V} P(\\mathbf{u}_i) \\right) \\left( \\prod_{V_i \\in V} P(v_i \\mid \\mathbf{pa}_i, \\mathbf{u}_i) \\right)\\]\nStep 3: Independence of \\(U_i\\) and \\(Pa_i\\) 외생 변수 \\(U_i\\)는 시스템 외부에서 결정되므로, 내생 변수인 부모 \\(Pa_i\\)와는 독립입니다. 따라서 \\(P(\\mathbf{u}_i) = P(\\mathbf{u}_i \\mid \\mathbf{pa}_i)\\)로 쓸 수 있습니다. \\[= \\sum_{\\mathbf{u}} \\prod_{V_i \\in V} P(v_i \\mid \\mathbf{pa}_i, \\mathbf{u}_i) P(\\mathbf{u}_i \\mid \\mathbf{pa}_i)\\]\nStep 4: Merging Conditional Probabilities 곱셈 법칙 \\(P(A|B)P(B) = P(A,B)\\)를 적용하여 항을 합칩니다. \\[= \\sum_{\\mathbf{u}} \\prod_{V_i \\in V} P(v_i, \\mathbf{u}_i \\mid \\mathbf{pa}_i)\\]\nStep 5: Rearranging Sum and Product 전체 외생 변수 \\(\\mathbf{u}\\)에 대한 합(\\(\\sum_{\\mathbf{u}}\\))을 개별 \\(\\mathbf{u}_i\\)에 대한 합으로 분리하여 곱셈 기호 안으로 넣습니다. 각 항은 해당되는 \\(\\mathbf{u}_i\\)에만 의존하기 때문에 가능합니다. \\[= \\prod_{V_i \\in V} \\left( \\sum_{\\mathbf{u}_i} P(v_i, \\mathbf{u}_i \\mid \\mathbf{pa}_i) \\right)\\]\nStep 6: Marginalization 괄호 안의 식 \\(\\sum_{\\mathbf{u}_i} P(v_i, \\mathbf{u}_i \\mid \\mathbf{pa}_i)\\)는 결합 확률에서 \\(\\mathbf{u}_i\\)를 덜어내는(Marginalize) 과정이므로 \\(P(v_i \\mid \\mathbf{pa}_i)\\)가 됩니다.\nFinal Result: \\[P(\\mathbf{v}) = \\prod_{V_i \\in V} P(v_i \\mid \\mathbf{pa}_i)\\]\n이 결과는 매우 강력합니다. 우리가 관측할 수 없는 \\(U\\)를 모르더라도, 오직 관측 가능한 데이터 내에서 부모-자식 간의 조건부 확률만 알면 전체 분포를 알 수 있다는 것을 의미하기 때문입니다.\n\n\n\nFigure: Markovian Factorization 유도 과정 요약. 독립성 가정과 확률의 연쇄 법칙을 통해 복잡한 결합 확률이 조건부 확률의 곱으로 분해됨을 보여준다."
  },
  {
    "objectID": "posts/lecture/L02/part-01/index.html#the-three-basic-structures-triplets",
    "href": "posts/lecture/L02/part-01/index.html#the-three-basic-structures-triplets",
    "title": "[Causal Inference] 02. Causal Models and Graphs (Part 1)",
    "section": "5.1 The Three Basic Structures (Triplets)",
    "text": "5.1 The Three Basic Structures (Triplets)\n\n1. Chain (\\(X \\rightarrow Z \\rightarrow Y\\))\n\n구조: \\(X\\)가 \\(Z\\)에 영향을 주고, \\(Z\\)가 \\(Y\\)에 영향을 줍니다.\n독립성:\n\n\\(Z\\)를 모를 때: \\(X\\)와 \\(Y\\)는 종속입니다 (정보가 흐름).\n\\(Z\\)를 알 때 (Given \\(Z\\)): \\(X\\)가 \\(Y\\)에 미치는 영향은 이미 \\(Z\\)에 의해 설명되었으므로, \\(X \\perp Y \\mid Z\\) (독립)입니다. \\(Z\\)가 정보를 차단(Block)합니다.\n\n\n\n\n\nFigure: Causal Chain 구조와 독립성. 중간 매개변수 Z를 조건부로 알게 되면 X와 Y 사이의 정보 흐름이 차단되어 독립이 된다.\n\n\n\n\n2. Fork / Common Cause (\\(X \\leftarrow Z \\rightarrow Y\\))\n\n구조: \\(Z\\)가 \\(X\\)와 \\(Y\\)의 공통 원인입니다. (예: \\(Z\\)=날씨, \\(X\\)=교통체증, \\(Y\\)=우산사용)\n독립성:\n\n\\(Z\\)를 모를 때: \\(X\\)와 \\(Y\\)는 종속입니다 (상관관계 발생).\n\\(Z\\)를 알 때 (Given \\(Z\\)): 공통 원인을 통제했으므로 \\(X \\perp Y \\mid Z\\) (독립)입니다.\n\n\n\n\n\nFigure: Common Cause 구조와 독립성. 공통 원인 Z를 통제하면 X와 Y 사이의 허위 상관관계(Spurious Correlation)가 사라져 독립이 된다.\n\n\n\n\n3. Collider / Common Effect (\\(X \\rightarrow Z \\leftarrow Y\\))\n\n구조: \\(X\\)와 \\(Y\\)가 동시에 \\(Z\\)에 영향을 줍니다. (예: \\(X\\)=감기, \\(Y\\)=휴일, \\(Z\\)=결석)\n독립성:\n\n\\(Z\\)를 모를 때: \\(X\\)와 \\(Y\\)는 독립입니다 (서로 관계없는 사건).\n\\(Z\\)를 알 때 (Given \\(Z\\)): \\(X \\not\\perp Y \\mid Z\\) (종속)이 됩니다.\n\nExplaining Away: 결석(\\(Z=1\\))했다는 사실을 알 때, 휴일이 아니라면(\\(Y=0\\)), 아플 확률(\\(X=1\\))이 높아집니다. 즉, 결과를 알면 원인들 사이에 상관관계가 생깁니다. Collider는 관측될 때 경로를 엽니다(Open).\n\n\n\n\nFigure: Common Effect (Collider) 구조와 Explaining Away 현상. 두 독립적인 원인이 공통 결과 Z를 조건부로 알게 되었을 때 종속적으로 변하는 현상을 설명한다."
  },
  {
    "objectID": "posts/lecture/L02/part-01/index.html#d-separation",
    "href": "posts/lecture/L02/part-01/index.html#d-separation",
    "title": "[Causal Inference] 02. Causal Models and Graphs (Part 1)",
    "section": "5.2 d-separation",
    "text": "5.2 d-separation\n이 세 가지 규칙을 일반화한 것이 d-separation입니다. 그래프 상의 두 노드 \\(X, Y\\) 사이의 모든 경로가 관측된 변수 집합 \\(Z\\)에 의해 차단(Blocked)된다면, \\(X\\)와 \\(Y\\)는 \\(Z\\)에 대해 조건부 독립입니다.\n\n경로가 차단되는 경우:\n\n경로 상의 Chain이나 Fork 노드가 \\(Z\\)에 포함될 때.\n경로 상의 Collider 노드와 그 자손들이 \\(Z\\)에 포함되지 않을 때."
  },
  {
    "objectID": "posts/lecture/L02/part-01/index.html#food-for-thought-quiz",
    "href": "posts/lecture/L02/part-01/index.html#food-for-thought-quiz",
    "title": "[Causal Inference] 02. Causal Models and Graphs (Part 1)",
    "section": "5.3 Food for Thought (Quiz)",
    "text": "5.3 Food for Thought (Quiz)\n아래 그래프를 보고 독립성을 판별해 봅시다.\n\n\n\nFigure: d-separation 연습을 위한 복합 그래프 예시. A, B, C, D 노드와 실선/점선 엣지가 섞여 있어 다양한 경로의 독립성을 테스트한다.\n\n\n\nIs \\(A \\perp D\\)? (No)\n\n경로: \\(A \\leftrightarrow B \\rightarrow D\\).\n\\(B\\)는 Chain/Fork 역할을 하지만 관측되지 않았으므로 경로가 열려 있습니다.\n\nIs \\(A \\perp C\\)? (Yes)\n\n경로: \\(A \\leftrightarrow B \\leftarrow C\\).\n\\(B\\)는 Collider입니다. 관측되지 않았으므로 경로는 차단되어 있습니다.\n\nIs \\(A \\perp C \\mid D\\)? (No)\n\n\\(D\\)는 Collider \\(B\\)의 자손(Descendant)입니다.\n\\(D\\)를 관측하면 \\(B\\)가 열리게 되어 경로가 연결됩니다.\n\nIs \\(D \\perp C \\mid B\\)? (No)\n\n경로 1: \\(C \\rightarrow B \\rightarrow D\\). \\(B\\)를 알면 차단됩니다.\n경로 2: \\(C \\leftrightarrow D\\) (Backdoor path, \\(C \\leftarrow U \\rightarrow D\\)). 이 경로는 \\(B\\)와 무관하게 열려 있습니다.\n하나라도 열린 경로가 있으므로 종속입니다."
  },
  {
    "objectID": "posts/lecture/L15A/SDiD/part-01/index.html",
    "href": "posts/lecture/L15A/SDiD/part-01/index.html",
    "title": "[Causal Inference] 15A. SDiD (Part 1)",
    "section": "",
    "text": "인과 추론(Causal Inference)에서 패널 데이터(Panel Data)를 분석할 때 가장 널리 쓰이는 두 가지 방법론은 이중차분법(Difference-in-Differences, DiD)과 통제집단합성법(Synthetic Control Method, SCM)입니다.\n하지만 이 두 방법론은 각각의 한계점을 가지고 있습니다.\n\nDiD는 엄격한 ’평행 추세 가정(Parallel Trends Assumption)’에 의존합니다.\nSCM은 처치 유닛(treated unit)과 대조 유닛(control unit)의 레벨(level)을 강제로 맞추려고 합니다.\n\n이번 포스트에서는 Arkhangelsky et al. (2021)이 제안한 Synthetic Difference-in-Differences (SDiD)를 다룹니다.\nSDiD는 DiD와 SCM의 장점을 결합하여, 가중치(weights)를 통해 평행 추세를 보정하고 이원 고정 효과(Two-way Fixed Effects)를 통해 강건성(robustness)을 확보하는 방법론입니다.\n\n\n\n\nFigure 1: DiD, SC, SDiD의 추정 방식 비교. (좌) DiD는 전체 대조군의 평균 추세를 평행 이동하여 반사실(counterfactual)을 추정함. (중) SC는 처치 이전 기간의 outcome 레벨까지 정확히 일치시키는 가중치를 찾음. (우) SDiD는 추세(trend)만 평행하게 맞추면 되며(절편 허용), 가중치를 통해 평행 추세 가정을 만족시키는 대조군을 합성함."
  },
  {
    "objectID": "posts/lecture/L15A/SDiD/part-01/index.html#setting-notation",
    "href": "posts/lecture/L15A/SDiD/part-01/index.html#setting-notation",
    "title": "[Causal Inference] 15A. SDiD (Part 1)",
    "section": "3.1. Setting & Notation",
    "text": "3.1. Setting & Notation\n\nSDiD 모델을 이해하기 위한 기본적인 데이터 구조와 파라미터 정의는 다음과 같습니다.\n\n\nData Structure\n\nBalanced Panel: \\(N\\)개의 유닛과 \\(T\\)개의 시간(periods)으로 구성된 균형 패널 데이터를 가정합니다.\n\\(Y_{it}\\): 유닛 \\(i\\), 시간 \\(t\\)에서의 결과 변수(Outcome).\n\\(X_{it} \\in \\{0, 1\\}\\): 이진 처치 여부(Binary treatment indicator).\nUnits Breakdown:\n\nControl Units (\\(N_{co}\\)): \\(i = 1, \\dots, N_{co}\\) (처치를 전혀 받지 않음).\nTreated Units (\\(N_{tr}\\)): \\(i = N_{co} + 1, \\dots, N\\) (시간 \\(T_{pre}\\) 이후 처치를 받음).\n\\(N_{tr} = N - N_{co}\\)\n\n\n\n\nModel Parameters (Fixed Effects)\n\n기존 DiD와 마찬가지로 Two-Way Fixed Effects(TWFE) 구조를 기반으로 합니다.\n\n\\(\\mu\\): Global Intercept (전체 절편).\n\n모든 유닛과 시점에 공통적으로 적용되는 기저 수준(Base level)입니다.\n\n\\(\\alpha_i\\): Unit Fixed Effects (유닛 고정 효과).\n\n유닛 \\(i\\)가 가진 고유한 특성으로, 시간에 따라 변하지 않는(Time-invariant) 이질성을 포착합니다.\n\n\\(\\beta_t\\): Time Fixed Effects (시간 고정 효과).\n\n특정 시점 \\(t\\)에 모든 유닛에게 공통적으로 영향을 미치는 충격으로, 유닛 간에 차이가 없는(Unit-invariant) 요인입니다.\n\n\n\n\n\nSDiD Weights\n\nSDiD는 위 파라미터를 추정하기 전에, 데이터의 균형을 맞추기 위한 두 가지 가중치를 먼저 계산합니다.\n\n\\(\\omega_i\\): Unit Weights (유닛 가중치).\n\n처치군의 추세(Trend)와 유사한 대조군을 합성하기 위해 대조 유닛들에 부여하는 가중치입니다.\n\n\\(\\lambda_t\\): Time Weights (시간 가중치).\n\n처치 이전 기간(Pre-treatment) 중, 처치 이후 기간(Post-treatment)과 유사한 시점을 강조하기 위해 부여하는 가중치입니다."
  },
  {
    "objectID": "posts/lecture/L15A/SDiD/part-01/index.html#formulations-comparison",
    "href": "posts/lecture/L15A/SDiD/part-01/index.html#formulations-comparison",
    "title": "[Causal Inference] 15A. SDiD (Part 1)",
    "section": "3.2. Formulations Comparison",
    "text": "3.2. Formulations Comparison\n\n세 가지 추정량(Estimator)은 최적화 문제(Minimization Problem)로 정식화하여 비교할 때 그 차이가 명확해집니다.\n우리는 평균 인과 효과 \\(\\tau\\)를 추정하고자 합니다.\n\n\n(1) DiD Estimator\n\nDiD는 평행 추세 가정(Parallel Trends Assumption)에 기반하여 인과 효과를 추정하며, 수식적으로 Unit Fixed Effect (\\(\\alpha_i\\))를 허용합니다.\nMechanism\n\n처치군과 대조군 사이에 레벨(Level) 차이가 있더라도, 그 차이가 시불변(\\(\\alpha_{tr} \\neq \\alpha_{co}\\))한다면, 변화량의 차이(Difference-in-Differences)를 구하는 과정에서 \\(\\alpha_i\\)가 상쇄되어 사라집니다.\n\nFormulation\n\n회귀분석 관점에서 DiD는 가중치 없이(unweighted) TWFE 문제를 푸는 것과 같습니다. \\[\n  \\hat{\\tau}^{DiD} = \\underset{\\alpha, \\beta, \\mu, \\tau}{\\arg \\min} \\left\\{ \\sum_{i=1}^{N}\\sum_{t=1}^{T} (Y_{it} - \\mu - \\alpha_i - \\beta_t - \\tau X_{it})^2 \\right\\}\n  \\]\n\nLimitation\n\n모든 대조군 유닛에 동일한 가중치(\\(1/N_{co}\\))를 부여합니다.\n따라서 평행 추세 가정이 위배되는(추세가 다른) 유닛들이 대조군에 섞여 있을 경우 편향(Bias)이 발생할 수 있습니다.\n\n\n\n\n(2) SCM Estimator\n\nSCM은 처치 유닛과 가장 유사한 가상의 대조군(Synthetic Control)을 만들기 위해 대조군 유닛들에 가중치(Unit weights, \\(\\omega_i\\))를 부여합니다.\nMechanism\n\nSCM은 처치 이전 기간의 결과 변수(\\(Y\\))의 경로(Path)와 레벨(Level)을 모두 맞추려고 시도합니다.\n즉, 추세뿐만 아니라 절대적인 수치까지 일치시키려 합니다.\n\nFormulation\n\n전통적인 SCM 추정식은 시간 고정 효과(\\(\\beta_t\\))는 포함하지만, Unit Fixed Effect (\\(\\alpha_i\\))와 전체 절편(Intercept)을 제외합니다. \\[\n  \\hat{\\tau}^{SCM} = \\underset{\\beta, \\mu, \\tau}{\\arg \\min} \\left\\{ \\sum_{i=1}^{N}\\sum_{t=1}^{T} (Y_{it} - \\mu - \\beta_t - \\tau X_{it})^2 \\cdot \\hat{\\omega}_i \\right\\}\n  \\]\n\nLimitation\n\n\\(\\alpha_i\\)를 모델에 포함하지 않기 때문에, SCM은 처치군과 대조군 간의 레벨 차이(Intercept shift)를 허용하지 않습니다.\n즉, “평행 이동”을 허용하지 않고 절대적인 수치까지 맞춰야 하므로, 완벽하게 일치하는 대조군을 찾지 못하면(Interpolation bias) 추정 성능이 떨어질 수 있습니다.\n\n\n\n\n(3) SDiD Estimator\n\nSDiD는 유닛 가중치 \\(\\hat{\\omega}_i\\)와 시간 가중치 \\(\\hat{\\lambda}_t\\)를 모두 사용하며, 동시에 유닛 및 시간 고정 효과(\\(\\alpha_i, \\beta_t\\))를 모두 포함합니다.\nMechanism\n\nLocal Regression: 가중치(\\(\\omega, \\lambda\\))를 통해 처치군과 유사한 대조군, 처치 시점과 유사한 시점을 강조합니다.\nRobustness: 고정 효과(\\(\\alpha, \\beta\\))를 통해 가중치로 설명되지 않는 시스템적인 차이(Systematic differences)를 제거합니다.\n\nFormulation\n\\[\n  \\hat{\\tau}^{SDiD} = \\underset{\\alpha, \\beta, \\mu, \\tau}{\\arg \\min} \\left\\{ \\sum_{i=1}^{N}\\sum_{t=1}^{T} (Y_{it} - \\mu - \\alpha_i - \\beta_t - \\tau X_{it})^2 \\cdot \\hat{\\omega}_i \\cdot \\hat{\\lambda}_t \\right\\}\n  \\]\nKey Advantage\n\nSCM의 유연성(Flexibility)과 DiD의 강건성(Robustness)을 결합하여, 레벨이 달라도 추세가 유사한 유닛들을 효과적으로 매칭하고 편향을 줄입니다."
  },
  {
    "objectID": "posts/lecture/L15A/SDiD/part-01/index.html#summary-comparison-of-methodologies",
    "href": "posts/lecture/L15A/SDiD/part-01/index.html#summary-comparison-of-methodologies",
    "title": "[Causal Inference] 15A. SDiD (Part 1)",
    "section": "Summary: Comparison of Methodologies",
    "text": "Summary: Comparison of Methodologies\n\n아래 표는 DiD, SCM, 그리고 SDiD가 고정 효과(Fixed Effect)와 가중치(Weights)를 다루는 방식의 핵심적인 차이를 요약합니다.\n\n\n\n\n\n\n\n\n\n\n구분\nDiD\nSCM\nSDiD\n\n\n\n\nUnit Fixed Effect (\\(\\alpha_i\\))\n포함 (Included)레벨 차이(Intercept) 허용\n미포함 (Excluded)절편 허용 안 함\n포함 (Included)레벨 차이(Intercept) 허용\n\n\n가중치 (Weights)\n없음 (Unweighted)모든 대조군 동일 가중치\nUnit Weights (\\(\\omega_i\\))유사한 유닛에 가중치 부여\nUnit(\\(\\omega_i\\)) + Time(\\(\\lambda_t\\))유사한 유닛 및 시점 강조\n\n\n매칭 조건 (Matching)\n추세 (Trend)만 평행하면 됨\n레벨 (Level)까지 정확히 일치해야 함\n추세 (Trend)만 평행하면 됨\n\n\n장점과 한계\n\\(\\alpha_i\\)를 허용하지만,가중치가 없어 유연성 부족\n가중치로 유연하게 맞추지만,레벨까지 맞춰야 하는 제약 존재\nSCM의 유연성(가중치)과DiD의 강건성(FE)을 결합\n\n\n\n\n결론적으로 SDiD는 SCM처럼 가중치를 사용하여 데이터에 유연하게 적합(Fit)시키면서도, DiD처럼 유닛 고정 효과를 도입하여 레벨이 아닌 추세(Trend)만 맞추면 되도록 설계된, 두 방법론의 장점을 결합한 접근법입니다."
  },
  {
    "objectID": "posts/lecture/L15A/SDiD/part-01/index.html#step-1-compute-unit-weights-hatomega_i",
    "href": "posts/lecture/L15A/SDiD/part-01/index.html#step-1-compute-unit-weights-hatomega_i",
    "title": "[Causal Inference] 15A. SDiD (Part 1)",
    "section": "Step 1: Compute Unit Weights (\\(\\hat{\\omega}_i\\))",
    "text": "Step 1: Compute Unit Weights (\\(\\hat{\\omega}_i\\))\n\n처치 이전 기간(\\(T_{pre}\\)) 동안, 대조군들의 가중 합이 처치군의 평균 추세를 따르도록 만듭니다.\n\n\\[\n\\hat{\\omega} = \\underset{\\omega_0, \\omega_{co}}{\\arg \\min} \\left( || \\overline{y}_{pre, tr} - (\\omega_0 + \\omega_{co} Y_{pre, co}) ||_2^2 + \\zeta^2 T_{pre} ||\\omega_{co}||_2^2 \\right)\n\\]\n\\[\n\\begin{aligned}\n\\text{where } \\quad \\bar{\\mathbf{y}}_{pre,tr} &= \\frac{1}{N_{tr}}\\sum_{i=N_{co}+1}^{N} Y_{it} \\\\\n\\omega_{co}\\mathbf{Y}_{pre,co} &= \\sum_{i=1}^{N_{co}}\\omega_i Y_{it}\n\\end{aligned}\n\\]\n\n여기서:\n\n\\(\\overline{y}_{pre, tr}\\): 처치군들의 처치 이전 평균 추세 (벡터)\n\\(Y_{pre, co}\\): 대조군들의 처치 이전 데이터 행렬 (\\(T_{pre} \\times N_{co}\\))\n\\(\\omega_0\\) (Intercept): SDiD의 결정적 차이점입니다. SCM과 달리 절편을 허용합니다. 즉, 레벨(Level)을 맞출 필요 없이 추세(Trend)만 평행하게 맞추면 됩니다.\n\\(L_2\\) Regularization (\\(\\zeta\\)): Ridge penalty를 사용하여 가중치가 특정 유닛에 쏠리는 것을 방지하고(dispersed weights), 대조군 전체에 고르게 분포되도록 합니다.\n\n\n\nRegularization Parameter \\(\\zeta\\)\n\n정규화 파라미터 \\(\\zeta\\)는 데이터의 변동성에 기반하여 다음과 같이 결정됩니다.\n\n\\[\n\\zeta = (N_{tr} \\cdot T_{post})^{1/4} \\hat{\\sigma}(\\Delta_{it})\n\\]\n\\[\n\\begin{aligned}\n\\text{where } \\quad \\Delta_{it} &= Y_{i(t+1)} - Y_{it} \\\\\n\\bar{\\Delta} &= \\frac{1}{N_{co}(T_{pre}-1)} \\sum_{i=1}^{N_{co}} \\sum_{t=1}^{T_{pre}-1} \\Delta_{it} \\\\\n\\hat{\\sigma}^2(\\Delta_{it}) &= \\frac{1}{N_{co}(T_{pre}-1)} \\sum_{i=1}^{N_{co}} \\sum_{t=1}^{T_{pre}-1} (\\Delta_{it} - \\bar{\\Delta})^2\n\\end{aligned}\n\\]\n\n이때 \\(\\Delta_{it}\\)는 결과 변수의 1차 차분(first difference, \\(Y_{it} - Y_{i(t-1)}\\))이며, \\(\\hat{\\sigma}\\)는 이 차분 값들의 표준편차입니다.\n이는 시계열적 변동성이 클수록 페널티를 강하게 주어 과적합을 막겠다는 의도입니다."
  },
  {
    "objectID": "posts/lecture/L15A/SDiD/part-01/index.html#step-2-compute-time-weights-hatlambda_t",
    "href": "posts/lecture/L15A/SDiD/part-01/index.html#step-2-compute-time-weights-hatlambda_t",
    "title": "[Causal Inference] 15A. SDiD (Part 1)",
    "section": "Step 2: Compute Time Weights (\\(\\hat{\\lambda}_t\\))",
    "text": "Step 2: Compute Time Weights (\\(\\hat{\\lambda}_t\\))\n\nSDiD는 시간 가중치도 계산합니다.\n\n이는 처치 이전 시점들(\\(1 \\dots T_{pre}\\)) 중, 처치 이후 시점(\\(T_{post}\\))과 유사한 시점에 더 큰 가중치를 부여하기 위함입니다.\n\n\n\\[\n\\hat{\\lambda} = \\underset{\\lambda_0, \\lambda_{pre}}{\\arg \\min} || \\overline{y}_{post, co} - (\\lambda_0 + \\lambda_{pre} Y_{pre, co}) ||_2^2\n\\]\n\\[\n\\begin{aligned}\n\\text{where } \\quad \\bar{\\mathbf{y}}_{post,co} &= \\frac{1}{T_{post}} \\sum_{t=T_{pre}+1}^{T} Y_{it} \\\\\n\\boldsymbol{\\lambda}_{pre}\\mathbf{Y}_{pre,co} &= \\sum_{t=1}^{T_{pre}} \\lambda_t Y_{it}\n\\end{aligned}\n\\]\n\n\\(\\overline{y}_{post, co}\\): 대조군의 처치 이후 평균 (스칼라 혹은 벡터)\n이 과정은 대조군 내에서 “처치 이전 기간의 가중 합”이 “처치 이후 기간”과 유사해지도록 만듭니다. 이를 통해 시간적 편향(bias)을 제거합니다."
  },
  {
    "objectID": "posts/lecture/L15A/SDiD/part-01/index.html#step-3-weighted-did-regression",
    "href": "posts/lecture/L15A/SDiD/part-01/index.html#step-3-weighted-did-regression",
    "title": "[Causal Inference] 15A. SDiD (Part 1)",
    "section": "Step 3: Weighted DiD Regression",
    "text": "Step 3: Weighted DiD Regression\n\n구해진 \\(\\hat{\\omega}_i\\)와 \\(\\hat{\\lambda}_t\\)를 사용하여 최종적으로 가중 이원 고정 효과(Weighted TWFE) 회귀를 수행합니다.\n\n\\[\n(\\hat{\\tau}^{SDiD}, \\hat{\\mu}, \\hat{\\alpha}, \\hat{\\beta}) = \\underset{\\tau, \\mu, \\alpha, \\beta}{\\arg \\min} \\left\\{ \\sum_{i=1}^{N}\\sum_{t=1}^{T} (Y_{it} - \\mu - \\alpha_i - \\beta_t - \\tau X_{it})^2 \\hat{\\omega}_i \\hat{\\lambda}_t \\right\\}\n\\]\n\n이 회귀분석의 \\(\\hat{\\tau}\\) 값이 바로 SDiD가 추정한 인과 효과입니다."
  },
  {
    "objectID": "posts/lecture/L15A/SDiD/part-01/index.html#appendix-closed-form-solution",
    "href": "posts/lecture/L15A/SDiD/part-01/index.html#appendix-closed-form-solution",
    "title": "[Causal Inference] 15A. SDiD (Part 1)",
    "section": "Appendix: Closed-Form Solution",
    "text": "Appendix: Closed-Form Solution\n\n1. Weighted TWFE Objective Function\n\nSDiD는 다음의 가중 잔차 제곱합(Weighted Sum of Squared Residuals)을 최소화하는 파라미터 \\(\\{\\tau, \\mu, \\alpha, \\beta\\}\\)를 찾습니다.\n\n\\[\n\\min_{\\tau, \\mu, \\alpha, \\beta} \\sum_{i=1}^N \\sum_{t=1}^T \\left( Y_{it} - \\mu - \\alpha_i - \\beta_t - \\tau X_{it} \\right)^2 \\hat{\\omega}_i \\hat{\\lambda}_t\n\\] * \\(X_{it}\\): 처치군(\\(tr\\))이면서 처치 후(\\(post\\))일 때 \\(1\\), 그 외 \\(0\\) (Treatment Indicator) * \\(\\hat{\\omega}_i, \\hat{\\lambda}_t\\): Step 1, 2에서 미리 구해둔 유닛 및 시간 가중치\n\n\n2. First Order Condition (FOC) w.r.t \\(\\tau\\)\n\n목적함수를 \\(\\tau\\)에 대해 편미분하고 \\(0\\)으로 둡니다.\n\n\\[\n\\frac{\\partial L}{\\partial \\tau} = -2 \\sum_{i=1}^N \\sum_{t=1}^T \\hat{\\omega}_i \\hat{\\lambda}_t \\left( Y_{it} - \\mu - \\alpha_i - \\beta_t - \\tau X_{it} \\right) X_{it} = 0\n\\]\n\n여기서 \\(X_{it}=1\\)인 경우(즉, 처치군의 사후 기간)만 항이 살아남으므로, 식을 정리하면 \\(\\hat{\\tau}\\)는 “관측된 값”과 “반사실적(Counterfactual) 추정치”의 차이가 됩니다.\n\n\\[\n\\hat{\\tau}^{SDiD} = \\underbrace{\\bar{Y}_{tr, post}}_{\\text{Observed}} - \\underbrace{(\\hat{\\mu} + \\hat{\\alpha}_{tr} + \\hat{\\beta}_{post})}_{\\text{Counterfactual } \\hat{Y}(0)}\n\\]\n\n이제 우리의 목표는 미지의 파라미터 조합 \\((\\hat{\\mu} + \\hat{\\alpha}_{tr} + \\hat{\\beta}_{post})\\)를 우리가 아는 데이터의 가중 평균(3개의 항)으로 표현하는 것입니다.\n\n\n\n3. Parameter Decomposition via Normal Equations\n\n최소자승법의 1계 조건(FOC)은 “잔차의 합을 0으로 만든다”는 성질이 있습니다.\n이를 이용해 관측 가능한 세 가지 항을 유도합니다.\n단, 가중치의 합은 1로 정규화되어 있다고 가정합니다: \\(\\sum \\hat{\\omega}_i = 1, \\sum \\hat{\\lambda}_t = 1\\)\n\n\n3-1. 처치군의 사전 기간 (\\(\\bar{Y}_{tr, pre}^{\\lambda}\\))\n\n처치 유닛(\\(i=tr\\))과 사전 기간(\\(t \\in Pre\\))에 해당하는 목적함수를 \\(\\hat{\\alpha}_{tr}\\)에 대해 편미분합니다.\n이 기간에는 \\(X_{it}=0\\)이므로 \\(\\tau\\) 항은 사라집니다.\n\n\\[\n\\frac{\\partial L_{tr}}{\\partial \\hat{\\alpha}_{tr}} = -2 \\sum_{t=1}^{T_{pre}} \\hat{\\lambda}_t (Y_{tr,t} - \\hat{\\mu} - \\hat{\\alpha}_{tr} - \\hat{\\beta}_t) = 0\n\\]\n\n시그마를 분배하고 정리하면 다음과 같습니다.\n\\(\\sum \\hat{\\lambda}_t = 1\\) 적용\n\n\\[\n\\underbrace{\\sum \\hat{\\lambda}_t Y_{tr,t}}_{\\bar{Y}_{tr, pre}^{\\lambda}} = \\hat{\\mu}\\underbrace{\\sum \\hat{\\lambda}_t}_{1} + \\hat{\\alpha}_{tr}\\underbrace{\\sum \\hat{\\lambda}_t}_{1} + \\underbrace{\\sum \\hat{\\lambda}_t \\hat{\\beta}_t}_{\\bar{\\beta}_{pre}^{\\lambda}}\n\\]\n\\[\n\\therefore \\quad \\bar{Y}_{tr, pre}^{\\lambda} = \\hat{\\mu} + \\hat{\\alpha}_{tr} + \\bar{\\beta}_{pre}^{\\lambda} \\quad \\cdots \\text{(식 1)}\n\\]\n\n\n3-2. 통제군의 사후 기간 (\\(\\bar{Y}_{co, post}^{\\omega}\\))\n\n통제 유닛들(\\(i \\in Co\\))과 사후 기간(\\(t=post\\))에 해당하는 목적함수를 \\(\\hat{\\beta}_{post}\\)에 대해 편미분합니다.\n통제군이므로 \\(X_{it}=0\\), 따라서 \\(\\tau\\) 항은 사라집니다.\n\n\\[\n\\frac{\\partial L_{post}}{\\partial \\hat{\\beta}_{post}} = -2 \\sum_{i=1}^{N_{co}} \\hat{\\omega}_i (Y_{i, post} - \\hat{\\mu} - \\hat{\\alpha}_i - \\hat{\\beta}_{post}) = 0\n\\]\n\n마찬가지로 정리합니다.\n\\(\\sum \\hat{\\omega}_i = 1\\) 적용\n\n\\[\n\\underbrace{\\sum \\hat{\\omega}_i Y_{i, post}}_{\\bar{Y}_{co, post}^{\\omega}} = \\hat{\\mu}\\underbrace{\\sum \\hat{\\omega}_i}_{1} + \\underbrace{\\sum \\hat{\\omega}_i \\hat{\\alpha}_i}_{\\bar{\\alpha}_{co}^{\\omega}} + \\hat{\\beta}_{post}\\underbrace{\\sum \\hat{\\omega}_i}_{1}\n\\]\n\\[\n\\therefore \\quad \\bar{Y}_{co, post}^{\\omega} = \\hat{\\mu} + \\bar{\\alpha}_{co}^{\\omega} + \\hat{\\beta}_{post} \\quad \\cdots \\text{(식 2)}\n\\]\n\n\n3-3. 통제군의 사전 기간 (\\(\\bar{Y}_{co, pre}^{\\omega, \\lambda}\\))\n\n통제 유닛(\\(i \\in Co\\))과 사전 기간(\\(t \\in Pre\\)) 전체에 대해 편미분(혹은 \\(\\hat{\\mu}\\)에 대한 FOC)을 적용합니다. (\\(X_{it}=0\\))\n\n\\[\n\\sum_{i=1}^{N_{co}} \\sum_{t=1}^{T_{pre}} \\hat{\\omega}_i \\hat{\\lambda}_t (Y_{it} - \\hat{\\mu} - \\hat{\\alpha}_i - \\hat{\\beta}_t) = 0\n\\]\n\n이중 시그마를 풀면 다음과 같습니다.\n\n\\[\n\\bar{Y}_{co, pre}^{\\omega, \\lambda} = \\hat{\\mu}(\\sum \\omega \\sum \\lambda) + (\\sum \\omega \\hat{\\alpha}_i)(\\sum \\lambda) + (\\sum \\lambda \\hat{\\beta}_t)(\\sum \\omega)\n\\]\n\\[\n\\therefore \\quad \\bar{Y}_{co, pre}^{\\omega, \\lambda} = \\hat{\\mu} + \\bar{\\alpha}_{co}^{\\omega} + \\bar{\\beta}_{pre}^{\\lambda} \\quad \\cdots \\text{(식 3)}\n\\]\n\n\n\n4. Cancellation & Derivation\n\n위에서 유도한 세 식을 조합하여 반사실적 추정치를 만들어냅니다.\n(식 1) + (식 2) - (식 3)을 계산하면, 우리가 원하지 않는 파라미터들이 소거됩니다.\n\n\\[\n\\begin{aligned}\n& \\quad \\underbrace{(\\hat{\\mu} + \\hat{\\alpha}_{tr} + \\bar{\\beta}_{pre}^{\\lambda})}_{\\text{① Treated, Pre}} + \\underbrace{(\\hat{\\mu} + \\bar{\\alpha}_{co}^{\\omega} + \\hat{\\beta}_{post})}_{\\text{② Control, Post}} - \\underbrace{(\\hat{\\mu} + \\bar{\\alpha}_{co}^{\\omega} + \\bar{\\beta}_{pre}^{\\lambda})}_{\\text{③ Control, Pre}} \\\\\n\\\\\n&= (\\hat{\\mu} + \\hat{\\mu} - \\hat{\\mu}) + \\hat{\\alpha}_{tr} + \\hat{\\beta}_{post} + \\underbrace{(\\bar{\\alpha}_{co}^{\\omega} - \\bar{\\alpha}_{co}^{\\omega})}_{\\text{Unit FE Cancel}} + \\underbrace{(\\bar{\\beta}_{pre}^{\\lambda} - \\bar{\\beta}_{pre}^{\\lambda})}_{\\text{Time FE Cancel}} \\\\\n\\\\\n&= \\mathbf{\\hat{\\mu} + \\hat{\\alpha}_{tr} + \\hat{\\beta}_{post}} \\quad (= \\text{Counterfactual})\n\\end{aligned}\n\\]\n\n\n5. Final Result\n\n따라서 FOC에서 도출된 \\(\\hat{\\tau}\\) 식에 대입하면, 최종적으로 2x2 DID 형태가 완성됩니다.\n\n\\[\n\\begin{aligned}\n\\hat{\\tau}^{SDiD} &= \\bar{Y}_{tr, post} - \\text{Counterfactual} \\\\\n&= \\bar{Y}_{tr, post} - \\left( \\bar{Y}_{tr, pre}^{\\lambda} + \\bar{Y}_{co, post}^{\\omega} - \\bar{Y}_{co, pre}^{\\omega, \\lambda} \\right) \\\\\n&= (\\bar{Y}_{tr, post} - \\bar{Y}_{tr, pre}^{\\lambda}) - (\\bar{Y}_{co, post}^{\\omega} - \\bar{Y}_{co, pre}^{\\omega, \\lambda})\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "posts/lecture/L15A/SDiD/part-01/index.html#vs.-did",
    "href": "posts/lecture/L15A/SDiD/part-01/index.html#vs.-did",
    "title": "[Causal Inference] 15A. SDiD (Part 1)",
    "section": "5.1. vs. DiD",
    "text": "5.1. vs. DiD\n\nLocal Fitting: DiD는 모든 대조군과 모든 시점을 동일하게 취급하지만, SDiD는 처치군과 유사한 과거를 가진 유닛, 처치 시기와 유사한 특성을 가진 시점을 강조(weighting)하여 “Local”한 회귀를 수행합니다.\nPrecision: 가중치를 통해 결과 변수의 시스템적이고 예측 가능한 부분을 제거함으로써 추정의 정밀도(precision)를 높입니다."
  },
  {
    "objectID": "posts/lecture/L15A/SDiD/part-01/index.html#vs.-scm",
    "href": "posts/lecture/L15A/SDiD/part-01/index.html#vs.-scm",
    "title": "[Causal Inference] 15A. SDiD (Part 1)",
    "section": "5.2. vs. SCM",
    "text": "5.2. vs. SCM\n\nParallelism over Levels: SCM은 Outcome의 절대적인 수치(Level)까지 맞춰야 하지만, SDiD는 유닛 고정 효과(\\(\\alpha_i\\))와 절편(\\(\\omega_0\\))을 포함하므로 평행 추세만 만족하면 됩니다. 이는 더 유연한 매칭을 가능하게 합니다.\nBias Removal: 시간 가중치(\\(\\lambda_t\\))를 도입하여, 처치 이후 기간과 성격이 매우 다른 처치 이전 기간의 영향력을 배제하여 편향을 줄입니다.\nRobustness: 유닛 고정 효과는 결과 변수의 변동 중 상당 부분을 설명하므로, 모델의 강건성을 높여줍니다."
  },
  {
    "objectID": "posts/lecture/L15A/Staggered-DiD/index.html",
    "href": "posts/lecture/L15A/Staggered-DiD/index.html",
    "title": "[Causal Inference] 15A. Staggered DiD",
    "section": "",
    "text": "전통적인 이중차분법(Difference-in-Differences, DiD)은 두 개의 그룹(Treatment/Control)과 두 개의 시점(Pre/Post)이 존재하는 2x2 Canonical Design에서 인과 효과를 추정하는 강력한 도구입니다. 그러나 실제 현실 데이터, 특히 정책 시행이나 서비스 도입과 같은 환경에서는 모든 실험군이 동시에 처치를 받는 경우는 드뭅니다.\n대신, Staggered Adoption Design (SAD)이라 불리는, 처치 시점이 유닛마다 다른 상황이 훨씬 빈번하게 발생합니다. 예를 들어, 어떤 지역은 정책을 2020년에 도입하고, 어떤 지역은 2021년에 도입하는 식입니다.\n이번 포스트에서는 전통적인 Two-Way Fixed Effects (TWFE) 회귀분석이 이러한 Staggered setup에서 왜 편향된(biased) 추정치를 낳는지 살펴보고, 이를 해결하기 위한 최신 방법론인 Callaway and Sant’Anna (2021)의 프레임워크를 상세히 정리해보겠습니다.\n &gt; Figure 1 설명: Staggered Treatment Timing을 나타내는 도식입니다. &gt; - Treated Group A: 가장 먼저 처치를 받기 시작함. &gt; - Treated Group B: A보다 나중에 처치를 받기 시작함. &gt; - Treated Group C: 가장 늦게 처치를 받기 시작함. &gt; - Never-Treated Group: 관찰 기간 내내 처치를 받지 않음. &gt; - 핵심은 처치를 받은 유닛은 다시 통제 상태로 돌아가지 않는다는(Irreversible) 가정입니다."
  },
  {
    "objectID": "posts/lecture/L15A/Staggered-DiD/index.html#the-limitation-of-twfe",
    "href": "posts/lecture/L15A/Staggered-DiD/index.html#the-limitation-of-twfe",
    "title": "[Causal Inference] 15A. Staggered DiD",
    "section": "2.1. The Limitation of TWFE",
    "text": "2.1. The Limitation of TWFE\n일반적으로 연구자들은 패널 데이터에서 다음과 같은 Two-Way Fixed Effects (TWFE) 선형 회귀 모형을 사용하여 \\(\\beta\\)를 인과 효과(ATT)로 해석해 왔습니다.\n\\[\nY_{it} = \\alpha_i + \\lambda_t + \\beta D_{it} + \\epsilon_{it}\n\\]\n여기서 \\(D_{it}\\)는 유닛 \\(i\\)가 시점 \\(t\\)에 처치를 받았으면 1, 아니면 0인 더미 변수입니다. 하지만 처치 시점이 다양하고(Staggered), 처치 효과가 시간에 따라 변하거나(Dynamic), 유닛마다 다르다면(Heterogeneous), \\(\\beta\\)는 우리가 원하는 Average Treatment Effect on the Treated (ATT)와 일치하지 않습니다."
  },
  {
    "objectID": "posts/lecture/L15A/Staggered-DiD/index.html#the-problem-of-bad-comparisons",
    "href": "posts/lecture/L15A/Staggered-DiD/index.html#the-problem-of-bad-comparisons",
    "title": "[Causal Inference] 15A. Staggered DiD",
    "section": "2.2. The Problem of “Bad Comparisons”",
    "text": "2.2. The Problem of “Bad Comparisons”\nGoodman-Bacon (2021) 등의 연구에 따르면, TWFE 추정량은 가능한 모든 2x2 DiD 비교의 가중 평균으로 분해됩니다. 이때 “Bad Comparisons” (Invalid Comparisons) 문제가 발생합니다.\n\nValid Comparisons (좋은 비교):\n\nTreated Unit vs. Never-treated Unit\nTreated Unit vs. Not-yet-treated Unit\n\nInvalid Comparisons (나쁜 비교):\n\nLater-treated vs. Earlier-treated (Already-treated): 늦게 처치를 받는 그룹을 실험군으로, 이미 처치를 받은 그룹을 통제군으로 사용하는 경우입니다.\n문제점: 만약 처치 효과가 시간에 따라 변한다면(Dynamic Effects), 이미 처치를 받은 그룹의 결과값 변화(\\(\\Delta Y\\))에는 시간 트렌드뿐만 아니라 처치 효과의 변화분이 섞여 있습니다. 이를 통제군으로 사용하면 평행 추세 가정(Parallel Trends)이 깨지게 되어 편향(Bias)이 발생합니다.\n\n\n &gt; Figure 2 설명: 각 그룹(A, B, C)의 시간에 따른 Outcome \\(Y\\)의 변화를 나타냅니다. &gt; - 점선(세모 마커)은 반사실적(Counterfactual) 상황, 즉 처치를 받지 않았을 때의 잠재적 결과를 의미합니다. &gt; - 실선(동그라미 마커)은 관측된 결과입니다. &gt; - 각 그룹이 처치를 받는 시점 이후로 Outcome이 급격히 상승하는 것을 볼 수 있으며, 이는 처치 효과의 이질성(Heterogeneity)을 시사합니다."
  },
  {
    "objectID": "posts/lecture/L15A/Staggered-DiD/index.html#notation-definitions",
    "href": "posts/lecture/L15A/Staggered-DiD/index.html#notation-definitions",
    "title": "[Causal Inference] 15A. Staggered DiD",
    "section": "3.1. Notation & Definitions",
    "text": "3.1. Notation & Definitions\n\nTime Periods: \\(t = 1, ..., \\mathcal{T}\\)\nTreatment Group (\\(G_g\\)): 시점 \\(g\\)에 처음으로 처치를 받기 시작한 유닛들의 집합. (즉, \\(G_i = g\\)이면 유닛 \\(i\\)는 시점 \\(g\\)부터 처치 상태).\nNever-Treated Group (\\(C\\)): 관찰 기간 동안 처치를 받지 않은 유닛 (\\(G_i = \\infty\\) 또는 \\(C_i = 1\\)).\nPotential Outcomes:\n\n\\(Y_{it}(0)\\): 시점 \\(t\\)에서 처치를 받지 않았을 때의 잠재적 결과.\n\\(Y_{it}(g)\\): 시점 \\(t\\)에서, 시점 \\(g\\)에 처치를 받기 시작했을 때의 잠재적 결과.\n\nObserved Outcome: \\[\n  Y_{it} = Y_{it}(0) \\cdot \\mathbb{1}\\{G_i &gt; t\\} + Y_{it}(G_i) \\cdot \\mathbb{1}\\{G_i \\le t\\}\n  \\] 즉, 처치 전에는 \\(Y(0)\\)를, 처치 후에는 해당 처치 시점에 종속된 \\(Y(g)\\)를 관측합니다."
  },
  {
    "objectID": "posts/lecture/L15A/Staggered-DiD/index.html#group-time-average-treatment-effect-attg-t",
    "href": "posts/lecture/L15A/Staggered-DiD/index.html#group-time-average-treatment-effect-attg-t",
    "title": "[Causal Inference] 15A. Staggered DiD",
    "section": "3.2. Group-Time Average Treatment Effect, \\(ATT(g, t)\\)",
    "text": "3.2. Group-Time Average Treatment Effect, \\(ATT(g, t)\\)\n가장 핵심적인 파라미터는 특정 처치 그룹 \\(g\\)가 특정 시점 \\(t\\)에 누리는 평균 처치 효과입니다.\n\\[\nATT(g, t) = \\mathbb{E}[Y_t(g) - Y_t(0) \\mid G=g]\n\\]\n이 정의는 매우 직관적입니다. “시점 \\(g\\)에 처치를 받은 사람들이, 시점 \\(t\\)에 실제로 겪은 효과”를 의미합니다. 만약 \\(t \\ge g\\)라면 처치 효과(Post-treatment effect)이고, \\(t &lt; g\\)라면 처치 전 효과(Pre-treatment effect, 일반적으로 0이어야 함)가 됩니다."
  },
  {
    "objectID": "posts/lecture/L15A/Staggered-DiD/index.html#parallel-trends-assumptions",
    "href": "posts/lecture/L15A/Staggered-DiD/index.html#parallel-trends-assumptions",
    "title": "[Causal Inference] 15A. Staggered DiD",
    "section": "4.1. Parallel Trends Assumptions",
    "text": "4.1. Parallel Trends Assumptions\nCS(2021) 방법론은 연구자가 통제군을 어떻게 정의하느냐에 따라 두 가지 버전의 가정을 제시합니다.\n\nOption 1: Based on Never-Treated Units\n처치를 전혀 받지 않은 그룹(\\(C=1\\))을 통제군으로 사용합니다.\n\\[\n\\mathbb{E}[Y_t(0) - Y_{t-1}(0) \\mid G=g] = \\mathbb{E}[Y_t(0) - Y_{t-1}(0) \\mid C=1]\n\\]\n\n해석: 처치가 없었다면, 그룹 \\(g\\)의 결과값 변화 추세는 Never-treated 그룹의 변화 추세와 같았을 것이다.\n\n\n\nOption 2: Based on Not-Yet-Treated Units\n시점 \\(t\\)까지 아직 처치를 받지 않은 그룹들(\\(D_s=0\\))을 통제군으로 사용합니다.\n\\[\n\\mathbb{E}[Y_t(0) - Y_{t-1}(0) \\mid G=g] = \\mathbb{E}[Y_t(0) - Y_{t-1}(0) \\mid D_t=0, G \\ne g]\n\\]\n\n해석: 처치가 없었다면, 그룹 \\(g\\)의 변화 추세는 해당 시점에 아직 처치를 받지 않은 그룹들의 추세와 같았을 것이다.\n장점: Never-treated 그룹이 없거나 매우 작을 때 유용합니다."
  },
  {
    "objectID": "posts/lecture/L15A/Staggered-DiD/index.html#derivation-of-the-estimator",
    "href": "posts/lecture/L15A/Staggered-DiD/index.html#derivation-of-the-estimator",
    "title": "[Causal Inference] 15A. Staggered DiD",
    "section": "4.2. Derivation of the Estimator",
    "text": "4.2. Derivation of the Estimator\nNever-treated 가정을 사용할 때, \\(ATT(g, t)\\)는 다음과 같이 유도됩니다.\n\n목표: \\(\\mathbb{E}[Y_t(g) - Y_t(0) \\mid G=g]\\) 구하기.\n분해: 기대값의 선형성에 의해: \\[\nATT(g,t) = \\mathbb{E}[Y_t(g) \\mid G=g] - \\mathbb{E}[Y_t(0) \\mid G=g]\n\\] 앞항 \\(\\mathbb{E}[Y_t(g) \\mid G=g]\\)는 데이터에서 관측 가능합니다(\\(t \\ge g\\)일 때). 뒷항은 반사실적이므로 관측 불가합니다.\n평행 추세 가정 적용: \\[\n\\mathbb{E}[Y_t(0) - Y_{g-1}(0) \\mid G=g] = \\mathbb{E}[Y_t(0) - Y_{g-1}(0) \\mid C=1]\n\\] 이를 \\(Y_t(0)\\)에 대해 정리하면(Baseline 시점을 \\(g-1\\)로 설정): \\[\n\\mathbb{E}[Y_t(0) \\mid G=g] = \\mathbb{E}[Y_{g-1}(0) \\mid G=g] + \\underbrace{\\mathbb{E}[Y_t(0) - Y_{g-1}(0) \\mid C=1]}_{\\text{Control Group's Trend}}\n\\]\n최종 식: \\[\nATT(g, t) = \\underbrace{\\mathbb{E}[Y_t - Y_{g-1} \\mid G=g]}_{\\text{Change for Treated}} - \\underbrace{\\mathbb{E}[Y_t - Y_{g-1} \\mid C=1]}_{\\text{Change for Control}}\n\\]\n\n즉, 각 그룹-시점별(\\(g, t\\))로 고전적인 2x2 DiD를 수행하는 것과 같습니다. 이때 중요한 것은 “이미 처치된 그룹”을 통제군으로 섞지 않는다는 점입니다."
  },
  {
    "objectID": "posts/lecture/L15A/Staggered-DiD/index.html#event-study-aggregation-theta_de",
    "href": "posts/lecture/L15A/Staggered-DiD/index.html#event-study-aggregation-theta_de",
    "title": "[Causal Inference] 15A. Staggered DiD",
    "section": "5.1. Event-Study Aggregation (\\(\\theta_D(e)\\))",
    "text": "5.1. Event-Study Aggregation (\\(\\theta_D(e)\\))\n처치 후 경과 시간(Event time, \\(e\\))에 따른 동태적 효과를 보고 싶을 때 사용합니다. \\(e = t - g\\) (처치 후 경과 기간).\n\\[\n\\theta_{D}(e) = \\sum_{g} w_g \\cdot ATT(g, g+e)\n\\] 여기서 \\(w_g\\)는 각 그룹의 샘플 비중입니다. * \\(e=0\\): 처치 원년의 효과 * \\(e=1, 2, \\dots\\): 처치 1년 후, 2년 후 효과 (Dynamic Effects) * \\(e &lt; 0\\): 처치 전 효과 (Pre-trend test로 활용 가능)"
  },
  {
    "objectID": "posts/lecture/L15A/Staggered-DiD/index.html#simple-overall-aggregation-theta_so",
    "href": "posts/lecture/L15A/Staggered-DiD/index.html#simple-overall-aggregation-theta_so",
    "title": "[Causal Inference] 15A. Staggered DiD",
    "section": "5.2. Simple Overall Aggregation (\\(\\theta_S^O\\))",
    "text": "5.2. Simple Overall Aggregation (\\(\\theta_S^O\\))\n단일 숫자로 전체 처치 효과를 요약하고 싶을 때 사용합니다.\n\\[\n\\theta_{S}^{O} = \\frac{1}{\\sum P(G=g)} \\sum_{g} \\sum_{t \\ge g} ATT(g, t) P(G=g)\n\\] 이는 모든 \\(ATT(g,t)\\) (단, \\(t \\ge g\\))를 평균 낸 값으로, “처치를 받은 모든 기간 동안의 평균 효과”로 해석됩니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "",
    "text": "지난 포스트들에서 우리는 이중차분법(DiD)을 통해 인과효과를 추정하는 방법을 배웠습니다.\n하지만 DiD를 적용하기 어려운 상황이 종종 발생합니다. 바로 “적절한 통제 집단(Control Group)을 찾기 어려울 때”입니다.\n예를 들어, 캘리포니아 주가 담배 규제 정책(Proposition 99)을 시행했을 때, 나머지 49개 주 전체를 평균 내어 비교하는 것이 공정할까요?\n캘리포니아와 인구 구조, 경제 규모, 흡연 문화가 비슷한 단일한 주는 존재하지 않을지도 모릅니다.\n이번 포스트에서는 이러한 문제를 해결하기 위해, 여러 통제 집단을 적절히 섞어 “가상의 도플갱어(Synthetic Control)”를 만들어내는 통제집단합성법(Synthetic Control Method, SCM)에 대해 알아봅니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#단순-비교의-함정",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#단순-비교의-함정",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "1.1 단순 비교의 함정",
    "text": "1.1 단순 비교의 함정\n\n가장 단순한 방법은 “캘리포니아”와 “나머지 미국 전체(Rest of the U.S.)”의 담배 판매량을 비교하는 것입니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#합성-캘리포니아-synthetic-california의-등장",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#합성-캘리포니아-synthetic-california의-등장",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "1.2 합성 캘리포니아 (Synthetic California)의 등장",
    "text": "1.2 합성 캘리포니아 (Synthetic California)의 등장\n\nSCM은 다른 주들의 데이터를 가중 평균(Weighted Average)하여, 1988년 이전의 캘리포니아와 거의 완벽하게 겹치는 가상의 캘리포니아를 만들어냅니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#setup",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#setup",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "2.1 Setup",
    "text": "2.1 Setup\n\n단일 처치 집단: \\(i=1\\)\n통제 집단 풀(Donor Pool): \\(i=2, \\dots, J+1\\)\n시간: \\(T_0\\) (개입 이전 기간), \\(T\\) (전체 기간)\n목표: 개입 이후(\\(t &gt; T_0\\))의 처치 효과 \\(\\tau_{1t}\\) 추정 \\[\\tau_{1t} = Y_{1t}(1) - Y_{1t}(0)\\]\n여기서 \\(Y_{1t}(1)\\)은 관찰되지만, 정책이 없었을 때의 결과인 \\(Y_{1t}(0)\\)은 결측된 반사실(Missing Counterfactual)입니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#합성-통제-집단-구성-weights-construction",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#합성-통제-집단-구성-weights-construction",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "2.2 합성 통제 집단 구성 (Weights Construction)",
    "text": "2.2 합성 통제 집단 구성 (Weights Construction)\n\nSCM의 핵심은 통제 집단 유닛들에 부여할 가중치 벡터 \\(W = (w_2, \\dots, w_{J+1})'\\)를 찾는 것입니다.\n이 가중치는 다음 두 가지 제약 조건을 만족해야 합니다.\n\n\n비음수 조건 (Non-negative): \\(w_j \\ge 0\\)\n\n\n합의 조건 (Sum to one): \\(\\sum_{j=2}^{J+1} w_j = 1\\)\n\n\n이 제약 조건들은 합성 통제 집단이 데이터들의 볼록 껍질(Convex Hull) 내부에 존재하게 하여, 내삽(Interpolation)을 수행하도록 강제합니다.\n즉, 데이터의 범위를 벗어나는 과도한 외삽(Extrapolation)을 방지합니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#최적화-문제-optimization",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#최적화-문제-optimization",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "2.3 최적화 문제 (Optimization)",
    "text": "2.3 최적화 문제 (Optimization)\n\nSCM의 핵심은 “어떤 주(State)를 얼마나 섞을 것인가?”를 결정하는 최적의 가중치 벡터 \\(W^*\\)를 찾는 것입니다.\n\n\n2.3.1 목적 함수 (Objective Function)\n\n우리는 개입 이전 기간(\\(t \\le T_0\\)) 동안, 처치 집단과 합성 통제 집단 사이의 차이(Distance)를 최소화하고자 합니다.\n이를 위한 목적 함수는 다음과 같이 구성됩니다.\n\n\\[\nW^* = \\underset{W}{\\mathrm{argmin}} \\sqrt{ \\underbrace{\\sum_{m=1}^{k} v_m \\left( X_{1m} - \\sum_{j=2}^{J+1} w_j X_{jm} \\right)^2}_{\\text{예측 변수들의 가중 거리 합}} }\n\\]\n\n여기서 \\(X_{1m}\\)과 \\(X_{jm}\\)은 각각 처치 집단과 통제 집단의 예측 변수(Pre-treatment outcomes 및 Covariates)를 의미하며, 수식의 의미는 다음과 같습니다.\n\n결과 변수 추세 매칭 (Outcome Matching):\n\n\n개입 이전의 결과 변수 추세가 처치 집단과 최대한 겹치도록 만듭니다.\n과거의 궤적을 잘 모사해야 미래의 반사실(Counterfactual)도 신뢰할 수 있습니다.\n\n\n공변량 매칭 (Covariate Matching):\n\n\n단순히 결과값의 패턴만 맞추는 것이 아니라, 결과에 영향을 미치는 근본적인 특성까지 유사하게 맞춥니다.\n이는 모델이 우연히 시계열 패턴만 맞추는 과적합(Overfitting)을 방지하고, 구조적인 유사성을 보장합니다.\n\n\n\n\n2.3.2 제약 조건 (Constraints)\n\n찾아낸 가중치 \\(W = (w_2, \\dots, w_{J+1})'\\)는 반드시 다음 두 가지 조건을 만족해야 합니다.\n비음수 조건 (\\(w_j \\ge 0\\)): 회귀분석과 달리 음의 가중치를 허용하지 않습니다. \\[\nw_j \\ge 0\n\\]\n합의 조건 (\\(\\sum w_j = 1\\)): 모든 가중치의 합은 1이어야 합니다. \\[\n\\sum_{j=2}^{J+1} w_j = 1\n\\]\n의미:\n\n이 제약 조건들로 인해 합성 대조군은 데이터의 볼록 껍질(Convex Hull) 내에서 생성됩니다.\n즉, 합성 대조군은 통제 집단들의 ‘엄밀한 내삽(Interpolation)’ 결과물이 되며, 데이터 범위를 벗어나는 외삽(Extrapolation)의 위험을 차단합니다.\n\n\n\n\n2.3.3 변수 중요도 행렬 (\\(V\\) Matrix)\n\n위 수식의 \\(v_m\\)은 각 변수 \\(m\\)이 합성에 얼마나 기여해야 하는지를 결정하는 중요도 가중치입니다.\n모든 변수가 예측에 동일하게 중요하지 않습니다. 예를 들어, 흡연량을 예측할 때 ’지난해 흡연량’이 ’GDP’보다 더 중요할 수 있습니다.\n실제 분석에서는 이중 최적화(Nested Optimization) 과정을 거칩니다.\n\nInner Step: \\(V\\)가 주어졌을 때, 차이를 최소화하는 \\(W\\)를 찾습니다.\nOuter Step: 개입 이전 기간의 예측 오차(MSPE)를 가장 낮추는 최적의 변수 중요도 \\(V\\)를 찾아냅니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#model-based-justification",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#model-based-justification",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "3.1. Model-based Justification",
    "text": "3.1. Model-based Justification\n\nSCM이 단순히 “비슷해 보이는” 대상을 섞는 것이 아니라, 수학적으로 타당한 인과추론 도구인 이유는 무엇일까요?\nAbadie et al. (2010)은 두 가지 모형을 통해 SCM의 강력함을 증명했습니다.\n\n\n모형 1: 상호작용 요인 모형 (Interacted Factor Model)\n\n가장 널리 인용되는 SCM의 기반 모형입니다.\n결과 변수 \\(Y_{it}(0)\\)가 관찰 가능한 요인뿐만 아니라, 관찰되지 않는 ‘시간에 따라 변하는 요인’에 의해 결정된다고 가정합니다.\n\n\\[\nY_{it}(0) = \\underbrace{\\delta_t}_{\\text{Time FE}} + \\underbrace{\\boldsymbol{Z}_i' \\boldsymbol{\\beta}_t}_{\\text{Covariates}} + \\underbrace{\\alpha_i}_{\\text{Unit FE}} + \\underbrace{\\boldsymbol{\\lambda}_t \\boldsymbol{\\mu}_i}_{\\text{Latent Factors}} + \\epsilon_{it}\n\\]\n\n이 수식의 각 항은 다음을 의미합니다.\n\n\\(\\delta_t\\): 모든 유닛에 공통적으로 영향을 미치는 시간 충격 (예: 글로벌 경제 위기).\n\\(\\boldsymbol{Z}_i' \\boldsymbol{\\beta}_t\\): 관찰 가능한 공변량(\\(Z\\))이 시간에 따라 미치는 영향(\\(\\beta_t\\))이 변할 수 있음을 허용.\n\\(\\alpha_i\\): 유닛 고유의 고정 효과 (기존 DiD가 통제하는 부분).\n\\(\\boldsymbol{\\lambda}_t \\boldsymbol{\\mu}_i\\) (핵심): 관찰되지 않는 공통 요인(\\(\\lambda_t\\))과 각 유닛의 요인 적재값(\\(\\mu_i\\))의 곱입니다.\n\n이는 시간 가변적 교란 요인(Time-varying Confounding)을 구조적으로 모형화한 것입니다.\n예를 들어, \\(\\lambda_t\\)가 ’기술 발전 속도’라면 \\(\\mu_i\\)는 해당 주(State)의 ’기술 수용성’이 될 수 있으며, 이 효과는 시간에 따라 달라집니다.\n\n\n기존의 이중차분법(DiD)은 \\(\\alpha_i\\)(시간 불변 요인)만 제거할 수 있습니다.\n하지만 SCM은 적절한 가중치(\\(W\\))를 통해 \\(\\boldsymbol{\\lambda}_t \\boldsymbol{\\mu}_i\\) 항까지 상쇄시킬 수 있어, 평행 추세 가정이 위배되는 상황에서도 편향 없는 추정이 가능합니다.\n\n\n\n모형 2: 자기회귀 모형 (Autoregressive Model)\n\n두 번째 정당화 논리는 데이터가 자기회귀(AR) 과정을 따른다는 가정에서 출발합니다.\n즉, 현재의 결과가 과거의 결과에 의존하는 경우입니다.\n\n\\[\nY_{i, t+1}(0) = \\alpha_t Y_{it}(0) + \\beta_{t+1} \\boldsymbol{Z}_{i, t+1} + u_{i, t+1}\n\\] \\[\n\\boldsymbol{Z}_{i, t+1} = \\gamma_t Y_{it}(0) + \\Pi_t \\boldsymbol{Z}_{it} + \\boldsymbol{v}_{i, t+1}\n\\]\n\n이 모형은 고정 효과(Fixed Effects) 없이도, 과거의 결과값(\\(Y_{it}\\))과 공변량(\\(Z\\))을 완벽하게 매칭하면 미래의 경로도 예측할 수 있음을 시사합니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#scm의-추정-성질-scm-properties",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#scm의-추정-성질-scm-properties",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "3.2 SCM의 추정 성질 (SCM Properties)",
    "text": "3.2 SCM의 추정 성질 (SCM Properties)\n\n위의 모형들 하에서, 만약 우리가 개입 이전 기간의 결과(\\(Y\\))와 공변량(\\(Z\\))을 완벽하게 균형 맞추는 가중치 \\(w^*\\)를 찾을 수 있다면 다음과 같은 성질이 성립합니다.\n\n\\[\n\\sum_{j=2}^{J+1} w_j^* Y_{jt} = Y_{1t} \\quad \\text{and} \\quad \\sum_{j=2}^{J+1} w_j^* \\boldsymbol{Z}_j = \\boldsymbol{Z}_1\n\\]\n\n이 조건이 충족될 때, 개입 이후 시점(\\(t &gt; T_0\\))에 대한 반사실 추정량 \\(\\hat{Y}_{1t}(0)\\)은 다음과 같은 특징을 가집니다.\n\n\nUnder Model 1 (점근적 일치성):\n\n개입 이전 기간(\\(T_0\\))이 길어질수록(\\(T_0 \\to \\infty\\)), 편향(Bias)이 0으로 수렴합니다.\n즉, \\(\\hat{Y}_{1t}(0) \\to Y_{1t}(0)\\)이 되어, 과거 데이터를 길게 확보할수록 추정이 정확해집니다.\n\nUnder Model 2 (비편향성):\n\n자기회귀 모형 하에서는 단기간의 개입 이전 데이터만으로도 비편향 추정량(\\(\\mathbb{E}[\\hat{Y}_{1t}(0)] = \\mathbb{E}[Y_{1t}(0)]\\))을 얻을 수 있습니다.\n\n\n\n결론적으로 SCM은 “과거의 궤적(Trajectory)을 오랫동안, 그리고 정확하게 흉내 낼 수 있다면 미래의 궤적 또한 신뢰할 수 있다”는 수학적 보장을 가지고 있습니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#볼록성convexity의-기하학적-의미",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#볼록성convexity의-기하학적-의미",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "3.3 볼록성(Convexity)의 기하학적 의미",
    "text": "3.3 볼록성(Convexity)의 기하학적 의미\n\nSCM은 데이터를 ‘섞어서’ 만드는 것이므로 기하학적으로는 다면체 내부의 한 점을 찾는 것과 같습니다.\n\n\n\n\nFigure: \\(X_1\\)(검은 점)을 \\(X_0\\)(빨간 점들)의 조합으로 표현할 때, \\(X_1\\)이 빨간 점들이 이루는 다면체(Triangle) 내부에 있어야 안전한 추론(Interpolation)이 가능합니다. 외부에 있다면 SCM 적용에 주의가 필요합니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#편향-보정-bias-correction",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#편향-보정-bias-correction",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "4.1 편향 보정 (Bias Correction)",
    "text": "4.1 편향 보정 (Bias Correction)\n\n현실에서는 개입 이전 기간(\\(T_0\\))에도 처치 집단과 합성 대조군이 완벽하게 일치하지 않을 수 있습니다(Imperfect Pre-treatment Fit).\n이 경우 추정치에 편향이 발생합니다.\n이를 해결하기 위해 Augmented SCM (ASCM)이 제안되었습니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#ascm-공식",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#ascm-공식",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "4.2 ASCM 공식",
    "text": "4.2 ASCM 공식\n\nASCM은 기존 SCM 추정치에 회귀분석을 이용한 보정항을 추가합니다. \\[\n\\hat{Y}_{1t}^{aug}(0) = \\underbrace{\\sum_{j=2}^{J+1} w_j Y_{jt}}_{\\text{Original SCM}} + \\underbrace{\\left( \\hat{m}_{1t} - \\sum_{j=2}^{J+1} w_j \\hat{m}_{jt} \\right)}_{\\text{Bias Correction}}\n\\]\n\n\\(\\hat{m}_{it}\\): 공변량 등을 이용해 예측한 결과값 (Ridge Regression 등을 사용)\n이 보정항은 합성 대조군이 설명하지 못하는 잔여 차이를 회귀 모델로 메꿔주는 역할을 합니다."
  },
  {
    "objectID": "posts/lecture/L12/index.html",
    "href": "posts/lecture/L12/index.html",
    "title": "[Causal Inference] 12. Matching",
    "section": "",
    "text": "인과추론(Causal Inference)의 근본적인 문제는 관측되지 않는 반사실(Counterfactual)을 추론하는 것입니다. 처치 집단(Treated units)과 통제 집단(Control units) 간의 비교를 통해 효과를 추정하고자 할 때, 우리는 종종 처치 집단에 대한 평균 처치 효과(ATT, Average Treatment Effect for the Treated)에 관심을 가집니다.\n\\[\n\\tau_{ATT} = E[Y(1) - Y(0) | T=1]\n\\]\n여기서 \\(Y(1)\\)은 처치를 받았을 때의 결과, \\(Y(0)\\)는 처치를 받지 않았을 때의 결과입니다. \\(T=1\\)인 집단에게 \\(Y(1)\\)은 관측되지만, \\(Y(0)\\)는 관측되지 않습니다(Missing Data).\n\n\n전통적인 회귀분석(Regression) 방식은 모델에 기반한 대체(Model-based Imputation)라고 볼 수 있습니다. 회귀분석을 통해 \\(\\hat{Y}(0)\\)를 추정할 때, 선형성 등 특정 함수 형태(functional form)를 가정해야 합니다.\n\\[\n\\hat{\\tau}_{reg} = \\frac{1}{N_1} \\sum_{i=1}^{N} T_i (Y_i - \\hat{\\mu}_0(X_i))\n\\]\n반면, 매칭(Matching)은 비모수적 대체(Nonparametric Imputation) 방법입니다. 함수 형태에 대한 강력한 가정 없이, 처치 집단과 특성(Covariates)이 유사한 통제 집단 데이터를 찾아 반사실을 대체합니다.\n\n\n\nFigure 1: Matching의 기본 아이디어. 모집단(Population)에는 다양한 특성을 가진 개체들이 섞여 있지만, 매칭을 통해 처치 집단(파란색)과 유사한 특성을 가진 통제 집단(회색)만을 선별하여 연구 집단을 구성한다.\n\n\n위 그림과 같이, 충분히 큰 통제 집단(Reservoir of potential controls)이 존재한다면, 각 처치 개체에 대해 하나 이상의 유사한 통제 개체를 매칭할 수 있습니다.\n\n\n\nFigure 2: 오리(Duck) 예시를 통한 매칭의 직관적 이해. 왼쪽의 프로그램 참여 오리들(Treated)과 특성이 가장 유사한 오른쪽의 비교군 오리들(Controls)을 일대일 혹은 일대다로 연결하여 비교 집단을 형성한다."
  },
  {
    "objectID": "posts/lecture/L12/index.html#regression-vs.-matching",
    "href": "posts/lecture/L12/index.html#regression-vs.-matching",
    "title": "[Causal Inference] 12. Matching",
    "section": "",
    "text": "전통적인 회귀분석(Regression) 방식은 모델에 기반한 대체(Model-based Imputation)라고 볼 수 있습니다. 회귀분석을 통해 \\(\\hat{Y}(0)\\)를 추정할 때, 선형성 등 특정 함수 형태(functional form)를 가정해야 합니다.\n\\[\n\\hat{\\tau}_{reg} = \\frac{1}{N_1} \\sum_{i=1}^{N} T_i (Y_i - \\hat{\\mu}_0(X_i))\n\\]\n반면, 매칭(Matching)은 비모수적 대체(Nonparametric Imputation) 방법입니다. 함수 형태에 대한 강력한 가정 없이, 처치 집단과 특성(Covariates)이 유사한 통제 집단 데이터를 찾아 반사실을 대체합니다.\n\n\n\nFigure 1: Matching의 기본 아이디어. 모집단(Population)에는 다양한 특성을 가진 개체들이 섞여 있지만, 매칭을 통해 처치 집단(파란색)과 유사한 특성을 가진 통제 집단(회색)만을 선별하여 연구 집단을 구성한다.\n\n\n위 그림과 같이, 충분히 큰 통제 집단(Reservoir of potential controls)이 존재한다면, 각 처치 개체에 대해 하나 이상의 유사한 통제 개체를 매칭할 수 있습니다.\n\n\n\nFigure 2: 오리(Duck) 예시를 통한 매칭의 직관적 이해. 왼쪽의 프로그램 참여 오리들(Treated)과 특성이 가장 유사한 오른쪽의 비교군 오리들(Controls)을 일대일 혹은 일대다로 연결하여 비교 집단을 형성한다."
  },
  {
    "objectID": "posts/lecture/L12/index.html#exact-matching-coarsened-exact-matching-cem",
    "href": "posts/lecture/L12/index.html#exact-matching-coarsened-exact-matching-cem",
    "title": "[Causal Inference] 12. Matching",
    "section": "3.1 Exact Matching & Coarsened Exact Matching (CEM)",
    "text": "3.1 Exact Matching & Coarsened Exact Matching (CEM)\nExact Matching은 말 그대로 공변량 \\(X\\)가 완전히 동일한 개체끼리 매칭하는 것입니다. 이 경우 처치 집단과 통제 집단 간의 공변량 분포가 완벽하게 일치하므로(\\(\\tilde{F}(X|T=1) = \\tilde{F}(X|T=0)\\)), \\(X\\)로 인한 편향(Bias)을 완전히 제거할 수 있습니다.\n하지만 차원의 저주(Curse of Dimensionality)로 인해 공변량이 많거나 연속형 변수가 포함된 경우, 정확히 일치하는 짝을 찾는 것은 현실적으로 불가능(Infeasible)합니다.\n이에 대한 대안으로 CEM(Coarsened Exact Matching)이 사용됩니다. * 연속형 변수 등을 구간화(Discretize/Coarsen)하여 범주형으로 만듭니다. * 예를 들어, 나이를 20대, 30대로 묶거나 소득을 구간별로 나누어 매칭합니다. * 여전히 일부 처치 개체는 매칭되는 짝이 없어 버려질 수 있습니다(Lack of overlap).\n\nCaveat: The King Charles vs. Ozzy Osbourne Example\n\n\n\nFigure 3: 표면적 특성의 함정. King Charles III와 Ozzy Osbourne은 모두 1948년생 남성, 영국 성장, 두 번의 결혼, 부유하고 유명함, 성에 거주함이라는 공통적인 인구통계학적 특성을 공유하지만, 그들의 라이프스타일과 건강 상태는 완전히 다르다.\n\n\n위 예시는 제한된 공변량만으로 매칭했을 때의 위험성을 보여줍니다. 관측된 변수가 같더라도 관측되지 않은 중요한 특성이 다를 수 있으므로(Unobserved Confounding), 매칭 변수 선정에 신중해야 합니다."
  },
  {
    "objectID": "posts/lecture/L12/index.html#nearest-neighbor-nn-matching",
    "href": "posts/lecture/L12/index.html#nearest-neighbor-nn-matching",
    "title": "[Causal Inference] 12. Matching",
    "section": "3.2 Nearest Neighbor (NN) Matching",
    "text": "3.2 Nearest Neighbor (NN) Matching\n가장 널리 사용되는 방법 중 하나로, 거리(Distance) 척도를 정의하고 가장 가까운 \\(M\\)개의 통제 개체를 찾는 방식입니다.\n\nDistance Metrics\n두 개체 \\(i, j\\) 사이의 거리를 측정하는 방법으로는 주로 유클리디안 거리 혹은 마할라노비스 거리가 사용됩니다.\nMahalanobis Distance: 공변량 간의 상관관계를 고려하고 스케일을 표준화한 거리 척도입니다. 공분산 행렬을 \\(\\Sigma\\)라고 할 때:\n\\[\nd(X_i, X_j) = \\sqrt{(X_i - X_j)' \\Sigma^{-1} (X_i - X_j)}\n\\]\n만약 \\(\\Sigma = I\\)라면 유클리디안 거리가 되며, 대각행렬이라면 정규화된 유클리디안 거리가 됩니다.\n\n\nAlgorithms: Greedy vs. Optimal\n\nGreedy Algorithm:\n\n처치 개체들을 무작위 혹은 특정 순서(예: Propensity Score 순)로 정렬합니다.\n순서대로 가장 가까운 통제 개체를 찾아 매칭하고, 비복원 추출인 경우 해당 통제 개체를 목록에서 제외합니다.\n계산이 빠르지만, 전체적으로 최적의 매칭을 보장하지 않습니다(초반에 좋은 대조군을 다 써버릴 수 있음).\n\nOptimal Matching:\n\n전체 처치 개체와 통제 개체 간의 거리 총합을 최소화하는 조합을 찾습니다.\n네트워크 흐름 문제(Network Flow Problem)로 환원되며, 헝가리안 알고리즘(Hungarian Algorithm) 등을 사용해 해결합니다.\n\n\n\n\nBias-Variance Trade-off in NN Matching\n고정된 \\(M\\)개의 매칭을 사용할 때 편향-분산 상충관계가 존재합니다. * \\(M\\)이 작으면(예: 1:1 매칭): 가장 유사한 개체만 쓰므로 편향(Bias)은 작지만, 분산(Variance)은 큽니다. * \\(M\\)이 크면: 덜 유사한 개체도 포함되므로 분산은 작아지지만, 편향은 커집니다.\n\nNote: Abadie & Imbens (2006)에 따르면, 연속형 공변량의 개수(\\(p\\))가 늘어날수록 NN 매칭 추정량의 편향은 \\(O(N^{-1/p})\\) 오더로 증가합니다. 즉, 고차원 데이터에서는 단순 NN 매칭이 비효율적일 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L12/index.html#kernel-matching",
    "href": "posts/lecture/L12/index.html#kernel-matching",
    "title": "[Causal Inference] 12. Matching",
    "section": "3.3 Kernel Matching",
    "text": "3.3 Kernel Matching\nNN 매칭이 가장 가까운 몇 개만 선택하는 것이라면, 커널 매칭은 밴드위스(Bandwidth, \\(h\\)) 내에 있는 모든 통제 개체를 사용하여 가중 평균을 구하는 방식입니다. 거리가 가까울수록 더 큰 가중치를 부여합니다.\n\\[\nw_i(j) = \\frac{K\\left(\\frac{X_j - X_i}{h}\\right)}{\\sum_{k: T_k=0} K\\left(\\frac{X_k - X_i}{h}\\right)}\n\\]"
  },
  {
    "objectID": "posts/lecture/L12/index.html#propensity-score-matching-psm",
    "href": "posts/lecture/L12/index.html#propensity-score-matching-psm",
    "title": "[Causal Inference] 12. Matching",
    "section": "3.4 Propensity Score Matching (PSM)",
    "text": "3.4 Propensity Score Matching (PSM)\n공변량이 매우 많은 경우(High-dimensional), 직접 매칭(Direct Matching)은 어렵습니다. 이를 해결하기 위해 성향 점수(Propensity Score)를 이용하여 차원을 축소합니다.\n\\[\ne(X) = P(T=1 | X)\n\\]\nRosenbaum & Rubin의 정리에 따라, \\(X\\) 대신 \\(e(X)\\)에 대해 매칭해도 편향을 제거할 수 있습니다. 실제로는 로지스틱 회귀 등을 통해 추정된 \\(\\hat{e}(X)\\)를 사용하거나, 선형 예측값(Linear Predictor)인 Logit 스케일에서 매칭을 수행하는 것이 일반적입니다.\n\\[\nd(i, j) = |\\text{logit}(\\hat{e}(X_i)) - \\text{logit}(\\hat{e}(X_j))|\n\\]"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "",
    "text": "지난 포스트에서 선형 모형(Linear Model) 가정 하의 IV를 다루었다면, 이번에는 무작위 실험(Randomized Experiment)에서 배정된 처치를 따르지 않는 ’불순응(Noncompliance)’이 발생했을 때의 IV 접근법을 다룹니다.\n경제학에서 도구변수(IV)는 주로 무작위 실험이 아닌 관찰 연구(Observational Study)에서 ’자연 실험(Natural Experiment)’의 일종으로 사용됩니다.\n좋은 도구변수 \\(Z\\)가 되기 위해서는 다음 두 가지 조건을 만족해야 합니다.\n\nRelevance (관련성): 도구변수 \\(Z\\)는 처치 \\(X\\)에 강한 영향을 미쳐야 합니다. (\\(Cov(X,Z)\\)가 커야 함). 그렇지 않으면(Weak IV), 추정량의 분산이 매우 커집니다.\nExclusion Restriction (배제 제약): 도구변수 \\(Z\\)는 결과 \\(Y\\)에 직접적인 영향을 미치지 않아야 하며, 오직 \\(X\\)를 통해서만 영향을 주어야 합니다.\n\n\n\n\n\nFigure 1: IV DAG regarding Noncompliance. Z(배정)가 X(실제 처치)를 통해 Y(결과)에 영향을 미치는 구조입니다. 점선 화살표는 잠재적 교란 요인을 의미합니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html#변수-정의",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html#변수-정의",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "2.1. 변수 정의",
    "text": "2.1. 변수 정의\n\n\\(Z_i\\) (Instrument/Assignment): 처치 배정 여부 (0 또는 1). 무작위 배정(Random Assignment)을 가정합니다.\n\\(X_i\\) (Treatment Received): 실제 처치를 받았는지 여부. \\(Z\\) 이후에 결정되므로(Post-treatment), \\(Z\\)에 따른 잠재적 결과를 가집니다.\n\n\\(X_i(z)\\): \\(Z=z\\)일 때 개인이 받게 될 처치 여부.\n\n\\(Y_i\\) (Outcome): 결과 변수.\n\n\\(Y_i(z, x)\\): 배정이 \\(z\\)이고 실제 처치가 \\(x\\)일 때의 잠재적 결과.\n일반적으로 Exclusion Restriction 가정 하에서 \\(Y_i(z=0, x) = Y_i(z=0, 1)\\)이므로 \\(Y_i(x)\\)로 표기.\n\n우리가 관측하는 데이터는 \\(Z_i, X_i = X_i(Z_i), Y_i = Y_i(Z_i)\\) 입니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html#순응-유형-compliance-types",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html#순응-유형-compliance-types",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "2.2. 순응 유형 (Compliance Types)",
    "text": "2.2. 순응 유형 (Compliance Types)\n\n사람들이 처치 배정(\\(Z\\))에 어떻게 반응하여 실제 처치(\\(X\\))를 받는지에 따라 4가지 잠재적 집단(Latent Subgroups)으로 나눌 수 있습니다.\n이를 \\(X_i(0)\\)와 \\(X_i(1)\\)의 조합으로 정의합니다.\n\n\n\n\n\n\n\n\n\n\nType\n\\(X_i(0)\\)\n\\(X_i(1)\\)\nDescription\n\n\n\n\nNever-taker\n0\n0\n배정을 받든 안 받든 처치를 받지 않음\n\n\nComplier\n0\n1\n배정받으면 처치 받고, 안 받으면 안 받음 (순응자)\n\n\nDefier\n1\n0\n배정과 반대로 행동함 (청개구리)\n\n\nAlways-taker\n1\n1\n배정을 받든 안 받든 항상 처치를 받음\n\n\n\n\nNote: 우리는 각 개인의 진짜 Type(\\(S\\))을 완벽하게 알 수 없습니다. 예를 들어 관측된 데이터에서 \\(Z=1, X=1\\)인 사람은 ’Complier’일 수도 있고 ’Always-taker’일 수도 있습니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html#itt-intent-to-treat-effects",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html#itt-intent-to-treat-effects",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "3.1. ITT (Intent-To-Treat) Effects",
    "text": "3.1. ITT (Intent-To-Treat) Effects\n\nITT 효과는 처치 배정(\\(Z\\))이 결과(\\(Y\\))에 미치는 인과적 효과입니다.\n개인의 순응 유형(\\(S\\))은 \\(Z\\)에 따라 변하지 않는 ’Baseline Characteristic’으로 간주할 수 있습니다.\n각 유형 \\(s \\in \\{c, n, a, d\\}\\)에 대한 ITT 효과는 다음과 같습니다. \\[ITT_s = \\mathbb{E}[Y_i(1) - Y_i(0) | S_i = s]\\]\n전체 모집단에 대한 Global ITT는 각 유형별 ITT의 가중 평균으로 표현됩니다. \\[\n\\begin{aligned}\nITT &= \\mathbb{E_s}[\\mathbb{E}[Y_i(1) - Y_i(0) | S_i = s]] \\\\\n&= \\pi_c ITT_c + \\pi_n ITT_n + \\pi_a ITT_a + \\pi_d ITT_d\n\\end{aligned}\n\\]\n\n여기서 \\(\\pi_s\\)는 각 유형의 구성 비율입니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html#식별을-위한-가정-assumptions",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html#식별을-위한-가정-assumptions",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "3.2. 식별을 위한 가정 (Assumptions)",
    "text": "3.2. 식별을 위한 가정 (Assumptions)\n\n비모수적 식별(Nonparametric Identification)을 위해 다음 3가지 핵심 가정이 필요합니다.\nAssumption 1: Random Assignment (무작위 배정) \\[\\{Y_i(0), Y_i(1), X_i(0), X_i(1)\\} \\perp Z_i\\]\n\n도구변수 \\(Z\\)가 잠재적 결과들과 독립이라는 가정입니다.\n\nAssumption 2: Strong Monotonicity (강한 단조성)\n\n\nNo Defiers:\n\n\n모든 \\(i\\)에 대해 \\(X_i(1) \\ge X_i(0)\\)\n우리의 예시에서는 \\(Z, X \\in \\{0, 1\\}\\) 이므로, \\(X_i(1) = 1 \\ge X_i(0) = 0\\)\n즉, 배정을 받았을 때 처치를 받을 확률이 배정을 안 받았을 때보다 작아지지는 않는다는 것입니다.\n이 가정에 의해 \\(\\pi_d = 0\\)이 됩니다.\n\n\nExistence of Compliers:\n\n\n\\(0 &lt; P(X_i=1 | Z_i=1) &lt; 1\\)\nComplier가 존재해야 합니다.\n\n\nAssumption 3: Exclusion Restriction (ER) for Noncompliers\n\n불순응자(Never-taker, Always-taker)에게는 배정(\\(Z\\)) 자체가 결과(\\(Y\\))에 영향을 주지 않아야 합니다.\n이들은 어차피 \\(Z\\)와 상관없이 동일한 \\(X\\)를 선택하기 때문입니다. \\[Y_i(1) = Y_i(0) \\quad \\text{for } S_i \\in \\{n, a\\}\\]\n따라서, \\(ITT_n = 0\\), \\(ITT_a = 0\\) 입니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html#유도-과정",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html#유도-과정",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "4.1. 유도 과정",
    "text": "4.1. 유도 과정\n\n원래 식: \\[ITT = \\pi_c ITT_c + \\pi_n ITT_n + \\pi_a ITT_a + \\pi_d ITT_d\\]\n\n\nMonotonicity 가정 적용: Defier가 없으므로 \\(\\pi_d = 0\\). \\[\\Rightarrow ITT = \\pi_c ITT_c + \\pi_n ITT_n + \\pi_a ITT_a\\]\nExclusion Restriction 가정 적용: Noncomplier의 ITT는 0이므로 \\(ITT_n = 0, ITT_a = 0\\). \\[\\Rightarrow ITT = \\pi_c ITT_c\\]\n\n\n결국 전체 ITT 효과는 Complier의 비율(\\(\\pi_c\\)) \\(\\times\\) Complier의 ITT 효과(\\(ITT_c\\))가 됩니다.\n이를 \\(ITT_c\\)에 대해 정리하면 다음과 같습니다.\n\n\\[ITT_c = \\frac{ITT}{\\pi_c}\\]\n\n이때, Complier에게는 \\(Z=X\\)이므로, \\(ITT_c\\)는 곧 Complier가 처치를 받았을 때의 인과 효과인 CACE가 됩니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html#complier-비율-pi_c-추정",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html#complier-비율-pi_c-추정",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "4.2. Complier 비율 (\\(\\pi_c\\)) 추정",
    "text": "4.2. Complier 비율 (\\(\\pi_c\\)) 추정\n\n관측된 데이터로 \\(\\pi_c\\)를 어떻게 구할까요?\n\n\\[\n\\begin{aligned}\n\\mathbb{E}[X_i | Z_i = 1] &= \\pi_c \\cdot 1 + \\pi_a \\cdot 1 + \\pi_n \\cdot 0 \\quad (\\text{Complier \\& Always-taker}) \\\\\n\\mathbb{E}[X_i | Z_i = 0] &= \\pi_c \\cdot 0 + \\pi_a \\cdot 1 + \\pi_n \\cdot 0 \\quad (\\text{Always-taker only})\n\\end{aligned}\n\\]\n\n두 식을 빼면:\n\n\\[\\mathbb{E}[X_i | Z_i = 1] - \\mathbb{E}[X_i | Z_i = 0] = \\pi_c\\]\n\n이것은 \\(Z\\)가 \\(X\\)에 미치는 ITT 효과(\\(ITT_X\\))와 같습니다.\n\n\\[ITT_X = \\mathbb{E}[X_i(1) - X_i(0)] = \\pi_c\\]"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html#cace-late-공식",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html#cace-late-공식",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "4.3. CACE / LATE 공식",
    "text": "4.3. CACE / LATE 공식\n\n최종적으로 CACE는 다음과 같이 두 ITT의 비율로 표현됩니다.\n\n\\[CACE \\equiv \\mathbb{E}[Y_i(1) - Y_i(0) | S_i = c] = \\frac{ITT_Y}{ITT_X} = \\frac{\\mathbb{E}[Y|Z=1] - \\mathbb{E}[Y|Z=0]}{\\mathbb{E}[X|Z=1] - \\mathbb{E}[X|Z=0]}\\]\n\n이는 Imbens and Angrist (1994)에서 제시한 LATE (Local Average Treatment Effect)와 동일한 개념입니다. “Local”인 이유는 전체 모집단이 아닌 Complier라는 특정 하위 집단에 대한 효과이기 때문입니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html#잠재적-결과의-식별-identification-of-potential-outcomes",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html#잠재적-결과의-식별-identification-of-potential-outcomes",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "4.4. 잠재적 결과의 식별 (Identification of Potential Outcomes)",
    "text": "4.4. 잠재적 결과의 식별 (Identification of Potential Outcomes)\n\nCACE를 계산하기 위해서는 Complier 집단의 잠재적 결과 평균(\\(\\mathbb{E}[Y_i(1)|c]\\)와 \\(\\mathbb{E}[Y_i(0)|c]\\))을 알아야 합니다.\n하지만 우리는 누가 Complier인지 개별적으로 알 수 없습니다.\n대신, 관측 가능한 집단(\\(Z, X\\))의 평균 결과가 어떤 잠재적 집단들의 혼합으로 이루어져 있는지 분해함으로써 이를 역추적할 수 있습니다.\n\n\n1. \\(Z=0, X=0\\) 집단 (Compliers + Never-takers)\n\n배정을 받지 않았고 처치도 받지 않은 그룹입니다.\n이들은 \\(Z=0\\)일 때 \\(X=0\\)인 Complier와 Never-taker로 구성됩니다. \\[\n\\mathbb{E}[Y_i | X_i = 0, Z_i = 0] = \\frac{\\pi_c}{\\pi_c + \\pi_n} \\cdot \\mathbb{E}[Y_i(0) | \\text{complier}] + \\frac{\\pi_n}{\\pi_c + \\pi_n} \\cdot \\mathbb{E}[Y_i(0) | \\text{never-taker}]\n\\]\n\n\n\n2. \\(Z=1, X=0\\) 집단 (Never-takers Only)\n\n배정을 받았으나(\\(Z=1\\)) 처치를 받지 않은(\\(X=0\\)) 그룹입니다.\nComplier라면 처치를 받았을 것이므로, 이 그룹은 순수하게 Never-taker들입니다. \\[\n\\mathbb{E}[Y_i | X_i = 0, Z_i = 1] = \\mathbb{E}[Y_i(0) | \\text{never-taker}]\n\\]\n\n\n\n3. \\(Z=0, X=1\\) 집단 (Always-takers Only)\n\n배정을 받지 않았는데도(\\(Z=0\\)) 처치를 받은(\\(X=1\\)) 그룹입니다.\nComplier라면 처치를 안 받았을 것이므로, 이 그룹은 순수하게 Always-taker들입니다. \\[\n\\mathbb{E}[Y_i | X_i = 1, Z_i = 0] = \\mathbb{E}[Y_i(1) | \\text{always-taker}]\n\\]\n\n\n\n4. \\(Z=1, X=1\\) 집단 (Compliers + Always-takers)\n\n배정을 받았고 처치도 받은 그룹입니다.\n이들은 \\(Z=1\\)일 때 \\(X=1\\)인 Complier와 Always-taker로 구성됩니다. \\[\n\\mathbb{E}[Y_i | X_i = 1, Z_i = 1] = \\frac{\\pi_c}{\\pi_c + \\pi_a} \\cdot \\mathbb{E}[Y_i(1) | \\text{complier}] + \\frac{\\pi_a}{\\pi_c + \\pi_a} \\cdot \\mathbb{E}[Y_i(1) | \\text{always-taker}]\n\\]\n\n\n결론: 위 식들을 연립하면, 관측 가능한 데이터로부터 미지수인 \\(\\mathbb{E}[Y_i(0) | \\text{complier}]\\)와 \\(\\mathbb{E}[Y_i(1) | \\text{complier}]\\)를 비모수적으로 식별(Nonparametrically Identify)할 수 있으며, 이를 통해 최종적으로 CACE를 구할 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html#one-sided-noncompliance-단측-불순응",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html#one-sided-noncompliance-단측-불순응",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "5.1. One-sided Noncompliance (단측 불순응)",
    "text": "5.1. One-sided Noncompliance (단측 불순응)\n\n실험 설계상 통제 집단(\\(Z=0\\))은 절대 처치를 받을 수 없는 경우(예: 신약 임상시험)입니다.\n즉, Always-taker가 없습니다(\\(X_i(0)=0\\)).\n이 경우 \\(\\sum X_i(1-Z_i) = 0\\) 이 되며 공식은 조금 더 단순해집니다.\n\n\\[\n\\begin{aligned}\n\\widehat{CACE} &= \\frac{\\widehat{E}[Y|Z=1] - \\widehat{E}[Y|Z=0]}{\\widehat{E}[X|Z=1]} \\\\\n&= \\frac{\\frac{\\sum Y_i Z_i}{\\sum Z_i} - \\frac{\\sum Y_i (1-Z_i)}{\\sum (1-Z_i)}}{\\frac{\\sum X_i Z_i}{\\sum Z_i}}\n\\end{aligned}\n\\]\n* 분모는 처치 집단 중 실제로 처치를 받은 사람의 비율"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html#two-sided-noncompliance-양측-불순응",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html#two-sided-noncompliance-양측-불순응",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "5.2. Two-sided Noncompliance (양측 불순응)",
    "text": "5.2. Two-sided Noncompliance (양측 불순응)\n\n일반적인 경우(Wald Estimator 형태)입니다.\n\n\\[\\widehat{CACE} = \\frac{\\widehat{E}[Y|Z=1] - \\widehat{E}[Y|Z=0]}{\\widehat{E}[X|Z=1] - \\widehat{E}[X|Z=0]}\\]"
  },
  {
    "objectID": "posts/lecture/L14/index.html",
    "href": "posts/lecture/L14/index.html",
    "title": "[Causal Inference] 14. Regression Discontinuity Design",
    "section": "",
    "text": "1. Introduction\n회귀 불연속 설계(Regression Discontinuity Design, RDD)는 인과 추론에서 무작위 배정(Random Assignment)이 불가능할 때, 관찰 데이터(Observational Data)를 이용해 인과 효과를 추정하는 가장 강력한 준실험(Quasi-experimental) 설계 중 하나입니다.\nRDD의 핵심 아이디어는 매우 직관적입니다. 특정 변수가 임계값(Cutoff)을 넘느냐 넘지 않느냐에 따라 처치(Treatment) 여부가 기계적으로 결정되는 상황을 이용합니다. 이 임계값 바로 주변에 있는 개체들은 사실상 무작위로 나뉜 것과 다름없다고 가정할 수 있습니다. [cite_start]즉, 임계값의 아주 미세한 차이로 처치를 받은 그룹과 받지 못한 그룹을 비교함으로써 인과 효과를 식별해내는 것입니다[cite: 303].\n\nMotivating Examples\n강의 자료에서는 다음과 같은 고전적인 예시들을 소개합니다:\n\n[cite_start]장학금 수여 (Thistlethwaite and Campbell, 1960)[cite: 307]: 시험 점수가 특정 커트라인(예: 80점)을 넘으면 장학금을 받고, 못 넘으면 받지 못하는 경우. 79점을 받은 학생과 81점을 받은 학생은 실력 면에서 큰 차이가 없다고 가정할 수 있으므로, 두 학생 그룹의 미래 성과 차이는 장학금의 인과 효과로 볼 수 있습니다.\n[cite_start]대학 재정 지원: 가구 소득이 특정 기준 이하인 학생에게만 지원금을 주는 경우[cite: 314].\n\n\n\n\nFigure 1: RDD의 기본 아이디어. 임계값(Cutoff) \\(c\\)를 기준으로 처치 여부가 갈리며, 결과 변수(Y)의 불연속적인 점프(Jump)를 통해 인과 효과 \\(\\gamma\\)를 추정한다.\n\n\n\n\n\n\n2. Core Concepts\nRDD를 이해하기 위해 필요한 핵심 구성 요소들은 다음과 같습니다.\n\n[cite_start]Forcing Variable (Running Variable, \\(Z_i\\)): 처치 여부를 결정하는 연속형 변수입니다 (예: 시험 점수, 소득). [cite: 294]\nCutoff (Threshold, \\(c\\)): 처치 여부가 갈리는 기준점입니다.\nTreatment Status (\\(X_i\\)): 개체 \\(i\\)가 처치를 받았는지 여부 (\\(X_i=1\\) or \\(0\\)).\n\n\nSharp vs. Fuzzy RDD\n[cite_start]처치 할당 메커니즘에 따라 RDD는 크게 두 가지로 나뉩니다. [cite: 327]\n\nSharp RD (단절적 RDD)\n\n처치 여부가 Forcing Variable과 Cutoff에 의해 결정론적(Deterministic)으로 정해집니다.\n모든 개체에 대해 \\(X_i = 1\\{Z_i \\ge c\\}\\)가 성립합니다.\n[cite_start]즉, 임계값을 넘으면 무조건 처치를 받고, 넘지 않으면 절대 받지 않습니다. [cite: 319]\n\nFuzzy RD (확률적 RDD)\n\n임계값을 기준으로 처치 받을 확률 \\(P(X_i=1)\\)이 불연속적으로 점프합니다.\n[cite_start]그러나 0에서 1로 완벽하게 변하지는 않습니다 (예: 기준을 넘겨도 처치를 거부하거나, 넘지 않아도 예외적으로 받는 경우). [cite: 347]\n\n\n\n이번 포스트에서는 Sharp RD를 중심으로 논의를 전개합니다.\n\n\n\n\nFigure 2: Sharp RD vs. Fuzzy RD. Sharp RD(상단)는 처치 확률이 0에서 1로 완전히 바뀌는 반면, Fuzzy RD(하단)는 확률의 불연속적인 점프만 존재한다.\n\n\n\n\n\n\n3. Mathematical Formulation & Identification\n우리의 관심 대상(Quantity of Interest)은 임계값 \\(c\\)에서의 국소 평균 처치 효과(Local Average Treatment Effect, LATE)입니다.\n\\[\n\\tau_{SRD} = \\mathbb{E}[Y_i(1) - Y_i(0) | Z_i = c]\n\\]\n[cite_start]여기서 \\(Y_i(1)\\)은 처치를 받았을 때의 잠재적 결과, \\(Y_i(0)\\)는 받지 않았을 때의 잠재적 결과입니다. [cite: 369]\n\nThe Identification Problem\n문제는 \\(Z_i\\)가 연속형 변수이기 때문에, 정확히 \\(Z_i = c\\)인 지점에서의 데이터를 관측할 확률은 0에 수렴한다는 점입니다. 심지어 \\(Z_i=c\\)인 데이터를 관측하더라도, Sharp RD 상황에서는 그 지점의 모든 사람이 처치를 받으므로 (\\(X_i=1\\)), 반대 상황인 \\(Y_i(0)\\) (대조군 결과)는 결코 관측할 수 없습니다.\n따라서 우리는 \\(c\\) 주변의 데이터를 이용해 외삽(Extrapolation)을 해야 합니다.\n\n\nThe Continuity Assumption\n이 외삽이 유효하기 위해서는 강력한 가정이 필요합니다. [cite_start]바로 잠재적 결과의 조건부 기댓값(CEF)이 \\(Z_i\\)에 대해 연속(Continuous)이어야 한다는 것입니다. [cite: 374]\n\\[\n\\lim_{z \\to c} \\mathbb{E}[Y_i(1) | Z_i=z] = \\mathbb{E}[Y_i(1) | Z_i=c] \\\\\n\\lim_{z \\to c} \\mathbb{E}[Y_i(0) | Z_i=z] = \\mathbb{E}[Y_i(0) | Z_i=c]\n\\]\n이 가정이 성립한다면, 우리는 관측된 데이터의 극한값을 이용해 보이지 않는 잠재적 결과를 대체할 수 있습니다.\n\n\nDerivation of the Estimator\n[cite_start]식별 과정은 다음과 같이 유도됩니다. [cite: 376, 381]\n\n임계값 바로 오른쪽 (\\(z \\downarrow c\\)): 이 영역의 사람들은 모두 처치를 받았습니다 (\\(X_i=1\\)). 따라서 관측된 결과 \\(Y_i\\)는 \\(Y_i(1)\\)입니다. \\[\n\\lim_{z \\downarrow c} \\mathbb{E}[Y_i | Z_i=z] = \\lim_{z \\downarrow c} \\mathbb{E}[Y_i(1) | Z_i=z] = \\mathbb{E}[Y_i(1) | Z_i=c]\n\\] (연속성 가정에 의해)\n임계값 바로 왼쪽 (\\(z \\uparrow c\\)): 이 영역의 사람들은 처치를 받지 않았습니다 (\\(X_i=0\\)). 관측된 결과 \\(Y_i\\)는 \\(Y_i(0)\\)입니다. \\[\n\\lim_{z \\uparrow c} \\mathbb{E}[Y_i | Z_i=z] = \\lim_{z \\uparrow c} \\mathbb{E}[Y_i(0) | Z_i=z] = \\mathbb{E}[Y_i(0) | Z_i=c]\n\\]\n최종 식별 식: \\[\n\\tau_{SRD} = \\underbrace{\\lim_{z \\downarrow c} \\mathbb{E}[Y_i | Z_i=z]}_{\\mu_+(c)} - \\underbrace{\\lim_{z \\uparrow c} \\mathbb{E}[Y_i | Z_i=z]}_{\\mu_-(c)}\n\\]\n\n결론적으로 RDD의 인과 효과는 임계값 \\(c\\)에서 우측 극한값과 좌측 극한값의 차이로 정의됩니다.\n\n\n\n\n4. Graphical Diagnostics (Validation)\n[cite_start]RDD 분석을 수행할 때, 모델링 이전에 반드시 확인해야 할 세 가지 시각적 진단 단계가 있습니다. [cite: 392]\n\n1. Outcomes by Running Variable\n실제로 결과 변수 \\(Y\\)가 임계값 \\(c\\)에서 불연속적으로 점프하는지 확인합니다. 점프가 없다면 처치 효과가 없다는 강력한 증거가 될 수 있습니다.\n\n\n2. Covariate Balance Check\n결과 변수 \\(Y\\) 이외의 다른 공변량(Covariates, \\(W\\))들이 임계값에서 점프를 보이는지 확인해야 합니다. * [cite_start]원칙: 공변량들은 임계값에서 부드럽게(Smooth) 이어져야 합니다. [cite: 414] * 만약 공변량이 점프한다면, \\(Y\\)의 점프가 처치 때문인지, 아니면 공변량의 차이 때문인지 구분할 수 없게 됩니다.\n\n\n3. Density of Running Variable (McCrary Test)\nForcing Variable \\(Z\\)의 밀도 함수(Density)가 임계값에서 연속인지 확인합니다. * [cite_start]Sorting / Bunching: 만약 사람들이 임계값을 알고 의도적으로 자신의 점수나 소득을 조작하여 처치 대상이 되려 한다면(예: 장학금을 받기 위해 재시험을 쳐서 점수를 턱걸이로 맞춤), \\(c\\) 근처의 밀도가 비정상적으로 솟아오르는 Bunching 현상이 발생합니다. [cite: 420] * [cite_start]이 경우 무작위 배정 가정이 깨지므로 RDD를 사용할 수 없습니다. [cite: 398]\n\n\n\nFigure 3: McCrary Test 예시. 왼쪽 그림은 밀도가 연속적이므로 조작의 증거가 없지만, 오른쪽 그림은 임계값 직후 밀도가 급증하여 Sorting(조작)을 의심해야 한다.\n\n\n\n\n\n\n5. Estimation Methods\n이론적으로는 극한값을 구해야 하지만, 실제 데이터는 이산적이므로 \\(c\\) 근처의 데이터를 어떻게 활용할지가 관건입니다.\n\nMethod 1: Local Averages (Kernel Regression)\n가장 단순한 방법은 임계값 \\(c\\)를 중심으로 폭(Bandwidth) \\(h\\)만큼의 구간 \\([c-h, c+h]\\) 데이터를 사용하여 평균을 비교하는 것입니다. [cite_start]이때 데이터 포인트에 가중치를 주는 커널(Kernel)을 사용할 수 있습니다. [cite: 431]\n\nUniform Kernel: 구간 내 모든 데이터에 동일한 가중치 (단순 평균 차이).\nTriangular Kernel: \\(c\\)에 가까울수록 더 높은 가중치 부여. [cite_start]경계점(Boundary) 추정에 유리하여 많이 사용됩니다. [cite: 447]\n\n\\[\n\\min_{\\alpha, \\tau} \\sum_{i=1}^N K\\left(\\frac{Z_i - c}{h}\\right) (Y_i - \\alpha - \\tau X_i)^2\n\\]\n\n\nMethod 2: Local Linear Regression (LLR)\n단순 평균(Kernel Regression)은 경계점(Boundary) 편향(Bias) 문제가 있습니다. 데이터가 한쪽에만 존재하기 때문입니다. [cite_start]이를 해결하기 위해 국소 선형 회귀(Local Linear Regression)를 사용하는 것이 표준입니다. [cite: 434]\n아이디어는 \\(c\\)의 왼쪽과 오른쪽에서 각각 선형 회귀선을 적합하여 \\(c\\) 지점의 절편 차이를 구하는 것입니다.\n\\[\n\\hat{\\tau}_{SRD} = \\hat{\\mu}_+(c) - \\hat{\\mu}_-(c)\n\\] 여기서 \\(\\hat{\\mu}_+(c)\\)와 \\(\\hat{\\mu}_-(c)\\)는 각각 우측 및 좌측 데이터로 추정한 회귀식의 \\(c\\) 지점 예측값입니다.\n\n\nMethod 3: Practical Implementation\n[cite_start]실제 분석에서는 이 두 과정을 하나의 회귀식으로 통합하여 추정하는 것이 편리합니다. [cite: 446]\n\\[\n\\min_{\\alpha, \\beta, \\tau, \\gamma} \\sum_{i \\in [c-h, c+h]} \\left( Y_i - \\alpha - \\beta(Z_i - c) - \\tau X_i - \\gamma(Z_i - c)X_i \\right)^2\n\\]\n이 식의 구성 요소를 뜯어보면: * \\(\\alpha\\): 임계값 좌측의 절편 (대조군의 \\(c\\) 지점 기댓값) * \\(\\beta(Z_i - c)\\): 임계값 좌측의 기울기 (Running variable의 영향 통제) * \\(\\tau\\): 처치 효과 (우리가 구하고자 하는 값, 절편의 점프 크기) * \\(\\gamma(Z_i - c)X_i\\): 임계값 우측에서의 기울기 변화 허용 (좌우 기울기가 다를 수 있음을 반영)\n[cite_start]여기에 커널 가중치 \\(K(\\cdot)\\)를 곱해주면 Local Linear Kernel Regression이 됩니다. [cite: 449]\n\n\nBandwidth Selection (\\(h\\))\n[cite_start]Bandwidth \\(h\\)의 선택은 Bias-Variance Trade-off 문제입니다. [cite: 451] * \\(h\\)가 크면: 데이터가 많아져 분산(Variance)은 줄지만, \\(c\\)에서 먼 데이터가 섞여 편향(Bias)이 커집니다. * \\(h\\)가 작으면: \\(c\\)에 아주 가까운 데이터만 써서 편향은 작지만, 데이터 수가 적어 분산이 커집니다.\n일반적으로 MSE(Mean Squared Error)를 최소화하는 최적의 \\(h\\)를 찾는 알고리즘을 사용합니다.\n\n\n\n\n6. Extensions: Kink RD\n만약 처치 자체가 불연속적으로 변하지 않더라도, 처치의 강도를 결정하는 함수의 기울기(Slope)가 불연속적으로 변한다면 어떨까요? [cite_start]이를 Regression Kink Design (RKD)라고 합니다. [cite: 453]\n\nSharp Kink RD: 함수 \\(E[Y|Z=z]\\)의 1계 도함수(기울기)에서의 불연속성을 이용해 식별합니다.\n정책이 특정 소득 구간부터 세율을 급격히 올리거나 혜택 감소율을 바꿀 때 적용할 수 있습니다.\n\n\n\n\n7. Summary\n\nRDD는 Forcing Variable의 임계값을 이용해 국소적으로 무작위 실험과 유사한 환경을 조성합니다.\n핵심 가정은 결과 변수의 잠재적 분포가 임계값 근처에서 연속적이어야 한다는 것과, 개체들이 임계값을 기준으로 정밀하게 Sorting하지 않아야 한다는 것입니다.\nMcCrary Density Test와 Covariate Balance Check는 필수적인 진단 과정입니다.\n추정 시에는 단순 평균보다는 Local Linear Regression을 Triangular Kernel과 함께 사용하는 것이 경계점 편향을 줄이는 데 효과적입니다.\n\n\n\n강의자료 검증 체크리스트\n\n포함된 내용:\n\nRDD의 정의 및 직관 (Slide 4-5)\n주요 예시 (장학금, 재정지원) (Slide 6-7)\nSharp vs. Fuzzy RD 구분 (Slide 8-9)\n식별 전략 및 연속성 가정 (Slide 10-13)\n그래프 분석 (Outcome, Covariate, Density) (Slide 14-16)\nBunching/Sorting 개념 (Slide 19-20)\n커널 회귀 및 Local Linear Regression 수식 (Slide 22-25)\n실전 추정 식 (상호작용항 포함) (Slide 30-31)\nBandwidth 선택의 Trade-off (Slide 32)\nKink RD 개념 (Slide 33)\n\n생략된 내용:\n\n강의 슬라이드에 포함된 구체적인 참고문헌 리스트나 강사 정보 등 메타 데이터는 블로그 포스트의 성격에 맞게 서두나 인용으로 갈무리했습니다.\nFuzzy RD의 구체적인 IV(도구변수) 추정 방식은 이번 자료가 Sharp RD 위주로 서술되어 있어, 개념적 정의 위주로 다루었습니다.\n\n\n이 포스트가 RDD를 처음 접하거나 다시 정리하려는 분들에게 도움이 되기를 바랍니다."
  },
  {
    "objectID": "posts/lecture/L09/part-03/index.html",
    "href": "posts/lecture/L09/part-03/index.html",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 3)",
    "section": "",
    "text": "이전 포스트에서는 선형 회귀분석이 인과적 편향(Bias)을 가질 수 있음을 확인하고, Single-Door 및 Back-Door Criterion과 같은 그래픽 기반의 식별 전략을 다루었습니다. 이번 포스트에서는 조금 더 근본적인 질문을 던져봅니다.\n\n“우리가 관측한 데이터(공분산 행렬)만으로, 미지의 인과 파라미터(\\(\\lambda\\))를 수학적으로 유일하게 풀어낼 수 있는가?”\n\n이것이 바로 선형 식별(Linear Identification) 문제의 핵심입니다. 그래프 구조가 주어졌을 때, 우리는 연립방정식을 세우고 이를 풀어냄으로써 인과 효과를 계산할 수 있습니다. 하지만 항상 유일한 해가 존재하는 것은 아닙니다. 때로는 해가 무수히 많을 수도(식별 불가), 유한한 개수로 존재할 수도(유한 식별) 있습니다.\n이 과정을 대수적으로 살펴보고, 식별이 불가능한 상황을 타개하기 위한 강력한 무기인 도구 변수(Instrumental Variables, IV)에 대해 알아봅니다."
  },
  {
    "objectID": "posts/lecture/L09/part-03/index.html#the-setup",
    "href": "posts/lecture/L09/part-03/index.html#the-setup",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 3)",
    "section": "2.1 The Setup",
    "text": "2.1 The Setup\n우리가 가진 정보(Knowns)와 알고 싶은 정보(Unknowns)는 다음과 같습니다.\n\nKnowns (Data): 관측 변수들의 공분산 행렬 \\(\\Sigma\\) (예: \\(\\sigma_{xx}, \\sigma_{xy}, \\sigma_{zx} \\dots\\))\nUnknowns (Parameters): 구조적 계수 \\(\\lambda\\) (인과 효과) 및 오차항의 공분산 \\(\\epsilon\\) (confounding strength)\n\n이들의 관계는 다음과 같은 행렬 방정식으로 표현됩니다.\n\\[\n\\Sigma = (I - \\Lambda)^{-T} \\Omega (I - \\Lambda)^{-1}\n\\]\n여기서 \\(\\Lambda\\)는 인과 계수 행렬, \\(\\Omega\\)는 오차항의 공분산 행렬입니다. 우리의 목표는 \\(\\Sigma\\)가 주어졌을 때 \\(\\Lambda\\)를 역산해내는 것입니다."
  },
  {
    "objectID": "posts/lecture/L09/part-03/index.html#solving-for-lambda-a-simple-example",
    "href": "posts/lecture/L09/part-03/index.html#solving-for-lambda-a-simple-example",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 3)",
    "section": "2.2 Solving for \\(\\lambda\\): A Simple Example",
    "text": "2.2 Solving for \\(\\lambda\\): A Simple Example\n다음과 같은 그래프를 생각해봅시다.\n\n\n\nFigure 1: Z가 X의 원인이고, X가 Y의 원인인 간단한 체인 구조. Z와 Y 사이에는 점선(Confounding)이 존재한다.\n\n\n\nModel:\n\n\\(X = \\lambda_{zx} Z + e_x\\)\n\\(Y = \\lambda_{xy} X + e_y\\)\n(단, \\(Z\\)와 \\(Y\\) 사이에는 교란 요인 \\(\\epsilon_{zy}\\)가 존재)\n\n\n이 구조에서 관측 가능한 공분산(\\(\\sigma\\))을 구조적 파라미터(\\(\\lambda, \\epsilon\\))로 표현하면 다음과 같은 방정식들을 얻을 수 있습니다.\n\n\\(\\sigma_{xz} = \\lambda_{zx}\\) (Z는 외생 변수이므로)\n\\(\\sigma_{xy} = \\lambda_{xy} + \\lambda_{zx}\\epsilon_{zy}\\) (Path rule 적용)\n\\(\\sigma_{zy} = \\lambda_{zx}\\lambda_{xy} + \\epsilon_{zy}\\)\n\n이제 우리는 3개의 식과 3개의 미지수(\\(\\lambda_{zx}, \\lambda_{xy}, \\epsilon_{zy}\\))를 가집니다. 이를 가우스 소거법(Gaussian Elimination) 등을 통해 풀어보면:\n\n첫 번째 식에서 \\(\\lambda_{zx}\\)는 바로 구해집니다: \\(\\lambda_{zx} = \\sigma_{xz}\\).\n남은 두 식은 \\(\\lambda_{xy}\\)와 \\(\\epsilon_{zy}\\)에 대한 선형 연립방정식이 됩니다. \\[\n\\begin{cases}\n\\lambda_{xy} + \\sigma_{xz}\\epsilon_{zy} = \\sigma_{xy} \\\\\n\\sigma_{xz}\\lambda_{xy} + \\epsilon_{zy} = \\sigma_{zy}\n\\end{cases}\n\\]\n\n이 시스템은 선형 독립이므로(Full-rank), 유일한 해를 구할 수 있습니다. 즉, \\(\\lambda_{xy}\\)는 식별 가능(Identifiable)합니다."
  },
  {
    "objectID": "posts/lecture/L09/part-03/index.html#not-identifiable-식별-불가능",
    "href": "posts/lecture/L09/part-03/index.html#not-identifiable-식별-불가능",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 3)",
    "section": "3.1 Not Identifiable (식별 불가능)",
    "text": "3.1 Not Identifiable (식별 불가능)\n미지수의 개수가 방정식의 개수보다 많거나, 방정식들이 서로 의존적일 때 발생합니다.\n\n\n\nFigure 2: X와 Y 사이의 직접적인 인과 관계와 교란 관계(점선)가 동시에 존재하는 그래프. 식별 불가능의 대표적 사례이다.\n\n\n\n구조: \\(X \\to Y\\) (\\(\\lambda_{xy}\\)) 그리고 \\(X \\leftrightarrow Y\\) (\\(\\epsilon_{xy}\\))\n방정식: \\(\\sigma_{xy} = \\lambda_{xy} + \\epsilon_{xy}\\)\n분석: 식은 1개인데 미지수는 2개(\\(\\lambda_{xy}, \\epsilon_{xy}\\))입니다.\n결과: \\(\\lambda_{xy}\\)와 \\(\\epsilon_{xy}\\)의 조합은 무수히 많으므로, 데이터를 아무리 많이 모아도 진짜 인과 효과를 하나로 특정할 수 없습니다."
  },
  {
    "objectID": "posts/lecture/L09/part-03/index.html#finite-identifiability-유한-식별-가능",
    "href": "posts/lecture/L09/part-03/index.html#finite-identifiability-유한-식별-가능",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 3)",
    "section": "3.2 Finite Identifiability (유한 식별 가능)",
    "text": "3.2 Finite Identifiability (유한 식별 가능)\n해가 유일하지는 않지만, 유한한 개수의 후보군으로 좁혀지는 흥미로운 경우입니다. 비선형 연립방정식이 등장할 때 주로 발생합니다.\n\n\n\nFigure 3: Bow-tie 형태의 복잡한 그래프 구조. X, Y, Z, W가 서로 복잡하게 얽혀 있어 유한 식별성을 가진다.\n\n\n강의 자료에 소개된 ‘Bow-tie’ 그래프 예시에서는 방정식들을 정리하면 \\(\\lambda_{xy}\\)에 대한 2차 방정식(Quadratic Equation)이 유도됩니다.\n\\[\nA \\lambda_{xy}^2 + B \\lambda_{xy} + C = 0\n\\]\n여기서 계수 \\(A, B, C\\)는 관측된 공분산들(\\(\\sigma\\))로 이루어진 복잡한 식입니다. 근의 공식에 의해 \\(\\lambda_{xy}\\)는 최대 2개의 가능한 값을 가집니다. 즉, 데이터만으로는 두 값 중 어느 것이 진실인지 알 수 없지만, 후보를 2개로 좁힐 수는 있습니다. 이를 Finite Identifiability라고 합니다."
  },
  {
    "objectID": "posts/lecture/L09/part-03/index.html#unique-identifiability-유일-식별-가능",
    "href": "posts/lecture/L09/part-03/index.html#unique-identifiability-유일-식별-가능",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 3)",
    "section": "3.3 Unique Identifiability (유일 식별 가능)",
    "text": "3.3 Unique Identifiability (유일 식별 가능)\n가장 이상적인 경우로, 해가 오직 하나만 존재합니다. 앞서 살펴본 2.2절의 예시나, 아래에서 다룰 도구 변수(IV)를 이용한 경우가 이에 해당합니다."
  },
  {
    "objectID": "posts/lecture/L09/part-03/index.html#concept-definition",
    "href": "posts/lecture/L09/part-03/index.html#concept-definition",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 3)",
    "section": "4.1 Concept & Definition",
    "text": "4.1 Concept & Definition\n의사의 처방(\\(Z\\))이 환자의 약물 복용량(\\(X\\))에 영향을 주고, 약물 복용량이 치료 결과(\\(Y\\))에 영향을 주는 상황을 가정해봅시다. 이때 약물 복용과 결과 사이에는 관측되지 않은 교란 요인(환자의 건강 상태 등)이 존재합니다.\n\n\n\nFigure 4: 도구 변수의 기본 구조. Z는 X에 영향을 주지만, Y에는 오직 X를 통해서만 영향을 미친다(Z -&gt; X -&gt; Y). X와 Y 사이에는 교란(점선)이 있지만, Z와 Y 사이에는 없다.\n\n\n변수 \\(Z\\)가 \\(X \\to Y\\)의 인과 효과 \\(\\lambda_{xy}\\)를 식별하기 위한 도구 변수(IV)가 되기 위한 조건은 다음과 같습니다:\n\nRelevance: \\(Z\\)는 \\(X\\)와 관련이 있어야 한다. (Graph 상에서 \\(Z\\)와 \\(X\\)가 d-separated 되지 않음)\nExclusion Restriction: \\(Z\\)는 \\(Y\\)에 직접적인 영향을 주지 않아야 하며, 오직 \\(X\\)를 통해서만 영향을 주어야 한다.\nUnconfoundedness: \\(Z\\)는 \\(Y\\)와 공유하는 교란 요인이 없어야 한다. (Graph 상에서 \\(Z\\)와 \\(Y\\)가 \\(G_{\\lambda_{xy}}\\)에서 d-separated 됨)"
  },
  {
    "objectID": "posts/lecture/L09/part-03/index.html#mathematical-derivation",
    "href": "posts/lecture/L09/part-03/index.html#mathematical-derivation",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 3)",
    "section": "4.2 Mathematical Derivation",
    "text": "4.2 Mathematical Derivation\n위 그래프 구조에서 방정식을 세워봅시다.\n\n\\(\\sigma_{zx} = \\lambda_{zx}\\) (Z는 외생변수)\n\\(\\sigma_{zy} = \\lambda_{zx} \\lambda_{xy}\\) (\\(Z \\to X \\to Y\\) 경로만 존재. \\(X \\leftrightarrow Y\\) 경로는 collider \\(X\\)에 의해 차단됨)\n\n이 두 식을 연립하면 놀랍도록 간단한 결과를 얻습니다.\n\\[\n\\lambda_{xy} = \\frac{\\sigma_{zy}}{\\lambda_{zx}} = \\frac{\\sigma_{zy}}{\\sigma_{zx}}\n\\]\n이것이 바로 유명한 IV Estimator입니다. 회귀 계수의 관점에서 보면 다음과 같이 표현됩니다.\n\\[\n\\lambda_{xy} = \\frac{r_{zy}}{r_{zx}}\n\\]\n즉, (\\(Y\\)와 \\(Z\\)의 상관관계)를 (\\(X\\)와 \\(Z\\)의 상관관계)로 나누어 줌으로써, \\(X\\)와 \\(Y\\) 사이의 교란 편향을 제거하고 순수한 인과 효과를 추출해냅니다."
  },
  {
    "objectID": "posts/lecture/L09/part-03/index.html#stage-least-squares-2sls-interpretation",
    "href": "posts/lecture/L09/part-03/index.html#stage-least-squares-2sls-interpretation",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 3)",
    "section": "4.3 2-Stage Least Squares (2SLS) Interpretation",
    "text": "4.3 2-Stage Least Squares (2SLS) Interpretation\n이 수식은 통계적으로 2단계 최소자승법(2SLS)으로 해석할 수 있습니다.\n\nStage 1: \\(X\\)를 \\(Z\\)로 회귀분석하여 예측값 \\(\\hat{X}\\)를 구합니다. \\[X = \\alpha Z + e \\implies \\hat{X} = \\sigma_{zx} Z\\] 이 과정은 \\(X\\)의 변동 중 교란 요인과 무관한, 순수하게 \\(Z\\)에 의해 설명되는 부분만을 발라내는 것입니다.\nStage 2: \\(Y\\)를 \\(\\hat{X}\\)에 대해 회귀분석합니다. \\[Y = \\beta \\hat{X} + u\\] 이때 구해지는 계수 \\(\\beta\\)가 바로 인과 효과 \\(\\lambda_{xy}\\)가 됩니다."
  },
  {
    "objectID": "posts/lecture/L09/part-03/index.html#definition",
    "href": "posts/lecture/L09/part-03/index.html#definition",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 3)",
    "section": "5.1 Definition",
    "text": "5.1 Definition\n변수 집합 \\(W\\)가 주어졌을 때, \\(Z\\)가 \\(\\lambda_{xy}\\)에 대한 Conditional IV가 되기 위한 조건:\n\n\\(W\\)는 \\(Y\\)의 자손(Descendant)을 포함하지 않는다.\n\\(W\\)를 조건부로 했을 때, \\(Z\\)와 \\(Y\\)는 \\(X \\to Y\\) 엣지를 제거한 그래프에서 d-separated 된다. (교란 경로 차단)\n\\(W\\)를 조건부로 했을 때, \\(Z\\)와 \\(X\\)는 d-separated 되지 않는다. (연관성 유지)"
  },
  {
    "objectID": "posts/lecture/L09/part-03/index.html#example-graph",
    "href": "posts/lecture/L09/part-03/index.html#example-graph",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 3)",
    "section": "5.2 Example Graph",
    "text": "5.2 Example Graph\n\n\n\nFigure 5: Conditional IV 예시 그래프. Z는 W를 통해 Y와 연결되는 뒷문 경로(Back-door path)를 가진다. W를 통제하면 이 경로가 차단되어 Z가 유효한 도구 변수가 된다.\n\n\n\n원래 \\(Z\\)는 \\(Z \\leftarrow W \\leftrightarrow Y\\) 등의 경로 때문에 \\(Y\\)와 상관성을 가져 IV가 될 수 없습니다.\n하지만 \\(W\\)를 회귀식에 포함하여 통제하면, \\(Z\\)와 \\(Y\\) 사이의 비인과적 경로가 차단됩니다.\n따라서 \\(W\\)를 포함한 상태에서 IV 분석을 수행하면 \\(\\lambda_{xy}\\)를 식별할 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L09/part-05/index.html",
    "href": "posts/lecture/L09/part-05/index.html",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 5)",
    "section": "",
    "text": "지난 포스트들에서 우리는 단일 도구 변수(IV)와 도구 변수 집합(Instrumental Sets)을 이용해 인과 효과를 식별하는 방법을 배웠습니다. 하지만 현실의 인과 그래프는 매우 복잡하여, 적절한 도구 변수 조건(특히 Exclusion Restriction이나 Unconfoundedness)을 만족하는 변수를 찾지 못할 때가 많습니다.\n이번 포스트에서는 “이미 식별된(Solved) 파라미터를 이용해 새로운 도구 변수를 창조하는 방법”, 즉 보조 변수법(The Method of Auxiliary Variables)에 대해 다룹니다. [cite_start]이는 마치 데이터에서 노이즈를 제거하여 순수한 신호만 남긴 뒤, 그 신호를 도구 변수로 사용하는 것과 같습니다[cite: 1981]."
  },
  {
    "objectID": "posts/lecture/L09/part-05/index.html#step-1-identify-lambda_zx",
    "href": "posts/lecture/L09/part-05/index.html#step-1-identify-lambda_zx",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 5)",
    "section": "3.1 Step 1: Identify \\(\\lambda_{zx}\\)",
    "text": "3.1 Step 1: Identify \\(\\lambda_{zx}\\)\n그래프를 보면 \\(Z\\)에서 \\(X\\)로 가는 관계에서 \\(Z\\)는 외생 변수(exogenous)입니다. [cite_start]따라서 \\(X\\)를 \\(Z\\)에 대해 회귀분석하면 \\(\\lambda_{zx}\\)를 편향 없이 구할 수 있습니다[cite: 2004].\n\\[\n\\lambda_{zx} = \\frac{Cov(Z, X)}{Var(Z)}\n\\]"
  },
  {
    "objectID": "posts/lecture/L09/part-05/index.html#step-2-create-the-auxiliary-variable-x",
    "href": "posts/lecture/L09/part-05/index.html#step-2-create-the-auxiliary-variable-x",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 5)",
    "section": "3.2 Step 2: Create the Auxiliary Variable \\(X^*\\)",
    "text": "3.2 Step 2: Create the Auxiliary Variable \\(X^*\\)\n이제 우리가 구한 \\(\\lambda_{zx}\\)를 이용하여 \\(X\\)에서 \\(Z\\)의 영향을 제거한 새로운 변수, 즉 잔차(Residual)에 해당하는 변수를 정의해봅시다. [cite_start]이를 Auxiliary Variable (AV)라고 부르고 \\(X^*\\)로 표기합니다[cite: 2022, 2038].\n\\[\nX^* \\equiv X - \\lambda_{zx} Z\n\\]\n이 식에 원래 \\(X\\)의 구조방정식(\\(X = \\lambda_{zx} Z + \\epsilon_x\\))을 대입해보면 흥미로운 사실을 알게 됩니다.\n\\[\nX^* = (\\lambda_{zx} Z + \\epsilon_x) - \\lambda_{zx} Z = \\epsilon_x\n\\]\n즉, \\(X^*\\)는 \\(X\\)의 변동 중 \\(Z\\)와 무관한, 순수한 외생적 오차항(\\(\\epsilon_x\\))과 같습니다."
  },
  {
    "objectID": "posts/lecture/L09/part-05/index.html#step-3-use-x-as-an-instrument",
    "href": "posts/lecture/L09/part-05/index.html#step-3-use-x-as-an-instrument",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 5)",
    "section": "3.3 Step 3: Use \\(X^*\\) as an Instrument",
    "text": "3.3 Step 3: Use \\(X^*\\) as an Instrument\n이제 새로 만든 변수 \\(X^*\\)를 그래프 상에서 생각해봅시다.\n\n\n\nFigure 2: 보조 변수 X의 생성 과정. X는 X의 오차항(epsilon_x)에 해당하며, Z나 Y의 교란 요인과 독립적이다.\n\n\n\nRelevance: \\(X^*\\)는 구성상 \\(X\\)의 일부분이므로 \\(X\\)와 당연히 연관되어 있습니다.\nUnconfoundedness: \\(X^*\\)는 사실상 \\(\\epsilon_x\\)입니다. 모형의 가정상 \\(\\epsilon_x\\)는 다른 변수의 오차항(\\(\\epsilon_{zy}, \\epsilon_y\\))과 독립적입니다.\n\n[cite_start]따라서 \\(X^*\\)는 \\(\\lambda_{xy}\\)를 식별하기 위한 완벽한 도구 변수(IV)가 됩니다! [cite: 2051]\n\nFinal Identification Formula\n[cite_start]\\(\\lambda_{xy}\\)는 \\(X^*\\)를 도구 변수로 사용하여 다음과 같이 계산됩니다[cite: 2052]:\n\\[\n\\lambda_{xy} = \\frac{Cov(X^*, Y)}{Cov(X^*, X)}\n\\]\n이 과정은 마치 2단계 최소자승법(2SLS)과 유사하지만, 예측값(\\(\\hat{X}\\))이 아닌 잔차(\\(X^*\\))를 도구 변수로 사용한다는 점에서 개념적 차이가 있습니다."
  },
  {
    "objectID": "posts/lecture/L09/part-05/index.html#the-complex-scenario",
    "href": "posts/lecture/L09/part-05/index.html#the-complex-scenario",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 5)",
    "section": "4.1 The Complex Scenario",
    "text": "4.1 The Complex Scenario\n아래와 같이 \\(W\\)라는 공통 원인이 존재하는 복잡한 구조를 봅시다.\n\n\n\nFigure 3: W가 Z1, Z2의 공통 원인이고, Z들이 X들에 얽혀 영향을 주는 복잡한 그래프. W 때문에 단순한 Instrumental Set 적용이 어렵다.\n\n\n\n목표: \\(\\lambda_{x_1 y}\\)를 식별하고 싶습니다.\n문제: \\(W\\)가 존재하여 \\(Z \\leftarrow W \\dashrightarrow Y\\)와 같은 뒷문 경로가 열려 있습니다. [cite_start]따라서 \\(\\{Z_1, Z_2\\}\\)를 바로 도구 변수 집합으로 쓸 수 없습니다[cite: 2074]."
  },
  {
    "objectID": "posts/lecture/L09/part-05/index.html#applying-the-av-method",
    "href": "posts/lecture/L09/part-05/index.html#applying-the-av-method",
    "title": "[Causal Inference] 09. Linear Structural Causal Models (Part 5)",
    "section": "4.2 Applying the AV Method",
    "text": "4.2 Applying the AV Method\n[cite_start]하지만 \\(W\\)에서 \\(Z\\)로 가는 계수 \\(\\lambda_{wz_1}, \\lambda_{wz_2}\\)가 식별 가능하다면(예: \\(W\\)가 관측 가능하거나 다른 방법으로 식별됨), 우리는 \\(W\\)의 영향을 제거한 보조 변수들을 만들 수 있습니다[cite: 2075, 2090].\n\\[\n\\begin{aligned}\nZ_1^* &= Z_1 - \\lambda_{wz_1} W \\\\\nZ_2^* &= Z_2 - \\lambda_{wz_2} W\n\\end{aligned}\n\\]\n[cite_start]이렇게 생성된 Auxiliary Variables Set \\(\\{Z_1^*, Z_2^*\\}\\)는 더 이상 \\(W\\)의 영향을 받지 않으며, \\(\\{X_1, X_2\\}\\)에 대한 유효한 Instrumental Set이 됩니다[cite: 2105].\n이제 우리는 지난 포스트에서 배운 Instrumental Set 공식을 적용하여 \\(\\lambda_{x_1 y}\\)와 \\(\\lambda_{x_2 y}\\)를 연립방정식으로 풀어낼 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L07/part-01/index.html",
    "href": "posts/lecture/L07/part-01/index.html",
    "title": "[Causal Inference] 07. An Algorithmic Approach to Identification (Part 1)",
    "section": "",
    "text": "인과 추론(Causal Inference)의 핵심 목표 중 하나는 관측 가능한 데이터(\\(P(v)\\))로부터 우리가 관심을 가지는 인과 효과(\\(P(y|do(x))\\))를 식별(Identification)해내는 것입니다. 간단한 구조에서는 Back-door criterion이나 Front-door criterion을 사용할 수 있지만, 변수 간의 관계가 복잡하고 관측되지 않은 교란 요인(Unobserved Confounder)이 존재하는 일반적인 SCM(Structural Causal Model) 환경에서는 보다 체계적이고 알고리즘적인 접근이 필요합니다.\n[cite_start]이번 포스트에서는 관측 분포를 인과 다이어그램(Causal Diagram)의 위상(Topology)에 따라 분해(Decomposition)하고, 이를 C-Factor(Confounded Factor) 라는 개념으로 일반화하여 인과 효과를 식별하는 과정을 다룹니다[cite: 209, 210].\n[cite_start]주요 로드맵은 다음과 같습니다[cite: 292, 293, 294, 295]: 1. SCM과 인과 다이어그램에 기반하여 확률 분포를 분해(Factorization)하는 방법을 정의합니다. 2. 분포의 특정 구성 요소(Factor)를 식별할 수 있는 연산(Operation)을 확립합니다. 3. 타겟 인과 효과를 이러한 Factor들의 조합으로 표현하여 식별 가능성을 판단합니다."
  },
  {
    "objectID": "posts/lecture/L07/part-01/index.html#markovian-case-no-unobserved-confounders",
    "href": "posts/lecture/L07/part-01/index.html#markovian-case-no-unobserved-confounders",
    "title": "[Causal Inference] 07. An Algorithmic Approach to Identification (Part 1)",
    "section": "2.1 Markovian Case (No Unobserved Confounders)",
    "text": "2.1 Markovian Case (No Unobserved Confounders)\n모든 변수가 관측 가능하고, 오차항(Error terms)들이 서로 독립인 Markovian 모델을 먼저 살펴봅시다. [cite_start]이 경우, 관측 변수 집합 \\(V\\)에 대한 결합 확률 분포 \\(P(v)\\)는 베이지안 네트워크의 분해 성질에 따라 각 변수의 부모 변수(\\(pa_i\\))에 대한 조건부 확률의 곱으로 표현됩니다[cite: 303, 304, 305].\n\\[\nP(v) = \\sum_{u} P(u) \\prod_{V_i \\in V} P(v_i | pa_i, u_i) = \\prod_{V_i \\in V} P(v_i | pa_i)\n\\]\n[cite_start]여기서 \\(P(v_i|pa_i)\\)는 \\(P(v)\\)로부터 직접 계산 가능하므로, 이를 Canonical Factor라고 부를 수 있습니다[cite: 316].\n 이 그림은 \\(X, Y, Z\\) 변수로 구성된 단순한 Markovian 모델을 보여줍니다. \\(U\\) 변수들이 서로 독립이므로, 전체 분포는 \\(P(z)P(x|z)P(y|x,z)\\)와 같이 각 노드의 조건부 확률곱으로 깔끔하게 분해됩니다."
  },
  {
    "objectID": "posts/lecture/L07/part-01/index.html#semi-markovian-case-with-unobserved-confounders",
    "href": "posts/lecture/L07/part-01/index.html#semi-markovian-case-with-unobserved-confounders",
    "title": "[Causal Inference] 07. An Algorithmic Approach to Identification (Part 1)",
    "section": "2.2 Semi-Markovian Case (With Unobserved Confounders)",
    "text": "2.2 Semi-Markovian Case (With Unobserved Confounders)\n현실에서는 관측되지 않은 교란 변수 \\(U\\)가 존재하여 변수들 간의 Markovian 성질을 깰 수 있습니다. 이를 Semi-Markovian 모델이라 합니다. [cite_start]예를 들어, \\(V_1 \\rightarrow V_2 \\rightarrow V_3 \\dots\\) 와 같은 구조에 관측되지 않은 \\(U_1\\)이 \\(V_1\\)과 \\(V_3\\)에 동시에 영향을 준다면, 분포의 분해는 더 복잡해집니다[cite: 336, 341].\n\\[\nP(v) = \\sum_{u} P(u) \\prod_{V_i \\in V} P(v_i | pa_i, u_i)\n\\]\n강의 자료의 예제(\\(V_1 \\dots V_5\\)와 \\(U_1, U_2, U_3\\)가 섞인 모델)를 보면, \\(U\\)에 대해 합(Summation)을 취하는 과정에서 서로 얽혀있는 항들이 생겨납니다. [cite_start]이로 인해 단순한 조건부 확률의 곱(\\(\\prod P(v_i|pa_i)\\)) 형태로 표현되지 않고, \\(U\\)를 공유하는 변수들의 묶음(Term) 들이 나타나게 됩니다[cite: 384].\n\\[\nP(v) = \\underbrace{\\left( \\sum_{u_3} P(v_2|v_1, u_3)P(v_4|v_3, u_3)P(u_3) \\right)}_{\\text{Factor 1}} \\cdot \\underbrace{\\left( \\sum_{u_1, u_2} P(u_1, u_2) \\dots \\right)}_{\\text{Factor 2}}\n\\]\n이러한 복잡한 묶음들을 체계적으로 다루기 위해 새로운 함수 \\(Q\\)를 도입합니다."
  },
  {
    "objectID": "posts/lecture/L07/part-01/index.html#definition-of-q-function",
    "href": "posts/lecture/L07/part-01/index.html#definition-of-q-function",
    "title": "[Causal Inference] 07. An Algorithmic Approach to Identification (Part 1)",
    "section": "3.1 Definition of Q-function",
    "text": "3.1 Definition of Q-function\n복잡한 합(Summation) 형태의 항들을 추상화하여 Q-Factor 또는 C-Factor라고 정의합니다. [cite_start]변수 집합 \\(C \\subseteq V\\)에 대하여 \\(Q[C]\\)는 다음과 같이 정의됩니다[cite: 220, 221, 396]:\n\\[\nQ[C](c, pa_c) = \\sum_{u(C)} P(u(C)) \\prod_{V_i \\in C} P(v_i | pa_i, u_i)\n\\]\n여기서 \\(U(C)\\)는 \\(C\\)에 속한 변수들의 부모인 오차항들의 집합(\\(\\bigcup_{V_i \\in C} U_i\\))을 의미합니다. [cite_start]이 정의를 사용하면, 앞서 복잡했던 \\(P(v)\\) 식을 C-Factor들의 곱으로 간결하게 다시 쓸 수 있습니다[cite: 397, 400].\n\\[\nP(v) = Q[\\{V_2, V_4\\}] \\cdot Q[\\{V_1, V_3, V_5\\}]\n\\]"
  },
  {
    "objectID": "posts/lecture/L07/part-01/index.html#interpretation-c-factors-as-causal-effects",
    "href": "posts/lecture/L07/part-01/index.html#interpretation-c-factors-as-causal-effects",
    "title": "[Causal Inference] 07. An Algorithmic Approach to Identification (Part 1)",
    "section": "3.2 Interpretation: C-Factors as Causal Effects",
    "text": "3.2 Interpretation: C-Factors as Causal Effects\nC-Factor \\(Q[C]\\)는 단순한 수식적 정의를 넘어 중요한 인과적 의미를 가집니다. [cite_start]\\(Q[C]\\)는 “\\(C\\)를 제외한 모든 변수(\\(V \\setminus C\\))에 개입(Intervention)했을 때, \\(C\\)가 가질 확률 분포” 로 해석될 수 있습니다[cite: 404, 407].\n\\[\nQ[C] = P(c \\mid do(v \\setminus c))\n\\]\n유도 과정: Truncated Product Formula에 의해 \\(P(c \\mid do(v \\setminus c))\\)는 \\(C\\)에 속하지 않는 변수들의 구조적 방정식(또는 조건부 확률)을 제거한 분포입니다. \\(C\\)의 부모가 아닌 \\(U\\)들은 모두 합쳐져서 사라지므로(Summed out), 결국 \\(C\\)에 영향을 주는 \\(U(C)\\)와 구조적 식들만 남아 \\(Q[C]\\)의 정의와 일치하게 됩니다."
  },
  {
    "objectID": "posts/lecture/L07/part-01/index.html#ancestral-reduction-marginalization",
    "href": "posts/lecture/L07/part-01/index.html#ancestral-reduction-marginalization",
    "title": "[Causal Inference] 07. An Algorithmic Approach to Identification (Part 1)",
    "section": "4.1 Ancestral Reduction (Marginalization)",
    "text": "4.1 Ancestral Reduction (Marginalization)\n특정 조건 하에서 C-Factor \\(Q[C]\\)로부터 일부 변수를 제거(Marginalization)하여 더 작은 집합의 \\(Q\\)를 얻을 수 있습니다.\n[cite_start]Lemma (Ancestral-Reduction)[cite: 422, 423]: 집합 \\(W \\subseteq C\\)가 \\(C\\) 내에서 유도된 서브그래프 \\(G[C]\\) 상에서 조상(Ancestral) 집합이라면(즉, \\(W\\)의 모든 조상이 \\(W\\)에 포함된다면), 다음이 성립합니다.\n\\[\nQ[W] = \\sum_{c \\setminus w} Q[C]\n\\]\n이 정리는 우리가 구하고자 하는 \\(Q\\) 팩터가 너무 클 때, 불필요한 변수를 합(Summation)으로 제거할 수 있는 조건을 제시합니다. [cite_start]예를 들어, \\(V_1 \\rightarrow V_2\\) 관계에서 \\(\\{V_1\\}\\)은 조상 집합이므로 \\(Q[\\{V_1\\}] = \\sum_{v_2} Q[\\{V_1, V_2\\}]\\)가 가능하지만, \\(\\{V_2\\}\\)만 남기는 것은 불가능할 수 있습니다[cite: 424]."
  },
  {
    "objectID": "posts/lecture/L07/part-01/index.html#c-component-factorization-tians-lemma",
    "href": "posts/lecture/L07/part-01/index.html#c-component-factorization-tians-lemma",
    "title": "[Causal Inference] 07. An Algorithmic Approach to Identification (Part 1)",
    "section": "4.2 C-Component Factorization (Tian’s Lemma)",
    "text": "4.2 C-Component Factorization (Tian’s Lemma)\n가장 강력한 도구는 그래프의 C-Component(Confounded Component) 구조를 이용해 \\(Q[C]\\)를 더 작은 단위로 쪼개는 것입니다.\n[cite_start]Definition (C-Component)[cite: 426, 427]: 두 변수 \\(V_i, V_j\\)가 관측되지 않은 공통 부모 \\(U\\)를 공유한다면(즉, \\(V_i \\leftrightarrow \\dots \\leftrightarrow V_j\\) 경로가 있다면), 두 변수는 같은 C-Component에 속합니다. [cite_start]이 관계는 반사, 대칭, 추이적(Reflexive, Symmetric, Transitive)이므로 변수 집합 \\(V\\)를 분할(Partition)합니다[cite: 431].\n[cite_start]Lemma (Tian [2002])[cite: 438, 439]: 어떤 변수 집합 \\(H \\subseteq V\\)에 대해, \\(G[H]\\)의 C-Component들이 \\(H_1, \\dots, H_k\\)라면, \\(Q[H]\\)는 다음과 같이 분해됩니다.\n\\[\nQ[H] = \\prod_{j=1}^{k} Q[H_j]\n\\]\n이 정리는 전체 분포 \\(P(v) = Q[V]\\)를 그래프상의 연결 요소(Connected Component via bidirected edges)별로 쪼갤 수 있음을 의미합니다.\n\nComputing Factors via Topological Order\n[cite_start]각 C-Component \\(Q[H_j]\\)를 실제로 계산하기 위해, \\(H\\)에 대한 위상 정렬(Topological Order) \\(V_{(1)} &lt; \\dots &lt; V_{(|H|)}\\)을 이용합니다[cite: 442, 443]. \\(H_{\\le i}\\)를 위상 정렬상 \\(V_{(i)}\\)까지의 변수 집합이라고 할 때,\n\\[\nQ[H_j] = \\prod_{V_{(i)} \\in H_j} \\frac{Q[H_{\\le i}]}{Q[H_{\\le i-1}]} = \\prod_{V_{(i)} \\in H_j} P(v_{(i)} \\mid v^{(i-1)})\n\\] (여기서 \\(v^{(i-1)}\\)는 위상 정렬 상 앞선 변수들)\n[cite_start]이 공식을 통해 복잡한 \\(Q\\) 팩터들을 관측 데이터 \\(P(v)\\)의 조건부 확률들의 곱 형태로 구체적으로 계산할 수 있습니다[cite: 268].\n C-Factorization의 개념도. 전체 집합 \\(V\\)에 대한 \\(Q[V]\\)에서 시작하여, 그래프의 C-Component 구조에 따라 더 작은 \\(Q\\) 팩터들(\\(Q[V_{123}], Q[V_{24}]\\) 등)로 쪼개지는 과정을 나타냅니다. 분해된 팩터들은 더 이상 분해되지 않을 때까지(Atomic) 계속됩니다."
  },
  {
    "objectID": "posts/lecture/L07/part-02/index.html",
    "href": "posts/lecture/L07/part-02/index.html",
    "title": "[Causal Inference] 07. An Algorithmic Approach to Identification (Part 2)",
    "section": "",
    "text": "지난 포스트에서는 인과 추론을 위한 알고리즘적 접근의 기초인 C-Factor(Confounded Factor) 와 Tian’s Factorization을 다루었습니다. 관측 분포 \\(P(v)\\)를 인과 그래프의 위상(Topology)에 따라 \\(Q[C]\\)라는 구성 요소들로 쪼개는 방법이었죠.\n이번 포스트에서는 이 강력한 도구를 사용하여 실제로 인과 효과를 식별(Identification)하는 과정을 살펴봅니다. 교과서적인 Back-door와 Front-door 기준이 C-Factor 관점에서 어떻게 유도되는지 확인하고, 직관적으로 해결하기 어려운 Napkin Model을 단계별로 풀어봅니다. 마지막으로, 모든 식별 가능한 인과 효과를 찾아낼 수 있는 일반화된 ID 알고리즘(General Identification Algorithm) 의 전체 프로세스를 정리합니다."
  },
  {
    "objectID": "posts/lecture/L07/part-02/index.html#the-back-door-criterion",
    "href": "posts/lecture/L07/part-02/index.html#the-back-door-criterion",
    "title": "[Causal Inference] 07. An Algorithmic Approach to Identification (Part 2)",
    "section": "2.1 The Back-door Criterion",
    "text": "2.1 The Back-door Criterion\n가장 기본적인 교란 구조를 살펴봅시다. \\(Z\\)가 \\(X\\)와 \\(Y\\)의 공통 원인인 경우입니다.\n\nGraph: \\(X \\leftarrow Z \\rightarrow Y\\) 그리고 \\(X \\rightarrow Y\\)\nQuery: \\(P(y|do(x))\\)\n\n이 그래프에서 모든 변수는 각자의 C-Component를 형성합니다(양방향 화살표가 없음). 따라서 결합 분포는 다음과 같이 분해됩니다.\n\\[\nP(x, y, z) = Q[X] \\cdot Q[Y] \\cdot Q[Z]\n\\]\n각 \\(Q\\) 팩터는 해당 변수의 조건부 확률(부모 변수가 주어졌을 때)과 같습니다. \\[\n\\begin{align}\nQ[Z] &= P(z) \\\\\nQ[X] &= P(x|z) \\\\\nQ[Y] &= P(y|x, z)\n\\end{align}\n\\]\n우리가 구하고자 하는 개입 분포 \\(P(y|do(x))\\)는, \\(X\\)로 들어오는 모든 화살표를 끊고 \\(X=x\\)로 고정한 모델에서의 분포입니다. C-Factor 관점에서는 \\(X\\)의 메커니즘인 \\(Q[X]\\)를 제거하고, 나머지 메커니즘 \\(Q[Y], Q[Z]\\)는 그대로 유지한 채 \\(Y\\)에 대해 합(Marginalization)을 구하는 것과 같습니다.\n\\[\n\\begin{align}\nP(y|do(x)) &= \\sum_{z} Q[Y](x, z) \\cdot Q[Z](z) \\\\\n&= \\sum_{z} P(y|x, z) P(z)\n\\end{align}\n\\]\n이 결과는 우리가 잘 아는 Back-door Adjustment Formula와 정확히 일치합니다.\n\n\n\nFigure: Back-door 그래프 구조와 분해. Z는 X와 Y의 교란 요인(Confounder)이며, 개입 시 X와 Z의 연결이 끊어짐을 보여준다."
  },
  {
    "objectID": "posts/lecture/L07/part-02/index.html#the-front-door-criterion",
    "href": "posts/lecture/L07/part-02/index.html#the-front-door-criterion",
    "title": "[Causal Inference] 07. An Algorithmic Approach to Identification (Part 2)",
    "section": "2.2 The Front-door Criterion",
    "text": "2.2 The Front-door Criterion\n다음은 \\(X\\)와 \\(Y\\) 사이에 관측되지 않은 교란 변수 \\(U\\)가 존재하지만(\\(X \\leftrightarrow Y\\)), 중간 매개 변수 \\(Z\\)가 존재하는 Front-door 구조입니다.\n\nGraph: \\(X \\rightarrow Z \\rightarrow Y\\), \\(X \\leftrightarrow Y\\) (via \\(U\\))\nQuery: \\(P(y|do(x))\\)\n\n이 그래프의 C-Component는 양방향 엣지로 연결된 \\(\\{X, Y\\}\\)와, 독립적인 \\(\\{Z\\}\\)로 나뉩니다. \\[\nP(x, y, z) = Q[\\{X, Y\\}] \\cdot Q[\\{Z\\}]\n\\]\n여기서 각 팩터를 관측 데이터로 식별해 봅시다. 1. \\(Q[\\{Z\\}]\\): \\(Z\\)의 부모는 \\(X\\)뿐이므로, \\(Q[\\{Z\\}] = P(z|x)\\). 2. \\(Q[\\{X, Y\\}]\\): 전체 분포를 \\(Q[\\{Z\\}]\\)로 나누면 얻을 수 있습니다. \\[Q[\\{X, Y\\}] = \\frac{P(x, y, z)}{P(z|x)} = P(y|x, z)P(x)\\]\n이제 \\(P(y|do(x))\\)를 구하기 위해 \\(X\\)에 개입합니다. 이는 그래프에서 \\(X\\)로 들어오는 엣지를 끊는 것인데, 이 모델에서 \\(X\\)의 부모는 \\(U\\)입니다. \\(do(x)\\) 연산은 \\(X\\)가 \\(U\\)의 영향을 받지 않게 하므로, \\(Q[\\{X, Y\\}]\\) 내에서 \\(X\\)의 확률 부분(\\(P(x)\\))을 제거하거나, \\(X\\)를 상수로 고정하고 \\(U\\)에 대해 적분하는 과정을 거칩니다.\n수식적으로 \\(P(y|do(x))\\)는 다음과 같이 유도됩니다 (Chain rule of do-calculus 활용 형태):\n\\[\nP(y|do(x)) = \\sum_{z} P(z|do(x)) P(y|do(x), z)\n\\]\n\\(X \\rightarrow Z\\)는 교란이 없으므로 \\(P(z|do(x)) = P(z|x)\\). \\(Z \\rightarrow Y\\)의 효과 \\(P(y|do(z))\\)는 \\(X\\)가 Back-door 역할을 하므로 \\(P(y|do(z)) = \\sum_{x'} P(y|x', z)P(x')\\). 이를 종합하면:\n\\[\nP(y|do(x)) = \\sum_{z} P(z|x) \\sum_{x'} P(y|x', z)P(x')\n\\]\n이것이 바로 Front-door Adjustment Formula입니다."
  },
  {
    "objectID": "posts/lecture/L06/part-01/index.html",
    "href": "posts/lecture/L06/part-01/index.html",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 1)",
    "section": "",
    "text": "인과추론(Causal Inference)의 핵심 목표 중 하나는 관측 데이터(Observational Data)로부터 개입(Intervention)의 효과를 추정하는 것입니다.\n이를 식별(Identification) 문제라고 합니다.\n우리는 변수 \\(X\\)가 \\(Y\\)에 미치는 인과적 효과를 \\(P(y|do(x))\\)로 표기합니다.\n하지만 현실 세계에서 우리는 \\(do(x)\\)(강제적 개입)가 적용된 데이터가 아니라, 자연스럽게 발생한 결합 확률 분포 \\(P(V)\\)만을 관측할 수 있습니다.\n이번 포스트에서는 Judea Pearl의 Causal Calculus 프레임워크를 기반으로, 구조적 인과 모델(Semi-Markovian Models) 하에서 \\(P(y|do(x))\\)를 계산하는 체계적인 접근법을 다룹니다.\n특히 다음 세 가지 대표적인 그래프 구조를 통해 식별 가능성(Identifiability)을 분석합니다.\n\n\nBack-door Graph: 식별 가능 (Identifiable)\n\n\nBow Graph: 식별 불가능 (Non-Identifiable)\n\n\nFront-door Graph: 식별 가능 (Identifiable)"
  },
  {
    "objectID": "posts/lecture/L06/part-01/index.html#structural-causal-model-scm",
    "href": "posts/lecture/L06/part-01/index.html#structural-causal-model-scm",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 1)",
    "section": "2.1. Structural Causal Model (SCM)",
    "text": "2.1. Structural Causal Model (SCM)\n\n변수 집합 \\(V\\)와 관측되지 않은 잠재 변수(Latent Variables) 집합 \\(U\\)가 있을 때, 구조적 인과 모델 \\(M\\)은 다음과 같은 함수들의 집합으로 정의됩니다.\n\n\\[\nv_i = f_i(pa_i, u_i), \\quad \\text{for each } V_i \\in V\n\\]\n\n여기서 \\(pa_i\\)는 \\(V_i\\)의 부모 변수(parents)를 의미합니다. 전체 결합 확률 분포 \\(P(v)\\)는 잠재 변수 \\(u\\)에 대한 합(또는 적분)을 통해 다음과 같이 표현됩니다.\n\n\\[\nP(v) = \\sum_{u} \\prod_{V_i \\in V} P(v_i | pa_i, u_i) P(u)\n\\]"
  },
  {
    "objectID": "posts/lecture/L06/part-01/index.html#interventions-and-truncated-factorization",
    "href": "posts/lecture/L06/part-01/index.html#interventions-and-truncated-factorization",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 1)",
    "section": "2.2. Interventions and Truncated Factorization",
    "text": "2.2. Interventions and Truncated Factorization\n\n변수 \\(X\\)에 특정 값 \\(x\\)를 강제로 할당하는 개입 \\(do(X=x)\\)가 발생하면, \\(X\\)를 결정하던 기존의 구조적 함수 \\(X \\leftarrow f_X(\\dots)\\)는 삭제되고 상수 \\(X=x\\)로 대체됩니다.\n이를 그래프 관점에서는 \\(X\\)로 들어오는 모든 화살표를 제거하는 것으로 해석할 수 있습니다.\n이때, 개입 후의 분포 \\(P(v'|do(x))\\)는 Truncated Factorization 공식에 의해 다음과 같이 주어집니다.\n\n\\[\nP(v'|do(x)) = \\sum_{u} \\prod_{V_i \\in V \\setminus X} P(v_i | pa_i, u_i) P(u)\n\\]\n\n즉, \\(X\\)와 관련된 확률 항만 제거되고 나머지 메커니즘은 불변(Invariant)한다는 가정입니다.\n관심 있는 결과 변수 집합 \\(Y\\)에 대한 효과는 \\(V\\)에서 \\(X\\)와 \\(Y\\)를 제외한 나머지 변수들에 대해 주변화(marginalization)하여 구할 수 있습니다.\n\n\\[\nP(y|do(x)) = \\sum_{v \\setminus (x \\cup y)} \\sum_{u} \\prod_{V_i \\in V \\setminus X} P(v_i | pa_i, u_i) P(u)\n\\]"
  },
  {
    "objectID": "posts/lecture/L06/part-01/index.html#model-setup",
    "href": "posts/lecture/L06/part-01/index.html#model-setup",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 1)",
    "section": "3.1. Model Setup",
    "text": "3.1. Model Setup\n이 모델의 SCM은 다음과 같습니다[cite: 28]. \\[\n\\mathcal{H} = \\begin{cases}\nZ \\leftarrow f_Z(u_z) \\\\\nX \\leftarrow f_X(z, u_x) \\\\\nY \\leftarrow f_Y(x, z, u_y)\n\\end{cases}\n\\]\n관측 분포 \\(P(v)\\)는 다음과 같이 분해됩니다[cite: 29]. \\[\nP(x, y, z) = \\sum_{u} P(z|u_z) P(x|z, u_x) P(y|x, z, u_y) P(u)\n\\]"
  },
  {
    "objectID": "posts/lecture/L06/part-01/index.html#derivation-of-intervention-distribution",
    "href": "posts/lecture/L06/part-01/index.html#derivation-of-intervention-distribution",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 1)",
    "section": "3.2. Derivation of Intervention Distribution",
    "text": "3.2. Derivation of Intervention Distribution\n개입 \\(do(X=x)\\)가 발생하면, \\(X\\)의 결정 식은 \\(X=x\\)로 고정되고 \\(X\\)로 향하는 \\(Z\\)의 영향력은 사라집니다. 우리는 \\(P(y|do(x))\\)를 구하고자 합니다[cite: 40].\n\\[\nP(y|do(x)) = \\sum_{u} P(z|u_z) P(y|x, z, u_y) P(u)\n\\]\n여기서 잠재 변수 \\(u\\)를 \\(u_z, u_x, u_y\\)로 나누어 합을 전개하면 다음과 같습니다[cite: 42].\n\nDecomposition: \\[\n= \\sum_{u_z} P(z|u_z)P(u_z) \\sum_{u_y} P(y|x,z,u_y)P(u_y) \\sum_{u_x} P(u_x)\n\\]\nSimplification: \\(\\sum_{u_x} P(u_x) = 1\\) 이므로 소거됩니다. 또한 \\(\\sum_{u_z} P(z|u_z)P(u_z) = P(z)\\) 입니다.\nResult: \\[\n= P(z) \\sum_{u_y} P(y|x,z,u_y) P(u_y)\n\\] 이때, \\(P(y|x,z) = \\sum_{u_y} P(y|x,z,u_y)P(u_y)\\) 이므로 최종적으로 다음과 같은 식을 얻습니다[cite: 45, 46].\n\n\\[\nP(y|do(x)) = \\sum_{z} P(y|x, z) P(z)\n\\]\n이것이 바로 유명한 Back-door Adjustment Formula입니다. \\(Z\\)를 통제(conditioning)하고 \\(Z\\)의 주변 확률로 가중 평균을 냄으로써 인과 효과를 식별할 수 있습니다[cite: 47]."
  },
  {
    "objectID": "posts/lecture/L06/part-01/index.html#model-setup-1",
    "href": "posts/lecture/L06/part-01/index.html#model-setup-1",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 1)",
    "section": "4.1. Model Setup",
    "text": "4.1. Model Setup\nBow Graph의 SCM은 다음과 같습니다[cite: 55]. 여기서 \\(u'\\)은 관측 불가능한 공통 원인입니다. \\[\n\\mathcal{H} = \\begin{cases}\nX \\leftarrow f_X(u', u_x) \\\\\nY \\leftarrow f_Y(x, u', u_y)\n\\end{cases}\n\\]"
  },
  {
    "objectID": "posts/lecture/L06/part-01/index.html#attempting-derivation",
    "href": "posts/lecture/L06/part-01/index.html#attempting-derivation",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 1)",
    "section": "4.2. Attempting Derivation",
    "text": "4.2. Attempting Derivation\n\\(do(X=x)\\)에 대한 Truncated Factorization을 적용해 봅시다[cite: 66].\n\\[\nP(y|do(x)) = \\sum_{u} P(y|x, u', u_y) P(u)\n\\]\n이 식을 전개하면 다음과 같습니다[cite: 68, 69].\n\\[\n\\begin{aligned}\nP(y|do(x)) &= \\sum_{u'} P(u') \\left( \\sum_{u_y} P(y|x, u', u_y) P(u_y) \\right) \\left( \\sum_{u_x} P(u_x) \\right) \\\\\n&= \\sum_{u'} P(y|x, u') P(u')\n\\end{aligned}\n\\]\n문제점: 위 식의 우변에 있는 \\(u'\\)은 관측되지 않는 잠재 변수입니다. 우리는 데이터에서 \\(P(u')\\)이나 \\(P(y|x, u')\\)를 추정할 수 없습니다. 따라서 이 경우 \\(P(y|do(x))\\)는 관측 데이터 \\(P(x,y)\\)만으로는 식별 불가능(Non-Identifiable)합니다."
  },
  {
    "objectID": "posts/lecture/L06/part-01/index.html#model-setup-2",
    "href": "posts/lecture/L06/part-01/index.html#model-setup-2",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 1)",
    "section": "5.1. Model Setup",
    "text": "5.1. Model Setup\nFront-door 모델의 구조는 다음과 같습니다[cite: 82]. \\[\n\\mathcal{M} = \\begin{cases}\nX \\leftarrow f_X(u_x, u') \\\\\nZ \\leftarrow f_Z(x, u_z) \\\\\nY \\leftarrow f_Y(z, u', u_y)\n\\end{cases}\n\\] 여기서 중요한 특징은 \\(Z\\)가 \\(u'\\)의 영향을 받지 않고 오직 \\(x\\)와 \\(u_z\\)에 의해서만 결정된다는 점입니다[cite: 82]."
  },
  {
    "objectID": "posts/lecture/L06/part-01/index.html#step-by-step-derivation",
    "href": "posts/lecture/L06/part-01/index.html#step-by-step-derivation",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 1)",
    "section": "5.2. Step-by-Step Derivation",
    "text": "5.2. Step-by-Step Derivation\n우리의 목표는 \\(P(y|do(x))\\)를 관측 가능한 확률들의 조합으로 표현하는 것입니다.\n\nStep 1: Truncated Factorization\n개입 후의 분포는 다음과 같습니다[cite: 91]. \\[\nP(y|do(x)) = \\sum_{u} P(x|u', u_x) P(z|x, u_z) P(y|z, u', u_y) P(u)\n\\] 하지만 개입 \\(do(X=x)\\) 하에서 \\(P(x|u', u_x)\\) 항은 삭제되거나 1이 되므로(intervention에 의해 고정됨), 식은 다음과 같이 정리됩니다[cite: 95].\n\\[\nP(y|do(x)) = \\sum_{u} P(z|x, u_z) P(y|z, u', u_y) P(u)\n\\]\n\n\nStep 2: Grouping Terms\n잠재 변수들을 그룹화하여 전개합니다[cite: 96]. \\[\n= \\left( \\sum_{u_z} P(z|x, u_z) P(u_z) \\right) \\left( \\sum_{u', u_y} P(y|z, u', u_y) P(u', u_y) \\right) \\left( \\sum_{u_x} P(u_x) \\right)\n\\] 마지막 항은 1이 되어 사라집니다. 첫 번째 항은 \\(P(z|x)\\)가 됩니다 (왜냐하면 \\(Z\\)는 \\(X\\) 외의 다른 교란 변수 \\(U'\\)의 영향을 받지 않기 때문입니다).\n\\[\n= P(z|x) \\sum_{u', u_y} P(y|z, u', u_y) P(u_y|u') P(u')\n\\]\n내부의 \\(u_y\\)에 대한 합을 계산하면 \\(P(y|z, u')\\)이 됩니다[cite: 97, 98]. \\[\nP(y|do(x)) = \\sum_{z} P(z|x) \\sum_{u'} P(y|z, u') P(u')\n\\] 아직 \\(u'\\)이 남아 있습니다. 이 식을 어떻게 관측 가능한 변수로 바꿀 수 있을까요?\n\n\nStep 3: Leveraging X’\n여기서 핵심 트릭은 \\(X\\)의 값을 \\(x'\\)로 관측했을 때의 정보를 이용하는 것입니다. \\(P(y|z, x')\\)를 생각해 봅시다. \\(X\\)가 \\(x'\\)일 때 \\(Z\\)와 \\(Y\\) 사이의 관계를 이용해 \\(u'\\) 항을 \\(x'\\)에 대한 식으로 변환할 수 있습니다. 유도 과정을 따라가면 다음과 같은 최종 식을 얻습니다 [cite: 130-134].\n\\[\n\\sum_{u'} P(y|z, u') P(u') = \\sum_{x'} P(y|z, x') P(x')\n\\] (상세 유도: \\(u'\\)은 \\(x'\\)와 독립적이지 않을 수 있지만, Back-door path를 차단하는 \\(z\\)와 \\(x\\)의 관계를 이용해 \\(P(u')\\) 성분을 \\(P(x')\\) 성분으로 대체하여 표현함)\n\n\nStep 4: Final Front-door Formula\n결과적으로 다음과 같은 식별 공식을 얻습니다[cite: 134].\n\\[\nP(y|do(x)) = \\sum_{z} P(z|x) \\sum_{x'} P(y|z, x') P(x')\n\\]\n이 공식은 관측되지 않은 교란 변수 \\(U'\\)이 존재하더라도, \\(X \\to Z \\to Y\\) 경로를 통해 인과 효과를 두 단계로 나누어(\\(X \\to Z\\) 그리고 \\(Z \\to Y\\)) 추정함으로써 전체 효과를 계산할 수 있음을 보여줍니다."
  },
  {
    "objectID": "posts/lecture/L06/part-04/index.html",
    "href": "posts/lecture/L06/part-04/index.html",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 4)",
    "section": "",
    "text": "통계학을 공부하다 보면 직관과 데이터가 충돌하는 순간을 마주하게 됩니다. 가장 대표적인 예가 바로 심슨의 역설(Simpson’s Paradox)입니다. 이는 부분 집합에서 나타나는 경향성이 데이터를 전체로 합쳤을 때 반전되는 현상을 말합니다.\n[cite_start]초기 통계학자인 Karl Pearson은 이를 두고 “이질적인 그룹들이 섞여 있을 때 발생하는 가짜 상관관계(spurious correlation)”라고 표현하며 충격을 받았습니다[cite: 728, 731]. 하지만 Judea Pearl은 이 역설이 단순한 통계적 오류가 아니라, 인과적 구조(Causal Structure)를 무시한 채 데이터만 해석하려 할 때 발생하는 문제라고 주장합니다.\n이번 포스트에서는 심슨의 역설을 do-operator를 통해 수학적으로 해결(dissolve)하고, 인과추론이 왜 데이터 과학의 필수적인 도구인지 확인해 보겠습니다."
  },
  {
    "objectID": "posts/lecture/L06/part-04/index.html#the-data-statistical-reversal",
    "href": "posts/lecture/L06/part-04/index.html#the-data-statistical-reversal",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 4)",
    "section": "2.1. The Data: Statistical Reversal",
    "text": "2.1. The Data: Statistical Reversal\n[cite_start]다음은 전체 환자(Total)와 성별(Male/Female, \\(F\\))로 나누어 본 회복률 데이터입니다[cite: 742, 746, 747].\n\n\n\nGroup\nTreatment (\\(X\\))\nRecovery (\\(Y=1\\))\nRate (\\(P(Y|X)\\))\n\n\n\n\nTotal\nDrug\n20 / 40\n50%\n\n\n\nNo Drug\n16 / 40\n40%\n\n\nMale (\\(\\neg F\\))\nDrug\n18 / 30\n60%\n\n\n\nNo Drug\n7 / 10\n70%\n\n\nFemale (\\(F\\))\nDrug\n2 / 10\n20%\n\n\n\nNo Drug\n9 / 30\n30%\n\n\n\n여기서 충격적인 모순이 발생합니다. * 전체 데이터: 약물을 복용한 집단의 회복률(50%)이 복용하지 않은 집단(40%)보다 높습니다. (\\(P(Y|X) &gt; P(Y|\\neg X)\\)) * 부분 데이터: 남성과 여성 그룹 각각을 보면, 약물을 복용하지 않은 쪽의 회복률이 더 높습니다. * 남성: \\(P(Y|\\neg F, X) &lt; P(Y|\\neg F, \\neg X)\\) (60% vs 70%) * 여성: \\(P(Y|F, X) &lt; P(Y|F, \\neg X)\\) (20% vs 30%)\n우리는 약을 써야 할까요, 말아야 할까요? [cite_start]남성에게도 해롭고 여성에게도 해로운 약이, 어떻게 전체 인류에게는 유익할 수 있을까요? [cite: 743-745]"
  },
  {
    "objectID": "posts/lecture/L06/part-04/index.html#why-this-happens",
    "href": "posts/lecture/L06/part-04/index.html#why-this-happens",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 4)",
    "section": "2.2. Why This Happens",
    "text": "2.2. Why This Happens\n이 현상은 우리가 “본 것(Seeing)”과 “하는 것(Doing)”을 혼동하기 때문에 발생합니다. [cite_start]위 데이터에서 \\(X\\)와 \\(Y\\)는 단순한 사건(Events)으로 취급되었습니다[cite: 754]. 성별(\\(F\\))이 약물 복용 여부(\\(X\\))와 회복률(\\(Y\\)) 모두에 영향을 미치는 교란 변수(Confounder)로 작용하여, 약물 복용 집단의 분포를 왜곡시킨 것입니다. (예: 회복력이 좋은 남성들이 약물을 더 많이 복용함)"
  },
  {
    "objectID": "posts/lecture/L06/part-04/index.html#the-inequality-flip",
    "href": "posts/lecture/L06/part-04/index.html#the-inequality-flip",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 4)",
    "section": "3.1. The Inequality Flip",
    "text": "3.1. The Inequality Flip\nDo-notation을 사용하여 질문을 다시 쓰면 역설은 사라집니다. [cite_start]만약 각 하위 그룹(성별)에서 약물이 해롭다면, 전체 인구에 대해서도 약물 복용(\\(do(X)\\))이 약물 비복용(\\(do(\\neg X)\\))보다 해로워야 합니다[cite: 760, 768].\n\\[\n\\text{If } \\begin{cases} P(Y|F, do(X)) &lt; P(Y|F, do(\\neg X)) \\\\ P(Y|\\neg F, do(X)) &lt; P(Y|\\neg F, do(\\neg X)) \\end{cases}\n\\] \\[\n\\text{Then, it must hold that: } P(Y|do(X)) &lt; P(Y|do(\\neg X))\n\\]\n[cite_start]즉, 인과적 관점(\\(do\\)-calculus)에서는 “부분의 합이 전체와 모순되는” 반전(Reversal)이 발생하지 않습니다[cite: 789]."
  },
  {
    "objectID": "posts/lecture/L06/part-04/index.html#mathematical-proof",
    "href": "posts/lecture/L06/part-04/index.html#mathematical-proof",
    "title": "[Causal Inference] 06. The Causal Calculus (Part 4)",
    "section": "3.2. Mathematical Proof",
    "text": "3.2. Mathematical Proof\n이를 수학적으로 증명해 봅시다. 우리는 전체 인과 효과 \\(P(y|do(x))\\)를 계산하기 위해 성별 \\(F\\)를 조정(adjustment)해야 합니다.\n\n\n\nFigure 1: 심슨의 역설을 설명하는 인과 그래프. 성별(F)은 약물 복용(X)과 회복(Y) 모두에 영향을 미치는 교란 요인(Confounder)입니다. X에서 Y로 가는 인과 효과를 올바르게 추정하기 위해서는 F로 인한 Back-door path를 차단해야 합니다.\n\n\n[cite_start]Do-Calculus의 규칙과 전확률의 법칙(Law of Total Probability)을 사용하면 다음과 같이 유도됩니다[cite: 774].\n\\[\n\\begin{aligned}\nP(y|do(x)) &= \\sum_{f} P(y|do(x), f) P(f|do(x)) \\\\\n&= \\sum_{f} P(y|x, f) P(f)\n\\end{aligned}\n\\]\n유도 단계 설명: 1. Rule 2 (Action to Observation): \\(f\\)가 주어졌을 때 \\(x\\)와 \\(y\\) 사이의 Back-door path가 차단되므로, \\(P(y|do(x), f) = P(y|x, f)\\)가 됩니다. 즉, 성별이 같은 그룹 내에서는 관측된 효과가 곧 인과 효과입니다. 2. Rule 3 (Deleting Action): 성별(\\(F\\))은 약물 복용(\\(X\\))보다 먼저 결정되므로, 약물 복용에 개입한다고 해서 성별의 분포가 바뀌지 않습니다. 따라서 \\(P(f|do(x)) = P(f)\\)입니다.\n결론: 이 공식(\\(\\sum P(y|x, f)P(f)\\))은 각 그룹의 회복률(\\(P(y|x, f)\\))을, 약물 복용 여부에 편향되지 않은 전체 인구의 성비(\\(P(f)\\))로 가중 평균을 냅니다. 이렇게 하면 데이터의 불균형이 보정되어, 부분 그룹의 경향성(약물이 해롭다)이 전체 결과에도 그대로 반영됩니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-01/index.html",
    "href": "posts/lecture/L08/causal-inference-08-part-01/index.html",
    "title": "[Causal Inference] 08. Partial Identification (Part 1)",
    "section": "",
    "text": "이전까지 우리는 인과 효과 \\(P(y|do(x))\\)를 관측 데이터 \\(P(v)\\)로부터 정확한 하나의 값(Point estimate)으로 계산할 수 있는지, 즉 식별 가능성(Identifiability)을 따졌습니다.\n하지만 현실의 많은 문제에서는 그래프 구조상 식별이 불가능한 경우(Non-identifiable)가 많습니다.\n이때 우리는 포기하는 대신 “그렇다면 인과 효과가 존재할 수 있는 범위(Bound)라도 알 수 없을까?”라는 질문을 던지게 됩니다.\n이것이 바로 부분 식별(Partial Identification) 문제입니다.\n\n\n\n\nFigure 1: Identification Process Flowchart. 식별 엔진이 ’No’를 반환했을 때, 구간 [a, b]를 찾는 과정으로 넘어가는 흐름도.\n\n\n\nNote: 식별 불가능(No) 판정이 났을 때, 우리는 0과 1 사이의 어딘가에 존재하는 구간 \\([a(y;x), b(y;x)]\\)를 찾게 됩니다. *"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-01/index.html#문제-설정",
    "href": "posts/lecture/L08/causal-inference-08-part-01/index.html#문제-설정",
    "title": "[Causal Inference] 08. Partial Identification (Part 1)",
    "section": "3.1 문제 설정",
    "text": "3.1 문제 설정\n다음과 같이 \\(X\\)와 \\(Y\\) 사이에 비관측 교란 변수 \\(U\\)가 존재하는 가장 일반적인 그래프를 가정해 봅시다.\n\n\n\nFigure 2: Basic Confounded Graph. X와 Y가 U에 의해 교란된 구조.\n\n\n\n우리의 목표는 \\(P(x, y)\\)가 주어졌을 때, \\(P(y|do(x))\\)의 범위를 구하는 것입니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-01/index.html#theorem",
    "href": "posts/lecture/L08/causal-inference-08-part-01/index.html#theorem",
    "title": "[Causal Inference] 08. Partial Identification (Part 1)",
    "section": "3.2 Theorem",
    "text": "3.2 Theorem\n\n관측 분포 \\(P(x, y)\\)가 주어졌을 때, 인과 효과 \\(P(y|do(x))\\)는 다음 구간 안에 존재합니다.\n\n\\[\nP(y, x) \\le P(y|do(x)) \\le P(y, x) + 1 - P(x)\n\\]\n\n하한 (Lower Bound): \\(a(y;x) = P(y, x)\\)\n상한 (Upper Bound): \\(b(y;x) = P(y, x) + 1 - P(x)\\)\n\n직관적 해석\n\n이 수식은 데이터를 통해 “확실히 아는 것”과 “모르는 것”을 구분하는 것으로 이해할 수 있습니다.\n우리가 \\(do(x)\\)를 했을 때, 원래 자연스럽게 \\(X=x\\)를 선택했던 사람들은 관측 데이터 \\(P(y, x)\\)와 똑같이 행동할 것입니다. 이는 최소한 보장되는 비율입니다 (하한).\n반면, 원래 \\(X \\ne x\\)였던 사람들(처치를 받지 않은 비율 \\(P(x')\\))이 강제로 처치를 받았을 때 어떻게 행동할지는 데이터로 알 수 없습니다.\n상한의 논리: “처치 받지 않은 비율(\\(P(x')\\))에 속하는 사람들이 강제로 처치를 받았을 때, 모두가 \\(Y=y\\)로 변화한다(성공한다)”고 가장 긍정적으로 가정하면 최댓값이 됩니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-01/index.html#유도-과정-derivation",
    "href": "posts/lecture/L08/causal-inference-08-part-01/index.html#유도-과정-derivation",
    "title": "[Causal Inference] 08. Partial Identification (Part 1)",
    "section": "3.3 유도 과정 (Derivation)",
    "text": "3.3 유도 과정 (Derivation)\n\n왜 저런 범위가 나오는지 수식으로 살펴봅시다. 구조적 인과 모델(SCM)에서 \\(P(y|do(x))\\)는 다음과 같이 정의됩니다.\n\n\\[\nP(y|do(x)) = \\sum_u P(y|x, u)P(u)\n\\]\n\n확률의 성질을 이용하여 \\(P(u)\\)를 두 부분으로 나눌 수 있습니다: \\(P(u) = P(u, x) + \\{P(u) - P(u, x)\\}\\). 이를 식에 대입하면:\n\n\\[\n\\begin{aligned}\nP(y|do(x)) &= \\sum_u P(y|x, u) [P(u, x) + \\{P(u) - P(u, x)\\}] \\\\\n&= \\underbrace{\\sum_u P(y|x, u)P(u, x)}_{\\text{Part A}} + \\underbrace{\\sum_u P(y|x, u)\\{P(u) - P(u, x)\\}}_{\\text{Part B}}\n\\end{aligned}\n\\]\n\n여기서 Part A를 정리하면:\n\n\\[\n\\text{Part A} = \\sum_u P(y|x, u)P(x|u)P(u) = \\sum_u P(y, x, u) = P(y, x)\n\\]\n\n즉, Part A는 우리가 관측 가능한 데이터 \\(P(y, x)\\)와 같습니다. 이제 Part B 때문에 범위가 생깁니다.\n\n\n3.3.1 하한 (Lower Bound) 유도\n\n\\(P(y|x, u)\\)는 확률이므로 \\(0 \\le P(y|x, u) \\le 1\\).\n\\(P(u) = \\sum_x P(u, x)\\)이므로 \\(P(u) \\ge P(u, x)\\).\n\n\\[\n\\begin{aligned}\nP(y|do(x)) &= \\sum_u P(y|x, u)P(u, x) + \\sum_u P(y|x, u)\\{P(u) - P(u, x)\\} \\\\\n&= P(y,x) + \\sum_u P(y|x, u)\\{P(u) - P(u, x)\\} \\\\\n&\\ge P(y, x) + 0 = P(y, x) \\\\\n\\end{aligned}\n\\]\n\n\n3.3.2 상한 (Upper Bound) 유도\n\n\\(P(y|x, u)\\)는 확률이므로 \\(0 \\le P(y|x, u) \\le 1\\).\n\nPart B의 조건부 확률이 모두 1일 때 전체 값은 최대가 됩니다. \\[\n\\begin{aligned}\nP(y|do(x)) &= \\sum_u P(y|x, u)P(u, x) + \\sum_u P(y|x, u)\\{P(u) - P(u, x)\\} \\\\\n&= P(y,x) + \\sum_u P(y|x, u)\\{P(u) - P(u, x)\\} \\\\\n&\\le P(y, x) + \\sum_u \\{P(u) - P(u, x)\\} \\\\\n&= P(y, x) + 1 - P(x)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-01/index.html#범위의-타당성-증명-tightness",
    "href": "posts/lecture/L08/causal-inference-08-part-01/index.html#범위의-타당성-증명-tightness",
    "title": "[Causal Inference] 08. Partial Identification (Part 1)",
    "section": "3.4 범위의 타당성 증명 (Tightness)",
    "text": "3.4 범위의 타당성 증명 (Tightness)\n\n구한 범위 \\([P(y, x), P(y, x) + 1 - P(x)]\\)가 Tight하다는 것은, 추가적인 가정 없이는 이 범위를 더 좁힐 수 없음을 의미합니다.\n이를 증명하기 위해, 관측 데이터 \\(P(x, y)\\)와 완벽히 일치하면서(Compatible), 인과 효과가 각각 하한값과 상한값을 갖는 두 개의 가상 모델(\\(M^{(1)}, M^{(2)}\\))을 만들어낼 수 있음을 보이면 됩니다.\n\n\n3.4.1 모델 설계 전략\n\n두 모델 모두 \\(U \\sim P(u)\\)와 \\(X \\leftarrow f_X(u)\\)는 동일하게 두고, \\(Y\\)를 결정하는 함수 \\(f_Y(x, u)\\)만 다르게 설정합니다.\n\n\\[\nf_Y(x, u) =\n\\begin{cases}\nf_Y^{\\text{observation}}(x, u) & \\text{if } x = f_X(u) \\quad \\text{(관측된 경우)} \\\\\nf_Y^{\\text{counterfactual}}(x, u) & \\text{if } x \\ne f_X(u) \\quad \\text{(반사실적 경우)}\n\\end{cases}\n\\]\n\n\n3.4.2 Case 분류\n\n우리는 상황을 두 가지 케이스로 나눌 수 있습니다.\n\nCase 1 (Observation): \\(x = f_X(u)\\).\n\n즉, 개인이 원래 \\(x\\)를 선택하려던 경우입니다.\n이 경우 모델은 관측 데이터와 일치해야 하므로 선택의 여지가 없습니다.\n\nCase 2 (Counterfactual): \\(x \\ne f_X(u)\\).\n\n즉, 원래 다른 것을 하려던 사람에게 억지로 \\(x\\)를 시킬 때입니다.\n이 부분은 데이터로 관측되지 않으므로, 우리가 임의로 0(실패) 또는 1(성공)을 부여하여 범위를 만듭니다.\n\n\n\n\n\n3.4.3 두 모델의 구성\n\n모델 \\(\\mathcal{M}_x^{(1)}\\) (하한 모델):\n\nCase 2일 때 무조건 \\(Y=0\\)을 출력하게 설정합니다.\n인과 효과: \\(P^{(1)}(y=1|do(x)) = P(y=1, x) + 0 = \\text{Lower Bound}\\)\n\n모델 \\(\\mathcal{M}_x^{(2)}\\) (상한 모델):\n\nCase 2일 때 무조건 \\(Y=1\\)을 출력하게 설정합니다.\n인과 효과: \\(P^{(2)}(y=1|do(x)) = P(y=1, x) + 1- P(x) = \\text{Upper Bound}\\)\n\n\n\n두 모델 모두 관측 상황(Case 1)에서는 동일하게 작동하므로 \\(P(x, y)\\) 분포는 같습니다.\n하지만 \\(do(x)\\) 개입 시(Case 2), \\(U\\)와 \\(X\\)가 일치할 필요가 없으므로 \\(\\mathcal{M}_x^{(1)}\\)와 \\(\\mathcal{M}_x^{(2)}\\)가 \\(Y = 1\\) 일 때, 다른 확률을 가질 수 있습니다.\n\n\\[\n\\begin{aligned}\nP^{(i)}(Y = 1|do(x)) &= \\sum_{u} P^{(i)}(Y = 1|do(x), u)P(u|do(x)) \\\\\n&= \\sum_{u} P^{(i)}(Y = 1|x, u)P(u) && \\because \\text{Rule 2, Rule 3}\\\\\n&= P^{(i)}(Y = 1|x, f_X(U) = x)P(f_X(U) = x) \\\\\n&\\quad + P^{(i)}(Y = 1|x, f_X(U) \\neq x)P(f_X(U) \\neq x) \\\\\n&= P^{(i)}(Y = 1|x)P(x) + \\mathbf{1}[i = 2]\\{1 - P(x)\\} \\\\\n&= P^{(i)}(x, Y = 1) + \\mathbf{1}[i = 2](1 - P(x))\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\nP^{(1)}(Y = 1|do(x)) &= a(y;x) = P(y = 1, x) \\quad \\text{while} \\\\\nP^{(2)}(Y = 1|do(x)) &= b(y;x) = P(y = 1, x) + 1 - P(x)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-03/index.html",
    "href": "posts/lecture/L08/causal-inference-08-part-03/index.html",
    "title": "[Causal Inference] 08. Partial Identification (Part 3)",
    "section": "",
    "text": "지난 포스트들에서 우리는 Natural Bounds와 도구 변수(IV)를 활용한 식별 범위 추정에 대해 알아보았습니다.\n이번 포스트에서는 Partial Identification 시리즈의 마지막으로, Backdoor 기준을 만족하는 변수들이 부분적으로만 관측될 때(Partially-observed) 어떻게 인과 효과의 범위를 구할 수 있는지 살펴봅니다.\n이는 데이터가 서로 다른 소스에서 수집되어 결합 분포(Joint Distribution)를 완전히 알 수 없는 현실적인 상황(예: \\(X, Y\\) 데이터와 \\(U\\) 데이터가 따로 있을 때)에서 매우 유용한 접근법입니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-03/index.html#목표-식-재구성",
    "href": "posts/lecture/L08/causal-inference-08-part-03/index.html#목표-식-재구성",
    "title": "[Causal Inference] 08. Partial Identification (Part 3)",
    "section": "4.1 목표 식 재구성",
    "text": "4.1 목표 식 재구성\n\nBackdoor 공식을 조건부 확률 정의에 따라 풀어쓰면 다음과 같습니다.\n\n\\[\n\\begin{aligned}\nP(y|do(x)) &= \\sum_{w, u} P(y|x, w, u)P(w, u) \\\\\n&= \\sum_{w, u} \\frac{P(x, y, w, u)P(w, u)}{P(x, w, u)}\n\\end{aligned}\n\\]\n\n이 식의 구성 요소들을 각각 미지수로 정의하여 최적화 문제를 설계합니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-03/index.html#파라미터-정의",
    "href": "posts/lecture/L08/causal-inference-08-part-03/index.html#파라미터-정의",
    "title": "[Causal Inference] 08. Partial Identification (Part 3)",
    "section": "4.2 파라미터 정의",
    "text": "4.2 파라미터 정의\n\n각 \\((w, u)\\) 조합에 대해 다음 세 가지 변수를 정의합니다.\n\n\n\\(a_{w,u} = P(x, y, w, u)\\): 전체 결합 확률의 일부\n\n\n\\(b_{w,u} = P(w, u)\\): 교란 변수들의 결합 확률\n\n\n\\(c_{w,u} = P(x, w, u)\\): 처치와 교란 변수들의 결합 확률\n\n\n이제 우리의 목표 함수(Objective Function)는 다음과 같습니다.\n\n\\[\n\\text{min / max } \\sum_{w, u} \\frac{a_{w,u} \\cdot b_{w,u}}{c_{w,u}}\n\\]"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-03/index.html#제약-조건-constraints",
    "href": "posts/lecture/L08/causal-inference-08-part-03/index.html#제약-조건-constraints",
    "title": "[Causal Inference] 08. Partial Identification (Part 3)",
    "section": "4.3 제약 조건 (Constraints)",
    "text": "4.3 제약 조건 (Constraints)\n\n우리가 관측한 데이터(\\(P(X,Y,W)\\)와 \\(P(U)\\))는 이 미지수들의 합으로 표현되어야 합니다. 이것이 최적화 문제의 제약 조건이 됩니다.\n\n관측 데이터와의 일치:\n\n\n\\(\\sum_u a_{w,u} = P(x, y, w)\\)\n\\(\\sum_u b_{w,u} = P(w)\\)\n\\(\\sum_u c_{w,u} = P(x, w)\\)\n\n\n확률의 기본 성질 (Fréchet Inequalities):\n\n\n\\(P(w, u) = \\sum_x P(x, w, u) = \\sum_x \\sum_y P(x, y, w, u)\\)이므로 \\[b_{w, u} \\ge c_{w,u} \\ge a_{w, u}\\]\n결합 확률은 개별 확률보다 클 수 없고, 합집합 확률보다 작을 수 없다는 성질을 이용해 각 파라미터의 범위를 제한합니다.\n\\(a_{w,u} = P(x, y, w, u)\\)의 경우, \\[\\max\\{0, P(x, y, w) + P(u) - 1\\} \\le a_{w,u} \\le \\min\\{P(x, y, w), P(u)\\}\\]\n\\(b_{w,u} = P(w, u)\\)의 경우, \\[\\max\\{0, P(w) + P(u) - 1\\} \\le b_{w,u} \\le \\min\\{P(w), P(u)\\}\\]\n\\(c_{w, u} = P(x, w, u)\\)의 경우, \\[\\max\\{0, P(x, w) + P(u) - 1\\} \\le c_{w,u} \\le \\min\\{P(x, w), P(u)\\}\\]\n\n이러한 제약 조건 하에서 목표 함수를 최적화하면, Natural Bounds보다 좁은 범위(Valid Bounds)를 얻을 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-03/index.html#요약",
    "href": "posts/lecture/L08/causal-inference-08-part-03/index.html#요약",
    "title": "[Causal Inference] 08. Partial Identification (Part 3)",
    "section": "5.1 요약",
    "text": "5.1 요약\n\n\nNatural Bounds: 그래프 구조에 대한 최소한의 가정만으로 구하는 가장 넓은 범위.\n\n\nCanonical Type Model (IV): 도구 변수가 있을 때, 비관측 변수 \\(U\\)를 유한한 반응 유형(Response Types)으로 나누어 선형 계획법(LP)으로 해결.\n\n\nPartially-observed Covariates: 데이터가 파편화되어 있을 때, 확률 분포의 제약 조건을 이용한 최적화 문제로 해결."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-03/index.html#추가적인-연구-주제들",
    "href": "posts/lecture/L08/causal-inference-08-part-03/index.html#추가적인-연구-주제들",
    "title": "[Causal Inference] 08. Partial Identification (Part 3)",
    "section": "5.2 추가적인 연구 주제들",
    "text": "5.2 추가적인 연구 주제들\n\nPartial Identification은 여전히 활발히 연구되고 있는 분야입니다. 더 깊이 있는 학습을 위해 다음 논문들을 참고할 수 있습니다.\n\n\n연속 변수(Continuous variables)에서의 Bound: Zhang and Bareinboim (2022)\n\n\nHigh Dimensional Data: Li and Pearl (2022)\n\n\n비순응(Non-Compliance) 분석: Balke and Pearl (1997), Chickering and Pearl (1996)\n\n\nNote: 더 복잡한 구조(예: 또 다른 Canonical Type Model)에서도 유사한 방식의 접근이 가능합니다.\n\n\n식별 불가능하다고 해서 분석을 멈추는 것이 아니라, “데이터가 허용하는 한계 내에서 최선의 정보”를 뽑아내는 것이 바로 Partial Identification의 핵심입니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "",
    "text": "딥러닝 모델과 같은 Black-box 머신러닝 모델들은 의료 진단이나 자율 주행과 같은 High-risk 환경에서 일상적으로 사용되고 있습니다.\n하지만 이러한 모델들은 종종 잘못된 예측을 내놓으면서도 높은 확신(Overconfidence)을 보이는 문제가 있습니다.\nConformal Prediction(CP)는 이러한 모델의 예측에 대해 통계적으로 엄밀한 불확실성 구간(Uncertainty Sets/Intervals)을 생성하는 방법론입니다.\nCP의 가장 큰 장점은 다음과 같습니다:\n\nDistribution-free: 데이터의 분포에 대한 가정(가우시안 분포 등)이 필요하지 않습니다.\nModel-agnostic: 뉴럴 네트워크를 포함한 어떤 학습된 모델(Pre-trained model)에도 적용 가능합니다.\nFinite-sample guarantee: 무한한 데이터가 아닌, 유한한 샘플 수에서도 통계적 커버리지(\\(1-\\alpha\\))를 보장합니다.\n\n이 글에서는 논문 “A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification”의 핵심 내용을 바탕으로 CP의 원리와 구현 방법을 정리합니다.\n\n\n\n\n\nCP를 이해하기 위해 가장 간단한 이미지 분류(Classification) 문제를 예로 들어보겠습니다.\n\\(K\\)개의 클래스를 분류하는 모델 \\(\\hat{f}\\)가 있다고 가정합시다.\n이 모델은 입력 이미지 \\(x\\)에 대해 각 클래스에 속할 확률(Softmax score)을 출력합니다.\n\n\n\n\nFigure 1: ImageNet 데이터셋에 대한 Prediction Set 예시. 다람쥐(Squirrel)와 같이 모델이 헷갈리는 이미지에 대해서는 여러 클래스를 포함하는 Set을 출력하여 정답을 포함할 확률을 보장한다.\n\n\n\n우리의 목표는 단순히 가장 높은 확률을 가진 하나의 라벨을 뱉는 것이 아니라, 정답 라벨 \\(Y\\)를 \\(1-\\alpha\\)(예: 90%)의 확률로 포함하는 후보 라벨들의 집합(Set) \\(\\mathcal{C}(X)\\)를 만드는 것입니다. \\[\n1-\\alpha \\le \\mathbb{P}(Y_{test} \\in \\mathcal{C}(X_{test})) \\le 1-\\alpha + \\frac{1}{n+1}\n\\]\n위 식은 Marginal Coverage라고 불리며, Calibration 데이터와 테스트 데이터의 무작위성을 평균했을 때 예측 집합이 정답을 포함할 확률이 \\(1-\\alpha\\) 이상임을 의미합니다.\n\n\n\n\n\nCP는 복잡한 최적화 과정 없이 Calibration Step이라고 불리는 간단한 절차를 통해 수행됩니다.\n핵심은 모델이 학습 과정에서 보지 못한 Calibration Data (약 500개 정도의 소규모 데이터)를 사용하는 것입니다.\n\n\n\n\n학습에 사용되지 않은 \\(n\\)개의 데이터 쌍 \\((X_1, Y_1), \\dots, (X_n, Y_n)\\)을 준비합니다.\n이 데이터는 교환 가능(Exchangeable), 일반적으로는 i.i.d. 가정만 만족하면 됩니다.\n\n\n\n\n\n각 Calibration 데이터에 대해 모델이 얼마나 “잘못” 예측했는지를 나타내는 Conformal Score \\(s_i\\)를 계산합니다.\n분류 문제에서 가장 일반적인 점수 함수는 다음과 같습니다:\n\n\\[\ns_i = 1 - \\hat{f}(X_i)_{Y_i}\n\\]\n\n여기서 \\(\\hat{f}(X_i)_{Y_i}\\)는 정답 클래스 \\(Y_i\\)에 대한 모델의 Softmax 확률입니다.\n모델이 정답을 확신할수록 \\(\\hat{f}(X_i)_{Y_i} \\approx 1\\)이므로 점수 \\(s_i\\)는 0에 가까워집니다.\n모델이 틀렸거나 불확실할수록 점수 \\(s_i\\)는 커집니다.\n\n\n\n\n\n우리는 새로운 데이터가 들어왔을 때, 모델의 불확실성(Score)이 어느 수준 이하이어야 안심할 수 있는지를 결정해야 합니다.\n이를 위해 계산된 점수들 \\(s_1, \\dots, s_n\\)의 분포에서 \\(\\hat{q}\\) (Quantile) 값을 찾습니다.\n엄밀한 커버리지를 보장하기 위해 다음과 같은 보정된 분위수(Adjusted Quantile)를 사용합니다:\n\n\\[\n\\hat{q} = \\text{Quantile}\\left( \\frac{\\lceil (n+1)(1-\\alpha) \\rceil}{n} ; \\{s_1, \\dots, s_n\\} \\right)\n\\]\n\n이 \\(\\hat{q}\\) 값은 “전체 데이터의 \\((1-\\alpha)\\) 비율이 이 점수보다 낮다”는 경계선 역할을 합니다.\n\n\n\n\n\n이제 새로운 테스트 데이터 \\(X_{test}\\)가 들어오면, 예측 집합 \\(\\mathcal{C}(X_{test})\\)를 다음과 같이 구성합니다:\n\n\\[\n\\mathcal{C}(X_{test}) = \\{ y : 1 - \\hat{f}(X_{test})_y \\le \\hat{q} \\} = \\{ y : \\hat{f}(X_{test})_y \\ge 1 - \\hat{q} \\}\n\\]\n\n즉, 모델의 예측 확률이 \\(1-\\hat{q}\\) 이상인 모든 클래스를 후보로 포함시킵니다.\n\n\n\n\nFigure 2: Conformal Prediction의 전체 프로세스 도식화 및 Python 코드 예시. (1) Score 계산, (2) Quantile 계산, (3) Prediction Set 구성의 3단계로 이루어진다.\n\n\n\n\n\n\n\n앞서 설명한 분류 문제는 CP의 특수한 사례일 뿐입니다.\nCP는 Regression, Segmentation 등 어떤 문제에도 적용할 수 있는 일반적인 프레임워크입니다.\n\n\n\n\nDiagram 1: Heuristic Notion of Uncertainty를 CP를 통해 Rigorous Uncertainty로 변환하는 과정\n\n\n일반화된 CP 알고리즘은 다음과 같습니다:\n\nHeuristic Notion of Uncertainty 식별: Pre-trained 모델을 사용하여 불확실성을 나타내는 지표를 정의합니다.\nScore Function 정의: \\(s(x, y) \\in \\mathbb{R}\\). 점수가 클수록 모델의 예측 \\(x\\)와 실제값 \\(y\\) 사이의 불일치(Error)가 큼을 의미해야 합니다.\nQuantile \\(\\hat{q}\\) 계산: Calibration 데이터셋에 대해 Score를 계산하고, \\(\\frac{\\lceil(n+1)(1-\\alpha)\\rceil}{n}\\) 분위수를 구합니다.\nPrediction Set 생성: \\[ \\mathcal{C}(X_{test}) = \\{ y : s(X_{test}, y) \\le \\hat{q} \\} \\] 이 집합은 Score가 \\(\\hat{q}\\)보다 작거나 같은 모든 \\(y\\)를 포함합니다.\n\n\n\n\n\nConformal Prediction이 강력한 이유는 다음의 정리에 의해 수학적으로 증명된 커버리지를 제공하기 때문입니다.\n\n\nTheorem 1 (Conformal Coverage Guarantee)\nCalibration 데이터 \\((X_i, Y_i)_{i=1}^n\\)와 테스트 데이터 \\((X_{test}, Y_{test})\\)가 i.i.d.라고 가정하자. 위에서 정의한 절차에 따라 \\(\\hat{q}\\)를 계산하고 집합 \\(\\mathcal{C}(X_{test})\\)를 구성하면, 다음이 성립한다:\n\\[ P(Y_{test} \\in \\mathcal{C}(X_{test})) \\ge 1 - \\alpha \\]\n\n\n이 정리는 모델이 아무리 엉터리(Bad)여도 성립합니다.\n하지만 “유용한(Useful)” 예측 집합을 얻기 위해서는 Score Function의 설계가 중요합니다.\n\nScore Function이 불확실성을 잘 반영한다면: 쉬운 입력에는 집합 크기가 작고, 어려운 입력에는 커집니다 (Adaptive).\nScore Function이 랜덤하다면: 집합 크기가 불필요하게 커지지만, 여전히 \\(1-\\alpha\\) 커버리지는 만족합니다.\n\n따라서 CP의 성패는 “좋은 Score Function을 어떻게 정의하느냐”에 달려 있습니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#introduction",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#introduction",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "",
    "text": "딥러닝 모델과 같은 Black-box 머신러닝 모델들은 의료 진단이나 자율 주행과 같은 High-risk 환경에서 일상적으로 사용되고 있습니다.\n하지만 이러한 모델들은 종종 잘못된 예측을 내놓으면서도 높은 확신(Overconfidence)을 보이는 문제가 있습니다.\nConformal Prediction(CP)는 이러한 모델의 예측에 대해 통계적으로 엄밀한 불확실성 구간(Uncertainty Sets/Intervals)을 생성하는 방법론입니다.\nCP의 가장 큰 장점은 다음과 같습니다:\n\nDistribution-free: 데이터의 분포에 대한 가정(가우시안 분포 등)이 필요하지 않습니다.\nModel-agnostic: 뉴럴 네트워크를 포함한 어떤 학습된 모델(Pre-trained model)에도 적용 가능합니다.\nFinite-sample guarantee: 무한한 데이터가 아닌, 유한한 샘플 수에서도 통계적 커버리지(\\(1-\\alpha\\))를 보장합니다.\n\n이 글에서는 논문 “A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification”의 핵심 내용을 바탕으로 CP의 원리와 구현 방법을 정리합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#the-intuition-classification-example",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#the-intuition-classification-example",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "",
    "text": "CP를 이해하기 위해 가장 간단한 이미지 분류(Classification) 문제를 예로 들어보겠습니다.\n\\(K\\)개의 클래스를 분류하는 모델 \\(\\hat{f}\\)가 있다고 가정합시다.\n이 모델은 입력 이미지 \\(x\\)에 대해 각 클래스에 속할 확률(Softmax score)을 출력합니다.\n\n\n\n\nFigure 1: ImageNet 데이터셋에 대한 Prediction Set 예시. 다람쥐(Squirrel)와 같이 모델이 헷갈리는 이미지에 대해서는 여러 클래스를 포함하는 Set을 출력하여 정답을 포함할 확률을 보장한다.\n\n\n\n우리의 목표는 단순히 가장 높은 확률을 가진 하나의 라벨을 뱉는 것이 아니라, 정답 라벨 \\(Y\\)를 \\(1-\\alpha\\)(예: 90%)의 확률로 포함하는 후보 라벨들의 집합(Set) \\(\\mathcal{C}(X)\\)를 만드는 것입니다. \\[\n1-\\alpha \\le \\mathbb{P}(Y_{test} \\in \\mathcal{C}(X_{test})) \\le 1-\\alpha + \\frac{1}{n+1}\n\\]\n위 식은 Marginal Coverage라고 불리며, Calibration 데이터와 테스트 데이터의 무작위성을 평균했을 때 예측 집합이 정답을 포함할 확률이 \\(1-\\alpha\\) 이상임을 의미합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#the-conformal-prediction-algorithm",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#the-conformal-prediction-algorithm",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "",
    "text": "CP는 복잡한 최적화 과정 없이 Calibration Step이라고 불리는 간단한 절차를 통해 수행됩니다.\n핵심은 모델이 학습 과정에서 보지 못한 Calibration Data (약 500개 정도의 소규모 데이터)를 사용하는 것입니다.\n\n\n\n\n학습에 사용되지 않은 \\(n\\)개의 데이터 쌍 \\((X_1, Y_1), \\dots, (X_n, Y_n)\\)을 준비합니다.\n이 데이터는 교환 가능(Exchangeable), 일반적으로는 i.i.d. 가정만 만족하면 됩니다.\n\n\n\n\n\n각 Calibration 데이터에 대해 모델이 얼마나 “잘못” 예측했는지를 나타내는 Conformal Score \\(s_i\\)를 계산합니다.\n분류 문제에서 가장 일반적인 점수 함수는 다음과 같습니다:\n\n\\[\ns_i = 1 - \\hat{f}(X_i)_{Y_i}\n\\]\n\n여기서 \\(\\hat{f}(X_i)_{Y_i}\\)는 정답 클래스 \\(Y_i\\)에 대한 모델의 Softmax 확률입니다.\n모델이 정답을 확신할수록 \\(\\hat{f}(X_i)_{Y_i} \\approx 1\\)이므로 점수 \\(s_i\\)는 0에 가까워집니다.\n모델이 틀렸거나 불확실할수록 점수 \\(s_i\\)는 커집니다.\n\n\n\n\n\n우리는 새로운 데이터가 들어왔을 때, 모델의 불확실성(Score)이 어느 수준 이하이어야 안심할 수 있는지를 결정해야 합니다.\n이를 위해 계산된 점수들 \\(s_1, \\dots, s_n\\)의 분포에서 \\(\\hat{q}\\) (Quantile) 값을 찾습니다.\n엄밀한 커버리지를 보장하기 위해 다음과 같은 보정된 분위수(Adjusted Quantile)를 사용합니다:\n\n\\[\n\\hat{q} = \\text{Quantile}\\left( \\frac{\\lceil (n+1)(1-\\alpha) \\rceil}{n} ; \\{s_1, \\dots, s_n\\} \\right)\n\\]\n\n이 \\(\\hat{q}\\) 값은 “전체 데이터의 \\((1-\\alpha)\\) 비율이 이 점수보다 낮다”는 경계선 역할을 합니다.\n\n\n\n\n\n이제 새로운 테스트 데이터 \\(X_{test}\\)가 들어오면, 예측 집합 \\(\\mathcal{C}(X_{test})\\)를 다음과 같이 구성합니다:\n\n\\[\n\\mathcal{C}(X_{test}) = \\{ y : 1 - \\hat{f}(X_{test})_y \\le \\hat{q} \\} = \\{ y : \\hat{f}(X_{test})_y \\ge 1 - \\hat{q} \\}\n\\]\n\n즉, 모델의 예측 확률이 \\(1-\\hat{q}\\) 이상인 모든 클래스를 후보로 포함시킵니다.\n\n\n\n\nFigure 2: Conformal Prediction의 전체 프로세스 도식화 및 Python 코드 예시. (1) Score 계산, (2) Quantile 계산, (3) Prediction Set 구성의 3단계로 이루어진다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#general-instructions-for-conformal-prediction",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#general-instructions-for-conformal-prediction",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "",
    "text": "앞서 설명한 분류 문제는 CP의 특수한 사례일 뿐입니다.\nCP는 Regression, Segmentation 등 어떤 문제에도 적용할 수 있는 일반적인 프레임워크입니다.\n\n\n\n\nDiagram 1: Heuristic Notion of Uncertainty를 CP를 통해 Rigorous Uncertainty로 변환하는 과정\n\n\n일반화된 CP 알고리즘은 다음과 같습니다:\n\nHeuristic Notion of Uncertainty 식별: Pre-trained 모델을 사용하여 불확실성을 나타내는 지표를 정의합니다.\nScore Function 정의: \\(s(x, y) \\in \\mathbb{R}\\). 점수가 클수록 모델의 예측 \\(x\\)와 실제값 \\(y\\) 사이의 불일치(Error)가 큼을 의미해야 합니다.\nQuantile \\(\\hat{q}\\) 계산: Calibration 데이터셋에 대해 Score를 계산하고, \\(\\frac{\\lceil(n+1)(1-\\alpha)\\rceil}{n}\\) 분위수를 구합니다.\nPrediction Set 생성: \\[ \\mathcal{C}(X_{test}) = \\{ y : s(X_{test}, y) \\le \\hat{q} \\} \\] 이 집합은 Score가 \\(\\hat{q}\\)보다 작거나 같은 모든 \\(y\\)를 포함합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#theoretical-guarantee",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#theoretical-guarantee",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "",
    "text": "Conformal Prediction이 강력한 이유는 다음의 정리에 의해 수학적으로 증명된 커버리지를 제공하기 때문입니다.\n\n\nTheorem 1 (Conformal Coverage Guarantee)\nCalibration 데이터 \\((X_i, Y_i)_{i=1}^n\\)와 테스트 데이터 \\((X_{test}, Y_{test})\\)가 i.i.d.라고 가정하자. 위에서 정의한 절차에 따라 \\(\\hat{q}\\)를 계산하고 집합 \\(\\mathcal{C}(X_{test})\\)를 구성하면, 다음이 성립한다:\n\\[ P(Y_{test} \\in \\mathcal{C}(X_{test})) \\ge 1 - \\alpha \\]\n\n\n이 정리는 모델이 아무리 엉터리(Bad)여도 성립합니다.\n하지만 “유용한(Useful)” 예측 집합을 얻기 위해서는 Score Function의 설계가 중요합니다.\n\nScore Function이 불확실성을 잘 반영한다면: 쉬운 입력에는 집합 크기가 작고, 어려운 입력에는 커집니다 (Adaptive).\nScore Function이 랜덤하다면: 집합 크기가 불필요하게 커지지만, 여전히 \\(1-\\alpha\\) 커버리지는 만족합니다.\n\n따라서 CP의 성패는 “좋은 Score Function을 어떻게 정의하느냐”에 달려 있습니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#problem-setup",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#problem-setup",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "2.1. Problem Setup",
    "text": "2.1. Problem Setup\n\nIntroduction: Why Adaptive?\n\n이전 포스트(Section 1)에서 다룬 기본적인 Conformal Prediction 방법은 단순하고 강력하지만 한 가지 단점이 있습니다.\n기존 방식(Naive method)은 단순히 \\(1 - \\hat{f}(x)_y\\)를 점수로 사용하기 때문에, 모든 클래스에 대해 고정된 임계값(Threshold)을 적용하는 경향이 있습니다.\n이로 인해 다음과 같은 문제가 발생합니다:\n\n\nHard Inputs (어려운 이미지): 모델이 헷갈려하는 경우에도 예측 집합이 충분히 커지지 않아 정답을 놓칠 수 있습니다 (Under-coverage).\n\n\nEasy Inputs (쉬운 이미지): 모델이 확신하는 경우에도 예측 집합이 불필요하게 클 수 있습니다 (Over-coverage).\n\n\n우리는 입력 이미지의 난이도에 따라 어려우면 집합을 크게, 쉬우면 집합을 작게 만드는 Adaptive Prediction Sets (APS) 기법을 도입하여 이 문제를 해결할 것입니다.\n\n\n\nThe Intuition: “Water-filling” Approach\n\nAPS의 핵심 아이디어는 직관적입니다.\n만약 모델의 예측 확률 \\(\\hat{f}(x)\\)가 완벽하다면, 우리는 확률이 높은 클래스부터 순서대로 골라 담으면서 그 확률의 합(Cumulative Sum)이 \\(1-\\alpha\\) (예: 90%)를 넘기는 순간 멈추면 됩니다.\n\n\\[\n\\sum_{j=1}^{k} \\hat{f}(x)_{\\pi_j(x)} \\ge 1 - \\alpha\n\\]\n\n여기서 \\(\\pi(x)\\)는 확률이 높은 순서대로 정렬된 클래스의 순열(Permutation)입니다.\n이 방식은 “컵에 물(확률)을 \\(90\\%\\)가 찰 때까지 붓는 것”과 유사합니다.\n쉬운 문제: 확률 분포가 뾰족(Peaked)하므로, 1~2개만 담아도 금방 \\(90\\%\\)가 찹니다. \\(\\rightarrow\\) Small Set\n어려운 문제: 확률 분포가 평평(Flat)하므로, 여러 개를 담아야 \\(90\\%\\)가 찹니다. \\(\\rightarrow\\) Large Set\n하지만 실제 모델의 확률 \\(\\hat{f}(x)\\)는 완벽하지 않으므로(Overconfident/Underconfident), 단순히 \\(1-\\alpha\\)에서 끊으면 커버리지를 보장할 수 없습니다.\n따라서 Conformal Prediction을 사용하여 이 “멈추는 지점(Threshold)”을 보정해야 합니다.\n\n\n\n\nFigure 4: Adaptive Prediction Sets (APS) 알고리즘의 시각화. 확률이 높은 클래스(Fox squirrel, Gray fox…)부터 순서대로 누적 합을 구하고, 그 합이 보정된 분위수(Quantile)를 넘을 때까지 클래스를 포함시킨다.\n\n\n\n\nMathematical Formulation\n\n이제 이를 수학적으로 엄밀하게 정의해보겠습니다.\n\n\n1. Defining the Score Function\n\nAPS를 위한 Score Function \\(s(x, y)\\)는 “정답 클래스 \\(y\\)를 포함시키기 위해, 확률 상위 몇 번째 클래스까지 내려가야 하는가?”를 누적 확률로 나타냅니다.\n먼저, 입력 \\(x\\)에 대해 모델이 예측한 확률을 내림차순으로 정렬하는 순열 함수 \\(\\pi(x)\\)를 정의합니다. \\[ \\hat{f}(x)_{\\pi_1(x)} \\ge \\hat{f}(x)_{\\pi_2(x)} \\ge \\dots \\ge \\hat{f}(x)_{\\pi_K(x)} \\]\n이때, 정답 클래스 \\(y\\)가 정렬된 순서상 \\(k\\)번째에 위치한다고 가정합시다 (\\(y = \\pi_k(x)\\)).\nScore \\(s(x, y)\\)는 \\(y\\)까지의 누적 확률 질량(Cumulative Probability Mass)으로 정의됩니다:\n\n\\[\ns(x,y) = \\sum_{j=1}^{k} \\hat{f}(x)_{\\pi_j(x)}\n\\]\n\n의미: “모델이 가장 가능성 높다고 생각하는 것부터 정답 \\(y\\)가 나올 때까지 확률을 다 더한 값”입니다.\n\n만약 모델이 정답을 1순위로 예측했다면, \\(s(x,y)\\)는 작을 것입니다.\n만약 모델이 정답을 하위권으로 예측했다면, \\(s(x,y)\\)는 1에 가까워질 것입니다.\n\n\n\n\n2. Calibration (Finding \\(\\hat{q}\\))\n\n이제 Calibration 데이터셋 \\((X_1, Y_1), \\dots, (X_n, Y_n)\\)에 대해 위 점수들을 계산합니다.\n그리고 다음 식을 만족하는 분위수(Quantile) \\(\\hat{q}\\)를 찾습니다.\n\n\\[\n\\hat{q} = \\text{Quantile}\\left( \\frac{\\lceil (n+1)(1-\\alpha) \\rceil}{n} ; \\{s_1, \\dots, s_n\\} \\right)\n\\]\n\n이 \\(\\hat{q}\\)는 “정답을 포함하기 위해 누적 확률을 어디까지 허용해야 하는가?”에 대한 통계적 임계값입니다.\n\n\n\n3. Constructing the Prediction Set\n\n새로운 테스트 데이터 \\(X_{test}\\)에 대해 예측 집합 \\(\\mathcal{C}(X_{test})\\)는 누적 확률이 \\(\\hat{q}\\)를 넘어서는 지점까지의 모든 클래스를 포함하여 구성됩니다.\n\n\\[\n\\mathcal{C}(x) = \\{ \\pi_1(x), \\dots, \\pi_k(x) \\}\n\\]\n\n여기서 \\(k\\)는 다음을 만족하는 가장 작은 정수입니다: \\[\n\\text{sup} \\left\\{ k' : \\sum_{j=1}^{k'} \\hat{f}(x)_{\\pi_j(x)} &lt; \\hat{q} \\right\\} + 1\n\\]\n즉, 누적 합이 \\(\\hat{q}\\)를 초과하는 순간까지 포함합니다.\n\n\n\n\nImplementation Steps\n\nPython 코드로 구현할 때의 핵심 로직은 다음과 같습니다.\n\n\n\n\nFigure 5: Adaptive Prediction Sets 구현을 위한 Python 코드 예시. argsort를 통해 정렬하고 cumsum을 통해 누적 확률을 계산하는 과정이 포함되어 있다.\n\n\n\nSoftmax & Sort: 모델 출력값(Softmax)을 구하고 argsort를 이용해 내림차순 정렬합니다.\nCumulative Sum: 정렬된 확률값들의 누적 합(cumsum)을 계산합니다.\nCalculate Scores (Calibration): 정답 라벨 위치에서의 누적 합을 가져와 \\(s_i\\)를 구하고, Quantile \\(\\hat{q}\\)를 계산합니다.\nPrediction (Test): 테스트 데이터의 누적 합이 \\(\\hat{q}\\)보다 작거나 같은 클래스들을 선택합니다. (엄밀하게는 \\(\\hat{q}\\)를 넘는 첫 번째 클래스까지 포함해야 함)\n\n\n\nSummary\n\nAdaptive Prediction Sets (APS)는 불확실성을 더 지능적으로 다루는 방법입니다.\n단순히 모델의 Softmax 값 하나만 보는 것이 아니라, 전체 확률 분포의 형상(Shape)을 고려합니다.\n그 결과, 쉬운 샘플에는 작은 집합을, 어려운 샘플에는 큰 집합을 할당하여 사용자가 모델의 신뢰도를 직관적으로 파악할 수 있게 해줍니다.\n이 모든 과정에서도 \\(1-\\alpha\\)라는 통계적 커버리지는 엄격하게 보장됩니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#traditional-inferential-targets",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#traditional-inferential-targets",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "2.2. Traditional Inferential Targets",
    "text": "2.2. Traditional Inferential Targets\n\nIntroduction\n\n이전 포스트에서는 분류(Classification) 문제에 대한 Conformal Prediction을 다루었습니다.\n이번에는 연속적인 값(Continuous Output)을 예측하는 회귀(Regression) 문제로 넘어가 보겠습니다.\n회귀 문제에서 우리의 목표는 입력 \\(x\\)에 대해 단순히 하나의 예측값 \\(\\hat{y}\\)를 내놓는 것이 아니라, 정답 \\(y\\)가 포함될 확률이 \\(1-\\alpha\\) (예: 90%)인 예측 구간(Prediction Interval)을 생성하는 것입니다.\n\n\\[\n\\mathcal{C}(x) = [\\text{Lower Bound}, \\text{Upper Bound}]\n\\]\n\n이를 위해 가장 효과적인 베이스 모델 중 하나인 Quantile Regression을 사용하고, CP를 통해 이를 보정하는 Conformalized Quantile Regression (CQR) 기법을 알아보겠습니다.\n\n\n\nBase Model: Quantile Regression\n\nConcept\n\n일반적인 회귀 모델은 평균(Mean)을 예측(MSE Loss 사용)하지만, Quantile Regression은 조건부 분포의 특정 분위수(Quantile)를 예측합니다.\n90%의 커버리지를 목표로 한다면, 우리는 양쪽 꼬리에서 5%씩을 제외한 구간을 알고 싶을 것입니다. 즉, 다음 두 가지 분위수를 학습합니다:\n\nLower Quantile: \\(\\alpha/2 = 0.05\\) (5% 지점)\nUpper Quantile: \\(1 - \\alpha/2 = 0.95\\) (95% 지점)\n\n모델이 완벽하다면, 정답 \\(y\\)는 90%의 확률로 이 구간 \\([\\hat{t}_{\\alpha/2}(x), \\hat{t}_{1-\\alpha/2}(x)]\\) 사이에 존재해야 합니다.\n\n\n\nQuantile Loss (Pinball Loss)\n\n이러한 분위수를 학습하기 위해 Quantile Loss (Pinball Loss)를 사용합니다.\n\n\\[\nL_{\\gamma}(\\hat{t}_{\\gamma}, y) = (y - \\hat{t}_{\\gamma})\\gamma \\mathbb{1}\\{y &gt; \\hat{t}_{\\gamma}\\} + (\\hat{t}_{\\gamma} - y)(1-\\gamma)\\mathbb{1}\\{y \\le \\hat{t}_{\\gamma}\\}\n\\]\n\n\\(\\gamma\\): 타겟 분위수 (예: 0.05 또는 0.95)\n이 손실 함수를 사용하여 뉴럴 네트워크 등 어떤 모델이든 특정 분위수를 예측하도록 학습시킬 수 있습니다.\n\n\n\n\nThe Problem: Why Conformalize?\n\nQuantile Regression으로 구한 구간 \\([\\hat{t}_{0.05}(x), \\hat{t}_{0.95}(x)]\\)는 꽤 훌륭한 불확실성 추정치입니다.\n하지만 문제는 “Finite Sample”에서 90% 커버리지를 보장하지 못한다는 점입니다.\n모델이 과적합(Overfitting)되거나 학습이 덜 되면, 실제 정답이 이 구간을 벗어나는 비율이 10%보다 훨씬 클 수도, 작을 수도 있습니다.\n따라서 우리는 Conformal Prediction을 사용하여 이 구간을 보정(Calibrate)해야 합니다.\n\n\n\nConformalized Quantile Regression Algorithm\n\nCQR의 핵심 아이디어는 학습된 분위수 구간을 \\(\\hat{q}\\)만큼 늘리거나 줄여서 엄밀한 커버리지를 맞추는 것입니다.\n\n\nStep 1: Define Score Function\n\nCalibration 데이터 \\((X_i, Y_i)\\)에 대해, 정답 \\(Y_i\\)가 학습된 구간 \\([\\hat{t}_{\\alpha/2}(X_i), \\hat{t}_{1-\\alpha/2}(X_i)]\\) 밖으로 얼마나 나갔는지를 측정하는 Score를 정의합니다.\n\n\\[\ns(x, y) = \\max \\{ \\hat{t}_{\\alpha/2}(x) - y, \\quad y - \\hat{t}_{1-\\alpha/2}(x) \\}\n\\]\n\n이 식의 의미를 직관적으로 살펴봅시다:\n\nCase 1: \\(y\\)가 구간 안에 있을 때:\n\n\\(\\hat{t}_{\\text{lower}} &lt; y &lt; \\hat{t}_{\\text{upper}}\\) 이므로, 두 항 모두 음수가 됩니다.\n\\(s(x, y) &lt; 0\\) (즉, 안전함)\n\nCase 2: \\(y\\)가 구간 밖(위쪽)에 있을 때:\n\n\\(y &gt; \\hat{t}_{\\text{upper}}\\) 이므로 \\(y - \\hat{t}_{\\text{upper}}\\) 가 양수가 됩니다.\n\\(s(x, y) &gt; 0\\) (즉, 위험함/에러)\n\n\n즉, 점수 \\(s\\)가 클수록 정답이 예측 구간을 크게 벗어났음을 의미합니다.\n\n\n\nStep 2: Calibration (Get \\(\\hat{q}\\))\n\n계산된 점수들 \\(s_1, \\dots, s_n\\)의 분포에서 \\(1-\\alpha\\) 분위수 \\(\\hat{q}\\)를 찾습니다.\n\n\\[\n\\hat{q} = \\text{Quantile}\\left( \\frac{\\lceil (n+1)(1-\\alpha) \\rceil}{n} ; \\{s_1, \\dots, s_n\\} \\right)\n\\]\n\n만약 모델이 불확실성을 과소평가했다면(구간이 너무 좁으면), 많은 \\(y\\)가 구간 밖에 있을 것이고 \\(s\\)값들이 커져서 양수의 \\(\\hat{q}\\)가 나옵니다.\n만약 모델이 불확실성을 과대평가했다면(구간이 너무 넓으면), \\(s\\)값들이 대부분 음수일 것이고 음수의 \\(\\hat{q}\\)가 나옵니다.\n\n\n\nStep 3: Construct Prediction Interval\n\n최종적으로 새로운 입력 \\(X_{test}\\)에 대한 예측 구간을 생성할 때, 원래 구간을 \\(\\hat{q}\\)만큼 조정합니다.\n\n\\[\n\\mathcal{C}(X_{test}) = [\\hat{t}_{\\alpha/2}(X_{test}) - \\hat{q}, \\quad \\hat{t}_{1-\\alpha/2}(X_{test}) + \\hat{q}]\n\\]\n\n\\(\\hat{q} &gt; 0\\): 원래 구간이 너무 좁았으므로, 양쪽으로 \\(\\hat{q}\\)만큼 넓힙니다.\n\\(\\hat{q} &lt; 0\\): 원래 구간이 너무 넓었으므로, 양쪽으로 \\(|\\hat{q}|\\)만큼 좁힙니다.\n\n\n\n\nFigure 6: CQR 알고리즘의 시각화. 원래의 Quantile Regression 구간(파란색 영역)을 Calibration을 통해 얻은 상수 \\(\\hat{q}\\)만큼 확장하거나 축소하여 최종 Prediction Set을 생성한다.\n\n\n\n\n\nImplementation\nPython으로 CQR을 구현하는 것은 매우 간단합니다.\n\n\n\nFigure 7: Conformalized Quantile Regression 구현을 위한 Python 코드. Score를 계산하고 Quantile을 구하여 최종 구간을 조정하는 과정이 몇 줄의 코드로 구현된다.\n\n\n\n\nGet Scores: Calibration 데이터에 대해 max(lower - y, y - upper)를 계산합니다.\n\n\nGet Quantile: 위 점수들의 \\((1-\\alpha)\\) 분위수 \\(\\hat{q}\\)를 계산합니다.\n\n\nDeploy: 새로운 데이터의 Lower/Upper 예측값에 각각 \\(-\\hat{q}, +\\hat{q}\\)를 더해줍니다.\n\n\n\n\nConclusion\n\nConformalized Quantile Regression (CQR)은 회귀 문제에서 가장 널리 사용되는 최신 기법 중 하나입니다.\nAdaptivity: 입력값 \\(x\\)에 따라 구간의 길이(불확실성 크기)가 달라지는 Quantile Regression의 장점을 그대로 가집니다. (어려운 입력은 구간이 넓고, 쉬운 입력은 구간이 좁음)\nValidity: Conformal Prediction을 통해 통계적 커버리지를 엄밀하게 보장합니다.\n이 방법은 단순한 MSE 기반 회귀보다 훨씬 풍부한 정보를 제공하며, 의료나 금융과 같이 리스크 관리가 중요한 분야에서 필수적인 도구입니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#coverage-of-interval-estimates",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#coverage-of-interval-estimates",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "2.3. Coverage of Interval Estimates",
    "text": "2.3. Coverage of Interval Estimates\n\nIntroduction\n\n이전 포스트에서 다룬 Conformalized Quantile Regression (CQR)은 매우 강력하지만, 두 개의 Quantile을 학습시켜야 한다는 조건이 있습니다.\n하지만 실무에서는 종종 평균(\\(\\mu\\))과 분산(\\(\\sigma^2\\))만을 예측하는 더 단순한 모델을 사용하거나, 혹은 모델 앙상블의 분산 등을 불확실성 지표로 삼기도 합니다.\n이번 포스트에서는 이러한 단일 스칼라 불확실성 지표(Scalar Uncertainty Estimate)를 활용하여 통계적으로 유효한 예측 구간을 생성하는 방법을 알아봅니다.\n\n\n\nHeuristic Uncertainty: The Estimated Standard Deviation\n가장 흔한 시나리오는 데이터가 정규분포(Gaussian)를 따른다고 가정하고 모델을 학습시키는 것입니다.\n\\[ Y | X = x \\sim \\mathcal{N}(\\mu(x), \\sigma(x)) \\]\n\n딥러닝 프레임워크(PyTorch 등)에서는 GaussianNLLLoss와 같은 손실 함수를 제공하여, 모델이 평균 예측값 \\(\\hat{f}(x)\\)와 불확실성 예측값 \\(\\hat{\\sigma}(x)\\)를 동시에 학습하도록 돕습니다.\n하지만 실제 데이터는 정규분포를 따르지 않는 경우가 대부분입니다.\n따라서 모델이 예측한 \\(\\hat{\\sigma}(x)\\)를 그대로 사용하여 \\(\\hat{f}(x) \\pm 1.96\\hat{\\sigma}(x)\\)와 같은 구간을 만들면, 실제로는 95% 커버리지를 보장할 수 없습니다.\n우리는 Conformal Prediction을 사용하여 이 부정확한(Heuristic) \\(\\hat{\\sigma}(x)\\)를 보정(Calibrate)할 것입니다.\n\n\n\nGeneralizing Uncertainty Scalars\n\n이 방법은 비단 표준편차뿐만 아니라, “값이 클수록 불확실하다”는 의미를 가진 어떤 함수 \\(u(x)\\)에도 적용 가능합니다.\n논문에서는 \\(u(x)\\)로 사용할 수 있는 다양한 예시를 제시합니다:\n\n\nResidual Prediction: \\(|y - \\hat{f}(x)|\\)를 예측하는 별도의 모델 학습.\n\n\nEnsemble Variance: 여러 모델 예측값들의 분산 측정.\n\n\nDropout Variance: 추론 시 Dropout을 켜고 여러 번 예측했을 때의 분산.\n\n\nInput Perturbation: 입력에 작은 노이즈를 주었을 때 출력의 변화량.\n\n\n우리는 이 \\(u(x)\\)를 “불확실성의 크기(Magnitude)”로 간주하고, 이를 스케일링하는 방식(Multiplicative Correction)을 사용합니다.\n\n\n\nThe Algorithm\n\n알고리즘의 핵심은 “실제 에러가 불확실성 지표 \\(u(x)\\) 대비 몇 배나 큰가?”를 측정하는 것입니다.\n\n\nStep 1: Define Score Function\n\nCalibration 데이터 \\((X_i, Y_i)\\)에 대해 다음과 같은 Score를 정의합니다.\n\n\\[\ns(x, y) = \\frac{|y - \\hat{f}(x)|}{u(x)}\n\\]\n\n분자 \\(|y - \\hat{f}(x)|\\): 실제 모델의 예측 오차(절대값)입니다.\n분모 \\(u(x)\\): 모델이 스스로 추정한 불확실성입니다.\n의미: “모델이 예상한 불확실성 대비 실제 오차의 비율”입니다.\n\n만약 모델이 불확실하다고 판단(\\(u(x)\\) 큼)했는데 오차도 크다면, \\(s\\)는 적절한 값을 가집니다.\n만약 모델이 확실하다고 판단(\\(u(x)\\) 작음)했는데 오차가 크다면, \\(s\\)는 매우 커집니다 (Penalty).\n\n\n\n\nStep 2: Calibration (Get \\(\\hat{q}\\))\n\n계산된 점수들 \\(s_1, \\dots, s_n\\)에 대해 \\(1-\\alpha\\) 분위수(Quantile) \\(\\hat{q}\\)를 구합니다.\n\n\\[\n\\hat{q} = \\text{Quantile}\\left( \\frac{\\lceil (n+1)(1-\\alpha) \\rceil}{n} ; \\{s_1, \\dots, s_n\\} \\right)\n\\]\n\n여기서 구해진 \\(\\hat{q}\\)는 “불확실성 지표 \\(u(x)\\)에 곱해야 할 보정 계수(Multiplier)” 역할을 합니다.\n\n\n\nStep 3: Construct Prediction Interval\n\n새로운 입력 \\(X_{test}\\)에 대한 예측 구간은 중심 예측값 \\(\\hat{f}(x)\\)에서 불확실성 지표 \\(u(x)\\)의 \\(\\hat{q}\\)배만큼 벌려준 구간이 됩니다.\n\n\\[\n\\mathcal{C}(x) = [\\hat{f}(x) - \\hat{q}u(x), \\quad \\hat{f}(x) + \\hat{q}u(x)]\n\\]\n\n유도 과정 (Derivation of Validity)\n\n이 구간이 왜 \\(1-\\alpha\\) 커버리지를 보장하는지 살펴보겠습니다.\n\n\nCalibration 단계에서 \\(\\hat{q}\\)를 구했으므로, 새로운 데이터에 대해 다음 확률이 성립합니다. \\[ \\mathbb{P}[s(X_{test}, Y_{test}) \\le \\hat{q}] \\ge 1 - \\alpha \\]\nScore \\(s\\)의 정의를 대입합니다. \\[ \\mathbb{P}\\left[ \\frac{|Y_{test} - \\hat{f}(X_{test})|}{u(X_{test})} \\le \\hat{q} \\right] \\ge 1 - \\alpha \\]\n양변에 \\(u(X_{test})\\)를 곱합니다 (불확실성은 항상 양수이므로 부등호 유지). \\[ \\mathbb{P}\\left[ |Y_{test} - \\hat{f}(X_{test})| \\le \\hat{q}u(X_{test}) \\right] \\ge 1 - \\alpha \\]\n절대값을 풉니다. \\[ \\mathbb{P}\\left[ -\\hat{q}u(X_{test}) \\le Y_{test} - \\hat{f}(X_{test}) \\le \\hat{q}u(X_{test}) \\right] \\ge 1 - \\alpha \\]\n\\(Y_{test}\\)에 대해 정리하면 최종 구간이 도출됩니다. \\[ \\mathbb{P}\\left[ \\hat{f}(X_{test}) - \\hat{q}u(X_{test}) \\le Y_{test} \\le \\hat{f}(X_{test}) + \\hat{q}u(X_{test}) \\right] \\ge 1 - \\alpha \\]\n\n\n\n\nFigure 8: Uncertainty Scalar를 이용한 예측 구간 시각화. 중심 예측값 \\(\\hat{f}(x)\\)를 기준으로, 위아래로 \\(\\hat{q}u(x)\\)만큼 벌어진 대칭적인 구간을 형성한다.\n\n\n\n\n\n\nImplementation\n\n이 방법은 구현이 매우 간단하며, PyTorch 등의 라이브러리와 쉽게 결합됩니다.\n\n\n\n\nFigure 9: Conformalized Uncertainty Scalars 구현을 위한 Python 코드. Score를 계산할 때 예측된 표준편차(model output의 두 번째 컬럼)로 나누어주는 것이 핵심이다.\n\n\n\nGet Scores: 에러의 절대값을 예측된 표준편차(또는 불확실성 지표)로 나눕니다.\nGet Quantile: 점수들의 분위수 \\(\\hat{q}\\)를 계산합니다.\nDeploy: 예측값 \\(\\pm (\\text{불확실성} \\times \\hat{q})\\)를 통해 구간을 생성합니다.\n\n\n\nDiscussion\n\n이 방법은 Symmetric(대칭적)인 구간을 생성한다는 특징이 있습니다.\n\n장점: 구현이 쉽고 직관적입니다. 이미 학습된 모델(Gaussian Output 등)을 그대로 재활용하기 좋습니다.\n단점: CQR과 달리 구간이 항상 예측값을 중심으로 대칭입니다. 실제 데이터 분포가 비대칭(Skewed)이라면 효율적이지 않을 수 있습니다. 또한, \\(u(x)\\)가 실제 분위수와 비례하지 않는다면 CQR보다 성능(구간의 평균 길이 등)이 떨어질 수 있습니다.\n\n따라서 가능하다면 Quantile Regression (CQR)을 사용하는 것이 더 좋지만, 상황이 여의치 않거나 빠른 배포가 필요할 때 이 방법은 훌륭한 대안이 됩니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#conformalizing-bayes",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#conformalizing-bayes",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "2.4. Conformalizing Bayes",
    "text": "2.4. Conformalizing Bayes\n\nIntroduction\n\nBayesian Neural Network와 같은 베이지안 모델들은 불확실성 정량화(Uncertainty Quantification) 분야에서 매우 매력적인 도구입니다.\n이들은 사전 지식(Prior)을 반영할 수 있고, 예측의 결과물로 단일 값이 아닌 분포(Posterior Predictive Density)를 제공하기 때문입니다.\n하지만 베이지안 모델에는 치명적인 약점이 있습니다.\n“모델의 가정(Prior, Likelihood function 등)이 완벽하게 맞아야만” 예측된 불확실성이 정확하다는 점입니다.\n현실의 복잡한 데이터에서 이러한 가정이 완벽히 들어맞기는 어렵습니다.\nConformalizing Bayes는 베이지안 모델의 정보량을 그대로 활용하되, Conformal Prediction을 통해 “가정이 틀렸더라도” 통계적 커버리지를 보장하는 강력한 방법론입니다.\n\n\n\nThe Bayesian Ideal vs. Reality\n\nIdeal Scenario\n\n만약 우리가 만든 베이지안 모델 \\(\\hat{f}(y|x)\\) (입력 \\(x\\)가 주어졌을 때 \\(y\\)의 사후 확률 밀도)가 완벽하다면, 최적의 예측 집합 \\(S(x)\\)는 단순히 밀도 함수(Density)가 높은 영역을 잘라내어 만들 수 있습니다.\n\n\\[\nS(x) = \\{ y : \\hat{f}(y|x) &gt; t \\}\n\\]\n\n여기서 임계값 \\(t\\)는 해당 영역의 적분값이 \\(1-\\alpha\\)가 되도록 설정합니다. \\[\\int_{y \\in S(x)} \\hat{f}(y|x) dy = 1-\\alpha\\]\n이를 Highest Posterior Density (HPD) Region이라고도 합니다.\n\n\n\nReality\n\n하지만 우리는 모델 \\(\\hat{f}\\)가 완벽하다고 보장할 수 없습니다.\n따라서 위 방식으로 구한 집합은 실제로는 90%를 커버하지 못할 수도(Under-coverage), 너무 넓을 수도(Over-coverage) 있습니다.\n우리는 베이지안 모델의 \\(\\hat{f}(y|x)\\)를 “진짜 확률”이 아니라 “유용한 불확실성 점수(Heuristic Score)”로 간주하고, CP를 적용하여 올바른 임계값(Threshold)을 찾을 것입니다.\n\n\n\n\nThe Algorithm\n\nConformalizing Bayes의 절차는 우리가 익숙한 CP의 흐름을 그대로 따릅니다.\n\n\nStep 1: Define Score Function\n\n우리는 모델이 예측한 사후 확률 밀도(Posterior Predictive Density)가 높을수록 에러가 작다(확실하다)고 봅니다.\nConformal Score는 “불확실한 정도”를 나타내야 하므로, 밀도 함수의 음수(Negative)를 취합니다. \\[\ns(x, y) = - \\hat{f}(y|x)\n\\]\n\n\\(\\hat{f}(y|x)\\)가 높음 (모델이 정답을 확신함) \\(\\rightarrow\\) Score \\(s\\)는 매우 작은 음수.\n\\(\\hat{f}(y|x)\\)가 낮음 (모델이 정답을 예측 못함) \\(\\rightarrow\\) Score \\(s\\)는 큰 값(0에 가까운 값 혹은 양수).\n\n\n\n\nStep 2: Calibration (Finding \\(\\hat{q}\\))\n\nCalibration 데이터 \\((X_1, Y_1), \\dots, (X_n, Y_n)\\)에 대해 점수들을 계산하고, \\(1-\\alpha\\) 분위수 \\(\\hat{q}\\)를 찾습니다.\n\n\\[\n\\hat{q} = \\text{Quantile}\\left( \\frac{\\lceil (n+1)(1-\\alpha) \\rceil}{n} ; \\{s_1, \\dots, s_n\\} \\right)\n\\]\n\n여기서 구한 \\(\\hat{q}\\)는 “밀도 함수를 어디서 잘라야(Thresholding) 하는가?”에 대한 보정된 기준선이 됩니다.\n\n\n\nStep 3: Construct Prediction Set\n\n새로운 입력 \\(X_{test}\\)에 대해, Score가 \\(\\hat{q}\\) 이하인(즉, 밀도가 \\(-\\hat{q}\\) 이상인) 모든 \\(y\\)를 포함합니다.\n\n\\[\n\\mathcal{C}(x) = \\{ y : s(x, y) \\le \\hat{q} \\} = \\{ y : -\\hat{f}(y|x) \\le \\hat{q} \\}\n\\]\n\n이를 정리하면 최종 예측 집합은 다음과 같습니다:\n\n\\[\n\\mathcal{C}(x) = \\{ y : \\hat{f}(y|x) \\ge -\\hat{q} \\}\n\\]\n\n즉, 보정된 임계값 \\(-\\hat{q}\\)보다 확률 밀도가 높은 모든 \\(y\\)의 집합(Superlevel Set)을 구성합니다.\n\n\n\n\nFigure 10: Conformalized Bayes 알고리즘 시각화. 사후 확률 밀도 함수(Posterior Predictive Density) \\(\\hat{f}(y|x)\\)를 Conformal Prediction으로 구한 임계값 \\(-\\hat{q}\\)에서 잘라(Slicing), 그 위의 영역을 예측 집합으로 삼는다.\n\n\n\n\n\nMathematical Derivation & Validity\n\n이 집합이 왜 유효한지(Valid) 수학적으로 살펴보겠습니다.\n\nCalibration Guarantee:\n\n\nCalibration 단계에서 \\(\\hat{q}\\)를 구했으므로, 새로운 i.i.d. 샘플에 대해 다음이 성립합니다. \\[ \\mathbb{P}[s(X_{test}, Y_{test}) \\le \\hat{q}] \\ge 1 - \\alpha \\]\n\n\nSubstitution:\n\n\nScore의 정의 \\(s(x,y) = -\\hat{f}(y|x)\\)를 대입합니다. \\[ \\mathbb{P}[-\\hat{f}(Y_{test} | X_{test}) \\le \\hat{q}] \\ge 1 - \\alpha \\]\n\n\nInequality Rearrangement:\n\n\n부등식의 양변에 -1을 곱하여 부등호 방향을 바꿉니다. \\[ \\mathbb{P}[\\hat{f}(Y_{test} | X_{test}) \\ge -\\hat{q}] \\ge 1 - \\alpha \\]\n\n\n4. Conclusion:  따라서, 예측 집합 \\(\\mathcal{C}(X_{test}) = \\{ y : \\hat{f}(y|X_{test}) \\ge -\\hat{q} \\}\\)는 정답 \\(Y_{test}\\)를 \\(1-\\alpha\\) 확률로 포함합니다.\n\n\nWhy is this useful? (Bayes Optimality)\n\n이 방법은 단순히 유효할(Valid) 뿐만 아니라, 특정 조건 하에서 효율적(Efficient)입니다.\n논문에 따르면, 만약 원래의 베이지안 모델이 (비록 틀렸을지라도) 어느 정도 합리적이라면, 이 방법으로 생성된 예측 집합은 \\(1-\\alpha\\) 커버리지를 만족하는 모든 예측 집합 중에서 평균 크기(Average Size)가 가장 작습니다 (Bayes Optimal).\n이는 Neyman-Pearson Lemma와 유사한 논리로, “가장 확률 밀도가 높은 곳부터 담는 것”이 주어진 확률 질량을 채우면서 집합의 크기(Volume)를 최소화하는 전략이기 때문입니다.\n\n\n\nSummary\n\nConformalizing Bayes는 베이지안 모델의 확률 밀도 함수를 Score로 사용하여 CP를 적용하는 기법입니다.\n결과적으로 “Superlevel Set of Density” 형태의 예측 집합을 얻게 됩니다.\n이 방법은 베이지안 모델의 가정이 틀려도 Coverage를 보장하며, 동시에 베이지안 모델의 정보량을 활용하여 집합의 크기를 최적화할 수 있습니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#evaluating-adaptivity",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#evaluating-adaptivity",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "3.1. Evaluating Adaptivity",
    "text": "3.1. Evaluating Adaptivity\n\nIntroduction\n\n지금까지 우리는 Conformal Prediction(CP)을 통해 \\(1-\\alpha\\)의 커버리지를 보장하는 예측 집합을 만드는 법을 배웠습니다.\n하지만 “평균적으로 90% 정답을 포함한다(Marginal Coverage)”는 사실만으로는 충분하지 않습니다.\n예를 들어, 어떤 의사가 쉬운 환자에게는 100% 정확한 진단을 내리지만, 어려운 희귀병 환자에게는 0%의 정확도를 보인다면 어떨까요?\n전체 평균으로는 90% 정확도일지 몰라도, 이는 좋은 시스템이라 할 수 없습니다.\n좋은 CP 알고리즘은 쉬운 입력에는 작은 집합(Small Sets)을, 어려운 입력에는 큰 집합(Large Sets)을 출력해야 합니다. 이를 Adaptivity(적응성)라고 합니다.\n이번 포스트에서는 내 모델이 얼마나 “적응적(Adaptive)”인지 평가하는 구체적인 지표들을 알아봅니다.\n\n\n\nMetric 1: Set Size Distribution\n\n가장 먼저 확인해야 할 지표는 예측 집합 크기(Set Size)의 분포입니다.\n단순히 평균 크기만 보는 것이 아니라, 히스토그램을 그려봐야 합니다.\n\n\n\n\nPlaceholder: Histogram of Set Sizes. X축은 집합의 크기, Y축은 빈도수를 나타낸다. 분포가 넓게 퍼져 있을수록 다양한 난이도의 입력을 잘 구별하고 있다는 의미이다.\n\n\n\n\nAverage Set Size:\n\n\n작을수록 좋습니다. (단, \\(1-\\alpha\\) 커버리지를 만족하는 전제하에)\n평균이 너무 크다면? \\(\\rightarrow\\) 모델 성능이 나쁘거나, Score Function이 효율적이지 않음을 의미합니다.\n\n\nSpread of Set Sizes:\n\n\n분포가 넓을수록(Dynamic Range가 클수록) 좋습니다.\n분포가 넓다는 것은 모델이 “확실한 것(크기 1)”과 “불확실한 것(크기 5 이상)”을 잘 구분하고 있다는 뜻입니다.\n\n\n\n\nMetric 2: Conditional Coverage\n\n우리가 궁극적으로 원하는 것은 모든 개별 입력 \\(X\\)에 대해 커버리지를 보장하는 Conditional Coverage입니다.\n\n\\[\n\\mathbb{P}[Y_{test} \\in \\mathcal{C}(X_{test}) | X_{test}] \\ge 1 - \\alpha\n\\]\n\n하지만 현실적으로 모든 \\(X\\)값 하나하나에 대해 이를 검증하는 것은 불가능합니다(Impossible in general case).\n대신 우리는 데이터를 의미 있는 그룹(Group)으로 나누어, 각 그룹별로 커버리지가 잘 지켜지는지 확인해야 합니다.\n\n\n\n\nFigure: Marginal Coverage vs Conditional Coverage 비교. (좌측) 커버리지가 지켜지지 않음. (중앙) Marginal Coverage는 만족하지만 특정 그룹(Group 2)에서 에러가 집중됨. (우측) Conditional Coverage는 모든 그룹에서 고르게 에러가 분산됨.\n\n\n\n위 그림의 중앙(Marginal) 케이스를 봅시다.\n\nGroup 1 (Easy): 100% 커버리지 (과잉)\nGroup 2 (Hard): 80% 커버리지 (부족)\n전체 평균: 90% 커버리지 (만족)\n\n이런 경우 “Marginal Coverage는 만족하지만, Conditional Coverage는 실패했다”고 합니다.\n이를 잡아내기 위해 다음 두 가지 지표를 사용합니다.\n\n\n2.1 Feature-stratified Coverage (FSC)\n\n데이터의 특성(Feature)에 따라 그룹을 나누어 커버리지를 측정하는 방법입니다.\n예를 들어 인종(Race), 나이대(Age), 혹은 이미지의 밝기 등으로 데이터를 그룹화(\\(g=1, \\dots, G\\))합니다.\n각 그룹 \\(\\mathcal{I}_g\\)에 속한 데이터들의 커버리지를 계산하고, 가장 성능이 안 좋은 그룹(Minimum Coverage)을 찾습니다.\n\n\\[\n\\text{FSC metric} = \\min_{g \\in \\{1, \\dots, G\\}} \\frac{1}{|\\mathcal{I}_g|} \\sum_{i \\in \\mathcal{I}_g} \\mathbb{I}\\{ Y_i \\in \\mathcal{C}(X_i) \\}\n\\]\n\n만약 완벽한 Conditional Coverage라면, 이 값은 \\(1-\\alpha\\)에 근접해야 합니다.\n이 값이 \\(1-\\alpha\\)보다 현저히 낮다면, 특정 그룹(예: 야간 주행 이미지)에서 모델이 실패하고 있음을 의미합니다.\n\n\n\n2.2 Size-stratified Coverage (SSC)\n\n하지만 어떤 Feature가 중요한지 모를 때는 어떻게 할까요?\n이때 사용할 수 있는 아주 일반적이고 강력한 방법이 “예측 집합의 크기”로 그룹을 나누는 것입니다.\n\n그룹 1: 집합 크기가 1인 데이터들 (\\(\\mathcal{C}(x)| = 1\\))\n그룹 2: 집합 크기가 2인 데이터들\n…\n\n모델이 “이건 정말 어려워서 후보를 10개나 뽑았어”라고 말한 경우(집합 크기 10), 실제로도 그 안에 정답이 90% 확률로 들어 있어야 합니다.\n\n\\[\n\\text{SSC metric} = \\min_{g \\in \\{ \\text{set sizes} \\}} \\frac{1}{|\\mathcal{I}_g|} \\sum_{i \\in \\mathcal{I}_g} \\mathbb{I}\\{ Y_i \\in \\mathcal{C}(X_i) \\}\n\\]\n\n이 지표는 사용자가 사전에 그룹을 정의할 필요가 없으므로(Feature-agnostic), 어떤 상황에서도 바로 적용해볼 수 있는 훌륭한 진단 도구입니다.\n\n\n\n\nSummary\n\nConformal Prediction을 평가할 때는 단순히 전체 커버리지만 보지 말고, 다음을 꼭 확인해야합니다:\n\n\nHistogram of Set Sizes: 쉬운 건 작게, 어려운 건 크게 잘 구분하고 있는가?\n\n\nStratified Coverage (FSC / SSC): 특정 그룹(인종, 나이, 혹은 모델이 불확실해하는 그룹)에서만 커버리지가 깨지고 있지는 않은가?\n\n\n이러한 Adaptivity 체크는 실험실 환경을 넘어 실제 서비스(Production)에 CP를 적용할 때 “Non-negotiable(타협할 수 없는)” 필수 검증 단계입니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#the-effect-of-the-size-of-the-calibration-set",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#the-effect-of-the-size-of-the-calibration-set",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "3.2. The Effect of the Size of the Calibration Set",
    "text": "3.2. The Effect of the Size of the Calibration Set\n\nIntroduction\n\nConformal Prediction(CP)을 실제 서비스에 배포할 때, 엔지니어가 가장 먼저 마주하는 실무적인 질문은 이것입니다.\n\n\n“Calibration Set(\\(n\\))의 크기는 얼마나 커야 할까요? 100개면 충분한가요, 아니면 1,000개가 필요한가요?”\n\n\n이론적으로 CP의 커버리지 보장(\\(1-\\alpha\\))은 \\(n\\)의 크기와 상관없이 성립합니다(Finite-sample guarantee).\n하지만 직관적으로 생각했을 때, 데이터가 많을수록 더 안정적일 것이라 예상할 수 있습니다.\n이번 포스트에서는 Calibration Set의 크기 \\(n\\)이 예측 구간의 안정성(Stability)에 미치는 영향을 수학적으로 분석하고, 실무적인 가이드라인(\\(n \\approx 1000\\))을 제시합니다.\n\n\n\nValidity vs. Stability\n\nThe Theoretical Guarantee (Validity)\n\n놀랍게도, CP의 커버리지 보장 정리(Theorem 1)는 모든 \\(n\\)에 대해 성립합니다.\nCalibration 데이터가 단 10개뿐이라도, 새로운 데이터에 대한 평균 커버리지는 \\(1-\\alpha\\)를 만족합니다.\n\n\n\nThe Catch (Stability)\n\n하지만 여기에는 중요한 디테일이 숨어 있습니다.\n우리가 보장하는 것은 “Calibration Set을 무한히 새로 뽑았을 때의 평균”입니다.\n하지만 현실에서 우리는 단 하나의 고정된 Calibration Set을 사용합니다.\n만약 우리가 운이 나빠서 이상한(Bias된) 데이터가 섞인 Calibration Set을 뽑았다면 어떨까요?\n이 고정된 데이터셋으로 학습된 CP 모델을 무한한 테스트 데이터에 적용했을 때의 실제 커버리지는 \\(1-\\alpha\\)와 정확히 일치하지 않을 수 있습니다.\n즉, Calibration Set 자체의 무작위성(Randomness) 때문에 실제 커버리지는 확률 변수(Random Quantity)가 됩니다.\n\n\n\n\nMathematical Derivation: Beta Distribution\n\nVladimir Vovk는 고정된 Calibration Set이 주어졌을 때, 무한한 검증 데이터에 대한 커버리지 확률 분포가 베타 분포(Beta Distribution)를 따른다는 것을 증명했습니다.\n\n\\[\n\\mathbb{P}(Y_{test} \\in \\mathcal{C}(X_{test}) \\mid \\{(X_i, Y_i)\\}_{i=1}^n) \\sim \\text{Beta}(n+1-l, l)\n\\]\n\n여기서 파라미터 \\(l\\)은 다음과 같이 정의됩니다: \\[\nl = \\lfloor (n+1)\\alpha \\rfloor\n\\]\n\n의미: 이 식은 \\(n\\)이 커질수록 커버리지 확률 분포가 \\(1-\\alpha\\)를 중심으로 얼마나 뾰족하게(Sharp) 모이는지를 설명합니다.\n평균: 베타 분포의 성질에 의해 이 분포의 기댓값은 정확히 \\(1-\\alpha\\)가 됩니다 (Validity).\n분산: \\(n\\)이 작을수록 분산이 커져서, 실제 커버리지가 목표치 \\(1-\\alpha\\)에서 크게 벗어날 확률이 높아집니다.\n\n\n\n\nVisualizing the Effect of \\(n\\)\n\n이 현상을 시각적으로 확인해보겠습니다.\n아래 그래프는 Calibration Set의 크기 \\(n\\)에 따른 커버리지 확률의 밀도 함수를 보여줍니다.\n\n\n\n\nFigure: 무한한 Validation Set에 대한 커버리지 분포. \\(n\\)이 100일 때는 분포가 넓게 퍼져 있지만, \\(n\\)이 10,000일 때는 \\(1-\\alpha(0.9)\\) 근처에 매우 좁게 집중된다. 분포는 \\(\\mathcal{O}(n^{-1/2})\\)의 속도로 수렴한다.\n\n\n\n\\(n=100\\) (파란색): 그래프가 넓게 퍼져 있습니다. 운이 나쁘면 실제 커버리지가 85%나 95%가 될 수도 있습니다.\n\\(n=1,000\\) (주황색): 그래프가 훨씬 좁아졌습니다. 대부분의 경우 커버리지가 88% ~ 92% 사이로 유지됩니다.\n\\(n=10,000\\) (초록색): 매우 뾰족합니다. 거의 정확하게 90%를 맞춥니다.\n\n\n\nPractical Guideline: The “n=1000” Rule\n\n그렇다면 실무에서는 몇 개를 써야 할까요?\n논문에서는 \\(n=1000\\) 정도면 대부분의 목적에 충분하다고 제안합니다.\n\n\n안정성 확보: 위 그래프에서 보듯이, \\(n=1000\\)일 때 커버리지는 목표치(\\(1-\\alpha\\))에서 \\(\\pm 2\\%\\) 내외의 오차 범위를 가집니다. 이는 대부분의 머신러닝 애플리케이션에서 허용 가능한 수준입니다.\n\n\n비용 효율성: 데이터를 10,000개까지 늘려도 얻을 수 있는 이득(오차 감소)은 크지 않습니다. (수렴 속도가 \\(\\mathcal{O}(n^{-1/2})\\)로 느려지기 때문)\n\n\n\n\nRequired Sample Size Calculation\n\n만약 더 엄격한 기준(예: 99% 확률로 오차 1% 이내)이 필요하다면, 다음 표를 참고하여 필요한 \\(n\\)을 역산할 수 있습니다.\n\n\n\n\n허용 오차 (\\(\\epsilon\\))\n필요한 \\(n\\) (신뢰도 90%)\n\n\n\n\n0.1 (10%)\n22\n\n\n0.05 (5%)\n102\n\n\n0.01 (1%)\n2,491\n\n\n0.005 (0.5%)\n9,812\n\n\n\n\n일반적인 기준인 90% 신뢰도(\\(\\delta=0.1\\))에서 목표 커버리지와의 오차를 1%(\\(\\epsilon=0.01\\)) 이내로 줄이려면 약 2,500개의 데이터가 필요합니다.\n하지만 5% 오차(\\(\\epsilon=0.05\\))를 허용한다면 102개로도 충분합니다.\n\n\n\n\nSummary\n\nConformal Prediction은 \\(n\\)이 작아도 평균적으로는 커버리지를 보장합니다.\n하지만 개별 Calibration Set에 대한 신뢰도(Stability)를 높이기 위해서는 충분한 \\(n\\)이 필요합니다.\nRule of Thumb: 약 1,000개의 Calibration 데이터를 사용하면, 실제 커버리지가 목표치에서 크게 벗어나지 않음(약 \\(\\pm 2\\%\\))을 확신할 수 있습니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#checking-for-correct-coverage",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#checking-for-correct-coverage",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "3.3. Checking for Correct Coverage",
    "text": "3.3. Checking for Correct Coverage\n\nIntroduction\n\nConformal Prediction(CP)을 구현했다면, 가장 먼저 해야 할 일은 “이게 정말 작동하는가?”를 확인하는 것입니다.\n즉, 우리가 설정한 목표 커버리지(예: 90%)가 실제 테스트 데이터에서도 지켜지는지 검증해야 합니다.\n하지만 단순히 한 번의 테스트 셋 결과만 보고 “90.1%니까 성공!”이라고 단정 짓기는 어렵습니다.\n데이터의 무작위성 때문에 우연히 잘 나왔을 수도, 우연히 못 나왔을 수도 있기 때문입니다.\n따라서 우리는 여러 번의 실험(Trials)을 통해 커버리지 분포를 확인해야 합니다.\n\n\n\nMethodology: Repeated Experiments\n\n가장 확실한 검증 방법은 \\(R\\)번의 독립적인 실험을 수행하는 것입니다.\n각 실험 \\(j=1, \\dots, R\\)마다 새로운 Calibration Set과 Validation Set을 준비하고, 다음 과정을 반복합니다:\n\n\nCalibration 수행 \\(\\rightarrow\\) \\(\\hat{q}_j\\) 계산\n\n\nValidation Set에 대해 예측 집합 구성 \\(\\mathcal{C}_j\\)\n\n\n경험적 커버리지(Empirical Coverage) \\(C_j\\) 계산:\n\n\n\n\\[\nC_j = \\frac{1}{n_{val}} \\sum_{i=1}^{n_{val}} \\mathbb{I} \\{ Y_{i,j}^{(val)} \\in \\mathcal{C}_j(X_{i,j}^{(val)}) \\}\n\\]\n\n이렇게 얻은 \\(R\\)개의 커버리지 값들 \\(C_1, \\dots, C_R\\)의 평균 \\(\\overline{C}\\)는 이론적으로 \\(1-\\alpha\\)에 매우 근접해야 합니다.\n\n\\[\n\\overline{C} = \\frac{1}{R} \\sum_{j=1}^{R} C_j \\approx 1 - \\alpha\n\\]\n\n또한, \\(C_j\\)들의 히스토그램을 그렸을 때 \\(1-\\alpha\\)를 중심으로 종 모양(Bell-curve) 분포를 보여야 합니다.\n\n\n\nThe Practical Challenge: Limited Data\n\n현실적인 문제는 “매번 새로운 데이터를 어디서 구하는가?”입니다.\n우리가 가진 데이터는 유한(총 \\(n_{total} = n + n_{val}\\))하므로, \\(R\\)번이나 새로운 데이터를 수집할 수는 없습니다.\n따라서 우리는 Resampling (Random Split) 방식을 사용합니다.\n전체 데이터를 무작위로 섞어서 Calibration/Validation 셋으로 나누는 과정을 \\(R\\)번 반복하는 것입니다.\n\n\nEfficiency Trick: Score Caching\n\n하지만 \\(R\\)번(예: 100번)이나 모델을 다시 학습시키거나 추론(Inference)을 돌리는 것은 계산 비용이 매우 큽니다.\n여기서 중요한 팁은 Conformal Score를 미리 계산해두는 것(Caching)입니다.\nCP 알고리즘은 Score값(\\(s_i\\))들의 순위에만 의존합니다.\n데이터가 어느 셋(Calibration vs Validation)에 속하느냐에 따라 역할만 달라질 뿐, 각 데이터 포인트의 Score 값 자체는 변하지 않습니다.\n따라서 다음과 같이 효율적으로 검증할 수 있습니다:\n\n\nPre-computation: 전체 데이터에 대해 Score를 미리 한 번만 계산합니다.\n\n\nShuffle & Split: 계산된 Score 배열만 무작위로 섞어서 나눕니다.\n\n\nEvaluate: 나누어진 Score들로 Quantile을 구하고 커버리지를 계산합니다.\n\n\n이 방식을 사용하면 딥러닝 모델을 매번 돌릴 필요가 없어 검증 속도가 수백 배 빨라집니다.\n\n\n\n\nImplementation\n\nPython 코드로 이를 구현하면 다음과 같습니다.\n\n\n\n\nFigure: Score Caching을 이용한 효율적인 커버리지 검증 코드. 전체 Score를 미리 계산해두고(get_scores), 반복문 안에서는 단순히 배열을 섞고(shuffle) 자르는 연산만 수행한다.\n\n\n\nCode Explanation\n\n\nLoad/Compute Scores: get_scores(X, Y)를 통해 모든 데이터의 Score를 계산하고 저장합니다.\n\n\nLoop \\(R\\) times:\n\n\nnp.random.shuffle(scores): Score들을 섞습니다.\ncalib, val = scores[:n], scores[n:]: \\(n\\)개는 Calibration용, 나머지는 검증용으로 나눕니다.\nqhat: Calibration Score들로 Quantile을 계산합니다.\nmean(): Validation Score들이 qhat보다 작은 비율(Coverage)을 계산합니다.\n\n\nCheck: coverages.mean()이 \\(1-\\alpha\\)와 비슷한지 확인하고, 히스토그램을 그립니다.\n\n\n\n\n\nInterpretation of Results\n\n검증 결과 커버리지가 정확히 90.00%가 나오지 않더라도 당황할 필요는 없습니다.\n\\(n\\) (Calibration 크기), \\(n_{val}\\) (Validation 크기), \\(R\\) (반복 횟수)이 모두 유한하기 때문에 약간의 변동(Benign Fluctuations)은 자연스러운 현상입니다.\n정상: 평균이 0.89 ~ 0.91 사이이며 히스토그램이 0.9 근처에 모여 있음.\n비정상: 평균이 0.80처럼 현저히 낮거나, 히스토그램이 한쪽으로 크게 치우침 \\(\\rightarrow\\) 구현 오류(버그) 혹은 데이터 분포의 문제(i.i.d. 위반 등)를 의심해야 합니다.\n이 진단 과정을 통과했다면, 여러분의 Conformal Predictor는 통계적으로 신뢰할 수 있는 상태입니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#group-balanced-conformal-prediction",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#group-balanced-conformal-prediction",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "4.1. Group-Balanced Conformal Prediction",
    "text": "4.1. Group-Balanced Conformal Prediction\n\nIntroduction: The Fairness Problem\n\n지금까지 우리는 전체 데이터셋에 대해 평균적으로 \\(1-\\alpha\\)의 커버리지를 보장하는 방법(Marginal Coverage)을 배웠습니다.\n하지만 현실 세계, 특히 의료나 금융 같은 민감한 분야에서는 “평균적인 성공”만으로는 충분하지 않습니다.\n예를 들어, 어떤 질병 진단 AI가 백인 환자에게는 99%의 정확도를 보이지만, 유색 인종 환자에게는 80%의 정확도밖에 보이지 않는다고 가정해봅시다.\n이 경우 백인 환자가 다수라면 전체 평균 정확도는 90%를 넘길 수 있겠지만, 이는 공정하지 못한(Unfair) 시스템입니다.\nGroup-Balanced Conformal Prediction은 이러한 문제를 해결하기 위해, 데이터 내의 특정 그룹(인종, 성별, 연령대 등) 각각에 대해 독립적으로 커버리지를 보장하는 기법입니다.\n\n\n\nProblem Formulation\n\n우리의 입력 데이터 \\(X\\)의 첫 번째 특성(Feature) \\(X_{i,1}\\)이 그룹을 나타내는 범주형 변수라고 가정해봅시다.\n이 그룹은 \\(\\{1, \\dots, G\\}\\) 중 하나의 값을 가집니다.\n기존의 CP는 다음을 보장했습니다: \\[ \\mathbb{P}(Y_{test} \\in \\mathcal{C}(X_{test})) \\ge 1-\\alpha \\]\n하지만 우리가 원하는 것은 모든 그룹 \\(g\\)에 대해 다음이 성립하는 것입니다:\n\n\\[\n\\mathbb{P}(Y_{test} \\in \\mathcal{C}(X_{test}) \\mid X_{test,1} = g) \\ge 1-\\alpha, \\quad \\forall g \\in \\{1, \\dots, G\\}\n\\]\n\n즉, 어떤 그룹에 속한 데이터가 들어오더라도 똑같이 \\(1-\\alpha\\) 이상의 확률로 정답을 포함해야 합니다.\n\n\n\nThe Algorithm\n\n이 문제를 해결하는 방법은 직관적입니다. “그룹별로 따로따로 Conformal Prediction을 수행”하는 것입니다.\n\n\nStep 1: Stratify Calibration Data\n\nCalibration 데이터셋을 그룹별로 나눕니다.\n그룹 \\(g\\)에 속하는 데이터들만 모아서 부분집합을 만듭니다.\n\n\\[\nS^{(g)} = \\{ (X_j, Y_j) : X_{j,1} = g \\}\n\\]\n\n\nStep 2: Calibrate per Group\n\n각 그룹 \\(g\\)에 대해 독립적으로 Quantile \\(\\hat{q}^{(g)}\\)를 계산합니다.\n\n그룹 \\(g\\) 데이터에 대한 Conformal Score들을 계산합니다: \\[s^{(g)}_1, \\dots, s^{(g)}_{n^{(g)}}\\]\n\n\n해당 그룹의 데이터 개수 \\(n^{(g)}\\)를 기준으로 보정된 분위수를 구합니다: \\[\n\\hat{q}^{(g)} = \\text{Quantile}\\left( \\frac{\\lceil (n^{(g)}+1)(1-\\alpha) \\rceil}{n^{(g)}} ; \\{s^{(g)}_1, \\dots, s^{(g)}_{n^{(g)}}\\} \\right)\n\\]\n\n결과적으로 우리는 그룹의 개수만큼 서로 다른 임계값(Threshold) \\(\\hat{q}^{(1)}, \\dots, \\hat{q}^{(G)}\\)를 얻게 됩니다.\n\n모델이 잘 맞추는 쉬운 그룹은 \\(\\hat{q}\\)가 작을 것이고 (작은 예측 집합),\n모델이 어려워하는 그룹은 \\(\\hat{q}\\)가 클 것입니다 (큰 예측 집합).\n\n\n\n\nStep 3: Inference\n\n새로운 테스트 데이터 \\(X_{test}\\)가 들어오면, 먼저 이 데이터가 어느 그룹에 속하는지(\\(X_{test,1}\\)) 확인합니다.\n그리고 해당 그룹에 맞는 임계값 \\(\\hat{q}^{(X_{test,1})}\\)을 사용하여 예측 집합을 구성합니다.\n\n\\[\n\\mathcal{C}(x) = \\{ y : s(x, y) \\le \\hat{q}^{(x_1)} \\}\n\\]\n\n\n\nFigure: Group-Balanced Conformal Prediction의 개념도. 전체 데이터를 파란색 그룹과 초록색 그룹으로 나누고, 각각의 분포(Histogram)에서 별도의 Quantile \\(\\hat{q}^{(1)}, \\hat{q}^{(2)}\\)를 계산하여 적용한다.\n\n\n\n\n\nTheoretical Guarantee\n\n이 방법은 Vovk에 의해 처음 제안되었으며, 다음의 명제에 의해 수학적으로 정당화됩니다.\n\n\nProposition 1 (Error control guarantee for group-balanced conformal prediction)\n데이터가 i.i.d. 가정하에 추출되었다면, 위 알고리즘을 통해 생성된 예측 집합 \\(\\mathcal{C}\\)는 모든 그룹 \\(g\\)에 대해 다음을 만족한다.\n\\[ \\mathbb{P}(Y_{test} \\in \\mathcal{C}(X_{test}) \\mid X_{test,1} = g) \\ge 1-\\alpha \\]\n\n\n이로써 우리는 인종, 성별 등 민감한 속성에 관계없이 모든 사용자에게 동등한 수준의 안전장치(Equal Coverage)를 제공할 수 있게 됩니다.\n\n\n\nPractical Note\n\nExplicit Groups: 인종, 성별처럼 데이터에 명시적으로 존재하는 카테고리를 사용할 수 있습니다.\nConstructed Groups (Binning): 나이(Age)와 같은 연속형 변수라도, ‘20대’, ‘30대’ 등으로 구간화(Binning)하여 그룹을 만든 뒤 이 방법을 적용할 수 있습니다. 이를 통해 연속적인 특성에 대한 Conditional Coverage를 근사할 수 있습니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#class-conditional-conformal-prediction",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#class-conditional-conformal-prediction",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "4.2. Class-Conditional Conformal Prediction",
    "text": "4.2. Class-Conditional Conformal Prediction\n\nIntroduction: The Problem with Imbalanced Classes\n\n머신러닝 분류 문제, 특히 의료 진단과 같은 분야에서는 클래스 불균형(Class Imbalance)이 흔하게 발생합니다.\n예를 들어, 암 진단 모델을 개발한다고 가정해봅시다.\n\n정상(Normal): 데이터의 95%\n암(Cancer): 데이터의 5%\n\n우리가 일반적인 Conformal Prediction을 사용하여 95% 커버리지를 달성했다고 칩시다.\n가장 쉬운 달성 방법은 무엇일까요?\n“그냥 모든 환자를 ’정상’이라고 예측하고, 암 환자는 다 틀리는 것”입니다.\n이렇게 해도 (정상 95% + 암 0%) / 100% \\(\\approx\\) 95% 커버리지는 달성됩니다.\n하지만 이는 재앙입니다.\n우리는 암 환자에 대해서도 똑같이 95%의 정확도로 정답을 포함시키기를 원합니다.\nClass-Conditional Conformal Prediction은 바로 이 문제, 즉 모든 정답 클래스(Ground Truth Class)에 대해 균등한 커버리지를 보장하기 위한 방법입니다.\n\n\n\nProblem Formulation\n\n우리의 목표는 단순한 전체 평균(\\(1-\\alpha\\))이 아니라, 각 클래스 \\(y \\in \\{1, \\dots, K\\}\\) 별로 조건부 커버리지를 만족하는 것입니다.\n\n\\[\n\\mathbb{P}(Y_{test} \\in \\mathcal{C}(X_{test}) \\mid Y_{test} = y) \\ge 1-\\alpha, \\quad \\forall y \\in \\{1, \\dots, K\\}\n\\]\n\n이것이 보장된다면, “암 환자” 그룹 내에서도 정답이 예측 집합에 포함될 확률이 95% 이상이 되고, “정상인” 그룹 내에서도 마찬가지가 됩니다.\n\n\n\nThe Algorithm\n\n알고리즘은 Group-Balanced CP와 유사하게 “따로따로(Separately)” 전략을 취하지만, 추론(Inference) 단계에서 중요한 차이가 있습니다.\n\n\nStep 1: Stratify Calibration Data by Class\n\nCalibration 데이터셋을 실제 정답 클래스(Ground Truth Class)별로 나눕니다.\n\n\\[\nS^{(k)} = \\{ (X_j, Y_j) : Y_j = k \\}\n\\]\n\n\nStep 2: Calibrate per Class\n\n각 클래스 \\(k\\)에 대해 독립적으로 Quantile \\(\\hat{q}^{(k)}\\)를 계산합니다.\n\n\n클래스 \\(k\\)에 속하는 데이터들의 Score \\(s^{(k)}_1, \\dots, s^{(k)}_{n^{(k)}}\\)를 모읍니다.\n\n\n해당 클래스의 데이터 수 \\(n^{(k)}\\)를 기준으로 보정된 분위수를 구합니다: \\[\n\\hat{q}^{(k)} = \\text{Quantile}\\left( \\frac{\\lceil (n^{(k)}+1)(1-\\alpha) \\rceil}{n^{(k)}} ; \\{s^{(k)}_1, \\dots, s^{(k)}_{n^{(k)}}\\} \\right)\n\\]\n\n\n결과적으로 우리는 클래스 개수만큼의 임계값 \\(\\hat{q}^{(1)}, \\dots, \\hat{q}^{(K)}\\)를 얻습니다.\n\n샘플이 적거나 모델이 어려워하는 클래스(예: 암)는 임계값이 높게(보수적으로) 설정될 것입니다.\n\n\n\n\nStep 3: Inference (Iterative Check)\n\n이 부분이 4.1절(Group-Balanced)과 가장 다릅니다.\n테스트 시점에는 입력 \\(X_{test}\\)의 진짜 클래스(True Class)가 무엇인지 모릅니다.\n따라서 “해당 그룹의 \\(\\hat{q}\\)를 가져다 쓰는” 방식은 불가능합니다.\n대신, 우리는 “만약 정답이 클래스 \\(y\\)라면?”이라는 가정을 모든 후보 클래스에 대해 수행합니다.\n예측 집합 \\(\\mathcal{C}(x)\\)는 다음 조건을 만족하는 모든 클래스 \\(y\\)를 포함합니다: \\[\n\\mathcal{C}(x) = \\{ y : s(x, y) \\le \\hat{q}^{(y)} \\}\n\\]\n\n후보 클래스 \\(y\\)가 ‘암’이라면? \\(\\rightarrow\\) \\(s(x, \\text{암})\\)을 계산하고, 이를 ’암’ 클래스의 임계값 \\(\\hat{q}^{(\\text{암})}\\)과 비교합니다.\n후보 클래스 \\(y\\)가 ‘정상’이라면? \\(\\rightarrow\\) \\(s(x, \\text{정상})\\)을 계산하고, 이를 ’정상’ 클래스의 임계값 \\(\\hat{q}^{(\\text{정상})}\\)과 비교합니다.\n\n각 클래스마다 자신만의 기준(Threshold)을 통과해야 집합에 들어갈 수 있는 것입니다.\n\n\n\n\nFigure: Class-Conditional Conformal Prediction의 개념도. Calibration 데이터를 색깔(클래스)별로 나누어 각각의 분포 \\(\\hat{q}^{(1)}, \\hat{q}^{(2)}\\)를 구한다. 추론 시에는 각 후보 클래스 \\(y\\)가 자신의 기준 \\(\\hat{q}^{(y)}\\)를 만족하는지 확인한다.\n\n\n\n\n\nComparison: Group-Balanced vs. Class-Conditional\n\n이 두 가지 확장의 차이를 명확히 구분하는 것이 중요합니다.\n\n\n\n\n\n\n\n\n\n특징\nGroup-Balanced (4.1)\nClass-Conditional (4.2)\n\n\n\n\n기준 (Condition)\n입력 특성 (Input Feature \\(X_{:,1}\\))\n출력 라벨 (Output Label \\(Y\\))\n\n\n정보 가용성\n테스트 시점에 \\(X\\)를 통해 그룹을 알 수 있음\n테스트 시점에 \\(Y\\)를 알 수 없음\n\n\n적용 방식\n그룹을 확인하고 \\(\\rightarrow\\) 해당 그룹의 \\(\\hat{q}\\) 적용\n모든 \\(y\\)에 대해 순회하며 \\(\\rightarrow\\) 각자의 \\(\\hat{q}^{(y)}\\) 적용\n\n\n주요 사용처\n공정성 (인종, 성별 간 평등)\n불균형 데이터 (희귀 클래스 탐지)\n\n\n\n\n\nTheoretical Guarantee\n\nVovk의 증명에 따르면, 이 방법 또한 수학적으로 엄밀한 커버리지를 보장합니다.\n\n\nProposition 2 (Error control guarantee for class-balanced conformal prediction)\n데이터가 i.i.d.라면, 위 알고리즘으로 생성된 집합 \\(\\mathcal{C}\\)는 모든 클래스 \\(y\\)에 대해 다음을 만족한다.\n\\[ \\mathbb{P}(Y_{test} \\in \\mathcal{C}(X_{test}) \\mid Y_{test} = y) \\ge 1-\\alpha \\]\n\n\n\nConclusion\n\nClass-Conditional CP는 불균형한 데이터셋에서 소수 클래스(Minority Class)의 성능을 희생하지 않기 위한 필수적인 기법입니다.\n비록 소수 클래스의 데이터가 적어서 \\(\\hat{q}\\)가 커지고(불확실성이 커지고), 결과적으로 예측 집합의 크기가 커질 수는 있습니다.\n하지만 이는 “틀리는 것”보다는 훨씬 낫습니다. 우리는 적어도 그 안에 정답이 있다는 확신(Safety)을 가질 수 있기 때문입니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#conformal-risk-control",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#conformal-risk-control",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "4.3. Conformal Risk Control",
    "text": "4.3. Conformal Risk Control\n\nIntroduction: Beyond Coverage\n\n지금까지 우리가 다룬 Conformal Prediction의 핵심 보장은 다음과 같은 형태였습니다.\n\n\\[ \\mathbb{P}(Y_{test} \\notin \\mathcal{C}(X_{test})) \\le \\alpha \\]\n\n즉, “정답을 놓칠 확률(Miscoverage rate)”을 \\(\\alpha\\) 이하로 묶는 것이었습니다.\n하지만 현실의 많은 머신러닝 문제에서는 단순히 “맞았다/틀렸다”의 이진(Binary) 에러보다 더 복잡한 손실(Loss)을 제어해야 할 때가 많습니다.\n\n의료 영상 분할(Tumor Segmentation): 암 영역을 조금이라도 놓치면(False Negative) 치명적입니다. 픽셀 단위의 재현율(Recall)을 보장해야 할 수 있습니다.\n다중 라벨 분류(Multilabel Classification): 여러 개의 태그 중 90% 이상을 맞추기를 원할 수 있습니다 (F1-score 등).\n\nConformal Risk Control (CRC)은 이러한 요구를 반영하여, 임의의 유계 손실 함수(Bounded Loss Function)의 기댓값을 제어하는 기법입니다.\n\n\\[\n\\mathbb{E}[l(\\mathcal{C}(X_{test}), Y_{test})] \\le \\alpha\n\\]\n\n\nProblem Formulation\n\n우리의 목표는 모델의 출력 집합 \\(\\mathcal{C}(X)\\)가 커질수록 손실(Loss)이 줄어드는 상황에서, 기대 손실(Expected Risk)이 사용자 지정 허용치 \\(\\alpha\\) 이하가 되도록 하는 파라미터를 찾는 것입니다.\n\n\nKey Components\n\n\nNested Sets (\\(\\mathcal{C}_\\lambda\\)):\n\n\n우리는 파라미터 \\(\\lambda\\)를 조절하여 예측 집합의 크기(보수적인 정도)를 조절합니다.\n\\(\\lambda\\)가 커질수록 예측 집합 \\(\\mathcal{C}_\\lambda(x)\\)는 더 커지고(더 많은 후보를 포함), 따라서 더 안전해집니다(Conservative).\n\n\nMonotone Loss Function (\\(l\\)):\n\n\n손실 함수 \\(l(\\mathcal{C}, Y)\\)는 집합 \\(\\mathcal{C}\\)가 커질수록 감소하거나 같아야 합니다 (Non-increasing).\n또한, 손실값은 어떤 상한선 \\(B\\)를 넘지 않아야 합니다 (\\(l \\in (-\\infty, B]\\)).\n\n\\[ \\lambda_1 \\le \\lambda_2 \\implies l(\\mathcal{C}_{\\lambda_1}(x), y) \\ge l(\\mathcal{C}_{\\lambda_2}(x), y) \\]\n\n\n\n\nThe Algorithm\n\nCRC의 알고리즘은 기존 CP와 매우 유사하지만, Quantile 대신 경험적 리스크(Empirical Risk)를 사용한다는 점이 다릅니다.\n\n\nStep 1: Calculate Empirical Risk\n\nCalibration 데이터셋 \\((X_1, Y_1), \\dots, (X_n, Y_n)\\)에 대해, 특정 파라미터 \\(\\lambda\\)를 썼을 때의 평균 손실(Empirical Risk)을 계산하는 함수 \\(\\hat{R}(\\lambda)\\)를 정의합니다.\n\n\\[\n\\hat{R}(\\lambda) = \\frac{1}{n} \\sum_{i=1}^{n} l(\\mathcal{C}_{\\lambda}(X_i), Y_i)\n\\]\n\n이 함수는 \\(\\lambda\\)가 증가함에 따라 손실이 감소하는 우하향 곡선을 그립니다.\n\n\n\nStep 2: Find Optimal \\(\\lambda\\)\n\n우리는 기대 손실이 \\(\\alpha\\) 이하가 되기를 원합니다.\n하지만 유한한 데이터(\\(n\\))로 인한 불확실성을 고려해야 하므로, 단순히 \\(\\hat{R}(\\lambda) \\le \\alpha\\)가 되는 지점을 찾으면 안 됩니다.\n대신, 다음과 같이 보정된 기준(Conservative Target)을 사용합니다.\n\n\\[\n\\hat{\\lambda} = \\inf \\left\\{ \\lambda : \\hat{R}(\\lambda) \\le \\alpha - \\frac{B - \\alpha}{n} \\right\\}\n\\]\n\n\\(B\\): 손실 함수의 최댓값 (Upper Bound)\nCorrection Term (\\(\\frac{B-\\alpha}{n}\\)): 데이터 개수 \\(n\\)이 적을 때 더 보수적으로 \\(\\lambda\\)를 선택하게 만드는 항입니다. \\(n\\)이 무한대로 가면 이 항은 0이 되어 \\(\\alpha\\)에 수렴합니다.\n\n\n\n\nFigure: Conformal Risk Control의 개념도. 파란색 실선은 \\(\\lambda\\)에 따른 경험적 리스크 \\(\\hat{R}(\\lambda)\\)를 나타낸다. 목표 리스크 \\(\\alpha\\)에서 보정항 \\(\\frac{B-\\alpha}{n}\\)만큼을 뺀 점선과 만나는 지점에서 \\(\\hat{\\lambda}\\)를 결정한다.\n\n\n\n\n\nExample: Multilabel Classification\n\n다중 라벨 분류 문제를 예로 들어보겠습니다.\n하나의 이미지가 ‘사람’, ‘차’, ‘신호등’ 등 여러 클래스(\\(Y_i \\subseteq \\{1, \\dots, K\\}\\))를 가질 수 있습니다.\n\nPrediction Set:\n\n\n모델이 각 클래스에 대해 예측한 점수 \\(f(X)_k\\)가 임계값 \\(1-\\lambda\\) 이상인 클래스들을 담습니다. \\[ \\mathcal{C}_\\lambda(x) = \\{ k : f(x)_k \\ge 1-\\lambda \\} \\]\n\n\\(\\lambda\\)가 클수록 임계값이 낮아져 더 많은 클래스가 선택됨\n\n\n\nLoss Function:\n\n\n“전체 정답 태그 중 놓친 태그의 비율”을 손실로 정의합니다. \\[ l(\\mathcal{C}, Y) = 1 - \\frac{|Y \\cap \\mathcal{C}|}{|Y|} \\]\n이 값은 0(모두 맞춤)과 1(하나도 못 맞춤) 사이이므로 \\(B=1\\)입니다.\n\n\nApplying CRC:\n\n\n사용자가 \\(\\alpha=0.1\\)로 설정했다면, 위 알고리즘을 통해 구한 \\(\\hat{\\lambda}\\)를 사용했을 때 “평균적으로 정답 태그의 90% 이상을 포함”하는 예측 집합을 얻게 됩니다.\n\n\n\n\nTheoretical Guarantee\n\n이 알고리즘은 다음 정리에 의해 수학적으로 보장됩니다.\n\n\nTheorem 2 (Conformal Risk Control)\n데이터가 i.i.d.이고 손실 함수가 단조 감소(Monotone)한다면, 위 알고리즘으로 선택된 \\(\\hat{\\lambda}\\)에 대해 다음이 성립한다.\n\\[ \\mathbb{E}[l(\\mathcal{C}_{\\hat{\\lambda}}(X_{test}), Y_{test})] \\le \\alpha \\]\n\n\n이 정리는 CP가 단순히 “에러율 제어”를 넘어, FNR, False Discovery Rate 등 비즈니스에 중요한 다양한 KPI를 직접 제어할 수 있는 도구로 확장됨을 의미합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#outlier-detection",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#outlier-detection",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "4.4. Outlier Detection",
    "text": "4.4. Outlier Detection\n\nIntroduction: Unsupervised Setting\n\n이전까지 우리는 입력 \\(X\\)와 정답 \\(Y\\)가 있는 지도 학습 환경을 다루었습니다.\n하지만 \\(Y\\) 라벨이 없는 경우, 특히 “정상 데이터 분포에서 벗어난 이상치(Outlier)”를 탐지해야 하는 상황은 어떻게 해야 할까요?\n\n공장 설비의 이상 진동 감지\n네트워크 침입 탐지\n불량품 검출\n\n이러한 Outlier Detection (Anomaly Detection) 문제에서도 Conformal Prediction을 활용하면, “정상 데이터를 이상치라고 오판할 확률(False Positive Rate)”을 통계적으로 제어할 수 있습니다.\n\n\n\nProblem Formulation\n\n우리는 오염되지 않은 깨끗한 데이터(Clean Dataset) \\(X_1, \\dots, X_n\\)을 가지고 있습니다.\n이들은 모두 정상(Inlier) 분포에서 나왔다고 가정합니다.\n우리의 목표는 새로운 데이터 \\(X_{test}\\)가 들어왔을 때, 이것이 정상 분포에서 온 것인지 아니면 이상치인지 판단하는 함수 \\(\\mathcal{C}\\)를 만드는 것입니다.\n이때, 실제로는 정상인데 이상치라고 잘못 판단할 확률(Type I Error)을 \\(\\alpha\\) 이하로 억제해야 합니다. \\[\n\\mathbb{P}(\\mathcal{C}(X_{test}) = \\text{outlier}) \\le \\alpha\n\\]\n\n여기서 확률은 \\(X_{test}\\)가 정상 데이터 분포에서 왔을 때의 확률입니다.\n\n\n\n\nThe Algorithm\n\n알고리즘은 기존의 Conformal Prediction과 매우 유사하지만, \\(Y\\)가 없기 때문에 입력 \\(X\\)만으로 계산되는 Score를 사용합니다.\n\n\nStep 1: Define Heuristic Score Function\n\n비지도 학습 모델(예: One-class SVM, Isolation Forest, Autoencoder의 Reconstruction Error 등)을 사용하여, 데이터 포인트가 이상치일수록 커지는 점수 함수 \\(s(x)\\)를 정의합니다. \\[ s(x): \\mathcal{X} \\rightarrow \\mathbb{R} \\]\n\n\\(s(x)\\)가 큼 \\(\\rightarrow\\) 이상치(Outlier)일 가능성 높음\n\\(s(x)\\)가 작음 \\(\\rightarrow\\) 정상(Inlier)일 가능성 높음\n\n\n\n\nStep 2: Calibration\n\n깨끗한 데이터셋 \\(X_1, \\dots, X_n\\)에 대해 점수들을 계산합니다. \\[ s_i = s(X_i), \\quad i=1, \\dots, n \\]\n그리고 이 점수들의 분포에서 \\(1-\\alpha\\) 분위수(Quantile)에 해당하는 임계값 \\(\\hat{q}\\)를 계산합니다.\n\n\\[\n\\hat{q} = \\text{Quantile}\\left( \\{s_1, \\dots, s_n\\} ; \\frac{\\lceil (n+1)(1-\\alpha) \\rceil}{n} \\right)\n\\]\n\n\nStep 3: Detection (Inference)\n\n새로운 테스트 데이터 \\(X_{test}\\)가 들어오면 점수 \\(s(X_{test})\\)를 계산하고, 임계값 \\(\\hat{q}\\)와 비교하여 판정합니다.\n\n\\[\n\\mathcal{C}(x) = \\begin{cases} \\text{inlier} & \\text{if } s(x) \\le \\hat{q} \\\\ \\text{outlier} & \\text{if } s(x) &gt; \\hat{q} \\end{cases}\n\\]\n\n\n\nTheoretical Guarantee & Interpretation\n\n이 간단한 절차는 다음 명제에 의해 False Positive Rate를 \\(\\alpha\\) 이하로 보장합니다.\n\n\nProposition 3 (Error control guarantee for outlier detection)\n\\(X_1, \\dots, X_n\\)과 \\(X_{test}\\)가 동일한 분포(i.i.d.)에서 추출되었다면, 위 알고리즘은 다음을 만족한다. \\[ \\mathbb{P}(\\mathcal{C}(X_{test}) = \\text{outlier}) \\le \\alpha \\]\n\n\nStatistical Interpretation\n\n이 과정은 통계적 가설 검정(Hypothesis Testing)과도 연결됩니다.\n\n귀무가설(\\(H_0\\)): \\(X_{test}\\)는 정상 데이터 분포(Calibration Data)와 교환 가능하다(Exchangeable).\n기각: 만약 \\(s(X_{test})\\)가 상위 \\(\\alpha\\) 범위에 들어간다면(즉, p-value &lt; \\(\\alpha\\)), 우리는 귀무가설을 기각하고 해당 데이터를 이상치로 판단합니다.\n\n\n\n\n\nConclusion\n\nConformal Outlier Detection은 복잡한 이상탐지 모델의 출력값을 “신뢰할 수 있는 통계적 판정”으로 변환해줍니다.\n사용자는 “이 데이터는 점수가 0.8입니다”라는 모호한 말 대신, “이 데이터는 95% 신뢰수준에서 정상 범위를 벗어났습니다”라는 명확한 근거를 가지고 의사결정을 내릴 수 있습니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#conformal-prediction-under-covariate-shift",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#conformal-prediction-under-covariate-shift",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "4.5. Conformal Prediction Under Covariate Shift",
    "text": "4.5. Conformal Prediction Under Covariate Shift\n\nIntroduction: When the i.i.d. Assumption Fails\n\n지금까지 우리가 배운 모든 Conformal Prediction(CP) 방법론은 하나의 강력한 가정에 의존하고 있습니다.\n바로 “테스트 데이터가 Calibration 데이터와 동일한 분포(i.i.d.)에서 왔다”는 가정입니다.\n하지만 현실은 그렇지 않습니다. 과거의 데이터가 미래를 완벽하게 대변하지 못하는 경우가 많습니다.\n\n의료 진단: 학습 데이터는 성인과 유아의 비율이 50:50이었는데, 실제 병원에는 성인이 95% 방문할 수 있습니다.\n자율 주행: 아침(밝음)에 데이터를 수집하여 학습했는데, 실제 주행은 오후(어두움)에 이루어질 수 있습니다.\n\n이러한 분포의 변화 중 Covariate Shift는 입력 변수 \\(X\\)의 분포 \\(P(X)\\)는 바뀌지만, 입력과 출력 사이의 관계 \\(P(Y|X)\\)는 유지되는 상황을 말합니다.\n이번 포스트에서는 Weighted Conformal Prediction을 사용하여 이러한 변화 속에서도 커버리지를 보장하는 방법을 알아봅니다.\n\n\n\nProblem Formulation: Covariate Shift\n\n우리의 상황을 수식으로 정의해봅시다.\n\nCalibration Data: \\(P\\) 분포에서 추출됨.\nTest Data: \\(\\mathcal{P}_{test}\\) 분포에서 추출됨.\n\n\n\\[\nX \\sim P \\quad \\rightarrow \\quad X_{test} \\sim \\mathcal{P}_{test}\n\\]\n\n단, \\(Y|X\\) (입력이 주어졌을 때 정답의 분포)는 변하지 않는다고 가정합니다.\n\n이를 Covariate Shift라고 합니다.\n\n이 상황에서 기존의 일반적인 CP를 사용하면 커버리지가 깨질 수 있습니다.\n\n예를 들어, 모델이 어려워하는 데이터(유아)가 테스트 셋에 더 많이 등장한다면, 에러율은 우리가 설정한 \\(\\alpha\\)보다 훨씬 높아질 것입니다.\n\n\n\n\nThe Solution: Weighted Conformal Prediction\n\n해결책의 핵심은 “테스트 분포 \\(\\mathcal{P}_{test}\\)에서 더 자주 등장할 것 같은 데이터에 더 큰 가중치(Weight)를 주는 것”입니다.\n\n\nStep 1: Likelihood Ratio Calculation\n\n먼저, 두 분포 사이의 비율(Likelihood Ratio)을 계산하는 함수 \\(w(x)\\)를 정의합니다. \\[\nw(x) = \\frac{d\\mathcal{P}_{test}(x)}{dP(x)}\n\\]\n\n\\(w(x) &gt; 1\\): 해당 샘플 \\(x\\)는 학습 때보다 테스트 때 더 자주 등장합니다 (중요함).\n\\(w(x) &lt; 1\\): 해당 샘플 \\(x\\)는 테스트 때 덜 등장합니다 (덜 중요함).\n\n\n\n\nStep 2: Compute Normalized Weights\n\n새로운 테스트 포인트 \\(x\\)가 들어왔을 때, 이 \\(x\\)와 기존 Calibration 데이터 \\(X_i\\)들에게 부여할 확률 질량(Probability Mass)을 재계산합니다.\n\n\\[\np_i^w(x) = \\frac{w(X_i)}{\\sum_{j=1}^{n} w(X_j) + w(x)}\n\\]\n\\[\np_{test}^w(x) = \\frac{w(x)}{\\sum_{j=1}^{n} w(X_j) + w(x)}\n\\]\n\n기존 CP에서는 모든 데이터가 \\(\\frac{1}{n+1}\\)의 동등한 확률을 가졌습니다.\nWeighted CP에서는 \\(w(\\cdot)\\)에 비례하여 확률을 다르게 배정합니다.\n즉, 테스트 분포와 유사한 데이터일수록 \\(p_i\\)가 커집니다.\n\n\n\nStep 3: Weighted Quantile Calculation\n\n이제 가장 중요한 단계인 Quantile 계산입니다.\n기존에는 단순히 점수를 정렬하고 \\((1-\\alpha)\\) 지점을 찾았지만, 이제는 가중치가 반영된 누적 분포(Weighted CDF)를 사용해야 합니다. \\[\n\\hat{q}(x) = \\inf \\left\\{ s_j : \\sum_{i=1}^{j} p_i^w(x) \\mathbb{I}\\{s_i \\le s_j\\} \\ge 1-\\alpha \\right\\}\n\\]\n\n여기서 \\(s_j\\)는 오름차순으로 정렬된 Calibration Score라고 가정합니다.\n\n즉, 가중치 \\(p_i^w(x)\\)들을 순서대로 더해가다가, 그 합이 \\(1-\\alpha\\)를 넘기는 순간의 점수를 \\(\\hat{q}(x)\\)로 선택합니다.\n\n\n\n\nIntuition: How Quantile Changes\n\n이 과정이 직관적으로 어떤 의미를 가질까요?\n\n\n\n\nFigure: Standard CP vs Weighted CP의 CDF 비교. (좌측) 일반적인 CP는 모든 점수의 가중치가 같아 직선 형태의 CDF를 가진다. (우측) Covariate Shift 상황에서는 가중치에 따라 CDF가 곡선이 되며, Quantile \\(\\hat{q}\\)의 위치가 달라진다.\n\n\n\nShift towards Hard Examples: 만약 테스트 분포가 모델이 어려워하는(Score가 높은) 데이터들 쪽으로 이동했다면, 높은 점수를 가진 \\(X_i\\)들의 가중치 \\(w(X_i)\\)가 커집니다. \\(\\rightarrow\\) CDF 그래프에서 오른쪽 부분의 경사가 가파라집니다. \\(\\rightarrow\\) \\(1-\\alpha\\) 지점에 도달하기 위해 더 많은 점수를 지나야 하거나, 더 높은 점수에서 도달하게 됩니다. \\(\\rightarrow\\) \\(\\hat{q}\\)가 증가합니다 (더 보수적인, 넓은 예측 집합 생성).\nShift towards Easy Examples: 반대로 테스트 분포가 쉬운 데이터들 위주라면, 낮은 점수들의 가중치가 커집니다. \\(\\rightarrow\\) \\(\\hat{q}\\)가 감소합니다 (더 좁고 효율적인 예측 집합 생성).\n\n\n\nTheorem & Guarantee\n\nTibshirani et al. (2019)에 의해 제안된 이 방법은 다음 정리에 의해 커버리지를 보장합니다.\n\n\nTheorem 3 (Conformal prediction under covariate shift)\n데이터가 위에서 정의한 Covariate Shift 가정하에 생성되었다면, Weighted Quantile \\(\\hat{q}(X_{test})\\)를 사용한 예측 집합 \\(\\mathcal{C}\\)는 다음을 만족한다.\n\\[ \\mathbb{P}(Y_{test} \\in \\mathcal{C}(X_{test})) \\ge 1-\\alpha \\]\n\n\n\nConclusion\n\nWeighted Conformal Prediction은 데이터 분포가 변하는 현실 세계의 문제에 CP를 적용하기 위한 필수적인 도구입니다.\n단순히 \\(\\frac{1}{n+1}\\)이라는 고정 관념을 깨고, “테스트 시점에 더 중요한 데이터에 가중치를 준다”는 아이디어를 통해 분포 변화에 유연하게 대처할 수 있습니다.\n이 방법은 \\(w(x)\\)를 정확히 안다면 완벽하게 작동하며, \\(w(x)\\)를 추정해야 하는 경우에도 꽤 견고한(Robust) 성능을 보여줍니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#conformal-prediction-under-distribution-shift",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#conformal-prediction-under-distribution-shift",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "4.6. Conformal Prediction Under Distribution Shift",
    "text": "4.6. Conformal Prediction Under Distribution Shift\n\nIntroduction: When Data Changes Over Time\n\n이전 포스트(4.5절)에서는 입력 분포가 변하는 Covariate Shift를 다루었습니다.\n하지만 그보다 더 다루기 까다로운 것은 Distribution Drift(분포 표류)입니다.\nDistribution Drift는 데이터의 분포가 시간이 지남에 따라 서서히(Slowly varying), 혹은 알 수 없는 방식으로 변하는 현상을 말합니다.\n\n주식 시장: 10년 전의 시장 상황과 오늘의 시장 상황은 전혀 다릅니다.\n센서 데이터: 기계가 노후화되면서 센서의 측정값 분포가 서서히 달라집니다.\n\n이런 시계열(Time-series) 문제에서는 “과거의 모든 데이터가 미래를 예측하는 데 동등하게 중요하다”는 i.i.d. 가정이 성립하지 않습니다.\n1년 전 데이터보다 어제의 데이터가 훨씬 중요하기 때문입니다.\n이번 포스트에서는 최신 데이터에 더 큰 가중치를 부여하는 Weighted Conformal Prediction을 통해 이 문제를 해결하는 방법을 알아봅니다.\n\n\n\nThe Method: Weighted Conformal Prediction (Again)\n\n기본적인 아이디어는 4.5절의 Covariate Shift와 동일하게 Weighted Quantile을 사용하는 것입니다.\n하지만 가중치 \\(w_i\\)를 결정하는 방식이 다릅니다.\nLikelihood Ratio를 계산하는 대신, 시간적 근접성(Recency)을 기준으로 가중치를 설정합니다.\n\n\nStep 1: Define Weight Schedule\n\n사용자는 도메인 지식에 기반하여 “오래된 데이터를 얼마나 잊을 것인가”를 결정하는 가중치 스케줄을 정의합니다.\n가장 널리 쓰이는 두 가지 방법은 다음과 같습니다:\n\nRolling Window (Sliding Window):\n\n\n최근 \\(K\\)개의 데이터만 사용하고, 나머지는 버립니다. \\[ w_i^{\\text{fixed}} = \\mathbb{I}\\{i \\ge n - K\\} \\]\n\n\nExponential Decay (Smooth Decay):\n\n\n과거 데이터의 영향력을 지수적으로 감소시킵니다. \\[ w_i^{\\text{decay}} = \\gamma^{n-i+1} \\quad (0 &lt; \\gamma &lt; 1) \\]\n예: \\(\\gamma = 0.99\\)라면 바로 직전 데이터는 1, 그 전은 0.99, 그 전은 \\(0.98 \\dots\\) 가중치를 가짐.\n\n\n\n\nStep 2: Normalize Weights\n\n정의된 가중치 \\(w_i\\)를 전체 합이 1이 되도록 정규화(Normalize)합니다.\n이때 테스트 포인트 \\(X_{test}\\)의 가중치 \\(w_{test}\\)도 포함하여 계산합니다.\n\n보통 \\(w_{test}=1\\)로 둠.\n\n\n\\[\n\\tilde{w}_i = \\frac{w_i}{\\sum_{j=1}^{n} w_j + 1}\n\\]\n\n\nStep 3: Weighted Quantile\n\n정규화된 가중치를 사용하여 보정된 분위수(Quantile) \\(\\hat{q}\\)를 계산합니다.\nCalibration Score \\(s_i\\)들을 오름차순 정렬했을 때, 누적 가중치 합이 \\(1-\\alpha\\)를 넘는 지점을 찾습니다.\n\n\\[\n\\hat{q} = \\inf \\left\\{ q : \\sum_{i=1}^{n} \\tilde{w}_i \\mathbb{I}\\{s_i \\le q\\} \\ge 1-\\alpha \\right\\}\n\\]\n\n\n\nTheoretical Analysis\n\n이 방식이 왜 작동하는지 수학적으로 살펴보겠습니다.\nBarber et al. (2022)의 연구에 따르면, Weighted CP는 분포 간의 거리(Total Variation Distance)에 비례하는 오차 범위 내에서 커버리지를 보장합니다.\n\n\nTheorem 4 (Conformal prediction under distribution drift)\n\\(i\\)번째 Calibration 데이터와 테스트 데이터 사이의 TV 거리(Total Variation Distance)를 \\(\\epsilon_i\\)라고 하자. \\[ \\epsilon_i = d_{TV}((X_i, Y_i), (X_{test}, Y_{test})) \\]\n이때 위에서 정의한 Weighted CP 절차는 다음을 만족한다: \\[ \\mathbb{P}(Y_{test} \\in \\mathcal{C}(X_{test})) \\ge 1 - \\alpha - 2 \\sum_{i=1}^{n} \\tilde{w}_i \\epsilon_i \\]\n\n\nInterpretation\n\n이 부등식의 우변에 있는 페널티 항 (\\(2 \\sum \\tilde{w}_i \\epsilon_i\\))을 줄이는 것이 핵심입니다.\n\n\\(\\epsilon_i\\) (Drift):\n\n데이터 \\(i\\)가 현재 시점(\\(test\\))과 얼마나 다른 분포를 가지는지를 나타냅니다.\n오래된 데이터일수록 \\(\\epsilon_i\\)가 클(1에 가까울) 것입니다.\n\n\\(\\tilde{w}_i\\) (Weight):\n\n우리가 부여한 가중치입니다.\n\n\n우리의 목표는 \\(\\epsilon_i\\)가 큰(오래되어 분포가 달라진) 데이터에 작은 가중치 \\(\\tilde{w}_i\\)를 부여하여, 곱 \\(\\tilde{w}_i \\epsilon_i\\)를 0에 가깝게 만드는 것입니다.\n즉, “분포가 많이 변한 데이터는 무시하겠다”는 전략을 통해 커버리지 손실을 막을 수 있습니다.\n\n\n\n\nPractical Consideration: Effective Sample Size\n\n가중치를 사용하면 분포 변화에는 대응할 수 있지만, 대가가 따릅니다. 바로 유효 샘플 수(Effective Sample Size)가 줄어든다는 점입니다.\n\n\\[\nn^{\\text{eff}} = \\frac{(\\sum w_i)^2}{\\sum w_i^2}\n\\]\n\nUniform Weights (\\(w_i=1\\)): \\(n^{\\text{eff}} = n\\). 모든 데이터를 다 쓰므로 샘플 수가 많아 분산이 작습니다 (안정적).\nConcentrated Weights: 최근 데이터에만 큰 가중치를 주면 \\(n^{\\text{eff}}\\)가 급격히 작아집니다.\n\n\\(n^{\\text{eff}}\\)가 작아지면 \\(\\rightarrow\\) 커버리지의 분산(Variance)이 커집니다. (즉, 예측 집합의 크기가 들쑥날쑥해짐)\n\n따라서 Trade-off가 존재합니다:\n\n가중치를 너무 급격하게 줄이면(빠른 적응) \\(\\rightarrow\\) 분포 변화에는 강하지만, 예측이 불안정해짐.\n가중치를 너무 천천히 줄이면(느린 적응) \\(\\rightarrow\\) 예측은 안정적이지만, 이미 변해버린 과거 분포의 영향을 받음.\n\n\n\n\nConclusion\n\nConformal Prediction Under Distribution Drift는 시계열 데이터와 같이 Non-stationary 환경에서 신뢰할 수 있는 예측 구간을 만드는 방법입니다.\n핵심은 Weighted Quantile을 사용하는 것입니다.\n가중치 스케줄(Sliding Window, Decay)을 통해 과거 데이터를 적절히 “망각(Forget)”해야 합니다.\n이론적으로, 분포 변화가 큰 데이터에 가중치를 적게 줌으로써 커버리지 하락을 방어합니다.\n하지만 너무 과도한 가중치 조절은 유효 샘플 수를 줄여 불안정성을 초래할 수 있으므로 주의가 필요합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#introduction-7",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#introduction-7",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "Introduction",
    "text": "Introduction\n\n지금까지 우리는 Conformal Prediction(CP)의 다양한 이론적 확장(Extension)들을 다루었습니다.\n이제 이 도구들이 실제 머신러닝 문제에서 어떻게 작동하는지 확인할 차례입니다.\n이번 포스트에서는 논문의 Section 5에서 소개된 5가지의 구체적인 적용 사례를 살펴봅니다.\n각 사례는 단순한 분류/회귀를 넘어, Risk Control, Distribution Shift, Outlier Detection 등 현실적인 난제들을 어떻게 해결하는지 보여줍니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#multilabel-classification-with-fnr-control",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#multilabel-classification-with-fnr-control",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "1. Multilabel Classification with FNR Control",
    "text": "1. Multilabel Classification with FNR Control\n\nProblem Setup\n\n이미지 안에 있는 모든 객체를 맞추는 다중 라벨 분류(Multilabel Classification) 문제입니다.\n단순히 정답을 포함하는 것을 넘어, “정답 객체 중 90% 이상을 찾아내라(Recall \\(\\ge\\) 90%)”와 같은 요구사항이 있을 때 사용합니다.\n이를 위해 False Negative Rate (FNR)를 제어합니다.\n\nDataset: Microsoft COCO (Common Objects in Context)\nGoal: 실제 객체들(\\(Y\\)) 중 모델이 예측한 집합(\\(\\mathcal{C}\\))에 포함되지 않은 비율(FNR)을 \\(\\alpha\\) 이하로 유지.\n\n\n\n\nMethodology: Conformal Risk Control\n\n여기서는 Section 4.3에서 다룬 Conformal Risk Control(CRC)을 사용합니다.\n\nPrediction Set Construction:\n\n\n모델의 예측 확률 \\(\\hat{f}(x)\\)가 임계값 \\(\\lambda\\) 이상인 클래스들을 선택합니다. \\[ \\mathcal{C}_\\lambda(x) = \\{ k : \\hat{f}(x)_k \\ge \\lambda \\} \\]\n\n\\(\\lambda\\)가 작을수록 더 많은 클래스를 포함하므로 보수적이 됨.\n\n\n\nLoss Function (\\(l_{FNR}\\)):\n\n\n예측 집합이 정답을 얼마나 놓쳤는지를 정의합니다. \\[l_{FNR}(\\mathcal{C}_\\lambda(x), y) = 1 - \\frac{|\\mathcal{C}_\\lambda(x) \\cap y|}{|y|}\\]\n만약 정답 \\(y=\\{\\text{사람, 차}\\}\\)인데 예측 \\(\\mathcal{C}=\\{\\text{사람}\\}\\)이라면, 교집합은 1개, 정답은 2개이므로 손실은 \\(1 - 1/2 = 0.5\\)입니다.\n\n\n\nThreshold Optimization:\n\nCalibration Set에서 경험적 리스크가 \\(\\alpha\\) (보정항 포함) 이하가 되는 \\(\\hat{\\lambda}\\)를 찾습니다. \\[ \\hat{\\lambda} = \\inf \\left\\{ \\lambda : \\frac{1}{n}\\sum_{i=1}^n l_{FNR}(\\mathcal{C}_\\lambda(X_i), Y_i) \\le \\alpha - \\frac{1-\\alpha}{n} \\right\\} \\]\n\n\n\n\n\nFigure: MS COCO 데이터셋에 대한 Multilabel Classification 결과 (\\(\\alpha=0.1\\)). 빨간색 텍스트는 놓친 정답(False Negative), 파란색은 잘못 예측한 오답(False Positive), 검은색은 맞춘 정답(True Positive)을 나타낸다. 평균적으로 90% 이상의 정답 라벨을 찾아내고 있다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#tumor-segmentation",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#tumor-segmentation",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "2. Tumor Segmentation",
    "text": "2. Tumor Segmentation\n\nProblem Setup\n\n의료 영상에서 종양(Tumor) 부위를 픽셀 단위로 분할(Segmentation)하는 문제입니다.\n여기서도 핵심은 “종양 픽셀을 놓치지 않는 것”입니다. 즉, 픽셀 단위의 FNR 제어가 필요합니다.\n\nDataset: Gut Polyps dataset\nGoal: 전체 종양 픽셀 중 예측 마스크가 커버하지 못한 비율을 제어.\n\n\n\n\nMethodology\n\nMultilabel Classification과 원리는 동일하지만, 대상이 클래스에서 픽셀로 바뀝니다.\n\nOutput: \\(M \\times N\\) 크기의 확률 맵 \\(\\hat{f}(x)\\).\n\n\nPrediction Mask: 각 픽셀 \\((i,j)\\)에 대해 확률이 \\(\\lambda\\) 이상이면 종양으로 예측. \\[\\mathcal{C}_\\lambda(x) = \\{ (i,j) : \\hat{f}(x)_{(i,j)} \\ge \\lambda \\}\\]\n\n\nLoss Function: \\[l(\\mathcal{C}, Y) = \\frac{\\text{\\# of missed tumor pixels}} {\\text{total \\# of tumor pixels}}\\]\n\n이 방법을 적용하면 의사는 “이 AI가 표시한 영역 안에 실제 종양의 90%가 포함되어 있다”는 확신을 가지고 진단에 임할 수 있습니다.\n\n\n\n\nFigure: 종양 분할(Tumor Segmentation) 결과 (\\(\\alpha=0.1\\)). 붉은 영역은 모델이 놓친 종양 부위(False Negative)이다. CRC를 통해 놓치는 부위를 통계적으로 최소화할 수 있다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#weather-prediction-time-series",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#weather-prediction-time-series",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "3. Weather Prediction (Time-Series)",
    "text": "3. Weather Prediction (Time-Series)\n\nProblem Setup\n\n시간의 흐름에 따라 기온(Temperature)을 예측하는 시계열 회귀 문제입니다.\n시간이 지남에 따라 계절이 바뀌고 기후가 변하므로, 데이터는 i.i.d.가 아니며 분포가 표류(Distribution Drift)합니다.\n\nDataset: Yandex Weather Prediction (Shifts Project)\nChallenge: 과거 데이터와 현재 데이터의 상관관계가 변함.\n\n\n\n\nMethodology: Weighted Conformal Prediction\n\nSection 4.6의 분포 표류(Distribution Drift) 대응법을 사용합니다.\n\nScore Function:\n\n\n예측값 \\(\\hat{f}(X_t)\\)와 불확실성 추정값 \\(\\hat{u}(X_t)\\)를 이용한 정규화된 잔차(Normalized Residual)를 사용합니다. \\[ s_t = \\frac{|Y_t - \\hat{f}(X_t)|}{\\hat{u}(X_t)} \\]\n\n\nWeighted Quantile:\n\n\n최근 \\(K\\)개의 데이터만 사용하는 Sliding Window 방식을 적용합니다.\n가중치 \\(w_{t'} = \\mathbb{I}\\{t' \\ge t - K\\}\\)를 사용하여, 오래된 데이터는 과감히 버리고 최근 데이터 분포에만 맞춥니다. \\[ \\hat{q}_t = \\text{Quantile}_{\\text{weighted}}(s_{t-K}, \\dots, s_{t-1}) \\]\n\n결과적으로 급격한 기온 변화나 계절 변화가 발생했을 때, 일반 CP보다 훨씬 빠르게 적응하여 적절한 커버리지를 회복합니다.\n\n\n\n\nFigure: 시계열 기온 예측 결과. (왼쪽) 일반 CP(주황색)는 분포 변화 시 커버리지가 무너지지만, Weighted CP(파란색)는 빠르게 회복하여 목표 커버리지(0.9)를 유지한다. (오른쪽) 예측된 구간의 시각화."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#toxic-comment-identification-outlier-detection",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#toxic-comment-identification-outlier-detection",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "4. Toxic Comment Identification (Outlier Detection)",
    "text": "4. Toxic Comment Identification (Outlier Detection)\n\nProblem Setup\n\n온라인 댓글이 유해한지(Toxic) 아닌지를 판별하는 문제입니다.\n정상적인 대화(Non-toxic) 데이터만 잔뜩 있는 상태에서, 새로운 댓글이 정상 범주를 벗어난(Outlier/Toxic) 것인지 탐지합니다.\n\nDataset: Jigsaw Multilingual Toxic Comment Classification\nGoal: 정상 댓글을 유해하다고 잘못 판별할 확률(False Positive Rate)을 \\(\\alpha\\) 이하로 제어. (Type-1 Error Control)\n\n\n\n\nMethodology: Conformal Outlier Detection\n\nSection 4.4의 방법을 적용합니다.\n\nHeuristic Model: BERT 기반의 유해성 점수 예측 모델 \\(f(x) \\in [0, 1]\\).\n\n\nCalibration: 정상 댓글(Non-toxic) \\(n\\)개에 대해 점수 \\(s_i = f(X_i)\\)를 계산하고 Quantile \\(\\hat{q}\\)를 구합니다.\n\n\nDetection: \\[ \\mathcal{C}(x) = \\begin{cases} \\text{Normal} & \\text{if } f(x) \\le \\hat{q} \\\\ \\text{Toxic (Outlier)} & \\text{if } f(x) &gt; \\hat{q} \\end{cases} \\]\n\n이 방식은 “이 댓글은 유해합니다”라고 경보를 울릴 때, 그 경보가 오작동일 확률을 수학적으로 보장해줍니다.\n\n\n\n\nFigure: 유해 댓글 탐지 예시 (\\(\\alpha=0.1\\)). 다국어 댓글에 대해 정상 댓글을 유해하다고 잘못 분류할 확률을 10%로 제한하면서, 실제 유해 댓글의 70%를 성공적으로 잡아냈다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#selective-classification-abstention",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#selective-classification-abstention",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "5. Selective Classification (Abstention)",
    "text": "5. Selective Classification (Abstention)\n\nProblem Setup\n\n모델이 확신할 수 없을 때는 “모르겠습니다(I don’t know)”라고 대답을 거부(Abstain)하는 시스템입니다.\n목표는 대답을 거부하지 않고 예측을 내놓았을 때의 정확도가 \\(\\ge 1-\\alpha\\)가 되도록 하는 것입니다.\n\nDataset: ImageNet\nGoal: Selective Accuracy \\(\\ge 90\\%\\).\n\n\n\n\nMethodology: Learn then Test\n\n이 문제는 정확도(Accuracy)가 임계값 \\(\\lambda\\)에 따라 단조 증가(Monotone)하지 않을 수 있기 때문에, 표준 CRC 대신 Learn then Test (Appendix A 내용) 프레임워크를 사용합니다.\n\nRisk Definition: \\[ R(\\lambda) = \\mathbb{P}(\\text{Error} \\mid \\text{Confidence} \\ge \\lambda) \\]\n\n\n조건부 확률이므로 직접 제어하기 까다롭습니다.\n\n\nEmpirical Estimate & Upper Bound:\n\n\nCalibration Set에서 특정 신뢰도 \\(\\lambda\\) 이상인 샘플들의 에러율 \\(\\hat{R}(\\lambda)\\)를 계산합니다.\n이 에러율은 이항 분포(Binomial Distribution)를 따르므로, 클로퍼-피어슨(Clopper-Pearson) 구간 등을 이용해 에러율의 보수적 상한선(Upper Bound) \\(\\hat{R}^+(\\lambda)\\)을 구합니다.\n\n\nScan & Select: \\(\\hat{R}^+(\\lambda) \\le \\alpha\\)를 만족하는 가장 작은 \\(\\lambda\\)를 선택합니다.\n\n결과적으로 모델은 자신이 없으면 대답을 회피하고, 대답을 했을 때는 매우 높은 정확도를 보장하게 됩니다.\n\n\n\n\nFigure: ImageNet에 대한 Selective Classification 결과. (왼쪽) \\(\\lambda\\)가 커질수록(가로축), 예측을 수행하는 비율(주황색)은 줄어들지만, 정확도(파란색)는 올라간다. 점선은 목표 정확도 90%를 달성하는 지점을 나타낸다. (오른쪽) 모델이 예측한 예시(가오리)와 기권을 선택한 예시(여우)."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#conclusion-5",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#conclusion-5",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "Conclusion",
    "text": "Conclusion\n\n이상의 5가지 예제는 Conformal Prediction이 단순히 이론적인 개념에 머무르지 않고, 실제 현업의 복잡한 문제들을 해결하는 강력한 도구임을 보여줍니다.\n\nSegmentation/Multilabel: 단순 에러율이 아닌 FNR 등 복잡한 Metric 제어.\nTime-series: 데이터 분포 변화(Drift)에 대한 적응.\nOutlier Detection: 비지도 학습 환경에서의 통계적 보장.\nSelective Classification: 고위험 환경에서의 안전한 AI.\n\n이 모든 과정에서 가장 중요한 것은 “적절한 Score Function의 정의”와 “올바른 Calibration 기법의 선택”입니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#introduction-the-efficiency-trade-off",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#introduction-the-efficiency-trade-off",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "Introduction: The Efficiency Trade-off",
    "text": "Introduction: The Efficiency Trade-off\n\n지금까지 우리가 다룬 방식은 Split Conformal Prediction (Inductive CP)이었습니다.\n이 방식은 데이터를 학습용(Train)과 보정용(Calibration)으로 나누어 사용합니다.\n\n장점: 계산이 매우 빠릅니다. 모델을 딱 한 번만 학습시키면 됩니다.\n단점: 데이터를 쪼개야 하므로 통계적 효율성(Statistical Efficiency)이 떨어집니다. 보정용 데이터는 학습에 기여하지 못하고, 학습용 데이터는 보정에 기여하지 못하기 때문입니다.\n\n데이터가 매우 귀하거나(예: 희귀병 임상 데이터), 예측의 정확도가 비용보다 훨씬 중요한 상황이라면 어떨까요?\n이때 우리는 계산 비용을 감수하더라도 모든 데이터를 학습과 보정에 동시에 사용하는 Full Conformal Prediction (Transductive CP)을 고려해야 합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#the-core-idea-what-if",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#the-core-idea-what-if",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "The Core Idea: “What if?”",
    "text": "The Core Idea: “What if?”\n\nFull CP의 핵심 아이디어는 새로운 데이터 \\(X_{n+1}\\)에 대해 “만약 정답이 \\(y\\)라면, 이 데이터가 기존 데이터들과 잘 어울리는가(Exchangeable)?”를 테스트하는 것입니다.\n우리는 아직 정답 \\(Y_{n+1}\\)을 모르지만, 가능한 모든 후보 \\(y \\in \\mathcal{Y}\\)를 하나씩 대입해볼 수는 있습니다.\n만약 \\(y\\)가 진짜 정답이라면, \\((X_{n+1}, y)\\)를 포함한 전체 데이터셋은 통계적으로 동질적(Exchangeable)이어야 합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#the-algorithm-6",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#the-algorithm-6",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "The Algorithm",
    "text": "The Algorithm\n\n알고리즘은 모든 가능한 라벨 \\(y\\)에 대해 재학습(Retraining)을 수행해야 하므로 꽤 무겁습니다.\n\n\nStep 1: Loop over all possible labels\n\n테스트 포인트 \\(X_{n+1}\\)에 대해, 가능한 모든 정답 후보 \\(y \\in \\mathcal{Y}\\) (예: 분류 문제의 모든 클래스)에 대해 다음 과정을 반복합니다.\n\n\n\nStep 2: Augment and Retrain\n\n기존 데이터셋에 가상의 데이터 포인트 \\((X_{n+1}, y)\\)를 추가하여 확장된 데이터셋을 만듭니다.\n그리고 이 데이터셋으로 모델 \\(\\hat{f}^y\\)를 처음부터 다시 학습시킵니다.\n\n\\[ \\text{Train } \\hat{f}^y \\text{ on } \\{(X_1, Y_1), \\dots, (X_n, Y_n), (X_{n+1}, y)\\} \\]\n\n주의: 이때 사용하는 학습 알고리즘은 데이터의 순서에 영향을 받지 않는 대칭적(Symmetric) 알고리즘이어야 합니다.\n\n\n\nStep 3: Compute Scores\n\n학습된 모델 \\(\\hat{f}^y\\)를 사용하여, 확장된 데이터셋 내의 모든 포인트(\\(i=1 \\dots n+1\\))에 대해 Conformal Score를 계산합니다.\n\n\\[ s_i^y = s(X_i, Y_i, \\hat{f}^y) \\quad \\text{for } i=1, \\dots, n \\] \\[ s_{n+1}^y = s(X_{n+1}, y, \\hat{f}^y) \\]\n\n\nStep 4: Compute Quantile\n\n이 \\(n+1\\)개의 점수들 사이에서 \\(s_{n+1}^y\\)의 위치를 확인합니다.\n정확히는 \\(1-\\alpha\\) 분위수 \\(\\hat{q}^y\\)를 계산하여, \\(s_{n+1}^y\\)가 이 안에 들어오는지 확인합니다.\n\n\\[ \\hat{q}^y = \\text{Quantile}\\left( \\{s_1^y, \\dots, s_{n+1}^y\\} ; \\frac{\\lceil (n+1)(1-\\alpha) \\rceil}{n+1} \\right) \\]\n\n\nStep 5: Construct Prediction Set\n\n위 조건을 만족하는(즉, 기존 데이터들과 잘 섞이는) 모든 \\(y\\)를 예측 집합에 포함시킵니다.\n\n\\[ \\mathcal{C}(X_{n+1}) = \\{ y \\in \\mathcal{Y} : s_{n+1}^y \\le \\hat{q}^y \\} \\]"
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#statistical-interpretation-permutation-test",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#statistical-interpretation-permutation-test",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "Statistical Interpretation: Permutation Test",
    "text": "Statistical Interpretation: Permutation Test\n\nFull Conformal Prediction이 왜 작동하는지, 그리고 왜 “데이터를 섞어서(Permutation)” 판단하는지 이해하기 위해 통계학의 순열 검정(Permutation Test) 개념을 연결해보겠습니다.\n\n\nThe Null Hypothesis of Exchangeability\n\n우리가 테스트 데이터 \\(X_{n+1}\\)에 대해 어떤 가상의 정답 \\(y\\)를 부여했을 때, 핵심 질문은 이것입니다.\n\n\n“이 데이터 포인트 \\((X_{n+1}, y)\\)가 기존 데이터들과 구별되지 않고 잘 섞이는가?”\n\n\n이를 통계적 가설 검정의 언어로 표현하면 다음과 같습니다.\n귀무가설 (\\(H_0\\)): 데이터들 \\(Z_1, \\dots, Z_{n+1}\\)은 교환 가능(Exchangeable)하다.\n즉, 데이터의 순서를 뒤섞어도 그 결합 확률 분포는 변하지 않는다.\n\n여기서 \\(Z_i = (X_i, Y_i)\\)입니다.\n\n\n\n\nThe Test Statistic & P-value\n\n이 귀무가설을 기각하기 위해, 우리는 데이터가 얼마나 “튀는지”를 측정하는 검정 통계량 \\(T\\)를 정의합니다.\nFull CP에서는 Nonconformity Score (\\(s\\))가 바로 이 역할을 합니다.\n\n\\[ T(Z) = s(X, Y) \\]\n\n점수 \\(s\\)가 클수록 해당 데이터는 다른 데이터들과 이질적이라는(Exchangeability를 위반한다는) 증거가 됩니다.\n우리는 관측된 데이터의 점수가, 데이터를 무작위로 섞었을 때 나올 수 있는 점수들과 비교해서 얼마나 큰지 p-value를 계산합니다.\n\n\\[ p = \\frac{\\sum_{\\sigma \\in S_{n+1}} \\mathbb{1}\\{ T(Z_{\\sigma(1)}, \\dots, Z_{\\sigma(n+1)}) \\ge T(Z_{observed}) \\}}{(n+1)!} \\]\n\n하지만 Full CP에서는 모든 순열을 다 계산할 필요 없이, 각 데이터 포인트의 점수 \\(s_i\\)들의 순위(Rank)만 보면 됩니다.\n따라서 p-value는 다음과 같이 단순화됩니다.\n\n\\[ p(y) = \\frac{1}{n+1} \\sum_{i=1}^{n+1} \\mathbb{1}\\{ s_i^y \\ge s_{n+1}^y \\} \\]\n\n\nDecision Rule (Validity Theorem)\n\n순열 검정의 핵심 정리에 따르면, 귀무가설(\\(H_0\\))이 참일 때 p-value는 균등 분포(Uniform Distribution)를 따릅니다. 따라서 다음이 성립합니다.\n\n\nTheorem (Validity of Permutation Test)\n모든 \\(\\tau \\in [0, 1]\\)과 모든 교환 가능한 분포 \\(P\\)에 대해: \\[ \\mathbb{P}_P(p \\le \\tau) \\le \\tau \\]\n\n\n우리는 허용 가능한 에러율 \\(\\alpha\\)를 설정했으므로, p-value가 \\(\\alpha\\)보다 작으면(너무 희박한 확률이면) 귀무가설을 기각합니다.\n\\(p(y) \\le \\alpha\\) (기각): “\\(y\\)를 정답이라고 가정했더니, 이 데이터는 상위 \\(\\alpha\\)% 안에 들 만큼 너무 이상해. \\(y\\)는 정답이 아닌 것 같아.” \\(\\rightarrow\\) 예측 집합에서 제외.\n\\(p(y) &gt; \\alpha\\) (채택): “\\(y\\)를 정답이라고 가정해도, 데이터가 전체 무리 속에 자연스럽게 섞여 들어가네. \\(y\\)는 정답일 수도 있어.” \\(\\rightarrow\\) 예측 집합에 포함.\n결국 Full CP의 예측 집합 \\(\\mathcal{C}(X_{n+1})\\)은 “순열 검정에서 기각되지 않고 살아남은 모든 \\(y\\)들의 모임”입니다.\n이것이 바로 Full CP가 수학적으로 엄밀한 커버리지를 보장하는 이유입니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#computational-cost-vs.-statistical-efficiency",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#computational-cost-vs.-statistical-efficiency",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "Computational Cost vs. Statistical Efficiency",
    "text": "Computational Cost vs. Statistical Efficiency\n\nThe Cost\n\n이 방법의 가장 큰 문제는 계산 비용입니다.\n테스트 데이터가 하나 들어올 때마다, 그리고 후보 클래스 \\(K\\)개마다 매번 모델을 재학습해야 합니다.\n총 학습 횟수: \\((n+1) \\times K\\)\n따라서 딥러닝과 같이 학습이 오래 걸리는 모델이나, 회귀 문제(Regression)처럼 후보 \\(y\\)가 무한히 많은 경우에는 그대로 적용하기 어렵습니다.\n\n\n\nThe Benefit\n\n하지만 데이터를 나누지 않고 \\(n\\)개를 모두 사용하므로, 예측 집합이 더 작고 효율적(Sharp)입니다.\nSplit CP보다 정보 손실이 적어, 데이터가 적은 상황에서는 훨씬 강력한 성능을 발휘합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#theoretical-guarantee-4",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#theoretical-guarantee-4",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "Theoretical Guarantee",
    "text": "Theoretical Guarantee\n\nFull CP 역시 수학적으로 엄밀한 커버리지를 보장합니다.\n\n\nTheorem 5 (Full conformal coverage guarantee)\n데이터가 교환 가능(Exchangeable)하고 학습 알고리즘이 대칭적(Symmetric)이라면, 다음이 성립한다.\n\\[ \\mathbb{P}(Y_{n+1} \\in \\mathcal{C}(X_{n+1})) \\ge 1-\\alpha \\]"
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#summary-4",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/index.html#summary-4",
    "title": "[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n\n\nFeature\nSplit Conformal (SCP)\nFull Conformal (FCP)\n\n\n\n\nData Usage\nTrain / Calib 분할 (비효율)\n전체 데이터 사용 (효율)\n\n\nComputation\n1회 학습 (빠름)\n\\(K\\)회 재학습 (매우 느림)\n\n\nUse Case\nBig Data, Deep Learning\nSmall Data, Statistically Critical Tasks\n\n\nInterpretation\nValidation Score Quantile\nPermutation Test\n\n\n\n\nFull CP는 계산 비용 때문에 현대 머신러닝에서는 잘 쓰이지 않지만, Jackknife+나 CV+ (Section 6.2) 같은 기법들의 이론적 토대가 되는 매우 중요한 개념입니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "",
    "text": "인과추론(Causal Inference)과 머신러닝의 교차점에서, 데이터의 생성 과정을 설명하는 방향성 비순환 그래프(Directed Acyclic Graph, DAG)를 학습하는 것은 매우 중요한 문제입니다. 이를 Structure Learning이라고 부릅니다.\nBayesian Network(BN)의 구조인 DAG는 변수 간의 조건부 독립성을 표현하며, Pearl(1988) 이후 의학, 유전학, 경제학 등 다양한 분야에서 인과관계를 파악하는 도구로 사용되어 왔습니다.\n하지만 데이터의 결합 분포(Joint Distribution)로부터 “Faithful”한 DAG를 찾아내는 것은 악명 높은 난제입니다.\n\n\nFaithfulness란?\n그래프 \\(G\\)와 결합 분포 \\(\\mathcal{P}\\)가 서로 “Faithful”하다는 것은, \\(\\mathcal{P}\\)에서 성립하는 모든 조건부 독립성이 그래프 \\(G\\)에서도 (d-separation을 통해) 나타나고, 그 역도 성립함을 의미합니다.\n\n\n\n\nDAG 구조 학습이 어려운 근본적인 이유는 탐색 공간(Search Space)의 방대함 때문입니다.\n노드(변수)의 개수가 늘어날 때, 가능한 그래프의 수는 초지수적(Superexponential)으로 증가합니다.\n이는 NP-hard 문제로 알려져 있습니다.\n전통적인 접근 방식은 크게 두 가지로 나뉩니다:\n\nScore-based Methods:\n\n\n가능한 그래프 구조에 대해 점수(BIC, BDeu 등)를 매기고, 이 점수를 최적화하는 그래프를 찾습니다.\n하지만 그래프는 반드시 Acyclic(비순환)이어야 한다는 조합적 제약 조건(Combinatorial Constraint) 때문에, 전역 최적해를 찾는 것이 매우 어렵습니다.\n따라서 탐욕적 탐색(Greedy Search)이나 트리 구조(Tree-structure) 가정 같은 근사법을 사용해야 했습니다.\n\n\nConstraint-based Methods:\n\n\n변수 간의 조건부 독립성 검정(Independence Test)을 수행하여 엣지를 연결하거나 제거합니다 (예: PC Algorithm).\n데이터 효율성이나 다중 가설 검정의 오류 문제 등이 존재합니다.\n\n\n\n\n\n\n최근 Zheng et al. (2018)의 연구(흔히 NOTEARS로 알려짐)는 이 분야에 혁신적인 돌파구를 마련했습니다.\n그들은 조합적 문제였던 “Acyclicity Constraint”를 미분 가능한 연속 함수 형태로 재정의했습니다.\n\n\\[\nh(A) = \\text{Tr}(e^{A \\circ A}) - d = 0\n\\]\n\n여기서 \\(A\\)는 인접 행렬(Adjacency Matrix), \\(d\\)는 노드의 개수입니다.\n이 제약 조건 덕분에 구조 학습 문제는 이제 연속 최적화(Continuous Optimization) 문제로 변환되어, 경사 하강법(Gradient Descent)과 같은 표준적인 최적화 기법을 사용할 수 있게 되었습니다.\n\n\n\n\n하지만 Zheng et al. (2018)의 접근법에도 한계가 있었습니다:\n\n\n선형성 가정 (Linearity Assumption): 기본적으로 선형 구조 방정식 모델(Linear SEM)을 가정합니다.\n\n\n분포의 제약: 최소제곱(Least-squares) 손실 함수를 사용하므로, 실제 데이터의 복잡한 분포를 반영하기 어렵습니다.\n\n\n현실 세계의 데이터는 비선형적 관계를 가지며, 단순한 선형 모델로는 포착할 수 없는 복잡한 메커니즘으로 생성됩니다.\n\n\n\n\n\n\n본 논문(Yu et al., 2019)은 딥러닝의 강력한 표현력을 활용하여 기존의 선형 가정을 극복하고자 합니다. 저자들은 DAG-GNN이라는 새로운 아키텍처를 제안합니다.\n\n\n\n\n이 모델의 핵심은 Variational Autoencoder (VAE) 프레임워크에 Graph Neural Network (GNN)을 결합한 것입니다.\nDeep Generative Model: 신경망은 “Universal Approximator”입니다. 이를 통해 변수 간의 복잡한 비선형 관계를 모델링합니다.\nEncoder/Decoder Parameterization: VAE의 인코더와 디코더를 일반적인 MLP가 아닌, 특별히 설계된 GNN으로 파라미터화합니다.\nEvidence Lower Bound (ELBO): 모델의 목적 함수(Score)는 VAE의 ELBO가 됩니다. 이는 데이터의 우도(Likelihood)를 최대화하는 방향으로 학습됨을 의미합니다.\n\n\n\n\n\n또한, 저자들은 NOTEARS에서 제안된 행렬 지수(Matrix Exponential) 제약 조건 대신, 딥러닝 프레임워크에서 구현하기 더 용이하고 수치적으로 안정적인 다항식(Polynomial) 형태의 새로운 제약 조건을 제안합니다.\nNOTEARS (Zheng et al., 2018): \\(Tr(e^{A \\circ A}) - d = 0\\)\nDAG-GNN 제안: 수치적 안정성을 높인 변형된 형태를 사용합니다.\n\n\n\n\n\n\n이 논문의 Introduction에서 강조하는 주요 기여점은 다음과 같이 네 가지로 요약할 수 있습니다.\n\nDeep Generative Model 기반 접근:\n\n\n기존의 Linear SEM을 넘어, VAE를 사용하여 데이터의 복잡한 비선형 분포를 포착하고 샘플링할 수 있는 모델을 제안했습니다.\n그래프 구조(Weighted Adjacency Matrix)는 잠재 변수가 아니라, 신경망 파라미터와 함께 학습되는 명시적인 파라미터로 설정됩니다.\n\n\n다양한 데이터 타입 지원:\n\n\nVAE 프레임워크의 특성상, 디코더의 출력 분포(Likelihood)를 적절히 설정함으로써 연속형 변수뿐만 아니라 이산형(Discrete) 변수도 자연스럽게 처리할 수 있습니다.\n\n\n벡터 값 노드(Vector-valued Nodes) 지원:\n\n\nGNN을 사용하므로 각 노드가 단순 스칼라 값이 아닌 벡터 값을 가질 수 있습니다. 이는 각 노드가 여러 특징(Feature)을 가지는 복잡한 시나리오에 적용 가능함을 의미합니다.\n\n\n개선된 Acyclicity Constraint:\n\n\n기존의 행렬 지수 제약 조건이 자동 미분(Automatic Differentiation) 라이브러리에서 구현하기 까다로울 수 있다는 점을 지적하며, 더 실용적이고 수치적으로 안정적인 다항식 기반의 대안을 제시했습니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#the-combinatorial-problem-기존의-한계",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#the-combinatorial-problem-기존의-한계",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "",
    "text": "DAG 구조 학습이 어려운 근본적인 이유는 탐색 공간(Search Space)의 방대함 때문입니다.\n노드(변수)의 개수가 늘어날 때, 가능한 그래프의 수는 초지수적(Superexponential)으로 증가합니다.\n이는 NP-hard 문제로 알려져 있습니다.\n전통적인 접근 방식은 크게 두 가지로 나뉩니다:\n\nScore-based Methods:\n\n\n가능한 그래프 구조에 대해 점수(BIC, BDeu 등)를 매기고, 이 점수를 최적화하는 그래프를 찾습니다.\n하지만 그래프는 반드시 Acyclic(비순환)이어야 한다는 조합적 제약 조건(Combinatorial Constraint) 때문에, 전역 최적해를 찾는 것이 매우 어렵습니다.\n따라서 탐욕적 탐색(Greedy Search)이나 트리 구조(Tree-structure) 가정 같은 근사법을 사용해야 했습니다.\n\n\nConstraint-based Methods:\n\n\n변수 간의 조건부 독립성 검정(Independence Test)을 수행하여 엣지를 연결하거나 제거합니다 (예: PC Algorithm).\n데이터 효율성이나 다중 가설 검정의 오류 문제 등이 존재합니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#the-paradigm-shift-from-discrete-to-continuous",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#the-paradigm-shift-from-discrete-to-continuous",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "",
    "text": "최근 Zheng et al. (2018)의 연구(흔히 NOTEARS로 알려짐)는 이 분야에 혁신적인 돌파구를 마련했습니다.\n그들은 조합적 문제였던 “Acyclicity Constraint”를 미분 가능한 연속 함수 형태로 재정의했습니다.\n\n\\[\nh(A) = \\text{Tr}(e^{A \\circ A}) - d = 0\n\\]\n\n여기서 \\(A\\)는 인접 행렬(Adjacency Matrix), \\(d\\)는 노드의 개수입니다.\n이 제약 조건 덕분에 구조 학습 문제는 이제 연속 최적화(Continuous Optimization) 문제로 변환되어, 경사 하강법(Gradient Descent)과 같은 표준적인 최적화 기법을 사용할 수 있게 되었습니다.\n\n\n\n\n하지만 Zheng et al. (2018)의 접근법에도 한계가 있었습니다:\n\n\n선형성 가정 (Linearity Assumption): 기본적으로 선형 구조 방정식 모델(Linear SEM)을 가정합니다.\n\n\n분포의 제약: 최소제곱(Least-squares) 손실 함수를 사용하므로, 실제 데이터의 복잡한 분포를 반영하기 어렵습니다.\n\n\n현실 세계의 데이터는 비선형적 관계를 가지며, 단순한 선형 모델로는 포착할 수 없는 복잡한 메커니즘으로 생성됩니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#dag-gnn-a-deep-generative-approach",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#dag-gnn-a-deep-generative-approach",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "",
    "text": "본 논문(Yu et al., 2019)은 딥러닝의 강력한 표현력을 활용하여 기존의 선형 가정을 극복하고자 합니다. 저자들은 DAG-GNN이라는 새로운 아키텍처를 제안합니다.\n\n\n\n\n이 모델의 핵심은 Variational Autoencoder (VAE) 프레임워크에 Graph Neural Network (GNN)을 결합한 것입니다.\nDeep Generative Model: 신경망은 “Universal Approximator”입니다. 이를 통해 변수 간의 복잡한 비선형 관계를 모델링합니다.\nEncoder/Decoder Parameterization: VAE의 인코더와 디코더를 일반적인 MLP가 아닌, 특별히 설계된 GNN으로 파라미터화합니다.\nEvidence Lower Bound (ELBO): 모델의 목적 함수(Score)는 VAE의 ELBO가 됩니다. 이는 데이터의 우도(Likelihood)를 최대화하는 방향으로 학습됨을 의미합니다.\n\n\n\n\n\n또한, 저자들은 NOTEARS에서 제안된 행렬 지수(Matrix Exponential) 제약 조건 대신, 딥러닝 프레임워크에서 구현하기 더 용이하고 수치적으로 안정적인 다항식(Polynomial) 형태의 새로운 제약 조건을 제안합니다.\nNOTEARS (Zheng et al., 2018): \\(Tr(e^{A \\circ A}) - d = 0\\)\nDAG-GNN 제안: 수치적 안정성을 높인 변형된 형태를 사용합니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#main-contributions",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#main-contributions",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "",
    "text": "이 논문의 Introduction에서 강조하는 주요 기여점은 다음과 같이 네 가지로 요약할 수 있습니다.\n\nDeep Generative Model 기반 접근:\n\n\n기존의 Linear SEM을 넘어, VAE를 사용하여 데이터의 복잡한 비선형 분포를 포착하고 샘플링할 수 있는 모델을 제안했습니다.\n그래프 구조(Weighted Adjacency Matrix)는 잠재 변수가 아니라, 신경망 파라미터와 함께 학습되는 명시적인 파라미터로 설정됩니다.\n\n\n다양한 데이터 타입 지원:\n\n\nVAE 프레임워크의 특성상, 디코더의 출력 분포(Likelihood)를 적절히 설정함으로써 연속형 변수뿐만 아니라 이산형(Discrete) 변수도 자연스럽게 처리할 수 있습니다.\n\n\n벡터 값 노드(Vector-valued Nodes) 지원:\n\n\nGNN을 사용하므로 각 노드가 단순 스칼라 값이 아닌 벡터 값을 가질 수 있습니다. 이는 각 노드가 여러 특징(Feature)을 가지는 복잡한 시나리오에 적용 가능함을 의미합니다.\n\n\n개선된 Acyclicity Constraint:\n\n\n기존의 행렬 지수 제약 조건이 자동 미분(Automatic Differentiation) 라이브러리에서 구현하기 까다로울 수 있다는 점을 지적하며, 더 실용적이고 수치적으로 안정적인 다항식 기반의 대안을 제시했습니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#problem-definition-faithfulness-structure-learning",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#problem-definition-faithfulness-structure-learning",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "Problem Definition: Faithfulness & Structure Learning",
    "text": "Problem Definition: Faithfulness & Structure Learning\n\n가장 먼저 정립해야 할 개념은 데이터와 그래프 사이의 관계입니다.\nDAG(Directed Acyclic Graph) \\(G\\)와 결합 분포(Joint Distribution) \\(\\mathcal{P}\\)가 서로 Faithful하다는 것은 다음을 의미합니다.\n\n\nFaithfulness Condition (Pearl, 1988)\n분포 \\(\\mathcal{P}\\)에서 성립하는 모든 조건부 독립성(Conditional Independence)이 그래프 \\(G\\)에서의 d-separation 조건에 의해 정확히 함의(entail)될 때, 그리고 그 역도 성립할 때 \\(G\\)와 \\(\\mathcal{P}\\)는 Faithful하다고 합니다.\n\n\n구조 학습(Structure Learning)이란, 미지의 분포로부터 생성된 i.i.d. 샘플 데이터 \\(D\\)가 주어졌을 때, 이 분포와 Faithful한 관계에 있는 (미지의) DAG \\(G\\)를 복원해내는 과정을 말합니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#traditional-approaches-the-era-of-discrete-search",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#traditional-approaches-the-era-of-discrete-search",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "Traditional Approaches: The Era of Discrete Search",
    "text": "Traditional Approaches: The Era of Discrete Search\n\n전통적으로 DAG를 학습하는 알고리즘은 크게 Score-based 방법과 Constraint-based 방법으로 나뉩니다.\n\n\n1) Score-based Approaches\n이 접근법은 그래프의 ’적합도’를 평가하는 점수(Score)를 정의하고, 이 점수를 최적화하는 그래프 구조를 탐색합니다.\n\n점수 기준 (Score Criteria): 주로 베이지안 관점의 점수들이 사용됩니다. 대표적으로 BDeu, BIC(Bayesian Information Criterion) 등이 있으며, 이들은 Decomposable(분해 가능), Consistent(일치성), Score Equivalent(점수 등가성) 등의 좋은 수학적 성질을 가집니다.\n탐색 알고리즘 (Search Procedures): 가능한 모든 그래프를 탐색하는 것은 불가능하므로 다양한 전략이 사용됩니다.\n\nHill-climbing: 지역적 최적해를 찾아가는 탐욕적 방법 (Heckerman et al., 1995 등)\nForward-backward search (Chickering, 2002)\nDynamic Programming (Singh & Moore, 2005 등)\nA* Search: 최단 경로 탐색 알고리즘 응용 (Yuan & Malone, 2013)\nInteger Programming: 정수 계획법을 통한 최적화 (Cussens, 2011 등)\n\n\n\n\n2) Constraint-based Approaches\n\n이 방식은 변수 쌍 사이의 조건부 독립성 검정(Independence Test)을 수행하여 엣지의 존재 여부를 결정합니다.\n대표 알고리즘: SGS, PC (Spirtes et al.), IC (Pearl), FCI (Zhang) 등이 있습니다.\n독립성 검정 결과를 바탕으로 엣지를 제거하거나 방향을 설정하여 그래프를 완성합니다.\n\n\n\n3) Hybrid Approaches & Approximations\n\n순수한 Score-based나 Constraint-based 방법의 단점을 보완하기 위한 시도들도 있습니다.\nHybrid: MMHC (Tsamardinos et al., 2003)와 같이 Constraint-based 방법으로 후보군을 줄인 뒤 Score-based로 최적화하는 방식입니다.\nApproximations: 탐색 공간을 줄이기 위해 Tree-width를 제한하거나(Nie et al., 2014), 트리 구조를 가정하는(Chow & Liu, 1968) 등의 가정을 도입하기도 합니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#the-computational-bottleneck",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#the-computational-bottleneck",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "The Computational Bottleneck",
    "text": "The Computational Bottleneck\n\n이러한 전통적 방법론들이 직면한 가장 큰 문제는 NP-Hardness입니다.\n변수의 수가 늘어남에 따라 가능한 DAG의 수는 초지수적(Superexponential)으로 증가합니다.\n따라서 많은 알고리즘이 이산형 변수(Discrete variables)로 대상을 한정하거나, 변수들이 결합 가우시안 분포(Jointly Gaussian)를 따른다고 가정해야만 했습니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#the-paradigm-shift-continuous-optimization",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#the-paradigm-shift-continuous-optimization",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "The Paradigm Shift: Continuous Optimization",
    "text": "The Paradigm Shift: Continuous Optimization\n\n최근 Zheng et al. (2018)의 연구(NOTEARS)는 이 분야에 새로운 패러다임을 제시했습니다.\n핵심 아이디어: 이산적인 탐색 과정(Discrete Search Procedure)을 등식 제약조건(Equality Constraint)이 있는 연속 최적화 문제로 변환했습니다.\n장점: 경사 하강법(Gradient Descent)과 같은 연속 최적화 기법을 사용하여 DAG 구조를 학습할 수 있게 되었습니다.\n한계: 이 접근법은 구조 복원 성능이 우수하지만, 설명의 편의를 위해 선형 구조 방정식 모델(Linear SEM)에만 적용된다는 한계가 있었습니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#neural-network-approaches",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#neural-network-approaches",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "Neural Network Approaches",
    "text": "Neural Network Approaches\n\n최근에는 신경망(Neural Network)을 이용한 접근 방식도 등장하기 시작했습니다.\nGAN-style Approach (Kalainathan et al., 2018):\n\n각 변수마다 별도의 생성 모델(Generative Model)을 두고, 생성된 샘플과 실제 데이터의 분포를 구분하는 판별자(Discriminator)를 두는 GAN 스타일의 방법론입니다.\n한계: 확장성(Scalability)은 좋아 보이지만, 결정적으로 비순환성(Acyclicity)이 강제되지 않는다는 문제가 있습니다. 즉, 학습된 결과가 DAG임을 보장할 수 없습니다.\n\n\n\nSummary: 기존의 전통적 방법은 탐색 공간 문제로 확장이 어렵고, 최근 등장한 연속 최적화 방법(NOTEARS)은 선형성에 갇혀 있으며, 기존의 딥러닝 접근(GAN)은 DAG 구조를 보장하지 못합니다. DAG-GNN은 이러한 한계점들을 극복하기 위해 제안되었습니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#linear-structural-equation-model-linear-sem",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#linear-structural-equation-model-linear-sem",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "3.1. Linear Structural Equation Model (Linear SEM)",
    "text": "3.1. Linear Structural Equation Model (Linear SEM)\n\n우리가 찾고자 하는 DAG(Directed Acyclic Graph)의 구조는 가중치가 있는 인접 행렬(Weighted Adjacency Matrix) \\(A\\)로 표현됩니다.\n\n\nNotation 및 정의\n\n먼저 모델링에 필요한 변수들을 정의합니다.\n\\(m\\): 노드(변수)의 개수입니다.\n\\(A \\in \\mathbb{R}^{m \\times m}\\):\n\nDAG의 가중치 인접 행렬입니다.\n\\(A_{ij}\\)가 0이 아니라면 \\(i\\)에서 \\(j\\)로 가는 엣지가 존재함을 의미합니다.\n\n\\(X \\in \\mathbb{R}^{m \\times d}\\):\n\n\\(m\\)개의 변수에 대한 데이터 행렬입니다.\n일반적인 문헌에서 변수는 스칼라(\\(d=1\\))로 취급되지만, 본 논문에서는 이를 \\(d\\)-차원 벡터로 일반화(Generalize)하여 Vector-valued Node를 다룹니다.\n각 행(Row)은 하나의 변수(노드)에 대응하고, 각 열(Column)은 해당 변수의 특징(Feature) 혹은 샘플 차원을 의미합니다.\n\n\\(Z \\in \\mathbb{R}^{m \\times d}\\):\n\n노이즈 행렬(Noise Matrix)입니다.\n외생 변수(Exogenous variable)에 해당합니다.\n\n\n\n\n선형 관계식 (The Model)\n\nLinear SEM은 변수 \\(X\\)가 부모 변수들의 선형 결합(Linear Combination)과 노이즈 \\(Z\\)의 합으로 생성된다고 가정합니다. 이를 행렬식으로 표현하면 다음과 같습니다.\n\n\\[\nX = A^T X + Z\n\\tag{1}\\]\n\n이 식은 “현재 노드의 값(\\(X\\))은 부모 노드들의 값(\\(A^T X\\))에 가중치를 곱해 더한 뒤, 고유한 노이즈(\\(Z\\))를 더한 것과 같다”는 인과적 메커니즘을 나타냅니다.\n\n\n\nFrom Structure to Generation (Derivation)\n\n이제 이 구조 방정식(Structural Equation)을 데이터를 생성하는 생성 모델(Generative Model)의 관점으로 전환해보겠습니다.\n이를 위해서는 \\(Z\\)에서 \\(X\\)를 만들어내는 과정으로 수식을 변형해야 합니다.\n\n\nAdjacency Matrix\n\n사이클 부재 (Acyclicity): DAG의 가장 중요한 성질 중 하나는, 그래프 내에 사이클(Cycle)이 없기 때문에 모든 노드를 위상 정렬(Topological Order) 순서로 나열할 수 있다는 점입니다.\n행렬의 형태: 노드들을 위상 정렬 순서(\\(\\pi\\))대로 재배열하면, 인접 행렬 \\(A\\)는 엄격한 상삼각 행렬(Strictly Upper Triangular Matrix)이 됩니다.\n\n즉, 대각 성분과 그 아래 성분들이 모두 0이 됩니다 (\\(A_{ij} = 0 \\text{ for } i \\ge j\\)).\n이는 어떤 노드도 자기 자신이나 자신의 후손(descendant)으로부터 영향을 받지 않음을 수학적으로 보장합니다.\n\n위상 정렬된 그래프의 인접 행렬 \\(A\\)는 다음과 같은 형태를 띱니다. 대각선(Diagonal)을 포함한 하단 부분이 모두 0이 되는 것이 핵심입니다.\n\n\\[\nA_{\\pi} =\n\\begin{bmatrix}\n\\color{red}0 & w_{12} & w_{13} & \\cdots & w_{1d} \\\\\n\\color{blue}0 & \\color{red}0 & w_{23} & \\cdots & w_{2d} \\\\\n\\color{blue}0 & \\color{blue}0 & \\color{red}0 & \\cdots & w_{3d} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\color{blue}0 & \\color{blue}0 & \\color{blue}0 & \\cdots & \\color{red}0\n\\end{bmatrix}\n\\]\n\n\\(\\color{red}{0}\\) (대각 성분): \\(A_{ii} = 0\\). 자기 자신으로 돌아오는 루프(Self-loop)가 없음.\n\\(\\color{blue}{0}\\) (하삼각 성분): \\(A_{ji} = 0 \\quad (\\text{where } j &gt; i)\\). 역방향(미래에서 과거로) 연결이 없음.\n결론: \\(i \\ge j\\) 인 모든 성분에 대해 \\(A_{ij} = 0\\) 입니다.\n\n\n\nTransformation\n\n식 (1)을 \\(X\\)에 대해 정리하는 과정을 단계별로 유도해보겠습니다.\n\n\\[\n\\begin{aligned}\nX - A^T X &= Z \\\\\n(I - A^T)X &= Z \\\\\nX &= (I - A^T)^{-1} Z\n\\end{aligned}\n\\]\n\n\nEquivalence with Ancestral Sampling\n\\[\nX = (I - A^T)^{-1} Z\n\\tag{2}\\]\n\n이 식은 “DAG를 따르는 Ancestral Sampling” 과정을 수학적으로 압축해 놓은 형태입니다. 그 이유를 단계별로 살펴보겠습니다.\n\n\nAncestral Sampling이란?\n\nAncestral Sampling(조상 샘플링)은 베이지안 네트워크에서 데이터를 생성하는 가장 표준적인 방법입니다.\n인과관계의 흐름(부모 \\(\\to\\) 자식)에 따라 순차적으로 값을 결정하는 방식입니다.\n\n\nTop-down: 부모가 없는 루트 노드(조상)의 값을 먼저 노이즈(\\(Z\\))로부터 결정합니다.\n\n\nPropagation: 그 결정된 값이 자식 노드로 전파되어, 자식 노드의 값 결정에 영향을 줍니다.\n\n\n이 과정을 위상 정렬(Topological Sort) 순서대로 끝까지 반복합니다.\n\n\n\n\n\nNeumann Series를 통한 연결\n\n식 (2) 의 역행렬 부분 \\((I - A^T)^{-1}\\)을 노이만 급수(Neumann Series)를 이용해 전개합니다.\n\n\\[\n(I - A^T)^{-1} = I + A^T + (A^T)^2 + (A^T)^3 + \\dots\n\\]\n\n이 전개식을 식 2에 대입하면 다음과 같습니다.\n\n\\[\nX = \\underbrace{I \\cdot Z}_{\\text{Self}} + \\underbrace{A^T \\cdot Z}_{\\text{Parents}} + \\underbrace{(A^T)^2 \\cdot Z}_{\\text{Grandparents}} + \\dots\n\\]\n\n\n행렬 거듭제곱(\\(A^k\\))의 의미\n\n여기서 행렬의 거듭제곱 항들은 그래프 이론에서 경로(Path)의 개념과 일치합니다.\n\n\\(I\\) (0-hop): 자기 자신의 고유한 노이즈(\\(Z\\))입니다.\n\\(A^T\\) (1-hop): 부모 노드들로부터 직접 받는 영향입니다.\n\\((A^T)^2\\) (2-hop): 부모를 거쳐서 오는 조부모(Grandparents)의 영향입니다.\n\\((A^T)^k\\) (\\(k\\)-hop): \\(k\\)단계를 거쳐서 오는 \\(k\\)대 조상들의 영향입니다.\n\n즉, \\(X = (I - A^T)^{-1} Z\\)라는 수식은 “나의 값(\\(X\\))은 내 고유한 성향(\\(Z\\))뿐만 아니라, 부모, 조부모 등 모든 조상들의 영향력이 누적되어 형성된 것이다”라는 Ancestral Sampling의 철학을 행렬 연산 한 번으로 표현한 것입니다.\n\n\n\n\n\n\n\nNote보충: 왜 거듭제곱이 경로인가? (수학적 귀납법 증명)\n\n\n\n\n\n행렬 \\(A\\)의 거듭제곱 \\(A^k\\)의 \\((i, j)\\) 성분이 노드 \\(i\\)에서 \\(j\\)로 가는 길이 \\(k\\)인 모든 경로의 가중치 합임을 수학적 귀납법으로 간단히 증명할 수 있습니다.\n명제 \\(P(k)\\): \\((A^k)_{ij}\\)는 \\(i \\to j\\)로 가는 길이 \\(k\\)인 경로들의 가중치 합이다.\n1. 기초 단계 (Base Case, \\(k=1\\)): 정의에 의해 \\((A^1)_{ij} = A_{ij}\\)입니다. 이는 \\(i\\)에서 \\(j\\)로 직접 연결된 엣지(길이 1)의 가중치이므로 명제 \\(P(1)\\)은 참입니다.\n2. 귀납 가정 (Inductive Step): 임의의 자연수 \\(k\\)에 대해 \\(P(k)\\)가 참이라고 가정합니다. 즉, \\((A^k)_{it}\\)는 \\(i \\to t\\)로 가는 길이 \\(k\\)인 경로의 합입니다.\n이제 \\(k+1\\)일 때를 살펴봅니다. 행렬 곱셈의 정의에 따라: \\[\n(A^{k+1})_{ij} = (A^k \\cdot A)_{ij} = \\sum_{t} (A^k)_{it} \\cdot A_{tj}\n\\]\n이 수식의 의미를 해석해 보면: * \\((A^k)_{it}\\): \\(i\\)에서 중간 노드 \\(t\\)까지 가는 길이 \\(k\\)인 경로 (귀납 가정) * \\(A_{tj}\\): \\(t\\)에서 도착 노드 \\(j\\)로 가는 길이 \\(1\\)인 엣지 * \\(\\sum_{t}\\): 가능한 모든 중간 경유지 \\(t\\)에 대해 합산\n즉, “\\(i\\)에서 \\(t\\)까지 \\(k\\)걸음으로 간 뒤, \\(t\\)에서 \\(j\\)로 1걸음 더 가는 모든 경우의 수”를 더한 것이므로, 이는 \\(i\\)에서 \\(j\\)로 가는 길이 \\(k+1\\)인 모든 경로의 합과 같습니다.\n3. 결론: 수학적 귀납법에 의해 모든 자연수 \\(k\\)에 대해 명제 \\(P(k)\\)는 참입니다. 따라서 \\((A^T)^k\\)는 \\(k\\)단계를 거친 조상들의 영향력을 의미하게 됩니다.\n\n\n\n\n\n\n결론: VAE 도입의 동기\n\n이러한 관점은 DAG 구조 학습 문제를 새로운 시각으로 바라보게 합니다.\n복잡한 인과관계 추론 문제를 “노이즈 \\(Z\\)를 데이터 \\(X\\)로 매핑하는 인코더/디코더를 학습하는 문제”로 치환할 수 있습니다.\n이것이 바로 저자들이 생성 모델의 대표 주자인 VAE(Variational Autoencoder)를 도입하여, 인코더와 디코더를 통해 \\(A\\)를 학습하고자 한 핵심적인 동기(Motivation)입니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#proposed-graph-neural-network-model",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#proposed-graph-neural-network-model",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "3.2. Proposed Graph Neural Network Model",
    "text": "3.2. Proposed Graph Neural Network Model\n\n앞선 섹션에서 우리는 Linear SEM이 다음과 같이 노이즈 \\(Z\\)를 데이터 \\(X\\)로 변환하는 선형 과정으로 표현됨을 확인했습니다.\n본 섹션에서는 이 수식을 Graph Neural Network(GNN)의 관점에서 재해석하고, 이를 바탕으로 비선형 관계까지 포착할 수 있는 DAG-GNN만의 독창적인 아키텍처를 검토합니다.\n\n\nLinear SEM as a Graph Neural Network\n\n저자들은 위 식 (2)를 딥러닝 커뮤니티의 관점에서 다음과 같은 일반적인 함수 꼴로 바라봅니다.\n\n\\[\nX = f_A(Z)\n\\]\n\n여기서 \\(f_A\\)는 그래프 구조(인접 행렬 \\(A\\))에 의해 파라미터화된 함수입니다.\n즉, “노드 특징(Feature)인 \\(Z\\)를 입력받아, 그래프 구조를 통과시켜 고차원 표현인 \\(X\\)를 반환하는 과정”으로 해석할 수 있습니다.\n\n\nExisting GNN Architectures\n\n대부분의 최신 GNN 모델들(GCN, GraphSAGE, GAT 등)도 이와 유사한 형태를 띱니다.\n예를 들어, 널리 쓰이는 GCN (Graph Convolutional Network)의 수식은 다음과 같습니다. \\[\nX = \\hat{A} \\cdot \\text{ReLU}(\\hat{A} Z W^1) \\cdot W^2\n\\]\n\n\\(\\hat{A}\\): 정규화된 인접 행렬 (Normalized Adjacency Matrix)\n\\(W^1, W^2\\): 학습 가능한 가중치 행렬\n\n하지만 일반적인 GNN은 주어진 고정된 그래프 위에서 노드 임베딩을 학습하는 것이 목표인 반면, 우리의 목표는 그래프 구조 \\(A\\) 자체를 학습하는 것입니다.\n\n\n\n\nThe DAG-GNN Architecture\n\n저자들은 Linear SEM의 구조적 특성(\\((I-A^T)^{-1}\\))을 그대로 계승하면서, 신경망의 표현력을 더하기 위해 새로운 GNN 아키텍처를 제안합니다.\n\n\nThe Proposed Equation\n제안하는 모델의 핵심 수식은 다음과 같습니다.\n\\[\nX = f_2 \\left( (I - A^T)^{-1} f_1(Z) \\right)\n\\tag{3}\\]\n\n이 수식은 세 단계의 변환 과정으로 구성됩니다:\n\nTransforming Noise (\\(f_1(Z)\\)):\n\n\n입력 노이즈 \\(Z\\)를 비선형 함수 \\(f_1\\) (MLP 등)을 통해 변환합니다.\n이는 단순한 가우시안 노이즈가 아닌 복잡한 잠재 분포를 표현하기 위함입니다.\n\n\nStructural Aggregation (\\((I-A^T)^{-1}\\)):\n\n\n변환된 신호들이 DAG 구조 \\(A\\)에 따라 전파(Propagation)됩니다.\n이 부분은 Linear SEM의 인과적 흐름을 그대로 따르며, 부모 노드의 영향력이 자식 노드로 전달되는 과정을 수학적으로 구현합니다.\n\n\nTransforming into Data Space (\\(f_2(\\cdot)\\)):\n\n\n구조적 정보가 반영된 신호를 다시 비선형 함수 \\(f_2\\)를 통해 관측 데이터 공간(\\(X\\))으로 매핑합니다.\n\n\n\n\n\nGeneralizing the Linear SEM (Interpretation)\n\n이 모델이 중요한 이유는, 이것이 기존의 Linear SEM을 비선형(Non-linear)으로 일반화(Generalize)한 형태이기 때문입니다.\n만약 \\(f_2\\)가 역함수(Invertible)를 가진다고 가정해봅시다. 그렇다면 식 (3)의 양변에 \\(f_2^{-1}\\)를 취하고 정리하여 다음과 같은 관계를 유도할 수 있습니다.\n\n\nDerivation\n\\[\n\\begin{aligned}\nX &= f_2((I - A^T)^{-1} f_1(Z)) \\\\\nf_2^{-1}(X) &= (I - A^T)^{-1} f_1(Z) \\\\\n(I - A^T) f_2^{-1}(X) &= f_1(Z) \\\\\nf_2^{-1}(X) - A^T f_2^{-1}(X) &= f_1(Z) \\\\\nf_2^{-1}(X) &= A^T f_2^{-1}(X) + f_1(Z)\n\\end{aligned}\n\\]\n\n\nGeneralized SEM\n\n결과적으로 다음과 같은 Generalized SEM 식을 얻게 됩니다.\n\n\\[\n\\underbrace{f_2^{-1}(X)}_{\\text{Transformed Data}} = A^T \\underbrace{f_2^{-1}(X)}_{\\text{Parents}} + \\underbrace{f_1(Z)}_{\\text{Transformed Noise}}\n\\]\n\nLinear SEM (\\(X = A^T X + Z\\))과의 비교:\n\nLinear SEM은 데이터 \\(X\\) 자체가 선형 결합을 이룹니다.\nDAG-GNN은 데이터 \\(X\\)를 적절히 비선형 변환한 \\(f_2^{-1}(X)\\) 공간에서 선형 관계(\\(A^T\\))가 성립한다고 가정합니다.\n또한 노이즈 역시 단순 합이 아니라 \\(f_1(Z)\\) 형태로 비선형적으로 결합됩니다.\n\n이러한 설계를 통해 DAG-GNN은 변수 간의 관계가 복잡한 비선형일 때도, 이를 잠재 공간(Latent Space)에서의 구조적 관계로 포착할 수 있게 됩니다.\n\n\n\n\nNote on Implementation\n\n저자들은 \\(f_1\\)과 \\(f_2\\)를 구체적으로 어떤 신경망으로 구현할지에 대해서는 후속 섹션으로 미루고 있습니다.\n다만 중요한 제약 사항 하나를 언급합니다:\n\n\n“\\(f_2\\)의 마지막 활성화 함수(Activation function)는 반드시 변수 \\(X\\)의 타입(Domain)과 일치해야 한다.”\n\n\n예를 들어, \\(X\\)가 실수형(Continuous)이라면 Identity 함수를, 이진형(Binary)이라면 Sigmoid 등을 사용해야 한다는 뜻입니다. 이는 추후 논의될 Discrete Variable 처리를 위한 포석입니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#model-learning-with-variational-autoencoder",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#model-learning-with-variational-autoencoder",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "3.3. Model Learning with Variational Autoencoder",
    "text": "3.3. Model Learning with Variational Autoencoder\n\n이제 우리의 목표는 주어진 데이터 \\(X^1, \\dots, X^n\\)을 가장 잘 설명하는 모델 파라미터(신경망 가중치 및 그래프 구조 \\(A\\))를 찾는 것입니다.\n본 섹션에서는 이를 위해 Variational Autoencoder (VAE) 프레임워크를 도입하는 과정과 그 수학적 배경을 상세히 다룹니다.\n\n\nThe Challenge of Intractability\n\n일반적으로 확률 모델의 학습은 관측 데이터의 로그 우도(Log-Likelihood), 또는 로그 증거(Log-Evidence)를 최대화하는 방향으로 진행됩니다.\n데이터 샘플 \\(X^1, \\dots, X^n\\)이 주어졌을 때, 평균 로그 증거는 다음과 같습니다.\n\n\\[\n\\frac{1}{n} \\sum_{k=1}^n \\log p(X^k) = \\frac{1}{n} \\sum_{k=1}^n \\log \\int p(X^k | Z) p(Z) \\, dZ\n\\]\n\n여기서 문제가 발생합니다.\n\n우변의 적분 \\(\\int p(X^k | Z) p(Z) \\, dZ\\)는 잠재 변수 \\(Z\\)의 모든 가능한 값에 대해 주변화(Marginalization)를 수행해야 합니다.\n하지만 \\(Z\\)가 고차원이거나 \\(p(X|Z)\\)가 복잡한 신경망(Neural Network)으로 구성된 경우, 이 적분은 해석적으로 구하는 것이 불가능하며(Intractable), 수치적으로 근사하기에도 계산 비용이 매우 큽니다.\n\n따라서 저자들은 이 문제를 해결하기 위해 변분 베이즈(Variational Bayes) 방법론을 도입합니다.\n\n\n\nThe Evidence Lower Bound (ELBO)\n\n계산 불가능한 사후 분포 \\(p(Z|X)\\)를 근사하기 위해, 우리는 다루기 쉬운 분포인 변분 사후 분포(Variational Posterior) \\(q(Z|X)\\)를 도입합니다.\n\n\nDerivation of ELBO\n\n로그 증거 \\(\\log p(X)\\)에서 출발하여 ELBO(Evidence Lower Bound)를 유도하는 과정은 다음과 같습니다. (편의상 \\(X^k\\)를 \\(X\\)로 표기합니다.)\n\n로그 내부의 분모/분자에 \\(q(Z|X)\\) 곱하기: \\[\n  \\begin{aligned}\n  \\log p(X) &= \\log \\int p(X|Z) p(Z) \\, dZ \\\\  \n  &= \\log \\int p(X, Z) \\, dZ \\\\\n  &= \\log \\int p(X, Z) \\frac{q(Z|X)}{q(Z|X)} \\, dZ\n  \\end{aligned}\n  \\]\n\n\n기댓값 형태로 변환: \\[\n  \\begin{aligned}\n  &= \\log \\int \\frac{p(X, Z)}{q(Z|X)} q(Z|X) \\, dZ \\\\\n  &= \\log \\mathbb{E}_{q(Z|X)} \\left[ \\frac{p(X, Z)}{q(Z|X)} \\right]\n  \\end{aligned}\n  \\]\n\n\n젠센 부등식(Jensen’s Inequality) 적용:\n\n\n로그 함수는 오목(Concave) 함수이므로 \\(\\log(\\mathbb{E}[Y]) \\ge \\mathbb{E}[\\log(Y)]\\)가 성립합니다. \\[\n  \\ge \\mathbb{E}_{q(Z|X)} \\left[ \\log \\frac{p(X, Z)}{q(Z|X)} \\right]\n  \\]\n\n\n항 분리 및 정리 (ELBO의 도출):\n\n\n로그의 성질을 이용해 항을 분리하고, \\(Z\\)와 관련된 항들을 묶어 정리합니다.\n\n\\[\n  \\begin{aligned}\n  \\mathcal{L} &= \\mathbb{E}_{q(Z|X)} \\left[ \\log \\frac{p(X|Z)p(Z)}{q(Z|X)} \\right] \\\\\n  &= \\mathbb{E}_{q(Z|X)} \\Big[ \\log p(X|Z) + \\underbrace{\\log p(Z) - \\log q(Z|X)}_{\\text{Latent Variable Terms}} \\Big]\n  \\end{aligned}\n  \\]\n\n여기서 KL Divergence(Kullback-Leibler Divergence)의 정의를 도입하여 식을 간결하게 정리할 수 있습니다.\n두 확률분포 \\(q\\)와 \\(p\\)의 차이를 측정하는 KL Divergence는 다음과 같이 정의됩니다. \\[D_{\\text{KL}}(q || p) = \\mathbb{E}_{x \\sim q} [ \\log q(x) - \\log p(x) ]\\]\n위 식의 뒷부분(\\(\\log p(Z) - \\log q(Z|X)\\))은 KL Divergence 정의와 부호가 반대입니다. 따라서 마이너스(\\(-\\))를 밖으로 빼내어 형태를 맞춥니다.\n\n\\[\n  \\begin{aligned}\n  &= \\mathbb{E}_{q(Z|X)} [\\log p(X|Z)] - \\mathbb{E}_{q(Z|X)} [\\underbrace{\\log q(Z|X) - \\log p(Z)}_{D_{\\text{KL}}(q||p) \\text{ Form}} ] \\\\\n  &= \\mathbb{E}_{q(Z|X)} [\\log p(X|Z)] - D_{\\text{KL}}(q(Z|X) || p(Z))\n  \\end{aligned}\n  \\]\n\n최종적으로 식 (4)에 해당하는 ELBO(Evidence Lower Bound)를 얻게 됩니다.\n\n\n\\[\n\\mathcal{L}_{\\text{ELBO}} \\equiv -D_{\\text{KL}} \\Big( q(Z|X^k) \\,||\\, p(Z) \\Big) + \\mathbb{E}_{q(Z|X^k)} \\Big[ \\log p(X^k|Z) \\Big]\n\\tag{4}\\]\n\n\nInterpretation of ELBO\n\n식 (4)는 두 가지 직관적인 항으로 구성됩니다.\n\nReconstruction Loss: \\(\\mathbb{E}_{q(Z|X^k)} [\\log p(X^k|Z)]\\)\n\n\n잠재 변수 \\(Z\\)로부터 데이터 \\(X\\)를 복원할 확률(Likelihood)을 최대화합니다.\nAutoencoder의 복원 오차 최소화와 대응됩니다.\n\n\nRegularization Term: \\(-D_{\\text{KL}}(q(Z|X^k) || p(Z))\\)\n\n\n우리가 근사한 사후 분포 \\(q(Z|X)\\)가 사전 분포 \\(p(Z)\\)(일반적으로 표준 정규분포)와 얼마나 다른지를 측정합니다.\n이 차이를 최소화(음수이므로 최대화)하여, 잠재 공간이 과도하게 찌그러지는 것을 방지합니다.\n\n결론적으로, 실제 로그 증거와 ELBO의 차이는 KL Divergence \\(D_{\\text{KL}}(q(Z|X) || p(Z|X)) \\ge 0\\) 만큼 발생하므로, ELBO를 최대화하는 것은 로그 증거의 하한(Lower Bound)을 최대화하는 것과 같습니다.\n\n\n\n\nArchitecture: Encoder and Decoder\n\nVAE 프레임워크를 DAG-GNN에 적용하기 위해, Encoder와 Decoder를 구체적인 신경망 구조로 정의해야 합니다.\n\n\nDecoder (Generative Model)\n\nDecoder는 잠재 변수 \\(Z\\)에서 데이터 \\(X\\)를 생성하는 역할을 합니다.\n이는 3.2절에서 정의한 Generalized SEM (식 3)과 정확히 일치합니다.\n\n\\[\n\\text{Decoder: } \\quad X = f_2 \\left( (I - A^T)^{-1} f_1(Z) \\right)\n\\]\n\n여기서 \\((I-A^T)^{-1}\\) 항은 \\(Z\\)의 정보가 그래프 구조를 따라 퍼져나가며(Propagation) \\(X\\)를 형성하는 과정을 담당합니다.\n\n\n\nEncoder (Inference Model)\n\nEncoder는 관측된 데이터 \\(X\\)로부터 잠재 변수 \\(Z\\)를 추론하는 역할을 합니다.\n저자들은 Decoder의 역연산 개념을 적용하여 다음과 같은 Encoder 구조를 제안합니다.\n\n\\[\n\\text{Encoder: } \\quad Z = f_4 \\left( (I - A^T) f_3(X) \\right)\n\\tag{5}\\]\n\n이 수식의 의미는 다음과 같습니다:\n\n\n\\(f_3(X)\\):\n\n\n데이터 \\(X\\)를 비선형 변환합니다. 개념적으로 Decoder의 \\(f_2\\)의 역함수 역할을 수행합니다.\n\n\n\\((I - A^T)\\):\n\n\nDecoder에서는 역행렬 \\((I-A^T)^{-1}\\)을 사용해 정보를 확산시켰다면, Encoder에서는 그 역연산인 \\((I-A^T)\\)를 곱합니다.\n이는 섞여 있는 정보들로부터 부모 노드의 영향을 제거하여 독립적인 노이즈(Latent factor)를 발라내는 과정으로 해석할 수 있습니다.\n\n\n\\(f_4(\\cdot)\\):\n\n\n최종적으로 비선형 변환을 통해 \\(Z\\) 공간으로 매핑합니다. 개념적으로 Decoder의 \\(f_1\\)의 역함수 역할을 합니다.\n\n\n\n\n\nParameterization\n\n함수: \\(f_1, f_2\\) (Decoder)와 \\(f_3, f_4\\) (Encoder)는 모두 MLP(Multi-Layer Perceptron)로 파라미터화됩니다.\n분포:\n\n\\(q(Z|X)\\)와 \\(p(X|Z)\\)는 각각 가우시안 분포 등을 가정하며, 신경망은 이 분포의 평균(\\(\\mu\\))과 분산(\\(\\sigma^2\\))을 출력하도록 설계됩니다.\n구체적인 분포의 형태와 활성화 함수는 데이터 \\(X\\)의 타입(연속형 vs 이산형)에 따라 결정됩니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#architecture-and-loss-function",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#architecture-and-loss-function",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "3.4. Architecture and Loss Function",
    "text": "3.4. Architecture and Loss Function\n\n이전 섹션에서 우리는 DAG 구조 학습을 위한 VAE 프레임워크를 정의했습니다.\n이제 추상적인 수식(\\(f_1, f_2, f_3, f_4\\))을 넘어, 실제로 모델을 어떻게 구현하고 학습시킬지 구체적인 Architecture와 Loss Function을 정의할 차례입니다.\n이 과정에서 우리는 입력 데이터 \\(X\\)와 잠재 변수 \\(Z\\)의 확률 분포를 가정하고, 이를 바탕으로 ELBO(Evidence Lower Bound)를 계산 가능한 수식으로 유도합니다.\n\n\nDistribution Specifications\n\n모델 학습을 위해서는 변수들의 확률 분포를 명시해야 합니다.\n여기서 \\(X\\)와 \\(Z\\)는 모두 \\(m \\times d\\) 차원의 행렬입니다 (\\(m\\): 노드 수, \\(d\\): 특징 차원).\n\n\nPrior Distribution \\(p(Z)\\)\n\n잠재 변수 \\(Z\\)의 사전 분포(Prior)는 가장 일반적인 가정인 Standard Matrix Normal 분포를 따릅니다.\n\n\\[\np(Z) = \\mathcal{MN}_{m \\times d}(0, I, I)\n\\]\n\n이는 \\(Z\\)의 모든 원소 \\(Z_{ij}\\)가 평균이 0이고 분산이 1인 독립적인 정규분포(i.i.d. Gaussian)를 따른다는 것을 의미하며, 계산의 편의성을 위해 다음과 같이 요소별(element-wise) 분포로 취급할 수 있습니다. \\[p(Z_{ij}) = \\mathcal{N}(0, 1)\\]\n\n\n\n\nEncoder Architecture (Inference Model)\n\nEncoder는 데이터 \\(X\\)를 입력받아 잠재 변수 \\(Z\\)의 분포 \\(q(Z|X)\\)를 추론합니다.\n가정: \\(q(Z|X)\\)는 Factored Gaussian (대각 공분산을 갖는 정규분포)을 따른다고 가정합니다.\n구성: 평균 행렬 \\(M_Z \\in \\mathbb{R}^{m \\times d}\\)와 표준편차 행렬 \\(S_Z \\in \\mathbb{R}^{m \\times d}\\)를 출력합니다.\n함수 매핑:\n\n앞선 섹션의 \\(f_3\\) (데이터 변환): MLP (Multi-Layer Perceptron)\n앞선 섹션의 \\(f_4\\) (잠재 공간 매핑): Identity Mapping\n\n이를 수식으로 표현하면 다음과 같습니다.\n\n\\[\n[M_Z | \\log S_Z] = \\underbrace{(I - A^T)}_{\\text{Structure Removal}} \\underbrace{\\text{MLP}(X, W^1, W^2)}_{\\text{Feature Transform}}\n\\tag{6}\\]\n\n여기서 \\(\\text{MLP}(X, W^1, W^2) := \\text{ReLU}(X W^1) W^2\\) 입니다.\n\n\nInterpretation\n\n식 (6)을 보면 \\((I-A^T)\\) 연산이 MLP 다음에 적용됩니다.\n이는 MLP를 통해 데이터의 비선형 특징을 추출한 뒤, \\((I-A^T)\\) 선형 변환을 통해 변수 간의 인과적 종속성(Parent effect)을 제거(Decorrelation)하여 독립적인 잠재 변수 \\(Z\\)를 만들어내겠다는 의도입니다.\n\n\n\n\nDecoder Architecture (Generative Model)\n\nDecoder는 잠재 변수 \\(Z\\)로부터 데이터 \\(X\\)를 복원(Reconstruction)합니다.\n가정: \\(p(X|Z)\\) 역시 Factored Gaussian을 따른다고 가정합니다.\n구성: 평균 행렬 \\(M_X \\in \\mathbb{R}^{m \\times d}\\)와 표준편차 행렬 \\(S_X \\in \\mathbb{R}^{m \\times d}\\)를 출력합니다.\n함수 매핑:\n\n앞선 섹션의 \\(f_1\\) (노이즈 변환): Identity Mapping\n앞선 섹션의 \\(f_2\\) (데이터 복원): MLP\n\n이를 수식으로 표현하면 다음과 같습니다.\n\n\\[\n[M_X | \\log S_X] = \\underbrace{\\text{MLP}}_{\\text{Data Generation}} \\left( \\underbrace{(I - A^T)^{-1} Z}_{\\text{Structure Propagation}}, W^3, W^4 \\right)\n\\tag{7}\\]\n\nInterpretation\n\n저자들은 \\(f_1\\)과 \\(f_2\\)의 위치를 바꾸어 실험해 보았으나, 현재의 설계(내부에 Identity, 외부에 MLP)가 성능이 더 좋았다고 보고합니다.\n그 이유는 식 (7)의 설계가 Linear SEM의 구조적 변환 \\((I-A^T)^{-1}Z\\)를 강조하기 때문입니다.\n구조적 전파(Propagation)가 먼저 일어난 뒤 MLP가 비선형성을 입히는 방식이 비선형 데이터 생성 과정을 더 잘 포착한다는 것입니다.\n\n\n\n\nFigure 1: DAG-GNN의 전체 아키텍처 (Continuous Variables). 입력 \\(X\\)가 MLP와 \\((I-A^T)\\)를 거쳐 잠재 변수 \\(Z\\)의 통계량(\\(M_Z, S_Z\\))으로 인코딩되고, 샘플링된 \\(Z\\)는 \\((I-A^T)^{-1}\\)와 MLP를 거쳐 다시 \\(X\\)의 통계량(\\(M_X, S_X\\))으로 디코딩된다.\n\n\n\n\n\nLoss Function Derivation (ELBO)\n\n이제 정의된 분포(\\(p(Z), q(Z|X), p(X|Z)\\))를 바탕으로, VAE의 목적 함수인 ELBO를 구체적인 수식으로 유도해 봅시다.\n\n\\[\n\\mathcal{L}_{\\text{ELBO}} = -D_{\\text{KL}}(q(Z|X) || p(Z)) + \\mathbb{E}_{q(Z|X)}[\\log p(X|Z)]\n\\]\n\nKL Divergence Term (Regularization)\n\n이 항은 근사 분포 \\(q(Z|X)\\)가 사전 분포 \\(p(Z)\\)와 얼마나 다른지를 측정합니다.\n두 분포가 모두 가우시안일 경우, 복잡한 적분 없이도 파라미터(\\(M_Z, S_Z\\))만으로 계산 가능한 Closed Form(닫힌 해)이 존재합니다.\n가정:\n\nVariational Posterior: \\(q(Z|X) = \\mathcal{N}(M_Z, S_Z^2)\\) (Factored Gaussian)\nPrior: \\(p(Z) = \\mathcal{N}(0, I)\\) (Standard Normal)\n\n모든 변수가 독립(Independent)이므로, 단일 원소 \\(z \\sim q(z) = \\mathcal{N}(\\mu, \\sigma^2)\\)와 \\(p(z) = \\mathcal{N}(0, 1)\\) 사이의 KL Divergence를 먼저 유도한 뒤 합산하면 됩니다.\n\n\n\n\n\n\n\nNote상세 유도: 두 가우시안 사이의 KL Divergence\n\n\n\n\n\n1. 정의: \\[D_{\\text{KL}}(q||p) = \\mathbb{E}_{z \\sim q} [\\log q(z) - \\log p(z)]\\]\n2. 로그 확률밀도함수 전개: \\[\\log q(z) = -\\frac{1}{2}\\log(2\\pi) - \\log\\sigma - \\frac{(z-\\mu)^2}{2\\sigma^2}\\] \\[\\log p(z) = -\\frac{1}{2}\\log(2\\pi) - \\frac{z^2}{2}\\]\n3. 차이 계산: \\[\n\\begin{aligned}\n\\log q(z) - \\log p(z) &= \\left( -\\log\\sigma - \\frac{(z-\\mu)^2}{2\\sigma^2} \\right) - \\left( - \\frac{z^2}{2} \\right) \\\\\n&= -\\log\\sigma + \\frac{1}{2}z^2 - \\frac{(z-\\mu)^2}{2\\sigma^2}\n\\end{aligned}\n\\]\n4. 기댓값(\\(\\mathbb{E}_q\\)) 취하기: \\(z \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)일 때, \\(\\mathbb{E}[z^2] = \\mu^2 + \\sigma^2\\) 이고 \\(\\mathbb{E}[(z-\\mu)^2] = \\sigma^2\\) 임을 이용합니다.\n\\[\n\\begin{aligned}\n\\mathbb{E}_q [\\dots] &= -\\log\\sigma + \\frac{1}{2}(\\mu^2 + \\sigma^2) - \\frac{\\sigma^2}{2\\sigma^2} \\\\\n&= -\\log\\sigma + \\frac{1}{2}\\mu^2 + \\frac{1}{2}\\sigma^2 - \\frac{1}{2} \\\\\n&= \\frac{1}{2} (\\sigma^2 + \\mu^2 - 2\\log\\sigma - 1)\n\\end{aligned}\n\\]\n\n\n\n\n위의 스칼라 유도 결과를 행렬 전체(\\(m \\times d\\))에 대해 합산하면 다음과 같습니다.\n\n\\[\nD_{\\text{KL}}\\Big(q(Z|X) \\,||\\, p(Z)\\Big) = \\frac{1}{2} \\sum_{i=1}^m \\sum_{j=1}^d \\left( \\underbrace{(S_Z)_{ij}^2}_{\\sigma^2} + \\underbrace{(M_Z)_{ij}^2}_{\\mu^2} - \\underbrace{2\\log(S_Z)_{ij}}_{2\\log\\sigma} - 1 \\right)\n\\tag{8}\\]\n\n의의: 이 식은 적분(Sampling)이 필요 없으므로 계산이 매우 빠르고, 역전파(Backpropagation)를 통한 미분이 용이하여 안정적인 학습을 가능하게 합니다.\n역할: 잠재 변수 \\(Z\\)가 평균 0, 분산 1인 분포에서 너무 멀어지지 않도록 강제하는 Regularizer 역할을 수행합니다.\n\n\n\nReconstruction Term (Likelihood)\n\n두 번째 항은 모델이 잠재 변수 \\(Z\\)로부터 관측 데이터 \\(X\\)를 얼마나 잘 복원하는지를 나타내는 복원 오차(Reconstruction Error)입니다.\n이 수식이 유도되는 과정은 Factored Gaussian 가정에 의해 다음과 같이 논리적으로 전개됩니다.\n\n\nStep 1: Factored Gaussian 가정 (행렬 \\(\\to\\) 스칼라 분해)\n\n우리가 구해야 할 것은 전체 데이터 행렬 \\(X\\)에 대한 우도 \\(P(X|Z)\\)입니다.\n앞서 우리는 \\(p(X|Z)\\)가 Factored Gaussian을 따른다고 가정했습니다.\n이는 \\(Z\\)가 주어졌을 때 \\(X\\)의 각 원소 \\(X_{ij}\\)가 서로 조건부 독립(Conditionally Independent)임을 의미합니다.\n따라서 결합 확률(Joint Probability)은 개별 스칼라 확률들의 곱으로 분해됩니다.\n\n\\[\nP(X|Z) = \\prod_{i=1}^m \\prod_{j=1}^d p(X_{ij} | Z)\n\\]\n\n\nStep 2: 로그 변환과 덧셈으로의 전환 (\\(\\prod \\to \\sum\\))\n\n목적 함수는 로그 우도(Log-Likelihood)입니다. 양변에 로그를 취하면, 거대한 곱셈이 덧셈(Summation)으로 변환됩니다.\n\n\\[\n\\log P(X|Z) = \\sum_{i=1}^m \\sum_{j=1}^d \\log p(X_{ij} | Z)\n\\]\n\n이제 문제는 복잡한 행렬 연산에서 “개별 요소(\\(X_{ij}\\))의 스칼라 가우시안 로그 우도를 구해서 더하는 문제”로 단순화되었습니다.\n\n\n\nStep 3: 스칼라 가우시안 로그 우도 계산\n\n단일 변수 \\(x\\)가 평균 \\(\\mu\\), 표준편차 \\(\\sigma\\)인 정규분포를 따를 때, 그 로그 확률밀도함수는 다음과 같습니다.\n\n\\[\n\\begin{aligned}\n\\log p(x | \\mu, \\sigma) &= \\log \\left( \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} \\right) \\\\\n&= \\underbrace{-\\log(\\sqrt{2\\pi})}_{\\text{Constant } c} - \\log \\sigma - \\frac{(x - \\mu)^2}{2\\sigma^2}\n\\end{aligned}\n\\]\n\n이 식을 위 Step 2의 합산 기호 안에 대입합니다.\n\n\n\nStep 4: 몬테카를로 근사 (Monte Carlo Approximation)\n\n마지막으로 기댓값 \\(\\mathbb{E}_{q(Z|X)}\\)를 계산하기 위해, 잠재 변수 \\(Z\\)를 \\(L\\)번 샘플링하여 그 평균으로 적분을 근사합니다.\n이 모든 단계를 종합하면 식 (9)를 얻게 됩니다.\n\n\\[\n\\mathbb{E}_{q(Z|X)} \\Big[ \\log p(X|Z) \\Big] \\approx \\frac{1}{L} \\sum_{l=1}^L \\sum_{i=1}^m \\sum_{j=1}^d \\left( \\underbrace{- \\frac{(X_{ij} - (M_X^{(l)})_{ij})^2}{2(S_X^{(l)})_{ij}^2}}_{\\text{Weighted MSE}} \\underbrace{- \\log(S_X^{(l)})_{ij}}_{\\text{Uncertainty Penalty}} \\right) - c\n\\tag{9}\\]\n\n해석: 이 수식은 본질적으로 가중치(분산의 역수)가 적용된 MSE와, 모델이 불확실성(분산)을 무작정 키우는 것을 막는 Penalty(\\(\\log S_X\\))의 합입니다.\n\n\n\n\n\nA Note on Latent Dimensions\n\nLinear SEM에서는 \\(Z\\)를 단순한 “Noise”로 보기에 \\(X\\)와 차원이 같아야 했습니다.\n하지만 VAE 프레임워크에서 \\(Z\\)는 Latent Factor로 해석됩니다.\n따라서 \\(Z\\)의 열(column) 차원을 \\(X\\)의 차원 \\(d\\)와 다르게 설정할 수 있습니다.\n만약 데이터의 내재적 차원(Intrinsic Dimension)이 작다고 판단되면, \\(Z\\)의 차원을 줄여서 모델의 파라미터 수(\\(W^2, W^3\\))를 줄이고 효율적인 표현을 학습할 수 있습니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#discrete-variables",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#discrete-variables",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "3.5. Discrete Variables",
    "text": "3.5. Discrete Variables\n\n현실 세계의 인과관계 데이터는 키, 몸무게 같은 연속형(Continuous) 변수뿐만 아니라, 질병 유무, 성별, 등급과 같은 이산형(Discrete) 변수로 구성된 경우가 많습니다.\nDAG-GNN의 가장 큰 장점 중 하나는 VAE(Variational Autoencoder) 프레임워크를 기반으로 하기 때문에, 데이터의 타입에 따라 우도(Likelihood) 분포만 적절히 교체해주면 자연스럽게 다양한 데이터 타입을 처리할 수 있다는 점입니다.\n이번 포스트에서는 DAG-GNN이 이산형 변수를 어떻게 모델링하는지 그 수식적 변형 과정을 살펴보겠습니다.\n\n\nData Representation (One-Hot Encoding)\n\n이산형 변수를 처리하기 위해 데이터 표현 방식부터 정의합니다.\n가정: 각 변수는 크기(Cardinality)가 \\(d\\)인 유한한 지지 집합(Finite support)을 가집니다.\n입력 \\(X\\): \\(X\\)의 각 행(변수)은 One-Hot Vector로 표현됩니다.\n\n즉, “On” 위치(값이 1인 인덱스)가 해당 변수의 범주(Category)를 나타냅니다.\n따라서 \\(X \\in \\mathbb{R}^{m \\times d}\\) 차원을 유지합니다.\n\n\n\n\nEncoder and Prior (Unchanged)\n\n이산형 데이터를 다룸에도 불구하고 Encoder(Inference Model)와 Prior는 연속형 모델과 동일하게 유지됩니다.\n\nPrior \\(p(Z)\\): 여전히 Standard Matrix Normal \\(\\mathcal{MN}(0, I, I)\\)을 따릅니다.\n\n\nPosterior \\(q(Z|X)\\): Factored Gaussian 분포를 가정합니다.\n\n\nEncoder 함수: 식 (6)의 구조를 그대로 사용합니다.\n\n\n\\[\n[M_Z | \\log S_Z] = (I - A^T) \\text{MLP}(X)\n\\]\n\n이는 잠재 공간(Latent Space) \\(Z\\)는 여전히 연속적인 공간으로 남겨두고, 이 공간에서 그래프 구조 학습과 변분 추론을 수행하겠다는 의도입니다.\n\n\n\nDecoder Modification (Categorical Likelihood)\n\n변화가 필요한 부분은 잠재 변수 \\(Z\\)에서 다시 데이터 \\(X\\)를 복원하는 Decoder(Generative Model) 파트입니다.\n\\(X\\)가 이산형이므로, 더 이상 가우시안 분포를 가정할 수 없습니다.\n\n\nDistribution Assumption\n\n우리는 우도 \\(p(X|Z)\\)를 Factored Categorical Distribution으로 가정합니다.\n출력: 확률 행렬 \\(P_X \\in \\mathbb{R}^{m \\times d}\\)\n각 행(Row)은 해당 변수가 각 범주에 속할 확률을 나타내는 확률 벡터(Probability Vector)가 됩니다.\n\n\n\nArchitecture Change\n\n이를 구현하기 위해, Decoder의 마지막 변환 함수 \\(f_2\\)를 Softmax 함수로 변경합니다.\n기존 (Continuous): \\(f_2 = \\text{MLP}\\) (Identity mapping for output range)\n변경 (Discrete): \\(f_2 = \\text{softmax}(\\text{MLP})\\)\n수식으로 표현하면 다음과 같습니다:\n\n\\[\nP_X = \\text{softmax} \\left( \\text{MLP} \\big( (I - A^T)^{-1} Z, W^3, W^4 \\big) \\right)\n\\tag{10}\\]\n\n여기서 softmax는 각 행(Row-wise)에 대해 적용되어, 각 변수의 범주별 확률 합이 1이 되도록 만듭니다.\n\n\n\n\nLoss Function Modification (Cross-Entropy)\n\n목적 함수인 ELBO(Evidence Lower Bound)의 두 항 중, KL Divergence 항은 \\(q(Z|X)\\)와 \\(p(Z)\\)가 변하지 않았으므로 식 (8) 그대로 유지됩니다.\n하지만 Reconstruction Term (Likelihood)은 가우시안 로그 우도(MSE 형태)에서 Categorical 로그 우도로 변경되어야 합니다. 이는 머신러닝에서 흔히 쓰이는 Cross-Entropy Loss와 형태가 같습니다.\n\n\nDerivation\n\nCategorical 분포의 로그 우도는 관측된 클래스(\\(X_{ij}=1\\))의 예측 확률(\\(P_{X_{ij}}\\))에 로그를 취한 값입니다. 이를 몬테카를로 샘플링을 적용하여 정리하면 식 (11)을 얻습니다. \\[\n\\mathbb{E}_{q(Z|X)} \\Big[ \\log p(X|Z) \\Big] \\approx \\frac{1}{L} \\sum_{l=1}^L \\sum_{i=1}^m \\sum_{j=1}^d X_{ij} \\log (P_X^{(l)})_{ij}\n\\tag{11}\\]\n\n\\(L\\): 몬테카를로 샘플 개수\n\\(X_{ij}\\): 실제 데이터의 One-hot 값 (0 또는 1)\n\\((P_X^{(l)})_{ij}\\): Decoder가 예측한 \\(l\\)번째 샘플의 확률 값\n이 식은 \\(X\\)와 \\(P_X\\) 사이의 Cross-Entropy를 계산하여, 모델이 실제 데이터의 범주를 정확하게 예측하도록 학습시킵니다.\n\n\n\n\n\nSummary\n\nDAG-GNN은 데이터 타입에 따라 모델의 핵심 구조(Encoder, Graph Operations, Latent Space)를 변경할 필요 없이, Decoder의 출력층(Softmax)과 손실 함수(Cross-Entropy)만 유연하게 교체하여 이산형 변수를 처리합니다.\n\n\n\n\n\n\n\n\n\n구분\n연속형 (Continuous)\n이산형 (Discrete)\n\n\n\n\nInput \\(X\\)\nReal Values (\\(\\mathbb{R}^{m \\times d}\\))\nOne-hot Vectors (\\(\\mathbb{R}^{m \\times d}\\))\n\n\nPrior / Encoder\nGaussian / MLP\nGaussian / MLP (동일)\n\n\nLikelihood\nGaussian \\(\\mathcal{N}(M_X, S_X)\\)\nCategorical \\(P_X\\)\n\n\nOutput Function (\\(f_2\\))\nIdentity / MLP\nSoftmax\n\n\nReconstruction Loss\nMean Squared Error (approx)\nCross Entropy\n\n\n\n\n이러한 설계는 다양한 형태의 변수가 섞여 있는(Mixed type) 실제 데이터셋에도 쉽게 확장 적용할 수 있는 가능성을 보여줍니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#connection-to-linear-sem",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#connection-to-linear-sem",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "3.6. Connection to Linear SEM",
    "text": "3.6. Connection to Linear SEM\n\n지금까지 우리는 Linear SEM에서 출발하여 비선형성을 더하고(Non-linearity), VAE 프레임워크를 입혀(Probabilistic) DAG-GNN을 완성했습니다.\n이제 저자들은 “역방향 사고(Reverse Thought Flow)”를 통해, DAG-GNN의 껍질을 하나씩 벗겨내면 결국 기존의 Linear SEM (Zheng et al., 2018, NOTEARS)과 수학적으로 완전히 일치함을 보입니다.\n이 과정은 DAG-GNN이 근본 없는 블랙박스 모델이 아니라, 기존의 최적화 기반 구조 학습 이론을 확장(Extension)한 것임을 증명하는 중요한 이론적 토대가 됩니다.\n\n\nStep 1: From VAE to Plain Autoencoder\n\n가장 먼저, 확률적(Probabilistic) 모델인 VAE에서 변분(Variational) 요소를 제거하여 결정론적(Deterministic)인 Plain Autoencoder로 축소해 봅시다.\n\n\nDeterministic Setup\n\n확률 분포 \\(q(Z|X)\\) 대신, 입력 \\(X\\)가 주어졌을 때 잠재 변수 \\(Z\\)가 고정된 값으로 결정된다고 가정합니다. 또한 비선형 함수 \\(f_1 \\dots f_4\\)는 그대로 유지합니다.\nEncoder (식 5 기반): \\[Z = f_4((I - A^T) f_3(X))\\]\nDecoder (식 3 기반): \\[\\hat{X} = f_2((I - A^T)^{-1} f_1(Z))\\]\n\n여기서 \\(\\hat{X}\\)는 Decoder에 의해 복원된 값을 의미합니다.\n\n\n\n\nCorrespondence of Loss Functions\n\n일반적인 Autoencoder가 최소화하려는 손실 함수(Sample Loss)는 복원 오차(Reconstruction Error)와 잠재 변수 규제(Regularization)의 합으로 표현됩니다.\n\n\\[\n\\mathcal{L}_{\\text{AE}} = \\underbrace{\\frac{1}{2} \\sum_{i=1}^m \\sum_{j=1}^d (X_{ij} - \\hat{X}_{ij})^2}_{\\text{Reconstruction}} + \\underbrace{\\frac{1}{2} \\sum_{i=1}^m \\sum_{j=1}^d Z_{ij}^2}_{\\text{Regularization}}\n\\]\n\n이 결정론적 손실 함수는 VAE의 ELBO와 정확히 대응됩니다:\n\nReconstruction Term:\n\n\nELBO의 복원 정확도 항(식 9)에서, \\(S_X\\) (Decoder 분산)를 1로 고정하고 \\(M_X\\) (Decoder 평균)를 \\(\\hat{X}\\)로 두면, 로그 우도 최대화는 곧 MSE(Mean Squared Error) 최소화와 같아집니다.\n\n\nRegularization Term:\n\n\nELBO의 KL Divergence 항(식 8)에서, \\(S_Z\\) (Encoder 분산)를 1로 고정하고 \\(M_Z\\) (Encoder 평균)를 \\(Z\\)로 두면, KL 항은 \\(\\sum Z_{ij}^2\\)에 비례하게 됩니다. 이는 L2 Regularization과 같습니다.\n\n\n\n\n\nStep 2: From Nonlinear to Linear (The Core Derivation)\n\n이제 두 번째 단계로, 모델의 비선형성(Non-linearity)을 제거해 봅시다. 즉, 모든 활성화 함수와 MLP를 걷어냅니다.\n\n\nLinear Assumptions\n\n모든 매핑 함수 \\(f_1, f_2, f_3, f_4\\)를 항등 함수(Identity Mapping)로 가정합니다.\n그렇다면 Encoder와 Decoder는 다음과 같이 단순한 선형 변환이 됩니다.\nLinear Encoder: \\[Z = (I - A^T) X\\]\nLinear Decoder: \\[\\hat{X} = (I - A^T)^{-1} Z\\]\n\n\n\nPerfect Reconstruction\n위 두 식을 결합하기 위해 Decoder 식의 \\(Z\\) 자리에 Encoder 식을 대입합니다.\n\\[\n\\begin{aligned}\n\\hat{X} &= (I - A^T)^{-1} \\left( (I - A^T) X \\right) \\\\\n&= \\underbrace{(I - A^T)^{-1} (I - A^T)}_{I} X \\\\\n&= X\n\\end{aligned}\n\\]\n\n즉, 선형 모델 하에서는 입력 \\(X\\)가 손실 없이 완벽하게 복원(\\(\\hat{X} = X\\))됩니다.\n따라서 손실 함수의 첫 번째 항인 Reconstruction Error는 0이 되어 사라집니다.\n\n\n\n\nDeriving the NOTEARS Loss\n\n이제 남은 것은 두 번째 항인 Regularization Term 뿐입니다.\n여기에 Linear Encoder 식 \\(Z = (I - A^T)X\\)를 대입하여 정리해 봅시다.\n\n\\[\n\\begin{aligned}\n\\mathcal{L}_{\\text{Linear}} &= \\frac{1}{2} \\sum_{i=1}^m \\sum_{j=1}^d Z_{ij}^2 \\\\\n&= \\frac{1}{2} \\| Z \\|_F^2 \\quad (\\text{Frobenius Norm}) \\\\\n&= \\frac{1}{2} \\| (I - A^T) X \\|_F^2\n\\end{aligned}\n\\tag{12}\\]\n\nResult and Interpretation\n\n유도된 최종 식 (12) \\(\\frac{1}{2} \\| (I - A^T) X \\|_F^2\\)는 정확히 Zheng et al. (2018)이 제안한 NOTEARS 알고리즘의 손실 함수(Least-squares loss)와 일치합니다.\n\n\n의미 (Insight): * Linear SEM(NOTEARS)은 모델이 완벽하게 복원된다고 가정하고, 노이즈 \\(Z\\)의 크기(L2 norm)를 최소화하는 문제로 해석될 수 있습니다. * DAG-GNN은 이를 확장하여, “완벽한 복원이 불가능한(비선형/노이즈 존재) 상황”까지 고려하기 위해 Reconstruction Loss 항을 추가하고, 비선형 변환을 도입한 일반화된 모델입니다.\n\n\n\n\nSummary\n\n\nDAG-GNN (VAE + Nonlinear)\n\n\n\\(\\downarrow\\) (Variational 제거: \\(S_Z, S_X \\to 1\\))\n\n\nDeterministic Autoencoder (MSE + L2 Reg)\n\n\n\\(\\downarrow\\) (Nonlinearity 제거: \\(f \\to Identity\\))\n\n\nLinear Model (Perfect Reconstruction, Reg only)\n\n\n\\(\\downarrow\\) (\\(Z = (I-A^T)X\\) 대입)\n\n\nLinear SEM Loss (Zheng et al., 2018)\n\n이로써 DAG-GNN은 Linear SEM의 탄탄한 이론적 기반 위에 서 있으면서도, 딥러닝의 표현력을 통해 더 복잡한 데이터 분포를 학습할 수 있는 모델임이 증명되었습니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#acyclicity-constraint",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#acyclicity-constraint",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "3.7. Acyclicity Constraint",
    "text": "3.7. Acyclicity Constraint\n\n앞선 섹션들에서 우리는 VAE 기반의 손실 함수(ELBO)와 선형/비선형 모델링을 정의했습니다.\n하지만 여기에는 치명적인 허점이 하나 있습니다.\nELBO를 최대화하든, Least-squares loss를 최소화하든, 학습된 인접 행렬 \\(A\\)가 DAG(비순환 그래프)라는 보장이 없다는 점입니다.\n그래프 \\(G\\)가 인과관계 모델이 되기 위해서는 반드시 사이클(Cycle)이 없어야 합니다.\n이번 포스트에서는 이 조합적(Combinatorial) 제약 조건을 어떻게 연속적인(Continuous) 수식으로 변환하여 최적화 과정에 통합했는지 살펴봅니다.\n\n\nMotivation: Trace and Cycles\n\n그래프 이론에서 인접 행렬의 거듭제곱은 경로(Path)와 깊은 연관이 있습니다.\n\n\nPath Counting Logic\n\n가중치가 있는 인접 행렬 \\(A\\)에 대해, 요소별 제곱(Element-wise square)을 수행하여 비음수(Non-negative) 행렬 \\(B\\)를 정의해 봅시다 (\\(B = A \\circ A\\)).\n행렬 \\(B\\)의 \\((i, j)\\) 요소가 양수라면, 노드 \\(i\\)에서 \\(j\\)로 가는 엣지가 존재함을 의미합니다.\n행렬의 곱셈 성질에 따라, \\(B^k\\)의 \\((i, j)\\) 요소가 양수라는 것은 노드 \\(i\\)에서 \\(j\\)로 가는 길이가 \\(k\\)인 경로가 존재함을 의미합니다.\n\n\n\nDetecting Cycles\n\n사이클이란 무엇일까요? 바로 자기 자신으로 돌아오는 경로(\\(i \\to \\dots \\to i\\))입니다.\n따라서, 어떤 정수 \\(k\\)에 대해 \\(B^k\\)의 대각 성분(Diagonal element) \\((B^k)_{ii}\\)가 양수라면, 노드 \\(i\\)를 포함하는 길이 \\(k\\)의 사이클이 존재한다는 뜻입니다.\n이 논리를 확장하면 다음과 같은 결론에 도달합니다.\n\n\n“모든 \\(k &gt; 0\\)에 대해 \\(B^k\\)의 대각 성분이 모두 0이라면(즉, Trace가 0이라면), 그 그래프는 DAG이다.”\n\n\n\n\nThe Matrix Exponential (Previous Work)\n\nZheng et al. (2018)의 NOTEARS 알고리즘은 이 원리를 이용하여 행렬 지수(Matrix Exponential) 형태의 제약 조건을 제안했습니다.\n\n\\[\nh(A) = \\text{tr}(e^{A \\circ A}) - m = 0\n\\]\n\n이 수식은 테일러 급수 전개를 통해 이해할 수 있습니다.\n\n\\[\ne^B = I + B + \\frac{B^2}{2!} + \\frac{B^3}{3!} + \\dots\n\\]\n\n\\(B\\)의 모든 거듭제곱(\\(B^k\\))의 합을 포함하므로, 어떤 길이의 사이클이라도 존재한다면 \\(e^B\\)의 대각 성분 합(Trace)은 \\(m\\) (항등 행렬 \\(I\\)의 Trace)보다 커지게 됩니다.\n수학적으로 매우 우아(Elegant)하지만, 실제 딥러닝 프레임워크에서 구현할 때 두 가지 문제가 있습니다.\n\n자동 미분 지원 미비: 모든 플랫폼이 행렬 지수의 미분을 효율적으로 지원하지 않습니다.\n수치적 불안정성: \\(e^B\\)는 값이 매우 빠르게 커지므로, 고유값(Eigenvalue)이 클 경우 오버플로우나 수치 오류가 발생하기 쉽습니다.\n\n\n\n\nProposed Solution: Polynomial Constraint\n\n저자들은 위 문제를 해결하기 위해, 행렬 지수 대신 다항식(Polynomial) 형태의 새로운 제약 조건을 제안합니다.\n\n\nTheorem 1 (Polynomial Acyclicity)\n\n\\(A \\in \\mathbb{R}^{m \\times m}\\)를 유향 그래프의 가중치 인접 행렬이라고 합시다.\n임의의 양수 \\(\\alpha &gt; 0\\)에 대하여, 다음 조건이 성립하면 그래프는 Acyclic입니다.\n\n\\[\n\\text{tr}\\left[ (I + \\alpha A \\circ A)^m \\right] - m = 0\n\\tag{13}\\]\n\n\nDerivation & Proof Logic\n\n이 식이 성립하는 이유는 다음과 같습니다.\n\n최장 경로의 길이: 노드가 \\(m\\)개인 그래프에서 사이클이 없다면(DAG라면), 존재할 수 있는 경로의 최대 길이는 \\(m-1\\)입니다.\n\n\n이항 전개 (Binomial Expansion): \\((I + \\alpha B)^m\\)을 전개하면 다음과 같은 형태가 됩니다. \\[I + \\binom{m}{1}\\alpha B + \\binom{m}{2}\\alpha^2 B^2 + \\dots + \\alpha^m B^m\\]\n\n\n포괄성: 이 식은 \\(I\\)부터 \\(B^m\\)까지의 모든 항을 양수 계수로 포함합니다.\n\n\n결론: 만약 그래프에 사이클이 있다면, \\(m\\) 이하의 어떤 길이 \\(k\\)에 대해 \\(B^k\\)의 Trace가 양수가 될 것입니다. 위 식은 \\(B^1\\)부터 \\(B^m\\)까지 모든 거듭제곱의 합을 검사하므로, 사이클이 하나라도 있다면 전체 Trace는 \\(m\\) (\\(I\\)의 Trace)보다 반드시 커지게 됩니다.\n\n따라서 식 (13)을 0으로 만드는 제약 조건은 그래프가 DAG임을 보장합니다.\n\n\n\n\nStability Analysis (Why Polynomial?)\n\n왜 \\(e^B\\) 대신 \\((I + \\alpha B)^m\\)을 써야 할까요? 저자들은 Theorem 2를 통해 수치적 안정성을 증명합니다.\n\n\nTheorem 2 (Comparison)\n\n\\(\\alpha = c/m &gt; 0\\) (단, \\(c\\)는 상수)라고 설정하면, 임의의 복소수 \\(\\lambda\\)에 대해 다음 부등식이 성립합니다.\n\n\\[\n(1 + \\alpha |\\lambda|)^m \\le e^{c|\\lambda|}\n\\]\n\n\nInterpretation\n\n좌변: 제안된 다항식 제약 조건의 성장 속도와 관련됨.\n우변: 기존 행렬 지수 제약 조건의 성장 속도와 관련됨.\n이 부등식은 다항식 제약 조건이 지수 함수보다 훨씬 완만하게 증가함을 보여줍니다.\n즉, \\(B\\)의 고유값(Eigenvalue) 크기가 클 때, 다항식 기반 제약 조건이 수치적 폭발(Numerical difficulty)을 겪을 위험이 훨씬 적습니다 (“less severe”).\n\n\n\nPractical Implementation\n\n실제 구현에서 \\(\\alpha\\)는 하이퍼파라미터로 취급됩니다.\n이론적으로 \\(\\alpha\\)는 \\(B\\)의 가장 큰 고유값(Spectral radius)에 의존합니다.\nPerron-Frobenius 정리에 따라, 비음수 행렬 \\(B\\)의 Spectral radius는 최대 행 합(Maximum row sum)에 의해 제한(Bounded)되므로, 이를 참고하여 \\(\\alpha\\)를 설정할 수 있습니다.\n\n\n\n\nSummary\n\nDAG-GNN은 구조 학습의 핵심인 Acyclicity Constraint를 현대적인 딥러닝 환경에 맞게 재설계했습니다.\n\n기존: \\(h(A) = \\text{tr}(e^{A \\circ A}) - m = 0\\) (NOTEARS)\n\n\n우아하지만 구현이 어렵고 불안정할 수 있음.\n\n\n제안: \\(h(A) = \\text{tr}((I + \\alpha A \\circ A)^m) - m = 0\\) (DAG-GNN)\n\n\nFinite Power: \\(m\\)차수까지만 검사해도 충분함 (DAG의 성질).\nStability: 지수 함수보다 완만하게 증가하여 수치적으로 안정적.\nConvenience: 일반적인 행렬 곱셈만으로 구현 가능하여 모든 딥러닝 프레임워크와 호환됨.\n\n이로써 DAG-GNN은 VAE를 통한 확률적 모델링, GNN을 통한 비선형성 확보, 그리고 Polynomial Constraint를 통한 구조적 보장까지 갖춘 완전한 프레임워크가 되었습니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#training",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#training",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "3.8. Training",
    "text": "3.8. Training\n\n지금까지 우리는 DAG-GNN의 두 가지 핵심 기둥을 세웠습니다.\n\n\nObjective: 데이터를 잘 설명하기 위한 VAE의 손실 함수 (Negative ELBO).\n\n\nConstraint: 그래프가 DAG임을 보장하기 위한 다항식 제약 조건 (\\(h(A) = 0\\)).\n\n\n이제 이 두 가지를 하나로 묶어 실제 학습을 수행하는 최적화 전략(Optimization Strategy)을 다룰 차례입니다.\n이 문제는 전형적인 비선형 등식 제약 최적화(Nonlinear Equality-Constrained Optimization) 문제입니다.\n\n\nProblem Formulation\n\n전체 학습 문제는 다음과 같은 최적화 문제로 정식화됩니다. \\[\n\\begin{aligned}\n\\min_{A, \\theta} \\quad & f(A, \\theta) \\equiv -L_{\\text{ELBO}} \\\\\n\\text{s.t.} \\quad & h(A) \\equiv \\text{tr}[(I + \\alpha A \\circ A)^m] - m = 0\n\\end{aligned}\n\\]\n\nObjective \\(f(A, \\theta)\\): ELBO(Evidence Lower Bound)를 최대화하는 것은 Negative ELBO를 최소화하는 것과 같습니다.\nConstraint \\(h(A)\\): 앞서 유도한 다항식 제약 조건으로, 이 값이 0이 되어야만 \\(A\\)가 DAG임이 보장됩니다.\nUnknowns:\n\n\\(A\\): 가중치 인접 행렬 (Weighted Adjacency Matrix)\n\\(\\theta\\): VAE를 구성하는 신경망의 파라미터들 (\\(\\{W^1, W^2, W^3, W^4\\}\\)).\n\n\n\n\n\nThe Augmented Lagrangian Method\n\n이러한 제약 조건이 있는 최적화 문제를 풀기 위해, 저자들은 증강 라그랑주(Augmented Lagrangian) 방법을 사용합니다.\n이는 표준적인 라그랑주 승수법에 페널티 항(Penalty term)을 추가하여 수치적 안정성과 수렴성을 높인 기법입니다 (Bertsekas, 1999).\n정의된 증강 라그랑주 함수 \\(L_c\\)는 다음과 같습니다.\n\n\\[\nL_c(A, \\theta, \\lambda) = f(A, \\theta) + \\lambda h(A) + \\frac{c}{2}|h(A)|^2\n\\]\n\n이 식은 세 가지 부분으로 구성됩니다:\n\n\n\\(f(A, \\theta)\\): 원래의 목적 함수 (Negative ELBO).\n\n\n\\(\\lambda h(A)\\): 표준 라그랑주 항. 여기서 \\(\\lambda\\)는 라그랑주 승수(Lagrange Multiplier)입니다.\n\n\n\\(\\frac{c}{2}|h(A)|^2\\): 제약 조건 위반에 대한 2차 페널티(Quadratic Penalty) 항입니다. \\(c\\)는 페널티 파라미터(Penalty Parameter)입니다.\n\n\n\n\nMotivation\n\n왜 단순 라그랑주나 단순 페널티 기법을 쓰지 않고 이 둘을 섞었을까요?\n단순 페널티 기법은 \\(c\\)를 무한대로 보내야만 제약 조건을 만족하는데, 이는 해 주변에서 함수를 매우 뾰족하게(Ill-conditioned) 만들어 최적화를 어렵게 합니다.\n증강 라그랑주 방법은 \\(\\lambda\\)의 도움을 받아, \\(c\\)가 적당히 크더라도 정확한 해로 수렴할 수 있게 해줍니다. 즉, \\(c \\to \\infty\\)일 때 \\(L_c\\)의 최소해는 제약 조건 \\(h(A)=0\\)을 만족하며 원래 목적 함수 \\(f\\)를 최소화하게 됩니다.\n\n\n\n\nAlgorithm: Iterative Update Rule\n\n학습은 \\(c\\)를 점진적으로 증가시키면서 일련의 비제약 최적화 문제(Unconstrained optimization)를 푸는 방식으로 진행됩니다.\n구체적인 알고리즘은 다음의 반복(Iteration) 과정으로 요약됩니다.\n각 반복 단계 \\(k\\)에서 다음을 수행합니다:\n\n\nStep 1: Primal Update (Subproblem)\n\n현재 고정된 \\(\\lambda^k\\)와 \\(c^k\\)에 대해, 증강 라그랑주 함수 \\(L_{c^k}\\)를 최소화하는 \\(A\\)와 \\(\\theta\\)를 찾습니다.\n\n\\[\n(A^k, \\theta^k) = \\underset{A, \\theta}{\\text{argmin}} \\ L_{c^k}(A, \\theta, \\lambda^k)\n\\tag{14}\\]\n\n이 단계(Subproblem)는 경사 하강법(Gradient Descent)과 같은 Blackbox Stochastic Optimization Solver(예: Adam)를 사용하여 해결합니다.\nELBO가 샘플 기반으로 정의되므로 확률적(Stochastic) 최적화가 적합합니다.\n\n\n\nStep 2: Dual Update (\\(\\lambda\\))\n\n제약 조건 위반 정도(\\(h(A^k)\\))를 반영하여 라그랑주 승수를 업데이트합니다.\n\n\\[\n\\lambda^{k+1} = \\lambda^k + c^k h(A^k)\n\\tag{15}\\]\n\n이 규칙은 쌍대 오름법(Dual Ascent)의 형태를 띠며, 제약 조건이 만족되지 않으면(즉 \\(h(A) \\neq 0\\)), \\(\\lambda\\)를 조정하여 다음 단계에서 해당 제약 조건이 더 중요하게 다뤄지도록 합니다.\n\n\n\nStep 3: Penalty Parameter Update (\\(c\\))\n\n제약 조건 위반 정도가 충분히 줄어들지 않았다면, 페널티 강도 \\(c\\)를 증가시킵니다.\n\n\\[\nc^{k+1} = \\begin{cases}\n\\eta c^k, & \\text{if } |h(A^k)| &gt; \\gamma |h(A^{k-1})| \\\\\nc^k, & \\text{otherwise}\n\\end{cases}\n\\tag{16}\\]\n\n조건 (\\(|h(A^k)| &gt; \\gamma |h(A^{k-1})|\\)): 이번 단계의 제약 위반 값이 이전 단계의 \\(\\gamma\\)배보다 크다는 것은, 위반 정도가 충분히(빠르게) 감소하지 않았음을 의미합니다.\n대응 (\\(c \\leftarrow \\eta c\\)): 이 경우 \\(c\\)를 \\(\\eta\\)배 키워서 제약 조건 위반에 대한 비용을 더 비싸게 만듭니다.\n\n\n\n\nHyperparameters and Implementation\n\n논문에서는 이 알고리즘의 효과적인 작동을 위한 하이퍼파라미터 설정 값을 제안합니다.\n\n\\(\\eta &gt; 1\\): 페널티 증가 비율. 논문에서는 \\(\\eta = 10\\)을 권장합니다.\n\\(\\gamma &lt; 1\\): 허용 가능한 위반 감소율. 논문에서는 \\(\\gamma = 1/4\\) (\\(0.25\\))를 권장합니다.\n\n이 설정은 제약 조건 위반이 매 단계마다 최소 25%씩은 줄어들기를 기대하며, 그렇지 않을 경우 페널티를 10배로 강력하게 키우겠다는 공격적인 전략을 의미합니다.\n\n\n\nSummary\n\nDAG-GNN의 학습 과정은 단순히 손실 함수를 미분하여 역전파하는 것을 넘어섭니다.\n\n\nAugmented Lagrangian을 통해 연속적인 제약 조건(Acyclicity)을 목적 함수에 부드럽게 통합했습니다.\n\n\nPrimal-Dual Update 방식을 통해 모델 파라미터(\\(A, \\theta\\))와 제약 파라미터(\\(\\lambda, c\\))를 번갈아 최적화하며, 점진적으로 DAG 구조를 만족하는 해로 수렴해 나갑니다.\n\n\n이로써 우리는 복잡한 조합 최적화 문제였던 구조 학습을, 딥러닝 프레임워크 위에서 수행 가능한 연속 최적화 문제로 완벽하게 변환하였습니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#synthetic-data-sets",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#synthetic-data-sets",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "4.1. Synthetic Data Sets",
    "text": "4.1. Synthetic Data Sets\n\n저자들은 Erdős-Rényi 모델을 사용하여 임의의 DAG 구조를 생성하고, 노드 수 \\(m \\in \\{10, 20, 50, 100\\}\\)에 대해 데이터를 생성하여 실험을 진행했습니다. (샘플 수 \\(n=5000\\))\n평가 지표로는 다음 두 가지를 사용합니다:\n\n\nSHD (Structural Hamming Distance): 예측된 그래프와 정답 그래프 간의 엣지 불일치 개수 (낮을수록 좋음).\n\n\nFDR (False Discovery Rate): 잘못 예측된 엣지의 비율 (낮을수록 좋음).\n\n\n\n\n4.1.1. Linear Case\n\n먼저, DAG-GNN이 기존 Linear SEM 환경에서도 잘 작동하는지 확인합니다. 데이터 생성 과정은 다음과 같습니다.\n\n\\[\nx = A^T x + z\n\\]\n\n여기서 \\(g\\)는 항등 함수(Identity mapping)입니다.\n\n\n\n\nFigure 2: Linear Case에서의 성능 비교. 그래프 크기(m)가 커짐에 따라 DAG-NOTEARS(파란색)와 DAG-GNN(빨간색)의 SHD와 FDR 변화를 보여준다. DAG-GNN이 선형 모델에서도 NOTEARS와 대등하거나 더 우수한 성능을 보임을 알 수 있다.\n\n\n\n결과: 선형 데이터임에도 불구하고, DAG-GNN은 Linear 전용 모델인 NOTEARS보다 더 정확한 구조를 학습했습니다. 특히 그래프 크기가 커질수록(\\(m=100\\)) 격차가 벌어지는 경향을 보입니다.\n\n\n\n4.1.2. Nonlinear Case (Core Contribution)\n\nDAG-GNN의 진가는 선형 모델을 넘어선 비선형 데이터 처리 능력에서 드러납니다. 저자들은 비선형성의 적용 시점에 따라 두 가지 시나리오를 실험했습니다.\n\n\n1) 변수에 비선형성이 먼저 적용되는 경우 (Element-wise Nonlinearity)\n\n첫 번째는 변수들에 비선형 함수 \\(h\\)가 적용된 후 선형 결합되는 모델입니다.\n\n\\[\nx = A^T h(x) + z, \\quad \\text{where } h(x) = \\cos(x + 1)\n\\]\n\n이 경우 \\(h(x)\\)를 1차 테일러 근사하면 \\(h(x) \\approx h(0)\\mathbf{1} + h'(0)x\\)가 되며, 이는 \\(h'(0)A\\)를 인접 행렬로 갖는 선형 모델로 근사하여 해석할 수 있습니다.\n\n\n\n\nFigure 3: Nonlinear Case (\\(h(x)=\\cos(x+1)\\))에서의 성능 비교. 비선형성이 도입되자 NOTEARS(파란색)의 SHD와 FDR이 급격히 증가하는 반면, DAG-GNN(빨간색)은 안정적인 성능을 유지한다.\n\n\n\n\n\nFigure 4: 파라미터 추정 히트맵 (Heatmap). (왼쪽) True Graph, (중간) DAG-GNN 추정, (오른쪽) NOTEARS 추정. DAG-GNN은 정답의 희소(Sparse)한 구조를 잘 복원하고 “False Alarm”이 적은 반면, NOTEARS는 노이즈가 많이 낀 결과를 보여준다.\n\n\n\n결과: SHD 측면에서 약간의 개선이 있었으나, 특히 FDR(가짜 발견율)이 약 3배 가량 대폭 개선되었습니다. 이는 DAG-GNN이 비선형 관계 속에서도 가짜 엣지(False Alarm)를 효과적으로 걸러냄을 보여줍니다.\n\n\n\n2) 선형 결합 후 비선형성이 발생하는 경우 (Complex Nonlinearity)\n\n저자들은 더 나아가 비선형성이 변수들의 선형 결합 이후(after)에 발생하는, 더 높은 수준의 비선형 모델에 대해서도 실험을 수행했습니다.\n\n\\[\nx = 2\\sin(A^T(x + 0.5 \\cdot \\mathbf{1})) + A^T(x + 0.5 \\cdot \\mathbf{1}) + z\n\\]\n\n\n\nFigure 5: 더 복잡한 비선형 모델에서의 구조 학습 성능 (SHD, FDR). 비선형성이 심화될수록 DAG-NOTEARS(파란색)와의 성능 격차가 더욱 벌어지며, DAG-GNN(빨간색)이 월등히 낮은 에러율을 보인다.\n\n\n\n결과: Figure 5에서 볼 수 있듯이, 비선형성이 더 강한 이 모델에서는 DAG-GNN이 DAG-NOTEARS에 비해 SHD와 FDR 모든 지표에서 압도적으로 우수한 성능을 보였습니다. 이는 DAG-GNN이 단순한 근사를 넘어 복잡한 비선형 인과 구조를 포착하는 데 매우 효과적임을 시사합니다.\n\n\n\n\n4.1.3. Vector-Valued Case\n\n기존 방법론들은 변수를 스칼라(Scalar)로만 취급했습니다. 하지만 DAG-GNN은 GNN 구조 덕분에 각 노드가 벡터(\\(d &gt; 1\\))인 경우도 자연스럽게 처리합니다.\n실험 설정은 다음과 같습니다:\n\n노드 차원 \\(d=5\\), 잠재 차원 \\(d_Z=1\\).\n데이터는 더욱 복잡한 비선형 식 \\(x = 2\\sin(A^T(x + 0.5 \\cdot 1)) + A^T(x + 0.5 \\cdot 1) + z\\) 로 생성됩니다.\n\n\n\n\n\nFigure 6: Vector-valued Case의 성능 비교. 벡터 노드와 복잡한 비선형성이 결합된 환경에서 DAG-GNN(빨간색)이 NOTEARS(파란색)를 압도하는 성능 차이를 보여준다.\n\n\n\n\n\nFigure 7: Vector-valued 데이터에 대한 파라미터 추정 비교. DAG-GNN은 Ground Truth의 구조를 거의 완벽하게 복원한 반면, NOTEARS는 구조를 거의 학습하지 못했다.\n\n\n\n결과: NOTEARS는 이러한 설정(벡터 입력)을 처리할 수 없어, 데이터를 강제로 스칼라로 변환하거나 가정을 단순화해야 했습니다. 반면 DAG-GNN은 구조적 정보를 잠재 공간(Latent Space)에서 효과적으로 포착하여 압도적인 성능 차이를 보여줍니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#benchmark-data-sets-discrete-variables",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#benchmark-data-sets-discrete-variables",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "4.2. Benchmark Data Sets (Discrete Variables)",
    "text": "4.2. Benchmark Data Sets (Discrete Variables)\n\n다음으로, 이산형 변수(Discrete Variables)로 구성된 유명한 베이지안 네트워크 벤치마크 데이터셋(Child, Alarm, Pigs)에 대한 실험입니다.\n여기서는 GOPNILP (Integer Programming을 이용한 Exact Solver)와 비교하여, BIC Score를 평가 지표로 사용했습니다.\n\n\n\n\nDataset\n\\(m\\) (Nodes)\nGround Truth BIC\nGOPNILP BIC\nDAG-GNN BIC\n\n\n\n\nChild\n20\n-1.27e+4\n-1.27e+4\n-1.38e+4\n\n\nAlarm\n37\n-1.07e+4\n-1.12e+4\n-1.28e+4\n\n\nPigs\n441\n-3.48e+5\n-3.50e+5\n-3.69e+5\n\n\n\n(Table 1의 내용을 재구성)\n\n해석: GOPNILP는 전역 최적해(Global Optimum)를 찾는 알고리즘이므로 가장 좋은 점수를 보입니다. DAG-GNN은 근사 해법임에도 불구하고, 전역 최적해에 합리적으로 근접한(reasonably close) 결과를 보여줍니다.\nBIC 차이가 나는 이유는 VAE 구조가 다항 분포(Multinomial distribution)를 근사하는 과정에서 발생하는 한계로 보이지만, 통합된 프레임워크로 이산형 데이터까지 처리할 수 있다는 점은 큰 강점입니다."
  },
  {
    "objectID": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#applications",
    "href": "posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/index.html#applications",
    "title": "[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks",
    "section": "4.3. Applications",
    "text": "4.3. Applications\n\nProtein Signaling Network\n\nSachs et al. (2005)의 단백질 신호 전달 네트워크 데이터(\\(n=7466, m=11\\))를 사용하여 실제 인과 구조 복원 능력을 테스트했습니다.\n\n\n\n\nMethod\nSHD\nPredicted Edges\n\n\n\n\nFGS (Fast Greedy Search)\n22\n17\n\n\nNOTEARS\n22\n16\n\n\nDAG-GNN\n19\n18\n\n\n\n(Table 2의 내용을 재구성)\n\n\n\nFigure 8: DAG-GNN이 추정한 단백질 신호 전달 네트워크. 붉은색 화살표는 Ground Truth와 일치하는 엣지, 파란색 점선은 간접 연결, 노란색은 역방향 연결을 나타낸다.\n\n\n\n결과: DAG-GNN은 SHD 19를 기록하여, NOTEARS(22) 및 FGS(22)보다 더 정확하게 실제 생물학적 인과관계(Ground Truth)를 복원했습니다.\n\n\n\nKnowledge Base Construction\n\nFB15K-237 데이터셋을 사용하여, 지식 베이스(Knowledge Base) 내의 관계(Relation)들 사이의 인과성을 추론하는 새로운 태스크를 제안했습니다.\n예를 들어, Person/Nationality라는 관계가 있다면, 이것이 Person/Language 관계의 원인이 될 수 있다는 식의 메타 관계를 학습합니다.\nTable 3 결과에 따르면, film/ProducedBy \\(\\Rightarrow\\) film/Country와 같이 직관적으로 타당한 인과 관계들을 성공적으로 추출했습니다."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "shsha0110.github.io",
    "section": "",
    "text": "[Causal Inference] 01. Introduction\n\n\n\nCausal Inference\n\n\n\nIntroduction to Causal Inference\n\n\n\n\n\nJan 6, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 02. Causal Models and Graphs (Part 2)\n\n\n\nCausal Inference\n\n\n\nStructural Causal Model (SCM), Markovian Factorization, and d-separation\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 02. Causal Models and Graphs (Part 1)\n\n\n\nCausal Inference\n\n\n\nStructural Causal Models (SCM), Causal Graphs, and Markovian Factorization\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 03. Identification of Causal Effects\n\n\n\nCausal Inference\n\n\n\n관측 데이터로부터 인과 효과를 계산할 수 있는가? (SCM, Truncated Factorization, Adjustment Formula)\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 04. Confounding and Backdoor (Part 1)\n\n\n\nCausal Inference\n\n\n\nIndentifiable and Non-identifiable Effects\n\n\n\n\n\nJan 7, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 04. Confounding and Backdoor (Part 2)\n\n\n\nCausal Inference\n\n\n\nCounfounding Bias\n\n\n\n\n\nJan 7, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 04. Confounding and Backdoor (Part 3)\n\n\n\nCausal Inference\n\n\n\nBack-door Criterion\n\n\n\n\n\nJan 7, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 04. Confounding and Backdoor (Part 4)\n\n\n\nCausal Inference\n\n\n\nInverse Probability Weighting\n\n\n\n\n\nJan 7, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 04. Confounding and Backdoor (Part 5)\n\n\n\nCausal Inference\n\n\n\nSimpson’s Paradox Simulation Using DoWhy: Stratification & Refutation\n\n\n\n\n\nJan 8, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 05. Adjustment Criterion (Part 1)\n\n\n\nCausal Inference\n\n\n\nBackdoor Criterion - Tightness of the Back-door Criterion\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 05. Adjustment Criterion (Part 2)\n\n\n\nCausal Inference\n\n\n\nAdjustment Criterion\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 05. Adjustment Criterion (Part 3)\n\n\n\nCausal Inference\n\n\n\nAlgorithm\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 05. Adjustment Criterion (Part 4)\n\n\n\nCausal Inference\n\n\n\nConditional Ignorability in Potential Outcome Framework\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 06. The Causal Calculus (Part 1)\n\n\n\nCausal Inference\n\n\n\nThree Examples\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 06. The Causal Calculus (Part 2)\n\n\n\nCausal Inference\n\n\n\nIdentification Approaches & Three Insights\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 06. The Causal Calculus (Part 3)\n\n\n\nCausal Inference\n\n\n\nCausal Calculus — A systematic approach for identification\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 06. The Causal Calculus (Part 4)\n\n\n\nCausal Inference\n\n\n\nBack to Simpson’s Paradox\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 07. An Algorithmic Approach to Identification (Part 1)\n\n\n\nCausal Inference\n\n\n\nFactorizing Observational Distributions\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 07. An Algorithmic Approach to Identification (Part 2)\n\n\n\nCausal Inference\n\n\n\nExpressing Causal Queries in terms of C-factors: Examples\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 07. An Algorithmic Approach to Identification (Part 3)\n\n\n\nCausal Inference\n\n\n\nA General Approach\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 08. Partial Identification (Part 1)\n\n\n\nCausal Inference\n\n\n\nPartial Identification Problem: Natural Bounds\n\n\n\n\n\nJan 11, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 08. Partial Identification (Part 2)\n\n\n\nCausal Inference\n\n\n\nPartial Identification Problem: Non-Compliance\n\n\n\n\n\nJan 12, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 08. Partial Identification (Part 3)\n\n\n\nCausal Inference\n\n\n\nBounds on Partially-observed Covariates\n\n\n\n\n\nJan 13, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 08. Partial Identification (Part 4)\n\n\n\nCausal Inference\n\n\n\nNon-Compliance Simulation\n\n\n\n\n\nJan 13, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 09. Linear Structural Causal Models (Part 1)\n\n\n\nCausal Inference\n\n\n\nIntroduction\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 09. Linear Structural Causal Models (Part 2)\n\n\n\nCausal Inference\n\n\n\nLinear Regression\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 09. Linear Structural Causal Models (Part 3)\n\n\n\nCausal Inference\n\n\n\nAlgorithmic Identification Methods\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 09. Linear Structural Causal Models (Part 4)\n\n\n\nCausal Inference\n\n\n\nIV to Instrumental Sets\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 09. Linear Structural Causal Models (Part 5)\n\n\n\nCausal Inference\n\n\n\nThe Method of Auxiliary Variables\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 10. Potential Outcome Framework (Part 1)\n\n\n\nCausal Inference\n\n\n\nIntroduction\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 10. Potential Outcome Framework (Part 2)\n\n\n\nCausal Inference\n\n\n\nRandomization and Observational Study\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 11. IPW and Its Variants (Part 1)\n\n\n\nCausal Inference\n\n\n\nIntroduction\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 11. IPW and Its Variants (Part 2)\n\n\n\nCausal Inference\n\n\n\nDoubly Robust Estimation\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 12. Matching\n\n\n\nCausal Inference\n\n\n\nNonparametric Imputation for Causal Inference: Exact, Nearest Neighbor, Propensity Score, and Balance Checking\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 13. IV (Part 1)\n\n\n\nCausal Inference\n\n\n\nIV under Linear Assumption\n\n\n\n\n\nJan 15, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 13. IV (Part 2)\n\n\n\nCausal Inference\n\n\n\nRandom Experiment wiht Noncompliance\n\n\n\n\n\nJan 16, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 13. IV (Part 3)\n\n\n\nCausal Inference\n\n\n\nLinear 2SLS vs. Deep IV\n\n\n\n\n\nJan 18, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 14. Regression Discontinuity Design\n\n\n\nCausal Inference\n\n\n\nDefinition, Indentification and Estimation of RDD\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 15. DiD & SCM (Part 1)\n\n\n\nCausal Inference\n\n\n\nDifference in Differences\n\n\n\n\n\nJan 22, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 15. DiD & SCM (Part 2)\n\n\n\nCausal Inference\n\n\n\nNonlinear DiD\n\n\n\n\n\nJan 22, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 15. DiD & SCM (Part 3)\n\n\n\nCausal Inference\n\n\n\nSynthetic Control Method\n\n\n\n\n\nJan 22, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 15A. SDiD (Part 1)\n\n\n\nCausal Inference\n\n\n\nSynthetic Difference-in-Differences\n\n\n\n\n\nJan 25, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 15A. SDiD (Part 2)\n\n\n\nCausal Inference\n\n\n\nSynthetic Difference-in-Differences\n\n\n\n\n\nJan 25, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 15A. Staggered DiD\n\n\n\nCausal Inference\n\n\n\nStaggered Difference-in-Differences\n\n\n\n\n\nJan 25, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 16. Causal Discovery (Part 1)\n\n\n\nCausal Inference\n\n\n\nIntroduction\n\n\n\n\n\nJan 22, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 16. Causal Discovery (Part 2)\n\n\n\nCausal Inference\n\n\n\nConstraint-Based Structure Learning\n\n\n\n\n\nJan 22, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 16. Causal Discovery (Part 3)\n\n\n\nCausal Inference\n\n\n\nExtensions of PC Algorithm & FCI\n\n\n\n\n\nJan 22, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 16. Causal Discovery (Part 4)\n\n\n\nCausal Inference\n\n\n\nScore-Based Approach\n\n\n\n\n\nJan 22, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 16. Causal Discovery (Part 5)\n\n\n\nCausal Inference\n\n\n\nParametric Approaches\n\n\n\n\n\nJan 22, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 16. Causal Discovery (Part 6)\n\n\n\nCausal Inference\n\n\n\nTime Series Causal Discovery\n\n\n\n\n\nJan 22, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 17. Causal Data Science (Part 1)\n\n\n\nCausal Inference\n\n\n\nIntroduction\n\n\n\n\n\nJan 25, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 17. Causal Data Science (Part 2)\n\n\n\nCausal Inference\n\n\n\nExperimental Conditions - General Identifiability\n\n\n\n\n\nJan 25, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 17. Causal Data Science (Part 3)\n\n\n\nCausal Inference\n\n\n\nEnvironmental Conditions - Transportability, External Validity, Meta-Analysis\n\n\n\n\n\nJan 25, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 17. Causal Data Science (Part 4)\n\n\n\nCausal Inference\n\n\n\nSampling Conditions - Recovering From Selection Bias\n\n\n\n\n\nJan 25, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 17. Causal Data Science (Part 5)\n\n\n\nCausal Inference\n\n\n\nMissing Data\n\n\n\n\n\nJan 25, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 17. Causal Data Science (Part 6)\n\n\n\nCausal Inference\n\n\n\nMeasurement\n\n\n\n\n\nJan 25, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification\n\n\n\nPaper Review\n\n\n\n\n\n\n\n\n\nJan 15, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Paper Review] Conformal Inference of Counterfactuals and Individual Treatment Effects\n\n\n\nPaper Review\n\n\n\n\n\n\n\n\n\nJan 23, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects\n\n\n\nPaper Review\n\n\n\nCausal Inference에서 불확실성을 다루는 새로운 프레임워크: Conformal Prediction과 Meta-learner의 결합\n\n\n\n\n\nJan 30, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks\n\n\n\nPaper Review\n\n\n\nVAE와 GNN을 결합하여 비선형 관계와 다양한 데이터 타입을 포괄하는 새로운 DAG 구조 학습 프레임워크 제안\n\n\n\n\n\nJan 31, 2026\n\n\n유성현\n\n\n\n\n\nNo matching items"
  }
]