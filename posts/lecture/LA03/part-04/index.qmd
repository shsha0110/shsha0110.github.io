---
title: "[Causal Inference] Appendix 03. Soft-Intervention and σ-calculus (Part 4)"
description: "C-Factors and Soft-Intervention"
author: "유성현"
date: "2026-02-07"
categories: [Causal Inference]
format:
  html:
    toc: true
    number-sections: false
    code-fold: show
    math: true
---

# 1. Introduction: Why Soft Interventions?

인과추론의 표준적인 프레임워크(Pearl's Causal Hierarchy)에서 우리는 주로 **Atomic Intervention(단일 개입)**을 다룹니다. 이는 $do(X=x)$와 같이 특정 변수 $X$를 상수 값 $x$로 고정하는 행위를 의미합니다.

하지만 현실 세계의 의사결정 문제에서는 변수를 특정 값으로 완벽하게 고정하는 것이 불가능하거나, 바람직하지 않은 경우가 많습니다. 대신 우리는 **정책(Policy)**을 변경하거나, 변수가 값을 취하는 **확률 분포** 자체를 변화시키고자 합니다.

* **Atomic Intervention:** "모든 사람이 담배를 피우지 않게 하겠다." ($do(Smoke=0)$)
* **Soft (Stochastic) Intervention:** "담배 가격을 올려서 흡연율을 현재의 50% 수준으로 낮추겠다." ($P^*(Smoke|Price)$)

[cite_start]이번 포스트에서는 이러한 확률적 개입을 다루는 **Soft Intervention**의 개념과, 이를 체계적으로 분석하기 위한 **$\sigma$-calculus**에 대해 다룹니다[cite: 1, 2].

---

# 2. Soft Interventions vs Atomic Interventions

## 2.1. 개념적 차이
[cite_start]Soft Intervention은 변수 $X$를 상수로 고정하는 것이 아니라, $X$가 그 부모 변수(Parents)나 다른 변수들에 반응하는 **함수적 관계(메커니즘)를 변경**하는 것입니다[cite: 3].

* **Hard (Atomic) Intervention ($do(x)$):**
    * $X$로 들어오는 모든 화살표(Causal link)를 끊어버립니다.
    * $X$의 값은 외부에서 주입된 상수 $x$가 됩니다.
    * 그래프 상에서 $X$의 부모들과의 연결이 삭제됩니다.

* **Soft Intervention ($\sigma_X$):**
    * [cite_start]$X$가 값을 결정하는 조건부 확률 분포 $P(X|PA_X)$를 새로운 분포 $P^*(X|PA_X')$ 또는 $P^*(X|W)$로 대체합니다[cite: 29].
    * 그래프 상에서 기존의 화살표가 사라지는 것이 아니라, 새로운 의존성이 생기거나 기존 의존성이 변경될 수 있습니다.

![Figure 1: Atomic Intervention과 Soft Intervention의 도식적 차이. 왼쪽은 원본 그래프 $\mathcal{G}$, 오른쪽은 Soft Intervention $\sigma_X$가 적용된 그래프 $\mathcal{G}_{\sigma_X}$를 나타낸다. $\sigma_X$는 $X$의 메커니즘을 변경하여 새로운 부모 $W$ 혹은 기존 부모와의 관계를 재정의한다.](./images/soft_intervention_diagram.png)

## 2.2. 수식적 정의 (Notation)

[cite_start]모델 $M$의 인과 다이어그램을 $G$라고 할 때, 개입 전의 결합 확률 분포(Pre-intervention distribution)는 다음과 같이 Markov Factorization으로 표현됩니다[cite: 20, 21].

$$
P(z, x, y) = \sum_{u} P(z, x, y, u) = Q[Z]Q[X]Q[Y]
$$

여기서 $Q[V_i]$는 변수 $V_i$의 메커니즘을 나타내는 **C-Factor (Causal Factor)**입니다. 일반적으로 $Q[V_i] = P(v_i | pa_i)$로 이해할 수 있습니다.

Soft Intervention $\sigma_X$가 수행되면, $X$에 해당하는 메커니즘 $Q[X]$만이 $Q[X; [cite_start]\sigma_X]$로 교체되고, 나머지 변수들의 메커니즘은 불변(Invariant)한다고 가정합니다[cite: 26].

$$
P(z, x, y; \sigma_X) = Q[Z] \cdot \mathbf{Q[X; \sigma_X]} \cdot Q[Y]
$$

이 성질은 Soft Intervention의 효과를 식별(Identification)하는 핵심 원리가 됩니다.

---

# 3. Systematic Identification of Soft Interventions

Soft Intervention의 인과적 효과 $P(y; \sigma_X)$를 식별하기 위해 우리는 **C-Component** 분해를 활용합니다. 목표는 관측 가능한 데이터(Pre-intervention distribution)와 개입의 정의($\sigma_X$)만을 사용하여 $P(y; \sigma_X)$를 표현하는 것입니다.

## 3.1. C-Component와 Factorization

[cite_start]Tian & Pearl의 분해(Decomposition)에 따르면, 결합 확률 분포는 C-component($C_1, ..., C_k$)별로 분해될 수 있습니다[cite: 79, 80].

$$
Q[C_j] = \prod_{V_i \in C_j} P(v_i | pa_i) \quad \text{(Markovian case)}
$$
[cite_start]Semi-Markovian 모델(Latent confounder가 있는 경우)에서는 더 복잡한 형태를 띠며, 다음과 같이 정의됩니다[cite: 80]:
$$
Q[C_j] = \prod_{V_i \in C_j} \frac{Q[V^{\leq i}]}{Q[V^{\leq i-1}]}, \quad Q[V^{\leq i}] = \sum_{V^{> i}} P(v)
$$

이제 두 가지 예시를 통해 Soft Intervention이 어떻게 식별되거나 실패하는지 살펴보겠습니다.

## 3.2. Example 1: Identifiable Case

[cite_start]다음과 같은 인과 그래프와 개입을 고려해 봅시다[cite: 28, 29].

* **Graph $\mathcal{G}$:** $W \to Z, W \to X, X \to Z \to Y$. (Confounder $X \leftrightarrow Y$ 존재 가정)
* **Intervention:** $\sigma_X = P^*(X|W)$. 즉, $X$를 $W$에 의존하는 새로운 확률 분포로 변경.

![Figure 2: Example 1의 인과 그래프. (왼쪽) 원본 그래프 $\mathcal{G}$에서 $W$는 $X$와 $Z$의 부모이며, $X$와 $Y$ 사이에는 잠재적 교란 요인이 존재한다. (오른쪽) 개입 후 그래프 $\mathcal{G}_{\sigma_X}$에서 $X$는 $W$에 의해 제어되는 새로운 정책 $P^*(X|W)$를 따른다.](./images/example1_graph.png)

### Step 1: C-Component 식별
[cite_start]그래프 $\mathcal{G}$의 C-component는 다음과 같습니다[cite: 59, 75].
* $C_1 = \{X, Y\}$ (Latent confounder로 연결됨)
* $C_2 = \{W\}$
* $C_3 = \{Z\}$

### Step 2: Post-Intervention Distribution 표현
[cite_start]개입 후 분포 $P(v; \sigma_X)$는 $X$의 팩터만 교체된 형태입니다[cite: 41].

$$
P(v; \sigma_X) = Q[X; \sigma_X] Q[W] Q[Z] Q[Y]
$$
여기서 $Q[X; \sigma_X]$는 우리가 정의한 개입 $P^*(X|W)$입니다. [cite_start]나머지 $Q[W], Q[Z], Q[Y]$는 원본 데이터에서 식별해야 합니다[cite: 40].

### Step 3: 각 Q-factor 식별
[cite_start]알고리즘을 통해 각 구성요소를 식별합니다[cite: 76, 77].

1.  **$Q[C_2] = Q[W]$:** $W$는 외생변수이므로 $P(w)$.
2.  **$Q[C_3] = Q[Z]$:** $Z$의 부모는 $X, W$이므로 $P(z|x, w)$.
3.  **$Q[C_1] = Q[\{X, Y\}]$:** $X, Y$의 결합 분포. 이를 $Y$에 대한 부분만 떼어내면(Marginalizing $X$), $Q[Y]$ 관련 항을 얻을 수 있습니다.

### Step 4: 최종 유도 (Identification)
[cite_start]목표인 $P(y; \sigma_X)$를 구하기 위해 모든 변수 $V \setminus \{Y\}$에 대해 합을 구합니다[cite: 167].

$$
P(y; \sigma_X) = \sum_{w, x, z} P(w, x, z, y; \sigma_X)
$$
$$
= \sum_{w, x, z} \underbrace{Q[X; \sigma_X]}_{\text{New Policy}} \underbrace{Q[W] Q[Z] Q[Y]}_{\text{Pre-intervention Factors}}
$$

[cite_start]이 식을 정리하면 다음과 같은 최종 식별 공식을 얻습니다[cite: 168, 169].

$$
P(y; \sigma_X) = \sum_{w, x, z} P^*(x|w) P(z|x, w) P(w) \underbrace{\sum_{x'} P(y|x', z, w) P(x')}_{\text{from } Q[Y]}
$$
*(주: 마지막 항은 $Q[\{X,Y\}]$에서 $Y$에 기여하는 부분을 추출한 형태입니다. 구체적인 형태는 $Q[Y]$의 식별 과정에 따라 결정됩니다.)*

결론적으로, 이 경우는 **식별 가능(Identifiable)**합니다.

---

## 3.3. Example 2: Non-Identifiable Case

[cite_start]이제 식별이 불가능한 경우를 살펴봅니다[cite: 171].

* **Graph:** $X \to Z, X \to Y$, $W$와 $Z$ 사이, $W$와 $Y$ 사이 등에 복잡한 confounding 존재.
* **Intervention:** $\sigma_X = P^*(X|Z)$.

![Figure 3: Example 2의 인과 그래프. 소위 'Hedge' 또는 'Thicket' 구조를 포함하여, 특정 C-component의 조상 집합이 자기 자신과 겹치는 문제가 발생한다. 이는 식별 불가능성으로 이어진다.](./images/example2_graph.png)

### Step 1: C-Component 식별
[cite_start]이 그래프에서 $C_1 = \{W, X, Y\}$가 하나의 거대한 C-component를 형성한다고 가정해 봅시다[cite: 187].

### Step 2: 알고리즘 적용 (Identify 함수)
`Identify` 알고리즘은 $Q[C_1]$을 식별하려고 시도합니다.
1.  타겟 집합 $T = \{W, X, Y\}$.
2.  $A = An(C)$ (조상 집합)을 구합니다.
3.  [cite_start]만약 $A = T$라면(즉, 조상 집합이 전체 집합과 동일하여 더 이상 쪼개질 수 없다면), 알고리즘은 **Fail**을 반환합니다[cite: 190].

$$
\text{Identify}(C=\{W, Y\}, \dots) \to \text{Returns Fail}
$$

이는 $P(y; \sigma_X)$가 관측 데이터만으로는 유일하게 결정될 수 없음을 의미합니다.

---

# 4. σ-Calculus

[cite_start]$do$-calculus가 Atomic intervention을 위한 규칙을 제공하듯, **$\sigma$-calculus**는 Soft intervention을 위한 3가지 변환 규칙을 제공합니다[cite: 194].

이 규칙들은 확률 표현식에서 개입 항 $\sigma_X$를 추가하거나 제거하고, 관측값과 교환할 수 있게 해줍니다.

## Rule 1: Insertion/Deletion of Observations
[cite_start]관측 변수 $T$가 개입 $\sigma_X$ 하에서 $Y$와 조건부 독립이라면, 조건부에서 제거할 수 있습니다[cite: 195].

$$
P(y | w, t; \sigma_X) = P(y | w; \sigma_X) \quad \text{if } (Y \perp\!\!\perp T | W)_{G_{\sigma_X}}
$$

## Rule 2: Change of Regimes under Observation
개입 $\sigma_Z$를 다른 형태 $\sigma'_Z$ (혹은 $do(z)$ 등)로 바꾸거나 추가하는 규칙입니다. [cite_start]$W$가 주어졌을 때 $Y$와 $Z$가 독립이라면 개입의 형태를 바꿀 수 있습니다[cite: 195].

$$
P(y | w, z; \sigma_Z, \sigma_X) = P(y | w, z; \sigma'_Z, \sigma_X) \quad \text{if } (Y \perp\!\!\perp Z | W)_{G_{\sigma_X \sigma_Z}}
$$

## Rule 3: Change of Regimes without Observations
관측값 $Z$가 없는 상태에서 개입 $\sigma_Z$를 변경하는 규칙입니다. [cite_start]조건이 더 까다로우며 $Z$의 변동이 $Y$에 영향을 주지 않는 경로 구조여야 합니다[cite: 195].

$$
P(y | w; \sigma_Z, \sigma_X) = P(y | w; \sigma'_Z, \sigma_X) \quad \text{if } (Y \perp\!\!\perp Z | W)_{G_{\sigma_X \sigma_Z(W)}}
$$

---

# 5. Summary

Soft Intervention은 현실적인 정책 개입을 모델링하는 강력한 도구입니다.

1.  [cite_start]**Motivation:** $do(x)$와 같은 강제적 고정이 아닌, 조건부 확률 $P(X|W)$를 변경하는 개입을 다룹니다[cite: 191].
2.  **Factorization:** $P(v; \sigma_X)$는 $X$에 대한 새로운 메커니즘 $Q[X; [cite_start]\sigma_X]$와 기존의 불변하는 메커니즘들의 곱으로 표현됩니다[cite: 26].
3.  [cite_start]**Identification:** C-component 분해 알고리즘을 통해 식별 가능성을 체계적으로 판별할 수 있습니다[cite: 193].
4.  [cite_start]**$\sigma$-calculus:** $do$-calculus의 확장을 통해 복잡한 시나리오에서의 인과 효과를 유도할 수 있습니다[cite: 192, 194].

이 프레임워크는 의사결정 시스템, 개인화 추천, 경제 정책 분석 등 "메커니즘의 변화"를 다루는 모든 곳에 적용될 수 있습니다.

---

### 누락 방지 검증 체크리스트

* [x] **Motivation 포함:** Atomic intervention과의 차이 및 필요성 서술 (Section 1, 2)
* [x] **수식 재현:** $\sigma$-calculus 규칙 및 Factorization 식 LaTeX로 작성 (Section 2.2, 3.2, 4)
* [x] **Step-by-step 유도:** Example 1의 식별 과정을 단계별로 서술 (Section 3.2)
* [x] **실패 케이스 포함:** Example 2의 식별 실패 이유(Fail condition) 설명 (Section 3.3)
* [x] **이미지 태그:** 주요 그래프 위치에 Markdown 이미지 태그 삽입
* [x] **참고문헌 인용:** `` 형식을 사용하여 본문 내 근거 명시