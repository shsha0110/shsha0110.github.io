<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>shsha0110.github.io</title>
<link>https://shsha0110.github.io/</link>
<atom:link href="https://shsha0110.github.io/index.xml" rel="self" type="application/rss+xml"/>
<description>A blog built with Quarto</description>
<generator>quarto-1.8.26</generator>
<lastBuildDate>Fri, 30 Jan 2026 15:00:00 GMT</lastBuildDate>
<item>
  <title>[Paper Review] DAG-GNN: DAG Structure Learning with Graph Neural Networks</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/</link>
  <description><![CDATA[ 





<section id="introduction-the-challenge-of-structure-learning" class="level1">
<h1>1. Introduction: The Challenge of Structure Learning</h1>
<ul>
<li><p>인과추론(Causal Inference)과 머신러닝의 교차점에서, 데이터의 생성 과정을 설명하는 <strong>방향성 비순환 그래프(Directed Acyclic Graph, DAG)</strong>를 학습하는 것은 매우 중요한 문제입니다. 이를 <strong>Structure Learning</strong>이라고 부릅니다.</p></li>
<li><p>Bayesian Network(BN)의 구조인 DAG는 변수 간의 조건부 독립성을 표현하며, Pearl(1988) 이후 의학, 유전학, 경제학 등 다양한 분야에서 인과관계를 파악하는 도구로 사용되어 왔습니다.</p></li>
<li><p>하지만 데이터의 결합 분포(Joint Distribution)로부터 “Faithful”한 DAG를 찾아내는 것은 악명 높은 난제입니다.</p></li>
</ul>
<blockquote class="blockquote">
<p><strong>Faithfulness란?</strong></p>
<p>그래프 <img src="https://latex.codecogs.com/png.latex?G">와 결합 분포 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BP%7D">가 서로 “Faithful”하다는 것은, <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BP%7D">에서 성립하는 모든 조건부 독립성이 그래프 <img src="https://latex.codecogs.com/png.latex?G">에서도 (d-separation을 통해) 나타나고, 그 역도 성립함을 의미합니다.</p>
</blockquote>
<section id="the-combinatorial-problem-기존의-한계" class="level2">
<h2 class="anchored" data-anchor-id="the-combinatorial-problem-기존의-한계">The Combinatorial Problem (기존의 한계)</h2>
<ul>
<li><p>DAG 구조 학습이 어려운 근본적인 이유는 <strong>탐색 공간(Search Space)의 방대함</strong> 때문입니다.</p></li>
<li><p>노드(변수)의 개수가 늘어날 때, 가능한 그래프의 수는 초지수적(Superexponential)으로 증가합니다.</p></li>
<li><p>이는 NP-hard 문제로 알려져 있습니다.</p></li>
<li><p>전통적인 접근 방식은 크게 두 가지로 나뉩니다:</p></li>
<li><ol type="1">
<li><strong>Score-based Methods:</strong></li>
</ol>
<ul>
<li>가능한 그래프 구조에 대해 점수(BIC, BDeu 등)를 매기고, 이 점수를 최적화하는 그래프를 찾습니다.</li>
<li>하지만 그래프는 반드시 Acyclic(비순환)이어야 한다는 조합적 제약 조건(Combinatorial Constraint) 때문에, 전역 최적해를 찾는 것이 매우 어렵습니다.</li>
<li>따라서 탐욕적 탐색(Greedy Search)이나 트리 구조(Tree-structure) 가정 같은 근사법을 사용해야 했습니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Constraint-based Methods:</strong></li>
</ol>
<ul>
<li>변수 간의 조건부 독립성 검정(Independence Test)을 수행하여 엣지를 연결하거나 제거합니다 (예: PC Algorithm).</li>
<li>데이터 효율성이나 다중 가설 검정의 오류 문제 등이 존재합니다.</li>
</ul></li>
</ul>
</section>
<section id="the-paradigm-shift-from-discrete-to-continuous" class="level2">
<h2 class="anchored" data-anchor-id="the-paradigm-shift-from-discrete-to-continuous">The Paradigm Shift: From Discrete to Continuous</h2>
<ul>
<li>최근 <strong>Zheng et al.&nbsp;(2018)</strong>의 연구(흔히 <strong>NOTEARS</strong>로 알려짐)는 이 분야에 혁신적인 돌파구를 마련했습니다.</li>
<li>그들은 조합적 문제였던 “Acyclicity Constraint”를 미분 가능한 연속 함수 형태로 재정의했습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0Ah(A)%20=%20%5Ctext%7BTr%7D(e%5E%7BA%20%5Ccirc%20A%7D)%20-%20d%20=%200%0A"></p>
<ul>
<li>여기서 <img src="https://latex.codecogs.com/png.latex?A">는 인접 행렬(Adjacency Matrix), <img src="https://latex.codecogs.com/png.latex?d">는 노드의 개수입니다.</li>
<li>이 제약 조건 덕분에 구조 학습 문제는 이제 <strong>연속 최적화(Continuous Optimization)</strong> 문제로 변환되어, 경사 하강법(Gradient Descent)과 같은 표준적인 최적화 기법을 사용할 수 있게 되었습니다.</li>
</ul>
<section id="limitation-of-existing-continuous-methods" class="level3">
<h3 class="anchored" data-anchor-id="limitation-of-existing-continuous-methods">Limitation of Existing Continuous Methods</h3>
<ul>
<li>하지만 Zheng et al.&nbsp;(2018)의 접근법에도 한계가 있었습니다:
<ul>
<li><ol type="1">
<li><strong>선형성 가정 (Linearity Assumption):</strong> 기본적으로 선형 구조 방정식 모델(Linear SEM)을 가정합니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>분포의 제약:</strong> 최소제곱(Least-squares) 손실 함수를 사용하므로, 실제 데이터의 복잡한 분포를 반영하기 어렵습니다.</li>
</ol></li>
</ul></li>
<li>현실 세계의 데이터는 비선형적 관계를 가지며, 단순한 선형 모델로는 포착할 수 없는 복잡한 메커니즘으로 생성됩니다.</li>
</ul>
</section>
</section>
<section id="dag-gnn-a-deep-generative-approach" class="level2">
<h2 class="anchored" data-anchor-id="dag-gnn-a-deep-generative-approach">DAG-GNN: A Deep Generative Approach</h2>
<ul>
<li>본 논문(Yu et al., 2019)은 딥러닝의 강력한 표현력을 활용하여 기존의 선형 가정을 극복하고자 합니다. 저자들은 <strong>DAG-GNN</strong>이라는 새로운 아키텍처를 제안합니다.</li>
</ul>
<section id="key-idea-vae-graph-neural-networks" class="level3">
<h3 class="anchored" data-anchor-id="key-idea-vae-graph-neural-networks">Key Idea: VAE + Graph Neural Networks</h3>
<ul>
<li><p>이 모델의 핵심은 <strong>Variational Autoencoder (VAE)</strong> 프레임워크에 <strong>Graph Neural Network (GNN)</strong>을 결합한 것입니다.</p></li>
<li><p><strong>Deep Generative Model:</strong> 신경망은 “Universal Approximator”입니다. 이를 통해 변수 간의 복잡한 비선형 관계를 모델링합니다.</p></li>
<li><p><strong>Encoder/Decoder Parameterization:</strong> VAE의 인코더와 디코더를 일반적인 MLP가 아닌, 특별히 설계된 <strong>GNN</strong>으로 파라미터화합니다.</p></li>
<li><p><strong>Evidence Lower Bound (ELBO):</strong> 모델의 목적 함수(Score)는 VAE의 ELBO가 됩니다. 이는 데이터의 우도(Likelihood)를 최대화하는 방향으로 학습됨을 의미합니다.</p></li>
</ul>
</section>
<section id="a-new-acyclicity-constraint" class="level3">
<h3 class="anchored" data-anchor-id="a-new-acyclicity-constraint">A New Acyclicity Constraint</h3>
<ul>
<li><p>또한, 저자들은 NOTEARS에서 제안된 행렬 지수(Matrix Exponential) 제약 조건 대신, 딥러닝 프레임워크에서 구현하기 더 용이하고 수치적으로 안정적인 <strong>다항식(Polynomial) 형태의 새로운 제약 조건</strong>을 제안합니다.</p></li>
<li><p><strong>NOTEARS</strong> (Zheng et al., 2018): <img src="https://latex.codecogs.com/png.latex?Tr(e%5E%7BA%20%5Ccirc%20A%7D)%20-%20d%20=%200"></p></li>
<li><p><strong>DAG-GNN 제안:</strong> 수치적 안정성을 높인 변형된 형태를 사용합니다.</p></li>
</ul>
</section>
</section>
<section id="main-contributions" class="level2">
<h2 class="anchored" data-anchor-id="main-contributions">Main Contributions</h2>
<ul>
<li><p>이 논문의 Introduction에서 강조하는 주요 기여점은 다음과 같이 네 가지로 요약할 수 있습니다.</p></li>
<li><ol type="1">
<li><strong>Deep Generative Model 기반 접근:</strong></li>
</ol>
<ul>
<li>기존의 Linear SEM을 넘어, VAE를 사용하여 데이터의 복잡한 비선형 분포를 포착하고 샘플링할 수 있는 모델을 제안했습니다.</li>
<li>그래프 구조(Weighted Adjacency Matrix)는 잠재 변수가 아니라, 신경망 파라미터와 함께 학습되는 명시적인 파라미터로 설정됩니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>다양한 데이터 타입 지원:</strong></li>
</ol>
<ul>
<li>VAE 프레임워크의 특성상, 디코더의 출력 분포(Likelihood)를 적절히 설정함으로써 연속형 변수뿐만 아니라 이산형(Discrete) 변수도 자연스럽게 처리할 수 있습니다.</li>
</ul></li>
<li><ol start="3" type="1">
<li><strong>벡터 값 노드(Vector-valued Nodes) 지원:</strong></li>
</ol>
<ul>
<li>GNN을 사용하므로 각 노드가 단순 스칼라 값이 아닌 벡터 값을 가질 수 있습니다. 이는 각 노드가 여러 특징(Feature)을 가지는 복잡한 시나리오에 적용 가능함을 의미합니다.</li>
</ul></li>
<li><ol start="4" type="1">
<li><strong>개선된 Acyclicity Constraint:</strong></li>
</ol>
<ul>
<li>기존의 행렬 지수 제약 조건이 자동 미분(Automatic Differentiation) 라이브러리에서 구현하기 까다로울 수 있다는 점을 지적하며, 더 실용적이고 수치적으로 안정적인 다항식 기반의 대안을 제시했습니다.</li>
</ul></li>
</ul>
<hr>
</section>
</section>
<section id="background-and-related-work" class="level1">
<h1>2. Background and Related Work</h1>
<ul>
<li>DAG-GNN이 제안하는 새로운 방법론을 이해하기 위해서는, 먼저 <strong>구조 학습(Structure Learning)</strong>이 무엇인지, 그리고 지금까지 연구자들이 이 난제를 해결하기 위해 어떤 접근 방식을 취해왔는지 살펴볼 필요가 있습니다.</li>
<li>본 포스트에서는 논문의 <strong>Background</strong> 섹션을 바탕으로 인과 그래프 학습의 기술적 흐름을 정리합니다.</li>
</ul>
<section id="problem-definition-faithfulness-structure-learning" class="level2">
<h2 class="anchored" data-anchor-id="problem-definition-faithfulness-structure-learning">Problem Definition: Faithfulness &amp; Structure Learning</h2>
<ul>
<li>가장 먼저 정립해야 할 개념은 데이터와 그래프 사이의 관계입니다.</li>
<li>DAG(Directed Acyclic Graph) <img src="https://latex.codecogs.com/png.latex?G">와 결합 분포(Joint Distribution) <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BP%7D">가 서로 <strong>Faithful</strong>하다는 것은 다음을 의미합니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Faithfulness Condition (Pearl, 1988)</strong></p>
<p>분포 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BP%7D">에서 성립하는 모든 조건부 독립성(Conditional Independence)이 그래프 <img src="https://latex.codecogs.com/png.latex?G">에서의 <strong>d-separation</strong> 조건에 의해 정확히 함의(entail)될 때, 그리고 그 역도 성립할 때 <img src="https://latex.codecogs.com/png.latex?G">와 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BP%7D">는 Faithful하다고 합니다.</p>
</blockquote>
<ul>
<li><strong>구조 학습(Structure Learning)</strong>이란, 미지의 분포로부터 생성된 i.i.d. 샘플 데이터 <img src="https://latex.codecogs.com/png.latex?D">가 주어졌을 때, 이 분포와 Faithful한 관계에 있는 (미지의) DAG <img src="https://latex.codecogs.com/png.latex?G">를 복원해내는 과정을 말합니다.</li>
</ul>
</section>
<section id="traditional-approaches-the-era-of-discrete-search" class="level2">
<h2 class="anchored" data-anchor-id="traditional-approaches-the-era-of-discrete-search">Traditional Approaches: The Era of Discrete Search</h2>
<ul>
<li>전통적으로 DAG를 학습하는 알고리즘은 크게 <strong>Score-based</strong> 방법과 <strong>Constraint-based</strong> 방법으로 나뉩니다.</li>
</ul>
<section id="score-based-approaches" class="level3">
<h3 class="anchored" data-anchor-id="score-based-approaches">1) Score-based Approaches</h3>
<p>이 접근법은 그래프의 ’적합도’를 평가하는 점수(Score)를 정의하고, 이 점수를 최적화하는 그래프 구조를 탐색합니다.</p>
<ul>
<li><strong>점수 기준 (Score Criteria):</strong> 주로 베이지안 관점의 점수들이 사용됩니다. 대표적으로 BDeu, BIC(Bayesian Information Criterion) 등이 있으며, 이들은 <strong>Decomposable</strong>(분해 가능), <strong>Consistent</strong>(일치성), <strong>Score Equivalent</strong>(점수 등가성) 등의 좋은 수학적 성질을 가집니다.</li>
<li><strong>탐색 알고리즘 (Search Procedures):</strong> 가능한 모든 그래프를 탐색하는 것은 불가능하므로 다양한 전략이 사용됩니다.
<ul>
<li><em>Hill-climbing:</em> 지역적 최적해를 찾아가는 탐욕적 방법 (Heckerman et al., 1995 등)</li>
<li><em>Forward-backward search</em> (Chickering, 2002)</li>
<li><em>Dynamic Programming</em> (Singh &amp; Moore, 2005 등)</li>
<li><em>A* Search:</em> 최단 경로 탐색 알고리즘 응용 (Yuan &amp; Malone, 2013)</li>
<li><em>Integer Programming:</em> 정수 계획법을 통한 최적화 (Cussens, 2011 등)</li>
</ul></li>
</ul>
</section>
<section id="constraint-based-approaches" class="level3">
<h3 class="anchored" data-anchor-id="constraint-based-approaches">2) Constraint-based Approaches</h3>
<ul>
<li><p>이 방식은 변수 쌍 사이의 조건부 독립성 검정(Independence Test)을 수행하여 엣지의 존재 여부를 결정합니다.</p></li>
<li><p><strong>대표 알고리즘:</strong> SGS, PC (Spirtes et al.), IC (Pearl), FCI (Zhang) 등이 있습니다.</p></li>
<li><p>독립성 검정 결과를 바탕으로 엣지를 제거하거나 방향을 설정하여 그래프를 완성합니다.</p></li>
</ul>
</section>
<section id="hybrid-approaches-approximations" class="level3">
<h3 class="anchored" data-anchor-id="hybrid-approaches-approximations">3) Hybrid Approaches &amp; Approximations</h3>
<ul>
<li><p>순수한 Score-based나 Constraint-based 방법의 단점을 보완하기 위한 시도들도 있습니다.</p></li>
<li><p><strong>Hybrid:</strong> MMHC (Tsamardinos et al., 2003)와 같이 Constraint-based 방법으로 후보군을 줄인 뒤 Score-based로 최적화하는 방식입니다.</p></li>
<li><p><strong>Approximations:</strong> 탐색 공간을 줄이기 위해 Tree-width를 제한하거나(Nie et al., 2014), 트리 구조를 가정하는(Chow &amp; Liu, 1968) 등의 가정을 도입하기도 합니다.</p></li>
</ul>
</section>
</section>
<section id="the-computational-bottleneck" class="level2">
<h2 class="anchored" data-anchor-id="the-computational-bottleneck">The Computational Bottleneck</h2>
<ul>
<li><p>이러한 전통적 방법론들이 직면한 가장 큰 문제는 <strong>NP-Hardness</strong>입니다.</p></li>
<li><p>변수의 수가 늘어남에 따라 가능한 DAG의 수는 초지수적(Superexponential)으로 증가합니다.</p></li>
<li><p>따라서 많은 알고리즘이 이산형 변수(Discrete variables)로 대상을 한정하거나, 변수들이 결합 가우시안 분포(Jointly Gaussian)를 따른다고 가정해야만 했습니다.</p></li>
</ul>
</section>
<section id="the-paradigm-shift-continuous-optimization" class="level2">
<h2 class="anchored" data-anchor-id="the-paradigm-shift-continuous-optimization">The Paradigm Shift: Continuous Optimization</h2>
<ul>
<li><p>최근 <strong>Zheng et al.&nbsp;(2018)</strong>의 연구(NOTEARS)는 이 분야에 새로운 패러다임을 제시했습니다.</p></li>
<li><p><strong>핵심 아이디어:</strong> 이산적인 탐색 과정(Discrete Search Procedure)을 <strong>등식 제약조건(Equality Constraint)이 있는 연속 최적화 문제</strong>로 변환했습니다.</p></li>
<li><p><strong>장점:</strong> 경사 하강법(Gradient Descent)과 같은 연속 최적화 기법을 사용하여 DAG 구조를 학습할 수 있게 되었습니다.</p></li>
<li><p><strong>한계:</strong> 이 접근법은 구조 복원 성능이 우수하지만, 설명의 편의를 위해 <strong>선형 구조 방정식 모델(Linear SEM)</strong>에만 적용된다는 한계가 있었습니다.</p></li>
</ul>
</section>
<section id="neural-network-approaches" class="level2">
<h2 class="anchored" data-anchor-id="neural-network-approaches">Neural Network Approaches</h2>
<ul>
<li><p>최근에는 신경망(Neural Network)을 이용한 접근 방식도 등장하기 시작했습니다.</p></li>
<li><p><strong>GAN-style Approach (Kalainathan et al., 2018):</strong></p>
<ul>
<li>각 변수마다 별도의 생성 모델(Generative Model)을 두고, 생성된 샘플과 실제 데이터의 분포를 구분하는 판별자(Discriminator)를 두는 GAN 스타일의 방법론입니다.</li>
<li><strong>한계:</strong> 확장성(Scalability)은 좋아 보이지만, 결정적으로 <strong>비순환성(Acyclicity)이 강제되지 않는다</strong>는 문제가 있습니다. 즉, 학습된 결과가 DAG임을 보장할 수 없습니다.</li>
</ul></li>
</ul>
<blockquote class="blockquote">
<p><strong>Summary:</strong> 기존의 전통적 방법은 탐색 공간 문제로 확장이 어렵고, 최근 등장한 연속 최적화 방법(NOTEARS)은 선형성에 갇혀 있으며, 기존의 딥러닝 접근(GAN)은 DAG 구조를 보장하지 못합니다. <strong>DAG-GNN</strong>은 이러한 한계점들을 극복하기 위해 제안되었습니다.</p>
</blockquote>
<hr>
</section>
</section>
<section id="neural-dag-structure-learning" class="level1">
<h1>3. Neural DAG Structure Learning</h1>
<ul>
<li>본 논문은 선형 구조 방정식 모델(Linear SEM)을 일반화(Generalize)하여 딥러닝 기반의 생성 모델(Deep Generative Model)을 구축하는 것을 목표로 합니다.</li>
<li>첫 단계로, 가장 기본이 되는 <strong>Linear SEM</strong>의 수식적 구조와 그 의미를 먼저 명확히 짚고 넘어가겠습니다.</li>
</ul>
<section id="linear-structural-equation-model-linear-sem" class="level2">
<h2 class="anchored" data-anchor-id="linear-structural-equation-model-linear-sem">3.1. Linear Structural Equation Model (Linear SEM)</h2>
<ul>
<li>우리가 찾고자 하는 DAG(Directed Acyclic Graph)의 구조는 <strong>가중치가 있는 인접 행렬(Weighted Adjacency Matrix)</strong> <img src="https://latex.codecogs.com/png.latex?A">로 표현됩니다.</li>
</ul>
<section id="notation-및-정의" class="level3">
<h3 class="anchored" data-anchor-id="notation-및-정의">Notation 및 정의</h3>
<ul>
<li><p>먼저 모델링에 필요한 변수들을 정의합니다.</p></li>
<li><p><strong><img src="https://latex.codecogs.com/png.latex?m"></strong>: 노드(변수)의 개수입니다.</p></li>
<li><p><strong><img src="https://latex.codecogs.com/png.latex?A%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20m%7D"></strong>:</p>
<ul>
<li>DAG의 가중치 인접 행렬입니다.</li>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bij%7D">가 0이 아니라면 <img src="https://latex.codecogs.com/png.latex?i">에서 <img src="https://latex.codecogs.com/png.latex?j">로 가는 엣지가 존재함을 의미합니다.</li>
</ul></li>
<li><p><strong><img src="https://latex.codecogs.com/png.latex?X%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20d%7D"></strong>:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?m">개의 변수에 대한 데이터 행렬입니다.</li>
<li>일반적인 문헌에서 변수는 스칼라(<img src="https://latex.codecogs.com/png.latex?d=1">)로 취급되지만, 본 논문에서는 이를 <img src="https://latex.codecogs.com/png.latex?d">-차원 벡터로 일반화(Generalize)하여 <strong>Vector-valued Node</strong>를 다룹니다.</li>
<li>각 행(Row)은 하나의 변수(노드)에 대응하고, 각 열(Column)은 해당 변수의 특징(Feature) 혹은 샘플 차원을 의미합니다.</li>
</ul></li>
<li><p><strong><img src="https://latex.codecogs.com/png.latex?Z%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20d%7D"></strong>:</p>
<ul>
<li>노이즈 행렬(Noise Matrix)입니다.</li>
<li>외생 변수(Exogenous variable)에 해당합니다.</li>
</ul></li>
</ul>
</section>
<section id="선형-관계식-the-model" class="level3">
<h3 class="anchored" data-anchor-id="선형-관계식-the-model">선형 관계식 (The Model)</h3>
<ul>
<li>Linear SEM은 변수 <img src="https://latex.codecogs.com/png.latex?X">가 부모 변수들의 선형 결합(Linear Combination)과 노이즈 <img src="https://latex.codecogs.com/png.latex?Z">의 합으로 생성된다고 가정합니다. 이를 행렬식으로 표현하면 다음과 같습니다.</li>
</ul>
<p><span id="eq-(1)"><img src="https://latex.codecogs.com/png.latex?%0AX%20=%20A%5ET%20X%20+%20Z%0A%5Ctag%7B1%7D"></span></p>
<ul>
<li>이 식은 <strong>“현재 노드의 값(<img src="https://latex.codecogs.com/png.latex?X">)은 부모 노드들의 값(<img src="https://latex.codecogs.com/png.latex?A%5ET%20X">)에 가중치를 곱해 더한 뒤, 고유한 노이즈(<img src="https://latex.codecogs.com/png.latex?Z">)를 더한 것과 같다”</strong>는 인과적 메커니즘을 나타냅니다.</li>
</ul>
</section>
<section id="from-structure-to-generation-derivation" class="level3">
<h3 class="anchored" data-anchor-id="from-structure-to-generation-derivation">From Structure to Generation (Derivation)</h3>
<ul>
<li>이제 이 구조 방정식(Structural Equation)을 데이터를 생성하는 <strong>생성 모델(Generative Model)</strong>의 관점으로 전환해보겠습니다.</li>
<li>이를 위해서는 <img src="https://latex.codecogs.com/png.latex?Z">에서 <img src="https://latex.codecogs.com/png.latex?X">를 만들어내는 과정으로 수식을 변형해야 합니다.</li>
</ul>
<section id="topological-sort" class="level4">
<h4 class="anchored" data-anchor-id="topological-sort">Topological Sort</h4>
<ul>
<li><p>DAG의 가장 중요한 성질 중 하나는, 그래프 내에 사이클(Cycle)이 없기 때문에 모든 노드를 <strong>위상 정렬(Topological Order)</strong> 순서로 나열할 수 있다는 점입니다.</p></li>
<li><p>만약 노드들을 위상 정렬 순서대로 재배열한다면, 인접 행렬 <img src="https://latex.codecogs.com/png.latex?A">는 <strong>엄격한 상삼각 행렬(Strictly Upper Triangular Matrix)</strong>이 됩니다.</p>
<ul>
<li>즉, 대각 성분과 그 아래 성분들이 모두 0이 됩니다 (<img src="https://latex.codecogs.com/png.latex?A_%7Bij%7D%20=%200%20%5Ctext%7B%20for%20%7D%20i%20%5Cge%20j">).</li>
<li>이는 어떤 노드도 자기 자신이나 자신의 후손(descendant)으로부터 영향을 받지 않음을 수학적으로 보장합니다.</li>
</ul></li>
</ul>
</section>
<section id="transformation" class="level4">
<h4 class="anchored" data-anchor-id="transformation">Transformation</h4>
<ul>
<li>식 (1)을 <img src="https://latex.codecogs.com/png.latex?X">에 대해 정리하는 과정을 단계별로 유도해보겠습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0AX%20-%20A%5ET%20X%20&amp;=%20Z%20%5C%5C%0A(I%20-%20A%5ET)X%20&amp;=%20Z%20%5C%5C%0AX%20&amp;=%20(I%20-%20A%5ET)%5E%7B-1%7D%20Z%0A%5Cend%7Baligned%7D%0A"></p>
</section>
<section id="equivalence-with-ancestral-sampling" class="level4">
<h4 class="anchored" data-anchor-id="equivalence-with-ancestral-sampling">Equivalence with Ancestral Sampling</h4>
<p><span id="eq-(2)"><img src="https://latex.codecogs.com/png.latex?%0AX%20=%20(I%20-%20A%5ET)%5E%7B-1%7D%20Z%0A%5Ctag%7B2%7D"></span></p>
<ul>
<li>이 식은 <strong>“DAG를 따르는 Ancestral Sampling”</strong> 과정을 수학적으로 압축해 놓은 형태입니다. 그 이유를 단계별로 살펴보겠습니다.</li>
</ul>
<section id="ancestral-sampling이란" class="level5">
<h5 class="anchored" data-anchor-id="ancestral-sampling이란">Ancestral Sampling이란?</h5>
<ul>
<li><strong>Ancestral Sampling(조상 샘플링)</strong>은 베이지안 네트워크에서 데이터를 생성하는 가장 표준적인 방법입니다.</li>
<li>인과관계의 흐름(부모 <img src="https://latex.codecogs.com/png.latex?%5Cto"> 자식)에 따라 순차적으로 값을 결정하는 방식입니다.
<ul>
<li><ol type="1">
<li><strong>Top-down:</strong> 부모가 없는 루트 노드(조상)의 값을 먼저 노이즈(<img src="https://latex.codecogs.com/png.latex?Z">)로부터 결정합니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Propagation:</strong> 그 결정된 값이 자식 노드로 전파되어, 자식 노드의 값 결정에 영향을 줍니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li>이 과정을 위상 정렬(Topological Sort) 순서대로 끝까지 반복합니다.</li>
</ol></li>
</ul></li>
</ul>
</section>
<section id="neumann-series를-통한-연결" class="level5">
<h5 class="anchored" data-anchor-id="neumann-series를-통한-연결">Neumann Series를 통한 연결</h5>
<ul>
<li>식 (2) 의 역행렬 부분 <img src="https://latex.codecogs.com/png.latex?(I%20-%20A%5ET)%5E%7B-1%7D">을 <strong>노이만 급수(Neumann Series)</strong>를 이용해 전개합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A(I%20-%20A%5ET)%5E%7B-1%7D%20=%20I%20+%20A%5ET%20+%20(A%5ET)%5E2%20+%20(A%5ET)%5E3%20+%20%5Cdots%0A"></p>
<ul>
<li>이 전개식을 식 2에 대입하면 다음과 같습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AX%20=%20%5Cunderbrace%7BI%20%5Ccdot%20Z%7D_%7B%5Ctext%7BSelf%7D%7D%20+%20%5Cunderbrace%7BA%5ET%20%5Ccdot%20Z%7D_%7B%5Ctext%7BParents%7D%7D%20+%20%5Cunderbrace%7B(A%5ET)%5E2%20%5Ccdot%20Z%7D_%7B%5Ctext%7BGrandparents%7D%7D%20+%20%5Cdots%0A"></p>
</section>
<section id="행렬-거듭제곱ak의-의미" class="level5">
<h5 class="anchored" data-anchor-id="행렬-거듭제곱ak의-의미">행렬 거듭제곱(<img src="https://latex.codecogs.com/png.latex?A%5Ek">)의 의미</h5>
<ul>
<li>여기서 행렬의 거듭제곱 항들은 그래프 이론에서 <strong>경로(Path)</strong>의 개념과 일치합니다.
<ul>
<li><strong><img src="https://latex.codecogs.com/png.latex?I"> (0-hop):</strong> 자기 자신의 고유한 노이즈(<img src="https://latex.codecogs.com/png.latex?Z">)입니다.</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?A%5ET"> (1-hop):</strong> 부모 노드들로부터 직접 받는 영향입니다.</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?(A%5ET)%5E2"> (2-hop):</strong> 부모를 거쳐서 오는 <strong>조부모(Grandparents)</strong>의 영향입니다.</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?(A%5ET)%5Ek"> (<img src="https://latex.codecogs.com/png.latex?k">-hop):</strong> <img src="https://latex.codecogs.com/png.latex?k">단계를 거쳐서 오는 <strong><img src="https://latex.codecogs.com/png.latex?k">대 조상</strong>들의 영향입니다.</li>
</ul></li>
<li>즉, <img src="https://latex.codecogs.com/png.latex?X%20=%20(I%20-%20A%5ET)%5E%7B-1%7D%20Z">라는 수식은 <strong>“나의 값(<img src="https://latex.codecogs.com/png.latex?X">)은 내 고유한 성향(<img src="https://latex.codecogs.com/png.latex?Z">)뿐만 아니라, 부모, 조부모 등 모든 조상들의 영향력이 누적되어 형성된 것이다”</strong>라는 Ancestral Sampling의 철학을 행렬 연산 한 번으로 표현한 것입니다.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="보충: 왜 거듭제곱이 경로인가? (수학적 귀납법 증명)">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>보충: 왜 거듭제곱이 경로인가? (수학적 귀납법 증명)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>행렬 <img src="https://latex.codecogs.com/png.latex?A">의 거듭제곱 <img src="https://latex.codecogs.com/png.latex?A%5Ek">의 <img src="https://latex.codecogs.com/png.latex?(i,%20j)"> 성분이 <strong>노드 <img src="https://latex.codecogs.com/png.latex?i">에서 <img src="https://latex.codecogs.com/png.latex?j">로 가는 길이 <img src="https://latex.codecogs.com/png.latex?k">인 모든 경로의 가중치 합</strong>임을 수학적 귀납법으로 간단히 증명할 수 있습니다.</p>
<p><strong>명제 <img src="https://latex.codecogs.com/png.latex?P(k)">:</strong> <img src="https://latex.codecogs.com/png.latex?(A%5Ek)_%7Bij%7D">는 <img src="https://latex.codecogs.com/png.latex?i%20%5Cto%20j">로 가는 길이 <img src="https://latex.codecogs.com/png.latex?k">인 경로들의 가중치 합이다.</p>
<p><strong>1. 기초 단계 (Base Case, <img src="https://latex.codecogs.com/png.latex?k=1">):</strong> 정의에 의해 <img src="https://latex.codecogs.com/png.latex?(A%5E1)_%7Bij%7D%20=%20A_%7Bij%7D">입니다. 이는 <img src="https://latex.codecogs.com/png.latex?i">에서 <img src="https://latex.codecogs.com/png.latex?j">로 직접 연결된 엣지(길이 1)의 가중치이므로 명제 <img src="https://latex.codecogs.com/png.latex?P(1)">은 참입니다.</p>
<p><strong>2. 귀납 가정 (Inductive Step):</strong> 임의의 자연수 <img src="https://latex.codecogs.com/png.latex?k">에 대해 <img src="https://latex.codecogs.com/png.latex?P(k)">가 참이라고 가정합니다. 즉, <img src="https://latex.codecogs.com/png.latex?(A%5Ek)_%7Bit%7D">는 <img src="https://latex.codecogs.com/png.latex?i%20%5Cto%20t">로 가는 길이 <img src="https://latex.codecogs.com/png.latex?k">인 경로의 합입니다.</p>
<p>이제 <img src="https://latex.codecogs.com/png.latex?k+1">일 때를 살펴봅니다. 행렬 곱셈의 정의에 따라: <img src="https://latex.codecogs.com/png.latex?%0A(A%5E%7Bk+1%7D)_%7Bij%7D%20=%20(A%5Ek%20%5Ccdot%20A)_%7Bij%7D%20=%20%5Csum_%7Bt%7D%20(A%5Ek)_%7Bit%7D%20%5Ccdot%20A_%7Btj%7D%0A"></p>
<p>이 수식의 의미를 해석해 보면: * <img src="https://latex.codecogs.com/png.latex?(A%5Ek)_%7Bit%7D">: <img src="https://latex.codecogs.com/png.latex?i">에서 중간 노드 <img src="https://latex.codecogs.com/png.latex?t">까지 가는 길이 <img src="https://latex.codecogs.com/png.latex?k">인 경로 (귀납 가정) * <img src="https://latex.codecogs.com/png.latex?A_%7Btj%7D">: <img src="https://latex.codecogs.com/png.latex?t">에서 도착 노드 <img src="https://latex.codecogs.com/png.latex?j">로 가는 길이 <img src="https://latex.codecogs.com/png.latex?1">인 엣지 * <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bt%7D">: 가능한 모든 중간 경유지 <img src="https://latex.codecogs.com/png.latex?t">에 대해 합산</p>
<p>즉, <strong>“<img src="https://latex.codecogs.com/png.latex?i">에서 <img src="https://latex.codecogs.com/png.latex?t">까지 <img src="https://latex.codecogs.com/png.latex?k">걸음으로 간 뒤, <img src="https://latex.codecogs.com/png.latex?t">에서 <img src="https://latex.codecogs.com/png.latex?j">로 1걸음 더 가는 모든 경우의 수”</strong>를 더한 것이므로, 이는 <img src="https://latex.codecogs.com/png.latex?i">에서 <img src="https://latex.codecogs.com/png.latex?j">로 가는 <strong>길이 <img src="https://latex.codecogs.com/png.latex?k+1">인 모든 경로의 합</strong>과 같습니다.</p>
<p><strong>3. 결론:</strong> 수학적 귀납법에 의해 모든 자연수 <img src="https://latex.codecogs.com/png.latex?k">에 대해 명제 <img src="https://latex.codecogs.com/png.latex?P(k)">는 참입니다. 따라서 <img src="https://latex.codecogs.com/png.latex?(A%5ET)%5Ek">는 <img src="https://latex.codecogs.com/png.latex?k">단계를 거친 조상들의 영향력을 의미하게 됩니다.</p>
</div>
</div>
</div>
</section>
</section>
<section id="결론-vae-도입의-동기" class="level4">
<h4 class="anchored" data-anchor-id="결론-vae-도입의-동기">결론: VAE 도입의 동기</h4>
<ul>
<li>이러한 관점은 DAG 구조 학습 문제를 새로운 시각으로 바라보게 합니다.</li>
<li>복잡한 인과관계 추론 문제를 <strong>“노이즈 <img src="https://latex.codecogs.com/png.latex?Z">를 데이터 <img src="https://latex.codecogs.com/png.latex?X">로 매핑하는 인코더/디코더를 학습하는 문제”</strong>로 치환할 수 있습니다.</li>
<li>이것이 바로 저자들이 생성 모델의 대표 주자인 <strong>VAE(Variational Autoencoder)</strong>를 도입하여, 인코더와 디코더를 통해 <img src="https://latex.codecogs.com/png.latex?A">를 학습하고자 한 핵심적인 <strong>동기(Motivation)</strong>입니다.</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="proposed-graph-neural-network-model" class="level2">
<h2 class="anchored" data-anchor-id="proposed-graph-neural-network-model">3.2. Proposed Graph Neural Network Model</h2>
<ul>
<li>앞선 섹션에서 우리는 Linear SEM이 다음과 같이 노이즈 <img src="https://latex.codecogs.com/png.latex?Z">를 데이터 <img src="https://latex.codecogs.com/png.latex?X">로 변환하는 선형 과정으로 표현됨을 확인했습니다.</li>
<li>본 섹션에서는 이 수식을 <strong>Graph Neural Network(GNN)</strong>의 관점에서 재해석하고, 이를 바탕으로 비선형 관계까지 포착할 수 있는 <strong>DAG-GNN</strong>만의 독창적인 아키텍처를 검토합니다.</li>
</ul>
<section id="linear-sem-as-a-graph-neural-network" class="level3">
<h3 class="anchored" data-anchor-id="linear-sem-as-a-graph-neural-network">Linear SEM as a Graph Neural Network</h3>
<ul>
<li>저자들은 위 식 (2)를 딥러닝 커뮤니티의 관점에서 다음과 같은 일반적인 함수 꼴로 바라봅니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AX%20=%20f_A(Z)%0A"></p>
<ul>
<li>여기서 <img src="https://latex.codecogs.com/png.latex?f_A">는 그래프 구조(인접 행렬 <img src="https://latex.codecogs.com/png.latex?A">)에 의해 파라미터화된 함수입니다.</li>
<li>즉, <strong>“노드 특징(Feature)인 <img src="https://latex.codecogs.com/png.latex?Z">를 입력받아, 그래프 구조를 통과시켜 고차원 표현인 <img src="https://latex.codecogs.com/png.latex?X">를 반환하는 과정”</strong>으로 해석할 수 있습니다.</li>
</ul>
<section id="existing-gnn-architectures" class="level4">
<h4 class="anchored" data-anchor-id="existing-gnn-architectures">Existing GNN Architectures</h4>
<ul>
<li>대부분의 최신 GNN 모델들(GCN, GraphSAGE, GAT 등)도 이와 유사한 형태를 띱니다.</li>
<li>예를 들어, 널리 쓰이는 <strong>GCN (Graph Convolutional Network)</strong>의 수식은 다음과 같습니다. <img src="https://latex.codecogs.com/png.latex?%0AX%20=%20%5Chat%7BA%7D%20%5Ccdot%20%5Ctext%7BReLU%7D(%5Chat%7BA%7D%20Z%20W%5E1)%20%5Ccdot%20W%5E2%0A">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Chat%7BA%7D">: 정규화된 인접 행렬 (Normalized Adjacency Matrix)</li>
<li><img src="https://latex.codecogs.com/png.latex?W%5E1,%20W%5E2">: 학습 가능한 가중치 행렬</li>
</ul></li>
<li>하지만 일반적인 GNN은 주어진 고정된 그래프 위에서 노드 임베딩을 학습하는 것이 목표인 반면, 우리의 목표는 <strong>그래프 구조 <img src="https://latex.codecogs.com/png.latex?A"> 자체를 학습</strong>하는 것입니다.</li>
</ul>
</section>
</section>
<section id="the-dag-gnn-architecture" class="level3">
<h3 class="anchored" data-anchor-id="the-dag-gnn-architecture">The DAG-GNN Architecture</h3>
<ul>
<li>저자들은 Linear SEM의 구조적 특성(<img src="https://latex.codecogs.com/png.latex?(I-A%5ET)%5E%7B-1%7D">)을 그대로 계승하면서, 신경망의 표현력을 더하기 위해 <strong>새로운 GNN 아키텍처</strong>를 제안합니다.</li>
</ul>
<section id="the-proposed-equation" class="level4">
<h4 class="anchored" data-anchor-id="the-proposed-equation">The Proposed Equation</h4>
<p>제안하는 모델의 핵심 수식은 다음과 같습니다.</p>
<p><span id="eq-(3)"><img src="https://latex.codecogs.com/png.latex?%0AX%20=%20f_2%20%5Cleft(%20(I%20-%20A%5ET)%5E%7B-1%7D%20f_1(Z)%20%5Cright)%0A%5Ctag%7B3%7D"></span></p>
<ul>
<li><p>이 수식은 세 단계의 변환 과정으로 구성됩니다:</p></li>
<li><ol type="1">
<li><strong>Transforming Noise (<img src="https://latex.codecogs.com/png.latex?f_1(Z)">):</strong></li>
</ol>
<ul>
<li>입력 노이즈 <img src="https://latex.codecogs.com/png.latex?Z">를 비선형 함수 <img src="https://latex.codecogs.com/png.latex?f_1"> (MLP 등)을 통해 변환합니다.</li>
<li>이는 단순한 가우시안 노이즈가 아닌 복잡한 잠재 분포를 표현하기 위함입니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Structural Aggregation (<img src="https://latex.codecogs.com/png.latex?(I-A%5ET)%5E%7B-1%7D">):</strong></li>
</ol>
<ul>
<li>변환된 신호들이 DAG 구조 <img src="https://latex.codecogs.com/png.latex?A">에 따라 전파(Propagation)됩니다.</li>
<li>이 부분은 Linear SEM의 인과적 흐름을 그대로 따르며, 부모 노드의 영향력이 자식 노드로 전달되는 과정을 수학적으로 구현합니다.</li>
</ul></li>
<li><ol start="3" type="1">
<li><strong>Transforming into Data Space (<img src="https://latex.codecogs.com/png.latex?f_2(%5Ccdot)">):</strong></li>
</ol>
<ul>
<li>구조적 정보가 반영된 신호를 다시 비선형 함수 <img src="https://latex.codecogs.com/png.latex?f_2">를 통해 관측 데이터 공간(<img src="https://latex.codecogs.com/png.latex?X">)으로 매핑합니다.</li>
</ul></li>
</ul>
</section>
</section>
<section id="generalizing-the-linear-sem-interpretation" class="level3">
<h3 class="anchored" data-anchor-id="generalizing-the-linear-sem-interpretation">Generalizing the Linear SEM (Interpretation)</h3>
<ul>
<li><p>이 모델이 중요한 이유는, 이것이 기존의 <strong>Linear SEM을 비선형(Non-linear)으로 일반화(Generalize)</strong>한 형태이기 때문입니다.</p></li>
<li><p>만약 <img src="https://latex.codecogs.com/png.latex?f_2">가 <strong>역함수(Invertible)를 가진다</strong>고 가정해봅시다. 그렇다면 식 (3)의 양변에 <img src="https://latex.codecogs.com/png.latex?f_2%5E%7B-1%7D">를 취하고 정리하여 다음과 같은 관계를 유도할 수 있습니다.</p></li>
</ul>
<section id="derivation" class="level4">
<h4 class="anchored" data-anchor-id="derivation">Derivation</h4>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0AX%20&amp;=%20f_2((I%20-%20A%5ET)%5E%7B-1%7D%20f_1(Z))%20%5C%5C%0Af_2%5E%7B-1%7D(X)%20&amp;=%20(I%20-%20A%5ET)%5E%7B-1%7D%20f_1(Z)%20%5C%5C%0A(I%20-%20A%5ET)%20f_2%5E%7B-1%7D(X)%20&amp;=%20f_1(Z)%20%5C%5C%0Af_2%5E%7B-1%7D(X)%20-%20A%5ET%20f_2%5E%7B-1%7D(X)%20&amp;=%20f_1(Z)%20%5C%5C%0Af_2%5E%7B-1%7D(X)%20&amp;=%20A%5ET%20f_2%5E%7B-1%7D(X)%20+%20f_1(Z)%0A%5Cend%7Baligned%7D%0A"></p>
</section>
<section id="generalized-sem" class="level4">
<h4 class="anchored" data-anchor-id="generalized-sem">Generalized SEM</h4>
<ul>
<li>결과적으로 다음과 같은 <strong>Generalized SEM</strong> 식을 얻게 됩니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cunderbrace%7Bf_2%5E%7B-1%7D(X)%7D_%7B%5Ctext%7BTransformed%20Data%7D%7D%20=%20A%5ET%20%5Cunderbrace%7Bf_2%5E%7B-1%7D(X)%7D_%7B%5Ctext%7BParents%7D%7D%20+%20%5Cunderbrace%7Bf_1(Z)%7D_%7B%5Ctext%7BTransformed%20Noise%7D%7D%0A"></p>
<ul>
<li><strong>Linear SEM (<img src="https://latex.codecogs.com/png.latex?X%20=%20A%5ET%20X%20+%20Z">)과의 비교:</strong>
<ul>
<li>Linear SEM은 데이터 <img src="https://latex.codecogs.com/png.latex?X"> 자체가 선형 결합을 이룹니다.</li>
<li>DAG-GNN은 데이터 <img src="https://latex.codecogs.com/png.latex?X">를 적절히 비선형 변환한 <strong><img src="https://latex.codecogs.com/png.latex?f_2%5E%7B-1%7D(X)"> 공간에서 선형 관계(<img src="https://latex.codecogs.com/png.latex?A%5ET">)가 성립</strong>한다고 가정합니다.</li>
<li>또한 노이즈 역시 단순 합이 아니라 <img src="https://latex.codecogs.com/png.latex?f_1(Z)"> 형태로 비선형적으로 결합됩니다.</li>
</ul></li>
<li>이러한 설계를 통해 DAG-GNN은 변수 간의 관계가 복잡한 비선형일 때도, 이를 잠재 공간(Latent Space)에서의 구조적 관계로 포착할 수 있게 됩니다.</li>
</ul>
</section>
</section>
<section id="note-on-implementation" class="level3">
<h3 class="anchored" data-anchor-id="note-on-implementation">Note on Implementation</h3>
<ul>
<li>저자들은 <img src="https://latex.codecogs.com/png.latex?f_1">과 <img src="https://latex.codecogs.com/png.latex?f_2">를 구체적으로 어떤 신경망으로 구현할지에 대해서는 후속 섹션으로 미루고 있습니다.</li>
<li>다만 중요한 제약 사항 하나를 언급합니다:</li>
</ul>
<blockquote class="blockquote">
<p>“<img src="https://latex.codecogs.com/png.latex?f_2">의 마지막 활성화 함수(Activation function)는 반드시 변수 <img src="https://latex.codecogs.com/png.latex?X">의 타입(Domain)과 일치해야 한다.”</p>
</blockquote>
<ul>
<li>예를 들어, <img src="https://latex.codecogs.com/png.latex?X">가 실수형(Continuous)이라면 Identity 함수를, 이진형(Binary)이라면 Sigmoid 등을 사용해야 한다는 뜻입니다. 이는 추후 논의될 <strong>Discrete Variable</strong> 처리를 위한 포석입니다.</li>
</ul>
<hr>
</section>
</section>
<section id="model-learning-with-variational-autoencoder" class="level2">
<h2 class="anchored" data-anchor-id="model-learning-with-variational-autoencoder">3.3. Model Learning with Variational Autoencoder</h2>
<ul>
<li>이제 우리의 목표는 주어진 데이터 <img src="https://latex.codecogs.com/png.latex?X%5E1,%20%5Cdots,%20X%5En">을 가장 잘 설명하는 모델 파라미터(신경망 가중치 및 그래프 구조 <img src="https://latex.codecogs.com/png.latex?A">)를 찾는 것입니다.</li>
<li>본 섹션에서는 이를 위해 <strong>Variational Autoencoder (VAE)</strong> 프레임워크를 도입하는 과정과 그 수학적 배경을 상세히 다룹니다.</li>
</ul>
<section id="the-challenge-of-intractability" class="level3">
<h3 class="anchored" data-anchor-id="the-challenge-of-intractability">The Challenge of Intractability</h3>
<ul>
<li><p>일반적으로 확률 모델의 학습은 관측 데이터의 <strong>로그 우도(Log-Likelihood)</strong>, 또는 <strong>로그 증거(Log-Evidence)</strong>를 최대화하는 방향으로 진행됩니다.</p></li>
<li><p>데이터 샘플 <img src="https://latex.codecogs.com/png.latex?X%5E1,%20%5Cdots,%20X%5En">이 주어졌을 때, 평균 로그 증거는 다음과 같습니다.</p></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B1%7D%7Bn%7D%20%5Csum_%7Bk=1%7D%5En%20%5Clog%20p(X%5Ek)%20=%20%5Cfrac%7B1%7D%7Bn%7D%20%5Csum_%7Bk=1%7D%5En%20%5Clog%20%5Cint%20p(X%5Ek%20%7C%20Z)%20p(Z)%20%5C,%20dZ%0A"></p>
<ul>
<li>여기서 문제가 발생합니다.
<ul>
<li>우변의 적분 <img src="https://latex.codecogs.com/png.latex?%5Cint%20p(X%5Ek%20%7C%20Z)%20p(Z)%20%5C,%20dZ">는 잠재 변수 <img src="https://latex.codecogs.com/png.latex?Z">의 모든 가능한 값에 대해 주변화(Marginalization)를 수행해야 합니다.</li>
<li>하지만 <img src="https://latex.codecogs.com/png.latex?Z">가 고차원이거나 <img src="https://latex.codecogs.com/png.latex?p(X%7CZ)">가 복잡한 신경망(Neural Network)으로 구성된 경우, 이 적분은 해석적으로 구하는 것이 불가능하며(Intractable), 수치적으로 근사하기에도 계산 비용이 매우 큽니다.</li>
</ul></li>
<li>따라서 저자들은 이 문제를 해결하기 위해 <strong>변분 베이즈(Variational Bayes)</strong> 방법론을 도입합니다.</li>
</ul>
</section>
<section id="the-evidence-lower-bound-elbo" class="level3">
<h3 class="anchored" data-anchor-id="the-evidence-lower-bound-elbo">The Evidence Lower Bound (ELBO)</h3>
<ul>
<li>계산 불가능한 사후 분포 <img src="https://latex.codecogs.com/png.latex?p(Z%7CX)">를 근사하기 위해, 우리는 다루기 쉬운 분포인 <strong>변분 사후 분포(Variational Posterior)</strong> <img src="https://latex.codecogs.com/png.latex?q(Z%7CX)">를 도입합니다.</li>
</ul>
<section id="derivation-of-elbo" class="level4">
<h4 class="anchored" data-anchor-id="derivation-of-elbo">Derivation of ELBO</h4>
<ul>
<li><p>로그 증거 <img src="https://latex.codecogs.com/png.latex?%5Clog%20p(X)">에서 출발하여 <strong>ELBO(Evidence Lower Bound)</strong>를 유도하는 과정은 다음과 같습니다. (편의상 <img src="https://latex.codecogs.com/png.latex?X%5Ek">를 <img src="https://latex.codecogs.com/png.latex?X">로 표기합니다.)</p></li>
<li><ol type="1">
<li><strong>로그 내부의 분모/분자에 <img src="https://latex.codecogs.com/png.latex?q(Z%7CX)"> 곱하기:</strong> <img src="https://latex.codecogs.com/png.latex?%0A%20%20%5Cbegin%7Baligned%7D%0A%20%20%5Clog%20p(X)%20&amp;=%20%5Clog%20%5Cint%20p(X%7CZ)%20p(Z)%20%5C,%20dZ%20%5C%5C%20%20%0A%20%20&amp;=%20%5Clog%20%5Cint%20p(X,%20Z)%20%5C,%20dZ%20%5C%5C%0A%20%20&amp;=%20%5Clog%20%5Cint%20p(X,%20Z)%20%5Cfrac%7Bq(Z%7CX)%7D%7Bq(Z%7CX)%7D%20%5C,%20dZ%0A%20%20%5Cend%7Baligned%7D%0A%20%20"></li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>기댓값 형태로 변환:</strong> <img src="https://latex.codecogs.com/png.latex?%0A%20%20%5Cbegin%7Baligned%7D%0A%20%20&amp;=%20%5Clog%20%5Cint%20%5Cfrac%7Bp(X,%20Z)%7D%7Bq(Z%7CX)%7D%20q(Z%7CX)%20%5C,%20dZ%20%5C%5C%0A%20%20&amp;=%20%5Clog%20%5Cmathbb%7BE%7D_%7Bq(Z%7CX)%7D%20%5Cleft%5B%20%5Cfrac%7Bp(X,%20Z)%7D%7Bq(Z%7CX)%7D%20%5Cright%5D%0A%20%20%5Cend%7Baligned%7D%0A%20%20"></li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>젠센 부등식(Jensen’s Inequality) 적용:</strong></li>
</ol>
<ul>
<li>로그 함수는 오목(Concave) 함수이므로 <img src="https://latex.codecogs.com/png.latex?%5Clog(%5Cmathbb%7BE%7D%5BY%5D)%20%5Cge%20%5Cmathbb%7BE%7D%5B%5Clog(Y)%5D">가 성립합니다. <img src="https://latex.codecogs.com/png.latex?%0A%20%20%5Cge%20%5Cmathbb%7BE%7D_%7Bq(Z%7CX)%7D%20%5Cleft%5B%20%5Clog%20%5Cfrac%7Bp(X,%20Z)%7D%7Bq(Z%7CX)%7D%20%5Cright%5D%0A%20%20"></li>
</ul></li>
<li><ol start="4" type="1">
<li><strong>항 분리 및 정리 (ELBO의 도출):</strong></li>
</ol>
<ul>
<li>로그의 성질을 이용해 항을 분리하고, <img src="https://latex.codecogs.com/png.latex?Z">와 관련된 항들을 묶어 정리합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%20%20%5Cbegin%7Baligned%7D%0A%20%20%5Cmathcal%7BL%7D%20&amp;=%20%5Cmathbb%7BE%7D_%7Bq(Z%7CX)%7D%20%5Cleft%5B%20%5Clog%20%5Cfrac%7Bp(X%7CZ)p(Z)%7D%7Bq(Z%7CX)%7D%20%5Cright%5D%20%5C%5C%0A%20%20&amp;=%20%5Cmathbb%7BE%7D_%7Bq(Z%7CX)%7D%20%5CBig%5B%20%5Clog%20p(X%7CZ)%20+%20%5Cunderbrace%7B%5Clog%20p(Z)%20-%20%5Clog%20q(Z%7CX)%7D_%7B%5Ctext%7BLatent%20Variable%20Terms%7D%7D%20%5CBig%5D%0A%20%20%5Cend%7Baligned%7D%0A%20%20"></p>
<ul>
<li>여기서 <strong>KL Divergence(Kullback-Leibler Divergence)</strong>의 정의를 도입하여 식을 간결하게 정리할 수 있습니다.</li>
<li>두 확률분포 <img src="https://latex.codecogs.com/png.latex?q">와 <img src="https://latex.codecogs.com/png.latex?p">의 차이를 측정하는 KL Divergence는 다음과 같이 정의됩니다. <img src="https://latex.codecogs.com/png.latex?D_%7B%5Ctext%7BKL%7D%7D(q%20%7C%7C%20p)%20=%20%5Cmathbb%7BE%7D_%7Bx%20%5Csim%20q%7D%20%5B%20%5Clog%20q(x)%20-%20%5Clog%20p(x)%20%5D"></li>
<li>위 식의 뒷부분(<img src="https://latex.codecogs.com/png.latex?%5Clog%20p(Z)%20-%20%5Clog%20q(Z%7CX)">)은 KL Divergence 정의와 부호가 반대입니다. 따라서 마이너스(<img src="https://latex.codecogs.com/png.latex?-">)를 밖으로 빼내어 형태를 맞춥니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%20%20%5Cbegin%7Baligned%7D%0A%20%20&amp;=%20%5Cmathbb%7BE%7D_%7Bq(Z%7CX)%7D%20%5B%5Clog%20p(X%7CZ)%5D%20-%20%5Cmathbb%7BE%7D_%7Bq(Z%7CX)%7D%20%5B%5Cunderbrace%7B%5Clog%20q(Z%7CX)%20-%20%5Clog%20p(Z)%7D_%7BD_%7B%5Ctext%7BKL%7D%7D(q%7C%7Cp)%20%5Ctext%7B%20Form%7D%7D%20%5D%20%5C%5C%0A%20%20&amp;=%20%5Cmathbb%7BE%7D_%7Bq(Z%7CX)%7D%20%5B%5Clog%20p(X%7CZ)%5D%20-%20D_%7B%5Ctext%7BKL%7D%7D(q(Z%7CX)%20%7C%7C%20p(Z))%0A%20%20%5Cend%7Baligned%7D%0A%20%20"></p>
<ul>
<li>최종적으로 식 (4)에 해당하는 <strong>ELBO(Evidence Lower Bound)</strong>를 얻게 됩니다.</li>
</ul></li>
</ul>
<p><span id="eq-(4)"><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D_%7B%5Ctext%7BELBO%7D%7D%20%5Cequiv%20-D_%7B%5Ctext%7BKL%7D%7D%20%5CBig(%20q(Z%7CX%5Ek)%20%5C,%7C%7C%5C,%20p(Z)%20%5CBig)%20+%20%5Cmathbb%7BE%7D_%7Bq(Z%7CX%5Ek)%7D%20%5CBig%5B%20%5Clog%20p(X%5Ek%7CZ)%20%5CBig%5D%0A%5Ctag%7B4%7D"></span></p>
</section>
<section id="interpretation-of-elbo" class="level4">
<h4 class="anchored" data-anchor-id="interpretation-of-elbo">Interpretation of ELBO</h4>
<ul>
<li><p>식 (4)는 두 가지 직관적인 항으로 구성됩니다.</p></li>
<li><ol type="1">
<li><strong>Reconstruction Loss:</strong> <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BE%7D_%7Bq(Z%7CX%5Ek)%7D%20%5B%5Clog%20p(X%5Ek%7CZ)%5D"></li>
</ol>
<ul>
<li>잠재 변수 <img src="https://latex.codecogs.com/png.latex?Z">로부터 데이터 <img src="https://latex.codecogs.com/png.latex?X">를 복원할 확률(Likelihood)을 최대화합니다.</li>
<li>Autoencoder의 복원 오차 최소화와 대응됩니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Regularization Term:</strong> <img src="https://latex.codecogs.com/png.latex?-D_%7B%5Ctext%7BKL%7D%7D(q(Z%7CX%5Ek)%20%7C%7C%20p(Z))"></li>
</ol>
<ul>
<li>우리가 근사한 사후 분포 <img src="https://latex.codecogs.com/png.latex?q(Z%7CX)">가 사전 분포 <img src="https://latex.codecogs.com/png.latex?p(Z)">(일반적으로 표준 정규분포)와 얼마나 다른지를 측정합니다.</li>
<li>이 차이를 최소화(음수이므로 최대화)하여, 잠재 공간이 과도하게 찌그러지는 것을 방지합니다.</li>
</ul></li>
<li><p>결론적으로, 실제 로그 증거와 ELBO의 차이는 KL Divergence <img src="https://latex.codecogs.com/png.latex?D_%7B%5Ctext%7BKL%7D%7D(q(Z%7CX)%20%7C%7C%20p(Z%7CX))%20%5Cge%200"> 만큼 발생하므로, <strong>ELBO를 최대화하는 것은 로그 증거의 하한(Lower Bound)을 최대화하는 것</strong>과 같습니다.</p></li>
</ul>
</section>
</section>
<section id="architecture-encoder-and-decoder" class="level3">
<h3 class="anchored" data-anchor-id="architecture-encoder-and-decoder">Architecture: Encoder and Decoder</h3>
<ul>
<li>VAE 프레임워크를 DAG-GNN에 적용하기 위해, Encoder와 Decoder를 구체적인 신경망 구조로 정의해야 합니다.</li>
</ul>
<section id="decoder-generative-model" class="level4">
<h4 class="anchored" data-anchor-id="decoder-generative-model">Decoder (Generative Model)</h4>
<ul>
<li>Decoder는 잠재 변수 <img src="https://latex.codecogs.com/png.latex?Z">에서 데이터 <img src="https://latex.codecogs.com/png.latex?X">를 생성하는 역할을 합니다.</li>
<li>이는 3.2절에서 정의한 <strong>Generalized SEM (식 3)</strong>과 정확히 일치합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BDecoder:%20%7D%20%5Cquad%20X%20=%20f_2%20%5Cleft(%20(I%20-%20A%5ET)%5E%7B-1%7D%20f_1(Z)%20%5Cright)%0A"></p>
<ul>
<li>여기서 <img src="https://latex.codecogs.com/png.latex?(I-A%5ET)%5E%7B-1%7D"> 항은 <img src="https://latex.codecogs.com/png.latex?Z">의 정보가 그래프 구조를 따라 퍼져나가며(Propagation) <img src="https://latex.codecogs.com/png.latex?X">를 형성하는 과정을 담당합니다.</li>
</ul>
</section>
<section id="encoder-inference-model" class="level4">
<h4 class="anchored" data-anchor-id="encoder-inference-model">Encoder (Inference Model)</h4>
<ul>
<li>Encoder는 관측된 데이터 <img src="https://latex.codecogs.com/png.latex?X">로부터 잠재 변수 <img src="https://latex.codecogs.com/png.latex?Z">를 추론하는 역할을 합니다.</li>
<li>저자들은 Decoder의 역연산 개념을 적용하여 다음과 같은 <strong>Encoder 구조</strong>를 제안합니다.</li>
</ul>
<p><span id="eq-(5)"><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BEncoder:%20%7D%20%5Cquad%20Z%20=%20f_4%20%5Cleft(%20(I%20-%20A%5ET)%20f_3(X)%20%5Cright)%0A%5Ctag%7B5%7D"></span></p>
<ul>
<li>이 수식의 의미는 다음과 같습니다:
<ul>
<li><ol type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?f_3(X)">:</strong></li>
</ol>
<ul>
<li>데이터 <img src="https://latex.codecogs.com/png.latex?X">를 비선형 변환합니다. 개념적으로 Decoder의 <img src="https://latex.codecogs.com/png.latex?f_2">의 역함수 역할을 수행합니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?(I%20-%20A%5ET)">:</strong></li>
</ol>
<ul>
<li>Decoder에서는 역행렬 <img src="https://latex.codecogs.com/png.latex?(I-A%5ET)%5E%7B-1%7D">을 사용해 정보를 확산시켰다면, Encoder에서는 그 역연산인 <img src="https://latex.codecogs.com/png.latex?(I-A%5ET)">를 곱합니다.</li>
<li>이는 섞여 있는 정보들로부터 <strong>부모 노드의 영향을 제거</strong>하여 독립적인 노이즈(Latent factor)를 발라내는 과정으로 해석할 수 있습니다.</li>
</ul></li>
<li><ol start="3" type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?f_4(%5Ccdot)">:</strong></li>
</ol>
<ul>
<li>최종적으로 비선형 변환을 통해 <img src="https://latex.codecogs.com/png.latex?Z"> 공간으로 매핑합니다. 개념적으로 Decoder의 <img src="https://latex.codecogs.com/png.latex?f_1">의 역함수 역할을 합니다.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="parameterization" class="level4">
<h4 class="anchored" data-anchor-id="parameterization">Parameterization</h4>
<ul>
<li><strong>함수:</strong> <img src="https://latex.codecogs.com/png.latex?f_1,%20f_2"> (Decoder)와 <img src="https://latex.codecogs.com/png.latex?f_3,%20f_4"> (Encoder)는 모두 MLP(Multi-Layer Perceptron)로 파라미터화됩니다.</li>
<li><strong>분포:</strong>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?q(Z%7CX)">와 <img src="https://latex.codecogs.com/png.latex?p(X%7CZ)">는 각각 가우시안 분포 등을 가정하며, 신경망은 이 분포의 평균(<img src="https://latex.codecogs.com/png.latex?%5Cmu">)과 분산(<img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2">)을 출력하도록 설계됩니다.</li>
<li>구체적인 분포의 형태와 활성화 함수는 데이터 <img src="https://latex.codecogs.com/png.latex?X">의 타입(연속형 vs 이산형)에 따라 결정됩니다.</li>
</ul></li>
</ul>
<hr>
</section>
</section>
</section>
<section id="architecture-and-loss-function" class="level2">
<h2 class="anchored" data-anchor-id="architecture-and-loss-function">3.4. Architecture and Loss Function</h2>
<ul>
<li>이전 섹션에서 우리는 DAG 구조 학습을 위한 VAE 프레임워크를 정의했습니다.</li>
<li>이제 추상적인 수식(<img src="https://latex.codecogs.com/png.latex?f_1,%20f_2,%20f_3,%20f_4">)을 넘어, 실제로 모델을 어떻게 구현하고 학습시킬지 구체적인 <strong>Architecture</strong>와 <strong>Loss Function</strong>을 정의할 차례입니다.</li>
<li>이 과정에서 우리는 입력 데이터 <img src="https://latex.codecogs.com/png.latex?X">와 잠재 변수 <img src="https://latex.codecogs.com/png.latex?Z">의 확률 분포를 가정하고, 이를 바탕으로 ELBO(Evidence Lower Bound)를 계산 가능한 수식으로 유도합니다.</li>
</ul>
<section id="distribution-specifications" class="level3">
<h3 class="anchored" data-anchor-id="distribution-specifications">Distribution Specifications</h3>
<ul>
<li>모델 학습을 위해서는 변수들의 확률 분포를 명시해야 합니다.</li>
<li>여기서 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Z">는 모두 <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20d"> 차원의 행렬입니다 (<img src="https://latex.codecogs.com/png.latex?m">: 노드 수, <img src="https://latex.codecogs.com/png.latex?d">: 특징 차원).</li>
</ul>
<section id="prior-distribution-pz" class="level4">
<h4 class="anchored" data-anchor-id="prior-distribution-pz">Prior Distribution <img src="https://latex.codecogs.com/png.latex?p(Z)"></h4>
<ul>
<li>잠재 변수 <img src="https://latex.codecogs.com/png.latex?Z">의 사전 분포(Prior)는 가장 일반적인 가정인 <strong>Standard Matrix Normal</strong> 분포를 따릅니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0Ap(Z)%20=%20%5Cmathcal%7BMN%7D_%7Bm%20%5Ctimes%20d%7D(0,%20I,%20I)%0A"></p>
<ul>
<li>이는 <img src="https://latex.codecogs.com/png.latex?Z">의 모든 원소 <img src="https://latex.codecogs.com/png.latex?Z_%7Bij%7D">가 평균이 0이고 분산이 1인 독립적인 정규분포(i.i.d. Gaussian)를 따른다는 것을 의미하며, 계산의 편의성을 위해 다음과 같이 요소별(element-wise) 분포로 취급할 수 있습니다. <img src="https://latex.codecogs.com/png.latex?p(Z_%7Bij%7D)%20=%20%5Cmathcal%7BN%7D(0,%201)"></li>
</ul>
</section>
</section>
<section id="encoder-architecture-inference-model" class="level3">
<h3 class="anchored" data-anchor-id="encoder-architecture-inference-model">Encoder Architecture (Inference Model)</h3>
<ul>
<li><p>Encoder는 데이터 <img src="https://latex.codecogs.com/png.latex?X">를 입력받아 잠재 변수 <img src="https://latex.codecogs.com/png.latex?Z">의 분포 <img src="https://latex.codecogs.com/png.latex?q(Z%7CX)">를 추론합니다.</p></li>
<li><p><strong>가정:</strong> <img src="https://latex.codecogs.com/png.latex?q(Z%7CX)">는 <strong>Factored Gaussian</strong> (대각 공분산을 갖는 정규분포)을 따른다고 가정합니다.</p></li>
<li><p><strong>구성:</strong> 평균 행렬 <img src="https://latex.codecogs.com/png.latex?M_Z%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20d%7D">와 표준편차 행렬 <img src="https://latex.codecogs.com/png.latex?S_Z%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20d%7D">를 출력합니다.</p></li>
<li><p><strong>함수 매핑:</strong></p>
<ul>
<li>앞선 섹션의 <img src="https://latex.codecogs.com/png.latex?f_3"> (데이터 변환): <strong>MLP (Multi-Layer Perceptron)</strong></li>
<li>앞선 섹션의 <img src="https://latex.codecogs.com/png.latex?f_4"> (잠재 공간 매핑): <strong>Identity Mapping</strong></li>
</ul></li>
<li><p>이를 수식으로 표현하면 다음과 같습니다.</p></li>
</ul>
<p><span id="eq-(6)"><img src="https://latex.codecogs.com/png.latex?%0A%5BM_Z%20%7C%20%5Clog%20S_Z%5D%20=%20%5Cunderbrace%7B(I%20-%20A%5ET)%7D_%7B%5Ctext%7BStructure%20Removal%7D%7D%20%5Cunderbrace%7B%5Ctext%7BMLP%7D(X,%20W%5E1,%20W%5E2)%7D_%7B%5Ctext%7BFeature%20Transform%7D%7D%0A%5Ctag%7B6%7D"></span></p>
<ul>
<li>여기서 <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BMLP%7D(X,%20W%5E1,%20W%5E2)%20:=%20%5Ctext%7BReLU%7D(X%20W%5E1)%20W%5E2"> 입니다.</li>
</ul>
<section id="interpretation" class="level4">
<h4 class="anchored" data-anchor-id="interpretation">Interpretation</h4>
<ul>
<li>식 (6)을 보면 <img src="https://latex.codecogs.com/png.latex?(I-A%5ET)"> 연산이 MLP <strong>다음에</strong> 적용됩니다.</li>
<li>이는 MLP를 통해 데이터의 비선형 특징을 추출한 뒤, <img src="https://latex.codecogs.com/png.latex?(I-A%5ET)"> 선형 변환을 통해 변수 간의 인과적 종속성(Parent effect)을 제거(Decorrelation)하여 독립적인 잠재 변수 <img src="https://latex.codecogs.com/png.latex?Z">를 만들어내겠다는 의도입니다.</li>
</ul>
</section>
</section>
<section id="decoder-architecture-generative-model" class="level3">
<h3 class="anchored" data-anchor-id="decoder-architecture-generative-model">Decoder Architecture (Generative Model)</h3>
<ul>
<li><p>Decoder는 잠재 변수 <img src="https://latex.codecogs.com/png.latex?Z">로부터 데이터 <img src="https://latex.codecogs.com/png.latex?X">를 복원(Reconstruction)합니다.</p></li>
<li><p><strong>가정:</strong> <img src="https://latex.codecogs.com/png.latex?p(X%7CZ)"> 역시 <strong>Factored Gaussian</strong>을 따른다고 가정합니다.</p></li>
<li><p><strong>구성:</strong> 평균 행렬 <img src="https://latex.codecogs.com/png.latex?M_X%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20d%7D">와 표준편차 행렬 <img src="https://latex.codecogs.com/png.latex?S_X%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20d%7D">를 출력합니다.</p></li>
<li><p><strong>함수 매핑:</strong></p>
<ul>
<li>앞선 섹션의 <img src="https://latex.codecogs.com/png.latex?f_1"> (노이즈 변환): <strong>Identity Mapping</strong></li>
<li>앞선 섹션의 <img src="https://latex.codecogs.com/png.latex?f_2"> (데이터 복원): <strong>MLP</strong></li>
</ul></li>
<li><p>이를 수식으로 표현하면 다음과 같습니다.</p></li>
</ul>
<p><span id="eq-(7)"><img src="https://latex.codecogs.com/png.latex?%0A%5BM_X%20%7C%20%5Clog%20S_X%5D%20=%20%5Cunderbrace%7B%5Ctext%7BMLP%7D%7D_%7B%5Ctext%7BData%20Generation%7D%7D%20%5Cleft(%20%5Cunderbrace%7B(I%20-%20A%5ET)%5E%7B-1%7D%20Z%7D_%7B%5Ctext%7BStructure%20Propagation%7D%7D,%20W%5E3,%20W%5E4%20%5Cright)%0A%5Ctag%7B7%7D"></span></p>
<section id="interpretation-1" class="level4">
<h4 class="anchored" data-anchor-id="interpretation-1">Interpretation</h4>
<ul>
<li>저자들은 <img src="https://latex.codecogs.com/png.latex?f_1">과 <img src="https://latex.codecogs.com/png.latex?f_2">의 위치를 바꾸어 실험해 보았으나, 현재의 설계(내부에 Identity, 외부에 MLP)가 성능이 더 좋았다고 보고합니다.</li>
<li>그 이유는 식 (7)의 설계가 <strong>Linear SEM의 구조적 변환 <img src="https://latex.codecogs.com/png.latex?(I-A%5ET)%5E%7B-1%7DZ">를 강조</strong>하기 때문입니다.</li>
<li>구조적 전파(Propagation)가 먼저 일어난 뒤 MLP가 비선형성을 입히는 방식이 비선형 데이터 생성 과정을 더 잘 포착한다는 것입니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/images/dag_gnn_architecture_schematic.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: DAG-GNN의 전체 아키텍처 (Continuous Variables). 입력 <img src="https://latex.codecogs.com/png.latex?X">가 MLP와 <img src="https://latex.codecogs.com/png.latex?(I-A%5ET)">를 거쳐 잠재 변수 <img src="https://latex.codecogs.com/png.latex?Z">의 통계량(<img src="https://latex.codecogs.com/png.latex?M_Z,%20S_Z">)으로 인코딩되고, 샘플링된 <img src="https://latex.codecogs.com/png.latex?Z">는 <img src="https://latex.codecogs.com/png.latex?(I-A%5ET)%5E%7B-1%7D">와 MLP를 거쳐 다시 <img src="https://latex.codecogs.com/png.latex?X">의 통계량(<img src="https://latex.codecogs.com/png.latex?M_X,%20S_X">)으로 디코딩된다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="loss-function-derivation-elbo" class="level3">
<h3 class="anchored" data-anchor-id="loss-function-derivation-elbo">Loss Function Derivation (ELBO)</h3>
<ul>
<li>이제 정의된 분포(<img src="https://latex.codecogs.com/png.latex?p(Z),%20q(Z%7CX),%20p(X%7CZ)">)를 바탕으로, VAE의 목적 함수인 <strong>ELBO</strong>를 구체적인 수식으로 유도해 봅시다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D_%7B%5Ctext%7BELBO%7D%7D%20=%20-D_%7B%5Ctext%7BKL%7D%7D(q(Z%7CX)%20%7C%7C%20p(Z))%20+%20%5Cmathbb%7BE%7D_%7Bq(Z%7CX)%7D%5B%5Clog%20p(X%7CZ)%5D%0A"></p>
<section id="kl-divergence-term-regularization" class="level4">
<h4 class="anchored" data-anchor-id="kl-divergence-term-regularization">KL Divergence Term (Regularization)</h4>
<ul>
<li><p>이 항은 근사 분포 <img src="https://latex.codecogs.com/png.latex?q(Z%7CX)">가 사전 분포 <img src="https://latex.codecogs.com/png.latex?p(Z)">와 얼마나 다른지를 측정합니다.</p></li>
<li><p>두 분포가 모두 가우시안일 경우, 복잡한 적분 없이도 파라미터(<img src="https://latex.codecogs.com/png.latex?M_Z,%20S_Z">)만으로 계산 가능한 <strong>Closed Form(닫힌 해)</strong>이 존재합니다.</p></li>
<li><p><strong>가정:</strong></p>
<ul>
<li><strong>Variational Posterior:</strong> <img src="https://latex.codecogs.com/png.latex?q(Z%7CX)%20=%20%5Cmathcal%7BN%7D(M_Z,%20S_Z%5E2)"> (Factored Gaussian)</li>
<li><strong>Prior:</strong> <img src="https://latex.codecogs.com/png.latex?p(Z)%20=%20%5Cmathcal%7BN%7D(0,%20I)"> (Standard Normal)</li>
</ul></li>
<li><p>모든 변수가 독립(Independent)이므로, 단일 원소 <img src="https://latex.codecogs.com/png.latex?z%20%5Csim%20q(z)%20=%20%5Cmathcal%7BN%7D(%5Cmu,%20%5Csigma%5E2)">와 <img src="https://latex.codecogs.com/png.latex?p(z)%20=%20%5Cmathcal%7BN%7D(0,%201)"> 사이의 KL Divergence를 먼저 유도한 뒤 합산하면 됩니다.</p></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="상세 유도: 두 가우시안 사이의 KL Divergence">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>상세 유도: 두 가우시안 사이의 KL Divergence
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>1. 정의:</strong> <img src="https://latex.codecogs.com/png.latex?D_%7B%5Ctext%7BKL%7D%7D(q%7C%7Cp)%20=%20%5Cmathbb%7BE%7D_%7Bz%20%5Csim%20q%7D%20%5B%5Clog%20q(z)%20-%20%5Clog%20p(z)%5D"></p>
<p><strong>2. 로그 확률밀도함수 전개:</strong> <img src="https://latex.codecogs.com/png.latex?%5Clog%20q(z)%20=%20-%5Cfrac%7B1%7D%7B2%7D%5Clog(2%5Cpi)%20-%20%5Clog%5Csigma%20-%20%5Cfrac%7B(z-%5Cmu)%5E2%7D%7B2%5Csigma%5E2%7D"> <img src="https://latex.codecogs.com/png.latex?%5Clog%20p(z)%20=%20-%5Cfrac%7B1%7D%7B2%7D%5Clog(2%5Cpi)%20-%20%5Cfrac%7Bz%5E2%7D%7B2%7D"></p>
<p><strong>3. 차이 계산:</strong> <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Clog%20q(z)%20-%20%5Clog%20p(z)%20&amp;=%20%5Cleft(%20-%5Clog%5Csigma%20-%20%5Cfrac%7B(z-%5Cmu)%5E2%7D%7B2%5Csigma%5E2%7D%20%5Cright)%20-%20%5Cleft(%20-%20%5Cfrac%7Bz%5E2%7D%7B2%7D%20%5Cright)%20%5C%5C%0A&amp;=%20-%5Clog%5Csigma%20+%20%5Cfrac%7B1%7D%7B2%7Dz%5E2%20-%20%5Cfrac%7B(z-%5Cmu)%5E2%7D%7B2%5Csigma%5E2%7D%0A%5Cend%7Baligned%7D%0A"></p>
<p><strong>4. 기댓값(<img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BE%7D_q">) 취하기:</strong> <img src="https://latex.codecogs.com/png.latex?z%20%5Csim%20%5Cmathcal%7BN%7D(%5Cmu,%20%5Csigma%5E2)">일 때, <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BE%7D%5Bz%5E2%5D%20=%20%5Cmu%5E2%20+%20%5Csigma%5E2"> 이고 <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BE%7D%5B(z-%5Cmu)%5E2%5D%20=%20%5Csigma%5E2"> 임을 이용합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Cmathbb%7BE%7D_q%20%5B%5Cdots%5D%20&amp;=%20-%5Clog%5Csigma%20+%20%5Cfrac%7B1%7D%7B2%7D(%5Cmu%5E2%20+%20%5Csigma%5E2)%20-%20%5Cfrac%7B%5Csigma%5E2%7D%7B2%5Csigma%5E2%7D%20%5C%5C%0A&amp;=%20-%5Clog%5Csigma%20+%20%5Cfrac%7B1%7D%7B2%7D%5Cmu%5E2%20+%20%5Cfrac%7B1%7D%7B2%7D%5Csigma%5E2%20-%20%5Cfrac%7B1%7D%7B2%7D%20%5C%5C%0A&amp;=%20%5Cfrac%7B1%7D%7B2%7D%20(%5Csigma%5E2%20+%20%5Cmu%5E2%20-%202%5Clog%5Csigma%20-%201)%0A%5Cend%7Baligned%7D%0A"></p>
</div>
</div>
</div>
<ul>
<li>위의 스칼라 유도 결과를 행렬 전체(<img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20d">)에 대해 합산하면 다음과 같습니다.</li>
</ul>
<p><span id="eq-(8)"><img src="https://latex.codecogs.com/png.latex?%0AD_%7B%5Ctext%7BKL%7D%7D%5CBig(q(Z%7CX)%20%5C,%7C%7C%5C,%20p(Z)%5CBig)%20=%20%5Cfrac%7B1%7D%7B2%7D%20%5Csum_%7Bi=1%7D%5Em%20%5Csum_%7Bj=1%7D%5Ed%20%5Cleft(%20%5Cunderbrace%7B(S_Z)_%7Bij%7D%5E2%7D_%7B%5Csigma%5E2%7D%20+%20%5Cunderbrace%7B(M_Z)_%7Bij%7D%5E2%7D_%7B%5Cmu%5E2%7D%20-%20%5Cunderbrace%7B2%5Clog(S_Z)_%7Bij%7D%7D_%7B2%5Clog%5Csigma%7D%20-%201%20%5Cright)%0A%5Ctag%7B8%7D"></span></p>
<ul>
<li><strong>의의:</strong> 이 식은 적분(Sampling)이 필요 없으므로 계산이 매우 빠르고, 역전파(Backpropagation)를 통한 미분이 용이하여 안정적인 학습을 가능하게 합니다.</li>
<li><strong>역할:</strong> 잠재 변수 <img src="https://latex.codecogs.com/png.latex?Z">가 평균 0, 분산 1인 분포에서 너무 멀어지지 않도록 강제하는 <strong>Regularizer</strong> 역할을 수행합니다.</li>
</ul>
</section>
<section id="reconstruction-term-likelihood" class="level4">
<h4 class="anchored" data-anchor-id="reconstruction-term-likelihood">Reconstruction Term (Likelihood)</h4>
<ul>
<li>두 번째 항은 모델이 잠재 변수 <img src="https://latex.codecogs.com/png.latex?Z">로부터 관측 데이터 <img src="https://latex.codecogs.com/png.latex?X">를 얼마나 잘 복원하는지를 나타내는 <strong>복원 오차(Reconstruction Error)</strong>입니다.</li>
<li>이 수식이 유도되는 과정은 <strong>Factored Gaussian 가정</strong>에 의해 다음과 같이 논리적으로 전개됩니다.</li>
</ul>
<section id="step-1-factored-gaussian-가정-행렬-to-스칼라-분해" class="level5">
<h5 class="anchored" data-anchor-id="step-1-factored-gaussian-가정-행렬-to-스칼라-분해"><strong>Step 1: Factored Gaussian 가정 (행렬 <img src="https://latex.codecogs.com/png.latex?%5Cto"> 스칼라 분해)</strong></h5>
<ul>
<li><p>우리가 구해야 할 것은 전체 데이터 행렬 <img src="https://latex.codecogs.com/png.latex?X">에 대한 우도 <img src="https://latex.codecogs.com/png.latex?P(X%7CZ)">입니다.</p></li>
<li><p>앞서 우리는 <img src="https://latex.codecogs.com/png.latex?p(X%7CZ)">가 <strong>Factored Gaussian</strong>을 따른다고 가정했습니다.</p></li>
<li><p>이는 <img src="https://latex.codecogs.com/png.latex?Z">가 주어졌을 때 <img src="https://latex.codecogs.com/png.latex?X">의 각 원소 <img src="https://latex.codecogs.com/png.latex?X_%7Bij%7D">가 서로 <strong>조건부 독립(Conditionally Independent)</strong>임을 의미합니다.</p></li>
<li><p>따라서 결합 확률(Joint Probability)은 개별 스칼라 확률들의 곱으로 분해됩니다.</p></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(X%7CZ)%20=%20%5Cprod_%7Bi=1%7D%5Em%20%5Cprod_%7Bj=1%7D%5Ed%20p(X_%7Bij%7D%20%7C%20Z)%0A"></p>
</section>
<section id="step-2-로그-변환과-덧셈으로의-전환-prod-to-sum" class="level5">
<h5 class="anchored" data-anchor-id="step-2-로그-변환과-덧셈으로의-전환-prod-to-sum"><strong>Step 2: 로그 변환과 덧셈으로의 전환 (<img src="https://latex.codecogs.com/png.latex?%5Cprod%20%5Cto%20%5Csum">)</strong></h5>
<ul>
<li>목적 함수는 <strong>로그 우도(Log-Likelihood)</strong>입니다. 양변에 로그를 취하면, 거대한 곱셈이 덧셈(Summation)으로 변환됩니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clog%20P(X%7CZ)%20=%20%5Csum_%7Bi=1%7D%5Em%20%5Csum_%7Bj=1%7D%5Ed%20%5Clog%20p(X_%7Bij%7D%20%7C%20Z)%0A"></p>
<ul>
<li>이제 문제는 복잡한 행렬 연산에서 <strong>“개별 요소(<img src="https://latex.codecogs.com/png.latex?X_%7Bij%7D">)의 스칼라 가우시안 로그 우도를 구해서 더하는 문제”</strong>로 단순화되었습니다.</li>
</ul>
</section>
<section id="step-3-스칼라-가우시안-로그-우도-계산" class="level5">
<h5 class="anchored" data-anchor-id="step-3-스칼라-가우시안-로그-우도-계산"><strong>Step 3: 스칼라 가우시안 로그 우도 계산</strong></h5>
<ul>
<li>단일 변수 <img src="https://latex.codecogs.com/png.latex?x">가 평균 <img src="https://latex.codecogs.com/png.latex?%5Cmu">, 표준편차 <img src="https://latex.codecogs.com/png.latex?%5Csigma">인 정규분포를 따를 때, 그 로그 확률밀도함수는 다음과 같습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Clog%20p(x%20%7C%20%5Cmu,%20%5Csigma)%20&amp;=%20%5Clog%20%5Cleft(%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%5Csigma%7D%20e%5E%7B-%5Cfrac%7B(x-%5Cmu)%5E2%7D%7B2%5Csigma%5E2%7D%7D%20%5Cright)%20%5C%5C%0A&amp;=%20%5Cunderbrace%7B-%5Clog(%5Csqrt%7B2%5Cpi%7D)%7D_%7B%5Ctext%7BConstant%20%7D%20c%7D%20-%20%5Clog%20%5Csigma%20-%20%5Cfrac%7B(x%20-%20%5Cmu)%5E2%7D%7B2%5Csigma%5E2%7D%0A%5Cend%7Baligned%7D%0A"></p>
<ul>
<li>이 식을 위 Step 2의 합산 기호 안에 대입합니다.</li>
</ul>
</section>
<section id="step-4-몬테카를로-근사-monte-carlo-approximation" class="level5">
<h5 class="anchored" data-anchor-id="step-4-몬테카를로-근사-monte-carlo-approximation"><strong>Step 4: 몬테카를로 근사 (Monte Carlo Approximation)</strong></h5>
<ul>
<li><p>마지막으로 기댓값 <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BE%7D_%7Bq(Z%7CX)%7D">를 계산하기 위해, 잠재 변수 <img src="https://latex.codecogs.com/png.latex?Z">를 <img src="https://latex.codecogs.com/png.latex?L">번 샘플링하여 그 평균으로 적분을 근사합니다.</p></li>
<li><p>이 모든 단계를 종합하면 식 (9)를 얻게 됩니다.</p></li>
</ul>
<p><span id="eq-(9)"><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BE%7D_%7Bq(Z%7CX)%7D%20%5CBig%5B%20%5Clog%20p(X%7CZ)%20%5CBig%5D%20%5Capprox%20%5Cfrac%7B1%7D%7BL%7D%20%5Csum_%7Bl=1%7D%5EL%20%5Csum_%7Bi=1%7D%5Em%20%5Csum_%7Bj=1%7D%5Ed%20%5Cleft(%20%5Cunderbrace%7B-%20%5Cfrac%7B(X_%7Bij%7D%20-%20(M_X%5E%7B(l)%7D)_%7Bij%7D)%5E2%7D%7B2(S_X%5E%7B(l)%7D)_%7Bij%7D%5E2%7D%7D_%7B%5Ctext%7BWeighted%20MSE%7D%7D%20%5Cunderbrace%7B-%20%5Clog(S_X%5E%7B(l)%7D)_%7Bij%7D%7D_%7B%5Ctext%7BUncertainty%20Penalty%7D%7D%20%5Cright)%20-%20c%0A%5Ctag%7B9%7D"></span></p>
<ul>
<li><strong>해석:</strong> 이 수식은 본질적으로 <strong>가중치(분산의 역수)가 적용된 MSE</strong>와, 모델이 불확실성(분산)을 무작정 키우는 것을 막는 <strong>Penalty(<img src="https://latex.codecogs.com/png.latex?%5Clog%20S_X">)</strong>의 합입니다.</li>
</ul>
</section>
</section>
</section>
<section id="a-note-on-latent-dimensions" class="level3">
<h3 class="anchored" data-anchor-id="a-note-on-latent-dimensions">A Note on Latent Dimensions</h3>
<ul>
<li>Linear SEM에서는 <img src="https://latex.codecogs.com/png.latex?Z">를 단순한 “Noise”로 보기에 <img src="https://latex.codecogs.com/png.latex?X">와 차원이 같아야 했습니다.</li>
<li>하지만 VAE 프레임워크에서 <img src="https://latex.codecogs.com/png.latex?Z">는 <strong>Latent Factor</strong>로 해석됩니다.</li>
<li>따라서 <img src="https://latex.codecogs.com/png.latex?Z">의 열(column) 차원을 <img src="https://latex.codecogs.com/png.latex?X">의 차원 <img src="https://latex.codecogs.com/png.latex?d">와 다르게 설정할 수 있습니다.</li>
<li>만약 데이터의 내재적 차원(Intrinsic Dimension)이 작다고 판단되면, <img src="https://latex.codecogs.com/png.latex?Z">의 차원을 줄여서 모델의 파라미터 수(<img src="https://latex.codecogs.com/png.latex?W%5E2,%20W%5E3">)를 줄이고 효율적인 표현을 학습할 수 있습니다.</li>
</ul>
<hr>
</section>
</section>
<section id="discrete-variables" class="level2">
<h2 class="anchored" data-anchor-id="discrete-variables">3.5. Discrete Variables</h2>
<ul>
<li><p>현실 세계의 인과관계 데이터는 키, 몸무게 같은 연속형(Continuous) 변수뿐만 아니라, 질병 유무, 성별, 등급과 같은 <strong>이산형(Discrete) 변수</strong>로 구성된 경우가 많습니다.</p></li>
<li><p>DAG-GNN의 가장 큰 장점 중 하나는 VAE(Variational Autoencoder) 프레임워크를 기반으로 하기 때문에, 데이터의 타입에 따라 <strong>우도(Likelihood) 분포만 적절히 교체</strong>해주면 자연스럽게 다양한 데이터 타입을 처리할 수 있다는 점입니다.</p></li>
<li><p>이번 포스트에서는 DAG-GNN이 이산형 변수를 어떻게 모델링하는지 그 수식적 변형 과정을 살펴보겠습니다.</p></li>
</ul>
<section id="data-representation-one-hot-encoding" class="level3">
<h3 class="anchored" data-anchor-id="data-representation-one-hot-encoding">Data Representation (One-Hot Encoding)</h3>
<ul>
<li><p>이산형 변수를 처리하기 위해 데이터 표현 방식부터 정의합니다.</p></li>
<li><p><strong>가정:</strong> 각 변수는 크기(Cardinality)가 <img src="https://latex.codecogs.com/png.latex?d">인 유한한 지지 집합(Finite support)을 가집니다.</p></li>
<li><p><strong>입력 <img src="https://latex.codecogs.com/png.latex?X">:</strong> <img src="https://latex.codecogs.com/png.latex?X">의 각 행(변수)은 <strong>One-Hot Vector</strong>로 표현됩니다.</p>
<ul>
<li>즉, “On” 위치(값이 1인 인덱스)가 해당 변수의 범주(Category)를 나타냅니다.</li>
<li>따라서 <img src="https://latex.codecogs.com/png.latex?X%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20d%7D"> 차원을 유지합니다.</li>
</ul></li>
</ul>
</section>
<section id="encoder-and-prior-unchanged" class="level3">
<h3 class="anchored" data-anchor-id="encoder-and-prior-unchanged">Encoder and Prior (Unchanged)</h3>
<ul>
<li>이산형 데이터를 다룸에도 불구하고 <strong>Encoder(Inference Model)와 Prior는 연속형 모델과 동일</strong>하게 유지됩니다.</li>
<li><ol type="1">
<li><strong>Prior <img src="https://latex.codecogs.com/png.latex?p(Z)">:</strong> 여전히 Standard Matrix Normal <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BMN%7D(0,%20I,%20I)">을 따릅니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Posterior <img src="https://latex.codecogs.com/png.latex?q(Z%7CX)">:</strong> Factored Gaussian 분포를 가정합니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Encoder 함수:</strong> 식 (6)의 구조를 그대로 사용합니다.</li>
</ol></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5BM_Z%20%7C%20%5Clog%20S_Z%5D%20=%20(I%20-%20A%5ET)%20%5Ctext%7BMLP%7D(X)%0A"></p>
<ul>
<li>이는 <strong>잠재 공간(Latent Space) <img src="https://latex.codecogs.com/png.latex?Z">는 여전히 연속적인 공간</strong>으로 남겨두고, 이 공간에서 그래프 구조 학습과 변분 추론을 수행하겠다는 의도입니다.</li>
</ul>
</section>
<section id="decoder-modification-categorical-likelihood" class="level3">
<h3 class="anchored" data-anchor-id="decoder-modification-categorical-likelihood">Decoder Modification (Categorical Likelihood)</h3>
<ul>
<li>변화가 필요한 부분은 잠재 변수 <img src="https://latex.codecogs.com/png.latex?Z">에서 다시 데이터 <img src="https://latex.codecogs.com/png.latex?X">를 복원하는 <strong>Decoder(Generative Model)</strong> 파트입니다.</li>
<li><img src="https://latex.codecogs.com/png.latex?X">가 이산형이므로, 더 이상 가우시안 분포를 가정할 수 없습니다.</li>
</ul>
<section id="distribution-assumption" class="level4">
<h4 class="anchored" data-anchor-id="distribution-assumption">Distribution Assumption</h4>
<ul>
<li><p>우리는 우도 <img src="https://latex.codecogs.com/png.latex?p(X%7CZ)">를 <strong>Factored Categorical Distribution</strong>으로 가정합니다.</p></li>
<li><p><strong>출력:</strong> 확률 행렬 <img src="https://latex.codecogs.com/png.latex?P_X%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20d%7D"></p></li>
<li><p>각 행(Row)은 해당 변수가 각 범주에 속할 확률을 나타내는 확률 벡터(Probability Vector)가 됩니다.</p></li>
</ul>
</section>
<section id="architecture-change" class="level4">
<h4 class="anchored" data-anchor-id="architecture-change">Architecture Change</h4>
<ul>
<li><p>이를 구현하기 위해, Decoder의 마지막 변환 함수 <img src="https://latex.codecogs.com/png.latex?f_2">를 <strong>Softmax</strong> 함수로 변경합니다.</p></li>
<li><p>기존 (Continuous): <img src="https://latex.codecogs.com/png.latex?f_2%20=%20%5Ctext%7BMLP%7D"> (Identity mapping for output range)</p></li>
<li><p><strong>변경 (Discrete):</strong> <img src="https://latex.codecogs.com/png.latex?f_2%20=%20%5Ctext%7Bsoftmax%7D(%5Ctext%7BMLP%7D)"></p></li>
<li><p>수식으로 표현하면 다음과 같습니다:</p></li>
</ul>
<p><span id="eq-(10)"><img src="https://latex.codecogs.com/png.latex?%0AP_X%20=%20%5Ctext%7Bsoftmax%7D%20%5Cleft(%20%5Ctext%7BMLP%7D%20%5Cbig(%20(I%20-%20A%5ET)%5E%7B-1%7D%20Z,%20W%5E3,%20W%5E4%20%5Cbig)%20%5Cright)%0A%5Ctag%7B10%7D"></span></p>
<ul>
<li>여기서 <code>softmax</code>는 각 행(Row-wise)에 대해 적용되어, 각 변수의 범주별 확률 합이 1이 되도록 만듭니다.</li>
</ul>
</section>
</section>
<section id="loss-function-modification-cross-entropy" class="level3">
<h3 class="anchored" data-anchor-id="loss-function-modification-cross-entropy">Loss Function Modification (Cross-Entropy)</h3>
<ul>
<li><p>목적 함수인 ELBO(Evidence Lower Bound)의 두 항 중, KL Divergence 항은 <img src="https://latex.codecogs.com/png.latex?q(Z%7CX)">와 <img src="https://latex.codecogs.com/png.latex?p(Z)">가 변하지 않았으므로 식 (8) 그대로 유지됩니다.</p></li>
<li><p>하지만 <strong>Reconstruction Term (Likelihood)</strong>은 가우시안 로그 우도(MSE 형태)에서 <strong>Categorical 로그 우도</strong>로 변경되어야 합니다. 이는 머신러닝에서 흔히 쓰이는 <strong>Cross-Entropy Loss</strong>와 형태가 같습니다.</p></li>
</ul>
<section id="derivation-1" class="level4">
<h4 class="anchored" data-anchor-id="derivation-1">Derivation</h4>
<ul>
<li>Categorical 분포의 로그 우도는 관측된 클래스(<img src="https://latex.codecogs.com/png.latex?X_%7Bij%7D=1">)의 예측 확률(<img src="https://latex.codecogs.com/png.latex?P_%7BX_%7Bij%7D%7D">)에 로그를 취한 값입니다. 이를 몬테카를로 샘플링을 적용하여 정리하면 식 (11)을 얻습니다. <span id="eq-(11)"><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BE%7D_%7Bq(Z%7CX)%7D%20%5CBig%5B%20%5Clog%20p(X%7CZ)%20%5CBig%5D%20%5Capprox%20%5Cfrac%7B1%7D%7BL%7D%20%5Csum_%7Bl=1%7D%5EL%20%5Csum_%7Bi=1%7D%5Em%20%5Csum_%7Bj=1%7D%5Ed%20X_%7Bij%7D%20%5Clog%20(P_X%5E%7B(l)%7D)_%7Bij%7D%20%5Cquad%20%5Ccdots%20(11)%0A%5Ctag%7B11%7D"></span></li>
<li><img src="https://latex.codecogs.com/png.latex?L">: 몬테카를로 샘플 개수</li>
<li><img src="https://latex.codecogs.com/png.latex?X_%7Bij%7D">: 실제 데이터의 One-hot 값 (0 또는 1)</li>
<li><img src="https://latex.codecogs.com/png.latex?(P_X%5E%7B(l)%7D)_%7Bij%7D">: Decoder가 예측한 <img src="https://latex.codecogs.com/png.latex?l">번째 샘플의 확률 값</li>
<li>이 식은 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?P_X"> 사이의 Cross-Entropy를 계산하여, 모델이 실제 데이터의 범주를 정확하게 예측하도록 학습시킵니다.</li>
</ul>
</section>
</section>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<ul>
<li>DAG-GNN은 데이터 타입에 따라 모델의 핵심 구조(Encoder, Graph Operations, Latent Space)를 변경할 필요 없이, <strong>Decoder의 출력층(Softmax)과 손실 함수(Cross-Entropy)</strong>만 유연하게 교체하여 이산형 변수를 처리합니다.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">구분</th>
<th style="text-align: left;">연속형 (Continuous)</th>
<th style="text-align: left;">이산형 (Discrete)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Input <img src="https://latex.codecogs.com/png.latex?X"></strong></td>
<td style="text-align: left;">Real Values (<img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20d%7D">)</td>
<td style="text-align: left;">One-hot Vectors (<img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20d%7D">)</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Prior / Encoder</strong></td>
<td style="text-align: left;">Gaussian / MLP</td>
<td style="text-align: left;">Gaussian / MLP (동일)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Likelihood</strong></td>
<td style="text-align: left;">Gaussian <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BN%7D(M_X,%20S_X)"></td>
<td style="text-align: left;">Categorical <img src="https://latex.codecogs.com/png.latex?P_X"></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Output Function (<img src="https://latex.codecogs.com/png.latex?f_2">)</strong></td>
<td style="text-align: left;">Identity / MLP</td>
<td style="text-align: left;">Softmax</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Reconstruction Loss</strong></td>
<td style="text-align: left;">Mean Squared Error (approx)</td>
<td style="text-align: left;">Cross Entropy</td>
</tr>
</tbody>
</table>
<ul>
<li>이러한 설계는 다양한 형태의 변수가 섞여 있는(Mixed type) 실제 데이터셋에도 쉽게 확장 적용할 수 있는 가능성을 보여줍니다.</li>
</ul>
<hr>
</section>
</section>
<section id="connection-to-linear-sem" class="level2">
<h2 class="anchored" data-anchor-id="connection-to-linear-sem">3.6. Connection to Linear SEM</h2>
<ul>
<li><p>지금까지 우리는 Linear SEM에서 출발하여 비선형성을 더하고(Non-linearity), VAE 프레임워크를 입혀(Probabilistic) DAG-GNN을 완성했습니다.</p></li>
<li><p>이제 저자들은 <strong>“역방향 사고(Reverse Thought Flow)”</strong>를 통해, DAG-GNN의 껍질을 하나씩 벗겨내면 결국 기존의 <strong>Linear SEM (Zheng et al., 2018, NOTEARS)</strong>과 수학적으로 완전히 일치함을 보입니다.</p></li>
<li><p>이 과정은 DAG-GNN이 근본 없는 블랙박스 모델이 아니라, 기존의 최적화 기반 구조 학습 이론을 <strong>확장(Extension)</strong>한 것임을 증명하는 중요한 이론적 토대가 됩니다.</p></li>
</ul>
<section id="step-1-from-vae-to-plain-autoencoder" class="level3">
<h3 class="anchored" data-anchor-id="step-1-from-vae-to-plain-autoencoder">Step 1: From VAE to Plain Autoencoder</h3>
<ul>
<li>가장 먼저, 확률적(Probabilistic) 모델인 VAE에서 변분(Variational) 요소를 제거하여 결정론적(Deterministic)인 <strong>Plain Autoencoder</strong>로 축소해 봅시다.</li>
</ul>
<section id="deterministic-setup" class="level4">
<h4 class="anchored" data-anchor-id="deterministic-setup">Deterministic Setup</h4>
<ul>
<li><p>확률 분포 <img src="https://latex.codecogs.com/png.latex?q(Z%7CX)"> 대신, 입력 <img src="https://latex.codecogs.com/png.latex?X">가 주어졌을 때 잠재 변수 <img src="https://latex.codecogs.com/png.latex?Z">가 고정된 값으로 결정된다고 가정합니다. 또한 비선형 함수 <img src="https://latex.codecogs.com/png.latex?f_1%20%5Cdots%20f_4">는 그대로 유지합니다.</p></li>
<li><p><strong>Encoder (식 5 기반):</strong> <img src="https://latex.codecogs.com/png.latex?Z%20=%20f_4((I%20-%20A%5ET)%20f_3(X))"></p></li>
<li><p><strong>Decoder (식 3 기반):</strong> <img src="https://latex.codecogs.com/png.latex?%5Chat%7BX%7D%20=%20f_2((I%20-%20A%5ET)%5E%7B-1%7D%20f_1(Z))"></p>
<ul>
<li>여기서 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BX%7D">는 Decoder에 의해 복원된 값을 의미합니다.</li>
</ul></li>
</ul>
</section>
<section id="correspondence-of-loss-functions" class="level4">
<h4 class="anchored" data-anchor-id="correspondence-of-loss-functions">Correspondence of Loss Functions</h4>
<ul>
<li>일반적인 Autoencoder가 최소화하려는 손실 함수(Sample Loss)는 <strong>복원 오차(Reconstruction Error)</strong>와 <strong>잠재 변수 규제(Regularization)</strong>의 합으로 표현됩니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D_%7B%5Ctext%7BAE%7D%7D%20=%20%5Cunderbrace%7B%5Cfrac%7B1%7D%7B2%7D%20%5Csum_%7Bi=1%7D%5Em%20%5Csum_%7Bj=1%7D%5Ed%20(X_%7Bij%7D%20-%20%5Chat%7BX%7D_%7Bij%7D)%5E2%7D_%7B%5Ctext%7BReconstruction%7D%7D%20+%20%5Cunderbrace%7B%5Cfrac%7B1%7D%7B2%7D%20%5Csum_%7Bi=1%7D%5Em%20%5Csum_%7Bj=1%7D%5Ed%20Z_%7Bij%7D%5E2%7D_%7B%5Ctext%7BRegularization%7D%7D%0A"></p>
<ul>
<li><p>이 결정론적 손실 함수는 VAE의 <strong>ELBO</strong>와 정확히 대응됩니다:</p></li>
<li><ol type="1">
<li><strong>Reconstruction Term:</strong></li>
</ol>
<ul>
<li>ELBO의 복원 정확도 항(식 9)에서, <img src="https://latex.codecogs.com/png.latex?S_X"> (Decoder 분산)를 1로 고정하고 <img src="https://latex.codecogs.com/png.latex?M_X"> (Decoder 평균)를 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BX%7D">로 두면, 로그 우도 최대화는 곧 <strong>MSE(Mean Squared Error) 최소화</strong>와 같아집니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Regularization Term:</strong></li>
</ol>
<ul>
<li>ELBO의 KL Divergence 항(식 8)에서, <img src="https://latex.codecogs.com/png.latex?S_Z"> (Encoder 분산)를 1로 고정하고 <img src="https://latex.codecogs.com/png.latex?M_Z"> (Encoder 평균)를 <img src="https://latex.codecogs.com/png.latex?Z">로 두면, KL 항은 <img src="https://latex.codecogs.com/png.latex?%5Csum%20Z_%7Bij%7D%5E2">에 비례하게 됩니다. 이는 <strong>L2 Regularization</strong>과 같습니다.</li>
</ul></li>
</ul>
</section>
</section>
<section id="step-2-from-nonlinear-to-linear-the-core-derivation" class="level3">
<h3 class="anchored" data-anchor-id="step-2-from-nonlinear-to-linear-the-core-derivation">Step 2: From Nonlinear to Linear (The Core Derivation)</h3>
<ul>
<li>이제 두 번째 단계로, 모델의 <strong>비선형성(Non-linearity)</strong>을 제거해 봅시다. 즉, 모든 활성화 함수와 MLP를 걷어냅니다.</li>
</ul>
<section id="linear-assumptions" class="level4">
<h4 class="anchored" data-anchor-id="linear-assumptions">Linear Assumptions</h4>
<ul>
<li><p>모든 매핑 함수 <img src="https://latex.codecogs.com/png.latex?f_1,%20f_2,%20f_3,%20f_4">를 <strong>항등 함수(Identity Mapping)</strong>로 가정합니다.</p></li>
<li><p>그렇다면 Encoder와 Decoder는 다음과 같이 단순한 선형 변환이 됩니다.</p></li>
<li><p><strong>Linear Encoder:</strong> <img src="https://latex.codecogs.com/png.latex?Z%20=%20(I%20-%20A%5ET)%20X"></p></li>
<li><p><strong>Linear Decoder:</strong> <img src="https://latex.codecogs.com/png.latex?%5Chat%7BX%7D%20=%20(I%20-%20A%5ET)%5E%7B-1%7D%20Z"></p></li>
</ul>
</section>
<section id="perfect-reconstruction" class="level4">
<h4 class="anchored" data-anchor-id="perfect-reconstruction">Perfect Reconstruction</h4>
<p>위 두 식을 결합하기 위해 Decoder 식의 <img src="https://latex.codecogs.com/png.latex?Z"> 자리에 Encoder 식을 대입합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Chat%7BX%7D%20&amp;=%20(I%20-%20A%5ET)%5E%7B-1%7D%20%5Cleft(%20(I%20-%20A%5ET)%20X%20%5Cright)%20%5C%5C%0A&amp;=%20%5Cunderbrace%7B(I%20-%20A%5ET)%5E%7B-1%7D%20(I%20-%20A%5ET)%7D_%7BI%7D%20X%20%5C%5C%0A&amp;=%20X%0A%5Cend%7Baligned%7D%0A"></p>
<ul>
<li>즉, 선형 모델 하에서는 입력 <img src="https://latex.codecogs.com/png.latex?X">가 손실 없이 완벽하게 복원(<img src="https://latex.codecogs.com/png.latex?%5Chat%7BX%7D%20=%20X">)됩니다.</li>
<li>따라서 손실 함수의 첫 번째 항인 <strong>Reconstruction Error는 0</strong>이 되어 사라집니다.</li>
</ul>
</section>
</section>
<section id="deriving-the-notears-loss" class="level3">
<h3 class="anchored" data-anchor-id="deriving-the-notears-loss">Deriving the NOTEARS Loss</h3>
<ul>
<li>이제 남은 것은 두 번째 항인 <strong>Regularization Term</strong> 뿐입니다.</li>
<li>여기에 Linear Encoder 식 <img src="https://latex.codecogs.com/png.latex?Z%20=%20(I%20-%20A%5ET)X">를 대입하여 정리해 봅시다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Cmathcal%7BL%7D_%7B%5Ctext%7BLinear%7D%7D%20&amp;=%20%5Cfrac%7B1%7D%7B2%7D%20%5Csum_%7Bi=1%7D%5Em%20%5Csum_%7Bj=1%7D%5Ed%20Z_%7Bij%7D%5E2%20%5C%5C%0A&amp;=%20%5Cfrac%7B1%7D%7B2%7D%20%5C%7C%20Z%20%5C%7C_F%5E2%20%5Cquad%20(%5Ctext%7BFrobenius%20Norm%7D)%20%5C%5C%0A&amp;=%20%5Cfrac%7B1%7D%7B2%7D%20%5C%7C%20(I%20-%20A%5ET)%20X%20%5C%7C_F%5E2%20%5Cquad%20%5Ccdots%20(12)%0A%5Cend%7Baligned%7D%0A"></p>
<section id="result-and-interpretation" class="level4">
<h4 class="anchored" data-anchor-id="result-and-interpretation">Result and Interpretation</h4>
<ul>
<li>유도된 최종 식 (12) <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B1%7D%7B2%7D%20%5C%7C%20(I%20-%20A%5ET)%20X%20%5C%7C_F%5E2">는 정확히 <strong>Zheng et al.&nbsp;(2018)</strong>이 제안한 <strong>NOTEARS 알고리즘의 손실 함수(Least-squares loss)</strong>와 일치합니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>의미 (Insight):</strong> * Linear SEM(NOTEARS)은 모델이 완벽하게 복원된다고 가정하고, 노이즈 <img src="https://latex.codecogs.com/png.latex?Z">의 크기(L2 norm)를 최소화하는 문제로 해석될 수 있습니다. * <strong>DAG-GNN</strong>은 이를 확장하여, <strong>“완벽한 복원이 불가능한(비선형/노이즈 존재) 상황”</strong>까지 고려하기 위해 Reconstruction Loss 항을 추가하고, 비선형 변환을 도입한 일반화된 모델입니다.</p>
</blockquote>
</section>
</section>
<section id="summary-1" class="level3">
<h3 class="anchored" data-anchor-id="summary-1">Summary</h3>
<ul>
<li><ol type="1">
<li><strong>DAG-GNN (VAE + Nonlinear)</strong></li>
</ol>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cdownarrow"> (Variational 제거: <img src="https://latex.codecogs.com/png.latex?S_Z,%20S_X%20%5Cto%201">)</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Deterministic Autoencoder (MSE + L2 Reg)</strong></li>
</ol>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cdownarrow"> (Nonlinearity 제거: <img src="https://latex.codecogs.com/png.latex?f%20%5Cto%20Identity">)</li>
</ul></li>
<li><ol start="3" type="1">
<li><strong>Linear Model (Perfect Reconstruction, Reg only)</strong></li>
</ol>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cdownarrow"> (<img src="https://latex.codecogs.com/png.latex?Z%20=%20(I-A%5ET)X"> 대입)</li>
</ul></li>
<li><ol start="4" type="1">
<li><strong>Linear SEM Loss (Zheng et al., 2018)</strong></li>
</ol></li>
<li>이로써 DAG-GNN은 Linear SEM의 탄탄한 이론적 기반 위에 서 있으면서도, 딥러닝의 표현력을 통해 더 복잡한 데이터 분포를 학습할 수 있는 모델임이 증명되었습니다.</li>
</ul>
<hr>
</section>
</section>
<section id="acyclicity-constraint" class="level2">
<h2 class="anchored" data-anchor-id="acyclicity-constraint">3.7. Acyclicity Constraint</h2>
<ul>
<li><p>앞선 섹션들에서 우리는 VAE 기반의 손실 함수(ELBO)와 선형/비선형 모델링을 정의했습니다.</p></li>
<li><p>하지만 여기에는 치명적인 허점이 하나 있습니다.</p></li>
<li><p>ELBO를 최대화하든, Least-squares loss를 최소화하든, 학습된 인접 행렬 <img src="https://latex.codecogs.com/png.latex?A">가 <strong>DAG(비순환 그래프)</strong>라는 보장이 없다는 점입니다.</p></li>
<li><p>그래프 <img src="https://latex.codecogs.com/png.latex?G">가 인과관계 모델이 되기 위해서는 반드시 사이클(Cycle)이 없어야 합니다.</p></li>
<li><p>이번 포스트에서는 이 조합적(Combinatorial) 제약 조건을 어떻게 연속적인(Continuous) 수식으로 변환하여 최적화 과정에 통합했는지 살펴봅니다.</p></li>
</ul>
<section id="motivation-trace-and-cycles" class="level3">
<h3 class="anchored" data-anchor-id="motivation-trace-and-cycles">Motivation: Trace and Cycles</h3>
<ul>
<li>그래프 이론에서 인접 행렬의 거듭제곱은 경로(Path)와 깊은 연관이 있습니다.</li>
</ul>
<section id="path-counting-logic" class="level4">
<h4 class="anchored" data-anchor-id="path-counting-logic">Path Counting Logic</h4>
<ul>
<li><p>가중치가 있는 인접 행렬 <img src="https://latex.codecogs.com/png.latex?A">에 대해, 요소별 제곱(Element-wise square)을 수행하여 비음수(Non-negative) 행렬 <img src="https://latex.codecogs.com/png.latex?B">를 정의해 봅시다 (<img src="https://latex.codecogs.com/png.latex?B%20=%20A%20%5Ccirc%20A">).</p></li>
<li><p>행렬 <img src="https://latex.codecogs.com/png.latex?B">의 <img src="https://latex.codecogs.com/png.latex?(i,%20j)"> 요소가 양수라면, 노드 <img src="https://latex.codecogs.com/png.latex?i">에서 <img src="https://latex.codecogs.com/png.latex?j">로 가는 엣지가 존재함을 의미합니다.</p></li>
<li><p>행렬의 곱셈 성질에 따라, <img src="https://latex.codecogs.com/png.latex?B%5Ek">의 <img src="https://latex.codecogs.com/png.latex?(i,%20j)"> 요소가 양수라는 것은 <strong>노드 <img src="https://latex.codecogs.com/png.latex?i">에서 <img src="https://latex.codecogs.com/png.latex?j">로 가는 길이가 <img src="https://latex.codecogs.com/png.latex?k">인 경로가 존재함</strong>을 의미합니다.</p></li>
</ul>
</section>
<section id="detecting-cycles" class="level4">
<h4 class="anchored" data-anchor-id="detecting-cycles">Detecting Cycles</h4>
<ul>
<li><p>사이클이란 무엇일까요? 바로 <strong>자기 자신으로 돌아오는 경로(<img src="https://latex.codecogs.com/png.latex?i%20%5Cto%20%5Cdots%20%5Cto%20i">)</strong>입니다.</p></li>
<li><p>따라서, 어떤 정수 <img src="https://latex.codecogs.com/png.latex?k">에 대해 <img src="https://latex.codecogs.com/png.latex?B%5Ek">의 대각 성분(Diagonal element) <img src="https://latex.codecogs.com/png.latex?(B%5Ek)_%7Bii%7D">가 양수라면, 노드 <img src="https://latex.codecogs.com/png.latex?i">를 포함하는 길이 <img src="https://latex.codecogs.com/png.latex?k">의 사이클이 존재한다는 뜻입니다.</p></li>
<li><p>이 논리를 확장하면 다음과 같은 결론에 도달합니다.</p></li>
</ul>
<blockquote class="blockquote">
<p><strong>“모든 <img src="https://latex.codecogs.com/png.latex?k%20%3E%200">에 대해 <img src="https://latex.codecogs.com/png.latex?B%5Ek">의 대각 성분이 모두 0이라면(즉, Trace가 0이라면), 그 그래프는 DAG이다.”</strong></p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/images/adjacency_power_cycles.png" class="img-fluid figure-img"></p>
<figcaption>Figure: 인접 행렬의 거듭제곱과 사이클 검출의 원리. (A) 사이클이 있는 그래프 예시. (B) 인접 행렬 <img src="https://latex.codecogs.com/png.latex?A">와 <img src="https://latex.codecogs.com/png.latex?A%5E2,%20A%5E3"> 계산 결과. 대각 성분에 0이 아닌 값이 등장하는 순간 사이클이 존재함을 수학적으로 알 수 있다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="the-matrix-exponential-previous-work" class="level3">
<h3 class="anchored" data-anchor-id="the-matrix-exponential-previous-work">The Matrix Exponential (Previous Work)</h3>
<ul>
<li><strong>Zheng et al.&nbsp;(2018)</strong>의 NOTEARS 알고리즘은 이 원리를 이용하여 <strong>행렬 지수(Matrix Exponential)</strong> 형태의 제약 조건을 제안했습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0Ah(A)%20=%20%5Ctext%7Btr%7D(e%5E%7BA%20%5Ccirc%20A%7D)%20-%20m%20=%200%0A"></p>
<ul>
<li>이 수식은 테일러 급수 전개를 통해 이해할 수 있습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0Ae%5EB%20=%20I%20+%20B%20+%20%5Cfrac%7BB%5E2%7D%7B2!%7D%20+%20%5Cfrac%7BB%5E3%7D%7B3!%7D%20+%20%5Cdots%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?B">의 모든 거듭제곱(<img src="https://latex.codecogs.com/png.latex?B%5Ek">)의 합을 포함하므로, 어떤 길이의 사이클이라도 존재한다면 <img src="https://latex.codecogs.com/png.latex?e%5EB">의 대각 성분 합(Trace)은 <img src="https://latex.codecogs.com/png.latex?m"> (항등 행렬 <img src="https://latex.codecogs.com/png.latex?I">의 Trace)보다 커지게 됩니다.</li>
<li>수학적으로 매우 우아(Elegant)하지만, 실제 딥러닝 프레임워크에서 구현할 때 두 가지 문제가 있습니다.
<ol type="1">
<li><strong>자동 미분 지원 미비:</strong> 모든 플랫폼이 행렬 지수의 미분을 효율적으로 지원하지 않습니다.</li>
<li><strong>수치적 불안정성:</strong> <img src="https://latex.codecogs.com/png.latex?e%5EB">는 값이 매우 빠르게 커지므로, 고유값(Eigenvalue)이 클 경우 오버플로우나 수치 오류가 발생하기 쉽습니다.</li>
</ol></li>
</ul>
</section>
<section id="proposed-solution-polynomial-constraint" class="level3">
<h3 class="anchored" data-anchor-id="proposed-solution-polynomial-constraint">Proposed Solution: Polynomial Constraint</h3>
<ul>
<li>저자들은 위 문제를 해결하기 위해, 행렬 지수 대신 <strong>다항식(Polynomial)</strong> 형태의 새로운 제약 조건을 제안합니다.</li>
</ul>
<section id="theorem-1-polynomial-acyclicity" class="level4">
<h4 class="anchored" data-anchor-id="theorem-1-polynomial-acyclicity">Theorem 1 (Polynomial Acyclicity)</h4>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20m%7D">를 유향 그래프의 가중치 인접 행렬이라고 합시다.</li>
<li>임의의 양수 <img src="https://latex.codecogs.com/png.latex?%5Calpha%20%3E%200">에 대하여, 다음 조건이 성립하면 그래프는 Acyclic입니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Btr%7D%5Cleft%5B%20(I%20+%20%5Calpha%20A%20%5Ccirc%20A)%5Em%20%5Cright%5D%20-%20m%20=%200%20%5Cquad%20%5Ccdots%20(13)%0A"></p>
</section>
<section id="derivation-proof-logic" class="level4">
<h4 class="anchored" data-anchor-id="derivation-proof-logic">Derivation &amp; Proof Logic</h4>
<ul>
<li><p>이 식이 성립하는 이유는 다음과 같습니다.</p></li>
<li><ol type="1">
<li><strong>최장 경로의 길이:</strong> 노드가 <img src="https://latex.codecogs.com/png.latex?m">개인 그래프에서 사이클이 없다면(DAG라면), 존재할 수 있는 경로의 최대 길이는 <img src="https://latex.codecogs.com/png.latex?m-1">입니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>이항 전개 (Binomial Expansion):</strong> <img src="https://latex.codecogs.com/png.latex?(I%20+%20%5Calpha%20B)%5Em">을 전개하면 다음과 같은 형태가 됩니다. <img src="https://latex.codecogs.com/png.latex?I%20+%20%5Cbinom%7Bm%7D%7B1%7D%5Calpha%20B%20+%20%5Cbinom%7Bm%7D%7B2%7D%5Calpha%5E2%20B%5E2%20+%20%5Cdots%20+%20%5Calpha%5Em%20B%5Em"></li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>포괄성:</strong> 이 식은 <img src="https://latex.codecogs.com/png.latex?I">부터 <img src="https://latex.codecogs.com/png.latex?B%5Em">까지의 모든 항을 양수 계수로 포함합니다.</li>
</ol></li>
<li><ol start="4" type="1">
<li><strong>결론:</strong> 만약 그래프에 사이클이 있다면, <img src="https://latex.codecogs.com/png.latex?m"> 이하의 어떤 길이 <img src="https://latex.codecogs.com/png.latex?k">에 대해 <img src="https://latex.codecogs.com/png.latex?B%5Ek">의 Trace가 양수가 될 것입니다. 위 식은 <img src="https://latex.codecogs.com/png.latex?B%5E1">부터 <img src="https://latex.codecogs.com/png.latex?B%5Em">까지 모든 거듭제곱의 합을 검사하므로, 사이클이 하나라도 있다면 전체 Trace는 <img src="https://latex.codecogs.com/png.latex?m"> (<img src="https://latex.codecogs.com/png.latex?I">의 Trace)보다 반드시 커지게 됩니다.</li>
</ol></li>
<li><p>따라서 식 (13)을 0으로 만드는 제약 조건은 그래프가 DAG임을 보장합니다.</p></li>
</ul>
</section>
</section>
<section id="stability-analysis-why-polynomial" class="level3">
<h3 class="anchored" data-anchor-id="stability-analysis-why-polynomial">Stability Analysis (Why Polynomial?)</h3>
<ul>
<li>왜 <img src="https://latex.codecogs.com/png.latex?e%5EB"> 대신 <img src="https://latex.codecogs.com/png.latex?(I%20+%20%5Calpha%20B)%5Em">을 써야 할까요? 저자들은 <strong>Theorem 2</strong>를 통해 수치적 안정성을 증명합니다.</li>
</ul>
<section id="theorem-2-comparison" class="level4">
<h4 class="anchored" data-anchor-id="theorem-2-comparison">Theorem 2 (Comparison)</h4>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Calpha%20=%20c/m%20%3E%200"> (단, <img src="https://latex.codecogs.com/png.latex?c">는 상수)라고 설정하면, 임의의 복소수 <img src="https://latex.codecogs.com/png.latex?%5Clambda">에 대해 다음 부등식이 성립합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A(1%20+%20%5Calpha%20%7C%5Clambda%7C)%5Em%20%5Cle%20e%5E%7Bc%7C%5Clambda%7C%7D%0A"></p>
</section>
<section id="interpretation-2" class="level4">
<h4 class="anchored" data-anchor-id="interpretation-2">Interpretation</h4>
<ul>
<li><strong>좌변:</strong> 제안된 다항식 제약 조건의 성장 속도와 관련됨.</li>
<li><strong>우변:</strong> 기존 행렬 지수 제약 조건의 성장 속도와 관련됨.</li>
<li>이 부등식은 <strong>다항식 제약 조건이 지수 함수보다 훨씬 완만하게 증가함</strong>을 보여줍니다.</li>
<li>즉, <img src="https://latex.codecogs.com/png.latex?B">의 고유값(Eigenvalue) 크기가 클 때, 다항식 기반 제약 조건이 수치적 폭발(Numerical difficulty)을 겪을 위험이 훨씬 적습니다 (“less severe”).</li>
</ul>
</section>
<section id="practical-implementation" class="level4">
<h4 class="anchored" data-anchor-id="practical-implementation">Practical Implementation</h4>
<ul>
<li>실제 구현에서 <img src="https://latex.codecogs.com/png.latex?%5Calpha">는 하이퍼파라미터로 취급됩니다.</li>
<li>이론적으로 <img src="https://latex.codecogs.com/png.latex?%5Calpha">는 <img src="https://latex.codecogs.com/png.latex?B">의 가장 큰 고유값(Spectral radius)에 의존합니다.</li>
<li>Perron-Frobenius 정리에 따라, 비음수 행렬 <img src="https://latex.codecogs.com/png.latex?B">의 Spectral radius는 최대 행 합(Maximum row sum)에 의해 제한(Bounded)되므로, 이를 참고하여 <img src="https://latex.codecogs.com/png.latex?%5Calpha">를 설정할 수 있습니다.</li>
</ul>
</section>
</section>
<section id="summary-2" class="level3">
<h3 class="anchored" data-anchor-id="summary-2">Summary</h3>
<ul>
<li><p>DAG-GNN은 구조 학습의 핵심인 Acyclicity Constraint를 현대적인 딥러닝 환경에 맞게 재설계했습니다.</p></li>
<li><ol type="1">
<li><strong>기존:</strong> <img src="https://latex.codecogs.com/png.latex?h(A)%20=%20%5Ctext%7Btr%7D(e%5E%7BA%20%5Ccirc%20A%7D)%20-%20m%20=%200"> (NOTEARS)</li>
</ol>
<ul>
<li>우아하지만 구현이 어렵고 불안정할 수 있음.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>제안:</strong> <img src="https://latex.codecogs.com/png.latex?h(A)%20=%20%5Ctext%7Btr%7D((I%20+%20%5Calpha%20A%20%5Ccirc%20A)%5Em)%20-%20m%20=%200"> (DAG-GNN)</li>
</ol>
<ul>
<li><strong>Finite Power:</strong> <img src="https://latex.codecogs.com/png.latex?m">차수까지만 검사해도 충분함 (DAG의 성질).</li>
<li><strong>Stability:</strong> 지수 함수보다 완만하게 증가하여 수치적으로 안정적.</li>
<li><strong>Convenience:</strong> 일반적인 행렬 곱셈만으로 구현 가능하여 모든 딥러닝 프레임워크와 호환됨.</li>
</ul></li>
<li><p>이로써 DAG-GNN은 VAE를 통한 확률적 모델링, GNN을 통한 비선형성 확보, 그리고 Polynomial Constraint를 통한 구조적 보장까지 갖춘 완전한 프레임워크가 되었습니다.</p></li>
</ul>
<hr>
</section>
</section>
<section id="training" class="level2">
<h2 class="anchored" data-anchor-id="training">3.8. Training</h2>
<ul>
<li>지금까지 우리는 DAG-GNN의 두 가지 핵심 기둥을 세웠습니다.
<ul>
<li><ol type="1">
<li><strong>Objective:</strong> 데이터를 잘 설명하기 위한 VAE의 손실 함수 (Negative ELBO).</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Constraint:</strong> 그래프가 DAG임을 보장하기 위한 다항식 제약 조건 (<img src="https://latex.codecogs.com/png.latex?h(A)%20=%200">).</li>
</ol></li>
</ul></li>
<li>이제 이 두 가지를 하나로 묶어 실제 학습을 수행하는 <strong>최적화 전략(Optimization Strategy)</strong>을 다룰 차례입니다.</li>
<li>이 문제는 전형적인 <strong>비선형 등식 제약 최적화(Nonlinear Equality-Constrained Optimization)</strong> 문제입니다.</li>
</ul>
<section id="problem-formulation" class="level3">
<h3 class="anchored" data-anchor-id="problem-formulation">Problem Formulation</h3>
<ul>
<li>전체 학습 문제는 다음과 같은 최적화 문제로 정식화됩니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Cmin_%7BA,%20%5Ctheta%7D%20%5Cquad%20&amp;%20f(A,%20%5Ctheta)%20%5Cequiv%20-L_%7B%5Ctext%7BELBO%7D%7D%20%5C%5C%0A%5Ctext%7Bs.t.%7D%20%5Cquad%20&amp;%20h(A)%20%5Cequiv%20%5Ctext%7Btr%7D%5B(I%20+%20%5Calpha%20A%20%5Ccirc%20A)%5Em%5D%20-%20m%20=%200%0A%5Cend%7Baligned%7D%0A"></p>
<ul>
<li><strong>Objective <img src="https://latex.codecogs.com/png.latex?f(A,%20%5Ctheta)">:</strong> ELBO(Evidence Lower Bound)를 최대화하는 것은 Negative ELBO를 최소화하는 것과 같습니다.</li>
<li><strong>Constraint <img src="https://latex.codecogs.com/png.latex?h(A)">:</strong> 앞서 유도한 다항식 제약 조건으로, 이 값이 0이 되어야만 <img src="https://latex.codecogs.com/png.latex?A">가 DAG임이 보장됩니다.</li>
<li><strong>Unknowns:</strong>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A">: 가중치 인접 행렬 (Weighted Adjacency Matrix)</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctheta">: VAE를 구성하는 신경망의 파라미터들 (<img src="https://latex.codecogs.com/png.latex?%5C%7BW%5E1,%20W%5E2,%20W%5E3,%20W%5E4%5C%7D">).</li>
</ul></li>
</ul>
</section>
<section id="the-augmented-lagrangian-method" class="level3">
<h3 class="anchored" data-anchor-id="the-augmented-lagrangian-method">The Augmented Lagrangian Method</h3>
<ul>
<li><p>이러한 제약 조건이 있는 최적화 문제를 풀기 위해, 저자들은 <strong>증강 라그랑주(Augmented Lagrangian)</strong> 방법을 사용합니다.</p></li>
<li><p>이는 표준적인 라그랑주 승수법에 페널티 항(Penalty term)을 추가하여 수치적 안정성과 수렴성을 높인 기법입니다 (Bertsekas, 1999).</p></li>
<li><p>정의된 증강 라그랑주 함수 <img src="https://latex.codecogs.com/png.latex?L_c">는 다음과 같습니다.</p></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AL_c(A,%20%5Ctheta,%20%5Clambda)%20=%20f(A,%20%5Ctheta)%20+%20%5Clambda%20h(A)%20+%20%5Cfrac%7Bc%7D%7B2%7D%7Ch(A)%7C%5E2%0A"></p>
<ul>
<li>이 식은 세 가지 부분으로 구성됩니다:
<ul>
<li><ol type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?f(A,%20%5Ctheta)">:</strong> 원래의 목적 함수 (Negative ELBO).</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?%5Clambda%20h(A)">:</strong> 표준 라그랑주 항. 여기서 <img src="https://latex.codecogs.com/png.latex?%5Clambda">는 라그랑주 승수(Lagrange Multiplier)입니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bc%7D%7B2%7D%7Ch(A)%7C%5E2">:</strong> 제약 조건 위반에 대한 2차 페널티(Quadratic Penalty) 항입니다. <img src="https://latex.codecogs.com/png.latex?c">는 페널티 파라미터(Penalty Parameter)입니다.</li>
</ol></li>
</ul></li>
</ul>
<section id="motivation" class="level4">
<h4 class="anchored" data-anchor-id="motivation">Motivation</h4>
<ul>
<li>왜 단순 라그랑주나 단순 페널티 기법을 쓰지 않고 이 둘을 섞었을까요?</li>
<li>단순 페널티 기법은 <img src="https://latex.codecogs.com/png.latex?c">를 무한대로 보내야만 제약 조건을 만족하는데, 이는 해 주변에서 함수를 매우 뾰족하게(Ill-conditioned) 만들어 최적화를 어렵게 합니다.</li>
<li>증강 라그랑주 방법은 <img src="https://latex.codecogs.com/png.latex?%5Clambda">의 도움을 받아, <img src="https://latex.codecogs.com/png.latex?c">가 적당히 크더라도 정확한 해로 수렴할 수 있게 해줍니다. 즉, <strong><img src="https://latex.codecogs.com/png.latex?c%20%5Cto%20%5Cinfty">일 때 <img src="https://latex.codecogs.com/png.latex?L_c">의 최소해는 제약 조건 <img src="https://latex.codecogs.com/png.latex?h(A)=0">을 만족하며 원래 목적 함수 <img src="https://latex.codecogs.com/png.latex?f">를 최소화</strong>하게 됩니다.</li>
</ul>
</section>
</section>
<section id="algorithm-iterative-update-rule" class="level3">
<h3 class="anchored" data-anchor-id="algorithm-iterative-update-rule">Algorithm: Iterative Update Rule</h3>
<ul>
<li><p>학습은 <strong><img src="https://latex.codecogs.com/png.latex?c">를 점진적으로 증가</strong>시키면서 일련의 비제약 최적화 문제(Unconstrained optimization)를 푸는 방식으로 진행됩니다.</p></li>
<li><p>구체적인 알고리즘은 다음의 반복(Iteration) 과정으로 요약됩니다.</p></li>
<li><p>각 반복 단계 <img src="https://latex.codecogs.com/png.latex?k">에서 다음을 수행합니다:</p></li>
</ul>
<section id="step-1-primal-update-subproblem" class="level4">
<h4 class="anchored" data-anchor-id="step-1-primal-update-subproblem">Step 1: Primal Update (Subproblem)</h4>
<ul>
<li>현재 고정된 <img src="https://latex.codecogs.com/png.latex?%5Clambda%5Ek">와 <img src="https://latex.codecogs.com/png.latex?c%5Ek">에 대해, 증강 라그랑주 함수 <img src="https://latex.codecogs.com/png.latex?L_%7Bc%5Ek%7D">를 최소화하는 <img src="https://latex.codecogs.com/png.latex?A">와 <img src="https://latex.codecogs.com/png.latex?%5Ctheta">를 찾습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A(A%5Ek,%20%5Ctheta%5Ek)%20=%20%5Cunderset%7BA,%20%5Ctheta%7D%7B%5Ctext%7Bargmin%7D%7D%20%5C%20L_%7Bc%5Ek%7D(A,%20%5Ctheta,%20%5Clambda%5Ek)%20%5Cquad%20%5Ccdots%20(14)%0A"></p>
<ul>
<li>이 단계(Subproblem)는 경사 하강법(Gradient Descent)과 같은 Blackbox Stochastic Optimization Solver(예: Adam)를 사용하여 해결합니다.</li>
<li>ELBO가 샘플 기반으로 정의되므로 확률적(Stochastic) 최적화가 적합합니다.</li>
</ul>
</section>
<section id="step-2-dual-update-lambda" class="level4">
<h4 class="anchored" data-anchor-id="step-2-dual-update-lambda">Step 2: Dual Update (<img src="https://latex.codecogs.com/png.latex?%5Clambda">)</h4>
<ul>
<li>제약 조건 위반 정도(<img src="https://latex.codecogs.com/png.latex?h(A%5Ek)">)를 반영하여 라그랑주 승수를 업데이트합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clambda%5E%7Bk+1%7D%20=%20%5Clambda%5Ek%20+%20c%5Ek%20h(A%5Ek)%20%5Cquad%20%5Ccdots%20(15)%0A"></p>
<ul>
<li>이 규칙은 쌍대 오름법(Dual Ascent)의 형태를 띠며, 제약 조건이 만족되지 않으면(즉 <img src="https://latex.codecogs.com/png.latex?h(A)%20%5Cneq%200">), <img src="https://latex.codecogs.com/png.latex?%5Clambda">를 조정하여 다음 단계에서 해당 제약 조건이 더 중요하게 다뤄지도록 합니다.</li>
</ul>
</section>
<section id="step-3-penalty-parameter-update-c" class="level4">
<h4 class="anchored" data-anchor-id="step-3-penalty-parameter-update-c">Step 3: Penalty Parameter Update (<img src="https://latex.codecogs.com/png.latex?c">)</h4>
<ul>
<li>제약 조건 위반 정도가 충분히 줄어들지 않았다면, 페널티 강도 <img src="https://latex.codecogs.com/png.latex?c">를 증가시킵니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0Ac%5E%7Bk+1%7D%20=%20%5Cbegin%7Bcases%7D%0A%5Ceta%20c%5Ek,%20&amp;%20%5Ctext%7Bif%20%7D%20%7Ch(A%5Ek)%7C%20%3E%20%5Cgamma%20%7Ch(A%5E%7Bk-1%7D)%7C%20%5C%5C%0Ac%5Ek,%20&amp;%20%5Ctext%7Botherwise%7D%0A%5Cend%7Bcases%7D%20%5Cquad%20%5Ccdots%20(16)%0A"></p>
<ul>
<li><strong>조건 (<img src="https://latex.codecogs.com/png.latex?%7Ch(A%5Ek)%7C%20%3E%20%5Cgamma%20%7Ch(A%5E%7Bk-1%7D)%7C">):</strong> 이번 단계의 제약 위반 값이 이전 단계의 <img src="https://latex.codecogs.com/png.latex?%5Cgamma">배보다 크다는 것은, 위반 정도가 충분히(빠르게) 감소하지 않았음을 의미합니다.</li>
<li><strong>대응 (<img src="https://latex.codecogs.com/png.latex?c%20%5Cleftarrow%20%5Ceta%20c">):</strong> 이 경우 <img src="https://latex.codecogs.com/png.latex?c">를 <img src="https://latex.codecogs.com/png.latex?%5Ceta">배 키워서 제약 조건 위반에 대한 비용을 더 비싸게 만듭니다.</li>
</ul>
</section>
</section>
<section id="hyperparameters-and-implementation" class="level3">
<h3 class="anchored" data-anchor-id="hyperparameters-and-implementation">Hyperparameters and Implementation</h3>
<ul>
<li>논문에서는 이 알고리즘의 효과적인 작동을 위한 하이퍼파라미터 설정 값을 제안합니다.
<ul>
<li><strong><img src="https://latex.codecogs.com/png.latex?%5Ceta%20%3E%201">:</strong> 페널티 증가 비율. 논문에서는 <strong><img src="https://latex.codecogs.com/png.latex?%5Ceta%20=%2010"></strong>을 권장합니다.</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?%5Cgamma%20%3C%201">:</strong> 허용 가능한 위반 감소율. 논문에서는 <strong><img src="https://latex.codecogs.com/png.latex?%5Cgamma%20=%201/4"></strong> (<img src="https://latex.codecogs.com/png.latex?0.25">)를 권장합니다.</li>
</ul></li>
<li>이 설정은 제약 조건 위반이 매 단계마다 최소 25%씩은 줄어들기를 기대하며, 그렇지 않을 경우 페널티를 10배로 강력하게 키우겠다는 공격적인 전략을 의미합니다.</li>
</ul>
</section>
<section id="summary-3" class="level3">
<h3 class="anchored" data-anchor-id="summary-3">Summary</h3>
<ul>
<li>DAG-GNN의 학습 과정은 단순히 손실 함수를 미분하여 역전파하는 것을 넘어섭니다.
<ul>
<li><ol type="1">
<li><strong>Augmented Lagrangian</strong>을 통해 연속적인 제약 조건(Acyclicity)을 목적 함수에 부드럽게 통합했습니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Primal-Dual Update</strong> 방식을 통해 모델 파라미터(<img src="https://latex.codecogs.com/png.latex?A,%20%5Ctheta">)와 제약 파라미터(<img src="https://latex.codecogs.com/png.latex?%5Clambda,%20c">)를 번갈아 최적화하며, 점진적으로 DAG 구조를 만족하는 해로 수렴해 나갑니다.</li>
</ol></li>
</ul></li>
<li>이로써 우리는 복잡한 조합 최적화 문제였던 구조 학습을, 딥러닝 프레임워크 위에서 수행 가능한 연속 최적화 문제로 완벽하게 변환하였습니다.</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="experiments" class="level1">
<h1>4. Experiments</h1>
<ul>
<li>본 섹션에서는 제안된 <strong>DAG-GNN</strong> 모델의 성능을 다양한 합성 데이터셋(Synthetic Data)과 벤치마크 데이터셋(Benchmark Data)을 통해 검증합니다.</li>
<li><ul>
<li>비교 대상으로는 당시 SOTA였던 연속 최적화 기반의 <strong>DAG-NOTEARS (Zheng et al., 2018)</strong>를 주로 사용합니다.</li>
</ul></li>
<li>실험의 목표는 DAG-GNN이 <strong>선형성(Linearity)</strong> 가정에 국한되지 않고, <strong>비선형(Nonlinear)</strong> 관계나 <strong>이산형(Discrete)</strong> 변수, 그리고 <strong>벡터 값 노드(Vector-valued node)</strong>까지 얼마나 유연하게 처리할 수 있는지 보여주는 데 있습니다.</li>
</ul>
<hr>
<section id="synthetic-data-sets" class="level2">
<h2 class="anchored" data-anchor-id="synthetic-data-sets">4.1. Synthetic Data Sets</h2>
<ul>
<li><p>저자들은 Erdős-Rényi 모델을 사용하여 임의의 DAG 구조를 생성하고, 노드 수 <img src="https://latex.codecogs.com/png.latex?m%20%5Cin%20%5C%7B10,%2020,%2050,%20100%5C%7D">에 대해 데이터를 생성하여 실험을 진행했습니다. (샘플 수 <img src="https://latex.codecogs.com/png.latex?n=5000">)</p></li>
<li><p>평가 지표로는 다음 두 가지를 사용합니다:</p>
<ul>
<li><ol type="1">
<li><strong>SHD (Structural Hamming Distance):</strong> 예측된 그래프와 정답 그래프 간의 엣지 불일치 개수 (낮을수록 좋음).</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>FDR (False Discovery Rate):</strong> 잘못 예측된 엣지의 비율 (낮을수록 좋음).</li>
</ol></li>
</ul></li>
</ul>
<section id="linear-case" class="level3">
<h3 class="anchored" data-anchor-id="linear-case">4.1.1. Linear Case</h3>
<ul>
<li>먼저, DAG-GNN이 기존 Linear SEM 환경에서도 잘 작동하는지 확인합니다. 데이터 생성 과정은 다음과 같습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax%20=%20A%5ET%20x%20+%20z%0A"></p>
<ul>
<li>여기서 <img src="https://latex.codecogs.com/png.latex?g">는 항등 함수(Identity mapping)입니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/images/figure2_linear_case.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: Linear Case에서의 성능 비교. 그래프 크기(m)가 커짐에 따라 DAG-NOTEARS(파란색)와 DAG-GNN(빨간색)의 SHD와 FDR 변화를 보여준다. DAG-GNN이 선형 모델에서도 NOTEARS와 대등하거나 더 우수한 성능을 보임을 알 수 있다.</figcaption>
</figure>
</div>
<ul>
<li><strong>결과:</strong> 선형 데이터임에도 불구하고, DAG-GNN은 Linear 전용 모델인 NOTEARS보다 더 정확한 구조를 학습했습니다. 특히 그래프 크기가 커질수록(<img src="https://latex.codecogs.com/png.latex?m=100">) 격차가 벌어지는 경향을 보입니다.</li>
</ul>
</section>
<section id="nonlinear-case-core-contribution" class="level3">
<h3 class="anchored" data-anchor-id="nonlinear-case-core-contribution">4.1.2. Nonlinear Case (Core Contribution)</h3>
<ul>
<li>DAG-GNN의 진가는 비선형 데이터에서 드러납니다. 저자들은 다음과 같은 비선형 생성 모델을 사용했습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax%20=%20A%5ET%20h(x)%20+%20z,%20%5Cquad%20%5Ctext%7Bwhere%20%7D%20h(x)%20=%20%5Ccos(x%20+%201)%0A"></p>
<ul>
<li>이 경우 <img src="https://latex.codecogs.com/png.latex?h(x)">를 1차 테일러 근사하면 <img src="https://latex.codecogs.com/png.latex?h(x)%20%5Capprox%20h(0)%5Cmathbf%7B1%7D%20+%20h'(0)x">가 되며, 이는 <img src="https://latex.codecogs.com/png.latex?h'(0)A">를 인접 행렬로 갖는 선형 모델로 근사될 수 있습니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/images/figure3_nonlinear_case.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3: Nonlinear Case (<img src="https://latex.codecogs.com/png.latex?h(x)=%5Ccos(x+1)">)에서의 성능 비교. 비선형성이 도입되자 NOTEARS(파란색)의 SHD와 FDR이 급격히 증가하는 반면, DAG-GNN(빨간색)은 안정적인 성능을 유지한다.</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/images/figure4_heatmap_nonlinear.png" class="img-fluid figure-img"></p>
<figcaption>Figure 4: 파라미터 추정 히트맵 (Heatmap). (왼쪽) True Graph, (중간) DAG-GNN 추정, (오른쪽) NOTEARS 추정. DAG-GNN은 정답의 희소(Sparse)한 구조를 잘 복원하고 “False Alarm”이 적은 반면, NOTEARS는 노이즈가 많이 낀 결과를 보여준다.</figcaption>
</figure>
</div>
<ul>
<li><strong>결과:</strong> SHD 측면에서 약간의 개선이 있었고, 특히 <strong>FDR(가짜 발견율)이 약 3배 가량 개선</strong>되었습니다. 이는 DAG-GNN이 비선형 관계 속에서도 진짜 인과관계만을 정확하게 발라내는 능력이 탁월함을 의미합니다.</li>
</ul>
</section>
<section id="vector-valued-case" class="level3">
<h3 class="anchored" data-anchor-id="vector-valued-case">4.1.3. Vector-Valued Case</h3>
<ul>
<li><p>기존 방법론들은 변수를 스칼라(Scalar)로만 취급했습니다. 하지만 DAG-GNN은 GNN 구조 덕분에 각 노드가 벡터(<img src="https://latex.codecogs.com/png.latex?d%20%3E%201">)인 경우도 자연스럽게 처리합니다.</p></li>
<li><p>실험 설정은 다음과 같습니다:</p>
<ul>
<li>노드 차원 <img src="https://latex.codecogs.com/png.latex?d=5">, 잠재 차원 <img src="https://latex.codecogs.com/png.latex?d_Z=1">.</li>
<li>데이터는 더욱 복잡한 비선형 식 <img src="https://latex.codecogs.com/png.latex?x%20=%202%5Csin(A%5ET(x%20+%200.5%20%5Ccdot%201))%20+%20A%5ET(x%20+%200.5%20%5Ccdot%201)%20+%20z"> 로 생성됩니다.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/images/figure6_vector_case.png" class="img-fluid figure-img"></p>
<figcaption>Figure 6: Vector-valued Case의 성능 비교. 벡터 노드와 복잡한 비선형성이 결합된 환경에서 DAG-GNN(빨간색)이 NOTEARS(파란색)를 압도하는 성능 차이를 보여준다.</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/images/figure7_heatmap_vector.png" class="img-fluid figure-img"></p>
<figcaption>Figure 7: Vector-valued 데이터에 대한 파라미터 추정 비교. DAG-GNN은 Ground Truth의 구조를 거의 완벽하게 복원한 반면, NOTEARS는 구조를 거의 학습하지 못했다.</figcaption>
</figure>
</div>
<ul>
<li><strong>결과:</strong> NOTEARS는 이러한 설정(벡터 입력)을 처리할 수 없어, 데이터를 강제로 스칼라로 변환하거나 가정을 단순화해야 했습니다. 반면 DAG-GNN은 구조적 정보를 잠재 공간(Latent Space)에서 효과적으로 포착하여 압도적인 성능 차이를 보여줍니다.</li>
</ul>
<hr>
</section>
</section>
<section id="benchmark-data-sets-discrete-variables" class="level2">
<h2 class="anchored" data-anchor-id="benchmark-data-sets-discrete-variables">4.2. Benchmark Data Sets (Discrete Variables)</h2>
<ul>
<li>다음으로, 이산형 변수(Discrete Variables)로 구성된 유명한 베이지안 네트워크 벤치마크 데이터셋(Child, Alarm, Pigs)에 대한 실험입니다.</li>
<li>여기서는 <strong>GOPNILP</strong> (Integer Programming을 이용한 Exact Solver)와 비교하여, <strong>BIC Score</strong>를 평가 지표로 사용했습니다.</li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Dataset</th>
<th style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?m"> (Nodes)</th>
<th style="text-align: left;">Ground Truth BIC</th>
<th style="text-align: left;">GOPNILP BIC</th>
<th style="text-align: left;">DAG-GNN BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Child</strong></td>
<td style="text-align: left;">20</td>
<td style="text-align: left;">-1.27e+4</td>
<td style="text-align: left;">-1.27e+4</td>
<td style="text-align: left;">-1.38e+4</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Alarm</strong></td>
<td style="text-align: left;">37</td>
<td style="text-align: left;">-1.07e+4</td>
<td style="text-align: left;">-1.12e+4</td>
<td style="text-align: left;">-1.28e+4</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Pigs</strong></td>
<td style="text-align: left;">441</td>
<td style="text-align: left;">-3.48e+5</td>
<td style="text-align: left;">-3.50e+5</td>
<td style="text-align: left;">-3.69e+5</td>
</tr>
</tbody>
</table>
<p><em>(Table 1의 내용을 재구성)</em></p>
<ul>
<li><strong>해석:</strong> GOPNILP는 전역 최적해(Global Optimum)를 찾는 알고리즘이므로 가장 좋은 점수를 보입니다. DAG-GNN은 근사 해법임에도 불구하고, 전역 최적해에 <strong>합리적으로 근접한(reasonably close)</strong> 결과를 보여줍니다.</li>
<li>BIC 차이가 나는 이유는 VAE 구조가 다항 분포(Multinomial distribution)를 근사하는 과정에서 발생하는 한계로 보이지만, 통합된 프레임워크로 이산형 데이터까지 처리할 수 있다는 점은 큰 강점입니다.</li>
</ul>
<hr>
</section>
<section id="applications" class="level2">
<h2 class="anchored" data-anchor-id="applications">4.3. Applications</h2>
<section id="protein-signaling-network" class="level3">
<h3 class="anchored" data-anchor-id="protein-signaling-network">Protein Signaling Network</h3>
<ul>
<li>Sachs et al.&nbsp;(2005)의 단백질 신호 전달 네트워크 데이터(<img src="https://latex.codecogs.com/png.latex?n=7466,%20m=11">)를 사용하여 실제 인과 구조 복원 능력을 테스트했습니다.</li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Method</th>
<th style="text-align: left;">SHD</th>
<th style="text-align: left;">Predicted Edges</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">FGS (Fast Greedy Search)</td>
<td style="text-align: left;">22</td>
<td style="text-align: left;">17</td>
</tr>
<tr class="even">
<td style="text-align: left;">NOTEARS</td>
<td style="text-align: left;">22</td>
<td style="text-align: left;">16</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>DAG-GNN</strong></td>
<td style="text-align: left;"><strong>19</strong></td>
<td style="text-align: left;"><strong>18</strong></td>
</tr>
</tbody>
</table>
<p><em>(Table 2의 내용을 재구성)</em></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/images/figure8_protein_network.png" class="img-fluid figure-img"></p>
<figcaption>Figure 8: DAG-GNN이 추정한 단백질 신호 전달 네트워크. 붉은색 화살표는 Ground Truth와 일치하는 엣지, 파란색 점선은 간접 연결, 노란색은 역방향 연결을 나타낸다.</figcaption>
</figure>
</div>
<ul>
<li><strong>결과:</strong> DAG-GNN은 SHD 19를 기록하여, NOTEARS(22) 및 FGS(22)보다 <strong>더 정확하게 실제 생물학적 인과관계(Ground Truth)를 복원</strong>했습니다.</li>
</ul>
</section>
<section id="knowledge-base-construction" class="level3">
<h3 class="anchored" data-anchor-id="knowledge-base-construction">Knowledge Base Construction</h3>
<ul>
<li><p>FB15K-237 데이터셋을 사용하여, 지식 베이스(Knowledge Base) 내의 관계(Relation)들 사이의 인과성을 추론하는 새로운 태스크를 제안했습니다.</p></li>
<li><p>예를 들어, <code>Person/Nationality</code>라는 관계가 있다면, 이것이 <code>Person/Language</code> 관계의 원인이 될 수 있다는 식의 메타 관계를 학습합니다.</p></li>
<li><p>Table 3 결과에 따르면, <code>film/ProducedBy</code> <img src="https://latex.codecogs.com/png.latex?%5CRightarrow"> <code>film/Country</code>와 같이 직관적으로 타당한 인과 관계들을 성공적으로 추출했습니다.</p></li>
</ul>
<hr>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>5. Conclusion</h1>
<ul>
<li><p>본 논문은 그래프 구조 학습(Structure Learning)이라는 난제를 해결하기 위해, <strong>딥러닝(Deep Generative Model)과 연속 최적화(Continuous Optimization)</strong>를 결합한 <strong>DAG-GNN</strong> 프레임워크를 제안했습니다.</p></li>
<li><p>이 연구의 핵심 기여와 의의는 다음과 같이 요약할 수 있습니다.</p>
<ul>
<li><ol type="1">
<li><strong>Generalized SEM:</strong> 기존의 선형 구조 방정식 모델(Linear SEM)을 일반화하여, 비선형 관계와 복잡한 데이터 분포를 포착할 수 있는 VAE 기반 생성 모델을 설계했습니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Novel GNN Architecture:</strong> 인코더와 디코더를 구조 학습에 특화된 새로운 Graph Neural Network로 파라미터화했습니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Polynomial Acyclicity Constraint:</strong> 기존의 Matrix Exponential 제약 조건의 수치적 불안정성을 개선하고 구현 용이성을 높인 다항식 형태의 제약 조건을 제안했습니다.</li>
</ol></li>
<li><ol start="4" type="1">
<li><strong>Versatility:</strong> 실험을 통해 선형/비선형, 연속형/이산형, 스칼라/벡터 노드 등 다양한 데이터 형태에 대해 일관되게 우수한 성능을 입증했습니다.</li>
</ol></li>
</ul></li>
<li><p>DAG-GNN은 인과추론 분야에서 딥러닝의 표현력을 구조 학습에 성공적으로 이식한 중요한 이정표가 되는 연구라 할 수 있습니다.</p></li>
</ul>



</section>

 ]]></description>
  <category>Paper Review</category>
  <guid>https://shsha0110.github.io/posts/paper/DAG-GNN: DAG Structure Learning with Graph Neural Networks/</guid>
  <pubDate>Fri, 30 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Paper Review] Conformal Meta-learners for Predictive Inference of Individual Treatment Effects</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<ul>
<li>최근 의료, 정치, 사회과학 등 다양한 분야에서 <strong>개별 대상에 대한 처치 효과의 이질성(Heterogeneity in Treatment Effects)</strong>을 식별하는 문제는 핵심적인 과제로 떠올랐습니다.</li>
<li>단순히 집단 전체의 평균적인 효과를 아는 것을 넘어, “이 약이 <strong>특정 환자</strong>에게 얼마나 효과가 있을까?”와 같은 질문에 답하기 위해 Machine Learning(ML) 모델을 활용하려는 시도가 늘어나고 있습니다.</li>
<li>하지만 기존의 ML 기반 인과추론 모델들은 대부분 <strong>조건부 평균 처치 효과(CATE, Conditional Average Treatment Effect)</strong>의 <strong>점 추정(Point Estimate)</strong>에만 집중해 왔습니다. 즉, 주어진 공변량 <img src="https://latex.codecogs.com/png.latex?X">를 가진 개인의 기대 처치 효과를 하나의 숫자로만 예측할 뿐, 그 예측이 얼마나 불확실한지에 대한 정보는 제공하지 못했습니다.</li>
<li>이 논문은 이러한 한계를 극복하기 위해, <strong>개별 처치 효과(ITE, Individual Treatment Effect)</strong>에 대한 <strong>예측 구간(Predictive Intervals)</strong>을 생성하는 새로운 프레임워크를 제안합니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/images/cate_vs_ite_uncertainty.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: CATE 점 추정과 ITE 구간 추정의 차이. 기존 방법론은 평균적인 효과(실선)만을 추정하지만, 본 논문은 개별 효과의 불확실성을 포함한 구간(음영 영역)을 제시하고자 한다.</figcaption>
</figure>
</div>
<section id="기존-방법론bayesian의-한계" class="level2">
<h2 class="anchored" data-anchor-id="기존-방법론bayesian의-한계">기존 방법론(Bayesian)의 한계</h2>
<ul>
<li><p>기존에 ITE의 불확실성을 다루기 위한 시도들은 주로 <strong>Bayesian 방법론</strong>에 의존해 왔습니다.</p></li>
<li><p>대표적으로 BART(Bayesian Additive Regression Trees)나 Gaussian Processes(GPs)가 있습니다.</p></li>
<li><p>이들은 사후 분포(Posterior Distribution)를 통해 신용 구간(Credible Interval)을 제공할 수 있다는 장점이 있습니다.</p></li>
<li><p>그러나 이러한 Bayesian 접근법은 다음과 같은 명확한 한계가 존재합니다:</p>
<ul>
<li><ol type="1">
<li><strong>Model-Specific:</strong> 특정 모델 구조에 종속적입니다. 최근 Vision이나 NLP 분야에서 두각을 나타내는 Transformer와 같은 현대적인 딥러닝 아키텍처에 유연하게 적용하기 어렵습니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Lack of Frequentist Guarantee:</strong> Bayesian 신용 구간의 커버리지(Coverage)는 사전 분포(Prior)에 의존하며, 유한한 샘플(Finite-sample)에서 빈도주의적 커버리지(Frequentist Coverage)를 보장하지 못합니다.</li>
</ol></li>
</ul></li>
</ul>
</section>
<section id="conformal-prediction-cp의-도입" class="level2">
<h2 class="anchored" data-anchor-id="conformal-prediction-cp의-도입">Conformal Prediction (CP)의 도입</h2>
<ul>
<li>이러한 배경에서 저자들은 <strong>Conformal Prediction (CP)</strong>에 주목합니다.</li>
<li>CP는 어떤 ML 모델이든 상관없이(Model-agnostic), 데이터 분포에 대한 가정 없이(Distribution-free), 유효한 예측 구간을 생성할 수 있는 빈도주의적 대안입니다.</li>
<li>하지만 일반적인 회귀(Regression) 문제와 달리, 인과추론 문제에 CP를 적용하는 것은 <strong>“인과추론의 근본적인 문제(Fundamental Problem of Causal Inference)”</strong> 때문에 훨씬 까다롭습니다.</li>
</ul>
</section>
<section id="core-challenges-in-causal-conformal-prediction" class="level2">
<h2 class="anchored" data-anchor-id="core-challenges-in-causal-conformal-prediction">Core Challenges in Causal Conformal Prediction</h2>
<ul>
<li>일반적인 지도 학습(Supervised Learning)에서 우리는 입력 <img src="https://latex.codecogs.com/png.latex?X">와 정답 라벨 <img src="https://latex.codecogs.com/png.latex?Y">를 모두 관측할 수 있습니다.</li>
<li>하지만 인과추론에서의 “라벨”은 <strong>ITE(Individual Treatment Effect)</strong>이며, 이는 관측이 불가능합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BITE%7D_i%20=%20Y_i(1)%20-%20Y_i(0)%0A"></p>
<ul>
<li>여기서 <img src="https://latex.codecogs.com/png.latex?Y_i(1)">은 처치를 받았을 때의 잠재적 결과, <img src="https://latex.codecogs.com/png.latex?Y_i(0)">는 받지 않았을 때의 결과입니다.</li>
<li>우리는 현실에서 둘 중 하나만 관측할 수 있습니다(Factual Outcome). 나머지 하나는 영원히 알 수 없는 반사실적 결과(Counterfactual Outcome)입니다.</li>
<li>이로 인해 ITE에 대한 예측 구간을 생성할 때 두 가지 주요한 도전 과제가 발생합니다.</li>
</ul>
<section id="challenge-1-covariate-shift-공변량-이동" class="level3">
<h3 class="anchored" data-anchor-id="challenge-1-covariate-shift-공변량-이동">Challenge 1: Covariate Shift (공변량 이동)</h3>
<ul>
<li>처치 집단과 통제 집단은 무작위로 배정되지 않는 경우가 많습니다.</li>
<li>개인의 특성(Covariate)에 따라 처치를 받을 확률이 달라지기 때문에, 처치군과 대조군의 공변량 분포가 서로 다릅니다.</li>
<li>결과적으로 모델을 학습시키는 데이터의 분포와 우리가 예측하고자 하는 목표 모집단의 분포가 달라지는 <strong>Covariate Shift</strong> 문제가 발생합니다.</li>
</ul>
</section>
<section id="challenge-2-inductive-biases-귀납적-편향" class="level3">
<h3 class="anchored" data-anchor-id="challenge-2-inductive-biases-귀납적-편향">Challenge 2: Inductive Biases (귀납적 편향)</h3>
<ul>
<li>ITE는 직접 관측되지 않기 때문에 모델을 ITE에 직접 피팅(Fit)할 수 없습니다.</li>
<li>대신 우리는 <img src="https://latex.codecogs.com/png.latex?Y(1)">과 <img src="https://latex.codecogs.com/png.latex?Y(0)">라는 <strong>Nuisance Parameters(관심 없는 모수)</strong>를 각각 추정하고 이를 조합해야 합니다.</li>
<li>이 과정에서 어떤 방식으로 잠재적 결과를 추정하고 결합하느냐에 따라 모델의 성능이 달라지며, 이를 해결하기 위해 다양한 <strong>Meta-learner</strong>들이 개발되었습니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/images/causal_inference_fundamental_problem.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: 인과추론에서의 데이터 관측 구조와 Meta-learner의 필요성. 관측된 데이터(Factual)만을 사용하여 관측되지 않은 잠재적 결과(Counterfactual)를 추론하고, 이를 결합하여 ITE를 도출하는 과정을 보여준다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="proposed-framework-conformal-meta-learners" class="level2">
<h2 class="anchored" data-anchor-id="proposed-framework-conformal-meta-learners">Proposed Framework: Conformal Meta-learners</h2>
<ul>
<li>이 논문의 핵심 기여는 위의 두 가지 문제(Covariate Shift, Inductive Biases)를 동시에 해결하는 <strong>Conformal Meta-learners</strong> 프레임워크를 제안한 것입니다.</li>
</ul>
<section id="two-stage-pseudo-outcome-regression" class="level3">
<h3 class="anchored" data-anchor-id="two-stage-pseudo-outcome-regression">Two-stage Pseudo-outcome Regression</h3>
<ul>
<li>저자들은 <strong>Two-stage pseudo-outcome regression</strong>에 기반한 광범위한 Meta-learner 클래스에 집중합니다.</li>
<li>이 방법론은 다음과 같은 2단계로 진행됩니다:
<ul>
<li><ol type="1">
<li><strong>Pseudo-outcome Estimation:</strong> 관측 가능한 변수들만을 사용하여 ITE의 대리 변수(Proxy) 역할을 하는 <strong>Pseudo-outcome</strong>을 생성합니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Regression:</strong> 이 Pseudo-outcome을 공변량 <img src="https://latex.codecogs.com/png.latex?X">에 대해 회귀 분석하여 CATE의 점 추정치를 얻습니다.</li>
</ol></li>
</ul></li>
</ul>
</section>
<section id="conformal-inference-procedure" class="level3">
<h3 class="anchored" data-anchor-id="conformal-inference-procedure">Conformal Inference Procedure</h3>
<ul>
<li><p>Conformal Meta-learner는 이 과정 위에 CP를 적용합니다.</p></li>
<li><p>핵심 아이디어는 <strong>보류된 보정 데이터셋(Held-out Calibration Set)에서 Pseudo-outcome에 대한 적합성 점수(Conformity Scores)를 계산하고, 이 점수의 경험적 분위수(Empirical Quantile)를 사용하여 구간을 구성</strong>하는 것입니다.</p></li>
<li><p>이 접근법이 갖는 장점은 다음과 같습니다:</p>
<ul>
<li><strong>Covariate Shift 해결:</strong> Pseudo-outcome과 연관된 공변량의 분포는 학습 데이터와 테스트 데이터에서 동일하게 취급될 수 있습니다.</li>
<li><strong>Inductive Biases 해결:</strong> 보정 단계(Calibration step)가 모델 아키텍처와 분리되어 있습니다. 따라서 CATE 추정에 효과적이라고 알려진 기존의 다양한 Meta-learner(예: T-learner, X-learner 등)나 딥러닝 아키텍처를 그대로 가져와서 사용할 수 있습니다.</li>
</ul></li>
</ul>
</section>
<section id="theoretical-guarantee-stochastic-ordering" class="level3">
<h3 class="anchored" data-anchor-id="theoretical-guarantee-stochastic-ordering">Theoretical Guarantee: Stochastic Ordering</h3>
<ul>
<li><p>하지만 Pseudo-outcome에 대해 CP를 적용한다고 해서, 그것이 곧바로 관측되지 않은 <strong>ITE</strong>에 대한 커버리지를 보장하는 것은 아닙니다.</p></li>
<li><p>저자들은 이를 증명하기 위해 <strong>확률적 순서(Stochastic Ordering)</strong> 프레임워크를 도입했습니다.</p></li>
<li><p>만약 우리가 사용하는 Pseudo-outcome 기반의 적합성 점수(Conformity Score)가, 실제 ITE를 알았을 때 계산할 수 있는 “Oracle” 적합성 점수보다 <strong>확률적으로 우월(Stochastically Dominate)</strong>하다면, 결과적으로 생성된 구간은 유효(Valid)합니다.</p></li>
<li><p>특히, 널리 사용되는 <strong>Doubly-Robust Learner</strong>와 같은 Meta-learner들이 이러한 확률적 지배 조건(또는 볼록 지배 조건)을 만족함을 증명했습니다.</p></li>
</ul>
<hr>
</section>
</section>
</section>
<section id="predictive-inference-of-individual-treatment-effects-ites" class="level1">
<h1>2. Predictive Inference of Individual Treatment Effects (ITEs)</h1>
<section id="problem-setup" class="level2">
<h2 class="anchored" data-anchor-id="problem-setup">2.1. Problem Setup</h2>
<ul>
<li>논문은 인과추론의 표준인 <strong>잠재적 결과 프레임워크(Potential Outcomes Framework)</strong>, 혹은 <strong>Rubin Causal Model</strong>을 따릅니다.</li>
</ul>
<section id="notation-definition" class="level3">
<h3 class="anchored" data-anchor-id="notation-definition">Notation &amp; Definition</h3>
<ul>
<li>데이터는 <img src="https://latex.codecogs.com/png.latex?n">명의 대상(subject)에 대해 관측되며, 각 대상 <img src="https://latex.codecogs.com/png.latex?i">는 다음과 같은 변수들을 가집니다.
<ul>
<li><strong>Covariates (공변량)</strong> <img src="https://latex.codecogs.com/png.latex?X%20%5Cin%20%5Cmathcal%7BX%7D">: 개인의 특징.</li>
<li><strong>Treatment Indicator (처치 여부)</strong> <img src="https://latex.codecogs.com/png.latex?W%20%5Cin%20%5C%7B0,%201%5C%7D">: <img src="https://latex.codecogs.com/png.latex?1">이면 처치군, <img src="https://latex.codecogs.com/png.latex?0">이면 대조군.</li>
<li><strong>Outcome (결과)</strong> <img src="https://latex.codecogs.com/png.latex?Y%20%5Cin%20%5Cmathbb%7BR%7D">: 우리가 관심 있는 결과 변수.</li>
</ul></li>
<li>각 대상 <img src="https://latex.codecogs.com/png.latex?i">에 대해 두 가지 <strong>잠재적 결과(Potential Outcomes)</strong>가 존재합니다.
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Y_i(1)">: 처치를 받았을 때의 결과 (<img src="https://latex.codecogs.com/png.latex?W=1">)</li>
<li><img src="https://latex.codecogs.com/png.latex?Y_i(0)">: 처치를 받지 않았을 때의 결과 (<img src="https://latex.codecogs.com/png.latex?W=0">)</li>
</ul></li>
<li>하지만 현실에서는 <strong>인과추론의 근본적인 문제(Fundamental Problem of Causal Inference)</strong>로 인해, 우리는 오직 실제 발생한 결과(Factual Outcome)만을 관측할 수 있습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AY_i%20=%20W_i%20Y_i(1)%20+%20(1%20-%20W_i)%20Y_i(0)%0A"></p>
<ul>
<li>반면, 관측되지 않은 쪽인 <img src="https://latex.codecogs.com/png.latex?Y_i(1-W_i)">는 <strong>반사실적 결과(Counterfactual Outcome)</strong>가 됩니다.</li>
<li>우리는 <img src="https://latex.codecogs.com/png.latex?n">명의 대상에 대한 데이터 생성 과정(Data Generation Process)이 결합 분포 <img src="https://latex.codecogs.com/png.latex?P">로부터 <strong>독립적이고 동일하게 분포(i.i.d.)</strong>한다고 가정합니다.</li>
</ul>
<p><span id="eq-(1)"><img src="https://latex.codecogs.com/png.latex?%0A(X_i,%20W_i,%20Y_i(0),%20Y_i(1))%20%5Coverset%7Biid%7D%7B%5Csim%7D%20P(X,%20W,%20Y(0),%20Y(1)),%20%5Cquad%20i%20=%201,%20%5Cdots,%20n%0A%5Ctag%7B1%7D"></span></p>
</section>
<section id="assumptions" class="level3">
<h3 class="anchored" data-anchor-id="assumptions">Assumptions</h3>
<ul>
<li><p>관측된 데이터 <img src="https://latex.codecogs.com/png.latex?%5C%7BZ_i%20=%20(X_i,%20W_i,%20Y_i)%5C%7D_%7Bi=1%7D%5En">로부터 인과 효과를 식별(Identification)하기 위해 다음 세 가지 가정을 도입합니다.</p></li>
<li><ol type="1">
<li><strong>Unconfoundedness (Ignorability):</strong> <img src="https://latex.codecogs.com/png.latex?(Y(0),%20Y(1))%20%5Cperp%20W%20%5Cmid%20X"></li>
</ol>
<ul>
<li>공변량 <img src="https://latex.codecogs.com/png.latex?X">가 주어졌을 때, 처치 할당 <img src="https://latex.codecogs.com/png.latex?W">는 잠재적 결과들과 독립입니다.</li>
<li>즉, <img src="https://latex.codecogs.com/png.latex?X"> 외에 처치와 결과 모두에 영향을 주는 숨겨진 교란 변수(Confounder)는 없습니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Consistency:</strong> <img src="https://latex.codecogs.com/png.latex?Y%20=%20Y(W)"></li>
</ol>
<ul>
<li>관측된 결과 <img src="https://latex.codecogs.com/png.latex?Y">는 실제로 받은 처치 <img src="https://latex.codecogs.com/png.latex?W">에 해당하는 잠재적 결과와 일치합니다.</li>
</ul></li>
<li><ol start="3" type="1">
<li><strong>Positivity (Overlap):</strong> <img src="https://latex.codecogs.com/png.latex?0%20%3C%20P(W=1%20%5Cmid%20X=x)%20%3C%201,%20%5Cquad%20%5Cforall%20x%20%5Cin%20%5Cmathcal%7BX%7D"></li>
</ol>
<ul>
<li>모든 공변량 영역에서 처치군과 대조군이 될 확률이 0이 아니어야 합니다.</li>
</ul></li>
</ul>
</section>
<section id="cate-vs.-ite-무엇이-다른가" class="level3">
<h3 class="anchored" data-anchor-id="cate-vs.-ite-무엇이-다른가">CATE vs.&nbsp;ITE: 무엇이 다른가?</h3>
<ul>
<li><p>이 논문에서 가장 중요하게 강조하는 구분이 바로 <strong>CATE</strong>와 <strong>ITE</strong>의 차이입니다.</p></li>
<li><p><strong>CATE (Conditional Average Treatment Effect):</strong></p>
<ul>
<li>기존 연구들이 주로 추정해온 <strong>결정론적(Deterministic) 함수</strong>로, 조건부 기대값의 차이입니다. <img src="https://latex.codecogs.com/png.latex?%5Ctau(x)%20%5Ctriangleq%20%5Cmathbb%7BE%7D%5BY(1)%20-%20Y(0)%20%5Cmid%20X=x%5D"></li>
</ul></li>
<li><p><strong>ITE (Individual Treatment Effect):</strong></p>
<ul>
<li>이 논문의 관심 대상인 <strong>확률 변수(Random Variable)</strong>입니다. <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BITE%7D_i%20=%20Y_i(1)%20-%20Y_i(0)"></li>
</ul></li>
<li><p>CATE는 “당신과 같은 특성을 가진 사람들의 평균적인 효과”를 말해주지만, ITE는 “당신이 겪을 실제 효과”를 의미합니다.</p></li>
<li><p>ITE는 모델의 오차뿐만 아니라, 같은 <img src="https://latex.codecogs.com/png.latex?X">를 가진 사람들 사이에서도 존재하는 <strong>내재적 변동성(Intrinsic Variability)</strong>을 포함합니다.</p></li>
<li><p>관측된 변수 <img src="https://latex.codecogs.com/png.latex?Z=(X,%20W,%20Y)">의 분포를 기술하기 위해, 우리는 다음과 같은 두 가지 <strong>Nuisance Functions(방해 모수 함수)</strong>를 정의합니다.</p>
<ul>
<li><strong>Propensity Score <img src="https://latex.codecogs.com/png.latex?%5Cpi(x)">:</strong> 처치 할당 메커니즘을 나타냅니다.</li>
<li><strong>Outcome Mean Functions <img src="https://latex.codecogs.com/png.latex?%5Cmu_w(x)">:</strong> 각 처치 그룹 내에서의 조건부 기대 결과를 나타냅니다.</li>
</ul></li>
</ul>
<p><span id="eq-(2)"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Cpi(x)%20&amp;=%20%5Cmathbb%7BP%7D(W=1%20%5Cmid%20X=x),%20%5C%5C%0A%5Cmu_w(x)%20&amp;=%20%5Cmathbb%7BE%7D%5BY%20%5Cmid%20X=x,%20W=w%5D,%20%5Cquad%20w%20%5Cin%20%5C%7B0,%201%5C%7D.%0A%5Cend%7Baligned%7D%0A%5Ctag%7B2%7D"></span></p>
<ul>
<li>특히 본 논문에서는 데이터가 실험 연구(Experimental Study)에서 얻어졌거나 처치 할당 메커니즘이 알려져 있어, <strong>Propensity Score <img src="https://latex.codecogs.com/png.latex?%5Cpi(x)">를 알고 있다(Known)</strong>고 가정합니다.</li>
</ul>
</section>
<section id="목표-marginally-valid-predictive-interval" class="level3">
<h3 class="anchored" data-anchor-id="목표-marginally-valid-predictive-interval">목표: Marginally Valid Predictive Interval</h3>
<ul>
<li>논문의 목표는 새로운 데이터 <img src="https://latex.codecogs.com/png.latex?X_%7Bn+1%7D">이 주어졌을 때, 실제 ITE가 포함될 확률이 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha"> 이상인 <strong>예측 구간(Predictive Band)</strong> <img src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D(x)">를 구성하는 것입니다.</li>
</ul>
<p><span id="eq-(3)"><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D(Y_%7Bn+1%7D(1)%20-%20Y_%7Bn+1%7D(0)%20%5Cin%20%5Chat%7BC%7D(X_%7Bn+1%7D))%20%5Cge%201%20-%20%5Calpha%0A%5Ctag%7B3%7D"></span></p>
<ul>
<li>이 확률은 훈련 데이터 <img src="https://latex.codecogs.com/png.latex?%5C%7BZ_i%5C%7D">와 새로운 테스트 포인트의 랜덤성을 모두 고려한 <strong>Marginal Validity</strong>를 의미합니다.</li>
</ul>
<hr>
</section>
</section>
<section id="conformal-prediction" class="level2">
<h2 class="anchored" data-anchor-id="conformal-prediction">2.2. Conformal Prediction</h2>
<ul>
<li>이 목표를 달성하기 위한 도구로 <strong>Conformal Prediction (CP)</strong>을 사용합니다.</li>
<li>CP는 모델이나 분포에 대한 가정 없이(Model-free, Distribution-free) 유효한 예측 구간을 생성하는 프레임워크입니다.</li>
</ul>
<section id="split-conformal-prediction-inductive-cp" class="level3">
<h3 class="anchored" data-anchor-id="split-conformal-prediction-inductive-cp">Split Conformal Prediction (Inductive CP)</h3>
<ul>
<li><p>가장 기본적인 형태인 Split CP의 절차는 다음과 같습니다.</p></li>
<li><ol type="1">
<li><strong>Data Splitting:</strong> 전체 데이터 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D">를 훈련 집합 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D_%7Bt%7D">와 보정 집합(Calibration set) <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D_%7Bc%7D">로 나눕니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Model Fitting:</strong> <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D_%7Bt%7D">를 사용하여 예측 모델 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmu%7D(x)">를 학습합니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Conformity Scores Calculation:</strong> 보정 집합 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D_%7Bc%7D">의 모든 샘플에 대해, 실제 값과 예측 값의 괴리를 나타내는 점수(Conformity Score)를 계산합니다. 일반적인 회귀 문제에서는 절대 잔차(Absolute Residual)를 사용합니다. <span id="eq-(4)"><img src="https://latex.codecogs.com/png.latex?V_k(%5Chat%7B%5Cmu%7D)%20%5Ctriangleq%20%7C%20%5Chat%7B%5Cmu%7D(X_k)%20-%20Y_k%20%7C,%20%5Cquad%20%5Cforall%20k%20%5Cin%20%5Cmathcal%7BD%7D_c%20%5Ctag%7B4%7D"></span></li>
</ol></li>
<li><ol start="4" type="1">
<li><strong>Quantile Computation:</strong> 계산된 모든 점수들의 집합을 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BV%7D(%5Chat%7B%5Cmu%7D)%20=%20%5C%7BV_k(%5Chat%7B%5Cmu%7D)%20:%20k%20%5Cin%20%5Cmathcal%7BD%7D_c%5C%7D">라고 할 때, 목표 커버리지 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha">에 해당하는 경험적 분위수(Empirical Quantile)를 구합니다. <span id="eq-(5)"><img src="https://latex.codecogs.com/png.latex?Q_%7B%5Cmathcal%7BV%7D%7D(1-%5Calpha)%20%5Ctriangleq%20(1-%5Calpha)(1%20+%201/%7C%5Cmathcal%7BD%7D_c%7C)%5Ctext%7B-th%20quantile%20of%20%7D%20%5Cmathcal%7BV%7D(%5Chat%7B%5Cmu%7D)%20%5Ctag%7B5%7D"></span></li>
</ol></li>
<li><ol start="5" type="1">
<li><strong>Interval Construction:</strong> 새로운 데이터 <img src="https://latex.codecogs.com/png.latex?X_%7Bn+1%7D=x">에 대한 예측 구간 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D(x)">는 예측값 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmu%7D(x)">를 중심으로 해당 분위수만큼 벌린 구간으로 정의됩니다. <span id="eq-(6)"><img src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D(x)%20=%20%5B%5Chat%7B%5Cmu%7D(x)%20-%20Q_%7B%5Cmathcal%7BV%7D%7D(1-%5Calpha),%20%5C;%5C;%20%5Chat%7B%5Cmu%7D(x)%20+%20Q_%7B%5Cmathcal%7BV%7D%7D(1-%5Calpha)%5D%20%5Ctag%7B6%7D"></span></li>
</ol></li>
<li><p>이 구간은 훈련 데이터와 테스트 데이터 간의 <strong>Exchangeability (교환 가능성)</strong> 가정 하에서, 새로운 데이터 <img src="https://latex.codecogs.com/png.latex?Y_%7Bn+1%7D">을 포함할 확률이 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha"> 이상임이 수학적으로 보장됩니다 (Marginal Coverage Guarantee).</p></li>
</ul>
<hr>
</section>
</section>
<section id="oracle-conformal-prediction-of-ites" class="level2">
<h2 class="anchored" data-anchor-id="oracle-conformal-prediction-of-ites">2.3. Oracle Conformal Prediction of ITEs</h2>
<ul>
<li><p>이제 CP를 ITE 추정에 적용해봅시다. 만약 우리가 <strong>신(Oracle)</strong>이어서 반사실적 결과까지 모두 볼 수 있다면, 문제는 매우 간단해집니다.</p></li>
<li><p>가상의 “Oracle 데이터셋” <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D%5E*%20=%20%5C%7B(X_i,%20%5Cunderbrace%7BY_i(1)%20-%20Y_i(0)%7D_%7B%5Ctext%7BTrue%20ITE%7D%7D)%5C%7D_%7Bi%7D"> 가 있다고 가정해봅시다.</p></li>
<li><p>이 경우 <strong>Oracle Conformity Score</strong>를 다음과 같이 정의할 수 있습니다. <span id="eq-(7)"><img src="https://latex.codecogs.com/png.latex?V%5E*_k(%5Chat%7B%5Ctau%7D)%20%5Ctriangleq%20V(X_k,%20%5Cunderbrace%7BY_k(1)%20-%20Y_k(0)%7D_%7B%5Ctext%7BLabel%7D%7D,%20%5Chat%7B%5Ctau%7D)%20%5Ctag%7B7%7D"></span></p></li>
<li><p>이 점수를 사용해 CP를 수행하면 식 (3)의 coverage 조건을 완벽하게 만족하는 구간 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D%5E*(X)">를 얻을 수 있습니다.</p></li>
<li><p>하지만 현실에서는 <img src="https://latex.codecogs.com/png.latex?Y_i(1)">과 <img src="https://latex.codecogs.com/png.latex?Y_i(0)"> 중 하나만 관측되므로, <strong>이 Oracle 절차는 불가능(Infeasible)</strong>합니다.</p></li>
</ul>
<hr>
</section>
<section id="the-two-challenges-of-predictive-inference-on-ites" class="level2">
<h2 class="anchored" data-anchor-id="the-two-challenges-of-predictive-inference-on-ites">2.4. The Two Challenges of Predictive Inference on ITEs</h2>
<ul>
<li><p>현실적인 대안으로, 관측된 데이터를 처치군(<img src="https://latex.codecogs.com/png.latex?W=1">)과 대조군(<img src="https://latex.codecogs.com/png.latex?W=0">)으로 나누어 각각의 잠재적 결과 <img src="https://latex.codecogs.com/png.latex?Y(1)">과 <img src="https://latex.codecogs.com/png.latex?Y(0)">에 대해 별도로 CP를 적용하는 “Naïve Approach”를 생각할 수 있습니다.</p></li>
<li><p>이 방식은 먼저 데이터를 처치 그룹(<img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D_1">)과 대조 그룹(<img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D_0">)으로 분할한 뒤, 각각의 Nuisance Estimate (<img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmu%7D_1,%20%5Chat%7B%5Cmu%7D_0">)에 대해 다음과 같이 별도의 적합성 점수(Conformity Scores)를 생성합니다.</p></li>
</ul>
<p><span id="eq-(8)"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0AV_k%5E%7B(0)%7D(%5Chat%7B%5Cmu%7D_0)%20&amp;%5Ctriangleq%20V(X_k,%20Y_k(0);%20%5Chat%7B%5Cmu%7D_0),%20%5Cquad%20%5Cforall%20k%20%5Cin%20%5Cmathcal%7BD%7D_%7Bc,0%7D%20%5C%5C%0AV_k%5E%7B(1)%7D(%5Chat%7B%5Cmu%7D_1)%20&amp;%5Ctriangleq%20V(X_k,%20Y_k(1);%20%5Chat%7B%5Cmu%7D_1),%20%5Cquad%20%5Cforall%20k%20%5Cin%20%5Cmathcal%7BD%7D_%7Bc,1%7D%0A%5Cend%7Baligned%7D%0A%5Ctag%7B8%7D"></span></p>
<ul>
<li>여기서 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D_%7Bc,0%7D">와 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D_%7Bc,1%7D">은 각각 대조군과 처치군의 보정 데이터셋을 의미합니다.</li>
<li>하지만 이 접근법은 다음과 같은 두 가지 심각한 문제에 직면합니다.</li>
</ul>
<section id="challenge-1-covariate-shift-공변량-이동-1" class="level3">
<h3 class="anchored" data-anchor-id="challenge-1-covariate-shift-공변량-이동-1">Challenge 1: Covariate Shift (공변량 이동)</h3>
<ul>
<li><p>CP의 핵심 가정은 <strong>Exchangeability</strong>입니다. 즉, 보정 데이터(Calibration data)와 테스트 데이터(Test data)가 같은 분포에서 와야 합니다.</p></li>
<li><p>그러나 인과추론 상황에서는 필연적으로 <strong>Covariate Shift</strong>가 발생합니다.</p></li>
<li><p>처치를 받을 확률(Propensity Score, <img src="https://latex.codecogs.com/png.latex?%5Cpi(x)">)이 개인마다 다르기 때문입니다.</p></li>
<li><p>처치군(<img src="https://latex.codecogs.com/png.latex?W=1">)의 공변량 분포 <img src="https://latex.codecogs.com/png.latex?P_%7BX%7CW=1%7D">와 대조군(<img src="https://latex.codecogs.com/png.latex?W=0">)의 분포 <img src="https://latex.codecogs.com/png.latex?P_%7BX%7CW=0%7D">는 서로 다릅니다.</p></li>
<li><p>무엇보다, 이 둘은 우리가 예측하고자 하는 전체 모집단의 분포 <img src="https://latex.codecogs.com/png.latex?P_X">와도 다릅니다 (<img src="https://latex.codecogs.com/png.latex?P_%7BX%7CW=0%7D%20%5Cneq%20P_%7BX%7CW=1%7D%20%5Cneq%20P_X">).</p></li>
<li><p>이러한 공변량의 이동은 결과적으로 우리가 계산하는 <strong>Conformity Score (<img src="https://latex.codecogs.com/png.latex?V">)의 결합 분포</strong>에도 영향을 미칩니다.</p></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AP_%7BX,V%5E%7B(0)%7D%7CW=0%7D%20%5Cneq%20P_%7BX,V%5E%7B(0)%7D%7D,%20%5Cquad%20P_%7BX,V%5E%7B(1)%7D%7CW=1%7D%20%5Cneq%20P_%7BX,V%5E%7B(1)%7D%7D%0A"></p>
<ul>
<li>즉, 특정 처치 그룹에서 계산한 점수의 분포가 전체 모집단에서의 분포와 일치하지 않게 됩니다.</li>
<li>따라서 단순히 처치군 데이터로 학습하고 보정한 모델을 전체 모집단에 적용하면 <strong>Exchangeability 가정이 깨지므로, CP의 커버리지 보장(Validity)이 성립하지 않습니다.</strong></li>
</ul>
</section>
<section id="challenge-2-inductive-biases-귀납적-편향-1" class="level3">
<h3 class="anchored" data-anchor-id="challenge-2-inductive-biases-귀납적-편향-1">Challenge 2: Inductive Biases (귀납적 편향)</h3>
<ul>
<li>지도 학습에서는 <img src="https://latex.codecogs.com/png.latex?(X,%20Y)"> 쌍을 통해 하나의 함수를 학습하지만, ITE 추정은 관측되지 않는 효과를 추정해야 하므로 모델링의 자유도가 훨씬 높습니다. 이를 위해 다양한 <strong>Meta-learner</strong>들이 존재합니다.
<ul>
<li><strong>T-learner:</strong> <img src="https://latex.codecogs.com/png.latex?%5Cmu_0(x)">와 <img src="https://latex.codecogs.com/png.latex?%5Cmu_1(x)">를 별도로 학습하여 <img src="https://latex.codecogs.com/png.latex?Y(0),%20Y(1)"> 각각에 서로 다른 규제(Regularization)를 가함.</li>
<li><strong>S-learner:</strong> 처치 변수 <img src="https://latex.codecogs.com/png.latex?W">를 공변량에 포함시켜 하나의 모델 <img src="https://latex.codecogs.com/png.latex?%5Cmu(X,%20W)"> 학습.</li>
</ul></li>
<li>각 Meta-learner는 <img src="https://latex.codecogs.com/png.latex?Y(0)">와 <img src="https://latex.codecogs.com/png.latex?Y(1)">이라는 <strong>Nuisance Parameters(방해 모수)</strong>를 추정하고 결합하는 방식에 있어 서로 다른 <strong>Inductive Bias</strong>를 가집니다.</li>
</ul>
</section>
<section id="limitations-of-existing-approaches-기존-방법의-한계" class="level3">
<h3 class="anchored" data-anchor-id="limitations-of-existing-approaches-기존-방법의-한계">Limitations of Existing Approaches (기존 방법의 한계)</h3>
<ul>
<li>기존 연구들은 이러한 Covariate Shift를 해결하기 위해 Conformity Score에 가중치를 부여(Reweighting)하거나, <img src="https://latex.codecogs.com/png.latex?Y(0)">와 <img src="https://latex.codecogs.com/png.latex?Y(1)"> 각각에 대한 구간을 구한 뒤 이를 결합하는 방식을 사용했습니다. 하지만 이는 다음과 같은 한계를 가집니다.
<ul>
<li><ol type="1">
<li><strong>Loss of Post-hoc Nature (사후적 특성 상실):</strong> CP 절차가 모델 아키텍처(Nuisance Parameter 추정 방식)에 종속되게 만들어, CP 고유의 장점인 ‘모델에 구애받지 않는(Model-agnostic)’ 성격을 잃게 합니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Conservativeness (보수성):</strong> 두 개의 잠재적 결과(PO) 구간을 결합하여 ITE 구간을 생성할 경우, 구간이 불필요하게 넓어져 효율성이 떨어집니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Limited Applicability (적용의 한계):</strong> 모든 CATE 모델이 <img src="https://latex.codecogs.com/png.latex?Y(0)">와 <img src="https://latex.codecogs.com/png.latex?Y(1)">을 명시적으로 추정하는 것은 아니므로, 다양한 Inductive Prior를 유연하게 적용하기 어렵습니다.</li>
</ol></li>
</ul></li>
</ul>
<hr>
</section>
</section>
</section>
<section id="conformal-meta-learners" class="level1">
<h1>3. Conformal Meta-learners</h1>
<ul>
<li>저자들이 제안한 핵심 솔루션인 <strong>Conformal Meta-learners</strong> 프레임워크를 자세히 살펴봅니다.</li>
<li>이 방법론은 <strong>Pseudo-outcome</strong>이라는 개념을 도입하여 기존의 CATE 추정 모델들을 Conformal Prediction(CP) 파이프라인에 유연하게 결합합니다.</li>
<li>또한, 우리가 만든 구간이 실제 ITE를 포함한다는 것을 보장하기 위해 필요한 수학적 조건인 <strong>Stochastic Dominance(확률적 지배)</strong> 개념까지 확장해 보겠습니다.</li>
</ul>
<section id="pseudo-outcome-regression-for-cate-estimation" class="level2">
<h2 class="anchored" data-anchor-id="pseudo-outcome-regression-for-cate-estimation">3.1. Pseudo-outcome Regression for CATE Estimation</h2>
<ul>
<li>Conformal Meta-learner의 핵심 아이디어는 관측되지 않는 ITE(<img src="https://latex.codecogs.com/png.latex?Y(1)-Y(0)">)를 직접 예측하려 드는 대신, 관측 가능한 변수들로 구성된 대리 변수, 즉 <strong>Pseudo-outcome (<img src="https://latex.codecogs.com/png.latex?%5Ctilde%7BY%7D_%7B%5Cvarphi%7D">)</strong>을 정의하는 것입니다.</li>
</ul>
<section id="two-stage-regression-procedure" class="level3">
<h3 class="anchored" data-anchor-id="two-stage-regression-procedure">Two-stage Regression Procedure</h3>
<ul>
<li><p>이 프레임워크는 크게 두 단계로 구성됩니다.</p></li>
<li><ol type="1">
<li><strong>Stage 1 (Nuisance Estimation):</strong></li>
</ol>
<ul>
<li>데이터의 일부(<img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D_%7B%5Cvarphi%7D">)를 사용하여 Nuisance parameter인 <img src="https://latex.codecogs.com/png.latex?%5Cvarphi%20=%20(%5Cpi,%20%5Cmu_0,%20%5Cmu_1)">를 추정합니다.</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cpi(x)%20=%20P(W=1%7CX=x)">: Propensity score (실험 데이터라면 알려져 있음)</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmu_w(x)%20=%20%5Cmathbb%7BE%7D%5BY%7CX=x,%20W=w%5D">: Response surfaces</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Stage 2 (CATE Estimation):</strong></li>
</ol>
<ul>
<li>추정된 Nuisance parameter <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cvarphi%7D">를 사용하여 각 관측치에 대해 Pseudo-outcome <img src="https://latex.codecogs.com/png.latex?%5Ctilde%7BY%7D_%7B%5Cvarphi%7D">를 생성합니다.</li>
<li>그 후, 공변량 <img src="https://latex.codecogs.com/png.latex?X">를 입력으로 하고 <img src="https://latex.codecogs.com/png.latex?%5Ctilde%7BY%7D_%7B%5Cvarphi%7D">를 타겟으로 하는 회귀 모델을 학습하여 CATE(<img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Ctau%7D">)를 추정합니다.</li>
</ul></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7B%5Ctau%7D(x)%20=%20%5Cmathbb%7BE%7D%5B%5Ctilde%7BY%7D_%7B%5Cvarphi%7D%20%5Cmid%20X=x%5D%0A"></p>
</section>
<section id="meta-learners-as-pseudo-outcomes" class="level3">
<h3 class="anchored" data-anchor-id="meta-learners-as-pseudo-outcomes">Meta-learners as Pseudo-outcomes</h3>
<ul>
<li>흥미로운 점은, 기존에 제안된 유명한 Meta-learner들이 사실 이 <strong>Pseudo-outcome Regression</strong>의 특수한 형태(Instantiation)로 해석될 수 있다는 것입니다.</li>
<li>논문에서는 다음 세 가지 대표적인 Learner들을 재정의합니다.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Meta-learner</th>
<th style="text-align: left;">Pseudo-outcome Definition (<img src="https://latex.codecogs.com/png.latex?%5Ctilde%7BY%7D_%7B%5Cvarphi%7D">)</th>
<th style="text-align: left;">설명</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>IPW-learner</strong></td>
<td style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?%5Cdisplaystyle%20%5Cfrac%7BW-%5Cpi(X)%7D%7B%5Cpi(X)(1-%5Cpi(X))%7DY"></td>
<td style="text-align: left;">Propensity Score로 가중치를 부여하여 Factual Outcome을 재조정함. 편향은 적으나 분산이 큼.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>X-learner</strong></td>
<td style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?%5Cdisplaystyle%20W(Y-%5Chat%7B%5Cmu%7D_0(X))%20+%20(1-W)(%5Chat%7B%5Cmu%7D_1(X)-Y)"></td>
<td style="text-align: left;">처치군에서는 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmu%7D_0">를 빼고, 대조군에서는 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmu%7D_1">을 빼서 반사실적 결과를 보정(Imputation)함.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>DR-learner</strong></td>
<td style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?%5Cdisplaystyle%20%5Cfrac%7BW-%5Cpi(X)%7D%7B%5Cpi(X)(1-%5Cpi(X))%7D(Y-%5Chat%7B%5Cmu%7D_W(X))%20+%20%5Chat%7B%5Cmu%7D_1(X)%20-%20%5Chat%7B%5Cmu%7D_0(X)"></td>
<td style="text-align: left;">IPW와 Regression Adjustment를 결합한 Doubly Robust 형태. 모델 설정이 하나라도 맞으면 일치성(Consistency)을 가짐.</td>
</tr>
</tbody>
</table>
<ul>
<li>이러한 통합된 관점은 우리가 어떤 Meta-learner를 사용하든, 공통된 Conformal Prediction 절차를 적용할 수 있게 해줍니다.</li>
</ul>
</section>
</section>
<section id="conformal-pseudo-intervals-for-ites" class="level2">
<h2 class="anchored" data-anchor-id="conformal-pseudo-intervals-for-ites">3.2. Conformal Pseudo-Intervals for ITEs</h2>
<ul>
<li>이제 이 Pseudo-outcome 위에 CP를 얹어 <strong>예측 구간(Pseudo-intervals)</strong>을 생성하는 전체 알고리즘을 살펴보겠습니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/images/conformal_meta_learner_process.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: Conformal Meta-learners의 전체 구조. (Left) Nuisance Estimator를 통해 생성된 Pseudo-outcome을 사용하여 CATE Estimator를 학습한다. (Right) Calibration Set에서 계산된 Pseudo-outcome의 잔차(Conformity Score) 분포를 이용해 불확실성 구간을 계산한다.</figcaption>
</figure>
</div>
<section id="data-splitting-strategy" class="level3">
<h3 class="anchored" data-anchor-id="data-splitting-strategy">Data Splitting Strategy</h3>
<ul>
<li><p>데이터의 독립성을 보장하기 위해 전체 데이터셋 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D">를 세 개의 상호 배타적인(Mutually Exclusive) 부분집합으로 나눕니다.</p></li>
<li><ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D_%7B%5Cvarphi%7D">: Nuisance parameter (<img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cpi%7D,%20%5Chat%7B%5Cmu%7D_0,%20%5Chat%7B%5Cmu%7D_1">) 학습용</li>
</ol></li>
<li><ol start="2" type="1">
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D_%7Bt%7D">: CATE 모델(<img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Ctau%7D">) 학습용 (Pseudo-outcome 타겟 회귀)</li>
</ol></li>
<li><ol start="3" type="1">
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D_%7Bc%7D">: Calibration(보정) 및 Conformity score 계산용</li>
</ol></li>
</ul>
</section>
<section id="algorithm-steps-algorithm-1" class="level3">
<h3 class="anchored" data-anchor-id="algorithm-steps-algorithm-1">Algorithm Steps (Algorithm 1)</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/images/algorithm1.png" class="img-fluid figure-img"></p>
<figcaption>Algorithm 1: Conformal Meta-Learner</figcaption>
</figure>
</div>
<ul>
<li><ol type="1">
<li><strong>Estimation:</strong> <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D_%7B%5Cvarphi%7D">를 이용해 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cvarphi%7D%20=%20(%5Cpi,%20%5Chat%7B%5Cmu%7D_0,%20%5Chat%7B%5Cmu%7D_1)">를 추정합니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Transformation:</strong> <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D_%7Bt%7D">의 각 데이터에 대해 Pseudo-outcome <img src="https://latex.codecogs.com/png.latex?%5Ctilde%7BY%7D_%7B%5Cvarphi%7D">를 계산하고, 이를 타겟으로 하는 모델 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Ctau%7D(x)">를 학습합니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Calibration:</strong> 보정 데이터셋 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D_%7Bc%7D">에 대해 <strong>Pseudo-outcome 기반의 Conformity Score</strong>를 계산합니다. <span id="eq-(9)"><img src="https://latex.codecogs.com/png.latex?%0A%20%20V_%7B%5Cvarphi,%20k%7D(%5Chat%7B%5Ctau%7D)%20%5Ctriangleq%20V(X_k,%20%5Ctilde%7BY%7D_%7B%5Cvarphi,%20k%7D;%20%5Chat%7B%5Ctau%7D),%20%5Cquad%20%5Cforall%20k%20%5Cin%20%5Cmathcal%7BD%7D_%7Bc%7D%0A%20%20%20%5Ctag%7B9%7D"></span></li>
</ol></li>
<li><ol start="4" type="1">
<li><strong>Interval Construction:</strong> 점수들의 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha"> 분위수(Quantile)인 <img src="https://latex.codecogs.com/png.latex?Q_%7B%5Cmathcal%7BV%7D_%7B%5Cvarphi%7D%7D(1-%5Calpha)">를 구하여, 새로운 데이터 <img src="https://latex.codecogs.com/png.latex?X_%7Bn+1%7D">에 대한 구간을 반환합니다. <span id="eq-(10)"><img src="https://latex.codecogs.com/png.latex?%0A%20%20%5Chat%7BC%7D_%7B%5Cvarphi%7D(X_%7Bn+1%7D)%20=%20%5B%5Chat%7B%5Ctau%7D(X_%7Bn+1%7D)%20-%20Q_%7B%5Cmathcal%7BV%7D_%7B%5Cvarphi%7D%7D(1-%5Calpha),%20%5C;%5C;%20%5Chat%7B%5Ctau%7D(X_%7Bn+1%7D)%20+%20Q_%7B%5Cmathcal%7BV%7D_%7B%5Cvarphi%7D%7D(1-%5Calpha)%5D%0A%20%20%20%5Ctag%7B10%7D"></span></li>
</ol></li>
</ul>
</section>
<section id="why-this-solves-the-challenges" class="level3">
<h3 class="anchored" data-anchor-id="why-this-solves-the-challenges">Why this solves the challenges?</h3>
<ul>
<li><strong>Covariate Shift 해결:</strong> Pseudo-outcome <img src="https://latex.codecogs.com/png.latex?%5Ctilde%7BY%7D_%7B%5Cvarphi%7D">는 관측 데이터 <img src="https://latex.codecogs.com/png.latex?(X,%20W,%20Y)">의 함수이므로, Calibration set과 Test set의 공변량 분포가 동일합니다(Exchangeability 성립).</li>
<li><strong>Inductive Bias 분리:</strong> 어떤 Meta-learner를 쓰든 Pseudo-outcome으로 변환만 하면 되므로, CP 절차는 모델 구조와 무관(Model-agnostic)하게 적용 가능합니다.</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="validity-of-conformal-meta-learners-a-stochastic-ordering-framework" class="level1">
<h1>4. Validity of Conformal Meta-learners: A Stochastic Ordering Framework</h1>
<ul>
<li>정리하면 <strong>Conformal Meta-learners</strong>의 알고리즘과 Pseudo-outcome(<img src="https://latex.codecogs.com/png.latex?%5Ctilde%7BY%7D_%7B%5Cvarphi%7D">)을 이용해 CATE를 추정하고 예측 구간을 생성하는 과정을 살펴보았습니다.</li>
<li>하지만 여기서 우리는 아주 본질적이고 불편한 질문을 마주해야 합니다.</li>
<li>우리가 만든 구간은 <strong>Pseudo-outcome</strong>을 잘 맞추도록 설계되었습니다. 그런데 이 구간이 과연 <strong>실제 ITE (Individual Treatment Effect)</strong>를 포함한다고 보장할 수 있을까요?</li>
<li>아래에서 이 질문에 답하기 위해 저자들이 도입한 <strong>Stochastic Ordering (확률적 지배)</strong> 프레임워크와, 이를 통해 증명된 <strong>Theorem 1 &amp; 2</strong>를 검토해 보겠습니다.</li>
</ul>
<section id="the-validity-gap-exchangeability-breakdown" class="level2">
<h2 class="anchored" data-anchor-id="the-validity-gap-exchangeability-breakdown">The Validity Gap: Exchangeability Breakdown</h2>
<ul>
<li><p>Conformal Prediction(CP)의 강력함은 <strong>Exchangeability(교환 가능성)</strong> 가정에서 나옵니다. 하지만 ITE 추정 문제에서는 이 가정이 미묘하게 깨집니다.</p></li>
<li><p>우리가 비교해야 할 두 가지 대상은 다음과 같습니다.</p></li>
<li><ol type="1">
<li><strong>Pseudo-outcome Conformity Score (<img src="https://latex.codecogs.com/png.latex?V_%7B%5Cvarphi%7D">):</strong> 우리가 실제로 계산하는 값. <img src="https://latex.codecogs.com/png.latex?V_%7B%5Cvarphi%7D(%5Chat%7B%5Ctau%7D)%20=%20%7C%5Chat%7B%5Ctau%7D(X)%20-%20%5Ctilde%7BY%7D_%7B%5Cvarphi%7D%7C"></li>
</ol>
<ul>
<li>이는 Nuisance parameter <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cvarphi%7D">를 통해 변환된 Pseudo-outcome을 사용합니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Oracle Conformity Score (<img src="https://latex.codecogs.com/png.latex?V%5E*">):</strong> 우리가 알고 싶은 이상적인 값. <img src="https://latex.codecogs.com/png.latex?V%5E*(%5Chat%7B%5Ctau%7D)%20=%20%7C%5Chat%7B%5Ctau%7D(X)%20-%20(Y(1)%20-%20Y(0))%7C"></li>
</ol>
<ul>
<li>이는 실제 ITE를 사용합니다.</li>
</ul></li>
</ul>
<p><strong>문제점:</strong> 비록 Pseudo-outcome이 동일한 공변량 분포에서 나왔다 하더라도, <img src="https://latex.codecogs.com/png.latex?V_%7B%5Cvarphi%7D">와 <img src="https://latex.codecogs.com/png.latex?V%5E*">는 서로 다른 변수입니다. 따라서 <img src="https://latex.codecogs.com/png.latex?V_%7B%5Cvarphi%7D">에 대해 CP를 적용해 얻은 커버리지 보장(<img src="https://latex.codecogs.com/png.latex?1-%5Calpha">)이 <img src="https://latex.codecogs.com/png.latex?V%5E*">에 그대로 적용된다는 보장이 없습니다.</p>
<ul>
<li>저자들은 이 간극을 메우기 위해 <strong>“우리의 점수(<img src="https://latex.codecogs.com/png.latex?V_%7B%5Cvarphi%7D">)가 Oracle 점수(<img src="https://latex.codecogs.com/png.latex?V%5E*">)보다 확률적으로 더 크거나 넓게 퍼져 있다면, 구간도 더 넓어질 것이므로 안전하다”</strong>라는 논리를 펼칩니다.</li>
</ul>
</section>
<section id="stochastic-ordering-framework" class="level2">
<h2 class="anchored" data-anchor-id="stochastic-ordering-framework">Stochastic Ordering Framework</h2>
<ul>
<li>두 확률 변수의 크기나 변동성을 비교하기 위해 <strong>Stochastic Dominance(확률적 지배)</strong> 개념을 도입합니다.</li>
<li><img src="https://latex.codecogs.com/png.latex?F">와 <img src="https://latex.codecogs.com/png.latex?G">를 각각 두 확률 변수의 누적 분포 함수(CDF)라고 합시다.</li>
</ul>
<section id="definition-1.1-first-order-stochastic-dominance-fosd" class="level3">
<h3 class="anchored" data-anchor-id="definition-1.1-first-order-stochastic-dominance-fosd">Definition 1.1: First-order Stochastic Dominance (FOSD)</h3>
<p><img src="https://latex.codecogs.com/png.latex?F%20%5Cge_%7B(1)%7D%20G%20%5Ciff%20F(x)%20%5Cle%20G(x),%20%5Cquad%20%5Cforall%20x"> * <strong>의미:</strong> <img src="https://latex.codecogs.com/png.latex?F">의 CDF가 <img src="https://latex.codecogs.com/png.latex?G">보다 항상 아래에 있습니다. 이는 <img src="https://latex.codecogs.com/png.latex?F">에서 추출한 샘플이 <img src="https://latex.codecogs.com/png.latex?G">보다 <strong>확률적으로 더 큼</strong>을 의미합니다. * <strong>직관:</strong> 모든 의사결정자가 <img src="https://latex.codecogs.com/png.latex?G">보다 <img src="https://latex.codecogs.com/png.latex?F">를 선호하는 상황입니다.</p>
</section>
<section id="definition-1.2-second-order-stochastic-dominance-sosd" class="level3">
<h3 class="anchored" data-anchor-id="definition-1.2-second-order-stochastic-dominance-sosd">Definition 1.2: Second-order Stochastic Dominance (SOSD)</h3>
<p><img src="https://latex.codecogs.com/png.latex?F%20%5Cge_%7B(2)%7D%20G%20%5Ciff%20%5Cint_%7B-%5Cinfty%7D%5E%7Bx%7D%20%5BG(t)%20-%20F(t)%5D%20dt%20%5Cge%200,%20%5Cquad%20%5Cforall%20x"> * <strong>의미:</strong> 위험 회피적(Risk-averse)인 관점에서 <img src="https://latex.codecogs.com/png.latex?F">가 <img src="https://latex.codecogs.com/png.latex?G">보다 선호되지 않는 상황입니다. 통계적으로는 <img src="https://latex.codecogs.com/png.latex?F">가 <img src="https://latex.codecogs.com/png.latex?G">보다 <strong>평균은 같더라도 분산(Spread)이 더 큼</strong>을 의미할 수 있습니다.</p>
</section>
<section id="definition-2-monotone-convex-dominance-mcx" class="level3">
<h3 class="anchored" data-anchor-id="definition-2-monotone-convex-dominance-mcx">Definition 2: Monotone Convex Dominance (MCX)</h3>
<p><img src="https://latex.codecogs.com/png.latex?F%20%5Cge_%7Bmcx%7D%20G%20%5Ciff%20%5Cmathbb%7BE%7D_%7BX%20%5Csim%20F%7D%5Bu(X)%5D%20%5Cge%20%5Cmathbb%7BE%7D_%7BX%20%5Csim%20G%7D%5Bu(X)%5D"> * 단, <img src="https://latex.codecogs.com/png.latex?u">는 모든 비감소 볼록 함수(non-decreasing convex function)입니다. * <strong>의미:</strong> <img src="https://latex.codecogs.com/png.latex?F">가 <img src="https://latex.codecogs.com/png.latex?G">보다 <strong>꼬리(Tail)가 더 두꺼움(Heavier tails)</strong>을 의미합니다. 즉, 극단적인 값이 나올 확률이 더 높다는 뜻이며, 이는 CP에서 더 넓은 구간을 유도합니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/images/stochastic_dominance_illustration.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: 확률적 지배의 개념적 도식. (a) FOSD는 분포 자체가 오른쪽(큰 값)으로 이동한 형태이고, (b) SOSD/MCX는 분포가 더 넓게 퍼져 불확실성이 큰 형태를 띤다. [cite: 279]</figcaption>
</figure>
</div>
</section>
</section>
<section id="theorem-1-general-validity-condition" class="level2">
<h2 class="anchored" data-anchor-id="theorem-1-general-validity-condition">Theorem 1: General Validity Condition</h2>
<ul>
<li>이 정의들을 바탕으로 저자들은 Conformal Meta-learner가 유효하기 위한 충분 조건을 제시합니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Theorem 1.</strong> 만약 Pseudo-outcome Conformity Score <img src="https://latex.codecogs.com/png.latex?V_%7B%5Cvarphi%7D">가 Oracle Score <img src="https://latex.codecogs.com/png.latex?V%5E*">에 대해 다음 중 하나를 만족한다면:</p>
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?V_%7B%5Cvarphi%7D%20%5Cge_%7B(1)%7D%20V%5E*"> (FOSD)</li>
<li><img src="https://latex.codecogs.com/png.latex?V_%7B%5Cvarphi%7D%20%5Cle_%7B(2)%7D%20V%5E*"> (SOSD의 역방향 조건)</li>
<li><img src="https://latex.codecogs.com/png.latex?V_%7B%5Cvarphi%7D%20%5Cge_%7Bmcx%7D%20V%5E*"> (MCX)</li>
</ol>
<p>특정 범위의 <img src="https://latex.codecogs.com/png.latex?%5Calpha%20%5Cin%20(0,%20%5Calpha%5E*)">에 대하여, 다음 커버리지 보장이 성립한다. <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BP%7D(%5Ctext%7BITE%7D%20%5Cin%20%5Chat%7BC%7D_%7B%5Cvarphi%7D(X))%20%5Cge%201%20-%20%5Calpha"> [cite: 300-302]</p>
</blockquote>
<ul>
<li><strong>해석:</strong>
<ul>
<li>우리가 사용하는 점수 <img src="https://latex.codecogs.com/png.latex?V_%7B%5Cvarphi%7D">가 Oracle 점수 <img src="https://latex.codecogs.com/png.latex?V%5E*">보다 <strong>더 크거나(FOSD), 더 변동성이 크다면(MCX)</strong>, 우리가 설정한 분위수(Quantile) <img src="https://latex.codecogs.com/png.latex?Q_%7BV_%7B%5Cvarphi%7D%7D">는 Oracle 분위수 <img src="https://latex.codecogs.com/png.latex?Q_%7BV%5E*%7D">보다 크게 됩니다.</li>
<li>결과적으로 <strong>생성된 구간의 폭이 실제 필요한 폭보다 넓어지므로</strong>, 보수적인 관점에서 실제 ITE를 안전하게 포함하게 됩니다.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/images/validity_region_theorem1.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3: Theorem 1의 시각적 설명. Pseudo-score(점선)의 CDF가 Oracle-score(실선)보다 아래에 위치하거나 꼬리가 두꺼우면, 같은 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha"> 레벨에서 더 큰 Threshold 값을 가지게 되어 Validity Region에 들어간다.</figcaption>
</figure>
</div>
</section>
<section id="theorem-2-which-meta-learners-are-valid" class="level2">
<h2 class="anchored" data-anchor-id="theorem-2-which-meta-learners-are-valid">Theorem 2: Which Meta-learners are Valid?</h2>
<ul>
<li>그렇다면 우리가 앞서 살펴본 3가지 Meta-learner(IPW, X, DR) 중 어떤 것이 이 조건을 만족할까요? 이것이 논문의 핵심 발견입니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Theorem 2.</strong> Propensity score <img src="https://latex.codecogs.com/png.latex?%5Cpi(x)">가 정확히 알려져 있다고 가정할 때:</p>
<ol type="1">
<li><strong>X-learner:</strong> <img src="https://latex.codecogs.com/png.latex?V_%7B%5Cvarphi%7D">와 <img src="https://latex.codecogs.com/png.latex?V%5E*"> 사이에 모델이나 분포와 무관한(Model-free distribution-free) 확률적 순서가 존재하지 않는다.</li>
<li><strong>IPW-learner &amp; DR-learner:</strong> 모든 데이터 분포와 Nuisance estimate에 대해 다음을 만족한다. <img src="https://latex.codecogs.com/png.latex?V_%7B%5Cvarphi%7D%20%5Cge_%7Bmcx%7D%20V%5E*"> 즉, <strong>Monotone Convex Dominance</strong>를 만족하여 유효성을 보장한다.</li>
</ol>
</blockquote>
<section id="why-ipw-dr-satisfy-mcx" class="level3">
<h3 class="anchored" data-anchor-id="why-ipw-dr-satisfy-mcx">Why IPW &amp; DR satisfy MCX?</h3>
<ul>
<li>IPW와 DR-learner의 공통점은 Pseudo-outcome <img src="https://latex.codecogs.com/png.latex?%5Ctilde%7BY%7D_%7B%5Cvarphi%7D">가 CATE에 대해 <strong>비편향(Unbiased)</strong>적으로 구성된다는 점입니다. <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BE%7D%5B%5Ctilde%7BY%7D_%7B%5Cvarphi%7D%20%5Cmid%20X=x%5D%20=%20%5Ctau(x)"></li>
<li>이 구조적 특성 덕분에, Pseudo-outcome의 노이즈가 Oracle의 노이즈보다 더 크거나 같은 변동성을 가지게 됨(Convex Dominance)이 수학적으로 증명됩니다.</li>
<li>이는 Nuisance model <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmu%7D_0,%20%5Chat%7B%5Cmu%7D_1">의 성능과 무관하게 성립합니다.</li>
</ul>
</section>
<section id="why-x-learner-fails" class="level3">
<h3 class="anchored" data-anchor-id="why-x-learner-fails">Why X-learner fails?</h3>
<ul>
<li>반면 X-learner의 Pseudo-outcome은 다음과 같습니다. <img src="https://latex.codecogs.com/png.latex?%5Ctilde%7BY%7D_%7B%5Cvarphi%7D%20=%20W(Y-%5Chat%7B%5Cmu%7D_0)%20+%20(1-W)(%5Chat%7B%5Cmu%7D_1-Y)"></li>
<li>이 식은 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmu%7D_0,%20%5Chat%7B%5Cmu%7D_1"> 추정이 완벽하지 않다면 <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BE%7D%5B%5Ctilde%7BY%7D_%7B%5Cvarphi%7D%7CX%5D%20%5Cneq%20%5Ctau(x)">일 수 있습니다.</li>
<li>또한 Propensity score를 이용해 이 오차를 보정하는 구조가 아니기 때문에, 분포에 따라 <img src="https://latex.codecogs.com/png.latex?V_%7B%5Cvarphi%7D">가 <img src="https://latex.codecogs.com/png.latex?V%5E*">보다 작아질 위험(Under-coverage)이 존재합니다.</li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Meta-learner</th>
<th style="text-align: left;">Conformity Score Order</th>
<th style="text-align: left;">Validity Guarantee</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>X-learner</strong></td>
<td style="text-align: left;">No stochastic order</td>
<td style="text-align: left;">❌ Not Guaranteed</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>IPW-learner</strong></td>
<td style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?V_%7B%5Cvarphi%7D%20%5Cge_%7Bmcx%7D%20V%5E*"></td>
<td style="text-align: left;">✅ Valid</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>DR-learner</strong></td>
<td style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?V_%7B%5Cvarphi%7D%20%5Cge_%7Bmcx%7D%20V%5E*"></td>
<td style="text-align: left;">✅ Valid</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="limitations-and-discussion" class="level2">
<h2 class="anchored" data-anchor-id="limitations-and-discussion">Limitations and Discussion</h2>
<ul>
<li>이 이론은 강력하지만, 저자들은 두 가지 현실적인 한계를 솔직하게 인정합니다.</li>
</ul>
<section id="limitation-1-known-propensity-score-assumption" class="level3">
<h3 class="anchored" data-anchor-id="limitation-1-known-propensity-score-assumption">Limitation 1: Known Propensity Score Assumption</h3>
<ul>
<li>Theorem 2의 보장은 Propensity score <img src="https://latex.codecogs.com/png.latex?%5Cpi(x)">를 정확히 알고 있다는 가정하에 성립합니다.</li>
<li>RCT(무작위 대조 실험) 데이터라면 <img src="https://latex.codecogs.com/png.latex?%5Cpi(x)">가 설계에 의해 주어지므로 문제가 없습니다.</li>
<li>하지만 관측 데이터(Observational Data)라면 <img src="https://latex.codecogs.com/png.latex?%5Cpi(x)">를 추정해야 하며, 추정 오차가 발생할 경우 이론적 보장이 약화될 수 있습니다. (다만 이는 Weighted CP 등 다른 방법론들도 공유하는 문제입니다)</li>
</ul>
</section>
<section id="limitation-2-unknown-alpha" class="level3">
<h3 class="anchored" data-anchor-id="limitation-2-unknown-alpha">Limitation 2: Unknown <img src="https://latex.codecogs.com/png.latex?%5Calpha%5E*"></h3>
<ul>
<li>Theorem 1은 “특정 <img src="https://latex.codecogs.com/png.latex?%5Calpha%5E*"> 이하의 <img src="https://latex.codecogs.com/png.latex?%5Calpha">에 대해 유효하다”라고 말합니다.</li>
<li>하지만 이 임계값 <img src="https://latex.codecogs.com/png.latex?%5Calpha%5E*">가 정확히 얼마인지는 데이터 분포에 따라 다르며 사전에 알기 어렵습니다.</li>
<li>저자들은 이를 이론적으로 유도하는 것을 Future Work로 남겨두고, 실험적으로 이를 검증하는 방식을 택했습니다.</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="experiments" class="level1">
<h1>5. Experiments</h1>
<p>지난 포스트들에서는 <strong>Conformal Meta-learners</strong>의 이론적 배경과 <strong>Stochastic Ordering</strong>을 통한 유효성 증명을 살펴보았습니다.</p>
<p>이론적으로 IPW-learner와 DR-learner는 유효함이 증명되었고, X-learner는 보장할 수 없다는 결론을 얻었습니다. 이번 마지막 포스트에서는 이러한 이론적 결과가 <strong>실제 데이터(Synthetic &amp; Semi-synthetic)</strong> 실험에서도 나타나는지 확인하고, 경쟁 모델(Baselines)과 비교하여 어떤 성능 차이를 보이는지 분석합니다.</p>
<section id="experimental-setup" class="level2">
<h2 class="anchored" data-anchor-id="experimental-setup">5.1. Experimental Setup</h2>
<p>인과추론 실험의 가장 큰 어려움은 <strong>Ground Truth (실제 ITE)</strong>를 관측할 수 없다는 점입니다. 따라서 저자들은 실제 공변량을 사용하되 결과값은 시뮬레이션하는 방식 등을 도입했습니다.</p>
<section id="datasets" class="level3">
<h3 class="anchored" data-anchor-id="datasets">1.1. Datasets</h3>
<p>실험은 크게 두 가지 환경에서 진행되었습니다.</p>
<ol type="1">
<li><strong>Synthetic Datasets (완전 합성 데이터):</strong> [cite: 339-344]
<ul>
<li>공변량 <img src="https://latex.codecogs.com/png.latex?X">와 처치 <img src="https://latex.codecogs.com/png.latex?W">를 모두 생성.</li>
<li><strong>Heteroscedastic Noise Model:</strong> 오차의 분산이 공변량에 따라 달라지는 <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2(x)%20=%20-%5Clog(x_1)"> 모델을 사용하여 불확실성 추정의 난이도를 높였습니다.</li>
<li><strong>Setup A:</strong> 처치 효과가 없는 경우 (<img src="https://latex.codecogs.com/png.latex?%5Czeta=1">).</li>
<li><strong>Setup B:</strong> 이질적 처치 효과(Heterogeneous effects)가 존재하는 경우 (<img src="https://latex.codecogs.com/png.latex?%5Czeta=0">).</li>
</ul></li>
<li><strong>Semi-synthetic Datasets (준합성 데이터):</strong> [cite: 405-406]
<ul>
<li><strong>IHDP:</strong> 영유아 건강 발달 프로그램 데이터.</li>
<li><strong>NLSM:</strong> 국립 학습 사고 방식 연구 데이터.</li>
<li>실제 공변량을 사용하되, 결과 변수(Outcome)는 시뮬레이션하여 <img src="https://latex.codecogs.com/png.latex?Y(1)">과 <img src="https://latex.codecogs.com/png.latex?Y(0)">를 모두 알 수 있게 설정했습니다.</li>
</ul></li>
</ol>
</section>
<section id="baselines-비교-모델" class="level3">
<h3 class="anchored" data-anchor-id="baselines-비교-모델">1.2. Baselines (비교 모델)</h3>
<p>Conformal Meta-learner(CM)와 비교할 대상은 <strong>Weighted Conformal Prediction (WCP)</strong> 계열의 방법론들입니다. [cite: 410-414]</p>
<ul>
<li><strong>Naïve WCP:</strong> <img src="https://latex.codecogs.com/png.latex?Y(0)">와 <img src="https://latex.codecogs.com/png.latex?Y(1)"> 각각에 대해 구간을 구한 뒤, Bonferroni correction을 이용해 결합합니다. (보수적임)</li>
<li><strong>Exact Nested WCP:</strong> ITE의 Plug-in 추정치에 대해 WCP를 적용하고, 2차 CP 절차를 수행합니다. (유효성 보장됨)</li>
<li><strong>Inexact Nested WCP:</strong> Exact 방식에서 2차 CP 대신 Quantile Regression을 사용합니다. (유효성 보장 안 됨)</li>
<li><strong>CM Variants:</strong> 본 논문의 제안 방법론 (CM-IPW, CM-DR, CM-X).</li>
</ul>
<p>모든 모델은 기본 예측기(Base Learner)로 <strong>Gradient Boosting</strong>을 사용했습니다.</p>
<hr>
</section>
</section>
<section id="results-and-discussion" class="level2">
<h2 class="anchored" data-anchor-id="results-and-discussion">5.2. Results and Discussion</h2>
<section id="key-result-1-empirical-stochastic-orders" class="level3">
<h3 class="anchored" data-anchor-id="key-result-1-empirical-stochastic-orders">Key Result 1: Empirical Stochastic Orders</h3>
<p>가장 먼저 확인해야 할 것은 <strong>Theorem 1 &amp; 2</strong>의 이론적 예측이 실제 데이터 분포에서 성립하는지 여부입니다.</p>
<p>우리는 <strong>Pseudo-outcome Conformity Score (<img src="https://latex.codecogs.com/png.latex?V_%7B%5Cvarphi%7D">)</strong>의 누적 분포 함수(CDF)가 <strong>Oracle Score (<img src="https://latex.codecogs.com/png.latex?V%5E*">)</strong>의 CDF보다 아래에 위치(FOSD)하거나, 더 완만하게 증가(MCX)하기를 기대합니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/images/figure4_synthetic_results.png" class="img-fluid figure-img"></p>
<figcaption>Figure 4: 합성 데이터 실험 결과. (a) Conformity Score들의 CDF 비교. 파란색 실선(<img src="https://latex.codecogs.com/png.latex?V_%7B%5Cvarphi%7D">)이 빨간색 점선(<img src="https://latex.codecogs.com/png.latex?V%5E*">)보다 우측에 위치하면 확률적으로 더 큰 값(FOSD)임을 의미한다. DR과 IPW는 이를 만족하지만, X-learner는 반대 경향을 보인다.</figcaption>
</figure>
</div>
<section id="분석-결과-cite-416-417-480-482" class="level4">
<h4 class="anchored" data-anchor-id="분석-결과-cite-416-417-480-482">분석 결과 [cite: 416-417, 480-482]</h4>
<ul>
<li><strong>IPW &amp; DR-learner:</strong> 그래프 (a)에서 파란색 선(<img src="https://latex.codecogs.com/png.latex?V_%7B%5Cvarphi%7D">)이 빨간색 선(<img src="https://latex.codecogs.com/png.latex?V%5E*">)보다 <strong>항상 우측 하단</strong>에 위치합니다. 이는 <strong>First-Order Stochastic Dominance (FOSD)</strong>를 만족함을 보여줍니다.
<ul>
<li>FOSD는 이론적으로 요구되었던 MCX보다 훨씬 강력한 조건입니다. 즉, 이 모델들은 매우 안정적으로 유효한 구간을 생성합니다.</li>
</ul></li>
<li><strong>X-learner:</strong> 반대로 파란색 선이 빨간색 선보다 좌측 상단에 위치합니다. 이는 Pseudo-score가 실제 오차보다 과소평가됨을 의미하며, <strong>Under-coverage(커버리지 미달)</strong>로 이어질 것임을 예고합니다.</li>
</ul>
</section>
</section>
<section id="key-result-2-performance-comparison" class="level3">
<h3 class="anchored" data-anchor-id="key-result-2-performance-comparison">Key Result 2: Performance Comparison</h3>
<p>이제 실제 <strong>커버리지(Coverage)</strong>, <strong>구간 길이(Efficiency)</strong>, <strong>정확도(RMSE)</strong> 측면에서 성능을 비교해봅시다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/images/figure5_semisynthetic_results.png" class="img-fluid figure-img"></p>
<figcaption>Figure 5: 준합성 데이터(IHDP, NLSM)에서의 확률적 지배 양상. DR-learner와 IPW-learner는 Oracle Score를 지배(Dominance)하는 패턴을 유지한다.</figcaption>
</figure>
</div>
<section id="coverage-유효성-cite-484-485" class="level4">
<h4 class="anchored" data-anchor-id="coverage-유효성-cite-484-485">3.1. Coverage (유효성) [cite: 484-485]</h4>
<ul>
<li><strong>CM-DR, CM-IPW:</strong> 목표 수준인 90% (<img src="https://latex.codecogs.com/png.latex?1-%5Calpha=0.9">)를 안정적으로 달성하거나 상회했습니다.</li>
<li><strong>CM-X:</strong> 예상대로 목표 커버리지에 도달하지 못했습니다 (Under-coverage).</li>
<li><strong>Baselines:</strong> Naïve와 Exact WCP는 유효했으나, Inexact WCP는 커버리지를 보장하지 못했습니다.</li>
</ul>
</section>
<section id="efficiency-구간-길이-rmse-cite-488-490" class="level4">
<h4 class="anchored" data-anchor-id="efficiency-구간-길이-rmse-cite-488-490">3.2. Efficiency (구간 길이) &amp; RMSE [cite: 488-490]</h4>
<ul>
<li><strong>CM-DR (Winner):</strong> DR-learner는 유효한 모델들 중에서 <strong>가장 짧은 구간 길이(Interval Length)</strong>와 <strong>가장 낮은 RMSE</strong>를 기록했습니다. 즉, <strong>“정답을 포함하면서도 가장 타이트한 구간”</strong>을 제공했습니다.</li>
<li><strong>Naïve WCP:</strong> 유효하지만 구간이 너무 넓어 실용성이 떨어집니다.</li>
<li><strong>CM-X:</strong> RMSE는 가장 낮았으나(점 추정은 정확함), 구간 추정이 틀렸기 때문에 신뢰할 수 없습니다.</li>
</ul>
</section>
<section id="why-is-dr-better-than-ipw-cite-495-499" class="level4">
<h4 class="anchored" data-anchor-id="why-is-dr-better-than-ipw-cite-495-499">3.3. Why is DR better than IPW? [cite: 495-499]</h4>
<p>CM-IPW와 CM-DR 모두 유효하지만, CM-DR의 구간이 더 좁고 효율적입니다. 그 이유는 <strong>CDF의 차이(Gap)</strong>에 있습니다. * IPW의 Pseudo-outcome은 분산이 매우 큽니다. 이로 인해 Conformity score가 지나치게 커져, Oracle score와의 격차(Gap)가 벌어집니다. * 반면, DR-learner는 Regression adjustment 항 덕분에 Pseudo-outcome의 분산이 상대적으로 작습니다. 결과적으로 <img src="https://latex.codecogs.com/png.latex?V_%7B%5Cvarphi%7D">의 분포가 <img src="https://latex.codecogs.com/png.latex?V%5E*">의 분포에 더 가깝게 밀착(Tight bound)되어, 불필요하게 넓은 구간을 만들지 않습니다.</p>
<hr>
</section>
</section>
</section>
</section>
<section id="conclusions" class="level1">
<h1>6. Conclusions</h1>
<p>이 논문(<strong>Conformal Meta-learners for Predictive Inference of Individual Treatment Effects</strong>)은 인과추론의 난제인 ITE 구간 추정 문제를 해결하기 위해, Conformal Prediction과 Meta-learner를 결합한 새로운 프레임워크를 제안했습니다.</p>
<section id="핵심-요약-cite-502-505" class="level3">
<h3 class="anchored" data-anchor-id="핵심-요약-cite-502-505">핵심 요약 [cite: 502-505]</h3>
<ol type="1">
<li><strong>Framework:</strong> Pseudo-outcome을 정의하여 CATE 추정 문제를 회귀 문제로 변환하고, 그 위에 CP를 적용하여 모델에 구애받지 않는(Model-agnostic) 구간 추정 방법을 제시했습니다.</li>
<li><strong>Theory:</strong> Pseudo-score와 Oracle-score 간의 <strong>Stochastic Ordering (확률적 지배)</strong> 조건을 정립하여, 어떤 상황에서 구간이 유효한지 수학적으로 증명했습니다.</li>
<li><strong>Findings:</strong>
<ul>
<li><strong>DR-learner</strong>와 <strong>IPW-learner</strong>는 이론적/실험적으로 유효성(Validity)이 보장됩니다.</li>
<li>특히 <strong>DR-learner</strong>는 가장 효율적인(좁은) 구간을 제공하여 실용적으로 가장 우수합니다.</li>
<li><strong>X-learner</strong>는 점 추정 성능은 좋으나, 불확실성 추정에는 적합하지 않을 수 있습니다.</li>
</ul></li>
</ol>
</section>
<section id="future-work-cite-331-332-500" class="level3">
<h3 class="anchored" data-anchor-id="future-work-cite-331-332-500">Future Work [cite: 331-332, 500]</h3>
<ul>
<li>Propensity score를 모를 때의 불확실성 반영.</li>
<li>이론적인 최적 <img src="https://latex.codecogs.com/png.latex?%5Calpha%5E*"> 값의 유도.</li>
<li>Stochastic order를 유지하면서도 효율성을 극대화하는 새로운 Pseudo-outcome 변환법 연구.</li>
</ul>
<p>이로써 총 4편에 걸친 논문 리뷰를 마칩니다. 이 연구는 머신러닝 기반 인과추론 모델을 현업(의료, 정책 등)에 적용할 때 반드시 필요한 <strong>“신뢰성(Reliability)”</strong> 문제를 다루었다는 점에서 큰 의의가 있습니다.</p>



</section>
</section>

 ]]></description>
  <category>Paper Review</category>
  <guid>https://shsha0110.github.io/posts/paper/Conformal Meta-learners for Predictive Inference of Individual Treatment Effects/</guid>
  <pubDate>Thu, 29 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 15A. SDiD (Part 1)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L15A/SDiD/part-01/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<ul>
<li><p>인과 추론(Causal Inference)에서 패널 데이터(Panel Data)를 분석할 때 가장 널리 쓰이는 두 가지 방법론은 <strong>이중차분법(Difference-in-Differences, DiD)</strong>과 <strong>통제집단합성법(Synthetic Control Method, SCM)</strong>입니다.</p></li>
<li><p>하지만 이 두 방법론은 각각의 한계점을 가지고 있습니다.</p>
<ul>
<li>DiD는 엄격한 ’평행 추세 가정(Parallel Trends Assumption)’에 의존합니다.</li>
<li>SCM은 처치 유닛(treated unit)과 대조 유닛(control unit)의 레벨(level)을 강제로 맞추려고 합니다.</li>
</ul></li>
<li><p>이번 포스트에서는 Arkhangelsky et al.&nbsp;(2021)이 제안한 <strong>Synthetic Difference-in-Differences (SDiD)</strong>를 다룹니다.</p></li>
<li><p>SDiD는 DiD와 SCM의 장점을 결합하여, <strong>가중치(weights)</strong>를 통해 평행 추세를 보정하고 이원 고정 효과(Two-way Fixed Effects)를 통해 강건성(robustness)을 확보하는 방법론입니다.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L15A/SDiD/part-01/images/did_sc_sdid_comparison.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: DiD, SC, SDiD의 추정 방식 비교. (좌) DiD는 전체 대조군의 평균 추세를 평행 이동하여 반사실(counterfactual)을 추정함. (중) SC는 처치 이전 기간의 outcome 레벨까지 정확히 일치시키는 가중치를 찾음. (우) SDiD는 추세(trend)만 평행하게 맞추면 되며(절편 허용), 가중치를 통해 평행 추세 가정을 만족시키는 대조군을 합성함.</figcaption>
</figure>
</div>
<hr>
</section>
<section id="recap-fixed-effects" class="level1">
<h1>2. Recap: Fixed Effects</h1>
<ul>
<li>SDiD는 기존 방법론들의 한계를 극복하기 위해 등장했습니다.</li>
<li>이를 이해하기 위해서는 먼저 <strong>고정 효과(Fixed Effects)</strong>의 개념을 이해해야 합니다.</li>
<li>패널 데이터 분석에서 관측되지 않는 이질성(Unobserved Heterogeneity)을 통제하는 것은 인과 추론의 핵심입니다.</li>
<li>이를 위해 우리는 주로 <strong>이원 고정 효과(Two-Way Fixed Effects, TWFE)</strong> 모델을 사용합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AY_%7Bit%7D%20=%20%5Cmu%20+%20%5Calpha_i%20+%20%5Cbeta_t%20+%20%5Ctau%20X_%7Bit%7D%20+%20%5Cvarepsilon_%7Bit%7D%0A"></p>
<ul>
<li><strong>Unit Fixed Effect (<img src="https://latex.codecogs.com/png.latex?%5Calpha_i">)</strong>:
<ul>
<li>개별 유닛 <img src="https://latex.codecogs.com/png.latex?i">가 고유하게 가지는 특성으로, <strong>시간이 지나도 변하지 않는(Time-invariant)</strong> 요인입니다.</li>
<li>e.g.&nbsp;국가의 지리적 위치, 회사의 기업 문화</li>
</ul></li>
<li><strong>Time Fixed Effect (<img src="https://latex.codecogs.com/png.latex?%5Cbeta_t">)</strong>:
<ul>
<li>특정 시점 <img src="https://latex.codecogs.com/png.latex?t">에 모든 유닛에게 공통적으로 영향을 미치는 충격으로, <strong>유닛 간에 차이가 없는(Unit-invariant)</strong> 요인입니다.</li>
<li>e.g.&nbsp;거시경제적 쇼크, 팬데믹</li>
</ul></li>
<li>SDiD의 핵심 동기는 기존의 방법론들이 이 <img src="https://latex.codecogs.com/png.latex?%5Calpha_i">와 <img src="https://latex.codecogs.com/png.latex?%5Cbeta_t">를 다루는 방식에서 각각 장단점이 뚜렷하다는 점에 착안합니다.</li>
</ul>
<hr>
</section>
<section id="synthetic-difference-in-differences-sdid" class="level1">
<h1>3. Synthetic Difference-in-Differences (SDiD)</h1>
<ul>
<li>SDiD는 SCM처럼 처치 이전(pre-treatment) 추세를 맞추기 위해 재가중(reweighting)을 수행하면서도, DiD처럼 유닛 수준의 레벨 차이(additive unit-level shifts)에 불변(invariant)하도록 설계되었습니다.</li>
</ul>
<section id="setting-notation" class="level2">
<h2 class="anchored" data-anchor-id="setting-notation">3.1. Setting &amp; Notation</h2>
<ul>
<li>SDiD 모델을 이해하기 위한 기본적인 데이터 구조와 파라미터 정의는 다음과 같습니다.</li>
</ul>
<section id="data-structure" class="level3">
<h3 class="anchored" data-anchor-id="data-structure">Data Structure</h3>
<ul>
<li><strong>Balanced Panel:</strong> <img src="https://latex.codecogs.com/png.latex?N">개의 유닛과 <img src="https://latex.codecogs.com/png.latex?T">개의 시간(periods)으로 구성된 균형 패널 데이터를 가정합니다.</li>
<li><img src="https://latex.codecogs.com/png.latex?Y_%7Bit%7D">: 유닛 <img src="https://latex.codecogs.com/png.latex?i">, 시간 <img src="https://latex.codecogs.com/png.latex?t">에서의 결과 변수(Outcome).</li>
<li><img src="https://latex.codecogs.com/png.latex?X_%7Bit%7D%20%5Cin%20%5C%7B0,%201%5C%7D">: 이진 처치 여부(Binary treatment indicator).</li>
<li><strong>Units Breakdown:</strong>
<ul>
<li><strong>Control Units (<img src="https://latex.codecogs.com/png.latex?N_%7Bco%7D">):</strong> <img src="https://latex.codecogs.com/png.latex?i%20=%201,%20%5Cdots,%20N_%7Bco%7D"> (처치를 전혀 받지 않음).</li>
<li><strong>Treated Units (<img src="https://latex.codecogs.com/png.latex?N_%7Btr%7D">):</strong> <img src="https://latex.codecogs.com/png.latex?i%20=%20N_%7Bco%7D%20+%201,%20%5Cdots,%20N"> (시간 <img src="https://latex.codecogs.com/png.latex?T_%7Bpre%7D"> 이후 처치를 받음).</li>
<li><img src="https://latex.codecogs.com/png.latex?N_%7Btr%7D%20=%20N%20-%20N_%7Bco%7D"></li>
</ul></li>
</ul>
</section>
<section id="model-parameters-fixed-effects" class="level3">
<h3 class="anchored" data-anchor-id="model-parameters-fixed-effects">Model Parameters (Fixed Effects)</h3>
<ul>
<li>기존 DiD와 마찬가지로 Two-Way Fixed Effects(TWFE) 구조를 기반으로 합니다.
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmu">: <strong>Global Intercept (전체 절편)</strong>.
<ul>
<li>모든 유닛과 시점에 공통적으로 적용되는 기저 수준(Base level)입니다.</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Calpha_i">: <strong>Unit Fixed Effects (유닛 고정 효과)</strong>.
<ul>
<li>유닛 <img src="https://latex.codecogs.com/png.latex?i">가 가진 고유한 특성으로, <strong>시간에 따라 변하지 않는(Time-invariant)</strong> 이질성을 포착합니다.</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbeta_t">: <strong>Time Fixed Effects (시간 고정 효과)</strong>.
<ul>
<li>특정 시점 <img src="https://latex.codecogs.com/png.latex?t">에 모든 유닛에게 공통적으로 영향을 미치는 충격으로, <strong>유닛 간에 차이가 없는(Unit-invariant)</strong> 요인입니다.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="sdid-weights" class="level3">
<h3 class="anchored" data-anchor-id="sdid-weights">SDiD Weights</h3>
<ul>
<li>SDiD는 위 파라미터를 추정하기 전에, 데이터의 균형을 맞추기 위한 두 가지 가중치를 먼저 계산합니다.
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Comega_i">: <strong>Unit Weights (유닛 가중치)</strong>.
<ul>
<li>처치군의 <strong>추세(Trend)</strong>와 유사한 대조군을 합성하기 위해 대조 유닛들에 부여하는 가중치입니다.</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Clambda_t">: <strong>Time Weights (시간 가중치)</strong>.
<ul>
<li>처치 이전 기간(Pre-treatment) 중, 처치 이후 기간(Post-treatment)과 유사한 시점을 강조하기 위해 부여하는 가중치입니다.</li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="formulations-comparison" class="level2">
<h2 class="anchored" data-anchor-id="formulations-comparison">3.2. Formulations Comparison</h2>
<ul>
<li>세 가지 추정량(Estimator)은 <strong>최적화 문제(Minimization Problem)</strong>로 정식화하여 비교할 때 그 차이가 명확해집니다.</li>
<li>우리는 평균 인과 효과 <img src="https://latex.codecogs.com/png.latex?%5Ctau">를 추정하고자 합니다.</li>
</ul>
<section id="did-estimator" class="level3">
<h3 class="anchored" data-anchor-id="did-estimator">(1) DiD Estimator</h3>
<ul>
<li><p>DiD는 <strong>평행 추세 가정(Parallel Trends Assumption)</strong>에 기반하여 인과 효과를 추정하며, 수식적으로 <strong>Unit Fixed Effect (<img src="https://latex.codecogs.com/png.latex?%5Calpha_i">)를 허용</strong>합니다.</p></li>
<li><p><strong>Mechanism</strong></p>
<ul>
<li>처치군과 대조군 사이에 레벨(Level) 차이가 있더라도, 그 차이가 시불변(<img src="https://latex.codecogs.com/png.latex?%5Calpha_%7Btr%7D%20%5Cneq%20%5Calpha_%7Bco%7D">)한다면, 변화량의 차이(Difference-in-Differences)를 구하는 과정에서 <img src="https://latex.codecogs.com/png.latex?%5Calpha_i">가 상쇄되어 사라집니다.</li>
</ul></li>
<li><p><strong>Formulation</strong></p>
<ul>
<li>회귀분석 관점에서 DiD는 <strong>가중치 없이(unweighted)</strong> TWFE 문제를 푸는 것과 같습니다. <img src="https://latex.codecogs.com/png.latex?%0A%20%20%5Chat%7B%5Ctau%7D%5E%7BDiD%7D%20=%20%5Cunderset%7B%5Calpha,%20%5Cbeta,%20%5Cmu,%20%5Ctau%7D%7B%5Carg%20%5Cmin%7D%20%5Cleft%5C%7B%20%5Csum_%7Bi=1%7D%5E%7BN%7D%5Csum_%7Bt=1%7D%5E%7BT%7D%20(Y_%7Bit%7D%20-%20%5Cmu%20-%20%5Calpha_i%20-%20%5Cbeta_t%20-%20%5Ctau%20X_%7Bit%7D)%5E2%20%5Cright%5C%7D%0A%20%20"></li>
</ul></li>
<li><p><strong>Limitation</strong></p>
<ul>
<li>모든 대조군 유닛에 동일한 가중치(<img src="https://latex.codecogs.com/png.latex?1/N_%7Bco%7D">)를 부여합니다.</li>
<li>따라서 평행 추세 가정이 위배되는(추세가 다른) 유닛들이 대조군에 섞여 있을 경우 편향(Bias)이 발생할 수 있습니다.</li>
</ul></li>
</ul>
</section>
<section id="scm-estimator" class="level3">
<h3 class="anchored" data-anchor-id="scm-estimator">(2) SCM Estimator</h3>
<ul>
<li><p>SCM은 처치 유닛과 가장 유사한 가상의 대조군(Synthetic Control)을 만들기 위해 대조군 유닛들에 <strong>가중치(Unit weights, <img src="https://latex.codecogs.com/png.latex?%5Comega_i">)</strong>를 부여합니다.</p></li>
<li><p><strong>Mechanism</strong></p>
<ul>
<li>SCM은 처치 이전 기간의 결과 변수(<img src="https://latex.codecogs.com/png.latex?Y">)의 <strong>경로(Path)와 레벨(Level)</strong>을 모두 맞추려고 시도합니다.</li>
<li>즉, 추세뿐만 아니라 절대적인 수치까지 일치시키려 합니다.</li>
</ul></li>
<li><p><strong>Formulation</strong></p>
<ul>
<li>전통적인 SCM 추정식은 시간 고정 효과(<img src="https://latex.codecogs.com/png.latex?%5Cbeta_t">)는 포함하지만, <strong>Unit Fixed Effect (<img src="https://latex.codecogs.com/png.latex?%5Calpha_i">)와 전체 절편(Intercept)을 제외</strong>합니다. <img src="https://latex.codecogs.com/png.latex?%0A%20%20%5Chat%7B%5Ctau%7D%5E%7BSCM%7D%20=%20%5Cunderset%7B%5Cbeta,%20%5Cmu,%20%5Ctau%7D%7B%5Carg%20%5Cmin%7D%20%5Cleft%5C%7B%20%5Csum_%7Bi=1%7D%5E%7BN%7D%5Csum_%7Bt=1%7D%5E%7BT%7D%20(Y_%7Bit%7D%20-%20%5Cmu%20-%20%5Cbeta_t%20-%20%5Ctau%20X_%7Bit%7D)%5E2%20%5Ccdot%20%5Chat%7B%5Comega%7D_i%20%5Cright%5C%7D%0A%20%20"></li>
</ul></li>
<li><p><strong>Limitation</strong></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Calpha_i">를 모델에 포함하지 않기 때문에, SCM은 처치군과 대조군 간의 레벨 차이(Intercept shift)를 허용하지 않습니다.</li>
<li>즉, <strong>“평행 이동”을 허용하지 않고 절대적인 수치까지 맞춰야 하므로</strong>, 완벽하게 일치하는 대조군을 찾지 못하면(Interpolation bias) 추정 성능이 떨어질 수 있습니다.</li>
</ul></li>
</ul>
</section>
<section id="sdid-estimator" class="level3">
<h3 class="anchored" data-anchor-id="sdid-estimator">(3) SDiD Estimator</h3>
<ul>
<li><p>SDiD는 <strong>유닛 가중치 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Comega%7D_i"></strong>와 <strong>시간 가중치 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Clambda%7D_t"></strong>를 모두 사용하며, 동시에 <strong>유닛 및 시간 고정 효과(<img src="https://latex.codecogs.com/png.latex?%5Calpha_i,%20%5Cbeta_t">)</strong>를 모두 포함합니다.</p></li>
<li><p><strong>Mechanism</strong></p>
<ul>
<li><strong>Local Regression:</strong> 가중치(<img src="https://latex.codecogs.com/png.latex?%5Comega,%20%5Clambda">)를 통해 처치군과 유사한 대조군, 처치 시점과 유사한 시점을 강조합니다.</li>
<li><strong>Robustness:</strong> 고정 효과(<img src="https://latex.codecogs.com/png.latex?%5Calpha,%20%5Cbeta">)를 통해 가중치로 설명되지 않는 시스템적인 차이(Systematic differences)를 제거합니다.</li>
</ul></li>
<li><p><strong>Formulation</strong></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%20%20%5Chat%7B%5Ctau%7D%5E%7BSDiD%7D%20=%20%5Cunderset%7B%5Calpha,%20%5Cbeta,%20%5Cmu,%20%5Ctau%7D%7B%5Carg%20%5Cmin%7D%20%5Cleft%5C%7B%20%5Csum_%7Bi=1%7D%5E%7BN%7D%5Csum_%7Bt=1%7D%5E%7BT%7D%20(Y_%7Bit%7D%20-%20%5Cmu%20-%20%5Calpha_i%20-%20%5Cbeta_t%20-%20%5Ctau%20X_%7Bit%7D)%5E2%20%5Ccdot%20%5Chat%7B%5Comega%7D_i%20%5Ccdot%20%5Chat%7B%5Clambda%7D_t%20%5Cright%5C%7D%0A%20%20"></p></li>
<li><p><strong>Key Advantage</strong></p>
<ul>
<li>SCM의 유연성(Flexibility)과 DiD의 강건성(Robustness)을 결합하여, 레벨이 달라도 추세가 유사한 유닛들을 효과적으로 매칭하고 편향을 줄입니다.</li>
</ul></li>
</ul>
<hr>
</section>
</section>
<section id="summary-comparison-of-methodologies" class="level2">
<h2 class="anchored" data-anchor-id="summary-comparison-of-methodologies">Summary: Comparison of Methodologies</h2>
<ul>
<li>아래 표는 DiD, SCM, 그리고 SDiD가 고정 효과(Fixed Effect)와 가중치(Weights)를 다루는 방식의 핵심적인 차이를 요약합니다.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">구분</th>
<th style="text-align: left;"><strong>DiD</strong></th>
<th style="text-align: left;"><strong>SCM</strong></th>
<th style="text-align: left;"><strong>SDiD</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Unit Fixed Effect (<img src="https://latex.codecogs.com/png.latex?%5Calpha_i">)</strong></td>
<td style="text-align: left;"><strong>포함 (Included)</strong><br>레벨 차이(Intercept) 허용</td>
<td style="text-align: left;"><strong>미포함 (Excluded)</strong><br>절편 허용 안 함</td>
<td style="text-align: left;"><strong>포함 (Included)</strong><br>레벨 차이(Intercept) 허용</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>가중치 (Weights)</strong></td>
<td style="text-align: left;"><strong>없음 (Unweighted)</strong><br>모든 대조군 동일 가중치</td>
<td style="text-align: left;"><strong>Unit Weights (<img src="https://latex.codecogs.com/png.latex?%5Comega_i">)</strong><br>유사한 유닛에 가중치 부여</td>
<td style="text-align: left;"><strong>Unit(<img src="https://latex.codecogs.com/png.latex?%5Comega_i">) + Time(<img src="https://latex.codecogs.com/png.latex?%5Clambda_t">)</strong><br>유사한 유닛 및 시점 강조</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>매칭 조건 (Matching)</strong></td>
<td style="text-align: left;"><strong>추세 (Trend)</strong>만 평행하면 됨</td>
<td style="text-align: left;"><strong>레벨 (Level)</strong>까지 정확히 일치해야 함</td>
<td style="text-align: left;"><strong>추세 (Trend)</strong>만 평행하면 됨</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>장점과 한계</strong></td>
<td style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?%5Calpha_i">를 허용하지만,<br>가중치가 없어 유연성 부족</td>
<td style="text-align: left;">가중치로 유연하게 맞추지만,<br>레벨까지 맞춰야 하는 제약 존재</td>
<td style="text-align: left;"><strong>SCM의 유연성(가중치)</strong>과<br><strong>DiD의 강건성(FE)</strong>을 결합</td>
</tr>
</tbody>
</table>
<ul>
<li>결론적으로 <strong>SDiD</strong>는 SCM처럼 가중치를 사용하여 데이터에 유연하게 적합(Fit)시키면서도, DiD처럼 유닛 고정 효과를 도입하여 레벨이 아닌 <strong>추세(Trend)만 맞추면 되도록</strong> 설계된, 두 방법론의 장점을 결합한 접근법입니다.</li>
</ul>
<hr>
</section>
</section>
<section id="sdid-algorithm-description" class="level1">
<h1>4. SDiD Algorithm Description</h1>
<ul>
<li>SDiD 알고리즘은 크게 세 단계로 구성됩니다: <strong>(1) 유닛 가중치 계산</strong>, <strong>(2) 시간 가중치 계산</strong>, <strong>(3) 가중 회귀 분석</strong>.</li>
</ul>
<section id="step-1-compute-unit-weights-hatomega_i" class="level2">
<h2 class="anchored" data-anchor-id="step-1-compute-unit-weights-hatomega_i">Step 1: Compute Unit Weights (<img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Comega%7D_i">)</h2>
<ul>
<li>처치 이전 기간(<img src="https://latex.codecogs.com/png.latex?T_%7Bpre%7D">) 동안, 대조군들의 가중 합이 처치군의 평균 추세를 따르도록 만듭니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7B%5Comega%7D%20=%20%5Cunderset%7B%5Comega_0,%20%5Comega_%7Bco%7D%7D%7B%5Carg%20%5Cmin%7D%20%5Cleft(%20%7C%7C%20%5Coverline%7By%7D_%7Bpre,%20tr%7D%20-%20(%5Comega_0%20+%20%5Comega_%7Bco%7D%20Y_%7Bpre,%20co%7D)%20%7C%7C_2%5E2%20+%20%5Czeta%5E2%20T_%7Bpre%7D%20%7C%7C%5Comega_%7Bco%7D%7C%7C_2%5E2%20%5Cright)%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Ctext%7Bwhere%20%7D%20%5Cquad%20%5Cbar%7B%5Cmathbf%7By%7D%7D_%7Bpre,tr%7D%20&amp;=%20%5Cfrac%7B1%7D%7BN_%7Btr%7D%7D%5Csum_%7Bi=N_%7Bco%7D+1%7D%5E%7BN%7D%20Y_%7Bit%7D%20%5C%5C%0A%5Comega_%7Bco%7D%5Cmathbf%7BY%7D_%7Bpre,co%7D%20&amp;=%20%5Csum_%7Bi=1%7D%5E%7BN_%7Bco%7D%7D%5Comega_i%20Y_%7Bit%7D%0A%5Cend%7Baligned%7D%0A"></p>
<ul>
<li>여기서:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Coverline%7By%7D_%7Bpre,%20tr%7D">: 처치군들의 처치 이전 평균 추세 (벡터)</li>
<li><img src="https://latex.codecogs.com/png.latex?Y_%7Bpre,%20co%7D">: 대조군들의 처치 이전 데이터 행렬 (<img src="https://latex.codecogs.com/png.latex?T_%7Bpre%7D%20%5Ctimes%20N_%7Bco%7D">)</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?%5Comega_0"> (Intercept):</strong> SDiD의 결정적 차이점입니다. SCM과 달리 절편을 허용합니다. 즉, <strong>레벨(Level)을 맞출 필요 없이 추세(Trend)만 평행하게 맞추면 됩니다.</strong></li>
<li><strong><img src="https://latex.codecogs.com/png.latex?L_2"> Regularization (<img src="https://latex.codecogs.com/png.latex?%5Czeta">):</strong> Ridge penalty를 사용하여 가중치가 특정 유닛에 쏠리는 것을 방지하고(dispersed weights), 대조군 전체에 고르게 분포되도록 합니다.</li>
</ul></li>
</ul>
<section id="regularization-parameter-zeta" class="level3">
<h3 class="anchored" data-anchor-id="regularization-parameter-zeta">Regularization Parameter <img src="https://latex.codecogs.com/png.latex?%5Czeta"></h3>
<ul>
<li>정규화 파라미터 <img src="https://latex.codecogs.com/png.latex?%5Czeta">는 데이터의 변동성에 기반하여 다음과 같이 결정됩니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Czeta%20=%20(N_%7Btr%7D%20%5Ccdot%20T_%7Bpost%7D)%5E%7B1/4%7D%20%5Chat%7B%5Csigma%7D(%5CDelta_%7Bit%7D)%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Ctext%7Bwhere%20%7D%20%5Cquad%20%5CDelta_%7Bit%7D%20&amp;=%20Y_%7Bi(t+1)%7D%20-%20Y_%7Bit%7D%20%5C%5C%0A%5Cbar%7B%5CDelta%7D%20&amp;=%20%5Cfrac%7B1%7D%7BN_%7Bco%7D(T_%7Bpre%7D-1)%7D%20%5Csum_%7Bi=1%7D%5E%7BN_%7Bco%7D%7D%20%5Csum_%7Bt=1%7D%5E%7BT_%7Bpre%7D-1%7D%20%5CDelta_%7Bit%7D%20%5C%5C%0A%5Chat%7B%5Csigma%7D%5E2(%5CDelta_%7Bit%7D)%20&amp;=%20%5Cfrac%7B1%7D%7BN_%7Bco%7D(T_%7Bpre%7D-1)%7D%20%5Csum_%7Bi=1%7D%5E%7BN_%7Bco%7D%7D%20%5Csum_%7Bt=1%7D%5E%7BT_%7Bpre%7D-1%7D%20(%5CDelta_%7Bit%7D%20-%20%5Cbar%7B%5CDelta%7D)%5E2%0A%5Cend%7Baligned%7D%0A"></p>
<ul>
<li>이때 <img src="https://latex.codecogs.com/png.latex?%5CDelta_%7Bit%7D">는 결과 변수의 1차 차분(first difference, <img src="https://latex.codecogs.com/png.latex?Y_%7Bit%7D%20-%20Y_%7Bi(t-1)%7D">)이며, <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Csigma%7D">는 이 차분 값들의 표준편차입니다.</li>
<li>이는 시계열적 변동성이 클수록 페널티를 강하게 주어 과적합을 막겠다는 의도입니다.</li>
</ul>
</section>
</section>
<section id="step-2-compute-time-weights-hatlambda_t" class="level2">
<h2 class="anchored" data-anchor-id="step-2-compute-time-weights-hatlambda_t">Step 2: Compute Time Weights (<img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Clambda%7D_t">)</h2>
<ul>
<li>SDiD는 <strong>시간 가중치</strong>도 계산합니다.</li>
<li><ul>
<li>이는 처치 이전 시점들(<img src="https://latex.codecogs.com/png.latex?1%20%5Cdots%20T_%7Bpre%7D">) 중, 처치 이후 시점(<img src="https://latex.codecogs.com/png.latex?T_%7Bpost%7D">)과 유사한 시점에 더 큰 가중치를 부여하기 위함입니다.</li>
</ul></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7B%5Clambda%7D%20=%20%5Cunderset%7B%5Clambda_0,%20%5Clambda_%7Bpre%7D%7D%7B%5Carg%20%5Cmin%7D%20%7C%7C%20%5Coverline%7By%7D_%7Bpost,%20co%7D%20-%20(%5Clambda_0%20+%20%5Clambda_%7Bpre%7D%20Y_%7Bpre,%20co%7D)%20%7C%7C_2%5E2%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Ctext%7Bwhere%20%7D%20%5Cquad%20%5Cbar%7B%5Cmathbf%7By%7D%7D_%7Bpost,co%7D%20&amp;=%20%5Cfrac%7B1%7D%7BT_%7Bpost%7D%7D%20%5Csum_%7Bt=T_%7Bpre%7D+1%7D%5E%7BT%7D%20Y_%7Bit%7D%20%5C%5C%0A%5Cboldsymbol%7B%5Clambda%7D_%7Bpre%7D%5Cmathbf%7BY%7D_%7Bpre,co%7D%20&amp;=%20%5Csum_%7Bt=1%7D%5E%7BT_%7Bpre%7D%7D%20%5Clambda_t%20Y_%7Bit%7D%0A%5Cend%7Baligned%7D%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Coverline%7By%7D_%7Bpost,%20co%7D">: 대조군의 처치 이후 평균 (스칼라 혹은 벡터)</li>
<li>이 과정은 대조군 내에서 “처치 이전 기간의 가중 합”이 “처치 이후 기간”과 유사해지도록 만듭니다. 이를 통해 시간적 편향(bias)을 제거합니다.</li>
</ul>
</section>
<section id="step-3-weighted-did-regression" class="level2">
<h2 class="anchored" data-anchor-id="step-3-weighted-did-regression">Step 3: Weighted DiD Regression</h2>
<ul>
<li>구해진 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Comega%7D_i">와 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Clambda%7D_t">를 사용하여 최종적으로 가중 이원 고정 효과(Weighted TWFE) 회귀를 수행합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A(%5Chat%7B%5Ctau%7D%5E%7BSDiD%7D,%20%5Chat%7B%5Cmu%7D,%20%5Chat%7B%5Calpha%7D,%20%5Chat%7B%5Cbeta%7D)%20=%20%5Cunderset%7B%5Ctau,%20%5Cmu,%20%5Calpha,%20%5Cbeta%7D%7B%5Carg%20%5Cmin%7D%20%5Cleft%5C%7B%20%5Csum_%7Bi=1%7D%5E%7BN%7D%5Csum_%7Bt=1%7D%5E%7BT%7D%20(Y_%7Bit%7D%20-%20%5Cmu%20-%20%5Calpha_i%20-%20%5Cbeta_t%20-%20%5Ctau%20X_%7Bit%7D)%5E2%20%5Chat%7B%5Comega%7D_i%20%5Chat%7B%5Clambda%7D_t%20%5Cright%5C%7D%0A"></p>
<ul>
<li>이 회귀분석의 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Ctau%7D"> 값이 바로 SDiD가 추정한 인과 효과입니다.</li>
</ul>
<hr>
</section>
<section id="appendix-closed-form-solution" class="level2">
<h2 class="anchored" data-anchor-id="appendix-closed-form-solution">Appendix: Closed-Form Solution</h2>
<section id="weighted-twfe-objective-function" class="level3">
<h3 class="anchored" data-anchor-id="weighted-twfe-objective-function">1. Weighted TWFE Objective Function</h3>
<ul>
<li>SDiD는 다음의 <strong>가중 잔차 제곱합(Weighted Sum of Squared Residuals)</strong>을 최소화하는 파라미터 <img src="https://latex.codecogs.com/png.latex?%5C%7B%5Ctau,%20%5Cmu,%20%5Calpha,%20%5Cbeta%5C%7D">를 찾습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_%7B%5Ctau,%20%5Cmu,%20%5Calpha,%20%5Cbeta%7D%20%5Csum_%7Bi=1%7D%5EN%20%5Csum_%7Bt=1%7D%5ET%20%5Cleft(%20Y_%7Bit%7D%20-%20%5Cmu%20-%20%5Calpha_i%20-%20%5Cbeta_t%20-%20%5Ctau%20X_%7Bit%7D%20%5Cright)%5E2%20%5Chat%7B%5Comega%7D_i%20%5Chat%7B%5Clambda%7D_t%0A"> * <img src="https://latex.codecogs.com/png.latex?X_%7Bit%7D">: 처치군(<img src="https://latex.codecogs.com/png.latex?tr">)이면서 처치 후(<img src="https://latex.codecogs.com/png.latex?post">)일 때 <img src="https://latex.codecogs.com/png.latex?1">, 그 외 <img src="https://latex.codecogs.com/png.latex?0"> (Treatment Indicator) * <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Comega%7D_i,%20%5Chat%7B%5Clambda%7D_t">: Step 1, 2에서 미리 구해둔 유닛 및 시간 가중치</p>
</section>
<section id="first-order-condition-foc-w.r.t-tau" class="level3">
<h3 class="anchored" data-anchor-id="first-order-condition-foc-w.r.t-tau">2. First Order Condition (FOC) w.r.t <img src="https://latex.codecogs.com/png.latex?%5Ctau"></h3>
<ul>
<li>목적함수를 <img src="https://latex.codecogs.com/png.latex?%5Ctau">에 대해 편미분하고 <img src="https://latex.codecogs.com/png.latex?0">으로 둡니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20%5Ctau%7D%20=%20-2%20%5Csum_%7Bi=1%7D%5EN%20%5Csum_%7Bt=1%7D%5ET%20%5Chat%7B%5Comega%7D_i%20%5Chat%7B%5Clambda%7D_t%20%5Cleft(%20Y_%7Bit%7D%20-%20%5Cmu%20-%20%5Calpha_i%20-%20%5Cbeta_t%20-%20%5Ctau%20X_%7Bit%7D%20%5Cright)%20X_%7Bit%7D%20=%200%0A"></p>
<ul>
<li>여기서 <img src="https://latex.codecogs.com/png.latex?X_%7Bit%7D=1">인 경우(즉, 처치군의 사후 기간)만 항이 살아남으므로, 식을 정리하면 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Ctau%7D">는 <strong>“관측된 값”</strong>과 <strong>“반사실적(Counterfactual) 추정치”</strong>의 차이가 됩니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7B%5Ctau%7D%5E%7BSDiD%7D%20=%20%5Cunderbrace%7B%5Cbar%7BY%7D_%7Btr,%20post%7D%7D_%7B%5Ctext%7BObserved%7D%7D%20-%20%5Cunderbrace%7B(%5Chat%7B%5Cmu%7D%20+%20%5Chat%7B%5Calpha%7D_%7Btr%7D%20+%20%5Chat%7B%5Cbeta%7D_%7Bpost%7D)%7D_%7B%5Ctext%7BCounterfactual%20%7D%20%5Chat%7BY%7D(0)%7D%0A"></p>
<ul>
<li>이제 우리의 목표는 미지의 파라미터 조합 <strong><img src="https://latex.codecogs.com/png.latex?(%5Chat%7B%5Cmu%7D%20+%20%5Chat%7B%5Calpha%7D_%7Btr%7D%20+%20%5Chat%7B%5Cbeta%7D_%7Bpost%7D)"></strong>를 우리가 아는 <strong>데이터의 가중 평균(3개의 항)</strong>으로 표현하는 것입니다.</li>
</ul>
</section>
<section id="parameter-decomposition-via-normal-equations" class="level3">
<h3 class="anchored" data-anchor-id="parameter-decomposition-via-normal-equations">3. Parameter Decomposition via Normal Equations</h3>
<ul>
<li>최소자승법의 1계 조건(FOC)은 <strong>“잔차의 합을 0으로 만든다”</strong>는 성질이 있습니다.</li>
<li>이를 이용해 관측 가능한 세 가지 항을 유도합니다.</li>
<li>단, 가중치의 합은 1로 정규화되어 있다고 가정합니다: <img src="https://latex.codecogs.com/png.latex?%5Csum%20%5Chat%7B%5Comega%7D_i%20=%201,%20%5Csum%20%5Chat%7B%5Clambda%7D_t%20=%201"></li>
</ul>
<section id="처치군의-사전-기간-bary_tr-prelambda" class="level4">
<h4 class="anchored" data-anchor-id="처치군의-사전-기간-bary_tr-prelambda">3-1. 처치군의 사전 기간 (<img src="https://latex.codecogs.com/png.latex?%5Cbar%7BY%7D_%7Btr,%20pre%7D%5E%7B%5Clambda%7D">)</h4>
<ul>
<li>처치 유닛(<img src="https://latex.codecogs.com/png.latex?i=tr">)과 사전 기간(<img src="https://latex.codecogs.com/png.latex?t%20%5Cin%20Pre">)에 해당하는 목적함수를 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Calpha%7D_%7Btr%7D">에 대해 편미분합니다.</li>
<li>이 기간에는 <img src="https://latex.codecogs.com/png.latex?X_%7Bit%7D=0">이므로 <img src="https://latex.codecogs.com/png.latex?%5Ctau"> 항은 사라집니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%5Cpartial%20L_%7Btr%7D%7D%7B%5Cpartial%20%5Chat%7B%5Calpha%7D_%7Btr%7D%7D%20=%20-2%20%5Csum_%7Bt=1%7D%5E%7BT_%7Bpre%7D%7D%20%5Chat%7B%5Clambda%7D_t%20(Y_%7Btr,t%7D%20-%20%5Chat%7B%5Cmu%7D%20-%20%5Chat%7B%5Calpha%7D_%7Btr%7D%20-%20%5Chat%7B%5Cbeta%7D_t)%20=%200%0A"></p>
<ul>
<li>시그마를 분배하고 정리하면 다음과 같습니다.</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Csum%20%5Chat%7B%5Clambda%7D_t%20=%201"> 적용</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cunderbrace%7B%5Csum%20%5Chat%7B%5Clambda%7D_t%20Y_%7Btr,t%7D%7D_%7B%5Cbar%7BY%7D_%7Btr,%20pre%7D%5E%7B%5Clambda%7D%7D%20=%20%5Chat%7B%5Cmu%7D%5Cunderbrace%7B%5Csum%20%5Chat%7B%5Clambda%7D_t%7D_%7B1%7D%20+%20%5Chat%7B%5Calpha%7D_%7Btr%7D%5Cunderbrace%7B%5Csum%20%5Chat%7B%5Clambda%7D_t%7D_%7B1%7D%20+%20%5Cunderbrace%7B%5Csum%20%5Chat%7B%5Clambda%7D_t%20%5Chat%7B%5Cbeta%7D_t%7D_%7B%5Cbar%7B%5Cbeta%7D_%7Bpre%7D%5E%7B%5Clambda%7D%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctherefore%20%5Cquad%20%5Cbar%7BY%7D_%7Btr,%20pre%7D%5E%7B%5Clambda%7D%20=%20%5Chat%7B%5Cmu%7D%20+%20%5Chat%7B%5Calpha%7D_%7Btr%7D%20+%20%5Cbar%7B%5Cbeta%7D_%7Bpre%7D%5E%7B%5Clambda%7D%20%5Cquad%20%5Ccdots%20%5Ctext%7B(%EC%8B%9D%201)%7D%0A"></p>
</section>
<section id="통제군의-사후-기간-bary_co-postomega" class="level4">
<h4 class="anchored" data-anchor-id="통제군의-사후-기간-bary_co-postomega">3-2. 통제군의 사후 기간 (<img src="https://latex.codecogs.com/png.latex?%5Cbar%7BY%7D_%7Bco,%20post%7D%5E%7B%5Comega%7D">)</h4>
<ul>
<li>통제 유닛들(<img src="https://latex.codecogs.com/png.latex?i%20%5Cin%20Co">)과 사후 기간(<img src="https://latex.codecogs.com/png.latex?t=post">)에 해당하는 목적함수를 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cbeta%7D_%7Bpost%7D">에 대해 편미분합니다.</li>
<li>통제군이므로 <img src="https://latex.codecogs.com/png.latex?X_%7Bit%7D=0">, 따라서 <img src="https://latex.codecogs.com/png.latex?%5Ctau"> 항은 사라집니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%5Cpartial%20L_%7Bpost%7D%7D%7B%5Cpartial%20%5Chat%7B%5Cbeta%7D_%7Bpost%7D%7D%20=%20-2%20%5Csum_%7Bi=1%7D%5E%7BN_%7Bco%7D%7D%20%5Chat%7B%5Comega%7D_i%20(Y_%7Bi,%20post%7D%20-%20%5Chat%7B%5Cmu%7D%20-%20%5Chat%7B%5Calpha%7D_i%20-%20%5Chat%7B%5Cbeta%7D_%7Bpost%7D)%20=%200%0A"></p>
<ul>
<li>마찬가지로 정리합니다.</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Csum%20%5Chat%7B%5Comega%7D_i%20=%201"> 적용</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cunderbrace%7B%5Csum%20%5Chat%7B%5Comega%7D_i%20Y_%7Bi,%20post%7D%7D_%7B%5Cbar%7BY%7D_%7Bco,%20post%7D%5E%7B%5Comega%7D%7D%20=%20%5Chat%7B%5Cmu%7D%5Cunderbrace%7B%5Csum%20%5Chat%7B%5Comega%7D_i%7D_%7B1%7D%20+%20%5Cunderbrace%7B%5Csum%20%5Chat%7B%5Comega%7D_i%20%5Chat%7B%5Calpha%7D_i%7D_%7B%5Cbar%7B%5Calpha%7D_%7Bco%7D%5E%7B%5Comega%7D%7D%20+%20%5Chat%7B%5Cbeta%7D_%7Bpost%7D%5Cunderbrace%7B%5Csum%20%5Chat%7B%5Comega%7D_i%7D_%7B1%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctherefore%20%5Cquad%20%5Cbar%7BY%7D_%7Bco,%20post%7D%5E%7B%5Comega%7D%20=%20%5Chat%7B%5Cmu%7D%20+%20%5Cbar%7B%5Calpha%7D_%7Bco%7D%5E%7B%5Comega%7D%20+%20%5Chat%7B%5Cbeta%7D_%7Bpost%7D%20%5Cquad%20%5Ccdots%20%5Ctext%7B(%EC%8B%9D%202)%7D%0A"></p>
</section>
<section id="통제군의-사전-기간-bary_co-preomega-lambda" class="level4">
<h4 class="anchored" data-anchor-id="통제군의-사전-기간-bary_co-preomega-lambda">3-3. 통제군의 사전 기간 (<img src="https://latex.codecogs.com/png.latex?%5Cbar%7BY%7D_%7Bco,%20pre%7D%5E%7B%5Comega,%20%5Clambda%7D">)</h4>
<ul>
<li>통제 유닛(<img src="https://latex.codecogs.com/png.latex?i%20%5Cin%20Co">)과 사전 기간(<img src="https://latex.codecogs.com/png.latex?t%20%5Cin%20Pre">) 전체에 대해 편미분(혹은 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmu%7D">에 대한 FOC)을 적용합니다. (<img src="https://latex.codecogs.com/png.latex?X_%7Bit%7D=0">)</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi=1%7D%5E%7BN_%7Bco%7D%7D%20%5Csum_%7Bt=1%7D%5E%7BT_%7Bpre%7D%7D%20%5Chat%7B%5Comega%7D_i%20%5Chat%7B%5Clambda%7D_t%20(Y_%7Bit%7D%20-%20%5Chat%7B%5Cmu%7D%20-%20%5Chat%7B%5Calpha%7D_i%20-%20%5Chat%7B%5Cbeta%7D_t)%20=%200%0A"></p>
<ul>
<li>이중 시그마를 풀면 다음과 같습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbar%7BY%7D_%7Bco,%20pre%7D%5E%7B%5Comega,%20%5Clambda%7D%20=%20%5Chat%7B%5Cmu%7D(%5Csum%20%5Comega%20%5Csum%20%5Clambda)%20+%20(%5Csum%20%5Comega%20%5Chat%7B%5Calpha%7D_i)(%5Csum%20%5Clambda)%20+%20(%5Csum%20%5Clambda%20%5Chat%7B%5Cbeta%7D_t)(%5Csum%20%5Comega)%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctherefore%20%5Cquad%20%5Cbar%7BY%7D_%7Bco,%20pre%7D%5E%7B%5Comega,%20%5Clambda%7D%20=%20%5Chat%7B%5Cmu%7D%20+%20%5Cbar%7B%5Calpha%7D_%7Bco%7D%5E%7B%5Comega%7D%20+%20%5Cbar%7B%5Cbeta%7D_%7Bpre%7D%5E%7B%5Clambda%7D%20%5Cquad%20%5Ccdots%20%5Ctext%7B(%EC%8B%9D%203)%7D%0A"></p>
</section>
</section>
<section id="cancellation-derivation" class="level3">
<h3 class="anchored" data-anchor-id="cancellation-derivation">4. Cancellation &amp; Derivation</h3>
<ul>
<li>위에서 유도한 세 식을 조합하여 <strong>반사실적 추정치</strong>를 만들어냅니다.</li>
<li><strong>(식 1) + (식 2) - (식 3)</strong>을 계산하면, 우리가 원하지 않는 파라미터들이 소거됩니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A&amp;%20%5Cquad%20%5Cunderbrace%7B(%5Chat%7B%5Cmu%7D%20+%20%5Chat%7B%5Calpha%7D_%7Btr%7D%20+%20%5Cbar%7B%5Cbeta%7D_%7Bpre%7D%5E%7B%5Clambda%7D)%7D_%7B%5Ctext%7B%E2%91%A0%20Treated,%20Pre%7D%7D%20+%20%5Cunderbrace%7B(%5Chat%7B%5Cmu%7D%20+%20%5Cbar%7B%5Calpha%7D_%7Bco%7D%5E%7B%5Comega%7D%20+%20%5Chat%7B%5Cbeta%7D_%7Bpost%7D)%7D_%7B%5Ctext%7B%E2%91%A1%20Control,%20Post%7D%7D%20-%20%5Cunderbrace%7B(%5Chat%7B%5Cmu%7D%20+%20%5Cbar%7B%5Calpha%7D_%7Bco%7D%5E%7B%5Comega%7D%20+%20%5Cbar%7B%5Cbeta%7D_%7Bpre%7D%5E%7B%5Clambda%7D)%7D_%7B%5Ctext%7B%E2%91%A2%20Control,%20Pre%7D%7D%20%5C%5C%0A%5C%5C%0A&amp;=%20(%5Chat%7B%5Cmu%7D%20+%20%5Chat%7B%5Cmu%7D%20-%20%5Chat%7B%5Cmu%7D)%20+%20%5Chat%7B%5Calpha%7D_%7Btr%7D%20+%20%5Chat%7B%5Cbeta%7D_%7Bpost%7D%20+%20%5Cunderbrace%7B(%5Cbar%7B%5Calpha%7D_%7Bco%7D%5E%7B%5Comega%7D%20-%20%5Cbar%7B%5Calpha%7D_%7Bco%7D%5E%7B%5Comega%7D)%7D_%7B%5Ctext%7BUnit%20FE%20Cancel%7D%7D%20+%20%5Cunderbrace%7B(%5Cbar%7B%5Cbeta%7D_%7Bpre%7D%5E%7B%5Clambda%7D%20-%20%5Cbar%7B%5Cbeta%7D_%7Bpre%7D%5E%7B%5Clambda%7D)%7D_%7B%5Ctext%7BTime%20FE%20Cancel%7D%7D%20%5C%5C%0A%5C%5C%0A&amp;=%20%5Cmathbf%7B%5Chat%7B%5Cmu%7D%20+%20%5Chat%7B%5Calpha%7D_%7Btr%7D%20+%20%5Chat%7B%5Cbeta%7D_%7Bpost%7D%7D%20%5Cquad%20(=%20%5Ctext%7BCounterfactual%7D)%0A%5Cend%7Baligned%7D%0A"></p>
</section>
<section id="final-result" class="level3">
<h3 class="anchored" data-anchor-id="final-result">5. Final Result</h3>
<ul>
<li>따라서 FOC에서 도출된 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Ctau%7D"> 식에 대입하면, 최종적으로 <strong>2x2 DID</strong> 형태가 완성됩니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Chat%7B%5Ctau%7D%5E%7BSDiD%7D%20&amp;=%20%5Cbar%7BY%7D_%7Btr,%20post%7D%20-%20%5Ctext%7BCounterfactual%7D%20%5C%5C%0A&amp;=%20%5Cbar%7BY%7D_%7Btr,%20post%7D%20-%20%5Cleft(%20%5Cbar%7BY%7D_%7Btr,%20pre%7D%5E%7B%5Clambda%7D%20+%20%5Cbar%7BY%7D_%7Bco,%20post%7D%5E%7B%5Comega%7D%20-%20%5Cbar%7BY%7D_%7Bco,%20pre%7D%5E%7B%5Comega,%20%5Clambda%7D%20%5Cright)%20%5C%5C%0A&amp;=%20(%5Cbar%7BY%7D_%7Btr,%20post%7D%20-%20%5Cbar%7BY%7D_%7Btr,%20pre%7D%5E%7B%5Clambda%7D)%20-%20(%5Cbar%7BY%7D_%7Bco,%20post%7D%5E%7B%5Comega%7D%20-%20%5Cbar%7BY%7D_%7Bco,%20pre%7D%5E%7B%5Comega,%20%5Clambda%7D)%0A%5Cend%7Baligned%7D%0A"></p>
<hr>
</section>
</section>
</section>
<section id="interpretation-why-sdid" class="level1">
<h1>5. Interpretation: Why SDiD?</h1>
<section id="vs.-did" class="level2">
<h2 class="anchored" data-anchor-id="vs.-did">5.1. vs.&nbsp;DiD</h2>
<ul>
<li><strong>Local Fitting:</strong> DiD는 모든 대조군과 모든 시점을 동일하게 취급하지만, SDiD는 처치군과 유사한 과거를 가진 유닛, 처치 시기와 유사한 특성을 가진 시점을 강조(weighting)하여 “Local”한 회귀를 수행합니다.</li>
<li><strong>Precision:</strong> 가중치를 통해 결과 변수의 시스템적이고 예측 가능한 부분을 제거함으로써 추정의 정밀도(precision)를 높입니다.</li>
</ul>
</section>
<section id="vs.-scm" class="level2">
<h2 class="anchored" data-anchor-id="vs.-scm">5.2. vs.&nbsp;SCM</h2>
<ul>
<li><strong>Parallelism over Levels:</strong> SCM은 Outcome의 절대적인 수치(Level)까지 맞춰야 하지만, SDiD는 유닛 고정 효과(<img src="https://latex.codecogs.com/png.latex?%5Calpha_i">)와 절편(<img src="https://latex.codecogs.com/png.latex?%5Comega_0">)을 포함하므로 <strong>평행 추세만 만족하면 됩니다.</strong> 이는 더 유연한 매칭을 가능하게 합니다.</li>
<li><strong>Bias Removal:</strong> 시간 가중치(<img src="https://latex.codecogs.com/png.latex?%5Clambda_t">)를 도입하여, 처치 이후 기간과 성격이 매우 다른 처치 이전 기간의 영향력을 배제하여 편향을 줄입니다.</li>
<li><strong>Robustness:</strong> 유닛 고정 효과는 결과 변수의 변동 중 상당 부분을 설명하므로, 모델의 강건성을 높여줍니다.</li>
</ul>
<hr>
</section>
</section>
<section id="key-takeaways" class="level1">
<h1>6. Key Takeaways</h1>
<ol type="1">
<li><strong>Trend Matching:</strong> SDiD는 SCM처럼 처치 이전 추세를 맞추지만, 레벨(Level)이 아닌 <strong>변화(Trend)</strong>가 평행하도록 가중치를 학습합니다 (Intercept <img src="https://latex.codecogs.com/png.latex?%5Comega_0"> 허용).</li>
<li><strong>Regularization:</strong> 유닛 가중치 계산 시 <img src="https://latex.codecogs.com/png.latex?L_2"> Norm을 사용하여 가중치가 특정 소수 유닛에 집중되는 SCM의 문제를 완화하고, 대조군 전반에 퍼지도록 합니다.</li>
<li><strong>Time Weights:</strong> DiD나 SCM에는 없는 <strong>시간 가중치(<img src="https://latex.codecogs.com/png.latex?%5Clambda_t">)</strong>를 도입하여, 처치 전후 기간의 구조적 차이에서 오는 편향을 보정합니다.</li>
<li><strong>Efficiency:</strong> 유닛/시간 고정 효과와 가중치를 동시에 활용함으로써 추정량의 분산을 줄이고 인과 효과 추정의 신뢰도를 높입니다.</li>
</ol>



</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L15A/SDiD/part-01/</guid>
  <pubDate>Sat, 24 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 15A. SDiD (Part 2)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L15A/SDiD/part-02/</link>
  <description><![CDATA[ 





<section id="개요-introduction" class="level1">
<h1>개요 (Introduction)</h1>
<ul>
<li><p>인과 추론(Causal Inference)에서 가장 널리 쓰이는 <strong>이중차분법(DiD)</strong>은 ’평행 추세 가정(Parallel Trends Assumption)’에 크게 의존합니다.</p></li>
<li><p>하지만 현실 데이터에서는 처치군과 대조군의 추세가 평행하지 않은 경우가 많습니다.</p></li>
<li><p>이를 보완하기 위해 <strong>Synthetic Control Method (SCM)</strong>이 등장했지만, SCM 역시 제약이 있습니다.</p></li>
<li><p><strong>Synthetic Difference in Differences (SDiD)</strong>는 DiD와 SCM의 장점을 결합하여, 평행 추세가 위배되는 상황에서도 더욱 강건한(robust) 추정치를 제공합니다.</p></li>
<li><p>이번 포스트에서는 파이썬을 사용하여 SDiD를 직접 구현해보고, 평행 추세가 위배되는 시뮬레이션 데이터를 통해 DiD, SCM과 성능을 비교해 봅니다.</p></li>
</ul>
</section>
<section id="sdid의-핵심-아이디어" class="level1">
<h1>SDiD의 핵심 아이디어</h1>
<ul>
<li><p>SDiD는 크게 두 단계의 가중치(Weighting) 과정을 거쳐 추정량을 도출합니다.</p></li>
<li><ol type="1">
<li><strong>Unit Weights (<img src="https://latex.codecogs.com/png.latex?%5Comega">)</strong>: 대조군(Control Units)들에 가중치를 부여하여, 처치 전 기간(Pre-treatment) 동안 처치군(Treated Unit)의 추세와 유사하게 만듭니다. (SCM의 아이디어)</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Time Weights (<img src="https://latex.codecogs.com/png.latex?%5Clambda">)</strong>: 처치 전 시점(Pre-periods)들에 가중치를 부여하여, 처치 후 시점(Post-periods)의 특성과 유사하게 만듭니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Weighted DiD</strong>: 구해진 가중치를 적용하여 이중차분법을 수행합니다.</li>
</ol></li>
</ul>
</section>
<section id="import-library" class="level1">
<h1>0. Import Library</h1>
<ul>
<li><code>cvxpy</code> 라이브러리를 사용하여 최적화 문제를 풉니다.</li>
</ul>
<div id="4dc3cb9e" class="cell" data-execution_count="1">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> cvxpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> cp</span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> statsmodels.api <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sm</span>
<span id="cb1-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> statsmodels.formula.api <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> smf</span></code></pre></div></div>
</details>
</div>
</section>
<section id="define-syntheticdid-class" class="level1">
<h1>1. Define SyntheticDiD Class</h1>
<ul>
<li>Python의 <code>SyntheticDiD</code> 클래스는 처치군(Treated)과 통제군(Control) 데이터를 입력받아, SDiD 추정량을 산출하는 핵심 로직을 담고 있습니다.</li>
<li>주요 단계는 초기화, 유닛 가중치 계산, 시간 가중치 계산, 그리고 최종 효과 추정으로 나뉩니다.</li>
</ul>
<section id="초기화-initialization" class="level2">
<h2 class="anchored" data-anchor-id="초기화-initialization">초기화 (Initialization)</h2>
<ul>
<li>입력된 데이터를 처치 시점(<img src="https://latex.codecogs.com/png.latex?T_%7Bpre%7D">)을 기준으로 <strong>Pre-period</strong>와 <strong>Post-period</strong>로 분리하고, 행렬 연산에 적합한 형태로 변환합니다.
<ul>
<li><strong>Inputs</strong>: <img src="https://latex.codecogs.com/png.latex?Y_%7Bco%7D"> (Control Data), <img src="https://latex.codecogs.com/png.latex?Y_%7Btr%7D"> (Treated Data), <img src="https://latex.codecogs.com/png.latex?T_%7Bpre%7D"> (Intervention Time)</li>
<li><strong>Split</strong>: <img src="https://latex.codecogs.com/png.latex?Y_%7Bpre,%20co%7D,%20Y_%7Bpre,%20tr%7D"> 등으로 데이터를 슬라이싱합니다.</li>
</ul></li>
</ul>
</section>
<section id="단위-가중치-unit-weights-계산" class="level2">
<h2 class="anchored" data-anchor-id="단위-가중치-unit-weights-계산">단위 가중치 (Unit Weights) 계산</h2>
<ul>
<li>처치 유닛의 처치 전 추세(Pre-trend)를 가장 잘 모방하는 합성 통제군을 만들기 위해 유닛 가중치 <img src="https://latex.codecogs.com/png.latex?%5Comega">를 계산합니다.</li>
</ul>
<section id="핵심-구현-사항" class="level3">
<h3 class="anchored" data-anchor-id="핵심-구현-사항">핵심 구현 사항</h3>
<ul>
<li><strong>Intercept (<img src="https://latex.codecogs.com/png.latex?%5Comega_0">) 허용</strong>:
<ul>
<li><code>get_unit_weights(intercept=True)</code> 옵션을 통해 절편을 포함합니다.</li>
<li>이는 기존 SCM과 달리 처치 유닛이 통제 유닛들의 볼록 껍질(Convex Hull) 밖에 있어도 평행 이동을 통해 맞출 수 있게 합니다.</li>
</ul></li>
<li><strong>Regularization (<img src="https://latex.codecogs.com/png.latex?%5Czeta">)</strong>:
<ul>
<li>가중치가 특정 유닛에 쏠리는 것을 방지하고 분산시키기 위해 Ridge Penalty(<img src="https://latex.codecogs.com/png.latex?%5Czeta%5E2%20%7C%7C%5Comega%7C%7C%5E2">)를 적용합니다.</li>
</ul></li>
</ul>
</section>
<section id="최적화-수식" class="level3">
<h3 class="anchored" data-anchor-id="최적화-수식">최적화 수식</h3>
<p><img src="https://latex.codecogs.com/png.latex?%0A(%5Chat%7B%5Comega%7D_0,%20%5Chat%7B%5Comega%7D)%20=%20%5Cunderset%7B%5Comega_0,%20%5Comega%7D%7B%5Carg%5Cmin%7D%20%5Csum_%7Bt=1%7D%5E%7BT_%7Bpre%7D%7D%20%5Cleft(%20Y_%7Btr,t%7D%20-%20%5Comega_0%20-%20%5Csum_%7Bi=1%7D%5E%7BN_%7Bco%7D%7D%20%5Comega_i%20Y_%7Bit%7D%20%5Cright)%5E2%20+%20%5Czeta%5E2%20%7C%7C%5Comega%7C%7C_2%5E2%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bsubject%20to%20%7D%20%5Csum_%7Bi=1%7D%5E%7BN_%7Bco%7D%7D%20%5Comega_i%20=%201,%20%5Cquad%20%5Comega_i%20%5Cge%200%0A"></p>
</section>
</section>
<section id="시간-가중치-time-weights-계산" class="level2">
<h2 class="anchored" data-anchor-id="시간-가중치-time-weights-계산">시간 가중치 (Time Weights) 계산</h2>
<ul>
<li>처치 전 기간(Pre-period) 중, 처치 후 기간(Post-period)과 가장 유사한 패턴을 보이는 시점들에 더 큰 비중을 두기 위해 시간 가중치 <img src="https://latex.codecogs.com/png.latex?%5Clambda">를 계산합니다.</li>
</ul>
<section id="핵심-구현-사항-1" class="level3">
<h3 class="anchored" data-anchor-id="핵심-구현-사항-1">핵심 구현 사항</h3>
<ul>
<li><strong>Target</strong>: 각 통제 유닛(Control Unit)의 <strong>처치 후 평균값</strong>(<img src="https://latex.codecogs.com/png.latex?%5Cbar%7BY%7D_%7Bpost,%20co%7D">)을 타겟으로 설정합니다.</li>
<li><strong>Intercept (<img src="https://latex.codecogs.com/png.latex?%5Clambda_0">) 허용</strong>: 시점 간의 레벨 차이를 보정하기 위해 절편을 포함합니다.</li>
</ul>
</section>
<section id="최적화-수식-1" class="level3">
<h3 class="anchored" data-anchor-id="최적화-수식-1">최적화 수식</h3>
<p><img src="https://latex.codecogs.com/png.latex?%0A(%5Chat%7B%5Clambda%7D_0,%20%5Chat%7B%5Clambda%7D)%20=%20%5Cunderset%7B%5Clambda_0,%20%5Clambda%7D%7B%5Carg%5Cmin%7D%20%5Csum_%7Bi=1%7D%5E%7BN_%7Bco%7D%7D%20%5Cleft(%20%5Cbar%7BY%7D_%7Bi,%20post%7D%20-%20%5Clambda_0%20-%20%5Csum_%7Bt=1%7D%5E%7BT_%7Bpre%7D%7D%20%5Clambda_t%20Y_%7Bit%7D%20%5Cright)%5E2%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bsubject%20to%20%7D%20%5Csum_%7Bt=1%7D%5E%7BT_%7Bpre%7D%7D%20%5Clambda_t%20=%201,%20%5Cquad%20%5Clambda_t%20%5Cge%200%0A"></p>
</section>
</section>
<section id="추정-estimation-closed-form-solution" class="level2">
<h2 class="anchored" data-anchor-id="추정-estimation-closed-form-solution">추정 (Estimation: Closed-form Solution)</h2>
<ul>
<li>복잡한 가중 회귀분석(Weighted TWFE)을 수행하는 대신, 구해진 가중치(<img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Comega%7D,%20%5Chat%7B%5Clambda%7D">)를 사용하여 <strong>가중 이중차분(Weighted DID)</strong> 형태로 직접 <img src="https://latex.codecogs.com/png.latex?%5Ctau_%7Bsdid%7D">를 계산합니다.</li>
</ul>
<section id="구현-로직-estimate-메서드" class="level3">
<h3 class="anchored" data-anchor-id="구현-로직-estimate-메서드">구현 로직 (<code>estimate</code> 메서드)</h3>
<ul>
<li>다음의 4가지 항을 계산하여 최종 효과를 도출합니다.</li>
</ul>
<ol type="1">
<li><strong>Treated Post</strong>: <img src="https://latex.codecogs.com/png.latex?%5Cbar%7BY%7D_%7Btr,%20post%7D"> (단순 평균)</li>
<li><strong>Treated Pre (Time-weighted)</strong>: <img src="https://latex.codecogs.com/png.latex?%5Cbar%7BY%7D_%7Btr,%20pre%7D%5E%7B%5Clambda%7D%20=%20%5Csum%20%5Chat%7B%5Clambda%7D_t%20Y_%7Btr,t%7D"></li>
<li><strong>Control Post (Unit-weighted)</strong>: <img src="https://latex.codecogs.com/png.latex?%5Cbar%7BY%7D_%7Bco,%20post%7D%5E%7B%5Comega%7D%20=%20%5Csum%20%5Chat%7B%5Comega%7D_i%20%5Cbar%7BY%7D_%7Bi,%20post%7D"></li>
<li><strong>Control Pre (Double-weighted)</strong>: <img src="https://latex.codecogs.com/png.latex?%5Cbar%7BY%7D_%7Bco,%20pre%7D%5E%7B%5Comega,%20%5Clambda%7D%20=%20%5Csum%20%5Chat%7B%5Comega%7D_i%20(%5Csum%20%5Chat%7B%5Clambda%7D_t%20Y_%7Bit%7D)"></li>
</ol>
</section>
<section id="최종-추정식" class="level3">
<h3 class="anchored" data-anchor-id="최종-추정식">최종 추정식</h3>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7B%5Ctau%7D%5E%7BSDiD%7D%20=%20%5Cunderbrace%7B(%5Cbar%7BY%7D_%7Btr,%20post%7D%20-%20%5Cbar%7BY%7D_%7Btr,%20pre%7D%5E%7B%5Clambda%7D)%7D_%7B%5Ctext%7BTreated%20Change%7D%7D%20-%20%5Cunderbrace%7B%5Csum_%7Bi=1%7D%5E%7BN_%7Bco%7D%7D%20%5Chat%7B%5Comega%7D_i%20(%5Cbar%7BY%7D_%7Bi,%20post%7D%20-%20%5Cbar%7BY%7D_%7Bi,%20pre%7D%5E%7B%5Clambda%7D)%7D_%7B%5Ctext%7BSynthetic%20Control%20Change%7D%7D%0A"></p>
<div id="4e70d316" class="cell" data-execution_count="2">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> SyntheticDiD:</span>
<span id="cb2-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, Y_co, Y_tr, T_pre):</span>
<span id="cb2-3">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Y_co <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Y_co  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Control Data (N_co x T)</span></span>
<span id="cb2-4">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Y_tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Y_tr  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Treated Data (1 x T)</span></span>
<span id="cb2-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.T_pre <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> T_pre</span>
<span id="cb2-6">        </span>
<span id="cb2-7">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Split Pre/Post</span></span>
<span id="cb2-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Y_pre_co <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Y_co[:, :T_pre]</span>
<span id="cb2-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Y_pre_tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Y_tr[:, :T_pre]</span>
<span id="cb2-10">        </span>
<span id="cb2-11">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.N_co <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Y_co.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb2-12">        </span>
<span id="cb2-13">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> get_unit_weights(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, zeta<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, intercept<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>):</span>
<span id="cb2-14">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb2-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Step 1: Compute Unit Weights (omega)</span></span>
<span id="cb2-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        SDiD Eq: argmin || mean(Y_tr) - (w0 + w @ Y_co) ||^2 + zeta^2 ||w||^2</span></span>
<span id="cb2-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb2-18">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Variables</span></span>
<span id="cb2-19">        w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cp.Variable(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.N_co)</span>
<span id="cb2-20">        w0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cp.Variable(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> intercept <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># SCM은 intercept=False</span></span>
<span id="cb2-21">        </span>
<span id="cb2-22">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Target (Treated Pre-trend)</span></span>
<span id="cb2-23">        target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Y_pre_tr.flatten()</span>
<span id="cb2-24">        </span>
<span id="cb2-25">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prediction (Weighted Control Pre-trend)</span></span>
<span id="cb2-26">        prediction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> w0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Y_pre_co</span>
<span id="cb2-27">        </span>
<span id="cb2-28">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Regularization (Zeta)</span></span>
<span id="cb2-29">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 논문의 zeta 계산식 간소화 (표준편차 * N_tr 등)</span></span>
<span id="cb2-30">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> zeta <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb2-31">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Simple heuristic for tutorial: std of first differences</span></span>
<span id="cb2-32">            diffs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.diff(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Y_pre_co, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb2-33">            sigma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.std(diffs)</span>
<span id="cb2-34">            zeta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.N_co <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Y_co.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.T_pre))<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> sigma</span>
<span id="cb2-35">        </span>
<span id="cb2-36">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Objective Function</span></span>
<span id="cb2-37">        error_term <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cp.sum_squares(target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> prediction)</span>
<span id="cb2-38">        reg_term <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cp.sum_squares(w) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (zeta<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb2-39">        objective <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cp.Minimize(error_term <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> reg_term)</span>
<span id="cb2-40">        </span>
<span id="cb2-41">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Constraints: Sum to 1, Non-negative (Simplex)</span></span>
<span id="cb2-42">        constraints <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [cp.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(w) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb2-43">        </span>
<span id="cb2-44">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Solve</span></span>
<span id="cb2-45">        prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cp.Problem(objective, constraints)</span>
<span id="cb2-46">        prob.solve()</span>
<span id="cb2-47">        </span>
<span id="cb2-48">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> w.value, (w0.value <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> intercept <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb2-49"></span>
<span id="cb2-50">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> get_time_weights(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, lambda_reg<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-6</span>):</span>
<span id="cb2-51">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb2-52"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Step 2: Compute Time Weights (lambda)</span></span>
<span id="cb2-53"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        SDiD Eq: argmin || mean(Y_post_co) - (lam0 + Y_pre_co @ lam) ||^2</span></span>
<span id="cb2-54"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb2-55">        T_pre <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.T_pre</span>
<span id="cb2-56">        lam <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cp.Variable(T_pre)</span>
<span id="cb2-57">        lam0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cp.Variable(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb2-58">        </span>
<span id="cb2-59">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Target: Control Units' Post-treatment Average (Vector of size N_co)</span></span>
<span id="cb2-60">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 각 Control Unit의 처치 후 평균값</span></span>
<span id="cb2-61">        target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Y_co[:, T_pre:], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb2-62">        </span>
<span id="cb2-63">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prediction: Weighted sum of Pre-treatment values for each unit</span></span>
<span id="cb2-64">        prediction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lam0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Y_pre_co <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> lam</span>
<span id="cb2-65">        </span>
<span id="cb2-66">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Objective</span></span>
<span id="cb2-67">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ridge penalty slightly added for numerical stability</span></span>
<span id="cb2-68">        objective <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cp.Minimize(cp.sum_squares(target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> prediction) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> lambda_reg <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> cp.sum_squares(lam))</span>
<span id="cb2-69">        </span>
<span id="cb2-70">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Constraints</span></span>
<span id="cb2-71">        constraints <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [cp.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(lam) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, lam <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb2-72">        </span>
<span id="cb2-73">        prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cp.Problem(objective, constraints)</span>
<span id="cb2-74">        prob.solve()</span>
<span id="cb2-75">        </span>
<span id="cb2-76">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> lam.value, lam0.value</span>
<span id="cb2-77"></span>
<span id="cb2-78">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> estimate(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb2-79">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. Unit Weights (SDiD)</span></span>
<span id="cb2-80">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.omega, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.omega0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.get_unit_weights(intercept<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb2-81">        </span>
<span id="cb2-82">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. Unit Weights (SCM - for comparison)</span></span>
<span id="cb2-83">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># SCM: No intercept, No regularization (or small) in classic form, but usually L2 used.</span></span>
<span id="cb2-84">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Here we mimic SCM by forcing intercept=0</span></span>
<span id="cb2-85">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.omega_sc, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.get_unit_weights(intercept<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, zeta<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>) </span>
<span id="cb2-86"></span>
<span id="cb2-87">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. Time Weights (SDiD)</span></span>
<span id="cb2-88">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lam, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lam0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.get_time_weights()</span>
<span id="cb2-89">        </span>
<span id="cb2-90">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 4. SDiD Estimator (Weighted TWFE)</span></span>
<span id="cb2-91">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 간단한 구현을 위해 Weighted Diff-in-Diff 공식을 직접 적용합니다.</span></span>
<span id="cb2-92">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># tau_sdid = (Y_tr_post - Y_tr_pre_weighted) - (Y_co_post_weighted - Y_co_pre_weighted)</span></span>
<span id="cb2-93">        </span>
<span id="cb2-94">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply Time Weights to Pre-periods</span></span>
<span id="cb2-95">        y_tr_post <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Y_tr[:, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.T_pre:])</span>
<span id="cb2-96">        y_tr_pre <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.dot(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Y_tr[:, :<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.T_pre].flatten(), <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lam)</span>
<span id="cb2-97">        </span>
<span id="cb2-98">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply Unit Weights to Control Units</span></span>
<span id="cb2-99">        y_co_post_series <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Y_co[:, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.T_pre:], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb2-100">        y_co_pre_matrix <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Y_co[:, :<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.T_pre]</span>
<span id="cb2-101">        </span>
<span id="cb2-102">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Double Weighted Control</span></span>
<span id="cb2-103">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Control Term = Sum( omega_i * ( Mean_Post_i - Sum(lambda_t * Y_it_pre) ) )</span></span>
<span id="cb2-104">        control_term <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb2-105">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.N_co):</span>
<span id="cb2-106">            y_i_post <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_co_post_series[i]</span>
<span id="cb2-107">            y_i_pre <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.dot(y_co_pre_matrix[i], <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lam)</span>
<span id="cb2-108">            control_term <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.omega[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (y_i_post <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> y_i_pre)</span>
<span id="cb2-109">            </span>
<span id="cb2-110">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.tau_sdid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (y_tr_post <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> y_tr_pre) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> control_term</span>
<span id="cb2-111">        </span>
<span id="cb2-112">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.tau_sdid</span></code></pre></div></div>
</details>
</div>
<hr>
</section>
</section>
</section>
<section id="시뮬레이션1-평행-추세-가정의-위배-selection-on-trends" class="level1">
<h1>시뮬레이션1: 평행 추세 가정의 위배 (Selection on Trends)</h1>
<ul>
<li>SDiD가 기존의 이중차분법(DID)보다 우수한 점을 검증하기 위해, <strong>평행 추세 가정(Parallel Trends Assumption)이 성립하지 않는 데이터</strong>를 생성합니다.</li>
<li>이를 위해 단순한 이원 고정 효과(TWFE) 모델이 아닌, <strong>잠재 요인(Latent Factor) 모형</strong>을 사용합니다.</li>
</ul>
<section id="data-generation" class="level2">
<h2 class="anchored" data-anchor-id="data-generation">1. Data Generation</h2>
<section id="데이터-생성-모형-dgp" class="level3">
<h3 class="anchored" data-anchor-id="데이터-생성-모형-dgp">데이터 생성 모형 (DGP)</h3>
<ul>
<li>데이터는 다음과 같은 수식을 따릅니다. <img src="https://latex.codecogs.com/png.latex?%0AY_%7Bit%7D%20=%20%5Cunderbrace%7B%5Calpha_i%7D_%7B%5Ctext%7BUnit%20FE%7D%7D%20+%20%5Cunderbrace%7B%5Cbeta_t%7D_%7B%5Ctext%7BTime%20FE%7D%7D%20+%20%5Cunderbrace%7B%5Cgamma_i%20f_t%7D_%7B%5Ctext%7BLatent%20Structure%7D%7D%20+%20%5Ctau%20D_%7Bit%7D%20+%20%5Cvarepsilon_%7Bit%7D%0A">
<ul>
<li><strong><img src="https://latex.codecogs.com/png.latex?%5Calpha_i,%20%5Cbeta_t"></strong>: 일반적인 개체 및 시간 고정 효과입니다.</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?f_t"></strong>: 시간에 따라 선형적으로 증가하는 공통의 잠재 요인입니다. (<img src="https://latex.codecogs.com/png.latex?f_t%20%5Cpropto%20t">)</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?%5Cgamma_i"></strong>: 잠재 요인 <img src="https://latex.codecogs.com/png.latex?f_t">에 반응하는 개체별 민감도(Factor Loading)입니다.</li>
</ul></li>
</ul>
</section>
<section id="non-parallel-trend" class="level3">
<h3 class="anchored" data-anchor-id="non-parallel-trend">Non-Parallel Trend</h3>
<ul>
<li>평행 추세를 깨뜨리기 위해, 처치 여부(<img src="https://latex.codecogs.com/png.latex?D_i">)가 무작위가 아니라 <strong>추세 민감도(<img src="https://latex.codecogs.com/png.latex?%5Cgamma_i">)</strong>에 따라 결정되도록 설정합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AD_i%20=%201%20%5Cquad%20%5Ctext%7Bif%20%7D%20%5Cgamma_i%20%5Ctext%7B%20is%20in%20top%20%7D%2010%5C%25,%20%5Cquad%20%5Ctext%7Belse%20%7D%200%0A"></p>
<div id="09770c75" class="cell" data-execution_count="3">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> generate_nonparallel_data(N<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, T<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>, T_pre<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>, treated_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, true_tau<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>):</span>
<span id="cb3-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> seed: np.random.seed(seed)</span>
<span id="cb3-3">    </span>
<span id="cb3-4">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. Fixed Effects</span></span>
<span id="cb3-5">    alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.normal(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>N)      <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Unit FE</span></span>
<span id="cb3-6">    beta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.normal(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>T) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> np.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, T) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Time FE (Trend)</span></span>
<span id="cb3-7">    </span>
<span id="cb3-8">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. Latent Factor (Time-varying Confounder) causing Non-parallel trends</span></span>
<span id="cb3-9">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 시간(t)에 따라 증가하는 패턴 (Trend Factor)</span></span>
<span id="cb3-10">    f_t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, T)</span>
<span id="cb3-11">    </span>
<span id="cb3-12">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 유닛별 민감도 (Loadings)</span></span>
<span id="cb3-13">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 처치군이 될 확률이 높은 유닛들이 더 가파른 기울기를 갖도록 설정</span></span>
<span id="cb3-14">    gamma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.uniform(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>N)</span>
<span id="cb3-15">    </span>
<span id="cb3-16">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. Treatment Assignment (Selection on Trends)</span></span>
<span id="cb3-17">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># gamma(기울기)가 큰 상위 유닛들을 처치군으로 선정 -&gt; 평행 추세 위배</span></span>
<span id="cb3-18">    N_tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(N <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> treated_ratio)</span>
<span id="cb3-19">    treated_indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.argsort(gamma)[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>N_tr:]</span>
<span id="cb3-20">    is_treated <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros(N, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span>)</span>
<span id="cb3-21">    is_treated[treated_indices] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb3-22">    </span>
<span id="cb3-23">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 4. Generate Outcome Y</span></span>
<span id="cb3-24">    Y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((N, T))</span>
<span id="cb3-25">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(N):</span>
<span id="cb3-26">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> t <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(T):</span>
<span id="cb3-27">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Base Model</span></span>
<span id="cb3-28">            y_val <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> alpha[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> beta[t] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> gamma[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> f_t[t] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> np.random.normal(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-29">            </span>
<span id="cb3-30">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add Treatment Effect</span></span>
<span id="cb3-31">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> is_treated[i] <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> T_pre:</span>
<span id="cb3-32">                y_val <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> true_tau</span>
<span id="cb3-33">            </span>
<span id="cb3-34">            Y[i, t] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_val</span>
<span id="cb3-35">            </span>
<span id="cb3-36">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare Output</span></span>
<span id="cb3-37">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 처치군 데이터를 맨 뒤로 보내거나 인덱스를 반환해야 하지만, </span></span>
<span id="cb3-38">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 여기서는 편의상 SyntheticDiD 클래스 입력 형식에 맞춰 정리</span></span>
<span id="cb3-39">    </span>
<span id="cb3-40">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Sort: Control first, Treated last</span></span>
<span id="cb3-41">    sorted_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.concatenate([np.where(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span>is_treated)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], np.where(is_treated)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]])</span>
<span id="cb3-42">    Y_sorted <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Y[sorted_idx, :]</span>
<span id="cb3-43">    </span>
<span id="cb3-44">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Split</span></span>
<span id="cb3-45">    N_co <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> N <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> N_tr</span>
<span id="cb3-46">    Y_co <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Y_sorted[:N_co, :]</span>
<span id="cb3-47">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># SDiD 클래스는 현재 1개의 Treated Unit을 가정하므로, 평균을 내서 1개로 만듭니다.</span></span>
<span id="cb3-48">    Y_tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(Y_sorted[N_co:, :], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).reshape(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-49">    </span>
<span id="cb3-50">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> Y_co, Y_tr, true_tau</span></code></pre></div></div>
</details>
</div>
<div id="2b537c5b" class="cell" data-execution_count="4">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -------------------------------------------------------</span></span>
<span id="cb4-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. 단일 시뮬레이션 데이터 생성</span></span>
<span id="cb4-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -------------------------------------------------------</span></span>
<span id="cb4-4">Y_co, Y_tr, true_tau <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> generate_nonparallel_data(seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>, N<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, treated_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>)</span>
<span id="cb4-5">T_pre <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span></span>
<span id="cb4-6">time_axis <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.arange(Y_co.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb4-7"></span>
<span id="cb4-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -------------------------------------------------------</span></span>
<span id="cb4-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. Counterfactuals 계산</span></span>
<span id="cb4-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -------------------------------------------------------</span></span>
<span id="cb4-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (1) True Counterfactual (Unobserved Truth)</span></span>
<span id="cb4-12">Y_tr_true_cf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Y_tr.flatten().copy()</span>
<span id="cb4-13">Y_tr_true_cf[T_pre:] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-=</span> true_tau </span>
<span id="cb4-14"></span>
<span id="cb4-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (2) Naive DiD Counterfactual (What DiD assumes)</span></span>
<span id="cb4-16">mean_tr_pre <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(Y_tr.flatten()[:T_pre])</span>
<span id="cb4-17">mean_co_pre <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(np.mean(Y_co, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)[:T_pre])</span>
<span id="cb4-18">level_gap <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_tr_pre <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> mean_co_pre</span>
<span id="cb4-19">Y_did_naive_cf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(Y_co, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> level_gap</span>
<span id="cb4-20"></span>
<span id="cb4-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -------------------------------------------------------</span></span>
<span id="cb4-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. 시각화</span></span>
<span id="cb4-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -------------------------------------------------------</span></span>
<span id="cb4-24">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb4-25"></span>
<span id="cb4-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (1) Control Units</span></span>
<span id="cb4-27">plt.plot(time_axis, np.mean(Y_co, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>), color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'navy'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Average Control'</span>)</span>
<span id="cb4-28"></span>
<span id="cb4-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (2) Treated Unit (Observed)</span></span>
<span id="cb4-30">plt.plot(time_axis, Y_tr.flatten(), color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'firebrick'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Treated (Observed)'</span>)</span>
<span id="cb4-31"></span>
<span id="cb4-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (3) True Counterfactual (Unobserved Truth) - RED Dotted</span></span>
<span id="cb4-33">plt.plot(time_axis, Y_tr_true_cf, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'firebrick'</span>, linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">':'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'True Counterfactual (Target)'</span>)</span>
<span id="cb4-34"></span>
<span id="cb4-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (4) Naive DiD Counterfactual - GREEN Dashed</span></span>
<span id="cb4-36">plt.plot(time_axis, Y_did_naive_cf, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>, linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Naive DiD Counterfactual (Biased)'</span>)</span>
<span id="cb4-37"></span>
<span id="cb4-38"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Settings</span></span>
<span id="cb4-39">plt.axvline(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>T_pre, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>, linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'-'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Intervention'</span>)</span>
<span id="cb4-40">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Why DiD Fails: True Counterfactual vs Naive DiD Projection"</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>)</span>
<span id="cb4-41">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Time"</span>)</span>
<span id="cb4-42">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Outcome Y"</span>)</span>
<span id="cb4-43">plt.legend(loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'upper left'</span>)</span>
<span id="cb4-44">plt.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb4-45">plt.show()</span></code></pre></div></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L15A/SDiD/part-02/index_files/figure-html/cell-5-output-1.png" width="968" height="526" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="simulation" class="level2">
<h2 class="anchored" data-anchor-id="simulation">2. Simulation</h2>
<ul>
<li>앞서 정의한 데이터 생성 함수(<code>generate_data</code>)와 <code>SyntheticDiD</code> 클래스를 사용하여 몬테카를로 시뮬레이션을 수행합니다.</li>
<li>총 50회의 반복 시행을 통해 <strong>SDiD</strong>, <strong>SCM</strong>, <strong>Standard DID</strong>의 성능을 비교합니다.</li>
</ul>
<div id="4ee30b63" class="cell" data-execution_count="5">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -------------------------------------------------------</span></span>
<span id="cb5-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Simulation Run</span></span>
<span id="cb5-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -------------------------------------------------------</span></span>
<span id="cb5-4">N_SIMULATIONS <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span></span>
<span id="cb5-5">results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'did'</span>: [], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'scm'</span>: [], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sdid'</span>: []}</span>
<span id="cb5-6"></span>
<span id="cb5-7"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Starting Monte Carlo Simulation (</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>N_SIMULATIONS<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> runs)..."</span>)</span>
<span id="cb5-8"></span>
<span id="cb5-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(N_SIMULATIONS):</span>
<span id="cb5-10">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. Generate Data (Non-parallel trends)</span></span>
<span id="cb5-11">    Y_co, Y_tr, true_tau <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> generate_nonparallel_data(seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>i)</span>
<span id="cb5-12">    T_pre <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span></span>
<span id="cb5-13">    </span>
<span id="cb5-14">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. Run Models</span></span>
<span id="cb5-15">    model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SyntheticDiD(Y_co, Y_tr, T_pre)</span>
<span id="cb5-16">    </span>
<span id="cb5-17">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (1) SDiD</span></span>
<span id="cb5-18">    est_sdid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.estimate()</span>
<span id="cb5-19">    </span>
<span id="cb5-20">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (2) SCM (Intercept=False, Zeta=0)</span></span>
<span id="cb5-21">    w_scm, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.get_unit_weights(intercept<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, zeta<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb5-22">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># SCM Estimator Calculation</span></span>
<span id="cb5-23">    y_tr_post <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(Y_tr[:, T_pre:])</span>
<span id="cb5-24">    y_sc_post <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(w_scm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> Y_co[:, T_pre:])</span>
<span id="cb5-25">    est_scm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_tr_post <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> y_sc_post</span>
<span id="cb5-26">    </span>
<span id="cb5-27">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (3) DiD (Simple TWFE)</span></span>
<span id="cb5-28">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Tau = (Tr_post - Tr_pre) - (Co_post - Co_pre)</span></span>
<span id="cb5-29">    diff_tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(Y_tr[:, T_pre:]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> np.mean(Y_tr[:, :T_pre])</span>
<span id="cb5-30">    diff_co <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(Y_co[:, T_pre:]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> np.mean(Y_co[:, :T_pre]) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Mean of all controls</span></span>
<span id="cb5-31">    est_did <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> diff_tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> diff_co</span>
<span id="cb5-32">    </span>
<span id="cb5-33">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Save</span></span>
<span id="cb5-34">    results[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sdid'</span>].append(est_sdid)</span>
<span id="cb5-35">    results[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'scm'</span>].append(est_scm)</span>
<span id="cb5-36">    results[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'did'</span>].append(est_did)</span>
<span id="cb5-37"></span>
<span id="cb5-38"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -------------------------------------------------------</span></span>
<span id="cb5-39"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Result Visualization</span></span>
<span id="cb5-40"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -------------------------------------------------------</span></span>
<span id="cb5-41">df_res <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(results)</span>
<span id="cb5-42">true_tau <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span></span>
<span id="cb5-43"></span>
<span id="cb5-44">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb5-45">sns.boxplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df_res)</span>
<span id="cb5-46">plt.axhline(y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>true_tau, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r'</span>, linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'True Effect (10)'</span>)</span>
<span id="cb5-47">plt.title(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Simulation Results (N=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>N_SIMULATIONS<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">): Bias Comparison"</span>)</span>
<span id="cb5-48">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Estimated Effect"</span>)</span>
<span id="cb5-49">plt.legend()</span>
<span id="cb5-50">plt.show()</span>
<span id="cb5-51"></span>
<span id="cb5-52"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate Metrics</span></span>
<span id="cb5-53">bias <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df_res.mean() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> true_tau</span>
<span id="cb5-54">rmse <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.sqrt(((df_res <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> true_tau)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).mean())</span>
<span id="cb5-55"></span>
<span id="cb5-56"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"=== Performance Metrics ==="</span>)</span>
<span id="cb5-57"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Method'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:&lt;10}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> | </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Bias'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:&lt;10}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> | </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RMSE'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:&lt;10}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb5-58"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"-"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">35</span>)</span>
<span id="cb5-59"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> method <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'did'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'scm'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sdid'</span>]:</span>
<span id="cb5-60">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>method<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>upper()<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:&lt;10}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> | </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>bias[method]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">     | </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>rmse[method]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Starting Monte Carlo Simulation (50 runs)...</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/anaconda3/envs/causal-inference-study/lib/python3.9/site-packages/cvxpy/problems/problem.py:1539: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L15A/SDiD/part-02/index_files/figure-html/cell-6-output-3.png" width="808" height="505" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=== Performance Metrics ===
Method     | Bias       | RMSE      
-----------------------------------
DID        | 7.5670     | 7.5781
SCM        | 1.3289     | 1.3910
SDID       | 0.6798     | 0.7493</code></pre>
</div>
</div>
<section id="결과" class="level3">
<h3 class="anchored" data-anchor-id="결과">결과</h3>
<ul>
<li><strong>DiD</strong>: 평행 추세 가정이 깨졌기 때문에(처치군이 더 가파른 추세를 가짐), 처치 효과를 과대평가(Bias 발생)하게 됩니다.</li>
<li><strong>SCM</strong>: 대조군을 합성하여 추세를 맞추려 노력하지만, 정규화(Regularization)나 시간 가중치(Time weights)의 부재로 인해 SDiD보다는 성능이 떨어질 수 있습니다.</li>
<li><strong>SDiD</strong>: Unit weights로 추세 차이를 보정하고, Time weights로 시간적 변동성까지 잡아내어 가장 낮은 편향(Bias)과 오차(RMSE)를 보여줍니다.</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="시뮬레이션2-극단적인-레벨-차이-level-shift-outlier" class="level1">
<h1>시뮬레이션2: 극단적인 레벨 차이 (Level Shift &amp; Outlier)</h1>
<ul>
<li>이 시나리오는 <strong>Synthetic Control Method (SCM)의 구조적 한계</strong>를 보여주기 위해 설계되었습니다.</li>
<li>처치 유닛의 결과값(<img src="https://latex.codecogs.com/png.latex?Y">)이 통제 유닛들이 형성하는 범위(Convex Hull)를 벗어나도록 극단적인 <strong>레벨 이동(Level Shift)</strong>을 가합니다.</li>
</ul>
<section id="data-generation-1" class="level2">
<h2 class="anchored" data-anchor-id="data-generation-1">1. Data Generation</h2>
<section id="데이터-생성-모형-dgp-1" class="level3">
<h3 class="anchored" data-anchor-id="데이터-생성-모형-dgp-1">데이터 생성 모형 (DGP)</h3>
<p><img src="https://latex.codecogs.com/png.latex?%0AY_%7Bit%7D%20=%20%5Cunderbrace%7B%5Calpha_i%7D_%7B%5Ctext%7BUnit%20FE%7D%7D%20+%20%5Cunderbrace%7B%5Cbeta_t%7D_%7B%5Ctext%7BTime%20FE%7D%7D%20+%20%5Cunderbrace%7B%5Cgamma_i%20f_t%7D_%7B%5Ctext%7BTrend%20Factor%7D%7D%20+%20%5Ctau%20D_%7Bit%7D%20+%20%5Cvarepsilon_%7Bit%7D%0A"></p>
</section>
<section id="the-trap" class="level3">
<h3 class="anchored" data-anchor-id="the-trap">The Trap</h3>
<section id="convex-hull-위배" class="level4">
<h4 class="anchored" data-anchor-id="convex-hull-위배"><strong>Convex Hull 위배</strong></h4>
<ul>
<li>처치 유닛의 고정 효과(<img src="https://latex.codecogs.com/png.latex?%5Calpha_%7Btr%7D">)를 통제 유닛들의 최댓값보다 훨씬 크게 설정합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Calpha_%7Btr%7D%20%5Cgg%20%5Cmax_%7Bj%20%5Cin%20Co%7D(%5Calpha_j)%20%5Cquad%20(%5Ctext%7BCode:%20%7D%20%5Cmax%20+%2030)%0A"></p>
<ul>
<li>SCM의 가중치는 <img src="https://latex.codecogs.com/png.latex?%5Csum%20%5Comega_i%20=%201,%20%5Comega_i%20%5Cge%200"> 제약을 따르므로, 합성 통제군은 결코 통제 유닛 중 가장 큰 값보다 커질 수 없습니다. <img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7BY%7D_%7Btr%7D%5E%7BSCM%7D%20=%20%5Csum%20%5Comega_i%20Y_%7Bi%7D%20%5Cle%20%5Cmax(Y_%7Bco%7D)%20%3C%20Y_%7Btr%7D%0A"></li>
<li>즉, <strong>절편 보정이 없는 SCM</strong>은 처치 유닛의 높은 레벨을 절대 따라잡을 수 없습니다.</li>
</ul>
<div id="74eb7007" class="cell" data-execution_count="6">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> generate_level_shifted_data(N<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>, T<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>, T_pre<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>, true_tau<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>):</span>
<span id="cb9-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> seed: np.random.seed(seed)</span>
<span id="cb9-3">    </span>
<span id="cb9-4">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. Base Components</span></span>
<span id="cb9-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Control Units의 Alpha는 작게 설정 (0 ~ 10)</span></span>
<span id="cb9-6">    alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.uniform(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>N)</span>
<span id="cb9-7">    </span>
<span id="cb9-8">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Time Trend (Common)</span></span>
<span id="cb9-9">    beta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, T)</span>
<span id="cb9-10">    </span>
<span id="cb9-11">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. Level Shift (Make Treated Unit an Outlier)</span></span>
<span id="cb9-12">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 처치 유닛의 Alpha를 대조군 최댓값보다 훨씬 크게 설정 (+30)</span></span>
<span id="cb9-13">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -&gt; SCM은 가중치 합이 1이라서 죽었다 깨어나도 이 레벨을 못 맞춤</span></span>
<span id="cb9-14">    treated_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> N <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 마지막 유닛을 처치군으로 지정</span></span>
<span id="cb9-15">    alpha[treated_idx] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(alpha[:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span> </span>
<span id="cb9-16">    </span>
<span id="cb9-17">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. Non-Parallel Trend Factor (Optional but good for killing DiD too)</span></span>
<span id="cb9-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 처치 유닛에게만 추가적인 성장 추세 부여</span></span>
<span id="cb9-19">    trend_factor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, T)</span>
<span id="cb9-20">    gamma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros(N)</span>
<span id="cb9-21">    gamma[treated_idx] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 처치 유닛만 더 가파르게 성장</span></span>
<span id="cb9-22">    </span>
<span id="cb9-23">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 4. Generate Y</span></span>
<span id="cb9-24">    Y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((N, T))</span>
<span id="cb9-25">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(N):</span>
<span id="cb9-26">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Y = Alpha + Beta + (Gamma * Trend) + Noise</span></span>
<span id="cb9-27">        Y[i, :] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> alpha[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> beta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (gamma[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> trend_factor) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> np.random.normal(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, T)</span>
<span id="cb9-28">        </span>
<span id="cb9-29">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add Treatment Effect (Post-period)</span></span>
<span id="cb9-30">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> treated_idx:</span>
<span id="cb9-31">            Y[i, T_pre:] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> true_tau</span>
<span id="cb9-32">            </span>
<span id="cb9-33">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Output Split</span></span>
<span id="cb9-34">    Y_co <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Y[:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, :]                 <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (N-1) x T</span></span>
<span id="cb9-35">    Y_tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Y[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, :].reshape(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1 x T</span></span>
<span id="cb9-36">    </span>
<span id="cb9-37">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> Y_co, Y_tr, true_tau</span></code></pre></div></div>
</details>
</div>
<div id="d2be97d2" class="cell" data-execution_count="7">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">Y_co, Y_tr, true_tau <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> generate_level_shifted_data(seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb10-2">T_pre <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span></span>
<span id="cb10-3">years <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>)</span>
<span id="cb10-4"></span>
<span id="cb10-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Run Models to get fitted values</span></span>
<span id="cb10-6">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SyntheticDiD(Y_co, Y_tr, T_pre)</span>
<span id="cb10-7"></span>
<span id="cb10-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (1) SCM Fit (Constrained)</span></span>
<span id="cb10-9">w_scm, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.get_unit_weights(intercept<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, zeta<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb10-10">Y_scm_fit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> w_scm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> Y_co</span>
<span id="cb10-11"></span>
<span id="cb10-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (2) SDiD Fit (Intercept Allowed)</span></span>
<span id="cb10-13">w_sdid, w0_sdid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.get_unit_weights(intercept<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-14">Y_sdid_fit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> w0_sdid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> w_sdid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> Y_co</span>
<span id="cb10-15"></span>
<span id="cb10-16">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb10-17"></span>
<span id="cb10-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Raw Data</span></span>
<span id="cb10-19">plt.plot(years, Y_co.T, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gray'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.15</span>)</span>
<span id="cb10-20">plt.plot(years, Y_tr.flatten(), color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'firebrick'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Treated (Observed)'</span>)</span>
<span id="cb10-21"></span>
<span id="cb10-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># SCM Fit (Failure)</span></span>
<span id="cb10-23">plt.plot(years, Y_scm_fit, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'SCM Fit (No Intercept)'</span>)</span>
<span id="cb10-24"></span>
<span id="cb10-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># SDiD Fit (Success)</span></span>
<span id="cb10-26">plt.plot(years, Y_sdid_fit, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>, linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'SDiD Fit (With Intercept)'</span>)</span>
<span id="cb10-27"></span>
<span id="cb10-28">plt.axvline(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>T_pre, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>, linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">':'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Intervention'</span>)</span>
<span id="cb10-29">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SCM Limitation: Convex Hull Condition Failure"</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>)</span>
<span id="cb10-30">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Time"</span>)</span>
<span id="cb10-31">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Outcome Y"</span>)</span>
<span id="cb10-32">plt.legend()</span>
<span id="cb10-33">plt.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb10-34">plt.show()</span></code></pre></div></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/anaconda3/envs/causal-inference-study/lib/python3.9/site-packages/cvxpy/problems/problem.py:1539: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L15A/SDiD/part-02/index_files/figure-html/cell-8-output-2.png" width="957" height="526" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="simulation-1" class="level2">
<h2 class="anchored" data-anchor-id="simulation-1">2. Simulation</h2>
<ul>
<li>앞서 정의한 <strong>Level Shift 데이터(Convex Hull 위배)</strong>를 사용하여 50회 반복 시뮬레이션을 수행합니다.</li>
</ul>
<div id="026a9d3d" class="cell" data-execution_count="8">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -------------------------------------------------------</span></span>
<span id="cb12-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Settings</span></span>
<span id="cb12-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -------------------------------------------------------</span></span>
<span id="cb12-4">N_SIM <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span></span>
<span id="cb12-5">results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'did'</span>: [], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'scm'</span>: [], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sdid'</span>: []}</span>
<span id="cb12-6"></span>
<span id="cb12-7"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Starting Level-Shift Simulation (</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>N_SIM<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> runs)..."</span>)</span>
<span id="cb12-8"></span>
<span id="cb12-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -------------------------------------------------------</span></span>
<span id="cb12-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Simulation Loop</span></span>
<span id="cb12-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -------------------------------------------------------</span></span>
<span id="cb12-12"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(N_SIM):</span>
<span id="cb12-13">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. Generate Data (Outlier Treated Unit)</span></span>
<span id="cb12-14">    Y_co, Y_tr, true_tau <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> generate_level_shifted_data(seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>i)</span>
<span id="cb12-15">    T_pre <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span></span>
<span id="cb12-16">    </span>
<span id="cb12-17">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. Initialize Model</span></span>
<span id="cb12-18">    model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SyntheticDiD(Y_co, Y_tr, T_pre)</span>
<span id="cb12-19">    </span>
<span id="cb12-20">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (1) SDiD Estimate (Intercept Allowed)</span></span>
<span id="cb12-21">    est_sdid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.estimate()</span>
<span id="cb12-22">    </span>
<span id="cb12-23">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (2) SCM Estimate (Intercept False)</span></span>
<span id="cb12-24">    w_scm, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.get_unit_weights(intercept<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, zeta<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb12-25">    </span>
<span id="cb12-26">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Counterfactual: w * Y_co (No intercept adjustment)</span></span>
<span id="cb12-27">    y_tr_post <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(Y_tr[:, T_pre:])</span>
<span id="cb12-28">    y_sc_post <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(w_scm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> Y_co[:, T_pre:]) </span>
<span id="cb12-29">    est_scm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_tr_post <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> y_sc_post</span>
<span id="cb12-30">    </span>
<span id="cb12-31">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (3) DiD Estimate (Standard TWFE)</span></span>
<span id="cb12-32">    diff_tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(Y_tr[:, T_pre:]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> np.mean(Y_tr[:, :T_pre])</span>
<span id="cb12-33">    diff_co <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(Y_co[:, T_pre:]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> np.mean(Y_co[:, :T_pre])</span>
<span id="cb12-34">    est_did <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> diff_tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> diff_co</span>
<span id="cb12-35">    </span>
<span id="cb12-36">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Save</span></span>
<span id="cb12-37">    results[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sdid'</span>].append(est_sdid)</span>
<span id="cb12-38">    results[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'scm'</span>].append(est_scm)</span>
<span id="cb12-39">    results[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'did'</span>].append(est_did)</span>
<span id="cb12-40"></span>
<span id="cb12-41"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -------------------------------------------------------</span></span>
<span id="cb12-42"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualization</span></span>
<span id="cb12-43"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -------------------------------------------------------</span></span>
<span id="cb12-44">df_res <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(results)</span>
<span id="cb12-45"></span>
<span id="cb12-46">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb12-47">sns.boxplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df_res)</span>
<span id="cb12-48"></span>
<span id="cb12-49"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 참값(True Tau) 표시</span></span>
<span id="cb12-50">plt.axhline(y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>true_tau, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r'</span>, linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'True Effect (</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>true_tau<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">)'</span>)</span>
<span id="cb12-51"></span>
<span id="cb12-52">plt.title(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Simulation Results (N=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>N_SIM<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">): Level-Shift &amp; Trend Failure"</span>)</span>
<span id="cb12-53">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Estimated Treatment Effect"</span>)</span>
<span id="cb12-54">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Method"</span>)</span>
<span id="cb12-55">plt.legend()</span>
<span id="cb12-56">plt.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb12-57">plt.show()</span>
<span id="cb12-58"></span>
<span id="cb12-59"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -------------------------------------------------------</span></span>
<span id="cb12-60"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Performance Metrics</span></span>
<span id="cb12-61"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -------------------------------------------------------</span></span>
<span id="cb12-62">bias <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df_res.mean() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> true_tau</span>
<span id="cb12-63">rmse <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.sqrt(((df_res <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> true_tau)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).mean())</span>
<span id="cb12-64"></span>
<span id="cb12-65"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">=== Performance Metrics (SCM Limitation Scenario) ==="</span>)</span>
<span id="cb12-66"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Method'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:&lt;10}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> | </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Bias'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:&lt;10}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> | </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RMSE'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:&lt;10}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb12-67"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"-"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">35</span>)</span>
<span id="cb12-68"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> method <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'did'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'scm'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sdid'</span>]:</span>
<span id="cb12-69">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>method<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>upper()<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:&lt;10}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> | </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>bias[method]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">     | </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>rmse[method]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Starting Level-Shift Simulation (50 runs)...</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L15A/SDiD/part-02/index_files/figure-html/cell-9-output-2.png" width="808" height="523" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
=== Performance Metrics (SCM Limitation Scenario) ===
Method     | Bias       | RMSE      
-----------------------------------
DID        | 2.5843     | 2.6168
SCM        | 34.6187     | 34.6213
SDID       | 2.6393     | 2.7111</code></pre>
</div>
</div>
<section id="결과-1" class="level3">
<h3 class="anchored" data-anchor-id="결과-1">결과</h3>
<ul>
<li><strong>SCM</strong>: Bias와 RMSE가 매우 큽니다. 이는 SCM이 처치 유닛의 높은 초기값(Level)을 합성해내지 못했기 때문입니다. 즉, <strong>“Convex Hull Condition”이 위배되면 SCM은 신뢰할 수 없습니다.</strong></li>
<li><strong>DID</strong>: 레벨 차이가 커도 차분 과정에서 사라지므로 SCM보다는 훨씬 나은 성능을 보입니다. 단, 미세한 추세 차이로 인한 편향은 남아 있습니다.</li>
<li><strong>SDiD</strong>: 절편()으로 레벨 차이를 완벽히 잡고, 가중치로 추세까지 보정하여 Bias와 RMSE 모두 가장 낮습니다.</li>
</ul>



</section>
</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L15A/SDiD/part-02/</guid>
  <pubDate>Sat, 24 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 15A. Staggered DiD</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L15A/Staggered-DiD/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>전통적인 이중차분법(Difference-in-Differences, DiD)은 두 개의 그룹(Treatment/Control)과 두 개의 시점(Pre/Post)이 존재하는 2x2 Canonical Design에서 인과 효과를 추정하는 강력한 도구입니다. 그러나 실제 현실 데이터, 특히 정책 시행이나 서비스 도입과 같은 환경에서는 모든 실험군이 동시에 처치를 받는 경우는 드뭅니다.</p>
<p>대신, <strong>Staggered Adoption Design (SAD)</strong>이라 불리는, 처치 시점이 유닛마다 다른 상황이 훨씬 빈번하게 발생합니다. 예를 들어, 어떤 지역은 정책을 2020년에 도입하고, 어떤 지역은 2021년에 도입하는 식입니다.</p>
<p>이번 포스트에서는 전통적인 Two-Way Fixed Effects (TWFE) 회귀분석이 이러한 Staggered setup에서 왜 편향된(biased) 추정치를 낳는지 살펴보고, 이를 해결하기 위한 최신 방법론인 <strong>Callaway and Sant’Anna (2021)</strong>의 프레임워크를 상세히 정리해보겠습니다.</p>
<p><img src="https://shsha0110.github.io/posts/lecture/L15A/Staggered-DiD/images/staggered_timeline.png" class="img-fluid" alt="Figure 1: Staggered Adoption의 개념도. 실험군 A, B, C가 서로 다른 시점에 처치를 받기 시작하며, Never-Treated Group은 끝까지 처치를 받지 않는다."> &gt; <strong>Figure 1 설명</strong>: Staggered Treatment Timing을 나타내는 도식입니다. &gt; - <strong>Treated Group A</strong>: 가장 먼저 처치를 받기 시작함. &gt; - <strong>Treated Group B</strong>: A보다 나중에 처치를 받기 시작함. &gt; - <strong>Treated Group C</strong>: 가장 늦게 처치를 받기 시작함. &gt; - <strong>Never-Treated Group</strong>: 관찰 기간 내내 처치를 받지 않음. &gt; - 핵심은 처치를 받은 유닛은 다시 통제 상태로 돌아가지 않는다는(Irreversible) 가정입니다.</p>
<hr>
</section>
<section id="why-twfe-fails-in-staggered-did" class="level1">
<h1>2. Why TWFE Fails in Staggered DiD?</h1>
<section id="the-limitation-of-twfe" class="level2">
<h2 class="anchored" data-anchor-id="the-limitation-of-twfe">2.1. The Limitation of TWFE</h2>
<p>일반적으로 연구자들은 패널 데이터에서 다음과 같은 <strong>Two-Way Fixed Effects (TWFE)</strong> 선형 회귀 모형을 사용하여 <img src="https://latex.codecogs.com/png.latex?%5Cbeta">를 인과 효과(ATT)로 해석해 왔습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AY_%7Bit%7D%20=%20%5Calpha_i%20+%20%5Clambda_t%20+%20%5Cbeta%20D_%7Bit%7D%20+%20%5Cepsilon_%7Bit%7D%0A"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?D_%7Bit%7D">는 유닛 <img src="https://latex.codecogs.com/png.latex?i">가 시점 <img src="https://latex.codecogs.com/png.latex?t">에 처치를 받았으면 1, 아니면 0인 더미 변수입니다. 하지만 처치 시점이 다양하고(Staggered), 처치 효과가 시간에 따라 변하거나(Dynamic), 유닛마다 다르다면(Heterogeneous), <img src="https://latex.codecogs.com/png.latex?%5Cbeta">는 우리가 원하는 <strong>Average Treatment Effect on the Treated (ATT)</strong>와 일치하지 않습니다.</p>
</section>
<section id="the-problem-of-bad-comparisons" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-of-bad-comparisons">2.2. The Problem of “Bad Comparisons”</h2>
<p>Goodman-Bacon (2021) 등의 연구에 따르면, TWFE 추정량은 가능한 모든 2x2 DiD 비교의 가중 평균으로 분해됩니다. 이때 <strong>“Bad Comparisons” (Invalid Comparisons)</strong> 문제가 발생합니다.</p>
<ul>
<li><strong>Valid Comparisons (좋은 비교):</strong>
<ul>
<li>Treated Unit vs.&nbsp;Never-treated Unit</li>
<li>Treated Unit vs.&nbsp;Not-yet-treated Unit</li>
</ul></li>
<li><strong>Invalid Comparisons (나쁜 비교):</strong>
<ul>
<li><strong>Later-treated vs.&nbsp;Earlier-treated (Already-treated):</strong> 늦게 처치를 받는 그룹을 실험군으로, 이미 처치를 받은 그룹을 통제군으로 사용하는 경우입니다.</li>
<li><strong>문제점:</strong> 만약 처치 효과가 시간에 따라 변한다면(Dynamic Effects), 이미 처치를 받은 그룹의 결과값 변화(<img src="https://latex.codecogs.com/png.latex?%5CDelta%20Y">)에는 <strong>시간 트렌드뿐만 아니라 처치 효과의 변화분</strong>이 섞여 있습니다. 이를 통제군으로 사용하면 평행 추세 가정(Parallel Trends)이 깨지게 되어 편향(Bias)이 발생합니다.</li>
</ul></li>
</ul>
<p><img src="https://shsha0110.github.io/posts/lecture/L15A/Staggered-DiD/images/outcome_trends.png" class="img-fluid" alt="Figure 2: Staggered DiD 상황에서의 Outcome 변화. A, B, C 그룹의 결과값이 처치 시점에 따라 계단식으로 상승하는 모습을 보인다."> &gt; <strong>Figure 2 설명</strong>: 각 그룹(A, B, C)의 시간에 따른 Outcome <img src="https://latex.codecogs.com/png.latex?Y">의 변화를 나타냅니다. &gt; - 점선(세모 마커)은 반사실적(Counterfactual) 상황, 즉 처치를 받지 않았을 때의 잠재적 결과를 의미합니다. &gt; - 실선(동그라미 마커)은 관측된 결과입니다. &gt; - 각 그룹이 처치를 받는 시점 이후로 Outcome이 급격히 상승하는 것을 볼 수 있으며, 이는 처치 효과의 이질성(Heterogeneity)을 시사합니다.</p>
<hr>
</section>
</section>
<section id="mathematical-framework-callaway-santanna" class="level1">
<h1>3. Mathematical Framework (Callaway &amp; Sant’Anna)</h1>
<p>이러한 문제를 해결하기 위해 Callaway &amp; Sant’Anna (2021)은 <strong>Group-Time ATT</strong>라는 개념을 도입합니다.</p>
<section id="notation-definitions" class="level2">
<h2 class="anchored" data-anchor-id="notation-definitions">3.1. Notation &amp; Definitions</h2>
<ul>
<li><strong>Time Periods:</strong> <img src="https://latex.codecogs.com/png.latex?t%20=%201,%20...,%20%5Cmathcal%7BT%7D"></li>
<li><strong>Treatment Group (<img src="https://latex.codecogs.com/png.latex?G_g">):</strong> 시점 <img src="https://latex.codecogs.com/png.latex?g">에 처음으로 처치를 받기 시작한 유닛들의 집합. (즉, <img src="https://latex.codecogs.com/png.latex?G_i%20=%20g">이면 유닛 <img src="https://latex.codecogs.com/png.latex?i">는 시점 <img src="https://latex.codecogs.com/png.latex?g">부터 처치 상태).</li>
<li><strong>Never-Treated Group (<img src="https://latex.codecogs.com/png.latex?C">):</strong> 관찰 기간 동안 처치를 받지 않은 유닛 (<img src="https://latex.codecogs.com/png.latex?G_i%20=%20%5Cinfty"> 또는 <img src="https://latex.codecogs.com/png.latex?C_i%20=%201">).</li>
<li><strong>Potential Outcomes:</strong>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Y_%7Bit%7D(0)">: 시점 <img src="https://latex.codecogs.com/png.latex?t">에서 처치를 받지 않았을 때의 잠재적 결과.</li>
<li><img src="https://latex.codecogs.com/png.latex?Y_%7Bit%7D(g)">: 시점 <img src="https://latex.codecogs.com/png.latex?t">에서, 시점 <img src="https://latex.codecogs.com/png.latex?g">에 처치를 받기 시작했을 때의 잠재적 결과.</li>
</ul></li>
<li><strong>Observed Outcome:</strong> <img src="https://latex.codecogs.com/png.latex?%0A%20%20Y_%7Bit%7D%20=%20Y_%7Bit%7D(0)%20%5Ccdot%20%5Cmathbb%7B1%7D%5C%7BG_i%20%3E%20t%5C%7D%20+%20Y_%7Bit%7D(G_i)%20%5Ccdot%20%5Cmathbb%7B1%7D%5C%7BG_i%20%5Cle%20t%5C%7D%0A%20%20"> 즉, 처치 전에는 <img src="https://latex.codecogs.com/png.latex?Y(0)">를, 처치 후에는 해당 처치 시점에 종속된 <img src="https://latex.codecogs.com/png.latex?Y(g)">를 관측합니다.</li>
</ul>
</section>
<section id="group-time-average-treatment-effect-attg-t" class="level2">
<h2 class="anchored" data-anchor-id="group-time-average-treatment-effect-attg-t">3.2. Group-Time Average Treatment Effect, <img src="https://latex.codecogs.com/png.latex?ATT(g,%20t)"></h2>
<p>가장 핵심적인 파라미터는 <strong>특정 처치 그룹 <img src="https://latex.codecogs.com/png.latex?g">가 특정 시점 <img src="https://latex.codecogs.com/png.latex?t">에 누리는 평균 처치 효과</strong>입니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AATT(g,%20t)%20=%20%5Cmathbb%7BE%7D%5BY_t(g)%20-%20Y_t(0)%20%5Cmid%20G=g%5D%0A"></p>
<p>이 정의는 매우 직관적입니다. “시점 <img src="https://latex.codecogs.com/png.latex?g">에 처치를 받은 사람들이, 시점 <img src="https://latex.codecogs.com/png.latex?t">에 실제로 겪은 효과”를 의미합니다. 만약 <img src="https://latex.codecogs.com/png.latex?t%20%5Cge%20g">라면 처치 효과(Post-treatment effect)이고, <img src="https://latex.codecogs.com/png.latex?t%20%3C%20g">라면 처치 전 효과(Pre-treatment effect, 일반적으로 0이어야 함)가 됩니다.</p>
<hr>
</section>
</section>
<section id="identification-strategy" class="level1">
<h1>4. Identification Strategy</h1>
<p><img src="https://latex.codecogs.com/png.latex?ATT(g,%20t)">를 식별(Identification)하기 위해서는 관측되지 않은 반사실적 결과 <img src="https://latex.codecogs.com/png.latex?Y_t(0)">를 대체할 수 있는 적절한 통제군이 필요합니다. 이를 위해 <strong>Parallel Trends Assumption (평행 추세 가정)</strong>이 필요합니다.</p>
<section id="parallel-trends-assumptions" class="level2">
<h2 class="anchored" data-anchor-id="parallel-trends-assumptions">4.1. Parallel Trends Assumptions</h2>
<p>CS(2021) 방법론은 연구자가 통제군을 어떻게 정의하느냐에 따라 두 가지 버전의 가정을 제시합니다.</p>
<section id="option-1-based-on-never-treated-units" class="level3">
<h3 class="anchored" data-anchor-id="option-1-based-on-never-treated-units">Option 1: Based on Never-Treated Units</h3>
<p>처치를 전혀 받지 않은 그룹(<img src="https://latex.codecogs.com/png.latex?C=1">)을 통제군으로 사용합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BE%7D%5BY_t(0)%20-%20Y_%7Bt-1%7D(0)%20%5Cmid%20G=g%5D%20=%20%5Cmathbb%7BE%7D%5BY_t(0)%20-%20Y_%7Bt-1%7D(0)%20%5Cmid%20C=1%5D%0A"></p>
<ul>
<li><strong>해석:</strong> 처치가 없었다면, 그룹 <img src="https://latex.codecogs.com/png.latex?g">의 결과값 변화 추세는 Never-treated 그룹의 변화 추세와 같았을 것이다.</li>
</ul>
</section>
<section id="option-2-based-on-not-yet-treated-units" class="level3">
<h3 class="anchored" data-anchor-id="option-2-based-on-not-yet-treated-units">Option 2: Based on Not-Yet-Treated Units</h3>
<p>시점 <img src="https://latex.codecogs.com/png.latex?t">까지 아직 처치를 받지 않은 그룹들(<img src="https://latex.codecogs.com/png.latex?D_s=0">)을 통제군으로 사용합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BE%7D%5BY_t(0)%20-%20Y_%7Bt-1%7D(0)%20%5Cmid%20G=g%5D%20=%20%5Cmathbb%7BE%7D%5BY_t(0)%20-%20Y_%7Bt-1%7D(0)%20%5Cmid%20D_t=0,%20G%20%5Cne%20g%5D%0A"></p>
<ul>
<li><strong>해석:</strong> 처치가 없었다면, 그룹 <img src="https://latex.codecogs.com/png.latex?g">의 변화 추세는 해당 시점에 아직 처치를 받지 않은 그룹들의 추세와 같았을 것이다.</li>
<li><strong>장점:</strong> Never-treated 그룹이 없거나 매우 작을 때 유용합니다.</li>
</ul>
</section>
</section>
<section id="derivation-of-the-estimator" class="level2">
<h2 class="anchored" data-anchor-id="derivation-of-the-estimator">4.2. Derivation of the Estimator</h2>
<p>Never-treated 가정을 사용할 때, <img src="https://latex.codecogs.com/png.latex?ATT(g,%20t)">는 다음과 같이 유도됩니다.</p>
<ol type="1">
<li><strong>목표:</strong> <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BE%7D%5BY_t(g)%20-%20Y_t(0)%20%5Cmid%20G=g%5D"> 구하기.</li>
<li><strong>분해:</strong> 기대값의 선형성에 의해: <img src="https://latex.codecogs.com/png.latex?%0AATT(g,t)%20=%20%5Cmathbb%7BE%7D%5BY_t(g)%20%5Cmid%20G=g%5D%20-%20%5Cmathbb%7BE%7D%5BY_t(0)%20%5Cmid%20G=g%5D%0A"> 앞항 <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BE%7D%5BY_t(g)%20%5Cmid%20G=g%5D">는 데이터에서 관측 가능합니다(<img src="https://latex.codecogs.com/png.latex?t%20%5Cge%20g">일 때). 뒷항은 반사실적이므로 관측 불가합니다.</li>
<li><strong>평행 추세 가정 적용:</strong> <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BE%7D%5BY_t(0)%20-%20Y_%7Bg-1%7D(0)%20%5Cmid%20G=g%5D%20=%20%5Cmathbb%7BE%7D%5BY_t(0)%20-%20Y_%7Bg-1%7D(0)%20%5Cmid%20C=1%5D%0A"> 이를 <img src="https://latex.codecogs.com/png.latex?Y_t(0)">에 대해 정리하면(Baseline 시점을 <img src="https://latex.codecogs.com/png.latex?g-1">로 설정): <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BE%7D%5BY_t(0)%20%5Cmid%20G=g%5D%20=%20%5Cmathbb%7BE%7D%5BY_%7Bg-1%7D(0)%20%5Cmid%20G=g%5D%20+%20%5Cunderbrace%7B%5Cmathbb%7BE%7D%5BY_t(0)%20-%20Y_%7Bg-1%7D(0)%20%5Cmid%20C=1%5D%7D_%7B%5Ctext%7BControl%20Group's%20Trend%7D%7D%0A"></li>
<li><strong>최종 식:</strong> <img src="https://latex.codecogs.com/png.latex?%0AATT(g,%20t)%20=%20%5Cunderbrace%7B%5Cmathbb%7BE%7D%5BY_t%20-%20Y_%7Bg-1%7D%20%5Cmid%20G=g%5D%7D_%7B%5Ctext%7BChange%20for%20Treated%7D%7D%20-%20%5Cunderbrace%7B%5Cmathbb%7BE%7D%5BY_t%20-%20Y_%7Bg-1%7D%20%5Cmid%20C=1%5D%7D_%7B%5Ctext%7BChange%20for%20Control%7D%7D%0A"></li>
</ol>
<p>즉, 각 그룹-시점별(<img src="https://latex.codecogs.com/png.latex?g,%20t">)로 고전적인 2x2 DiD를 수행하는 것과 같습니다. 이때 중요한 것은 <strong>“이미 처치된 그룹”을 통제군으로 섞지 않는다</strong>는 점입니다.</p>
<hr>
</section>
</section>
<section id="aggregation-summary-parameters" class="level1">
<h1>5. Aggregation: Summary Parameters</h1>
<p><img src="https://latex.codecogs.com/png.latex?ATT(g,%20t)">를 구하면 너무 많은 파라미터가 생성됩니다 (예: 그룹 5개 <img src="https://latex.codecogs.com/png.latex?%5Ctimes"> 기간 10개 = 50개). 따라서 이를 해석 가능한 형태로 요약(Aggregation)해야 합니다.</p>
<section id="event-study-aggregation-theta_de" class="level2">
<h2 class="anchored" data-anchor-id="event-study-aggregation-theta_de">5.1. Event-Study Aggregation (<img src="https://latex.codecogs.com/png.latex?%5Ctheta_D(e)">)</h2>
<p>처치 후 경과 시간(Event time, <img src="https://latex.codecogs.com/png.latex?e">)에 따른 동태적 효과를 보고 싶을 때 사용합니다. <img src="https://latex.codecogs.com/png.latex?e%20=%20t%20-%20g"> (처치 후 경과 기간).</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctheta_%7BD%7D(e)%20=%20%5Csum_%7Bg%7D%20w_g%20%5Ccdot%20ATT(g,%20g+e)%0A"> 여기서 <img src="https://latex.codecogs.com/png.latex?w_g">는 각 그룹의 샘플 비중입니다. * <img src="https://latex.codecogs.com/png.latex?e=0">: 처치 원년의 효과 * <img src="https://latex.codecogs.com/png.latex?e=1,%202,%20%5Cdots">: 처치 1년 후, 2년 후 효과 (Dynamic Effects) * <img src="https://latex.codecogs.com/png.latex?e%20%3C%200">: 처치 전 효과 (Pre-trend test로 활용 가능)</p>
</section>
<section id="simple-overall-aggregation-theta_so" class="level2">
<h2 class="anchored" data-anchor-id="simple-overall-aggregation-theta_so">5.2. Simple Overall Aggregation (<img src="https://latex.codecogs.com/png.latex?%5Ctheta_S%5EO">)</h2>
<p>단일 숫자로 전체 처치 효과를 요약하고 싶을 때 사용합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctheta_%7BS%7D%5E%7BO%7D%20=%20%5Cfrac%7B1%7D%7B%5Csum%20P(G=g)%7D%20%5Csum_%7Bg%7D%20%5Csum_%7Bt%20%5Cge%20g%7D%20ATT(g,%20t)%20P(G=g)%0A"> 이는 모든 <img src="https://latex.codecogs.com/png.latex?ATT(g,t)"> (단, <img src="https://latex.codecogs.com/png.latex?t%20%5Cge%20g">)를 평균 낸 값으로, “처치를 받은 모든 기간 동안의 평균 효과”로 해석됩니다.</p>
<hr>
</section>
</section>
<section id="conclusion-checklist" class="level1">
<h1>6. Conclusion &amp; Checklist</h1>
<p>Staggered DiD 환경에서 단순 TWFE를 사용하는 것은 이질적 처치 효과(Heterogeneous Treatment Effects)가 존재할 때 심각한 편향을 초래할 수 있습니다. Callaway &amp; Sant’Anna (2021) 등의 현대적 방법론은 <strong>“Clean Control” (Never-treated or Not-yet-treated)</strong> 만을 사용하여 <img src="https://latex.codecogs.com/png.latex?ATT(g,t)">를 식별하고, 이를 적절히 집계(Aggregation)함으로써 이 문제를 해결합니다.</p>
<p>연구자들은 이제 단순히 <code>lm(y ~ treat + time + unit_fe)</code>를 돌리기보다는, 자신의 데이터 구조(처치 시점의 다양성)와 처치 효과의 특성(동태성)을 고려하여 적절한 Estimator를 선택해야 합니다.</p>
<section id="lecture-contents-checklist" class="level3">
<h3 class="anchored" data-anchor-id="lecture-contents-checklist">Lecture Contents Checklist</h3>
<p>본 포스트는 제공된 강의 자료를 기반으로 작성되었으며, 다음 항목들을 포함하고 있습니다.</p>
<ul class="task-list">
<li><label><input type="checkbox" checked=""><strong>Staggered Adoption의 정의와 시각화:</strong> (Slide 3-5)</label></li>
<li><label><input type="checkbox" checked=""><strong>기존 TWFE의 한계:</strong> “Bad Comparisons” 및 이질성 문제 (Slide 7, 10)</label></li>
<li><label><input type="checkbox" checked=""><strong>주요 용어 정의:</strong> Static/Dynamic effects, Heterogeneity (Slide 9)</label></li>
<li><label><input type="checkbox" checked=""><strong>Notation:</strong> <img src="https://latex.codecogs.com/png.latex?Y_%7Bit%7D(g)">, <img src="https://latex.codecogs.com/png.latex?G_i">, <img src="https://latex.codecogs.com/png.latex?C_i"> 등의 엄밀한 정의 (Slide 12-14)</label></li>
<li><label><input type="checkbox" checked=""><strong>핵심 가정(Assumptions):</strong> Never-treated 및 Not-yet-treated 기반의 평행 추세 가정 (Slide 15-16, 19)</label></li>
<li><label><input type="checkbox" checked=""><strong>Identification:</strong> <img src="https://latex.codecogs.com/png.latex?ATT(g,t)">의 정의 및 유도 (Slide 17-18)</label></li>
<li><label><input type="checkbox" checked=""><strong>Aggregation Methods:</strong> Event-study형 및 Overall Average형 집계 (Slide 20-21)</label></li>
<li><label><input type="checkbox" checked=""><strong>최신 대안 방법론 언급:</strong> Callaway &amp; Sant’Anna, Sun &amp; Abraham 등 (Slide 11, 23)</label></li>
</ul>
</section>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">References</h3>
<ul>
<li>[1] Causality Lab. (2025). <em>Staggered Difference-in-Differences</em> [Lecture slides]. Seoul National University.</li>
<li>[2] Callaway, B., &amp; Sant’Anna, P. H. (2021). Difference-in-differences with multiple time periods. <em>Journal of Econometrics</em>, 225(2), 200-230.</li>
<li>[3] Goodman-Bacon, A. (2021). Difference-in-differences with variation in treatment timing. <em>Journal of Econometrics</em>, 225(2), 254-277.</li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L15A/Staggered-DiD/</guid>
  <pubDate>Sat, 24 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 17. Causal Data Science (Part 1)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L17/part-01/</link>
  <description><![CDATA[ 





<section id="introduction-all-data-is-not-created-equal" class="level1">
<h1>1. Introduction: All Data is Not Created Equal</h1>
<ul>
<li><p>현대의 데이터 과학(Data Science)은 수많은 데이터를 다루지만, 이 데이터들이 모두 동일한 가치를 지니거나 같은 방식으로 생성된 것은 아닙니다.</p></li>
<li><p><strong>“All data is not created equal”</strong>이라는 명제는 Causal Data Science의 가장 핵심적인 출발점입니다.</p></li>
<li><p>우리가 현실에서 마주하는 데이터는 거의 예외 없이 다음과 같은 문제점들을 안고 있습니다:</p>
<ul>
<li><ol type="1">
<li><strong>상이한 실험 조건 (Different Experimental Conditions):</strong> 관찰 데이터(Observational)인가, 실험 데이터(Experimental)인가?</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>상이한 모집단 (Different Underlying Populations):</strong> 데이터가 수집된 집단이 우리가 알고자 하는 대상과 같은가?</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>비무작위 표본 추출 (Non-random Sampling):</strong> 샘플링 과정에서 편향(Bias)이 발생했는가?</li>
</ol></li>
<li><ol start="4" type="1">
<li><strong>비무작위 처치 할당 (Non-random Treatment Assignment):</strong> 처치(Treatment)가 무작위로 배정되었는가, 아니면 선택 편향이 있는가?</li>
</ol></li>
<li><ol start="5" type="1">
<li><strong>측정되지 않은 변수 (Unmeasured Variables):</strong> 인과 관계를 파악하는 데 필요한 변수가 누락되었는가?</li>
</ol></li>
</ul></li>
<li><p>이러한 문제들로 인해 수집된 데이터는 “지저분(messy)”하며, 우리가 추론하고자 하는 <strong>Target</strong>과 완벽하게 일치하는 경우는 매우 드뭅니다.</p></li>
<li><p><strong>Causal Data Science</strong>의 목표는 이러한 이질적인(Heterogeneous) 데이터셋들을 결합하여 과학적이고 원칙적인(principled) 방법으로 인과 추론을 수행하는 것입니다.</p></li>
</ul>
<hr>
</section>
<section id="motivation-why-causal-data-science" class="level1">
<h1>2. Motivation: Why Causal Data Science?</h1>
<ul>
<li>왜 우리는 단순히 “빅데이터”를 모으는 것을 넘어, 데이터의 생성 과정을 고민해야 할까요? 아래 세 가지 주요 사례가 그 동기를 보여줍니다.</li>
</ul>
<section id="genetics-transportability" class="level2">
<h2 class="anchored" data-anchor-id="genetics-transportability">2.1. Genetics (Transportability)</h2>
<ul>
<li>쥐(Rats)를 대상으로 한 실험 연구에서 특정 물질이 발암성(Carcinogenic)이라는 결과가 나왔다고 가정해 봅시다.</li>
<li>우리의 질문은 다음과 같습니다.
<ul>
<li><strong>“이 결과가 인간에게도 그대로 적용될 것인가?”</strong></li>
</ul></li>
<li>이는 동물 모델에서 얻은 지식을 인간이라는 다른 모집단으로 옮길 수 있는지(Transportability)의 문제입니다.</li>
</ul>
</section>
<section id="advertisement-transfer-learning" class="level2">
<h2 class="anchored" data-anchor-id="advertisement-transfer-learning">2.2. Advertisement (Transfer Learning)</h2>
<ul>
<li>어떤 회사에서 ’제품 A’의 판매량을 높이기 위해 다양한 광고 전략의 효과를 분석했습니다. 이제 새로운 ’제품 B’를 출시하려고 합니다.
<ul>
<li><strong>“제품 A에서 얻은 데이터를 제품 B의 광고 전략 수립에 활용할 수 있는가?”</strong></li>
</ul></li>
<li>이는 기존 도메인의 지식을 새로운 도메인으로 전이(Transfer)하는 문제입니다.</li>
</ul>
</section>
<section id="robotics-domain-adaptation" class="level2">
<h2 class="anchored" data-anchor-id="robotics-domain-adaptation">2.3. Robotics (Domain Adaptation)</h2>
<ul>
<li>캘리포니아 사막에서 암석을 채굴하도록 훈련된 화성 탐사 로봇(Rover)이 있습니다.
<ul>
<li><strong>“지구에서 학습한 내용을 바탕으로, 화성에서의 비용 소모적인 탐색을 최소화할 수 있는가?”</strong></li>
</ul></li>
<li>환경이 급격히 변화했을 때, 에이전트가 어떻게 적응해야 하는지에 대한 문제입니다.</li>
</ul>
<hr>
</section>
</section>
<section id="heterogeneous-datasets-formalizing-the-messiness" class="level1">
<h1>3. Heterogeneous Datasets: Formalizing the Messiness</h1>
<ul>
<li>데이터가 지저분하다는 것은 직관적이지만, 이를 수학적으로 다루기 위해서는 형식이 필요합니다.</li>
<li>우리는 데이터를 다음과 같은 속성들의 집합으로 분류할 수 있습니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-01/images/heterogeneous_datasets_table.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: 이질적인 데이터셋들의 구조화. Target은 우리가 알고자 하는 인과 효과 <img src="https://latex.codecogs.com/png.latex?Q=P%5E*(y%7Cdo(x))">이다. 반면 우리가 가진 데이터들(<img src="https://latex.codecogs.com/png.latex?d_1,%20d_2,%20%5Cdots">)은 서로 다른 지역(Population), 수집 방식(Obs/Exp), 표본 추출 방식(Sampling), 측정 변수(Measured)를 가진다.</figcaption>
</figure>
</div>
<ul>
<li>위 그림(Figure 1)은 다양한 데이터셋(<img src="https://latex.codecogs.com/png.latex?d_1,%20d_2,%20%5Cdots">)이 어떻게 다른지를 보여줍니다.</li>
<li><strong>Target (<img src="https://latex.codecogs.com/png.latex?Q">):</strong> 우리의 목표는 <img src="https://latex.codecogs.com/png.latex?P%5E*(y%7Cdo(x))">를 알아내는 것입니다.</li>
<li><strong>Source Data:</strong>
<ul>
<li><strong>Population:</strong> LA, NY, Seoul, Boston 등 모집단이 다를 수 있습니다.</li>
<li><strong>Regime:</strong> 관찰(Observational) 데이터일 수도, 무작위 대조군 실험(RCT) 데이터일 수도 있습니다.</li>
<li><strong>Sampling:</strong> 나이(Age)나 사회경제적 지위(SES)에 따라 선택적으로 추출되었을 수 있습니다.</li>
<li><strong>Measurement:</strong> 어떤 데이터셋은 변수 <img src="https://latex.codecogs.com/png.latex?W">를 포함하지만, 다른 데이터셋은 포함하지 않을 수 있습니다.</li>
</ul></li>
</ul>
<hr>
</section>
<section id="the-big-picture-in-causal-inference" class="level1">
<h1>4. The “Big Picture” in Causal Inference</h1>
<ul>
<li>전통적인 인과 추론(Classic Causal Inference)과 Causal Data Science가 바라보는 관점의 차이를 이해해야 합니다.</li>
</ul>
<section id="classic-causal-inference-engine" class="level2">
<h2 class="anchored" data-anchor-id="classic-causal-inference-engine">4.1. Classic Causal Inference Engine</h2>
<ul>
<li>전통적인 접근법(예: Pearl의 프레임워크)은 단일 모집단 내에서의 식별(Identifiability) 문제에 집중했습니다.
<ul>
<li><ol type="1">
<li><strong>Query:</strong> <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))"></li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Causal Diagram (Knowledge):</strong> 변수들 간의 인과 구조 (DAG).</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Data:</strong> 관찰된 데이터 분포 <img src="https://latex.codecogs.com/png.latex?P(V)">.</li>
</ol></li>
<li><ol start="4" type="1">
<li><strong>Engine:</strong> 주어진 다이어그램에서 데이터만으로 쿼리를 계산할 수 있는지 판별(Yes/No)하고, 가능하다면 추정식(Estimand)을 도출.</li>
</ol></li>
</ul></li>
</ul>
</section>
<section id="causal-data-science-framework" class="level2">
<h2 class="anchored" data-anchor-id="causal-data-science-framework">4.2. Causal Data Science Framework</h2>
<ul>
<li>하지만 현실은 더 복잡합니다.</li>
<li>우리가 목표로 하는 <strong>Target Population (<img src="https://latex.codecogs.com/png.latex?%5CPi%5E*">)</strong>과 데이터가 수집되는 <strong>Source Populations (a, b, c, …)</strong>이 다르기 때문입니다 [cite: 104-135].</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-01/images/big_picture_graphs.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: Causal Data Science의 전체 그림. 중앙의 Target Population(US)에 대한 인과 효과를 추정하고 싶지만, 가용 데이터는 구조적으로 상이한 여러 지역(NY, LA, Boston, Texas 등)에서 수집되었다. 각 지역은 Causal Graph 상에서 화살표가 추가되거나(Selection Bias), 노드가 회색으로 처리되는(Missingness) 등의 구조적 차이를 보인다.</figcaption>
</figure>
</div>
<ul>
<li>위 그림(Figure 2)에서 볼 수 있듯이, 각 소스 데이터는 구조적 차이를 가집니다.
<ul>
<li><strong>Target (US):</strong> <img src="https://latex.codecogs.com/png.latex?X%20%5Crightarrow%20W%20%5Crightarrow%20Y">와 같은 기본 구조.</li>
<li><strong>NY:</strong> <img src="https://latex.codecogs.com/png.latex?W">가 측정되지 않음 (Grey Node).</li>
<li><strong>LA:</strong> <img src="https://latex.codecogs.com/png.latex?Z">가 선택 편향의 원인이 됨 (Selection Node <img src="https://latex.codecogs.com/png.latex?S">의 개입).</li>
<li><strong>Utah:</strong> <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?X">에 영향을 주지 않는 실험적 환경(Randomized).</li>
</ul></li>
<li>Causal Data Science의 목표는 이러한 <strong>Multiple, Heterogeneous Datasets</strong>를 융합(Fusion)하여 <strong>Automated Scientist</strong>처럼 타겟 질의에 답하는 것입니다.</li>
</ul>
<hr>
</section>
</section>
<section id="dimensions-and-tasks-of-causal-data-science" class="level1">
<h1>5. Dimensions and Tasks of Causal Data Science</h1>
<ul>
<li>이질적인 데이터셋을 통합적으로 다루기 위해, 데이터 수집 조건을 4가지 차원(Dimensions)의 튜플(Tuple)로 정의합니다. <img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BData%20Collection%20Tuple:%20%7D%20(d_1,%20d_2,%20d_3,%20d_4)%0A">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?d_1">: Population (모집단)</li>
<li><img src="https://latex.codecogs.com/png.latex?d_2">: Regime (관찰 vs 실험)</li>
<li><img src="https://latex.codecogs.com/png.latex?d_3">: Sampling (표본 추출 기전)</li>
<li><img src="https://latex.codecogs.com/png.latex?d_4">: Measurement (측정된 변수 집합)</li>
</ul></li>
<li>이 튜플의 변화는 우리가 해결해야 할 <strong>데이터 과학의 핵심 과제</strong>들과 1:1로 대응됩니다.</li>
</ul>
<section id="task-1-causal-inference-from-observational-studies" class="level2">
<h2 class="anchored" data-anchor-id="task-1-causal-inference-from-observational-studies">Task 1: Causal Inference (from Observational Studies)</h2>
<ul>
<li><strong>Transition:</strong> <img src="https://latex.codecogs.com/png.latex?(d_1,%20%5Ctext%7BObs%7D,%20d_3,%20d_4)%20%5Clongrightarrow%20(d_1,%20do(x),%20d_3,%20d_4)"></li>
<li><strong>Description:</strong> 가장 고전적인 인과 추론의 영역입니다. 관찰 데이터(<img src="https://latex.codecogs.com/png.latex?P(y%7Cx)">)로부터 실험적 결론(<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">)을 도출합니다. 교란 요인(Confounding Bias)을 통제하는 것이 핵심입니다.</li>
</ul>
</section>
<section id="task-2-experimental-inference-generalized-ivs" class="level2">
<h2 class="anchored" data-anchor-id="task-2-experimental-inference-generalized-ivs">Task 2: Experimental Inference (Generalized IVs)</h2>
<ul>
<li><strong>Transition:</strong> <img src="https://latex.codecogs.com/png.latex?(d_1,%20do(z),%20d_3,%20d_4)%20%5Clongrightarrow%20(d_1,%20do(x),%20d_3,%20d_4)"></li>
<li><strong>Description:</strong> 우리가 원하는 것은 <img src="https://latex.codecogs.com/png.latex?X">에 대한 개입(<img src="https://latex.codecogs.com/png.latex?do(x)">)의 효과인데, 실제 데이터는 도구 변수(Instrumental Variable, <img src="https://latex.codecogs.com/png.latex?Z">)에 대한 개입(<img src="https://latex.codecogs.com/png.latex?do(z)">)만 있는 경우입니다. 불완전한 순응(Imperfect Compliance) 문제를 다룹니다.</li>
</ul>
</section>
<section id="task-3-sampling-selection-bias" class="level2">
<h2 class="anchored" data-anchor-id="task-3-sampling-selection-bias">Task 3: Sampling Selection Bias</h2>
<ul>
<li><strong>Transition:</strong> <img src="https://latex.codecogs.com/png.latex?(d_1,%20d_2,%20%5Ctext%7BSelect%7D(Age),%20d_4)%20%5Clongrightarrow%20(d_1,%20d_2,%20%5C%7B%5C%7D,%20d_4)"></li>
<li><strong>Description:</strong> 데이터가 특정 조건(예: 나이, 소득)에 따라 편향되게 수집되었을 때, 이를 전체 모집단(Random Sample)의 분포로 복원하는 문제입니다.</li>
</ul>
</section>
<section id="task-4-transportability-external-validity" class="level2">
<h2 class="anchored" data-anchor-id="task-4-transportability-external-validity">Task 4: Transportability (External Validity)</h2>
<ul>
<li><strong>Transition:</strong> <img src="https://latex.codecogs.com/png.latex?(%5Ctext%7BBonobos%7D,%20d_2,%20d_3,%20d_4)%20%5Clongrightarrow%20(%5Ctext%7BHumans%7D,%20d_2,%20d_3,%20d_4)"></li>
<li><strong>Description:</strong> 소스 모집단(예: 보노보 원숭이, LA)에서 얻은 지식을 타겟 모집단(예: 인간, US 전체)으로 이송(Transport)하는 문제입니다. 환경적 조건의 차이를 극복해야 합니다.</li>
</ul>
</section>
<section id="summary-of-dimensions" class="level2">
<h2 class="anchored" data-anchor-id="summary-of-dimensions">Summary of Dimensions</h2>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Dimension</th>
<th style="text-align: left;">Problem Domain</th>
<th style="text-align: left;">Key Challenge</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>1. Experimental Cond.</strong></td>
<td style="text-align: left;">Causal Identification</td>
<td style="text-align: left;">Confounding Bias</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>2. Environmental Cond.</strong></td>
<td style="text-align: left;">Transportability</td>
<td style="text-align: left;">External Validity</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>3. Sampling Cond.</strong></td>
<td style="text-align: left;">Selection Bias</td>
<td style="text-align: left;">Sample Selection</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>4. Responding Cond.</strong></td>
<td style="text-align: left;">Missing Data</td>
<td style="text-align: left;">Recovering from Missingness</td>
</tr>
</tbody>
</table>
<ul>
<li>과거의 문헌들은 이 문제들을 각각 고립된 상태에서 특수한 모수적(parametric) 가정하에 다루었습니다.</li>
<li>하지만 <strong>Causal Data Science</strong>는 이 4가지 차원이 현실에서 복합적으로 나타난다는 점을 인식하고, 이를 통합적으로 해결하기 위한 일반화된 알고리즘과 조건을 연구합니다.</li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L17/part-01/</guid>
  <pubDate>Sat, 24 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 17. Causal Data Science (Part 2)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L17/part-02/</link>
  <description><![CDATA[ 





<section id="overview-the-challenge-of-experimental-conditions" class="level1">
<h1>Overview: The Challenge of Experimental Conditions</h1>
<ul>
<li><p>이전 포스트에서는 Causal Data Science가 다루는 4가지 차원(Dimensions)에 대해 개괄적으로 살펴보았습니다.</p></li>
<li><p>이번 포스트에서는 그 첫 번째이자 가장 기초가 되는 문제인 <strong>Experimental Conditions</strong>와 <strong>General Identifiability (g-ID)</strong>에 대해 깊이 있게 다룹니다.</p></li>
<li><p>우리가 <img src="https://latex.codecogs.com/png.latex?do(x)">에 대한 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 알고 싶을 때, 이상적인 상황은 <img src="https://latex.codecogs.com/png.latex?X">에 대한 무작위 대조군 실험(RCT) 데이터가 있는 것입니다.</p></li>
<li><p>하지만 현실에서는 다음과 같은 제약이 따릅니다:</p>
<ul>
<li><ol type="1">
<li><strong>윤리적/비용적 문제:</strong> <img src="https://latex.codecogs.com/png.latex?X">(예: 흡연, 유해 물질 노출)를 직접 실험할 수 없음.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>대리 실험(Surrogate Experiments):</strong> <img src="https://latex.codecogs.com/png.latex?X"> 대신 <img src="https://latex.codecogs.com/png.latex?Z">(예: 식이요법, 보조 약물)에 대한 실험 데이터만 존재함.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>이질적 데이터의 결합:</strong> 여러 개의 서로 다른 실험 결과(<img src="https://latex.codecogs.com/png.latex?do(x_1),%20do(x_2)">)를 결합하여 새로운 개입(<img src="https://latex.codecogs.com/png.latex?do(x_1,%20x_2)">)의 효과를 추정해야 함.</li>
</ol></li>
</ul></li>
<li><p>이 문제는 <strong>“우리가 가진 다양한 실험 및 관찰 데이터(<img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BP%7D">)를 활용하여, 타겟 질의(<img src="https://latex.codecogs.com/png.latex?Q">)를 식별할 수 있는가?”</strong>라는 <strong>General Identifiability</strong> 문제로 귀결됩니다.</p></li>
</ul>
<hr>
</section>
<section id="z-id-experimental-identifiability" class="level1">
<h1>2. z-ID: Experimental Identifiability</h1>
<section id="motivation-diet-cholesterol-and-heart-attack" class="level2">
<h2 class="anchored" data-anchor-id="motivation-diet-cholesterol-and-heart-attack">2.1. Motivation: Diet, Cholesterol, and Heart Attack</h2>
<ul>
<li>가장 단순한 형태의 대리 실험 문제를 살펴보겠습니다.</li>
<li>우리의 목표는 콜레스테롤 수치(<img src="https://latex.codecogs.com/png.latex?X">)가 심장마비(<img src="https://latex.codecogs.com/png.latex?Y">)에 미치는 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 알아내는 것입니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-02/images/zid_motivation_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: z-ID의 기본 모티베이션 그래프. Z(식이요법)는 X(콜레스테롤)에 영향을 주고, X는 Y(심장마비)에 영향을 준다. 점선 화살표는 측정되지 않은 교란 변수(Confounder)를 의미한다. Z와 Y 사이의 직접적인 화살표가 없다는 점(Exclusion Restriction)이 중요하다.</figcaption>
</figure>
</div>
<ul>
<li><strong>Query:</strong> <img src="https://latex.codecogs.com/png.latex?Q%20=%20P(y%7Cdo(x))"></li>
<li><strong>Problem:</strong> <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이에 관측되지 않은 교란 요인(Confounder)이 존재하여(위 그림의 <img src="https://latex.codecogs.com/png.latex?X%20%5Cleftrightarrow%20Y"> 점선), 관찰 데이터 <img src="https://latex.codecogs.com/png.latex?P(x,y,z)">만으로는 <img src="https://latex.codecogs.com/png.latex?Q">를 식별할 수 없습니다.</li>
<li><strong>Available Data:</strong>
<ul>
<li>Observational: <img src="https://latex.codecogs.com/png.latex?P(x,y,z)"></li>
<li>Experimental (Surrogate): <img src="https://latex.codecogs.com/png.latex?P(x,y%7Cdo(z))"> — 식이요법(<img src="https://latex.codecogs.com/png.latex?Z">)은 실험 가능함.</li>
</ul></li>
<li>이 경우, <img src="https://latex.codecogs.com/png.latex?Z">에 대한 실험 데이터를 사용하여 <img src="https://latex.codecogs.com/png.latex?X">의 효과를 식별할 수 있을까요? 이를 <strong>z-ID</strong> 문제라고 합니다.</li>
</ul>
</section>
<section id="instrumental-variable-formula-derived-from-experiments" class="level2">
<h2 class="anchored" data-anchor-id="instrumental-variable-formula-derived-from-experiments">2.2. Instrumental Variable Formula derived from Experiments</h2>
<p>만약 <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?X">를 통해서만 <img src="https://latex.codecogs.com/png.latex?Y">에 영향을 미친다면(즉, <img src="https://latex.codecogs.com/png.latex?Z%20%5Cto%20Y"> 직접 경로가 없고, <img src="https://latex.codecogs.com/png.latex?Z">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 교란이 없다면), 우리는 다음 식을 유도할 수 있습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Cfrac%7BP(x,y%7Cdo(z))%7D%7BP(x%7Cdo(z))%7D%20=%20P(y%7Cx,%20do(z))%0A"></p>
<section id="derivation" class="level3">
<h3 class="anchored" data-anchor-id="derivation">Derivation</h3>
<ul>
<li>이 식은 Do-Calculus 규칙을 적용하여 단계적으로 유도할 수 있습니다.</li>
<li>핵심은 <img src="https://latex.codecogs.com/png.latex?do(x)">라는 가상의 개입을 <img src="https://latex.codecogs.com/png.latex?do(z)">라는 실제 가능한 실험으로 변환하는 것입니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20%5Cxrightarrow%7B%5Ctext%7BStep%201%7D%7D%20P(y%7Cdo(x),%20do(z))%20%5Cxrightarrow%7B%5Ctext%7BStep%202%7D%7D%20P(y%7Cx,%20do(z))%0A"></p>
<section id="step-1-배제-제약-exclusion-restriction-적용" class="level4">
<h4 class="anchored" data-anchor-id="step-1-배제-제약-exclusion-restriction-적용">Step 1: 배제 제약 (Exclusion Restriction) 적용</h4>
<p><img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))%20=%20P(y%7Cdo(x),%20do(z))"></p>
<ul>
<li><strong>논리:</strong> 도구변수의 핵심 가정에 따르면 <img src="https://latex.codecogs.com/png.latex?Z">는 오직 <img src="https://latex.codecogs.com/png.latex?X">를 통해서만 <img src="https://latex.codecogs.com/png.latex?Y">에 영향을 줍니다.</li>
<li><strong>해석:</strong> 이미 <img src="https://latex.codecogs.com/png.latex?X">를 <img src="https://latex.codecogs.com/png.latex?do(x)">로 고정하여 <img src="https://latex.codecogs.com/png.latex?Y">에 대한 <img src="https://latex.codecogs.com/png.latex?X">의 영향력을 통제하고 있다면, <img src="https://latex.codecogs.com/png.latex?Z">를 추가로 <img src="https://latex.codecogs.com/png.latex?do(z)">로 고정하더라도 <img src="https://latex.codecogs.com/png.latex?Y">의 분포에는 아무런 변화가 없습니다. (<img src="https://latex.codecogs.com/png.latex?Z%20%5Cto%20Y"> 직접 경로 부재)</li>
</ul>
</section>
<section id="step-2-관측과-개입의-교환-rule-2" class="level4">
<h4 class="anchored" data-anchor-id="step-2-관측과-개입의-교환-rule-2">Step 2: 관측과 개입의 교환 (Rule 2)</h4>
<p><img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x),%20do(z))%20=%20P(y%7Cx,%20do(z))"></p>
<ul>
<li><strong>논리:</strong> <img src="https://latex.codecogs.com/png.latex?do(z)">가 수행된 실험적 환경에서는 <img src="https://latex.codecogs.com/png.latex?Z">가 무작위로 할당되므로, <img src="https://latex.codecogs.com/png.latex?Z">로 인해 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 교란(confounding) 경로가 차단됩니다.</li>
<li><strong>해석:</strong> 교란 요인이 없는 환경(<img src="https://latex.codecogs.com/png.latex?do(z)">) 하에서는, <img src="https://latex.codecogs.com/png.latex?X">를 강제로 고정(<img src="https://latex.codecogs.com/png.latex?do(x)">)했을 때의 결과나, 자연스럽게 <img src="https://latex.codecogs.com/png.latex?X=x">가 된 것을 관측했을 때의 결과가 동일합니다. 즉, <img src="https://latex.codecogs.com/png.latex?do(x)">를 조건부 확률 <img src="https://latex.codecogs.com/png.latex?x">로 바꿀 수 있습니다.</li>
</ul>
</section>
<section id="step-3-조건부-확률-정의-bayes-rule" class="level4">
<h4 class="anchored" data-anchor-id="step-3-조건부-확률-정의-bayes-rule">Step 3: 조건부 확률 정의 (Bayes’ Rule)</h4>
<ul>
<li>최종적으로 조건부 확률의 정의에 따라 우변을 다시 씁니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?P(y%7Cx,%20do(z))%20=%20%5Cfrac%7BP(x,y%7Cdo(z))%7D%7BP(x%7Cdo(z))%7D"></p>
<ul>
<li>이로써 우리가 실험 데이터(<img src="https://latex.codecogs.com/png.latex?do(z)">)를 통해 <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 인과적 효과(<img src="https://latex.codecogs.com/png.latex?do(x)">)를 식별(Identify)할 수 있음이 증명됩니다.</li>
</ul>
</section>
</section>
</section>
<section id="subtleties-of-z-id" class="level2">
<h2 class="anchored" data-anchor-id="subtleties-of-z-id">2.3. Subtleties of z-ID</h2>
<ul>
<li>모든 경우에 대리 실험이 유효한 것은 아닙니다. 그래프 구조에 따라 식별 가능 여부가 달라집니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-02/images/zid_vs_nonzid.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: z-ID 가능 그래프와 불가능 그래프의 비교. 상단 그래프들은 Z에 대한 실험으로 X의 효과를 식별할 수 있는 경우(z-ID)이고, 하단 그래프들은 식별 불가능한 경우(non-z-ID)이다. 핵심은 Z의 개입이 X와 Y 사이의 교란 요인을 통제하거나 우회할 수 있는지 여부이다.</figcaption>
</figure>
</div>
<ul>
<li>위 그림에서 <strong>z-ID</strong>가 가능한 경우와 그렇지 않은 경우(non-z-ID)를 구분하는 것은, <img src="https://latex.codecogs.com/png.latex?Z">에 대한 개입이 <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Y"> 관계를 교란하는 뒷문 경로(Back-door path)를 차단하거나, <img src="https://latex.codecogs.com/png.latex?X">의 변동을 충분히 설명할 수 있는지와 관련이 있습니다.</li>
</ul>
<hr>
</section>
</section>
<section id="advanced-derivation-combining-causal-mechanisms-z-id" class="level1">
<h1>3. Advanced Derivation: Combining Causal Mechanisms (z-ID)</h1>
<ul>
<li>복잡한 인과 그래프에서 <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7BV%7D)">(관측 데이터)만으로는 식별 불가능한 효과를, <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7BV%7D%7Cdo(z))">(실험 데이터)를 통해 어떻게 계산해 낼 수 있는지 단계별로 유도합니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-02/images/complex_zid_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3: z-ID 문제 상황. <img src="https://latex.codecogs.com/png.latex?Z%20%5Cto%20X%20%5Cto%20W%20%5Cto%20Y"> 경로 외에 점선으로 표시된 다양한 교란 요인(Confounder)들이 존재하여, 일반적인 Back-door criterion으로는 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 구할 수 없다.</figcaption>
</figure>
</div>
<section id="problem-definition-goal" class="level2">
<h2 class="anchored" data-anchor-id="problem-definition-goal">1. Problem Definition &amp; Goal</h2>
<ul>
<li><strong>Target:</strong> <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))"></li>
<li><strong>Challenge:</strong> 그래프에 존재하는 많은 교란 경로(Bi-directed arcs) 때문에, 관측 데이터 <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7BV%7D)">만으로는 이 효과를 식별할 수 없습니다 (<strong>Non-identifiable from <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7BV%7D)"></strong>).</li>
<li><strong>Solution:</strong> <img src="https://latex.codecogs.com/png.latex?Z">에 대한 실험 데이터, 즉 <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7BV%7D%7Cdo(z))">가 가용하다면(Available), 이를 활용해 타겟 효과를 계산할 수 있습니다.</li>
</ul>
</section>
<section id="derivation-step-1-decomposition-c-component" class="level2">
<h2 class="anchored" data-anchor-id="derivation-step-1-decomposition-c-component">2. Derivation Step 1: Decomposition (C-Component)</h2>
<ul>
<li>우선 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 중간 매개변수 <img src="https://latex.codecogs.com/png.latex?W">를 이용하여 두 개의 부분 문제(<img src="https://latex.codecogs.com/png.latex?Q%5BY%5D">와 <img src="https://latex.codecogs.com/png.latex?Q%5BW%5D">)로 분해합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0AP(y%7Cdo(x))%20&amp;=%20%5Csum_%7Bw%7D%20P(y%7Cdo(x),%20w)%20P(w%7Cdo(x))%20%5Cquad%20%5Ctext%7B(Law%20of%20Total%20Probability)%7D%20%5C%5C%0A&amp;=%20%5Csum_%7Bw%7D%20P(y%7Cdo(x),%20do(w))%20P(w%7Cdo(x))%20%5Cquad%20%5Ctext%7B(Rule%202:%20Action/Observation%20Exchange%20of%20W)%7D%20%5C%5C%0A&amp;=%20%5Csum_%7Bw%7D%20%5Cunderbrace%7BP(y%7Cdo(w))%7D_%7BQ%5BY%5D%7D%20%5Cunderbrace%7BP(w%7Cdo(x))%7D_%7BQ%5BW%5D%7D%20%5Cquad%20%5Ctext%7B(Rule%203:%20Removing%20Action%20of%20%7D%20X%20%5Ctext%7B)%7D%0A%5Cend%7Baligned%7D%0A"></p>
<ul>
<li><strong>해석:</strong> <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 영향은 <img src="https://latex.codecogs.com/png.latex?W">를 통하는 경로밖에 없으므로(<img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20W%20%5Cto%20Y">), <img src="https://latex.codecogs.com/png.latex?Y">에 대해 <img src="https://latex.codecogs.com/png.latex?W">를 직접 조작(<img src="https://latex.codecogs.com/png.latex?do(w)">)한다면 <img src="https://latex.codecogs.com/png.latex?X">의 조작(<img src="https://latex.codecogs.com/png.latex?do(x)">) 여부는 <img src="https://latex.codecogs.com/png.latex?Y">에 영향을 주지 않습니다.</li>
<li>이제 우리는 두 가지 항 <img src="https://latex.codecogs.com/png.latex?Q%5BY%5D">와 <img src="https://latex.codecogs.com/png.latex?Q%5BW%5D">를 각각 <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7BV%7D%7Cdo(z))">로 표현하면 됩니다.</li>
</ul>
</section>
<section id="derivation-step-2-identification-from-pmathbfvdoz" class="level2">
<h2 class="anchored" data-anchor-id="derivation-step-2-identification-from-pmathbfvdoz">3. Derivation Step 2: Identification from <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7BV%7D%7Cdo(z))"></h2>
<ul>
<li>이미지의 유도 과정을 따라 각 항을 실험 분포 <img src="https://latex.codecogs.com/png.latex?P(%5Ccdot%7Cdo(z))">로 변환합니다.</li>
</ul>
<section id="a.-identifying-qy-pydow" class="level3">
<h3 class="anchored" data-anchor-id="a.-identifying-qy-pydow">A. Identifying <img src="https://latex.codecogs.com/png.latex?Q%5BY%5D%20=%20P(y%7Cdo(w))"></h3>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Y">에 대한 <img src="https://latex.codecogs.com/png.latex?W">의 효과를 구하는 과정입니다. <img src="https://latex.codecogs.com/png.latex?W">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이에도 교란이 있으므로 <img src="https://latex.codecogs.com/png.latex?Z">를 도구로 사용합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0AQ%5BY%5D%20&amp;=%20P(y%7Cdo(w))%20%5C%5C%0A&amp;=%20P(y%7Cdo(w,%20z))%20%5Cquad%20%5Ctext%7B(Rule%203:%20Adding%20Action%20of%20%7D%20Z%20%5Ctext%7B)%7D%20%5C%5C%0A&amp;=%20%5Csum_%7Bx%7D%20P(y%7Cdo(w,%20z),%20x)%20P(x%7Cdo(w,%20z))%20%5Cquad%20%5Ctext%7B(Law%20of%20Total%20Probability%20on%20%7D%20X%20%5Ctext%7B)%7D%20%5C%5C%0A&amp;=%20%5Csum_%7Bx%7D%20P(y%7Cdo(w,%20z),%20x)%20P(x%7Cdo(z))%20%5Cquad%20%5Ctext%7B(Rule%203:%20Removing%20Action%20of%20%7D%20W%20%5Ctext%7B)%7D%20%5C%5C%0A&amp;=%20%5Csum_%7Bx%7D%20%5Cunderbrace%7BP(y%7Cdo(z),%20w,%20x)%7D_%7B%5Ctext%7BAvailable%20in%20Data%7D%7D%20%5Cunderbrace%7BP(x%7Cdo(z))%7D_%7B%5Ctext%7BAvailable%20in%20Data%7D%7D%20%5Cquad%20%5Ctext%7B(Rule%202:%20Action/Observation%20Exchange%20of%20%7D%20W%20%5Ctext%7B)%7D%0A%5Cend%7Baligned%7D%0A"></p>
<ul>
<li><strong>핵심:</strong> <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(z),%20w,%20x)">는 <img src="https://latex.codecogs.com/png.latex?do(z)"> 실험 데이터에서 관측 가능한 조건부 확률입니다. 즉, <img src="https://latex.codecogs.com/png.latex?do(w)">라는 가상의 개입을 관측값 <img src="https://latex.codecogs.com/png.latex?w">로 치환하는 데 성공했습니다.</li>
</ul>
</section>
<section id="b.-identifying-qw-pwdox" class="level3">
<h3 class="anchored" data-anchor-id="b.-identifying-qw-pwdox">B. Identifying <img src="https://latex.codecogs.com/png.latex?Q%5BW%5D%20=%20P(w%7Cdo(x))"></h3>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?W">에 미치는 효과를 구하는 과정입니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0AQ%5BW%5D%20&amp;=%20P(w%7Cdo(x))%20%5C%5C%0A&amp;=%20P(w%7Cdo(x,%20z))%20%5Cquad%20%5Ctext%7B(Rule%203:%20Adding%20Action%20of%20%7D%20Z%20%5Ctext%7B)%7D%20%5C%5C%0A&amp;=%20%5Cunderbrace%7BP(w%7Cdo(z),%20x)%7D_%7B%5Ctext%7BAvailable%20in%20Data%7D%7D%20%5Cquad%20%5Ctext%7B(Rule%202:%20Action/Observation%20Exchange%20of%20%7D%20X%20%5Ctext%7B)%7D%0A%5Cend%7Baligned%7D%0A"></p>
<ul>
<li><strong>핵심:</strong> <img src="https://latex.codecogs.com/png.latex?do(z)"> 환경에서는 <img src="https://latex.codecogs.com/png.latex?X">에서 <img src="https://latex.codecogs.com/png.latex?W">로 가는 경로의 교란이 해결되므로, <img src="https://latex.codecogs.com/png.latex?do(x)">를 관측값 <img src="https://latex.codecogs.com/png.latex?x">로 바꿀 수 있습니다.</li>
</ul>
</section>
</section>
<section id="final-formula" class="level2">
<h2 class="anchored" data-anchor-id="final-formula">4. Final Formula</h2>
<ul>
<li>위의 두 결과를 결합하면 최종적으로 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 실험 데이터 <img src="https://latex.codecogs.com/png.latex?do(z)">만으로 계산하는 식(calculus)이 완성됩니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bw%7D%20%5Cleft%5B%20%5Cleft(%20%5Csum_%7Bx'%7D%20P(y%7Cdo(z),%20w,%20x')P(x'%7Cdo(z))%20%5Cright)%20%5Ctimes%20P(w%7Cdo(z),%20x)%20%5Cright%5D%0A"></p>
<ul>
<li><strong>결론:</strong> 이처럼 복잡한 인과 그래프에서도 문제를 더 작은 단위(C-component)로 쪼개고, 각 단위를 가용한 실험 데이터(<img src="https://latex.codecogs.com/png.latex?do(z)">)로 환원(Reduce)시킴으로써 인과 효과를 식별해 낼 수 있습니다.</li>
</ul>
<hr>
</section>
</section>
<section id="example-drug-drug-interactions-combining-experiments" class="level1">
<h1>4. Example: Drug-Drug Interactions (Combining Experiments)</h1>
<ul>
<li>이 이론의 가장 강력한 응용 사례는 <strong>약물 상호작용(Drug-Drug Interaction)</strong> 분석입니다.</li>
<li>개별 약물 실험 데이터만 있을 때, 두 약물을 동시에 처방했을 때의 효과를 예측할 수 있을까요?</li>
</ul>
<section id="problem-setup" class="level2">
<h2 class="anchored" data-anchor-id="problem-setup">4.1. Problem Setup</h2>
<ul>
<li><strong>Variables:</strong>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?X_1">: 고혈압 치료제 (Anti-hypertensive drug)</li>
<li><img src="https://latex.codecogs.com/png.latex?X_2">: 당뇨 치료제 (Anti-diabetic drug)</li>
<li><img src="https://latex.codecogs.com/png.latex?B">: 혈압 (Blood pressure)</li>
<li><img src="https://latex.codecogs.com/png.latex?Y">: 심혈관 질환 (CVD)</li>
</ul></li>
<li><strong>Data Sources:</strong>
<ul>
<li>Study 1: <img src="https://latex.codecogs.com/png.latex?X_1">에 대한 RCT <img src="https://latex.codecogs.com/png.latex?%5Crightarrow%20P(v%7Cdo(x_1))"></li>
<li>Study 2: <img src="https://latex.codecogs.com/png.latex?X_2">에 대한 RCT <img src="https://latex.codecogs.com/png.latex?%5Crightarrow%20P(v%7Cdo(x_2))"></li>
</ul></li>
<li><strong>Target Query:</strong>
<ul>
<li>Joint Intervention: <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x_1,%20x_2))"></li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-02/images/drug_interaction_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 4: 약물 상호작용 인과 그래프. X1은 B에 영향을 주고, B는 Y에 영향을 준다. X2는 Y에 직접 영향을 준다. X1과 B, X2와 Y, X1와 X2 사이에는 교란 요인(점선)이 존재한다. 목표는 X1과 X2를 동시에 개입했을 때 Y의 분포를 구하는 것이다.</figcaption>
</figure>
</div>
</section>
<section id="derivation-1" class="level2">
<h2 class="anchored" data-anchor-id="derivation-1">4.2. Derivation</h2>
<ul>
<li>우리는 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x_1,%20x_2))">를 구해야 합니다. 혈압 <img src="https://latex.codecogs.com/png.latex?B">가 <img src="https://latex.codecogs.com/png.latex?X_1">과 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 매개체 역할을 한다는 점에 착안하여 식을 전개합니다.</li>
</ul>
<ol type="1">
<li><p><strong>Total Probability Theorem over B:</strong> <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x_1,%20x_2))%20=%20%5Csum_%7Bb%7D%20P(y%7Cdo(x_1,%20x_2),%20b)%20P(b%7Cdo(x_1,%20x_2))"></p></li>
<li><p><strong>Factor 1: <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x_1,%20x_2),%20b)"></strong></p>
<ul>
<li>그래프에서 <img src="https://latex.codecogs.com/png.latex?X_1">은 <img src="https://latex.codecogs.com/png.latex?B">로 가는 화살표를 제외하면 <img src="https://latex.codecogs.com/png.latex?Y">에 직접 영향을 주지 않습니다(Block).</li>
<li>따라서 <img src="https://latex.codecogs.com/png.latex?X_1">을 조건부에서 제거할 수 있습니다(Rule 3). <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x_1,%20x_2),%20b)%20=%20P(y%7Cdo(x_2),%20b)"></li>
<li>이 항은 <strong>Study 2 (<img src="https://latex.codecogs.com/png.latex?do(x_2)">)</strong> 데이터에서 <img src="https://latex.codecogs.com/png.latex?B">를 관측함으로써 얻을 수 있습니다 (<img src="https://latex.codecogs.com/png.latex?P_%7Bx_2%7D(y%7Cb)">).</li>
</ul></li>
<li><p><strong>Factor 2: <img src="https://latex.codecogs.com/png.latex?P(b%7Cdo(x_1,%20x_2))"></strong></p>
<ul>
<li>그래프에서 <img src="https://latex.codecogs.com/png.latex?X_2">는 <img src="https://latex.codecogs.com/png.latex?B">에 영향을 주지 않습니다 (<img src="https://latex.codecogs.com/png.latex?Y">에만 영향).</li>
<li>따라서 <img src="https://latex.codecogs.com/png.latex?X_2">를 제거할 수 있습니다. <img src="https://latex.codecogs.com/png.latex?P(b%7Cdo(x_1,%20x_2))%20=%20P(b%7Cdo(x_1))"></li>
<li>이 항은 <strong>Study 1 (<img src="https://latex.codecogs.com/png.latex?do(x_1)">)</strong> 데이터에서 바로 얻을 수 있습니다 (<img src="https://latex.codecogs.com/png.latex?P_%7Bx_1%7D(b)">).</li>
</ul></li>
</ol>
<section id="final-formula-1" class="level3">
<h3 class="anchored" data-anchor-id="final-formula-1">4.3. Final Formula</h3>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x_1,%20x_2))%20=%20%5Csum_%7Bb%7D%20P_%7Bx_1%7D(b)%20P_%7Bx_2%7D(y%7Cb)%0A"></p>
<ul>
<li>이 결과는 매우 강력합니다.</li>
<li><strong>두 약물을 동시에 사용하는 실험을 한 번도 수행하지 않았음에도</strong>, 개별 약물 실험 데이터를 수학적으로 결합하여 그 효과를 정확히 예측할 수 있기 때문입니다.</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="algorithm-for-general-identifiability-g-id" class="level1">
<h1>5. Algorithm for General Identifiability (g-ID)</h1>
<ul>
<li>위의 사례들을 일반화하면 <strong>General Identifiability (g-ID)</strong> 알고리즘을 만들 수 있습니다.</li>
</ul>
<section id="the-g-id-algorithm-flow" class="level2">
<h2 class="anchored" data-anchor-id="the-g-id-algorithm-flow">The g-ID Algorithm Flow</h2>
<ol type="1">
<li><strong>Decomposition (분해):</strong>
<ul>
<li>주어진 쿼리 <img src="https://latex.codecogs.com/png.latex?Q%20=%20P_x(y)">를 Causal Graph의 구조(C-components)를 이용하여 더 작은 <strong>Factors (요인들)</strong>의 곱과 합(<img src="https://latex.codecogs.com/png.latex?%5Csum%20%5Cprod">)으로 분해합니다. <img src="https://latex.codecogs.com/png.latex?Q%20=%20%5Csum%20%5Cprod%20P_%7B%5Cbullet%7D(%5Cbullet)"></li>
</ul></li>
<li><strong>Identification (식별):</strong>
<ul>
<li>분해된 각 Factor가 가용한 데이터 소스 집합 <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BP%7D%20=%20%5C%7B%20P(obs),%20P(do(z_1)),%20P(do(z_2)),%20%5Cdots%20%5C%7D"> 중 하나로부터 식별 가능한지 확인합니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-02/images/gid_algorithm_flow.png" class="img-fluid figure-img"></p>
<figcaption>Figure 5: g-ID 알고리즘의 도식화. 쿼리(좌측)가 여러 Factor로 분해되고, 각 Factor가 우측의 가용 데이터 소스(P_z1, P_zm…) 중 하나와 매칭되어 식별되는 과정을 보여준다.</figcaption>
</figure>
</div></li>
<li><strong>Conclusion:</strong>
<ul>
<li>만약 모든 Factor가 데이터 소스로부터 식별 가능하다면 <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> <strong>Identifiable</strong>.</li>
<li>하나라도 식별 불가능한 Factor가 남는다면 <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> <strong>Fail</strong>.</li>
</ul></li>
</ol>
</section>
<section id="significance" class="level2">
<h2 class="anchored" data-anchor-id="significance">Significance</h2>
<ul>
<li>이 알고리즘과 Do-calculus는 Experimental Identifiability 문제에 대해 <strong>Completeness(완전성)</strong>를 가집니다.</li>
<li>즉, 이 알고리즘으로 식별할 수 없다면, 그 인과 효과는 주어진 데이터와 그래프 가정하에서는 이론적으로 식별이 불가능한 것입니다.</li>
</ul>
<hr>
</section>
</section>
<section id="conclusion" class="level1">
<h1>6. Conclusion</h1>
<ul>
<li>이번 포스트에서는 Causal Data Science의 첫 번째 차원인 <strong>Experimental Conditions</strong>를 다루었습니다.
<ul>
<li><strong>z-ID:</strong> 직접 실험할 수 없는 변수의 효과를 대리 실험(<img src="https://latex.codecogs.com/png.latex?Z">)을 통해 식별하는 방법.</li>
<li><strong>Data Fusion:</strong> 서로 다른 실험 데이터(<img src="https://latex.codecogs.com/png.latex?do(x_1),%20do(x_2)">)를 결합하여 새로운 인과 효과를 추론하는 메커니즘.</li>
<li><strong>g-ID Algorithm:</strong> 이를 일반화하여 복잡한 쿼리를 분해하고 가용 데이터와 매핑하는 체계적인 방법론.</li>
</ul></li>
</ul>



</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L17/part-02/</guid>
  <pubDate>Sat, 24 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 17. Causal Data Science (Part 3)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L17/part-03/</link>
  <description><![CDATA[ 





<section id="introduction-moving-from-lab-to-real-world" class="level1">
<h1>1. Introduction: Moving from Lab to Real-World</h1>
<ul>
<li><p>데이터 과학과 인과 추론에서 가장 빈번하면서도 어려운 질문 중 하나는 <strong>“어떤 환경(Source)에서 얻은 지식을 다른 환경(Target)에 적용할 수 있는가?”</strong>입니다.</p></li>
<li><p>예를 들어:</p>
<ul>
<li>미국의 교육 정책 효과를 한국에 그대로 적용할 수 있는가?</li>
<li>LA에서 수행된 임상 시험 결과를 NYC의 환자들에게 적용할 수 있는가?</li>
<li>통제된 실험실 환경(Lab)의 로봇 학습 데이터를 실제 도로(Real-World)에 쓸 수 있는가?</li>
</ul></li>
<li><p>이 문제는 사회과학에서는 <strong>외부 타당성(External Validity)</strong>, 통계학에서는 <strong>일반화(Generalizability)</strong>, 머신러닝에서는 <strong>도메인 적응(Domain Adaptation)</strong> 등으로 불려왔습니다.</p></li>
<li><p><strong>Causal Data Science</strong>는 이 문제를 <strong>Transportability(이송 가능성)</strong>라는 수학적 프레임워크로 정의하고, <strong>Selection Diagram</strong>이라는 도구를 통해 데이터가 언제, 어떻게 이송 가능한지를 공식화합니다.</p></li>
</ul>
<hr>
</section>
<section id="the-transportability-problem" class="level1">
<h1>2. The Transportability Problem</h1>
<ul>
<li>우리의 목표는 Source Domain(<img src="https://latex.codecogs.com/png.latex?%5CPi">)에서 수집된 관찰(<img src="https://latex.codecogs.com/png.latex?P">) 및 실험(<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">) 데이터를 사용하여, Target Domain(<img src="https://latex.codecogs.com/png.latex?%5CPi%5E*">)에서의 인과 효과 <img src="https://latex.codecogs.com/png.latex?Q%20=%20P%5E*(y%7Cdo(x))">를 계산하는 것입니다.</li>
</ul>
<section id="trivial-vs.-non-trivial-cases" class="level2">
<h2 class="anchored" data-anchor-id="trivial-vs.-non-trivial-cases">2.1. Trivial vs.&nbsp;Non-Trivial Cases</h2>
<ul>
<li><p>가장 단순한 가정(<img src="https://latex.codecogs.com/png.latex?H_0">)은 Source와 Target의 모든 조건이 동일하다는 것입니다.</p></li>
<li><p>이 경우 결과는 자명하게 이식 가능합니다(Trivially Transportable).</p></li>
<li><p>하지만 현실(<img src="https://latex.codecogs.com/png.latex?H_a">)에서는 두 도메인 간에 차이가 존재합니다.</p>
<ul>
<li><strong>분포의 차이:</strong> <img src="https://latex.codecogs.com/png.latex?f_z%20%5Cneq%20f%5E*_z"> (예: LA와 NYC의 연령 분포가 다름)</li>
<li><strong>메커니즘의 차이:</strong> <img src="https://latex.codecogs.com/png.latex?f_y%20%5Cneq%20f%5E*_y"> (예: 동일한 치료제라도 인종적 특성에 따라 반응률이 다름)</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-03/images/transportability_spectrum.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: Source Domain과 Target Domain의 차이. 모든 구조적 방정식(Structural Equations) f가 동일하다면(H0) 문제는 간단하지만, 현실(Ha)에서는 변수들의 분포나 메커니즘이 다르다. 이를 ’Spectrum’으로 표현할 수 있다.</figcaption>
</figure>
</div>
<ul>
<li>위 그림(Figure 1)은 Source와 Target 사이에 구조적 불일치가 존재할 때, 단순한 데이터 결합이 불가능함을 보여줍니다.</li>
</ul>
<hr>
</section>
</section>
<section id="selection-diagrams-encoding-differences" class="level1">
<h1>3. Selection Diagrams: Encoding Differences</h1>
<ul>
<li>도메인 간의 차이를 체계적으로 표현하기 위해 Pearl과 Bareinboim은 <strong>Selection Diagram</strong>을 도입했습니다.</li>
</ul>
<section id="definition" class="level2">
<h2 class="anchored" data-anchor-id="definition">Definition</h2>
<ul>
<li>Selection Diagram은 기존의 Causal Graph <img src="https://latex.codecogs.com/png.latex?G">에 <strong>Selection Node (<img src="https://latex.codecogs.com/png.latex?S">)</strong>를 추가한 확장된 그래프입니다.</li>
<li><strong>Selection Node (Yellow Square):</strong> 특정 변수의 메커니즘이 도메인 간에 차이가 있음을 나타냅니다.</li>
<li>만약 변수 <img src="https://latex.codecogs.com/png.latex?V">에 대해 <img src="https://latex.codecogs.com/png.latex?f_V%20%5Cneq%20f%5E*_V">라면, <img src="https://latex.codecogs.com/png.latex?S%20%5Cto%20V"> 화살표를 추가합니다.</li>
<li>반대로, <img src="https://latex.codecogs.com/png.latex?S">가 가리키지 않는 변수는 도메인 간에 메커니즘이 동일(Invariant)하다고 가정합니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-03/images/selection_diagram_definition.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: Selection Diagram의 예시. 상단 그래프(G)는 일반적인 인과 그래프이고, 하단 우측 그래프(D)는 Selection Diagram이다. Z와 Y에 노란색 사각형(Selection Node)이 화살표를 보내고 있다. 이는 Z의 분포와 Y를 결정하는 메커니즘이 도메인 간에 다르다는 것을 의미한다. 반면 X와 W는 Selection Node가 없으므로 두 도메인에서 동일한 메커니즘을 가진다.</figcaption>
</figure>
</div>
<hr>
</section>
</section>
<section id="deriving-transport-formulas" class="level1">
<h1>4. Deriving Transport Formulas</h1>
<ul>
<li>Selection Diagram을 사용하면, 타겟 도메인의 데이터를 사용하지 않고도(혹은 일부만 사용하여) 타겟의 인과 효과를 계산하는 <strong>Transport Formula</strong>를 유도할 수 있습니다.</li>
</ul>
<section id="the-general-theorem-reduction-to-calculus" class="level2">
<h2 class="anchored" data-anchor-id="the-general-theorem-reduction-to-calculus">4.1. The General Theorem: Reduction to Calculus</h2>
<ul>
<li>Pearl &amp; Bareinboim은 Transportability 문제를 해결하기 위한 일반적인 정리를 제시했습니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Theorem:</strong> A causal relation <img src="https://latex.codecogs.com/png.latex?Q"> is transportable from <img src="https://latex.codecogs.com/png.latex?%5CPi"> to <img src="https://latex.codecogs.com/png.latex?%5CPi%5E*"> <strong>if and only if</strong> there exists a do-calculus reduction of <img src="https://latex.codecogs.com/png.latex?Q(%5CPi%5E*)"> to an estimand that is a function of the observed distributions.</p>
<p>즉, 타겟 도메인의 인과 효과 <img src="https://latex.codecogs.com/png.latex?Q">가 관측 가능한 분포들의 함수로 변환(Reduction)될 수 있을 때만, 해당 효과는 이전(Transportable) 가능합니다.</p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-03/images/transportability_calculus_slide.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3: Transportability의 일반화된 유도 과정. Selection Node(노란색 사각형)가 <img src="https://latex.codecogs.com/png.latex?Z">에 영향을 미치는 구조에서 <img src="https://latex.codecogs.com/png.latex?P%5E*(y%7Cdo(x))">를 유도하고 있다.</figcaption>
</figure>
</div>
<section id="derivation-step-by-step" class="level3">
<h3 class="anchored" data-anchor-id="derivation-step-by-step">Derivation Step-by-Step</h3>
<ul>
<li><p>위의 그래프(DAG)는 Selection Node(■)가 <img src="https://latex.codecogs.com/png.latex?Z">에만 영향을 미치고(<img src="https://latex.codecogs.com/png.latex?S%20%5Cto%20Z">), <img src="https://latex.codecogs.com/png.latex?Z%20%5Cto%20W%20%5Cto%20Y">의 경로를 가지는 상황을 보여줍니다.</p></li>
<li><p>이 경우 타겟 도메인의 효과 <img src="https://latex.codecogs.com/png.latex?P%5E*(y%7Cdo(x))">는 다음과 같이 유도됩니다.</p></li>
<li><ol type="1">
<li><strong>Definition of Target Quantity:</strong></li>
</ol>
<ul>
<li>타겟 도메인(<img src="https://latex.codecogs.com/png.latex?%5CPi%5E*">)에서의 효과는 Selection Node(<img src="https://latex.codecogs.com/png.latex?S">)가 켜진 조건부 확률(<img src="https://latex.codecogs.com/png.latex?S=%5Cblacksquare">)과 같습니다. <img src="https://latex.codecogs.com/png.latex?Q%20=%20P%5E*(y%7Cdo(x))%20=%20P(y%7Cdo(x),%20S)"></li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Probability Axioms (Conditioning on W):</strong></li>
</ol>
<ul>
<li>중간 변수 <img src="https://latex.codecogs.com/png.latex?W">에 대해 전체 확률의 법칙을 적용합니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7Bw%7D%20P(y%7Cdo(x),%20S,%20w)P(w%7Cdo(x),%20S)"></li>
</ul></li>
<li><ol start="3" type="1">
<li><strong>Rule 1 &amp; Graph Properties (Removal of S):</strong></li>
</ol>
<ul>
<li>그래프에서 <img src="https://latex.codecogs.com/png.latex?W">가 주어졌을 때, <img src="https://latex.codecogs.com/png.latex?Y">는 Selection Node(<img src="https://latex.codecogs.com/png.latex?S">)와 분리(d-separated)됩니다(<img src="https://latex.codecogs.com/png.latex?S%20%5Cto%20Z%20%5Cto%20W%20%5Cto%20Y">).</li>
<li>따라서 첫 번째 항에서 <img src="https://latex.codecogs.com/png.latex?S">를 제거할 수 있습니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7Bw%7D%20P(y%7Cdo(x),%20w)P(w%7Cdo(x),%20S)"></li>
</ul></li>
<li><ol start="4" type="1">
<li><strong>Rule 3 (Removal of do(x)):</strong></li>
</ol>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?X">에 대한 개입(<img src="https://latex.codecogs.com/png.latex?do(x)">)은 <img src="https://latex.codecogs.com/png.latex?W">에 영향을 주지 않습니다(그래프상 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?W"> 사이의 경로는 <img src="https://latex.codecogs.com/png.latex?Z">를 통하거나 교란 경로뿐인데, 개입 시 차단됨).</li>
<li>따라서 두 번째 항에서 <img src="https://latex.codecogs.com/png.latex?do(x)">를 제거할 수 있습니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7Bw%7D%20P(y%7Cdo(x),%20w)P(w%7CS)"></li>
</ul></li>
<li><ol start="5" type="1">
<li><strong>Final Transport Formula:</strong></li>
</ol>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?P(w%7CS)">는 타겟 도메인에서의 <img src="https://latex.codecogs.com/png.latex?W"> 분포인 <img src="https://latex.codecogs.com/png.latex?P%5E*(w)">와 같습니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7Bw%7D%20P(y%7Cdo(x),%20w)P%5E*(w)"></li>
</ul></li>
<li><p><strong>해석:</strong> 이 식은 타겟 도메인에서 <img src="https://latex.codecogs.com/png.latex?Y">나 <img src="https://latex.codecogs.com/png.latex?Z">에 대한 실험을 할 필요 없이, <strong>소스 도메인의 실험 결과(<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x),%20w)">)</strong>와 <strong>타겟 도메인의 관측 데이터(<img src="https://latex.codecogs.com/png.latex?P%5E*(w)">)</strong>만 결합하면 타겟의 인과 효과를 계산할 수 있음을 보여줍니다.</p></li>
</ul>
</section>
</section>
<section id="specific-cases-derived-from-graph-structure" class="level2">
<h2 class="anchored" data-anchor-id="specific-cases-derived-from-graph-structure">4.2. Specific Cases derived from Graph Structure</h2>
<ul>
<li>이제 그래프 구조(Causal Story)에 따라 공식이 어떻게 달라지는지 구체적인 세 가지 사례를 살펴보겠습니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-03/images/three_transportability_cases.png" class="img-fluid figure-img"></p>
<figcaption>Figure 4: 세 가지 다른 인과 구조에 따른 Transportability. (a) Z가 교란 변수(Confounder)인 경우, (b) Z가 결과의 결과(Outcome’s outcome)인 경우, (c) Z가 매개 변수(Mediator)인 경우. 각 경우마다 Selection Node(노란색 사각형)의 위치가 다르며, 이에 따라 유도되는 공식도 다르다.</figcaption>
</figure>
</div>
<section id="case-a-z-represents-age-confounder" class="level3">
<h3 class="anchored" data-anchor-id="case-a-z-represents-age-confounder">Case (a): Z represents Age (Confounder)</h3>
<ul>
<li><strong>Scenario:</strong> <img src="https://latex.codecogs.com/png.latex?Z">(나이)는 <img src="https://latex.codecogs.com/png.latex?X">(치료)와 <img src="https://latex.codecogs.com/png.latex?Y">(결과) 모두에 영향을 미치는 교란 요인입니다. 나이 분포(<img src="https://latex.codecogs.com/png.latex?P(z)">)는 도메인마다 다릅니다(<img src="https://latex.codecogs.com/png.latex?S%20%5Cto%20Z">).</li>
<li><strong>Formula:</strong> <img src="https://latex.codecogs.com/png.latex?P%5E*(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(y%7Cdo(x),%20z)%20P%5E*(z)"></li>
<li><strong>Interpretation:</strong> Source에서 <img src="https://latex.codecogs.com/png.latex?Z">별 인과 효과(<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x),z)">)를 구한 뒤, 이를 Target의 나이 분포(<img src="https://latex.codecogs.com/png.latex?P%5E*(z)">)에 맞춰 가중 평균(Re-weighting)합니다. 이것이 표준적인 <strong>Adjustment Formula</strong>입니다.</li>
</ul>
</section>
<section id="case-b-z-represents-language-skill-proxy" class="level3">
<h3 class="anchored" data-anchor-id="case-b-z-represents-language-skill-proxy">Case (b): Z represents Language Skill (Proxy)</h3>
<ul>
<li><strong>Scenario:</strong> <img src="https://latex.codecogs.com/png.latex?Z">(언어 능력)는 <img src="https://latex.codecogs.com/png.latex?Y">의 결과물일 뿐, <img src="https://latex.codecogs.com/png.latex?X">나 <img src="https://latex.codecogs.com/png.latex?Y">의 원인이 아닙니다. <img src="https://latex.codecogs.com/png.latex?Z">의 메커니즘이 도메인마다 다릅니다.</li>
<li><strong>Formula:</strong> <img src="https://latex.codecogs.com/png.latex?P%5E*(y%7Cdo(x))%20=%20P(y%7Cdo(x))"></li>
<li><strong>Interpretation:</strong> <img src="https://latex.codecogs.com/png.latex?Z">는 인과 경로에 개입하지 않으므로, <img src="https://latex.codecogs.com/png.latex?Z">의 차이는 <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Y"> 효과에 영향을 주지 않습니다. 즉, Source의 결과를 그대로 Target에 적용할 수 있습니다.</li>
</ul>
</section>
<section id="case-c-z-represents-bio-marker-mediator" class="level3">
<h3 class="anchored" data-anchor-id="case-c-z-represents-bio-marker-mediator">Case (c): Z represents Bio-marker (Mediator)</h3>
<ul>
<li><strong>Scenario:</strong> <img src="https://latex.codecogs.com/png.latex?Z">는 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 매개 변수입니다. <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Z">에 미치는 영향은 동일하지만, <img src="https://latex.codecogs.com/png.latex?Z">의 기저 분포나 측정 방식이 다를 수 있습니다(<img src="https://latex.codecogs.com/png.latex?S%20%5Cto%20Z">).</li>
<li><strong>Formula:</strong> <img src="https://latex.codecogs.com/png.latex?P%5E*(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(y%7Cdo(x),%20z)%20P%5E*(z%7Cx)"></li>
<li><strong>Interpretation:</strong> <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Z"> 메커니즘이 다르다면, Target 도메인에서의 조건부 확률 <img src="https://latex.codecogs.com/png.latex?P%5E*(z%7Cx)"> 정보를 사용하여 보정해야 합니다.</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="algorithm-to-determine-if-an-effect-is-transportable" class="level1">
<h1>5. Algorithm to Determine if an Effect is Transportable</h1>
<ul>
<li>지금까지 살펴본 사례들은 비교적 단순한 구조였지만, 현실의 인과 그래프는 훨씬 복잡할 수 있습니다.</li>
<li>Pearl &amp; Bareinboim은 임의의 그래프 구조에 대해 Transportability를 판단하고 공식을 도출하는 일반화된 알고리즘을 제시했습니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-03/images/transportability_algorithm_slide.png" class="img-fluid figure-img"></p>
<figcaption>Figure 5: Transportability 알고리즘의 예시. 복잡한 그래프(입력)에 대해 Selection Node의 위치를 분석하여, 타겟과 소스 데이터를 결합한 공식(출력)을 도출한다.</figcaption>
</figure>
</div>
<section id="input-output" class="level2">
<h2 class="anchored" data-anchor-id="input-output">5.1. Input &amp; Output</h2>
<ul>
<li><strong>INPUT:</strong> Selection Node(노란색 사각형, <img src="https://latex.codecogs.com/png.latex?%5Cblacksquare">)가 표시된 인과 그래프(Annotated Causal Graph).</li>
<li><strong>OUTPUT:</strong>
<ol type="1">
<li><strong>판단(Decision):</strong> 타겟 도메인의 인과 효과 <img src="https://latex.codecogs.com/png.latex?P%5E*(y%7Cdo(x))">가 이전을 통해 식별 가능한가(Transportable)?</li>
<li><strong>공식(Formula):</strong> 식별 가능하다면, 다음 두 가지 데이터를 결합한 수식:
<ul>
<li>소스 도메인의 실험 데이터 (Measurements from Source experiments)</li>
<li>타겟 도메인의 관측 데이터 (Measurements from Target observations)</li>
</ul></li>
</ol></li>
</ul>
</section>
<section id="the-logic-handling-non-identifiable-factors" class="level2">
<h2 class="anchored" data-anchor-id="the-logic-handling-non-identifiable-factors">5.2. The Logic: Handling Non-Identifiable Factors</h2>
<ul>
<li>이 알고리즘의 핵심은 전체 문제를 <strong>Q-factor(C-component)</strong> 단위로 쪼개고, 각 조각을 어디서 가져올지 결정하는 것입니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Key Logic:</strong> “Any <img src="https://latex.codecogs.com/png.latex?Q">-factors non-identifiable from <img src="https://latex.codecogs.com/png.latex?P%5E*(%5Cmathbf%7BV%7D)"> should be identified from experiments in the source domain. This corresponds to checking no <img src="https://latex.codecogs.com/png.latex?%5Cblacksquare"> points to the variables in the non-identified <img src="https://latex.codecogs.com/png.latex?Q">-factor!”</p>
</blockquote>
<ul>
<li><ol type="1">
<li><strong>Target Priority:</strong></li>
</ol>
<ul>
<li>먼저 타겟 도메인의 관측 데이터 <img src="https://latex.codecogs.com/png.latex?P%5E*(%5Cmathbf%7BV%7D)">만으로 계산 가능한 요소인지 확인합니다. 가능하다면 <img src="https://latex.codecogs.com/png.latex?P%5E*">를 그대로 사용합니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Source Fallback:</strong></li>
</ol>
<ul>
<li>타겟 데이터만으로 식별 불가능한(Non-identifiable) 요소가 있다면, 소스 도메인의 실험 결과(<img src="https://latex.codecogs.com/png.latex?P(v%7Cdo(x))">)를 가져와야 합니다.</li>
</ul></li>
<li><ol start="3" type="1">
<li><strong>Transportability Condition:</strong></li>
</ol>
<ul>
<li>이때 소스 데이터를 가져오기 위해서는 <strong>“해당 요소에 영향을 주는 Selection Node(<img src="https://latex.codecogs.com/png.latex?%5Cblacksquare">)가 없어야 한다”</strong>는 조건이 붙습니다.</li>
<li>만약 Selection Node가 가리키고 있다면, 메커니즘이 다르다는 뜻이므로 소스 데이터를 타겟에 대입할 수 없습니다. (즉, Transportable 하지 않음)</li>
</ul></li>
</ul>
</section>
<section id="derivation-example" class="level2">
<h2 class="anchored" data-anchor-id="derivation-example">5.3. Derivation Example</h2>
<ul>
<li>하단의 수식은 이 알고리즘을 적용한 결과입니다. 그래프의 각 부분(변수)이 어떻게 처리되었는지 분석해 봅시다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AP%5E*(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(y%7Cdo(x),z)%20%5Csum_%7Bw%7D%20P%5E*(z%7Cw)%20%5Csum_%7Bt%7D%20P(w%7Cdo(x),t)P%5E*(t)%0A"></p>
<ul>
<li><p>이 식은 크게 네 부분으로 나뉩니다.</p></li>
<li><ol type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?P%5E*(t)"> (Target Data):</strong></li>
</ol>
<ul>
<li>변수 <img src="https://latex.codecogs.com/png.latex?T">에는 Selection Node가 없습니다. 또한 <img src="https://latex.codecogs.com/png.latex?T">는 외생 변수이므로 타겟 도메인의 분포를 그대로 사용합니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?P(w%7Cdo(x),t)"> (Source Experiment):</strong></li>
</ol>
<ul>
<li>변수 <img src="https://latex.codecogs.com/png.latex?W">를 구하는 부분입니다. <img src="https://latex.codecogs.com/png.latex?W">에는 직접적인 Selection Node가 붙어있지 않으므로, 소스 도메인의 실험 결과(<img src="https://latex.codecogs.com/png.latex?X">에 개입했을 때의 <img src="https://latex.codecogs.com/png.latex?W">)를 가져와서 사용합니다.</li>
</ul></li>
<li><ol start="3" type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?P%5E*(z%7Cw)"> (Target Observation):</strong></li>
</ol>
<ul>
<li>변수 <img src="https://latex.codecogs.com/png.latex?Z">에는 Selection Node(<img src="https://latex.codecogs.com/png.latex?%5Cblacksquare%20%5Cto%20Z">)가 붙어 있습니다. 즉, 소스와 타겟 간에 메커니즘 차이가 있습니다.</li>
<li>따라서 소스 데이터를 쓰면 안 됩니다. 다행히 <img src="https://latex.codecogs.com/png.latex?Z">는 <img src="https://latex.codecogs.com/png.latex?W">가 주어졌을 때 타겟 도메인의 관측 데이터(<img src="https://latex.codecogs.com/png.latex?P%5E*">)만으로 식별이 가능하므로, <img src="https://latex.codecogs.com/png.latex?P%5E*(z%7Cw)">를 직접 측정하여 사용합니다.</li>
</ul></li>
<li><ol start="4" type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x),z)"> (Source Experiment):</strong></li>
</ol>
<ul>
<li>결과 변수 <img src="https://latex.codecogs.com/png.latex?Y">에는 Selection Node가 없습니다. 따라서 소스 도메인에서 <img src="https://latex.codecogs.com/png.latex?X">에 개입했을 때 <img src="https://latex.codecogs.com/png.latex?Z">에 따른 <img src="https://latex.codecogs.com/png.latex?Y">의 반응을 측정한 실험 데이터를 그대로 가져옵니다.</li>
</ul></li>
<li><p><strong>결론:</strong></p>
<ul>
<li>이 공식은 타겟 도메인에서 직접 실험을 하지 않고도(<img src="https://latex.codecogs.com/png.latex?do(x)"> in Target), <strong>소스의 실험 결과</strong>(1, 4번 항)와 <strong>타겟의 관측 결과</strong>(2, 3번 항)를 정교하게 조립하여 타겟의 인과 효과를 계산해 낸 것입니다.</li>
</ul></li>
</ul>
<hr>
</section>
</section>
<section id="general-transportability-data-fusion-from-multiple-domains" class="level1">
<h1>6. General Transportability: Data Fusion from Multiple Domains</h1>
<ul>
<li>가장 복잡하면서도 강력한 시나리오는, 단일 소스만으로는 문제를 해결할 수 없고 여러 소스 도메인(<img src="https://latex.codecogs.com/png.latex?%5CPi%5Ea,%20%5CPi%5Eb,%20%5Cdots">)의 데이터를 결합(Data Fusion)해야만 타겟(<img src="https://latex.codecogs.com/png.latex?%5CPi%5E*">)을 추론할 수 있는 경우입니다.</li>
</ul>
<section id="motivation-the-la-nyc-example" class="level2">
<h2 class="anchored" data-anchor-id="motivation-the-la-nyc-example">Motivation: The LA &amp; NYC Example</h2>
<ul>
<li><strong>Goal:</strong> 타겟 도메인(Target)에서의 인과 효과 <img src="https://latex.codecogs.com/png.latex?Q%20=%20P%5E*(y%7Cdo(x))">를 구하고 싶습니다.</li>
<li><strong>Problem:</strong> 그 어떤 도메인도 타겟과 완벽하게 일치하지 않습니다.
<ul>
<li><strong>Source A (LA, <img src="https://latex.codecogs.com/png.latex?%5CPi%5Ea">):</strong> <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">에 Selection Node(<img src="https://latex.codecogs.com/png.latex?%5Cblacksquare">)가 있습니다. 즉, <img src="https://latex.codecogs.com/png.latex?Y">가 생성되는 메커니즘이 타겟과 다릅니다. (하지만 <img src="https://latex.codecogs.com/png.latex?Z">는 타겟과 동일)</li>
<li><strong>Source B (NYC, <img src="https://latex.codecogs.com/png.latex?%5CPi%5Eb">):</strong> <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Z">에 Selection Node(<img src="https://latex.codecogs.com/png.latex?%5Cblacksquare">)가 있습니다. 즉, <img src="https://latex.codecogs.com/png.latex?Z">가 생성되는 메커니즘이 타겟과 다릅니다. (하지만 <img src="https://latex.codecogs.com/png.latex?Y">는 타겟과 동일)</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-03/images/multi_domain_fusion.png" class="img-fluid figure-img"></p>
<figcaption>Figure 6: 다중 도메인 데이터 융합(Data Fusion). 좌측(LA)은 Y와 X에, 우측(NYC)은 Z와 X에 구조적 차이(Selection Node)가 있다. 이 두 불완전한 소스를 결합하여 타겟의 효과를 추정해야 한다.</figcaption>
</figure>
</div>
</section>
<section id="derivation-steps-reduced-to-calculus" class="level2">
<h2 class="anchored" data-anchor-id="derivation-steps-reduced-to-calculus">Derivation Steps (Reduced to Calculus)</h2>
<ul>
<li>우리는 <strong>do-calculus</strong>와 확률의 법칙을 사용하여, 타겟 쿼리를 각 소스 도메인에서 식별 가능한(Transportable) 부분들로 분해하고 매핑합니다.</li>
</ul>
<ol type="1">
<li><p><strong>Definition &amp; Axioms (Decomposition):</strong> 먼저 타겟의 Selection Node 집합(<img src="https://latex.codecogs.com/png.latex?%5Cblacksquare_%7Bxzy%7D">)을 조건부에 포함시킨 뒤, <img src="https://latex.codecogs.com/png.latex?Z">에 대해 전체 확률의 법칙을 적용합니다. <img src="https://latex.codecogs.com/png.latex?Q%20=%20P%5E*(y%7Cdo(x))%20=%20P(y%7Cdo(x),%20%5Cblacksquare_%7Bxzy%7D)"> <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7Bz%7D%20P(y%7Cdo(x),%20z,%20%5Cblacksquare_%7Bxzy%7D)%20P(z%7Cdo(x),%20%5Cblacksquare_%7Bxzy%7D)"></p></li>
<li><p><strong>Rule 2 (Action/Observation Exchange):</strong> 첫 번째 항에서 <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Y"> 경로를 차단하므로, 관측된 <img src="https://latex.codecogs.com/png.latex?z">를 개입 <img src="https://latex.codecogs.com/png.latex?do(z)">로 바꿀 수 있습니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7Bz%7D%20P(y%7Cdo(x),%20do(z),%20%5Cblacksquare_%7Bxzy%7D)%20P(z%7Cdo(x),%20%5Cblacksquare_%7Bxzy%7D)"></p></li>
<li><p><strong>Rule 3 (Deletion of Action):</strong> 첫 번째 항에서 <img src="https://latex.codecogs.com/png.latex?Z">를 고정(<img src="https://latex.codecogs.com/png.latex?do(z)">)하면 <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 영향은 사라집니다. 따라서 <img src="https://latex.codecogs.com/png.latex?do(x)">를 제거합니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7Bz%7D%20P(y%7Cdo(z),%20%5Cblacksquare_%7Bxzy%7D)%20P(z%7Cdo(x),%20%5Cblacksquare_%7Bxzy%7D)"></p></li>
<li><p><strong>Rule 1 (Removal of Irrelevant Selection Nodes)</strong></p>
<ul>
<li><p><strong>논리:</strong> “이 변수(<img src="https://latex.codecogs.com/png.latex?Y"> 또는 <img src="https://latex.codecogs.com/png.latex?Z">)를 결정하는 데 있어, 관련 없는 Selection Node는 지울 수 있다.” (d-separation)</p></li>
<li><p><strong>(Term 1) <img src="https://latex.codecogs.com/png.latex?Y">에 대한 분석:</strong></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Y">는 <img src="https://latex.codecogs.com/png.latex?Z">가 주어졌을 때, <img src="https://latex.codecogs.com/png.latex?Z">나 <img src="https://latex.codecogs.com/png.latex?X">에 붙은 Selection Node(<img src="https://latex.codecogs.com/png.latex?%5Cblacksquare_z,%20%5Cblacksquare_x">)와는 독립적입니다. (그래프상 <img src="https://latex.codecogs.com/png.latex?Y">로 오는 화살표가 없음)</li>
<li>따라서 <img src="https://latex.codecogs.com/png.latex?%5Cblacksquare_y">만 남기고 나머지는 지웁니다. <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(z),%20%5Cblacksquare_%7Bx,z,y%7D)%20%5Cxrightarrow%7B%5Ctext%7BRule%201%7D%7D%20P(y%7Cdo(z),%20%5Cblacksquare_y)"></li>
</ul></li>
<li><p><strong>(Term 2) <img src="https://latex.codecogs.com/png.latex?Z">에 대한 분석:</strong></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Z">는 <img src="https://latex.codecogs.com/png.latex?X">가 주어졌을 때, <img src="https://latex.codecogs.com/png.latex?Y">에 붙은 Selection Node(<img src="https://latex.codecogs.com/png.latex?%5Cblacksquare_x,%20%5Cblacksquare_y">)와 독립적입니다.</li>
<li>따라서 <img src="https://latex.codecogs.com/png.latex?%5Cblacksquare_z">만 남기고 <img src="https://latex.codecogs.com/png.latex?%5Cblacksquare_x,%20%5Cblacksquare_y">는 지웁니다. <img src="https://latex.codecogs.com/png.latex?P(z%7Cdo(x),%20%5Cblacksquare_%7Bx,z,y%7D)%20%5Cxrightarrow%7B%5Ctext%7BRule%201%7D%7D%20P(z%7Cdo(x),%20%5Cblacksquare_%7Bz%7D)"></li>
</ul></li>
</ul></li>
<li><p><strong>Definition (Mapping to Sources)</strong></p>
<ul>
<li><p><strong>논리:</strong> “남아있는 Selection Node 구성과 일치하는 도메인(도시)을 찾아 연결한다.”</p></li>
<li><p><strong>(Term 1) <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(z),%20%5Cblacksquare_y)"> 매핑:</strong></p>
<ul>
<li>우리는 <img src="https://latex.codecogs.com/png.latex?Y">에 대한 메커니즘이 타겟과 동일한(즉, <img src="https://latex.codecogs.com/png.latex?%5Cblacksquare_y">가 없는/영향을 안 주는) 도메인을 찾아야 합니다.</li>
<li><strong>LA (<img src="https://latex.codecogs.com/png.latex?%5CPi%5Ea">):</strong> <img src="https://latex.codecogs.com/png.latex?Y">에 <img src="https://latex.codecogs.com/png.latex?%5Cblacksquare">가 있음 (Bad).</li>
<li><strong>NYC (<img src="https://latex.codecogs.com/png.latex?%5CPi%5Eb">):</strong> <img src="https://latex.codecogs.com/png.latex?Y">에 <img src="https://latex.codecogs.com/png.latex?%5Cblacksquare">가 <strong>없음</strong> (Good).</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> 따라서 <strong>NYC 데이터(<img src="https://latex.codecogs.com/png.latex?P%5E%7B(b)%7D">)</strong>를 사용합니다. <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(z),%20%5Cblacksquare_y)%20%5Crightarrow%20P%5E%7B(b)%7D(y%7Cdo(z))"></li>
</ul></li>
<li><p><strong>(Term 2) <img src="https://latex.codecogs.com/png.latex?P(z%7Cdo(x),%20%5Cblacksquare_%7Bz,x%7D)"> 매핑:</strong></p>
<ul>
<li>우리는 <img src="https://latex.codecogs.com/png.latex?Z">에 대한 메커니즘이 타겟과 동일한(즉, <img src="https://latex.codecogs.com/png.latex?%5Cblacksquare_z">가 없는) 도메인을 찾아야 합니다.</li>
<li><strong>NYC (<img src="https://latex.codecogs.com/png.latex?%5CPi%5Eb">):</strong> <img src="https://latex.codecogs.com/png.latex?Z">에 <img src="https://latex.codecogs.com/png.latex?%5Cblacksquare">가 있음 (Bad).</li>
<li><strong>LA (<img src="https://latex.codecogs.com/png.latex?%5CPi%5Ea">):</strong> <img src="https://latex.codecogs.com/png.latex?Z">에 <img src="https://latex.codecogs.com/png.latex?%5Cblacksquare">가 <strong>없음</strong> (Good).</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> 따라서 <strong>LA 데이터(<img src="https://latex.codecogs.com/png.latex?P%5E%7B(a)%7D">)</strong>를 사용합니다. <img src="https://latex.codecogs.com/png.latex?P(z%7Cdo(x),%20%5Cblacksquare_%7Bz%7D)%20%5Crightarrow%20P%5E%7B(a)%7D(z%7Cdo(x))"></li>
</ul></li>
</ul></li>
</ol>
</section>
<section id="final-transport-formula" class="level2">
<h2 class="anchored" data-anchor-id="final-transport-formula">Final Transport Formula</h2>
<p>최종적으로 두 도메인의 데이터를 결합한 공식은 다음과 같습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP%5E*(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20%5Cunderbrace%7BP%5E%7B(b)%7D(y%7Cdo(z))%7D_%7B%5Ctext%7Bfrom%20NYC%7D%7D%20%5Cunderbrace%7BP%5E%7B(a)%7D(z%7Cdo(x))%7D_%7B%5Ctext%7Bfrom%20LA%7D%7D%0A"></p>
<ul>
<li><strong>의미:</strong>
<ul>
<li><strong>LA 데이터</strong>에서는 <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Z">에 미치는 효과를 가져옵니다 (<img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Z"> 메커니즘 공유).</li>
<li><strong>NYC 데이터</strong>에서는 <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 효과를 가져옵니다 (<img src="https://latex.codecogs.com/png.latex?Z%20%5Cto%20Y"> 메커니즘 공유).</li>
<li>이들을 결합함으로써, <strong>그 어떤 도시에서도 수행된 적 없는 전체 실험(<img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Y">)의 결과</strong>를 정확하게 예측해 낼 수 있습니다.</li>
</ul></li>
</ul>
<hr>
</section>
</section>
<section id="conclusion-is-the-gold-standard-golden" class="level1">
<h1>7. Conclusion: Is the Gold Standard Golden?</h1>
<ul>
<li>무작위 대조군 실험(RCT)은 인과 추론의 “Gold Standard”로 여겨집니다.</li>
<li>하지만 Transportability 이론은 RCT조차 완벽하지 않음을 시사합니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-03/images/rct_limitations.png" class="img-fluid figure-img"></p>
<figcaption>Figure 7: RCT의 한계. 랜덤화(Randomization)는 X로 들어오는 화살표를 제거(우측 그래프)하여 교란을 없애주지만, 환경적 차이를 나타내는 Selection Node(상단 노란 사각형)는 제거하지 못한다. 즉, RCT는 내부 타당성(Internal Validity)만 보장할 뿐, 외부 타당성(External Validity)은 별도의 문제이다.</figcaption>
</figure>
</div>
<ul>
<li><strong>Lesson:</strong> 완벽한 RCT 데이터가 있더라도, 모집단 간의 차이(Selection Node)가 존재한다면 반드시 <strong>Transportability Exercise</strong>를 거쳐야 합니다.</li>
<li><strong>Completeness:</strong> 다행히도, Selection Diagram과 do-calculus를 이용한 이송 알고리즘은 <strong>완전(Complete)</strong>합니다. 즉, 이 방법으로 이송 공식을 유도할 수 없다면, 해당 데이터만으로는 이론적으로 타겟 효과를 식별할 수 없음이 증명된 것입니다.</li>
</ul>



</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L17/part-03/</guid>
  <pubDate>Sat, 24 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 17. Causal Data Science (Part 4)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L17/part-04/</link>
  <description><![CDATA[ 





<section id="introduction-the-man-made-bias" class="level1">
<h1>1. Introduction: The “Man-Made” Bias</h1>
<ul>
<li>데이터 과학에서 우리는 종종 <strong>“데이터가 스스로 말하게 하라(Let the data speak)”</strong>는 격언을 듣습니다.</li>
<li>하지만 데이터가 수집되는 과정에서 이미 입이 막혀 있거나, 왜곡된 목소리만 내고 있다면 어떨까요? 이것이 바로 <strong>선택 편향(Selection Bias)</strong>의 문제입니다.</li>
<li>선택 편향은 데이터 샘플링 과정에서 특정 개체가 우선적으로 포함되거나 배제됨으로써 발생합니다.</li>
<li>이는 단순한 통계적 오차를 넘어, 인과 추론의 타당성을 근본적으로 위협하는 주요 장애물입니다.</li>
</ul>
<section id="confounding-vs.-selection-bias" class="level2">
<h2 class="anchored" data-anchor-id="confounding-vs.-selection-bias">Confounding vs.&nbsp;Selection Bias</h2>
<ul>
<li>우리는 앞서 교란(Confounding)에 대해 다뤘습니다. 두 편향은 근본적으로 다릅니다.</li>
<li><strong>Confounding:</strong>
<ul>
<li>자연(Nature)적으로 발생하는 Treatment와 Outcome 사이의 정보 흐름(Common Cause)입니다.</li>
<li>“치료를 받은 사람이 더 건강해서 결과가 좋은가?”의 문제입니다.</li>
</ul></li>
<li><strong>Selection Bias:</strong>
<ul>
<li>인간(Man-made)에 의해, 혹은 측정 장비에 의해 발생하는 데이터 수집 과정의 편향입니다.</li>
<li>“특정 조건을 만족하는 사람만 설문에 응답했는가?”의 문제입니다.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-04/images/confounding_vs_selection.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: Confounding vs Selection Bias. 왼쪽은 Z가 X와 Y에 영향을 주는 교란(Confounding) 구조이고, 오른쪽은 X와 Y가 S(선택 여부)에 영향을 주는 선택 편향(Selection Bias) 구조이다. S=1인 샘플만 관측됨으로써 X와 Y 사이에 허위 상관관계(Spurious Correlation)가 발생한다.</figcaption>
</figure>
</div>
<ul>
<li>이 포스트에서는 선택 편향이 있는 데이터(<img src="https://latex.codecogs.com/png.latex?S=1">)만 관측 가능한 상황에서, 어떻게 전체 모집단의 분포(<img src="https://latex.codecogs.com/png.latex?P(y%7Cx)">)나 인과 효과(<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">)를 복원(Recover)할 수 있는지 다룹니다.</li>
</ul>
<hr>
</section>
</section>
<section id="modeling-selection-bias-with-causal-graphs" class="level1">
<h1>2. Modeling Selection Bias with Causal Graphs</h1>
<ul>
<li><p>선택 편향을 수학적으로 다루기 위해 우리는 <strong>선택 노드(Selection Node) <img src="https://latex.codecogs.com/png.latex?S"></strong>를 인과 그래프에 도입합니다.</p></li>
<li><p><strong>Definition:</strong> <img src="https://latex.codecogs.com/png.latex?S">는 이진 변수로, <img src="https://latex.codecogs.com/png.latex?S=1">인 샘플만 데이터셋에 포함됩니다.</p></li>
<li><p><strong>Problem:</strong> 우리의 목표는 <img src="https://latex.codecogs.com/png.latex?S=1"> 조건부 분포 <img src="https://latex.codecogs.com/png.latex?P(v%7CS=1)">로부터, 모집단 분포 <img src="https://latex.codecogs.com/png.latex?P(v)"> 혹은 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 추정하는 것입니다.</p></li>
</ul>
<section id="the-origin-of-selection-bias-collider-bias" class="level3">
<h3 class="anchored" data-anchor-id="the-origin-of-selection-bias-collider-bias">The Origin of Selection Bias (Collider Bias)</h3>
<p>선택 편향은 그래프상에서 <strong>Collider</strong> 구조로 설명될 수 있습니다. 예를 들어, 두 개의 독립적인 변수 <img src="https://latex.codecogs.com/png.latex?X">(재능)와 <img src="https://latex.codecogs.com/png.latex?Y">(미모)가 있고, 이 두 가지를 모두 갖춘 사람만이 연예인이 되어 TV에 나온다(<img src="https://latex.codecogs.com/png.latex?S=1">)고 가정해 봅시다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AX%20%5Crightarrow%20S%20%5Cleftarrow%20Y%0A"></p>
<p>전체 모집단에서 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">는 독립(<img src="https://latex.codecogs.com/png.latex?X%20%5Cperp%20Y">)이지만, 우리가 관측하는 TV 속 세상(<img src="https://latex.codecogs.com/png.latex?S=1">)에서는 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이에 강한 음의 상관관계가 생깁니다(Berkson’s Paradox). 즉, 재능이 없으면 미모라도 뛰어나야 하기 때문입니다.</p>
<hr>
</section>
</section>
<section id="recoverability-without-external-information" class="level1">
<h1>3. Recoverability without External Information</h1>
<p>가장 먼저 던져야 할 질문은 <strong>“편향된 데이터만 가지고 편향을 제거할 수 있는가?”</strong>입니다 [cite: 2329-2345].</p>
<section id="theorem-recoverability-of-conditional-probability" class="level3">
<h3 class="anchored" data-anchor-id="theorem-recoverability-of-conditional-probability">Theorem: Recoverability of Conditional Probability</h3>
<p>우리가 구하고 싶은 분포가 <img src="https://latex.codecogs.com/png.latex?Q%20=%20P(y%7Cx)">이고, 가진 데이터가 <img src="https://latex.codecogs.com/png.latex?P(y%7Cx,%20S=1)">일 때, 복원 가능 조건은 다음과 같습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cx)%20%5Ctext%7B%20is%20recoverable%7D%20%5Ciff%20Y%20%5Cperp%20S%20%5Cmid%20X%0A"></p>
<p>즉, 그래프상에서 <img src="https://latex.codecogs.com/png.latex?X">가 주어졌을 때 <img src="https://latex.codecogs.com/png.latex?Y">와 <img src="https://latex.codecogs.com/png.latex?S">가 <strong>d-separation</strong> 되어야 합니다.</p>
<ul>
<li><strong>직관:</strong> <img src="https://latex.codecogs.com/png.latex?X">라는 조건(예: 나이)을 알면, 데이터에 선택되었는지 여부(<img src="https://latex.codecogs.com/png.latex?S">)가 결과(<img src="https://latex.codecogs.com/png.latex?Y">)에 대한 추가적인 정보를 주지 않아야 합니다. 이 경우 <img src="https://latex.codecogs.com/png.latex?P(y%7Cx)%20=%20P(y%7Cx,%20S=1)">이 성립하여, 편향된 데이터를 그대로 사용할 수 있습니다.</li>
</ul>
<hr>
</section>
</section>
<section id="recoverability-with-external-information" class="level1">
<h1>4. Recoverability with External Information</h1>
<p>만약 <img src="https://latex.codecogs.com/png.latex?Y%20%5Cperp%20S%20%5Cmid%20X"> 조건이 성립하지 않는다면 어떻게 해야 할까요? 이때는 편향되지 않은 <strong>외부 데이터(External Data)</strong>의 도움이 필요합니다 [cite: 2346-2373].</p>
<ul>
<li><strong>Biased Data:</strong> <img src="https://latex.codecogs.com/png.latex?P(y,%20x,%20c%20%7C%20S=1)"> (풍부하지만 편향됨)</li>
<li><strong>Unbiased External Data:</strong> <img src="https://latex.codecogs.com/png.latex?P(c,%20x)"> (일부 변수에 대한 모집단 통계, 예: 인구센서스)</li>
</ul>
<section id="theorem-sufficiency-for-recoverability" class="level3">
<h3 class="anchored" data-anchor-id="theorem-sufficiency-for-recoverability">Theorem: Sufficiency for Recoverability</h3>
<p>다음 조건을 만족하는 변수 집합 <img src="https://latex.codecogs.com/png.latex?C">가 존재하면 <img src="https://latex.codecogs.com/png.latex?P(y%7Cx)">를 복원할 수 있습니다.</p>
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?Y%20%5Cperp%20S%20%5Cmid%20%5C%7BC,%20X%5C%7D"> in Graph <img src="https://latex.codecogs.com/png.latex?G"></li>
<li><img src="https://latex.codecogs.com/png.latex?P(C,%20X)"> is estimable (외부 데이터 존재)</li>
</ol>
<p>이때 복원 공식은 다음과 같습니다[cite: 2361]:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cx)%20=%20%5Csum_%7Bc%7D%20P(y%7Cx,%20c,%20S=1)%20P(c%7Cx)%0A"></p>
<ul>
<li><strong>해석:</strong> <img src="https://latex.codecogs.com/png.latex?C">라는 변수(예: 지역, 소득)를 통해 선택 편향의 고리를 끊을 수 있다면, 편향된 데이터에서 <img src="https://latex.codecogs.com/png.latex?C">별 <img src="https://latex.codecogs.com/png.latex?Y">의 분포를 구하고(<img src="https://latex.codecogs.com/png.latex?P(y%7Cx,c,S=1)">), 이를 외부 데이터의 <img src="https://latex.codecogs.com/png.latex?C"> 분포(<img src="https://latex.codecogs.com/png.latex?P(c%7Cx)">)로 가중 평균(Re-weighting)하여 모집단 분포를 재구성합니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-04/images/recoverability_external_c.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: 외부 정보를 이용한 복원 가능성 판단 예시. C={W1, W2}를 조건부로 했을 때 S와 Y가 독립이 된다면(d-separation), 외부의 P(W1, W2) 데이터를 이용하여 편향을 제거할 수 있다. 반면 C가 S와 Y 사이의 경로를 차단하지 못하면 복원 불가능하다.</figcaption>
</figure>
</div>
<hr>
</section>
</section>
<section id="generalized-adjustment-criterion" class="level1">
<h1>5. Generalized Adjustment Criterion</h1>
<p>이제 가장 일반적이고 강력한 시나리오를 다룹니다. 현실의 데이터는 <strong>교란(Confounding)과 선택 편향(Selection Bias)이 동시에 존재</strong>합니다. 우리는 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 구하기 위해 이 두 마리 토끼를 동시에 잡아야 합니다 [cite: 2428-2462].</p>
<section id="definition-generalized-adjustment-set" class="level3">
<h3 class="anchored" data-anchor-id="definition-generalized-adjustment-set">Definition: Generalized Adjustment Set</h3>
<p>변수 집합 <img src="https://latex.codecogs.com/png.latex?(Z,%20Z%5ET)">가 다음 세 가지 조건을 만족하면, 이를 통해 인과 효과를 식별할 수 있습니다 [cite: 2456-2461]. 여기서 <img src="https://latex.codecogs.com/png.latex?Z%5ET%20%5Csubseteq%20Z">는 편향 없이 측정 가능한 외부 데이터가 있는 부분집합입니다.</p>
<ol type="1">
<li><strong>Causal Path protection:</strong> <img src="https://latex.codecogs.com/png.latex?Z">는 <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Y">로 가는 어떠한 적절한 인과 경로(Proper Causal Path)도 차단해서는 안 됩니다. (과도한 통제 방지)</li>
<li><strong>Back-door Blocking:</strong> <img src="https://latex.codecogs.com/png.latex?Z%20%5Ccup%20%5C%7BS%5C%7D">는 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 모든 <strong>비인과적 경로(Non-causal paths)</strong>를 차단해야 합니다. (교란 제거)</li>
<li><strong>Selection Blocking:</strong> <img src="https://latex.codecogs.com/png.latex?Z%5ET">는 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 인과 경로가 끊어진 그래프에서, <img src="https://latex.codecogs.com/png.latex?Y">와 <img src="https://latex.codecogs.com/png.latex?S">를 d-separation 시켜야 합니다. (선택 편향 제거)</li>
</ol>
</section>
<section id="the-generalized-adjustment-formula" class="level3">
<h3 class="anchored" data-anchor-id="the-generalized-adjustment-formula">The Generalized Adjustment Formula</h3>
<p>위 조건이 만족될 때, 인과 효과는 다음과 같이 계산됩니다[cite: 2472]:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(y%7Cx,%20z,%20S=1)%20P(z%20%5Csetminus%20z%5ET%20%7C%20z%5ET,%20S=1)%20P(z%5ET)%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?P(y%7Cx,%20z,%20S=1)">: 편향된 데이터에서 추정한 모형.</li>
<li><img src="https://latex.codecogs.com/png.latex?P(z%20%5Csetminus%20z%5ET%20%7C%20z%5ET,%20S=1)">: 편향된 데이터에서 <img src="https://latex.codecogs.com/png.latex?Z"> 내부 변수 간의 관계.</li>
<li><img src="https://latex.codecogs.com/png.latex?P(z%5ET)">: 외부에서 가져온 편향 없는 모집단 데이터.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-04/images/generalized_adjustment_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3: Generalized Adjustment 예시. 교란 요인과 선택 편향 메커니즘이 복잡하게 얽힌 그래프에서, 적절한 Z 집합(일부는 biased, 일부는 external)을 찾아내어 인과 효과를 계산하는 과정을 보여준다.</figcaption>
</figure>
</div>
<p>이 공식은 기존의 Back-door Adjustment Formula (<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))%20=%20%5Csum_z%20P(y%7Cx,z)P(z)">)를 선택 편향이 있는 상황으로 확장한 것입니다. <img src="https://latex.codecogs.com/png.latex?S=1"> 조건이 붙은 항들과 외부 데이터 <img src="https://latex.codecogs.com/png.latex?P(z%5ET)">가 결합되는 형태를 주목하세요.</p>
<hr>
</section>
</section>
<section id="summary-the-power-of-causal-data-science" class="level1">
<h1>6. Summary: The Power of Causal Data Science</h1>
<p>이번 포스트를 통해 우리는 데이터 과학의 난제인 <strong>선택 편향</strong>을 인과 그래프를 통해 체계적으로 해결하는 방법을 배웠습니다.</p>
<ol type="1">
<li><strong>Problem Identification:</strong> 선택 편향은 데이터 수집 과정의 인과 구조(<img src="https://latex.codecogs.com/png.latex?S"> 노드)로 모델링됩니다.</li>
<li><strong>Pure Recoverability:</strong> 외부 데이터 없이도 <img src="https://latex.codecogs.com/png.latex?Y%20%5Cperp%20S%20%7C%20X"> 조건이 만족되면 복원 가능합니다.</li>
<li><strong>External Data Fusion:</strong> 외부 데이터(<img src="https://latex.codecogs.com/png.latex?P(c)">)가 있다면, 이를 연결고리(Re-weighting bridge)로 사용하여 복원할 수 있습니다.</li>
<li><strong>Generalized Adjustment:</strong> 교란과 선택 편향이 섞여 있어도, <strong>Generalized Adjustment Criterion</strong>을 통해 올바른 통제 변수 집합(<img src="https://latex.codecogs.com/png.latex?Z">)과 외부 데이터(<img src="https://latex.codecogs.com/png.latex?Z%5ET">)를 찾아내어 인과 효과를 편향 없이 추정할 수 있습니다.</li>
</ol>
<p>Bareinboim과 Tian 등의 연구에 따르면, 이 알고리즘들은 <strong>완전(Complete)</strong>합니다[cite: 2477]. 즉, 이 방법으로 복원할 수 없다면, 주어진 가정하에서는 그 어떤 방법으로도 편향을 제거하는 것이 불가능하다는 뜻입니다.</p>
<hr>
<section id="appendix-verification-checklist" class="level3">
<h3 class="anchored" data-anchor-id="appendix-verification-checklist"><strong>Appendix: Verification Checklist</strong></h3>
<ul>
<li><strong>포함된 내용:</strong>
<ul class="task-list">
<li><label><input type="checkbox" checked="">선택 편향의 정의 (Preferential inclusion) 및 Confounding과의 차이점 비교</label></li>
<li><label><input type="checkbox" checked="">선택 노드(S)를 포함한 인과 그래프 모델링</label></li>
<li><label><input type="checkbox" checked="">외부 정보 없는 복원 가능성 조건 (<img src="https://latex.codecogs.com/png.latex?Y%20%5Cperp%20S%20%7C%20X">) 및 정리(Theorem)</label></li>
<li><label><input type="checkbox" checked="">외부 정보(<img src="https://latex.codecogs.com/png.latex?P(c,x)">)를 이용한 복원 가능성(Sufficiency) 및 복원 공식 유도</label></li>
<li><label><input type="checkbox" checked="">Confounding과 Selection Bias가 동시에 존재하는 상황 (Generalized Adjustment)</label></li>
<li><label><input type="checkbox" checked="">Generalized Adjustment Criterion의 3가지 조건 상세 서술</label></li>
<li><label><input type="checkbox" checked="">Generalized Adjustment Formula (<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">)의 LaTeX 수식 정확한 재현</label></li>
<li><label><input type="checkbox" checked="">주요 도표(Origin of Bias, Recoverability examples)에 대한 Placeholder 및 캡션</label></li>
</ul></li>
<li><strong>생략된 내용:</strong>
<ul>
<li>강의 자료 마지막 부분의 Odds Ratio 관련 내용은 Selection Bias의 통계적 변형(Statistical Variant)으로 소개되었으나, 인과 추론(Causal Inference)의 핵심 흐름인 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))"> 복원에 집중하기 위해 본문에서는 간략히 언급하거나 생략하고 Recoverability Theorem에 집중함.</li>
</ul></li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L17/part-04/</guid>
  <pubDate>Sat, 24 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 17. Causal Data Science (Part 5)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L17/part-05/</link>
  <description><![CDATA[ 





<section id="introduction-missingness-is-a-causal-concept" class="level2">
<h2 class="anchored" data-anchor-id="introduction-missingness-is-a-causal-concept">1. Introduction: Missingness is a Causal Concept</h2>
<p>데이터 분석, 특히 사회과학이나 의료 데이터를 다룰 때 결측치(Missing Data)는 피할 수 없는 현실입니다. [cite_start]설문조사에서 응답자가 특정 문항을 건너뛰거나, 센서가 오작동하거나, 환자가 과거 기록을 기억하지 못하는 등 다양한 이유로 발생합니다[cite: 13, 14, 15].</p>
<p>통계학 문헌, 특히 Rubin의 선구적인 연구 이후 대부분의 결측치 처리 방식은 <strong>MAR(Missing At Random)</strong> 가정을 기반으로 합니다. [cite_start]이는 Maximum Likelihood나 Multiple Imputation의 수렴성을 보장하기 위한 필수적인 가정이지만, 실제 데이터에서 이 가정이 성립하는지 검증하는 것은 매우 어렵습니다[cite: 19, 20, 21, 23].</p>
<p>Mohan과 Pearl(2021)은 결측치 문제를 <strong>통계적 문제(Statistical Problem)가 아닌 인과적 문제(Causal Problem)</strong>로 재정의합니다. 데이터가 왜 비었는지에 대한 “이유(Reason)”는 데이터 생성 과정(Data Generating Process)의 일부이기 때문입니다. [cite_start]본 포스트에서는 그래프 모형(Graphical Models), 특히 <strong>m-graphs</strong>를 통해 결측 메커니즘을 시각화하고, 데이터의 복원 가능성(Recoverability)을 판단하는 방법을 정리합니다[cite: 31, 32].</p>
<hr>
</section>
<section id="formalism-the-m-graph" class="level2">
<h2 class="anchored" data-anchor-id="formalism-the-m-graph">2. Formalism: The m-graph</h2>
<p>결측 데이터 문제를 그래프로 표현하기 위해, 우리는 변수를 관측 여부와 역할에 따라 분류하고 <strong>Proxy Variable</strong>이라는 개념을 도입합니다.</p>
<section id="variables-classification" class="level3">
<h3 class="anchored" data-anchor-id="variables-classification">2.1. Variables Classification</h3>
<p>[cite_start]Causal DAG <img src="https://latex.codecogs.com/png.latex?G">의 노드들은 다음 다섯 가지 카테고리로 분류됩니다[cite: 115, 116]:</p>
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?U">: <strong>Latent Variables</strong> (관측되지 않는 잠재 변수)</li>
<li><img src="https://latex.codecogs.com/png.latex?V_o">: <strong>Fully Observed Variables</strong> (모든 레코드에서 관측된 변수)</li>
<li><img src="https://latex.codecogs.com/png.latex?V_m">: <strong>Missing Variables</strong> (적어도 하나의 레코드에서 결측이 발생한 변수)</li>
<li><img src="https://latex.codecogs.com/png.latex?R">: <strong>Missingness Mechanisms</strong> (결측을 유발하는 인과적 메커니즘을 나타내는 변수)</li>
<li><img src="https://latex.codecogs.com/png.latex?V%5E*">: <strong>Proxy Variables</strong> (실제로 관측된 변수)</li>
</ol>
</section>
<section id="the-proxy-variable-mechanism" class="level3">
<h3 class="anchored" data-anchor-id="the-proxy-variable-mechanism">2.2. The Proxy Variable Mechanism</h3>
<p>[cite_start]변수 <img src="https://latex.codecogs.com/png.latex?X">가 결측될 수 있다면, 우리는 실제 값 <img src="https://latex.codecogs.com/png.latex?X">와 결측 여부를 결정하는 스위치 <img src="https://latex.codecogs.com/png.latex?R_X">를 통해 관측된 값 <img src="https://latex.codecogs.com/png.latex?X%5E*">를 다음과 같이 정의합니다[cite: 49, 50].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AX%5E*%20=%20f(R_X,%20X)%20=%20%5Cbegin%7Bcases%7D%0AX%20&amp;%20%5Ctext%7Bif%20%7D%20R_X%20=%200%20%5Cquad%20(%5Ctext%7BObserved%7D)%20%5C%5C%0Am%20&amp;%20%5Ctext%7Bif%20%7D%20R_X%20=%201%20%5Cquad%20(%5Ctext%7BMissing%7D)%0A%5Cend%7Bcases%7D%0A"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?m">은 결측(missing value)을 나타내는 기호입니다. [cite_start]<img src="https://latex.codecogs.com/png.latex?R_X=1">이면 변수의 값은 가려지고(masked), <img src="https://latex.codecogs.com/png.latex?R_X=0">이면 드러납니다(revealed)[cite: 54, 55].</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-05/images/basic_proxy_structure.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: 비만도(Obesity) 예시를 통한 m-graph의 기본 구조. G(성별), A(나이)는 완전히 관측되지만, O(비만도)는 결측 메커니즘 <img src="https://latex.codecogs.com/png.latex?R_O">에 의해 <img src="https://latex.codecogs.com/png.latex?O%5E*">로 관측된다.</figcaption>
</figure>
</div>
<blockquote class="blockquote">
<p><strong>Figure 1 설명</strong>: 위 그림은 학교 데이터 예시를 보여줍니다. <img src="https://latex.codecogs.com/png.latex?G">(Gender)와 <img src="https://latex.codecogs.com/png.latex?A">(Age)는 학교 기록부에 있어 완전히 관측되지만(<img src="https://latex.codecogs.com/png.latex?V_o">), <img src="https://latex.codecogs.com/png.latex?O">(Obesity)는 학생이 응답을 거부할 수 있어 결측이 발생합니다(<img src="https://latex.codecogs.com/png.latex?V_m">). [cite_start]<img src="https://latex.codecogs.com/png.latex?R_O">는 <img src="https://latex.codecogs.com/png.latex?O">가 결측될지 여부를 결정하는 변수이며, 실제로 우리가 데이터셋에서 보는 것은 <img src="https://latex.codecogs.com/png.latex?O%5E*">(<img src="https://latex.codecogs.com/png.latex?V%5E*">)입니다[cite: 39, 44, 45, 49].</p>
</blockquote>
<hr>
</section>
</section>
<section id="categories-of-missingness-in-graphs" class="level2">
<h2 class="anchored" data-anchor-id="categories-of-missingness-in-graphs">3. Categories of Missingness in Graphs</h2>
<p>Rubin의 분류법인 MCAR, MAR, MNAR을 m-graph 상에서의 조건부 독립성(Conditional Independence)으로 명확히 정의할 수 있습니다. [cite_start]그래프 구조를 통해 데이터가 어떤 결측 유형에 속하는지 시각적으로 판별(Inspection)이 가능해집니다[cite: 34].</p>
<section id="mcar-missing-completely-at-random" class="level3">
<h3 class="anchored" data-anchor-id="mcar-missing-completely-at-random">3.1. MCAR (Missing Completely At Random)</h3>
<p>결측이 완전히 무작위로 발생하는 경우입니다. [cite_start]설문지를 잃어버리는 등의 상황이 이에 해당합니다[cite: 69].</p>
<ul>
<li><strong>정의</strong>: 결측 메커니즘 <img src="https://latex.codecogs.com/png.latex?R">이 데이터의 모든 변수(<img src="https://latex.codecogs.com/png.latex?V_m,%20V_o,%20U">)와 독립입니다.</li>
<li>[cite_start]<strong>그래프 조건</strong>: <img src="https://latex.codecogs.com/png.latex?R"> 변수들과 <img src="https://latex.codecogs.com/png.latex?V_o%20%5Ccup%20V_m"> 사이에 엣지가 없습니다[cite: 138, 143].</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AV_m,%20V_o,%20U%20%5Cperp%20%5Cmathbb%7BR%7D%0A"></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-05/images/mcar_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: MCAR의 그래프 구조. <img src="https://latex.codecogs.com/png.latex?R_O">로 들어오는 화살표가 없다. 즉, 나이(A)나 성별(G), 실제 비만도(O)가 결측 여부(<img src="https://latex.codecogs.com/png.latex?R_O">)에 영향을 주지 않는다.</figcaption>
</figure>
</div>
</section>
<section id="mar-missing-at-random" class="level3">
<h3 class="anchored" data-anchor-id="mar-missing-at-random">3.2. MAR (Missing At Random)</h3>
<p>결측이 <strong>완전히 관측된 변수(<img src="https://latex.codecogs.com/png.latex?V_o">)</strong>에만 의존하여 발생하는 경우입니다. [cite_start]예를 들어, 10대(<img src="https://latex.codecogs.com/png.latex?A">)들이 반항심에 몸무게를 보고하지 않는 경우 등입니다[cite: 77].</p>
<ul>
<li>[cite_start]<strong>정의</strong>: 관측된 변수 <img src="https://latex.codecogs.com/png.latex?V_o">가 주어졌을 때, 결측 메커니즘 <img src="https://latex.codecogs.com/png.latex?R">은 나머지 변수들과 독립입니다[cite: 146].</li>
<li>[cite_start]<strong>그래프 조건</strong>: (i) <img src="https://latex.codecogs.com/png.latex?R">과 부분적으로 관측된 변수(<img src="https://latex.codecogs.com/png.latex?V_m">) 사이에 엣지가 없고, (ii) <img src="https://latex.codecogs.com/png.latex?R">과 <img src="https://latex.codecogs.com/png.latex?V_o"> 사이에 양방향 엣지(bidirected edge, Latent confounder)가 없어야 합니다[cite: 147].</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AV_m,%20U%20%5Cperp%20%5Cmathbb%7BR%7D%20%5Cmid%20V_o%0A"></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-05/images/mar_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3: MAR의 그래프 구조. 나이(A)가 결측 메커니즘(<img src="https://latex.codecogs.com/png.latex?R_O">)에 영향을 준다(<img src="https://latex.codecogs.com/png.latex?A%20%5Crightarrow%20R_O">). 즉, 결측 여부는 관측된 나이에 따라 달라진다.</figcaption>
</figure>
</div>
</section>
<section id="mnar-missing-not-at-random" class="level3">
<h3 class="anchored" data-anchor-id="mnar-missing-not-at-random">3.3. MNAR (Missing Not At Random)</h3>
<p>데이터가 MCAR나 MAR이 아닌 모든 경우입니다. 특히, 결측된 변수 그 자체가 결측 원인이 되는 경우가 포함됩니다. [cite_start]예를 들어, 비만인 학생(<img src="https://latex.codecogs.com/png.latex?O">)이 부끄러워서 몸무게를 숨기는 경우입니다[cite: 87, 112].</p>
<ul>
<li><strong>특징</strong>: <img src="https://latex.codecogs.com/png.latex?R"> 변수로 들어오는 화살표가 결측 변수(<img src="https://latex.codecogs.com/png.latex?V_m">)나 잠재 변수(<img src="https://latex.codecogs.com/png.latex?U">)에서 시작됩니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-05/images/mnar_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 4: MNAR의 그래프 구조. 실제 비만도(O)가 결측 여부(<img src="https://latex.codecogs.com/png.latex?R_O">)에 직접 영향을 준다(<img src="https://latex.codecogs.com/png.latex?O%20%5Crightarrow%20R_O">). 비만일수록 응답하지 않을 확률이 높아지는 메커니즘이다.</figcaption>
</figure>
</div>
<hr>
</section>
</section>
<section id="recoverability-can-we-restore-the-truth" class="level2">
<h2 class="anchored" data-anchor-id="recoverability-can-we-restore-the-truth">4. Recoverability: Can We Restore the Truth?</h2>
<p>[cite_start]<strong>Recoverability(복원 가능성)</strong>란, 결측이 포함된 관측 데이터(<img src="https://latex.codecogs.com/png.latex?V%5E*,%20V_o,%20R">)의 분포로부터 우리가 알고 싶은 원래 분포(Target Distribution, <img src="https://latex.codecogs.com/png.latex?P(V_o,%20V_m)">)를 일관되게(consistently) 추정할 수 있는지에 대한 문제입니다[cite: 35].</p>
<section id="recoverability-of-mcar" class="level3">
<h3 class="anchored" data-anchor-id="recoverability-of-mcar">4.1. Recoverability of MCAR</h3>
<p>MCAR의 경우, <img src="https://latex.codecogs.com/png.latex?R_O">는 모든 변수와 독립이므로, 데이터를 삭제(List-wise deletion)하고 남은 데이터만 써도 편향(Bias)이 없습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(G,%20O,%20A)%20=%20P(G,%20O,%20A%20%5Cmid%20R_O%20=%200)%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?R_O%20=%200">인 조건 하에서는 <img src="https://latex.codecogs.com/png.latex?O%20=%20O%5E*">이므로,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A=%20P(G,%20O%5E*,%20A%20%5Cmid%20R_O%20=%200)%0A"></p>
<p>[cite_start]즉, 관측된 데이터만으로 원래 분포를 완벽히 복원할 수 있습니다[cite: 187, 189].</p>
</section>
<section id="recoverability-of-mar" class="level3">
<h3 class="anchored" data-anchor-id="recoverability-of-mar">4.2. Recoverability of MAR</h3>
<p>MAR의 경우, 단순 삭제는 편향을 낳지만, 조건부 확률을 이용해 복원할 수 있습니다. 예를 들어 <img src="https://latex.codecogs.com/png.latex?A%20%5Crightarrow%20R_O">인 상황(Figure 3)을 봅시다.</p>
<p>[cite_start]우리는 결합 확률 <img src="https://latex.codecogs.com/png.latex?P(G,%20O,%20A)">를 다음과 같이 분해(Factorization)할 수 있습니다[cite: 198]: <img src="https://latex.codecogs.com/png.latex?%0AP(G,%20O,%20A)%20=%20P(G,%20O%20%5Cmid%20A)P(A)%0A"></p>
<p>그래프에서 <img src="https://latex.codecogs.com/png.latex?A">는 <img src="https://latex.codecogs.com/png.latex?R_O">와 <img src="https://latex.codecogs.com/png.latex?%5C%7BG,%20O%5C%7D"> 사이를 <strong>d-separation</strong> 합니다. [cite_start]따라서 <img src="https://latex.codecogs.com/png.latex?R_O">에 조건을 걸어도 확률은 변하지 않습니다[cite: 199]. <img src="https://latex.codecogs.com/png.latex?%0AP(G,%20O%20%5Cmid%20A)%20=%20P(G,%20O%20%5Cmid%20A,%20R_O%20=%200)%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?R_O=0">일 때 <img src="https://latex.codecogs.com/png.latex?O=O%5E*">이므로, 최종적으로 관측 가능한 변수들로 표현됩니다: <img src="https://latex.codecogs.com/png.latex?%0AP(G,%20O,%20A)%20=%20P(G,%20O%5E*%20%5Cmid%20A,%20R_O%20=%200)P(A)%0A"></p>
<p>[cite_start]이것이 MAR 상황에서 데이터를 복원하는 핵심 논리입니다[cite: 202].</p>
</section>
<section id="the-challenge-of-mnar" class="level3">
<h3 class="anchored" data-anchor-id="the-challenge-of-mnar">4.3. The Challenge of MNAR</h3>
<p>MNAR, 예를 들어 <img src="https://latex.codecogs.com/png.latex?O%20%5Crightarrow%20R_O">인 경우(Figure 4), 위와 같은 분해나 d-separation을 사용할 수 없습니다. [cite_start]<img src="https://latex.codecogs.com/png.latex?O">를 관측하지 못했는데 <img src="https://latex.codecogs.com/png.latex?O">가 결측 원인이 되므로, 일반적으로 복원이 불가능(Non-recoverable)합니다[cite: 218, 224].</p>
<p>하지만 <strong>모든 MNAR이 복원 불가능한 것은 아닙니다.</strong> m-graph 구조에 따라 MNAR임에도 복원 가능한 특수한 케이스들이 존재합니다.</p>
<hr>
</section>
</section>
<section id="advanced-recoverability-theorems" class="level2">
<h2 class="anchored" data-anchor-id="advanced-recoverability-theorems">5. Advanced Recoverability Theorems</h2>
<p>MNAR 상황에서도 복원 가능한 조건을 다루는 두 가지 중요한 정리가 있습니다.</p>
<section id="sequential-factorization-순차적-분해" class="level3">
<h3 class="anchored" data-anchor-id="sequential-factorization-순차적-분해">5.1. Sequential Factorization (순차적 분해)</h3>
<p>[cite_start]타겟 분포 <img src="https://latex.codecogs.com/png.latex?Q">를 인수분해했을 때, 각 인수가 <img src="https://latex.codecogs.com/png.latex?P(Y_i%20%7C%20X_i)"> 꼴을 띠고, 각각의 <img src="https://latex.codecogs.com/png.latex?Y_i">가 <img src="https://latex.codecogs.com/png.latex?X_i">가 주어졌을 때 자신의 결측 메커니즘 <img src="https://latex.codecogs.com/png.latex?R_%7BY_i%7D">과 독립이라면 복원 가능합니다[cite: 247].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(Y_i%20%5Cmid%20X_i)%20=%20P(Y_i%5E*%20%5Cmid%20X_i%5E*,%20R_%7BY_i%7D=0,%20R_%7BX_i%7D=0)%0A"></p>
</section>
<section id="r-factorization-theorem" class="level3">
<h3 class="anchored" data-anchor-id="r-factorization-theorem">5.2. R-Factorization Theorem</h3>
<p>전체 결합 분포 <img src="https://latex.codecogs.com/png.latex?P(V)">의 복원 가능성에 대한 필요충분조건입니다. [cite_start]<img src="https://latex.codecogs.com/png.latex?R"> 변수들 간에 엣지가 없다고 가정할 때, 다음 두 조건에 해당하는 변수 <img src="https://latex.codecogs.com/png.latex?X%20%5Cin%20V_m">이 <strong>없다면</strong> 복원 가능합니다[cite: 254, 255, 256].</p>
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?R_X">가 이웃(neighbor)함.</li>
<li><img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?R_X">가 <img src="https://latex.codecogs.com/png.latex?V_m%20%5Ccup%20V_o"> 내의 collider들로만 이루어진 경로로 연결됨.</li>
</ol>
<p>[cite_start]복원 가능하다면, 분포는 다음과 같이 주어집니다[cite: 258]:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(V)%20=%20%5Cfrac%7BP(R=0,%20V%5E*)%7D%7B%5Cprod_i%20P(R_i=0%20%5Cmid%20Mb_%7BR_i%7D%5Eo,%20Mb_%7BR_i%7D%5Em,%20R_%7BMb_%7BR_i%7D%5Em%7D=0)%7D%0A"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?Mb_%7BR_i%7D">는 <img src="https://latex.codecogs.com/png.latex?R_i">의 Markov Blanket을 의미합니다.</p>
<hr>
</section>
</section>
<section id="case-study-recovering-causal-effect-pydoz" class="level2">
<h2 class="anchored" data-anchor-id="case-study-recovering-causal-effect-pydoz">6. Case Study: Recovering Causal Effect (<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(z))">)</h2>
<p>[cite_start]마지막으로, 결측 데이터가 있는 상황에서 인과 효과(Causal Effect)를 추정하는 예제를 살펴보겠습니다[cite: 261].</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-05/images/causal_effect_recovery_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 5: Causal Effect 복원 예시 그래프. <img src="https://latex.codecogs.com/png.latex?W%20%5Crightarrow%20Z%20%5Crightarrow%20Y">의 인과 경로가 있고, <img src="https://latex.codecogs.com/png.latex?W">가 <img src="https://latex.codecogs.com/png.latex?Y">의 결측(<img src="https://latex.codecogs.com/png.latex?R_Y">)에 영향을 주며, <img src="https://latex.codecogs.com/png.latex?W">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이에 잠재적 교란 요인(dashed bidirectional edge)이 존재하는 복잡한 MNAR 상황이다.</figcaption>
</figure>
</div>
<blockquote class="blockquote">
<p><strong>Figure 5 설명</strong>: 이 그래프에서 우리는 <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(z))">를 알고 싶습니다. 하지만 <img src="https://latex.codecogs.com/png.latex?Y">에는 결측이 있고, 결측 메커니즘 <img src="https://latex.codecogs.com/png.latex?R_Y">는 <img src="https://latex.codecogs.com/png.latex?W">에 의존합니다(<img src="https://latex.codecogs.com/png.latex?W%20%5Crightarrow%20R_Y">). 또한 <img src="https://latex.codecogs.com/png.latex?W">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이에는 Confounder가 있습니다.</p>
</blockquote>
<p><strong>유도 과정:</strong></p>
<ol type="1">
<li><p><strong>Backdoor Adjustment</strong>: <img src="https://latex.codecogs.com/png.latex?W">가 <img src="https://latex.codecogs.com/png.latex?Z%20%5Crightarrow%20Y"> 관계의 confounder 역할을 하므로, <img src="https://latex.codecogs.com/png.latex?W">에 대해 조정(adjustment)을 수행합니다. <img src="https://latex.codecogs.com/png.latex?P(y%20%5Cmid%20do(z))%20=%20%5Csum_w%20P(y%20%5Cmid%20w,%20z)%20P(w)"> [cite_start]<em>(주의: 슬라이드 수식 [cite: 269]에서는 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(z))">를 바로 전개하지만, 여기서는 이해를 돕기 위해 Backdoor 기준을 적용한 형태를 풀어서 설명합니다. 슬라이드의 전개는 do-calculus와 결측 매커니즘 분해를 결합한 것입니다.)</em></p>
<p>슬라이드의 유도 과정을 따라가면: <img src="https://latex.codecogs.com/png.latex?P(y%20%5Cmid%20do(z))%20=%20P(y%20%5Cmid%20do(z),%20r_y)%20%5Cquad%20%5Ctext%7B($R_y$%EB%8A%94%20%EA%B0%9C%EC%9E%85%20%EC%9D%B4%ED%9B%84%20%EB%B3%80%EC%88%98%EA%B0%80%20%EC%95%84%EB%8B%98)%7D"></p>
<p><img src="https://latex.codecogs.com/png.latex?R_y">가 조건부에 포함되면, 우리는 <img src="https://latex.codecogs.com/png.latex?Y"> 대신 <img src="https://latex.codecogs.com/png.latex?Y%5E*">를 사용할 수 있습니다 (<img src="https://latex.codecogs.com/png.latex?Y%20=%20Y%5E*"> when <img src="https://latex.codecogs.com/png.latex?R_Y=0"> or implicit context). <img src="https://latex.codecogs.com/png.latex?=%20P(y%5E*%20%5Cmid%20do(z),%20r_y)"></p>
<p>이 확률을 <img src="https://latex.codecogs.com/png.latex?W">를 통해 분해합니다: <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_w%20P(y%5E*%20%5Cmid%20w,%20do(z),%20r_y)%20P(w%20%5Cmid%20do(z),%20r_y)"></p>
<p>그래프 상의 독립성을 활용합니다. <img src="https://latex.codecogs.com/png.latex?Z">에 개입(<img src="https://latex.codecogs.com/png.latex?do(z)">)하면 <img src="https://latex.codecogs.com/png.latex?W">에서 오는 화살표는 무시되거나, <img src="https://latex.codecogs.com/png.latex?W">가 <img src="https://latex.codecogs.com/png.latex?Z">의 부모이므로 <img src="https://latex.codecogs.com/png.latex?do(z)">와 독립일 수 있습니다. 중요한 점은 <img src="https://latex.codecogs.com/png.latex?Y%5E*">가 관측 가능해진다는 것입니다.</p>
<p>[cite_start]최종적으로 슬라이드는 다음과 같은 형태의 복원식을 제시합니다[cite: 269]: <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_w%20P(y%5E*%20%5Cmid%20w,%20z,%20r_y)%20P(w%20%5Cmid%20r_y)"></p>
<p>이 식의 의미는, <strong>결측이 있는 상태(<img src="https://latex.codecogs.com/png.latex?Y%5E*">)에서도, 결측 메커니즘(<img src="https://latex.codecogs.com/png.latex?R_Y">)과 관련된 변수(<img src="https://latex.codecogs.com/png.latex?W">)들을 적절히 통제하면 원래의 인과 효과를 계산해낼 수 있다</strong>는 것입니다.</p></li>
</ol>
<hr>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">7. Conclusion</h2>
<p>이번 포스트에서는 결측 데이터 문제를 인과적 관점에서 바라보는 <strong>m-graph</strong> 프레임워크를 다뤘습니다.</p>
<ol type="1">
<li>[cite_start]<strong>Transparency</strong>: 그래프 모델은 결측의 원인(Missingness Mechanism)을 명시적으로 표현하여, MAR/MCAR 가정을 시각적으로 검증(Testability)할 수 있게 해줍니다[cite: 32, 36].</li>
<li><strong>Recoverability</strong>: 단순히 데이터를 삭제하거나 평균을 채워 넣는 것이 아니라, 그래프 구조에 기반하여 이론적으로 타당한 복원 공식을 유도할 수 있습니다.</li>
<li>[cite_start]<strong>Beyond MAR</strong>: 기존 통계학에서 다루기 어려웠던 MNAR 상황에서도, 구조적 특성을 이용해(Sequential Factorization 등) 편향 없는 추정이 가능함을 확인했습니다[cite: 24, 253].</li>
</ol>
<p>[cite_start]통계학자와 데이터 과학자는 결측치를 단순한 “전처리 대상”이 아니라, <strong>데이터 생성 과정의 일부</strong>로 보고 모델링해야 합니다[cite: 272].</p>
<hr>
<section id="누락-방지-검증-체크리스트" class="level3">
<h3 class="anchored" data-anchor-id="누락-방지-검증-체크리스트">누락 방지 검증 체크리스트</h3>
<ul>
<li><strong>포함된 내용</strong>:
<ul class="task-list">
<li><label><input type="checkbox" checked="">결측 데이터의 동기 및 기존 방법론(Rubin)의 한계</label></li>
<li><label><input type="checkbox" checked="">m-graph의 정의 및 구성 요소 (<img src="https://latex.codecogs.com/png.latex?V%5E*,%20R"> 등)</label></li>
<li><label><input type="checkbox" checked="">MCAR, MAR, MNAR의 그래프적 정의 및 예시</label></li>
<li><label><input type="checkbox" checked="">MCAR, MAR, MNAR 상황별 복원 가능성(Recoverability) 유도 과정</label></li>
<li><label><input type="checkbox" checked="">고급 정리: Sequential Factorization, R-Factorization Theorem 수식</label></li>
<li><label><input type="checkbox" checked="">Causal Effect (<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(z))">) 복원 예제</label></li>
</ul></li>
<li><strong>생략된 내용</strong>:
<ul>
<li>슬라이드 24의 복잡한 MNAR 예제 (<img src="https://latex.codecogs.com/png.latex?Z_1,%20Z_2,%20X,%20Y">)에 대한 세부 유도 과정은 R-Factorization Theorem의 일반론으로 갈음하고, 대신 Causal Effect 예제를 상세히 다루었습니다. (흐름상 핵심 정리를 보여주는 것이 더 중요하다고 판단)</li>
<li>JASA 논문 원문의 증명(Proof) 등은 슬라이드 범위를 벗어나므로 제외했습니다.</li>
</ul></li>
</ul>
<hr>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L17/part-05/</guid>
  <pubDate>Sat, 24 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 17. Causal Data Science (Part 6)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L17/part-06/</link>
  <description><![CDATA[ 





<section id="introduction-데이터-융합data-fusion의-필요성" class="level2">
<h2 class="anchored" data-anchor-id="introduction-데이터-융합data-fusion의-필요성">1. Introduction: 데이터 융합(Data Fusion)의 필요성</h2>
<p>현대 데이터 과학, 특히 사회과학과 공학이 교차하는 지점에서는 <strong>“모든 변수가 완벽하게 측정된 단 하나의 데이터셋”</strong>을 확보하는 것이 거의 불가능합니다. 현실에서는 다음과 같은 상황이 빈번하게 발생합니다.</p>
<ul>
<li><strong>실험 연구(Experimental Study):</strong> 핵심적인 처치(Treatment)와 주요 결과 변수만 측정하며, 비용 문제로 많은 공변량을 측정하지 못함.</li>
<li><strong>관찰 연구(Observational Study):</strong> 방대한 공변량과 결과 변수가 존재하지만, 처치 변수가 없거나 무작위 배정(Randomization)이 되어 있지 않음.</li>
</ul>
<p>이러한 상황에서, 서로 다른 변수 집합(<img src="https://latex.codecogs.com/png.latex?V_i%20%5Csubseteq%20V">)을 포함하는 이질적인 데이터셋들을 결합하여, 전체 시스템의 인과 효과(Causal Effect)를 추정할 수 있을까요? 이번 포스트에서는 <strong>General Identifiability with Partial Observation (GID-PO)</strong> 개념을 통해 이 문제를 해결하는 과정을 다룹니다.</p>
</section>
<section id="problem-setup-gid-po" class="level2">
<h2 class="anchored" data-anchor-id="problem-setup-gid-po">2. Problem Setup: GID-PO</h2>
<p>우리가 관심을 가지는 전체 변수 집합을 <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BV%7D">라고 합시다. 하지만 우리는 <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BV%7D"> 전체를 관측한 데이터가 없습니다. 대신, <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BV%7D">의 부분집합인 <img src="https://latex.codecogs.com/png.latex?V_i">만을 관측한 여러 개의 데이터셋(실험 또는 관찰) 모음 <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BP%7D=%5C%7BP_%7BZ_%7Bi%7D%7D(V_%7Bi%7D)%5C%7D_%7Bi%7D">를 가지고 있습니다.</p>
<p>이때 우리의 목표는 타겟 인과 효과 <img src="https://latex.codecogs.com/png.latex?P_x(y)"> (처치 <img src="https://latex.codecogs.com/png.latex?X">가 결과 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 효과)를 식별(Identify)하는 것입니다.</p>
<section id="예시-시나리오-운동이-뇌졸중에-미치는-영향" class="level3">
<h3 class="anchored" data-anchor-id="예시-시나리오-운동이-뇌졸중에-미치는-영향">2.1 예시 시나리오: 운동이 뇌졸중에 미치는 영향</h3>
<p>강의 자료에서 제시된 구체적인 예시를 통해 문제를 정의해 봅시다. 우리는 <strong>운동(Exercise, <img src="https://latex.codecogs.com/png.latex?X">)</strong>이 <strong>뇌졸중(Stroke, <img src="https://latex.codecogs.com/png.latex?Y">)</strong>에 미치는 인과적 효과를 알고 싶습니다.</p>
<p>관련된 변수들은 다음과 같습니다: * <img src="https://latex.codecogs.com/png.latex?A">: 나이 (Age) * <img src="https://latex.codecogs.com/png.latex?X">: 운동 (Exercise) - <strong>처치 변수</strong> * <img src="https://latex.codecogs.com/png.latex?B">: BMI * <img src="https://latex.codecogs.com/png.latex?C">: 혈압 (Blood Pressure) * <img src="https://latex.codecogs.com/png.latex?Y">: 뇌졸중 (Stroke) - <strong>결과 변수</strong></p>
<p>이 변수들의 인과 관계는 아래의 Causal Graph(DAG)로 표현됩니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-06/images/causal_graph_stroke_exercise.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: Exercise &amp; Stroke Causal Graph. A(Age)는 X(Exercise)와 B(BMI)에 영향을 줌. X는 B에 영향을 줌. B는 C(Blood Pressure)에 영향을 줌. C는 Y(Stroke)에 영향을 줌. 점선(Dashed Line)은 X와 Y 사이에 관측되지 않은 교란 요인(Unobserved Confounder)이 존재함을 암시함.</figcaption>
</figure>
</div>
</section>
<section id="주어진-데이터의-한계" class="level3">
<h3 class="anchored" data-anchor-id="주어진-데이터의-한계">2.2 주어진 데이터의 한계</h3>
<p>우리는 <img src="https://latex.codecogs.com/png.latex?P(A,%20X,%20B,%20C,%20Y)"> 전체를 포함하는 데이터가 없습니다. 대신 두 가지의 불완전한 연구 결과만 가지고 있다고 가정해 봅시다.</p>
<ol type="1">
<li><strong>연구 1 (Experimental Study):</strong>
<ul>
<li>운동(<img src="https://latex.codecogs.com/png.latex?X">)에 대해 무작위 배정(Intervention)을 수행했습니다.</li>
<li>측정 변수: 나이(<img src="https://latex.codecogs.com/png.latex?A">), 혈압(<img src="https://latex.codecogs.com/png.latex?C">). (BMI와 뇌졸중은 측정하지 않음)</li>
<li>확보된 분포: <img src="https://latex.codecogs.com/png.latex?P_X(A,%20C)"></li>
</ul></li>
<li><strong>연구 2 (Observational Study):</strong>
<ul>
<li>단순 관찰 연구입니다.</li>
<li>측정 변수: BMI(<img src="https://latex.codecogs.com/png.latex?B">), 혈압(<img src="https://latex.codecogs.com/png.latex?C">), 뇌졸중(<img src="https://latex.codecogs.com/png.latex?Y">). (나이와 운동 여부는 데이터에 없음)</li>
<li>확보된 분포: <img src="https://latex.codecogs.com/png.latex?P(B,%20C,%20Y)"></li>
</ul></li>
</ol>
<p><strong>Task:</strong> 이 두 가지 부분적인 분포 <img src="https://latex.codecogs.com/png.latex?P_X(A,%20C)">와 <img src="https://latex.codecogs.com/png.latex?P(B,%20C,%20Y)">만을 사용하여, 타겟 인과 효과 <strong><img src="https://latex.codecogs.com/png.latex?P_X(Y)"></strong>를 계산할 수 있는가?</p>
</section>
</section>
<section id="mathematical-derivations" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-derivations">3. Mathematical Derivations</h2>
<p>이 문제는 단순히 데이터를 합치는(Merge) 것으로는 해결되지 않습니다. 공통 변수가 <img src="https://latex.codecogs.com/png.latex?C">밖에 없으며, 연구 1은 실험 데이터, 연구 2는 관찰 데이터라는 성격의 차이가 있기 때문입니다. 우리는 확률 분포의 분해(Factorization) 법칙과 인과 그래프의 구조를 이용해야 합니다.</p>
<section id="step-1-target-distribution의-정의" class="level3">
<h3 class="anchored" data-anchor-id="step-1-target-distribution의-정의">3.1 Step 1: Target Distribution의 정의</h3>
<p>우리가 구하고자 하는 것은 <img src="https://latex.codecogs.com/png.latex?X">에 개입했을 때 <img src="https://latex.codecogs.com/png.latex?Y">의 주변 확률 분포(Marginal Distribution)입니다. <img src="https://latex.codecogs.com/png.latex?P_x(y)%20=%20%5Csum_%7Ba,b,c%7D%20P_x(a,%20b,%20c,%20y)"></p>
</section>
<section id="step-2-c-component-factorization" class="level3">
<h3 class="anchored" data-anchor-id="step-2-c-component-factorization">3.2 Step 2: C-Component Factorization</h3>
<p>인과 그래프(Figure 1)의 구조에 따라 결합 확률 분포(Joint Distribution)를 분해해 봅시다. 특히 <img src="https://latex.codecogs.com/png.latex?do(X)"> 연산이 적용된 개입 분포(Interventional Distribution) <img src="https://latex.codecogs.com/png.latex?P_x(%5Ccdot)">를 고려합니다.</p>
<p>일반적인 베이지안 네트워크 분해 법칙과 <img src="https://latex.codecogs.com/png.latex?do">-calculus의 원리에 따라, <img src="https://latex.codecogs.com/png.latex?X">로 들어오는 화살표를 제거한 그래프에서의 분해를 생각할 수 있습니다. 강의 자료의 유도 과정(Slide 8-10)에 따르면, 이 시스템은 다음과 같은 형태로 분해(Factorization)될 수 있습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?P_x(a,%20b,%20c,%20y)%20=%20P(a)%20%5Ccdot%20P_%7Ba,x%7D(b)%20%5Ccdot%20P_b(c)%20%5Ccdot%20P_c(y)"></p>
<p>이 식의 각 항이 의미하는 바는 다음과 같습니다: * <img src="https://latex.codecogs.com/png.latex?P(a)">: 나이의 분포 (외생 변수). * <img src="https://latex.codecogs.com/png.latex?P_%7Ba,x%7D(b)">: <img src="https://latex.codecogs.com/png.latex?A">와 <img src="https://latex.codecogs.com/png.latex?X">가 주어졌을 때(또는 개입했을 때) <img src="https://latex.codecogs.com/png.latex?B">의 분포. * <img src="https://latex.codecogs.com/png.latex?P_b(c)">: <img src="https://latex.codecogs.com/png.latex?B">가 주어졌을 때 <img src="https://latex.codecogs.com/png.latex?C">의 분포. * <img src="https://latex.codecogs.com/png.latex?P_c(y)">: <img src="https://latex.codecogs.com/png.latex?C">가 주어졌을 때 <img src="https://latex.codecogs.com/png.latex?Y">의 분포.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Why this factorization?</strong> 이 분해는 그래프의 <strong>c-component</strong> 구조에 기반합니다. <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이에는 직접적인(또는 confounding에 의한) 경로가 존재하지만, <img src="https://latex.codecogs.com/png.latex?A%20%5Cto%20B%20%5Cto%20C%20%5Cto%20Y">와 같은 매개 경로들이 존재합니다. 이 식은 전체 효과를 각 메커니즘의 결합으로 쪼갠 것입니다.</p>
</div>
</div>
</section>
<section id="step-3-수식의-재구성-regrouping" class="level3">
<h3 class="anchored" data-anchor-id="step-3-수식의-재구성-regrouping">3.3 Step 3: 수식의 재구성 (Regrouping)</h3>
<p>이제 위에서 얻은 식을 우리가 가진 데이터 <img src="https://latex.codecogs.com/png.latex?P_X(A,%20C)">와 <img src="https://latex.codecogs.com/png.latex?P(B,%20C,%20Y)">와 연결하기 위해 <img src="https://latex.codecogs.com/png.latex?%5Csum">의 순서를 조정하여 재구성합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0AP_x(y)%20&amp;=%20%5Csum_%7Ba,b,c%7D%20P(a)%20P_%7Ba,x%7D(b)%20P_b(c)%20P_c(y)%20%5C%5C%0A&amp;=%20%5Csum_%7Ba,c%7D%20P(a)%20%5Cleft(%20%5Csum_%7Bb%7D%20P_%7Ba,x%7D(b)%20P_b(c)%20%5Cright)%20P_c(y)%0A%5Cend%7Baligned%7D%0A"></p>
<p>여기서 괄호 안의 부분 <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bb%7D%20P_%7Ba,x%7D(b)%20P_b(c)">를 살펴봅시다. 이는 <img src="https://latex.codecogs.com/png.latex?A">와 <img src="https://latex.codecogs.com/png.latex?X">가 결정되었을 때, <img src="https://latex.codecogs.com/png.latex?B">를 거쳐 <img src="https://latex.codecogs.com/png.latex?C">가 결정되는 과정의 확률, 즉 <img src="https://latex.codecogs.com/png.latex?P_%7Ba,x%7D(c)">로 해석할 수 있습니다 (Chain Rule of Intervention).</p>
<p>따라서 식은 다음과 같이 간소화됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?P_x(y)%20=%20%5Csum_%7Ba,c%7D%20P(a)%20P_%7Ba,x%7D(c)%20P_c(y)"></p>
<p>이 식은 매우 중요한 의미를 가집니다. <strong>서로 다른 출처의 정보를 결합할 수 있는 연결고리</strong>가 되기 때문입니다.</p>
</section>
</section>
<section id="mapping-to-data-sources-the-puzzle" class="level2">
<h2 class="anchored" data-anchor-id="mapping-to-data-sources-the-puzzle">4. Mapping to Data Sources (The Puzzle)</h2>
<p>이제 최종 유도된 식의 각 구성 요소가 우리가 가진 두 개의 데이터셋 중 어디에서 올 수 있는지 확인해 봅시다.</p>
<p><img src="https://latex.codecogs.com/png.latex?P_x(y)%20=%20%5Csum_%7Ba,c%7D%20%5Cunderbrace%7BP(a)%20P_%7Ba,x%7D(c)%7D_%7B%5Ctext%7BSource%201%7D%7D%20%5Ccdot%20%5Cunderbrace%7BP_c(y)%7D_%7B%5Ctext%7BSource%202%7D%7D"></p>
<section id="source-1-experimental-study-p_xa-c" class="level3">
<h3 class="anchored" data-anchor-id="source-1-experimental-study-p_xa-c">4.1 Source 1: Experimental Study (<img src="https://latex.codecogs.com/png.latex?P_X(A,%20C)">)</h3>
<p>첫 번째 데이터셋은 운동(<img src="https://latex.codecogs.com/png.latex?X">)에 개입한 실험 데이터이며 <img src="https://latex.codecogs.com/png.latex?A">와 <img src="https://latex.codecogs.com/png.latex?C">를 관측합니다. 즉, <img src="https://latex.codecogs.com/png.latex?P_X(A,%20C)"> 분포를 온전히 가지고 있습니다.</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?P(a)">: <img src="https://latex.codecogs.com/png.latex?X">는 무작위 배정되었으므로 <img src="https://latex.codecogs.com/png.latex?A">와 독립입니다. 따라서 <img src="https://latex.codecogs.com/png.latex?P_x(a)%20=%20P(a)">. 실험군 내의 나이 분포에서 얻을 수 있습니다.</li>
<li><img src="https://latex.codecogs.com/png.latex?P_%7Ba,x%7D(c)">: <img src="https://latex.codecogs.com/png.latex?A">와 <img src="https://latex.codecogs.com/png.latex?X">가 주어졌을 때 <img src="https://latex.codecogs.com/png.latex?C">의 분포입니다. 실험 데이터 <img src="https://latex.codecogs.com/png.latex?P_X(A,%20C)">에서 조건부 확률 등을 통해 도출할 수 있습니다. (엄밀히는 <img src="https://latex.codecogs.com/png.latex?P_x(c%7Ca)"> 형태)</li>
</ul>
<p>따라서 식의 앞부분 <img src="https://latex.codecogs.com/png.latex?P(a)P_%7Ba,x%7D(c)">는 <strong>연구 1</strong>에서 식별 가능합니다.</p>
</section>
<section id="source-2-observational-study-pb-c-y" class="level3">
<h3 class="anchored" data-anchor-id="source-2-observational-study-pb-c-y">4.2 Source 2: Observational Study (<img src="https://latex.codecogs.com/png.latex?P(B,%20C,%20Y)">)</h3>
<p>두 번째 데이터셋은 <img src="https://latex.codecogs.com/png.latex?B,%20C,%20Y">를 관측합니다. 우리가 필요한 마지막 조각은 <img src="https://latex.codecogs.com/png.latex?P_c(y)">입니다.</p>
<ul>
<li>그래프 구조상 <img src="https://latex.codecogs.com/png.latex?C">에서 <img src="https://latex.codecogs.com/png.latex?Y">로 가는 길목에 <img src="https://latex.codecogs.com/png.latex?B">가 교란 요인으로 작용하지 않고(앞단의 변수임), <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 Confounding path는 존재하지만, <img src="https://latex.codecogs.com/png.latex?C"> 자체에 대한 개입(<img src="https://latex.codecogs.com/png.latex?P_c(y)">)을 고려할 때 <img src="https://latex.codecogs.com/png.latex?P(B,%20C,%20Y)"> 데이터 내에서 이를 추정할 수 있는 구조적 조건이 성립합니다.</li>
<li>즉, <img src="https://latex.codecogs.com/png.latex?P_c(y)">는 <strong>연구 2</strong>의 관찰 데이터로부터 복원해낼 수 있습니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-06/images/data_fusion_puzzle.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: The Puzzle of Data Fusion. 보라색 퍼즐 조각(<img src="https://latex.codecogs.com/png.latex?P_c(y)">, <img src="https://latex.codecogs.com/png.latex?P_%7Ba,x%7D(b)"> 등)과 초록색 퍼즐 조각(<img src="https://latex.codecogs.com/png.latex?P(a)">, <img src="https://latex.codecogs.com/png.latex?P_b(c)">)이 서로 다른 데이터셋에서 추출되어 하나의 완성된 그림(<img src="https://latex.codecogs.com/png.latex?P_x(y)">)을 맞추는 과정을 시각화함.</figcaption>
</figure>
</div>
</section>
<section id="final-formula" class="level3">
<h3 class="anchored" data-anchor-id="final-formula">4.3 Final Formula</h3>
<p>결과적으로 우리는 타겟 효과를 다음과 같이 계산할 수 있습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?P_x(y)%20=%20%5Csum_%7Ba,c%7D%20P_x(a,%20c)%20%5Ctimes%20P_c(y)"></p>
<p>(참고: 위 식은 직관적인 매핑을 보여주며, 실제 계산 시에는 <img src="https://latex.codecogs.com/png.latex?P_c(y)">를 <img src="https://latex.codecogs.com/png.latex?P(B,C,Y)">에서 도출하기 위한 추가적인 adjustment formula가 적용될 수 있습니다. 강의 자료 Slide 10 하단에는 다음과 같은 GID 공식이 제시되어 있습니다.)</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BGID%7D%20=%20%5Csum_%7Ba,c%7D%20P_%7Bx'%7D(a)%20P_x(c%7Ca)%20%5Cleft(%20%5Csum_b%20P(y%7Cb,c)P(b)%20%5Cright)"></p>
<p>이 공식은 각 데이터 소스에서 얻을 수 있는 확률값들의 곱과 합으로 타겟 인과 효과를 완벽하게 재구성합니다.</p>
</section>
</section>
<section id="conclusions" class="level2">
<h2 class="anchored" data-anchor-id="conclusions">5. Conclusions</h2>
<p>이번 GID-PO 프레임워크가 시사하는 바는 단순히 수식을 푸는 것 이상입니다.</p>
<ol type="1">
<li><strong>Data Fusion의 이론적 토대:</strong> 서로 다른 변수를 측정하는 이질적인 데이터셋들도, 그 기저에 있는 <strong>인과 메커니즘(Causal Mechanism)</strong>을 공유한다면 논리적으로 결합될 수 있습니다.</li>
<li><strong>데이터 과학의 새로운 패러다임:</strong> 빅데이터 시대에는 “모든 것을 측정한 스몰 데이터”보다 “부분적으로 측정한 빅 데이터”가 더 흔합니다. GID-PO는 이러한 환경에서 선택 편향(Selection Bias), 교란 편향(Confounding Bias), 그리고 데이터 결측(Missing Data) 문제를 통합적으로 해결할 수 있는 충분조건과 알고리즘을 제공합니다.</li>
<li><strong>Parsimonious Representation:</strong> 인과 그래프는 현상을 설명하는 가장 간결하고(coarse and parsimonious) 효율적인 표현 방식이며, 이를 통해 데이터 통합의 복잡성을 관리할 수 있습니다.</li>
</ol>
<hr>
<section id="appendix-checklist" class="level3">
<h3 class="anchored" data-anchor-id="appendix-checklist"><strong>Appendix: Checklist</strong></h3>
<p>본 포스트 작성을 위해 검토한 강의 자료 체크리스트입니다.</p>
<ul class="task-list">
<li><label><input type="checkbox" checked=""><strong>GID-PO 개념 정의</strong>: 부분 관측(Partial Observation) 하에서의 식별 가능성 문제 정의 완료.</label></li>
<li><label><input type="checkbox" checked=""><strong>Causal Graph &amp; Variables</strong>: Exercise-Stroke 예시의 변수(<img src="https://latex.codecogs.com/png.latex?A,%20X,%20B,%20C,%20Y">) 및 그래프 구조 반영 완료.</label></li>
<li><label><input type="checkbox" checked=""><strong>Data Sources</strong>: 실험 연구(<img src="https://latex.codecogs.com/png.latex?P_X(A,C)">)와 관찰 연구(<img src="https://latex.codecogs.com/png.latex?P(B,C,Y)">)의 차이 명시 완료.</label></li>
<li><label><input type="checkbox" checked=""><strong>Mathematical Derivation</strong>: <img src="https://latex.codecogs.com/png.latex?P_x(y)">의 분해 과정(Factorization) 및 단계별 유도(<img src="https://latex.codecogs.com/png.latex?%5Csum"> regrouping) 포함 완료.</label></li>
<li><label><input type="checkbox" checked=""><strong>Data Mapping</strong>: 유도된 수식의 각 항이 어느 데이터셋에서 식별 가능한지 설명 완료.</label></li>
<li><label><input type="checkbox" checked=""><strong>Visuals</strong>: 인과 그래프 및 퍼즐 비유 이미지에 대한 설명(Alt text) 포함 완료.</label></li>
<li><label><input type="checkbox" checked=""><strong>Conclusion</strong>: 인과 데이터 과학(Causal Data Science) 관점에서의 의의 서술 완료.</label></li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L17/part-06/</guid>
  <pubDate>Sat, 24 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 02. Causal Models and Graphs (Part 2)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L02/part-02/</link>
  <description><![CDATA[ 





<section id="introduction-why-causal-models" class="level1">
<h1>1. Introduction: Why Causal Models?</h1>
<p>기존의 통계학이나 머신러닝의 추론(Inference)은 주로 <strong>결합 확률 분포(Joint Distribution)</strong> <img src="https://latex.codecogs.com/png.latex?P(v)">를 파악하는 데 집중합니다. [cite_start]“고객이 A를 샀을 때 B도 살 확률은?”(<img src="https://latex.codecogs.com/png.latex?P(B%7CA)">)과 같은 질문은 데이터의 상관관계(Association)만으로도 충분히 답할 수 있습니다. [cite: 2412-2419]</p>
<p>하지만 “가격을 두 배로 올리면 판매량은 어떻게 변할까?”와 같은 <strong>개입(Intervention)</strong>이나 반사실적(Counterfactual) 질문에 답하기 위해서는 데이터 그 자체(<img src="https://latex.codecogs.com/png.latex?P">)를 넘어, 데이터가 생성되는 <strong>현실의 메커니즘(Reality)</strong>을 이해해야 합니다. [cite_start]이를 위해 우리는 <strong>구조적 인과 모델(Structural Causal Model, SCM)</strong>이라는 새로운 언어를 배웁니다. [cite: 2421-2449]</p>
<section id="motivation-simpsons-paradox-example" class="level2">
<h2 class="anchored" data-anchor-id="motivation-simpsons-paradox-example">1.1 Motivation: Simpson’s Paradox Example</h2>
<p>[cite_start]강의에서는 의사결정의 어려움을 보여주기 위해 가상의 전염병과 치료제 시나리오를 제시합니다. [cite: 2236-2246]</p>
<ul>
<li><strong>상황</strong>: 특정 도시에 전염병이 돌고 있고, 치료제(Drug)가 있습니다.</li>
<li><strong>숨겨진 진실(Reality - Unknown to physicians)</strong>:
<ol type="1">
<li><strong>부유층(Rich)</strong>: 생활 환경이 좋아 약물 복용 여부와 상관없이 생존합니다.</li>
<li><strong>빈곤층(Poor)</strong>:
<ul>
<li>유전 인자(Gene)가 없는 경우: 자연 치유력이 없어 사망합니다.</li>
<li>유전 인자가 있는 경우: 약을 먹으면 알레르기 반응으로 사망하고, 안 먹으면 생존합니다.</li>
</ul></li>
<li><strong>현재 처방 관행</strong>: 약값이 비싸서 의사들은 부유층에게만 약을 처방합니다.</li>
</ol></li>
</ul>
<p>이 상황에서 데이터만 관측하면(<img src="https://latex.codecogs.com/png.latex?P(r,%20d,%20a)">), 약을 먹은 사람(주로 부유층)은 생존율이 높고, 안 먹은 사람(주로 빈곤층)은 생존율이 낮게 나옵니다. 머신러닝 모델은 “약을 먹는 것이 생존에 유리하다”고 잘못된 결론을 내릴 수 있습니다. [cite_start]하지만 실제 메커니즘(SCM)을 안다면, <strong>“누구에게도 약을 주지 말아야 한다(빈곤층에게는 치명적, 부유층에게는 무의미)”</strong>는 정반대의 결론에 도달합니다. [cite: 2340-2402]</p>
<p>즉, 데이터(<img src="https://latex.codecogs.com/png.latex?P">)는 현실(<img src="https://latex.codecogs.com/png.latex?M">)의 그림자일 뿐이며, 올바른 인과 추론을 위해서는 <img src="https://latex.codecogs.com/png.latex?M">을 모델링해야 합니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-02/images/inference_paradigm.png" class="img-fluid figure-img"></p>
<figcaption>Figure: 기존 통계적 추론과 인과 추론의 패러다임 비교. 통계적 추론은 데이터 P 내에서의 성질 Q(P)를 찾지만, 인과 추론은 데이터 생성 모델 M을 통해 현실을 이해하고 P’를 추정한다.</figcaption>
</figure>
</div>
<hr>
</section>
</section>
<section id="structural-causal-model-scm" class="level1">
<h1>2. Structural Causal Model (SCM)</h1>
<p>인과 관계를 수학적으로 정의하기 위해 SCM을 도입합니다. SCM은 현실의 메커니즘을 <strong>결정론적 함수</strong>와 <strong>확률적 노이즈</strong>의 결합으로 표현합니다.</p>
<section id="definition" class="level2">
<h2 class="anchored" data-anchor-id="definition">2.1 Definition</h2>
<p>[cite_start]SCM <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BM%7D">은 4개의 요소 <img src="https://latex.codecogs.com/png.latex?%5Clangle%20V,%20U,%20F,%20P(U)%20%5Crangle">로 구성된 튜플입니다. [cite: 2548-2554]</p>
<ol type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?V%20=%20%5C%7BV_1,%20...,%20V_n%5C%7D"> (Endogenous Variables)</strong>: 모델 내부에서 결정되며, 우리가 관측할 수 있는 변수들입니다.</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?U%20=%20%5C%7BU_1,%20...,%20U_m%5C%7D"> (Exogenous Variables)</strong>: 모델 외부에서 결정되는 변수들로, 관측되지 않는 배경 요인(Background factors)이나 노이즈를 의미합니다.</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?F%20=%20%5C%7Bf_1,%20...,%20f_n%5C%7D"> (Structural Functions)</strong>: 각 내생 변수 <img src="https://latex.codecogs.com/png.latex?V_i">가 어떻게 결정되는지를 정의하는 함수 집합입니다. <img src="https://latex.codecogs.com/png.latex?v_i%20%5Cleftarrow%20f_i(pa_i,%20u_i)"> 여기서 <img src="https://latex.codecogs.com/png.latex?pa_i%20%5Csubseteq%20V%20%5Csetminus%20%5C%7BV_i%5C%7D">는 <img src="https://latex.codecogs.com/png.latex?V_i">의 부모 변수(직접적인 원인)들이고, <img src="https://latex.codecogs.com/png.latex?u_i%20%5Csubseteq%20U">는 관련된 외생 변수입니다.</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?P(U)"></strong>: 외생 변수 <img src="https://latex.codecogs.com/png.latex?U">에 대한 확률 분포입니다.</li>
</ol>
</section>
<section id="properties-of-scm" class="level2">
<h2 class="anchored" data-anchor-id="properties-of-scm">2.2 Properties of SCM</h2>
<p>[cite_start]SCM은 다음과 같은 중요한 성질을 가집니다. [cite: 2572-2637]</p>
<ol type="1">
<li><strong>Induces <img src="https://latex.codecogs.com/png.latex?P(V)"></strong>: 외생 변수의 분포 <img src="https://latex.codecogs.com/png.latex?P(U)">와 함수 <img src="https://latex.codecogs.com/png.latex?F">를 통해 관측 변수들의 결합 확률 분포 <img src="https://latex.codecogs.com/png.latex?P(V)">가 결정됩니다.</li>
<li><strong>Induces Causal Diagram</strong>: 변수 간의 함수적 관계(<img src="https://latex.codecogs.com/png.latex?f_i">)를 통해 인과 그래프(DAG)를 그릴 수 있습니다.</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-02/images/scm_conceptual.png" class="img-fluid figure-img"></p>
<figcaption>Figure: SCM의 개념도. 외생 변수 U가 확률 분포 P(U)를 따르고, 함수 F를 통해 내생 변수 V의 값을 결정하여 관측 데이터 분포 P(V)를 유도한다.</figcaption>
</figure>
</div>
<hr>
</section>
</section>
<section id="causal-diagrams-dags" class="level1">
<h1>3. Causal Diagrams (DAGs)</h1>
<p>SCM은 시각적으로 <strong>유향 비순환 그래프(DAG, Directed Acyclic Graph)</strong>로 표현됩니다. [cite_start]그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D%20=%20%5Clangle%20V,%20E%20%5Crangle">는 다음 규칙에 따라 생성됩니다. [cite: 2683-2687]</p>
<ol type="1">
<li><strong>Nodes</strong>: 각 내생 변수 <img src="https://latex.codecogs.com/png.latex?V_i">를 노드로 합니다.</li>
<li><strong>Directed Edges (<img src="https://latex.codecogs.com/png.latex?%5Crightarrow">)</strong>: 함수 <img src="https://latex.codecogs.com/png.latex?f_i">에서 <img src="https://latex.codecogs.com/png.latex?V_j">가 <img src="https://latex.codecogs.com/png.latex?V_i">의 인자(<img src="https://latex.codecogs.com/png.latex?pa_i">)로 사용되면 <img src="https://latex.codecogs.com/png.latex?V_j%20%5Crightarrow%20V_i"> 엣지를 그립니다.</li>
<li><strong>Bidirected Edges (<img src="https://latex.codecogs.com/png.latex?%5Cleftrightarrow">)</strong>: 두 변수 <img src="https://latex.codecogs.com/png.latex?V_i,%20V_j">가 공통된 외생 변수(Common unobserved confounder)를 공유하거나, 그들의 외생 변수 <img src="https://latex.codecogs.com/png.latex?U_i,%20U_j">가 서로 종속적(Correlated)일 때 점선 양방향 화살표로 연결합니다.</li>
</ol>
<hr>
</section>
<section id="markovian-factorization" class="level1">
<h1>4. Markovian Factorization</h1>
<p>SCM의 가장 강력한 점 중 하나는 복잡한 결합 확률 분포를 간단한 조건부 확률의 곱으로 분해할 수 있다는 것입니다. 이를 <strong>Markovian Factorization</strong> 또는 <strong>Bayesian Factorization</strong>이라고 합니다.</p>
<section id="markovian-condition" class="level2">
<h2 class="anchored" data-anchor-id="markovian-condition">4.1 Markovian Condition</h2>
<p>[cite_start]만약 모든 외생 변수 <img src="https://latex.codecogs.com/png.latex?U_i">들이 서로 <strong>독립(Jointly Independent)</strong>이라면, 즉 그래프에 양방향 엣지(<img src="https://latex.codecogs.com/png.latex?%5Cleftrightarrow">)가 하나도 없다면, 이 모델을 <strong>Markovian</strong>이라고 합니다. [cite: 2988-2991]</p>
</section>
<section id="mathematical-derivation" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-derivation">4.2 Mathematical Derivation</h2>
<p>[cite_start]Markovian 가정 하에서 결합 확률 분포 <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)">가 어떻게 분해되는지 단계별로 유도해 보겠습니다. [cite: 2992-2993]</p>
<p><strong>Step 1: Law of Total Probability</strong> 모든 변수 <img src="https://latex.codecogs.com/png.latex?V">의 결합 확률은 외생 변수 <img src="https://latex.codecogs.com/png.latex?U">를 포함한 전체 확률에서 <img src="https://latex.codecogs.com/png.latex?U">를 합(Summing out)하여 얻습니다. SCM에서 <img src="https://latex.codecogs.com/png.latex?v_i">는 <img src="https://latex.codecogs.com/png.latex?pa_i">와 <img src="https://latex.codecogs.com/png.latex?u_i">에 의해 결정되므로(<img src="https://latex.codecogs.com/png.latex?P(v_i%7Cpa_i,%20u_i)">는 0 또는 1), 다음과 같이 쓸 수 있습니다. <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)%20=%20%5Csum_%7B%5Cmathbf%7Bu%7D%7D%20P(%5Cmathbf%7Bu%7D)%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%5Cmid%20pa_i,%20u_i)"></p>
<p><strong>Step 2: Independence of Exogenous Variables</strong> Markovian 가정에 의해 <img src="https://latex.codecogs.com/png.latex?U">들이 서로 독립이므로, <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bu%7D)%20=%20%5Cprod%20P(u_i)">가 됩니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7B%5Cmathbf%7Bu%7D%7D%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%5Cmid%20pa_i,%20u_i)%20P(u_i)"></p>
<p><strong>Step 3: Independence of <img src="https://latex.codecogs.com/png.latex?U_i"> and <img src="https://latex.codecogs.com/png.latex?Pa_i"></strong> 외생 변수 <img src="https://latex.codecogs.com/png.latex?U_i">는 시스템 외부에서 결정되므로 내생 변수인 부모 <img src="https://latex.codecogs.com/png.latex?Pa_i">와 독립입니다. 따라서 <img src="https://latex.codecogs.com/png.latex?P(u_i)%20=%20P(u_i%20%5Cmid%20pa_i)">로 쓸 수 있습니다. 이를 식에 대입하고, 확률의 곱셈 법칙(<img src="https://latex.codecogs.com/png.latex?P(A%7CB)P(B)%20=%20P(A,B)">)을 적용합니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7B%5Cmathbf%7Bu%7D%7D%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%5Cmid%20pa_i,%20u_i)%20P(u_i%20%5Cmid%20pa_i)"> <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7B%5Cmathbf%7Bu%7D%7D%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i,%20u_i%20%5Cmid%20pa_i)"></p>
<p><strong>Step 4: Commutativity of Sum and Product</strong> 각 항은 자신에게 해당되는 <img src="https://latex.codecogs.com/png.latex?u_i">에만 의존하므로, 전체 합(<img src="https://latex.codecogs.com/png.latex?%5Csum_%7B%5Cmathbf%7Bu%7D%7D">)을 개별 합(<img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bu_i%7D">)의 곱으로 바꿀 수 있습니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20%5Cleft(%20%5Csum_%7Bu_i%7D%20P(v_i,%20u_i%20%5Cmid%20pa_i)%20%5Cright)"></p>
<p><strong>Step 5: Marginalization (Final Result)</strong> 괄호 안의 식은 결합 확률에서 <img src="https://latex.codecogs.com/png.latex?u_i">를 마지널라이즈(Marginalize)한 것과 같으므로 최종적으로 다음 식이 성립합니다. <img src="https://latex.codecogs.com/png.latex?%5Cboxed%7BP(%5Cmathbf%7Bv%7D)%20=%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%5Cmid%20pa_i)%7D"></p>
<p>이 결과는 관측 불가능한 <img src="https://latex.codecogs.com/png.latex?U">를 모르더라도, <strong>오직 부모-자식 간의 관계(Local Information)만으로 전체 시스템의 분포를 설명할 수 있음</strong>을 의미합니다.</p>
<hr>
</section>
</section>
<section id="conditional-independence-d-separation" class="level1">
<h1>5. Conditional Independence &amp; d-separation</h1>
<p>그래프 구조는 변수들 간의 조건부 독립성(Conditional Independence) 정보를 담고 있습니다. [cite_start]이를 파악하기 위해 세 가지 기본 구조(Triplets)를 이해해야 합니다. [cite: 3014-3191]</p>
<section id="the-three-basic-structures-triplets" class="level2">
<h2 class="anchored" data-anchor-id="the-three-basic-structures-triplets">5.1 The Three Basic Structures (Triplets)</h2>
<section id="chain-causal-chain" class="level3">
<h3 class="anchored" data-anchor-id="chain-causal-chain">1. Chain (Causal Chain)</h3>
<ul>
<li><strong>구조</strong>: <img src="https://latex.codecogs.com/png.latex?X%20%5Crightarrow%20Z%20%5Crightarrow%20Y"></li>
<li><strong>해석</strong>: <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Z">를 유발하고, <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?Y">를 유발합니다. (예: 공부 습관 <img src="https://latex.codecogs.com/png.latex?%5Cto"> 수능 점수 <img src="https://latex.codecogs.com/png.latex?%5Cto"> 대학 합격)</li>
<li><strong>독립성</strong>:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Z">를 모를 때: <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">는 종속적입니다.</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?Z">를 알 때 (Given <img src="https://latex.codecogs.com/png.latex?Z">)</strong>: <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 영향은 <img src="https://latex.codecogs.com/png.latex?Z">에 의해 차단(Blocked)되므로 <strong><img src="https://latex.codecogs.com/png.latex?X%20%5Cperp%20Y%20%5Cmid%20Z"></strong> (독립)입니다.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-02/images/causal_chain.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Causal Chain 구조. 중간 변수 Z를 관측하면 X와 Y의 정보 흐름이 차단되어 독립이 된다.</figcaption>
</figure>
</div>
</section>
<section id="fork-common-cause" class="level3">
<h3 class="anchored" data-anchor-id="fork-common-cause">2. Fork (Common Cause)</h3>
<ul>
<li><strong>구조</strong>: <img src="https://latex.codecogs.com/png.latex?X%20%5Cleftarrow%20Z%20%5Crightarrow%20Y"></li>
<li><strong>해석</strong>: <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">의 공통 원인입니다. (예: 비 <img src="https://latex.codecogs.com/png.latex?%5Cto"> 교통체증, 비 <img src="https://latex.codecogs.com/png.latex?%5Cto"> 우산 사용)</li>
<li><strong>독립성</strong>:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Z">를 모를 때: 공통 원인에 의해 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">는 상관관계를 가집니다(Spurious Correlation).</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?Z">를 알 때 (Given <img src="https://latex.codecogs.com/png.latex?Z">)</strong>: 공통 원인을 통제했으므로 <strong><img src="https://latex.codecogs.com/png.latex?X%20%5Cperp%20Y%20%5Cmid%20Z"></strong> (독립)입니다.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-02/images/common_cause.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Common Cause (Fork) 구조. 공통 원인 Z를 통제하면 X와 Y 사이의 허위 상관관계가 사라진다.</figcaption>
</figure>
</div>
</section>
<section id="collider-common-effect" class="level3">
<h3 class="anchored" data-anchor-id="collider-common-effect">3. Collider (Common Effect)</h3>
<ul>
<li><strong>구조</strong>: <img src="https://latex.codecogs.com/png.latex?X%20%5Crightarrow%20Z%20%5Cleftarrow%20Y"></li>
<li><strong>해석</strong>: 서로 독립인 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">가 공통 결과 <img src="https://latex.codecogs.com/png.latex?Z">를 유발합니다. (예: 감기 <img src="https://latex.codecogs.com/png.latex?%5Cto"> 결석, 휴일 <img src="https://latex.codecogs.com/png.latex?%5Cto"> 결석)</li>
<li><strong>독립성</strong>:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Z">를 모를 때: <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">는 서로 독립입니다. (<img src="https://latex.codecogs.com/png.latex?P(X,Y)%20=%20P(X)P(Y)">)</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?Z">를 알 때 (Given <img src="https://latex.codecogs.com/png.latex?Z">)</strong>: <strong><img src="https://latex.codecogs.com/png.latex?X%20%5Cnot%5Cperp%20Y%20%5Cmid%20Z"></strong> (종속)이 됩니다. 이를 <strong>“Explaining Away”</strong> 현상이라고 합니다. 결석(<img src="https://latex.codecogs.com/png.latex?Z=1">)했는데 휴일이 아니라면(<img src="https://latex.codecogs.com/png.latex?Y=0">), 감기일 확률(<img src="https://latex.codecogs.com/png.latex?X=1">)이 높아지기 때문입니다.</li>
<li><strong>주의</strong>: Collider 본인뿐만 아니라 <strong>Collider의 자손(Descendant)</strong>을 관측해도 경로가 열립니다.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-02/images/common_effect.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Common Effect (Collider) 구조. 두 독립적인 원인이 공통 결과 Z를 조건부로 알게 되었을 때 종속적으로 변하는 Explaining Away 현상을 보여준다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="d-separation-rule" class="level2">
<h2 class="anchored" data-anchor-id="d-separation-rule">5.2 d-separation Rule</h2>
<p>[cite_start]이 세 가지 규칙을 일반화하여 그래프상의 두 노드 <img src="https://latex.codecogs.com/png.latex?X,%20Y">가 조건부 집합 <img src="https://latex.codecogs.com/png.latex?Z">에 대해 독립인지 판별하는 규칙을 <strong>d-separation</strong>이라고 합니다. [cite: 3224-3228]</p>
<ul>
<li>두 노드 사이의 <strong>모든 경로</strong>가 차단(Blocked)되면 d-separated 되었다고 합니다.</li>
<li><strong>경로가 차단되는 조건</strong>:
<ol type="1">
<li>경로 상에 <img src="https://latex.codecogs.com/png.latex?Z">에 포함된 Chain이나 Fork 노드가 있을 때.</li>
<li>경로 상에 Collider가 있으면서, 그 Collider와 자손들이 하나도 <img src="https://latex.codecogs.com/png.latex?Z">에 포함되지 않았을 때.</li>
</ol></li>
</ul>
<hr>
</section>
</section>
<section id="implementation-topological-order" class="level1">
<h1>6. Implementation: Topological Order</h1>
<p>DAG에서 부모가 항상 자식보다 먼저 오도록 노드를 정렬하는 것을 위상 정렬(Topological Order)이라고 합니다. [cite_start]이는 인과 추론 알고리즘 구현의 기초가 됩니다. [cite: 3231-3250]</p>
<p>다음은 Python을 이용한 위상 정렬 구현 예시입니다.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> collections <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> deque</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> topological_order(G):</span>
<span id="cb1-4">    order <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> deque()</span>
<span id="cb1-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. 모든 노드의 진입 차수(in-degree) 계산 (부모의 수)</span></span>
<span id="cb1-6">    in_degrees <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {V: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(G.Pa(V)) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> V <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> G.Vs}</span>
<span id="cb1-7">    </span>
<span id="cb1-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">while</span> in_degrees:</span>
<span id="cb1-9">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. 부모가 없는(in-degree=0) 소스 노드 찾기</span></span>
<span id="cb1-10">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> v, v_deg <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> in_degrees.items():</span>
<span id="cb1-11">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> v_deg <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb1-12">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">break</span></span>
<span id="cb1-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb1-14">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 루프가 break 없이 끝났다면 사이클이 존재한다는 의미 (DAG가 아님)</span></span>
<span id="cb1-15">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">raise</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">ValueError</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cyclic'</span>)</span>
<span id="cb1-16">        </span>
<span id="cb1-17">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. 소스 노드를 순서에 추가하고 그래프에서 제거 개념 적용</span></span>
<span id="cb1-18">        order.append(v)</span>
<span id="cb1-19">        <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">del</span> in_degrees[v]</span>
<span id="cb1-20">        </span>
<span id="cb1-21">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 4. 해당 노드의 자식들의 진입 차수 감소</span></span>
<span id="cb1-22">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> G.Ch(v):</span>
<span id="cb1-23">            in_degrees[c] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb1-24">            </span>
<span id="cb1-25">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> order</span></code></pre></div></div>
<hr>
</section>
<section id="summary" class="level1">
<h1>7. Summary</h1>
<p>이번 포스트에서는 인과 추론의 기초가 되는 SCM과 인과 그래프에 대해 알아보았습니다.</p>
<ol type="1">
<li><strong>SCM</strong>: 현실의 메커니즘을 변수, 외생 변수, 함수적 관계로 정의하는 모델 ().</li>
<li><strong>Markovian Factorization</strong>: 외생 변수의 독립성을 가정하면, 결합 확률을 <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)%20=%20%5Cprod%20P(v_i%20%7C%20pa_i)">로 분해할 수 있습니다.</li>
<li><strong>d-separation</strong>: Chain, Fork, Collider 구조를 통해 변수 간의 조건부 독립성을 파악할 수 있으며, 특히 Collider가 관측될 때 경로가 열린다는 점에 주의해야 합니다.</li>
</ol>
<hr>
<section id="checklist-for-content-verification" class="level3">
<h3 class="anchored" data-anchor-id="checklist-for-content-verification">Checklist for Content Verification</h3>
<ul class="task-list">
<li><label><input type="checkbox" checked=""><strong>Motivation</strong>: Simpson’s Paradox 예시와 Data vs Reality의 차이 설명 포함.</label></li>
<li><label><input type="checkbox" checked=""><strong>SCM Definition</strong>: 4-tuple 정의 및 구성 요소 설명 포함.</label></li>
<li><label><input type="checkbox" checked=""><strong>Mathematical Derivation</strong>: Markovian Factorization의 단계별 유도 과정 LaTeX 수식으로 포함.</label></li>
<li><label><input type="checkbox" checked=""><strong>Basic Structures</strong>: Chain, Fork, Collider의 구조 및 독립성 조건 설명 포함.</label></li>
<li><label><input type="checkbox" checked=""><strong>d-separation</strong>: 경로 차단 조건 및 규칙 설명 포함.</label></li>
<li><label><input type="checkbox" checked=""><strong>Algorithm</strong>: 위상 정렬 알고리즘 및 Python 코드 포함.</label></li>
</ul>
<pre><code></code></pre>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L02/part-02/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 02. Causal Models and Graphs (Part 1)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L02/part-01/</link>
  <description><![CDATA[ 





<section id="introduction-from-statistics-to-causality" class="level1">
<h1>1. Introduction: From Statistics to Causality</h1>
<p>전통적인 통계학이나 머신러닝의 추론(Inference) 패러다임은 데이터의 <strong>결합 확률 분포(Joint Distribution)</strong> <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)">를 찾아내는 것에 집중합니다. 예를 들어, “상품 A를 산 고객이 상품 B도 살 확률은 얼마인가?”(<img src="https://latex.codecogs.com/png.latex?P(B%7CA)">)와 같은 질문은 관측된 데이터의 패턴(Association)만으로 충분히 답할 수 있습니다.</p>
<p>하지만 현실의 문제 해결은 종종 <strong>“만약 우리가 X를 변화시킨다면, Y는 어떻게 변할까?”</strong>라는 질문을 던집니다. * 가격을 두 배로 올리면 판매량은 어떻게 될까? * 흡연을 금지하면 암 발병률은 낮아질까?</p>
<p>이러한 질문은 데이터 자체(<img src="https://latex.codecogs.com/png.latex?P">)가 아니라 데이터가 생성되는 <strong>현실의 메커니즘(Reality)</strong>에 대한 이해를 요구합니다. 이번 포스트에서는 인과 추론의 핵심 언어인 <strong>구조적 인과 모델(Structural Causal Model, SCM)</strong>과 이를 시각화한 <strong>인과 그래프(Causal Graph)</strong>에 대해 다룹니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-01/images/stats_vs_causal_paradigm.png" class="img-fluid figure-img"></p>
<figcaption>Figure: 통계적 추론과 인과적 추론의 차이. 통계적 추론은 데이터 <img src="https://latex.codecogs.com/png.latex?P"> 내에서의 성질 <img src="https://latex.codecogs.com/png.latex?Q(P)">를 찾지만, 인과 추론은 데이터 생성 모델 <img src="https://latex.codecogs.com/png.latex?M">을 통해 현실의 메커니즘을 이해하고, 개입 후의 분포 <img src="https://latex.codecogs.com/png.latex?P'">를 추정하려 한다.</figcaption>
</figure>
</div>
<section id="motivation-simpsons-paradox-example" class="level2">
<h2 class="anchored" data-anchor-id="motivation-simpsons-paradox-example">1.1 Motivation: Simpson’s Paradox Example</h2>
<p>왜 데이터만으로는 충분하지 않을까요? 강의 자료에 제시된 ‘약물 투여와 생존율’ 예시를 봅시다.</p>
<ul>
<li><strong>상황</strong>: 특정 도시에 전염병이 돌고 있고, 치료제(Drug)가 있습니다.</li>
<li><strong>숨겨진 진실(Reality)</strong>:
<ol type="1">
<li>부유층(Rich)은 약물 복용 여부와 상관없이 생존합니다 (좋은 생활 환경).</li>
<li>빈곤층(Poor)은 약물을 복용하면 알레르기 반응으로 사망하고, 복용하지 않으면 생존합니다(자연 면역).</li>
<li>의사들은 부유층에게만 주로 약을 처방합니다(비용 문제).</li>
</ol></li>
</ul>
<p>이 경우 데이터만 보면 “약물을 복용한 집단(대부분 부유층)”의 생존율이 높게 나타납니다. 알고리즘은 “약을 먹어라”라고 추천할 것입니다. 하지만 실제 메커니즘(빈곤층에게는 치명적)을 안다면 빈곤층에게 약을 주면 안 된다는 정반대의 결론에 도달해야 합니다. 즉, <strong>데이터 생성 과정(Data Generating Process)</strong>을 모델링하지 않으면 잘못된 의사결정을 내리게 됩니다.</p>
<hr>
</section>
</section>
<section id="structural-causal-model-scm" class="level1">
<h1>2. Structural Causal Model (SCM)</h1>
<p>인과 관계를 수학적으로 엄밀하게 정의하기 위해 <strong>구조적 인과 모델(SCM)</strong>을 도입합니다.</p>
<section id="definition" class="level2">
<h2 class="anchored" data-anchor-id="definition">2.1 Definition</h2>
<p>SCM <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BM%7D">은 다음 4가지 요소의 튜플 <img src="https://latex.codecogs.com/png.latex?%5Clangle%20V,%20U,%20F,%20P(U)%20%5Crangle">로 정의됩니다.</p>
<ol type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?V%20=%20%5C%7BV_1,%20...,%20V_n%5C%7D"></strong>: <strong>내생 변수(Endogenous variables)</strong>. 우리가 관측할 수 있는 변수들입니다. (예: 흡연 여부, 폐암 발병 여부)</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?U%20=%20%5C%7BU_1,%20...,%20U_m%5C%7D"></strong>: <strong>외생 변수(Exogenous variables)</strong>. 모델 내부의 다른 변수에 의해 설명되지 않는, 시스템 외부에서 결정되는 변수들입니다. (예: 유전적 요인, 미관측 환경 요인)</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?F%20=%20%5C%7Bf_1,%20...,%20f_n%5C%7D"></strong>: <strong>구조적 함수(Structural functions)</strong>. 각 내생 변수 <img src="https://latex.codecogs.com/png.latex?V_i">가 어떻게 결정되는지를 나타내는 함수입니다. <img src="https://latex.codecogs.com/png.latex?v_i%20%5Cleftarrow%20f_i(pa_i,%20u_i)"> 여기서 <img src="https://latex.codecogs.com/png.latex?pa_i%20%5Csubseteq%20V%20%5Csetminus%20%5C%7BV_i%5C%7D">는 <img src="https://latex.codecogs.com/png.latex?V_i">의 <strong>부모(Parents)</strong> 변수 집합이고, <img src="https://latex.codecogs.com/png.latex?u_i%20%5Csubseteq%20U">는 관련된 외생 변수입니다.</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?P(U)"></strong>: 외생 변수 <img src="https://latex.codecogs.com/png.latex?U">에 대한 확률 분포입니다.</li>
</ol>
<blockquote class="blockquote">
<p><strong>Key Idea</strong>: SCM에서 자연(Nature)은 결정론적(Deterministic) 함수 <img src="https://latex.codecogs.com/png.latex?F">와 확률적(Probabilistic) 노이즈 <img src="https://latex.codecogs.com/png.latex?P(U)">의 결합으로 세상을 정의합니다.</p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-01/images/scm_conceptual_diagram.png" class="img-fluid figure-img"></p>
<figcaption>Figure: SCM의 개념적 도식. 외생 변수 U가 확률 분포 P(U)를 따르고, 함수 F를 통해 내생 변수 V의 값을 결정하여 관측 데이터 분포 P(V)를 유도한다.</figcaption>
</figure>
</div>
</section>
<section id="scm-induces-a-distribution-pv" class="level2">
<h2 class="anchored" data-anchor-id="scm-induces-a-distribution-pv">2.2 SCM Induces a Distribution <img src="https://latex.codecogs.com/png.latex?P(V)"></h2>
<p>SCM은 단순히 변수 간의 관계만 정의하는 것이 아니라, 관측 가능한 변수 <img src="https://latex.codecogs.com/png.latex?V">의 결합 확률 분포 <img src="https://latex.codecogs.com/png.latex?P(V)">를 유도(Induce)합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)%20=%20%5Csum_%7B%5Cmathbf%7Bu%7D%20:%20Y(%5Cmathbf%7Bu%7D)%20=%20%5Cmathbf%7Bv%7D%7D%20P(%5Cmathbf%7Bu%7D)"></p>
<p>즉, 우리가 관측하는 데이터의 분포는 <strong>외생 변수의 불확실성(<img src="https://latex.codecogs.com/png.latex?P(U)">)이 함수 <img src="https://latex.codecogs.com/png.latex?F">를 통과하여 내생 변수 <img src="https://latex.codecogs.com/png.latex?V">로 전파된 결과</strong>입니다.</p>
<hr>
</section>
</section>
<section id="causal-diagrams-graphical-models" class="level1">
<h1>3. Causal Diagrams (Graphical Models)</h1>
<p>SCM은 수식으로 정의되지만, 이를 직관적으로 이해하고 분석하기 위해 <strong>유향 비순환 그래프(DAG, Directed Acyclic Graph)</strong> 형태인 인과 그래프로 표현할 수 있습니다.</p>
<section id="construction-rules" class="level2">
<h2 class="anchored" data-anchor-id="construction-rules">3.1 Construction Rules</h2>
<p>SCM <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BM%7D">으로부터 인과 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D">를 그리는 규칙은 다음과 같습니다.</p>
<ol type="1">
<li><strong>Nodes</strong>: 각 내생 변수 <img src="https://latex.codecogs.com/png.latex?V_i">를 노드(Vertex)로 그립니다.</li>
<li><strong>Directed Edges (<img src="https://latex.codecogs.com/png.latex?%5Crightarrow">)</strong>: 함수 <img src="https://latex.codecogs.com/png.latex?f_i">에서 <img src="https://latex.codecogs.com/png.latex?V_j">가 <img src="https://latex.codecogs.com/png.latex?V_i">의 입력(<img src="https://latex.codecogs.com/png.latex?pa_i">)으로 사용된다면, <img src="https://latex.codecogs.com/png.latex?V_j%20%5Cto%20V_i"> 화살표를 그립니다.</li>
<li><strong>Bidirected Edges (<img src="https://latex.codecogs.com/png.latex?%5Cleftrightarrow">)</strong>: 두 변수 <img src="https://latex.codecogs.com/png.latex?V_i,%20V_j">에 영향을 주는 외생 변수 <img src="https://latex.codecogs.com/png.latex?U_i,%20U_j">가 서로 상관관계가 있거나(Correlated), 같은 외생 변수를 공유한다면 점선 양방향 화살표로 연결합니다. 이는 <strong>미관측 교란 요인(Unobserved Confounder)</strong>의 존재를 의미합니다.</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-01/images/scm_to_dag_example.png" class="img-fluid figure-img"></p>
<figcaption>Figure: SCM에서 인과 그래프로의 변환 예시. (좌) 수식으로 표현된 SCM, (우) 이에 대응하는 DAG. 외생 변수 U는 보통 그래프에서 생략되거나 점선으로 표현된다.</figcaption>
</figure>
</div>
</section>
<section id="terminology" class="level2">
<h2 class="anchored" data-anchor-id="terminology">3.2 Terminology</h2>
<ul>
<li><strong>Parents (<img src="https://latex.codecogs.com/png.latex?Pa_i">)</strong>: <img src="https://latex.codecogs.com/png.latex?V_i">로 직접 화살표를 보내는 변수들.</li>
<li><strong>Children (<img src="https://latex.codecogs.com/png.latex?Ch_i">)</strong>: <img src="https://latex.codecogs.com/png.latex?V_i">로부터 직접 화살표를 받는 변수들.</li>
<li><strong>Ancestors / Descendants</strong>: 화살표를 따라 거슬러 올라가거나 내려갈 수 있는 변수들.</li>
</ul>
<hr>
</section>
</section>
<section id="markovian-factorization-detailed-derivation" class="level1">
<h1>4. Markovian Factorization (Detailed Derivation)</h1>
<p>이 포스트의 핵심 파트입니다. SCM과 그래프 구조를 이용하여 복잡한 결합 확률 분포 <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)">를 어떻게 간단한 조건부 확률들의 곱으로 분해할 수 있는지 증명합니다.</p>
<section id="the-markovian-condition" class="level2">
<h2 class="anchored" data-anchor-id="the-markovian-condition">4.1 The Markovian Condition</h2>
<p>만약 외생 변수들 <img src="https://latex.codecogs.com/png.latex?U">가 서로 <strong>독립(Jointly Independent)</strong>이라면, 즉 그래프 상에 양방향 엣지(<img src="https://latex.codecogs.com/png.latex?%5Cleftrightarrow">)가 하나도 없다면, 이 모델을 <strong>Markovian</strong>이라고 부릅니다.</p>
</section>
<section id="derivation-of-bayesian-factorization" class="level2">
<h2 class="anchored" data-anchor-id="derivation-of-bayesian-factorization">4.2 Derivation of Bayesian Factorization</h2>
<p>우리의 목표는 <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)">를 <img src="https://latex.codecogs.com/png.latex?%5Cprod%20P(v_i%20%7C%20pa_i)"> 형태로 만드는 것입니다. 이를 <strong>Bayesian Factorization</strong>이라 합니다.</p>
<p><strong>Step 1: Law of Total Probability</strong> 모든 변수 <img src="https://latex.codecogs.com/png.latex?V">의 결합 확률은 외생 변수 <img src="https://latex.codecogs.com/png.latex?U">를 포함한 결합 확률에서 <img src="https://latex.codecogs.com/png.latex?U">를 합(Summing out)하여 얻을 수 있습니다. <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)%20=%20%5Csum_%7B%5Cmathbf%7Bu%7D%7D%20P(%5Cmathbf%7Bv%7D,%20%5Cmathbf%7Bu%7D)"></p>
<p>SCM에서 <img src="https://latex.codecogs.com/png.latex?V">는 <img src="https://latex.codecogs.com/png.latex?Pa">와 <img src="https://latex.codecogs.com/png.latex?U">에 의해 결정되므로(<img src="https://latex.codecogs.com/png.latex?v_i%20=%20f_i(pa_i,%20u_i)">), <img src="https://latex.codecogs.com/png.latex?P(v_i%20%7C%20pa_i,%20u_i)">는 결정론적입니다(0 또는 1). 이를 이용하여 식을 전개하면: <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)%20=%20%5Csum_%7B%5Cmathbf%7Bu%7D%7D%20P(%5Cmathbf%7Bu%7D)%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%5Cmid%20%5Cmathbf%7Bpa%7D_i,%20%5Cmathbf%7Bu%7D_i)"></p>
<p><strong>Step 2: Independence of Exogenous Variables</strong> Markovian 가정에 의해 <img src="https://latex.codecogs.com/png.latex?U">들이 서로 독립이므로, <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bu%7D)%20=%20%5Cprod%20P(%5Cmathbf%7Bu%7D_i)">가 성립합니다. 이를 대입합니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7B%5Cmathbf%7Bu%7D%7D%20%5Cleft(%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(%5Cmathbf%7Bu%7D_i)%20%5Cright)%20%5Cleft(%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%5Cmid%20%5Cmathbf%7Bpa%7D_i,%20%5Cmathbf%7Bu%7D_i)%20%5Cright)"></p>
<p><strong>Step 3: Independence of <img src="https://latex.codecogs.com/png.latex?U_i"> and <img src="https://latex.codecogs.com/png.latex?Pa_i"></strong> 외생 변수 <img src="https://latex.codecogs.com/png.latex?U_i">는 시스템 외부에서 결정되므로, 내생 변수인 부모 <img src="https://latex.codecogs.com/png.latex?Pa_i">와는 독립입니다. 따라서 <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bu%7D_i)%20=%20P(%5Cmathbf%7Bu%7D_i%20%5Cmid%20%5Cmathbf%7Bpa%7D_i)">로 쓸 수 있습니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7B%5Cmathbf%7Bu%7D%7D%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%5Cmid%20%5Cmathbf%7Bpa%7D_i,%20%5Cmathbf%7Bu%7D_i)%20P(%5Cmathbf%7Bu%7D_i%20%5Cmid%20%5Cmathbf%7Bpa%7D_i)"></p>
<p><strong>Step 4: Merging Conditional Probabilities</strong> 곱셈 법칙 <img src="https://latex.codecogs.com/png.latex?P(A%7CB)P(B)%20=%20P(A,B)">를 적용하여 항을 합칩니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7B%5Cmathbf%7Bu%7D%7D%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i,%20%5Cmathbf%7Bu%7D_i%20%5Cmid%20%5Cmathbf%7Bpa%7D_i)"></p>
<p><strong>Step 5: Rearranging Sum and Product</strong> 전체 외생 변수 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D">에 대한 합(<img src="https://latex.codecogs.com/png.latex?%5Csum_%7B%5Cmathbf%7Bu%7D%7D">)을 개별 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D_i">에 대한 합으로 분리하여 곱셈 기호 안으로 넣습니다. 각 항은 해당되는 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D_i">에만 의존하기 때문에 가능합니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20%5Cleft(%20%5Csum_%7B%5Cmathbf%7Bu%7D_i%7D%20P(v_i,%20%5Cmathbf%7Bu%7D_i%20%5Cmid%20%5Cmathbf%7Bpa%7D_i)%20%5Cright)"></p>
<p><strong>Step 6: Marginalization</strong> 괄호 안의 식 <img src="https://latex.codecogs.com/png.latex?%5Csum_%7B%5Cmathbf%7Bu%7D_i%7D%20P(v_i,%20%5Cmathbf%7Bu%7D_i%20%5Cmid%20%5Cmathbf%7Bpa%7D_i)">는 결합 확률에서 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D_i">를 덜어내는(Marginalize) 과정이므로 <img src="https://latex.codecogs.com/png.latex?P(v_i%20%5Cmid%20%5Cmathbf%7Bpa%7D_i)">가 됩니다.</p>
<p><strong>Final Result:</strong> <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)%20=%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%5Cmid%20%5Cmathbf%7Bpa%7D_i)"></p>
<p>이 결과는 매우 강력합니다. 우리가 관측할 수 없는 <img src="https://latex.codecogs.com/png.latex?U">를 모르더라도, <strong>오직 관측 가능한 데이터 내에서 부모-자식 간의 조건부 확률만 알면 전체 분포를 알 수 있다</strong>는 것을 의미하기 때문입니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-01/images/markovian_factorization_derivation.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Markovian Factorization 유도 과정 요약. 독립성 가정과 확률의 연쇄 법칙을 통해 복잡한 결합 확률이 조건부 확률의 곱으로 분해됨을 보여준다.</figcaption>
</figure>
</div>
<hr>
</section>
</section>
<section id="conditional-independence-d-separation" class="level1">
<h1>5. Conditional Independence &amp; d-separation</h1>
<p>그래프 구조는 변수들 사이의 조건부 독립(Conditional Independence, CI) 정보를 담고 있습니다. 이를 파악하기 위해 3가지 기본 구조(Triplets)를 이해해야 합니다.</p>
<section id="the-three-basic-structures-triplets" class="level2">
<h2 class="anchored" data-anchor-id="the-three-basic-structures-triplets">5.1 The Three Basic Structures (Triplets)</h2>
<section id="chain-x-rightarrow-z-rightarrow-y" class="level3">
<h3 class="anchored" data-anchor-id="chain-x-rightarrow-z-rightarrow-y">1. Chain (<img src="https://latex.codecogs.com/png.latex?X%20%5Crightarrow%20Z%20%5Crightarrow%20Y">)</h3>
<ul>
<li><strong>구조</strong>: <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Z">에 영향을 주고, <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?Y">에 영향을 줍니다.</li>
<li><strong>독립성</strong>:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Z">를 모를 때: <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">는 종속입니다 (정보가 흐름).</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?Z">를 알 때 (Given <img src="https://latex.codecogs.com/png.latex?Z">)</strong>: <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 영향은 이미 <img src="https://latex.codecogs.com/png.latex?Z">에 의해 설명되었으므로, <strong><img src="https://latex.codecogs.com/png.latex?X%20%5Cperp%20Y%20%5Cmid%20Z"> (독립)</strong>입니다. <img src="https://latex.codecogs.com/png.latex?Z">가 정보를 차단(Block)합니다.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-01/images/causal_chain.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Causal Chain 구조와 독립성. 중간 매개변수 Z를 조건부로 알게 되면 X와 Y 사이의 정보 흐름이 차단되어 독립이 된다.</figcaption>
</figure>
</div>
</section>
<section id="fork-common-cause-x-leftarrow-z-rightarrow-y" class="level3">
<h3 class="anchored" data-anchor-id="fork-common-cause-x-leftarrow-z-rightarrow-y">2. Fork / Common Cause (<img src="https://latex.codecogs.com/png.latex?X%20%5Cleftarrow%20Z%20%5Crightarrow%20Y">)</h3>
<ul>
<li><strong>구조</strong>: <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">의 공통 원인입니다. (예: <img src="https://latex.codecogs.com/png.latex?Z">=날씨, <img src="https://latex.codecogs.com/png.latex?X">=교통체증, <img src="https://latex.codecogs.com/png.latex?Y">=우산사용)</li>
<li><strong>독립성</strong>:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Z">를 모를 때: <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">는 종속입니다 (상관관계 발생).</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?Z">를 알 때 (Given <img src="https://latex.codecogs.com/png.latex?Z">)</strong>: 공통 원인을 통제했으므로 <strong><img src="https://latex.codecogs.com/png.latex?X%20%5Cperp%20Y%20%5Cmid%20Z"> (독립)</strong>입니다.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-01/images/common_cause.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Common Cause 구조와 독립성. 공통 원인 Z를 통제하면 X와 Y 사이의 허위 상관관계(Spurious Correlation)가 사라져 독립이 된다.</figcaption>
</figure>
</div>
</section>
<section id="collider-common-effect-x-rightarrow-z-leftarrow-y" class="level3">
<h3 class="anchored" data-anchor-id="collider-common-effect-x-rightarrow-z-leftarrow-y">3. Collider / Common Effect (<img src="https://latex.codecogs.com/png.latex?X%20%5Crightarrow%20Z%20%5Cleftarrow%20Y">)</h3>
<ul>
<li><strong>구조</strong>: <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">가 동시에 <img src="https://latex.codecogs.com/png.latex?Z">에 영향을 줍니다. (예: <img src="https://latex.codecogs.com/png.latex?X">=감기, <img src="https://latex.codecogs.com/png.latex?Y">=휴일, <img src="https://latex.codecogs.com/png.latex?Z">=결석)</li>
<li><strong>독립성</strong>:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Z">를 모를 때: <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">는 <strong>독립</strong>입니다 (서로 관계없는 사건).</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?Z">를 알 때 (Given <img src="https://latex.codecogs.com/png.latex?Z">)</strong>: <strong><img src="https://latex.codecogs.com/png.latex?X%20%5Cnot%5Cperp%20Y%20%5Cmid%20Z"> (종속)</strong>이 됩니다.</li>
</ul></li>
<li><strong>Explaining Away</strong>: 결석(<img src="https://latex.codecogs.com/png.latex?Z=1">)했다는 사실을 알 때, 휴일이 아니라면(<img src="https://latex.codecogs.com/png.latex?Y=0">), 아플 확률(<img src="https://latex.codecogs.com/png.latex?X=1">)이 높아집니다. 즉, 결과를 알면 원인들 사이에 상관관계가 생깁니다. <strong>Collider는 관측될 때 경로를 엽니다(Open).</strong></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-01/images/collider_structure.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Common Effect (Collider) 구조와 Explaining Away 현상. 두 독립적인 원인이 공통 결과 Z를 조건부로 알게 되었을 때 종속적으로 변하는 현상을 설명한다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="d-separation" class="level2">
<h2 class="anchored" data-anchor-id="d-separation">5.2 d-separation</h2>
<p>이 세 가지 규칙을 일반화한 것이 <strong>d-separation</strong>입니다. 그래프 상의 두 노드 <img src="https://latex.codecogs.com/png.latex?X,%20Y"> 사이의 모든 경로가 관측된 변수 집합 <img src="https://latex.codecogs.com/png.latex?Z">에 의해 차단(Blocked)된다면, <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">는 <img src="https://latex.codecogs.com/png.latex?Z">에 대해 조건부 독립입니다.</p>
<ul>
<li>경로가 차단되는 경우:
<ol type="1">
<li>경로 상의 Chain이나 Fork 노드가 <img src="https://latex.codecogs.com/png.latex?Z">에 포함될 때.</li>
<li>경로 상의 <strong>Collider 노드와 그 자손들이 <img src="https://latex.codecogs.com/png.latex?Z">에 포함되지 않을 때</strong>.</li>
</ol></li>
</ul>
</section>
<section id="food-for-thought-quiz" class="level2">
<h2 class="anchored" data-anchor-id="food-for-thought-quiz">5.3 Food for Thought (Quiz)</h2>
<p>아래 그래프를 보고 독립성을 판별해 봅시다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-01/images/food_for_thought_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure: d-separation 연습을 위한 복합 그래프 예시. A, B, C, D 노드와 실선/점선 엣지가 섞여 있어 다양한 경로의 독립성을 테스트한다.</figcaption>
</figure>
</div>
<ol type="1">
<li><strong>Is <img src="https://latex.codecogs.com/png.latex?A%20%5Cperp%20D">? (No)</strong>
<ul>
<li>경로: <img src="https://latex.codecogs.com/png.latex?A%20%5Cleftrightarrow%20B%20%5Crightarrow%20D">.</li>
<li><img src="https://latex.codecogs.com/png.latex?B">는 Chain/Fork 역할을 하지만 관측되지 않았으므로 경로가 열려 있습니다.</li>
</ul></li>
<li><strong>Is <img src="https://latex.codecogs.com/png.latex?A%20%5Cperp%20C">? (Yes)</strong>
<ul>
<li>경로: <img src="https://latex.codecogs.com/png.latex?A%20%5Cleftrightarrow%20B%20%5Cleftarrow%20C">.</li>
<li><img src="https://latex.codecogs.com/png.latex?B">는 Collider입니다. 관측되지 않았으므로 경로는 <strong>차단</strong>되어 있습니다.</li>
</ul></li>
<li><strong>Is <img src="https://latex.codecogs.com/png.latex?A%20%5Cperp%20C%20%5Cmid%20D">? (No)</strong>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?D">는 Collider <img src="https://latex.codecogs.com/png.latex?B">의 자손(Descendant)입니다.</li>
<li><img src="https://latex.codecogs.com/png.latex?D">를 관측하면 <img src="https://latex.codecogs.com/png.latex?B">가 열리게 되어 경로가 연결됩니다.</li>
</ul></li>
<li><strong>Is <img src="https://latex.codecogs.com/png.latex?D%20%5Cperp%20C%20%5Cmid%20B">? (No)</strong>
<ul>
<li>경로 1: <img src="https://latex.codecogs.com/png.latex?C%20%5Crightarrow%20B%20%5Crightarrow%20D">. <img src="https://latex.codecogs.com/png.latex?B">를 알면 차단됩니다.</li>
<li>경로 2: <img src="https://latex.codecogs.com/png.latex?C%20%5Cleftrightarrow%20D"> (Backdoor path, <img src="https://latex.codecogs.com/png.latex?C%20%5Cleftarrow%20U%20%5Crightarrow%20D">). 이 경로는 <img src="https://latex.codecogs.com/png.latex?B">와 무관하게 열려 있습니다.</li>
<li>하나라도 열린 경로가 있으므로 종속입니다.</li>
</ul></li>
</ol>
<hr>
</section>
</section>
<section id="summary" class="level1">
<h1>6. Summary</h1>
<p>이번 포스트에서는 인과 추론의 기초가 되는 SCM과 인과 그래프에 대해 알아보았습니다.</p>
<ol type="1">
<li><strong>SCM</strong>: 현실의 메커니즘을 변수, 외생 변수, 함수적 관계로 정의하는 모델입니다.</li>
<li><strong>Markovian Factorization</strong>: 외생 변수의 독립성을 가정하면, 결합 확률 분포를 <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)%20=%20%5Cprod%20P(v_i%20%7C%20pa_i)">로 분해할 수 있습니다.</li>
<li><strong>d-separation</strong>: 그래프 구조(Chain, Fork, Collider)를 통해 변수 간의 조건부 독립성을 파악할 수 있으며, 특히 Collider가 관측될 때 경로가 열린다는 점(Explaining Away)이 중요합니다.</li>
</ol>
<p>다음 시간에는 이 구조 위에서 실제로 <strong>개입(Intervention)</strong>을 했을 때 어떤 일이 벌어지는지(Pearl’s Causal Hierarchy의 2단계)에 대해 다루겠습니다.</p>
<hr>
<section id="checklist-for-content-verification" class="level3">
<h3 class="anchored" data-anchor-id="checklist-for-content-verification"><strong>Checklist for Content Verification</strong></h3>
<ul class="task-list">
<li><label><input type="checkbox" checked=""><strong>Motivation</strong>: Simpson’s Paradox (Drug example) included? (Yes)</label></li>
<li><label><input type="checkbox" checked=""><strong>SCM Definition</strong>: 4-tuple and definition of components included? (Yes)</label></li>
<li><label><input type="checkbox" checked=""><strong>Induced Distribution</strong>: How SCM induces <img src="https://latex.codecogs.com/png.latex?P(v)"> described? (Yes)</label></li>
<li><label><input type="checkbox" checked=""><strong>Causal Diagrams</strong>: Construction rules (Nodes, Edges) included? (Yes)</label></li>
<li><label><input type="checkbox" checked=""><strong>Markovian Factorization</strong>: Detailed mathematical derivation included? (Yes)</label></li>
<li><label><input type="checkbox" checked=""><strong>Conditional Independence</strong>: 3 Basic structures (Chain, Fork, Collider) explained? (Yes)</label></li>
<li><label><input type="checkbox" checked=""><strong>d-separation</strong>: General rule and specific quiz (Food for thought) analysis included? (Yes)</label></li>
<li><label><input type="checkbox" checked=""><strong>Algebra Review</strong>: Sum of products logic implicitly handled in the derivation section? (Yes)</label></li>
</ul>
<p>```</p>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L02/part-01/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 03. Identification of Causal Effects</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L03/</link>
  <description><![CDATA[ 





<blockquote class="blockquote">
<p>[cite_start]<strong>Note</strong>: 본 포스트는 서울대학교 GSDS 이상학 교수님의 “Identification of Causal Effects” 강의 자료를 바탕으로 작성되었습니다. [cite: 1, 2]</p>
</blockquote>
<section id="introduction-the-challenge-of-causal-inference" class="level1">
<h1>1. Introduction: The Challenge of Causal Inference</h1>
<p>인과 추론(Causal Inference)의 핵심 목표는 정적인 데이터(Static conditions)로부터 <strong>변화(Change)</strong>를 예측하는 것입니다.</p>
<p>[cite_start]우리가 흔히 접하는 관측 데이터(Observational Data)는 특정 체제(Regime) 하에서의 인구 집단 분포를 설명할 뿐, 시스템에 변화가 가해졌을 때 인구 집단이 어떻게 반응할지는 말해주지 않습니다[cite: 27, 28].</p>
<p>[cite_start]예를 들어, “흡연을 금지시킨다면 암 환자가 줄어들까?”라는 질문은 <img src="https://latex.codecogs.com/png.latex?P(Cancer%7CSmoking)">이라는 관측된 조건부 확률(Association)이 아니라, <img src="https://latex.codecogs.com/png.latex?P(Cancer%7Cdo(Smoking=no))">라는 개입(Intervention) 후의 확률을 묻는 것입니다[cite: 24, 25].</p>
<p>이 포스트에서는 <strong>구조적 인과 모형(Structural Causal Model, SCM)</strong>을 사용하여 관측 데이터(<img src="https://latex.codecogs.com/png.latex?P">)와 인과 그래프(<img src="https://latex.codecogs.com/png.latex?G">)가 주어졌을 때, 인과 효과(<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">)를 식별(Identify)해내는 과정을 수학적으로 다룹니다.</p>
<hr>
</section>
<section id="structural-causal-model-intervention" class="level1">
<h1>2. Structural Causal Model &amp; Intervention</h1>
<section id="real-world-vs.-hypothetical-world" class="level2">
<h2 class="anchored" data-anchor-id="real-world-vs.-hypothetical-world">2.1. Real World vs.&nbsp;Hypothetical World</h2>
<p>인과 효과를 정의하기 위해 우리는 두 개의 세계를 비교해야 합니다.</p>
<ol type="1">
<li><strong>Real World (Observational World):</strong> 변수들이 자연스러운 인과 구조에 따라 값을 갖는 세계. 결합 확률 분포 <img src="https://latex.codecogs.com/png.latex?P(z,%20x,%20w,%20y)">로 표현됩니다.</li>
<li><strong>Hyphetical World (Interventional World):</strong> 우리가 변수 <img src="https://latex.codecogs.com/png.latex?X">를 강제로 특정 값 <img src="https://latex.codecogs.com/png.latex?x">로 고정(<img src="https://latex.codecogs.com/png.latex?do(X=x)">)했을 때의 세계. [cite_start]분포 <img src="https://latex.codecogs.com/png.latex?P(z,%20w,%20y%20%7C%20do(x))">로 표현됩니다 [cite: 33-44].</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L03/images/real_vs_hypothetical_world.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Real world vs.&nbsp;Hypothetical world. 왼쪽(Real world)에서는 Z가 X에 영향을 주지만, 오른쪽(Hyphetical world)에서는 X에 대한 개입(do(X))으로 인해 Z에서 X로 가는 화살표가 끊어진(Mutilated) 것을 볼 수 있다.</figcaption>
</figure>
</div>
<p>위 그림에서 볼 수 있듯이, 개입 <img src="https://latex.codecogs.com/png.latex?do(X=x)">는 모델 내에서 <img src="https://latex.codecogs.com/png.latex?X">를 결정하는 모든 방정식(화살표)을 삭제하고, <img src="https://latex.codecogs.com/png.latex?X=x">라는 상수로 대체하는 연산입니다. [cite_start]이를 통해 <img src="https://latex.codecogs.com/png.latex?Z">(교란 변수)가 <img src="https://latex.codecogs.com/png.latex?X">에 미치는 영향을 차단합니다 [cite: 52-71].</p>
</section>
<section id="causal-effect의-정의" class="level2">
<h2 class="anchored" data-anchor-id="causal-effect의-정의">2.2. Causal Effect의 정의</h2>
<p>수학적으로, <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 <strong>인과 효과(Causal Effect)</strong> <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">는 다음과 같이 정의됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))%20=%20P_x(y)"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?P_x(y)">는 서브모델(Submodel) <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BM%7D_x">에서 <img src="https://latex.codecogs.com/png.latex?Y=y">일 확률을 의미합니다. [cite_start]<img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BM%7D_x">는 원래 모델 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BM%7D">에서 <img src="https://latex.codecogs.com/png.latex?X">에 관련된 모든 방정식을 삭제하고 <img src="https://latex.codecogs.com/png.latex?X=x">를 대입하여 얻은 모델입니다 [cite: 96-98].</p>
<hr>
</section>
</section>
<section id="computing-causal-effects-the-sprinkler-example" class="level1">
<h1>3. Computing Causal Effects: The Sprinkler Example</h1>
<p>[cite_start]이론적인 정의를 넘어, 실제 관측 데이터로 이를 어떻게 계산하는지 “스프링클러 예제”를 통해 살펴보겠습니다[cite: 125].</p>
<section id="시나리오-및-그래프" class="level2">
<h2 class="anchored" data-anchor-id="시나리오-및-그래프">3.1. 시나리오 및 그래프</h2>
<p>다음과 같은 변수와 인과 관계가 있다고 가정합니다. * <strong>Season (<img src="https://latex.codecogs.com/png.latex?Sn">):</strong> 계절 (모든 변수의 근원) * <strong>Sprinkler (<img src="https://latex.codecogs.com/png.latex?Sp">):</strong> 스프링클러 가동 여부 (계절에 영향 받음) * <strong>Rain (<img src="https://latex.codecogs.com/png.latex?Rn">):</strong> 비 옴 여부 (계절에 영향 받음) * <strong>Wet (<img src="https://latex.codecogs.com/png.latex?Wt">):</strong> 땅이 젖음 (스프링클러와 비에 영향 받음) * <strong>Slippery (<img src="https://latex.codecogs.com/png.latex?Sl">):</strong> 미끄러움 (땅이 젖음에 영향 받음)</p>
<p>전체 결합 확률 분포(Markovian factorization)는 다음과 같습니다: <img src="https://latex.codecogs.com/png.latex?P(v)%20=%20P(Sn)P(Sp%7CSn)P(Rn%7CSn)P(Wt%7CSp,%20Rn)P(Sl%7CWt)"> [cite_start][cite: 127]</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L03/images/sprinkler_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Sprinkler Example Causal Graph. Season이 Sprinkler와 Rain의 공통 원인(Confounder)으로 작용하고 있으며, Sprinkler와 Rain은 Wet의 원인이 된다.</figcaption>
</figure>
</div>
</section>
<section id="query-1-observation-pwtspon" class="level2">
<h2 class="anchored" data-anchor-id="query-1-observation-pwtspon">3.2. Query 1: Observation (<img src="https://latex.codecogs.com/png.latex?P(Wt%7CSp=on)">)</h2>
<p>우리가 단순히 “스프링클러가 켜진 것을 목격했을 때(<img src="https://latex.codecogs.com/png.latex?Sp=on">)”, 땅이 젖어 있을 확률은 조건부 확률의 정의에 따라 다음과 같습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AQ_1%20=%20P(Wt%20%7C%20Sp=%5Ctext%7Bon%7D)%20=%20%5Cfrac%7B%5Csum_%7Bsn,%20rn%7D%20P(sn)%20%5Cmathbf%7BP(Sp=%5Ctext%7Bon%7D%7Csn)%7D%20P(rn%7Csn)%20P(wt%7CSp=%5Ctext%7Bon%7D,%20rn)%7D%7B%5Csum_%7Bsn%7D%20%5Cmathbf%7BP(Sp=%5Ctext%7Bon%7D%7Csn)%7D%20P(sn)%7D%0A"> [cite_start][cite: 148]</p>
<ul>
<li><strong>해석:</strong> 여기서 <img src="https://latex.codecogs.com/png.latex?P(Sp=%5Ctext%7Bon%7D%7Csn)"> 항이 살아있습니다. 즉, 계절에 따라 스프링클러를 켜는 경향성(Selection Bias)이 결과에 반영됩니다.</li>
</ul>
</section>
<section id="query-2-intervention-pwtdospon" class="level2">
<h2 class="anchored" data-anchor-id="query-2-intervention-pwtdospon">3.3. Query 2: Intervention (<img src="https://latex.codecogs.com/png.latex?P(Wt%7Cdo(Sp=on))">)</h2>
<p>이제 우리가 “스프링클러를 강제로 켰을 때(<img src="https://latex.codecogs.com/png.latex?do(Sp=on)">)”, 땅이 젖어 있을 확률을 구해보겠습니다. 개입이 일어나면 <img src="https://latex.codecogs.com/png.latex?Sn%20%5Crightarrow%20Sp">의 화살표가 끊어지므로, <img src="https://latex.codecogs.com/png.latex?Sp">는 더 이상 <img src="https://latex.codecogs.com/png.latex?Sn">의 함수가 아닙니다. 따라서 분해 식에서 <strong><img src="https://latex.codecogs.com/png.latex?P(Sp%7CSn)"> 항이 제거(Truncated)</strong> 됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AQ_2%20=%20P(Wt%20%7C%20do(Sp=%5Ctext%7Bon%7D))%20=%20%5Csum_%7Bsn,%20rn%7D%20P(sn)%20P(rn%7Csn)%20P(wt%7CSp=%5Ctext%7Bon%7D,%20rn)%0A"> [cite_start][cite: 165]</p>
<ul>
<li><strong>중요한 차이:</strong> 관측 식(<img src="https://latex.codecogs.com/png.latex?Q_1">)과 달리, <img src="https://latex.codecogs.com/png.latex?Q_2">에서는 <img src="https://latex.codecogs.com/png.latex?P(Sp%7CSn)"> 항이 사라졌습니다. 대신 자연적인 계절의 분포 <img src="https://latex.codecogs.com/png.latex?P(Sn)">과 비의 분포 <img src="https://latex.codecogs.com/png.latex?P(Rn%7CSn)">에 따라 가중 평균을 구하게 됩니다.</li>
<li>[cite_start]이것은 관측 분포와 개입 분포 사이의 변환을 <strong>재가중(Re-weighting) 과정</strong>으로 해석할 수 있음을 보여줍니다[cite: 211].</li>
</ul>
<hr>
</section>
</section>
<section id="truncated-factorization-formula" class="level1">
<h1>4. Truncated Factorization Formula</h1>
<p>위 예제에서 본 원리를 일반화하면 <strong>Truncated Factorization Formula (절단된 분해 공식)</strong>를 얻을 수 있습니다. 이것은 마르코프 모형(Markovian Model)에서 인과 효과를 계산하는 가장 기본적인 정리입니다.</p>
<section id="theorem-manipulation-theorem" class="level2">
<h2 class="anchored" data-anchor-id="theorem-manipulation-theorem">4.1. Theorem (Manipulation Theorem)</h2>
<p>마르코프 모형 <img src="https://latex.codecogs.com/png.latex?M">에서 개입 <img src="https://latex.codecogs.com/png.latex?do(X=x)">에 의해 생성된 확률 분포는 다음과 같이 주어집니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?P(v%20%5Csetminus%20x%20%7C%20do(x))%20=%20%5Cprod_%7BV_i%20%5Cin%20V%20%5Csetminus%20X%7D%20P(v_i%20%7C%20pa_i)"> [cite_start][cite: 173]</p>
<p>즉, 전체 결합 확률 <img src="https://latex.codecogs.com/png.latex?P(v)%20=%20%5Cprod%20P(v_i%7Cpa_i)">에서 개입된 변수 <img src="https://latex.codecogs.com/png.latex?X">에 해당하는 항 <img src="https://latex.codecogs.com/png.latex?P(x%7Cpa_x)">만 제거한 형태입니다.</p>
</section>
<section id="re-weighting-관점" class="level2">
<h2 class="anchored" data-anchor-id="re-weighting-관점">4.2. Re-weighting 관점</h2>
<p>이 식은 관측 데이터의 분포 <img src="https://latex.codecogs.com/png.latex?P(v)">를 이용해 다음과 같이 다시 쓸 수 있습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(v%20%5Csetminus%20x%20%7C%20do(x))%20=%20%5Cfrac%7BP(v)%7D%7B%5Cprod_%7BX%20%5Cin%20X%7D%20P(x%7Cpa_X)%7D%0A"></p>
<p>만약 <img src="https://latex.codecogs.com/png.latex?X">가 단일 변수라면(Singleton), 이는 다음과 같이 표현됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(v%20%5Csetminus%20x%20%7C%20do(x))%20=%20%5Cfrac%7BP(v)%7D%7BP(x%7Cpa_X)%7D%20=%20P(v''%20%7C%20x,%20pa_X)P(pa_X)%0A"> (여기서 <img src="https://latex.codecogs.com/png.latex?V''%20=%20V%20%5Csetminus%20Pa_X%20%5Csetminus%20%5C%7BX%5C%7D">) [cite_start][cite: 200, 209].</p>
<p>이 공식은 인과 추론 문제를 “어떻게 <img src="https://latex.codecogs.com/png.latex?P(x%7Cpa_x)">(Propensity Score)로 관측 데이터를 역가중(Inverse weighting)할 것인가”의 문제로 연결해 줍니다.</p>
<hr>
</section>
</section>
<section id="the-identification-problem" class="level1">
<h1>5. The Identification Problem</h1>
<p>이제 근본적인 질문을 던져봅시다. <strong>“우리는 언제 인과 효과를 구할 수 있는가?”</strong></p>
<section id="식별-가능성-identifiability-정의" class="level2">
<h2 class="anchored" data-anchor-id="식별-가능성-identifiability-정의">5.1. 식별 가능성 (Identifiability) 정의</h2>
<p>[cite_start]인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">가 인과 그래프 <img src="https://latex.codecogs.com/png.latex?G">로부터 <strong>식별 가능하다(Identifiable)</strong>는 것은, 관측 가능한 변수들의 확률 분포 <img src="https://latex.codecogs.com/png.latex?P(v)"> (<img src="https://latex.codecogs.com/png.latex?P(v)%3E0">)만으로 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 유일하게(Uniquely) 계산해낼 수 있다는 뜻입니다[cite: 219].</p>
<p><img src="https://latex.codecogs.com/png.latex?P%5E%7BM_1%7D(v)%20=%20P%5E%7BM_2%7D(v)%20%5Cimplies%20P%5E%7BM_1%7D(y%7Cdo(x))%20=%20P%5E%7BM_2%7D(y%7Cdo(x))"></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L03/images/identifiability_venn.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Identifiability Venn Diagram. 관측 분포 P(v)와 그래프 G를 공유하는 모든 모델(M1, M2)이 동일한 인과 효과 P(y|do(x))를 내놓는다면, 그 효과는 식별 가능하다. 만약 그렇지 않다면(빨간 교집합 영역), 식별 불가능하다.</figcaption>
</figure>
</div>
<p>[cite_start]즉, 데이터(<img src="https://latex.codecogs.com/png.latex?P(v)">)와 가정(<img src="https://latex.codecogs.com/png.latex?G">)이 같다면, 내부 파라미터가 달라도 결론(<img src="https://latex.codecogs.com/png.latex?Q">)은 같아야 한다는 것입니다 [cite: 302-304].</p>
<hr>
</section>
</section>
<section id="identification-in-markovian-models" class="level1">
<h1>6. Identification in Markovian Models</h1>
<p>모든 관련 변수가 관측된(Hidden variable이 없는) 마르코프 모형에서는 인과 효과가 <strong>항상 식별 가능</strong>합니다.</p>
<section id="general-theorem" class="level2">
<h2 class="anchored" data-anchor-id="general-theorem">6.1. General Theorem</h2>
<p>[cite_start]모든 변수 <img src="https://latex.codecogs.com/png.latex?V">가 측정된 마르코프 모형의 인과 그래프 <img src="https://latex.codecogs.com/png.latex?G">가 주어졌을 때, 임의의 집합 <img src="https://latex.codecogs.com/png.latex?X,%20Y">에 대한 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">는 식별 가능하며, 다음 두 단계로 계산됩니다 [cite: 361-364].</p>
<ol type="1">
<li><strong>Truncated Factorization:</strong> 전체 시스템의 개입 후 분포를 구합니다. <img src="https://latex.codecogs.com/png.latex?P(v'%20%7C%20do(x))%20=%20%5Cprod_%7BV_i%20%5Cin%20V%20%5Csetminus%20X%7D%20P(v_i%20%7C%20pa_i)"></li>
<li><strong>Marginalization (Hence step):</strong> 관심 있는 결과 변수 <img src="https://latex.codecogs.com/png.latex?Y">를 제외한 나머지 변수(<img src="https://latex.codecogs.com/png.latex?V'%20%5Csetminus%20Y">)를 합(Summation)하여 제거합니다. <img src="https://latex.codecogs.com/png.latex?P(y%20%7C%20do(x))%20=%20%5Csum_%7BV'%20%5Csetminus%20Y%7D%20%5Cprod_%7BV_i%20%5Cin%20V%20%5Csetminus%20X%7D%20P(v_i%20%7C%20pa_i)"></li>
</ol>
<hr>
</section>
</section>
<section id="adjustment-formulas-backdoor-adjustment" class="level1">
<h1>7. Adjustment Formulas (Backdoor Adjustment)</h1>
<p>위의 일반 정리를 실전에서 자주 쓰이는 형태로 정리한 것이 <strong>조정 공식(Adjustment Formula)</strong>입니다.</p>
<section id="adjustment-by-direct-parents-singleton" class="level2">
<h2 class="anchored" data-anchor-id="adjustment-by-direct-parents-singleton">7.1. Adjustment by Direct Parents (Singleton)</h2>
<p>[cite_start]단일 변수 <img src="https://latex.codecogs.com/png.latex?X">에 대해, 그 부모 변수들 <img src="https://latex.codecogs.com/png.latex?Pa_X">가 모두 관측되었다면, 인과 효과는 다음과 같이 부모 변수를 조정(Conditioning)하여 계산할 수 있습니다 [cite: 368-369].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bpa_X%7D%20P(y%7Cx,%20pa_X)P(pa_X)%0A"></p>
<p>이 공식은 “원인의 직접적인 원인(Parents)”을 통제하면 교란 요인을 차단할 수 있다는 직관을 수식화한 것입니다.</p>
</section>
<section id="adjustment-by-direct-parents-set-of-treatments---advanced" class="level2">
<h2 class="anchored" data-anchor-id="adjustment-by-direct-parents-set-of-treatments---advanced">7.2. Adjustment by Direct Parents (Set of Treatments) - Advanced</h2>
<p>만약 <img src="https://latex.codecogs.com/png.latex?X">가 단일 변수가 아니라 변수들의 집합 <img src="https://latex.codecogs.com/png.latex?X%20=%20%5C%7BX_1,%20...,%20X_k%5C%7D">라면 어떻게 될까요? [cite_start]변수들이 위상학적 순서(Topological order)로 정렬되어 있다고 가정할 때, 다음 조건이 만족되면 일반화된 조정 공식을 사용할 수 있습니다 [cite: 374-379].</p>
<p><strong>Theorem:</strong> 만약 모든 <img src="https://latex.codecogs.com/png.latex?i%20%3C%20j">에 대해, <img src="https://latex.codecogs.com/png.latex?Pa_%7BX_j%7D%20%5Csetminus%20(X_%7B%3Cj%7D%20%5Ccup%20Pa_%7BX_%7B%3Cj%7D%7D%5E-)">가 <img src="https://latex.codecogs.com/png.latex?X_i">의 자손(Descendant)이 아니라면:</p>
<p><img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))%20=%20%5Csum_%7Bpa_X%5E-%7D%20P(y%7Cx,%20pa_X%5E-)P(pa_X%5E-)"> (여기서 <img src="https://latex.codecogs.com/png.latex?Pa_X%5E-%20=%20Pa_X%20%5Csetminus%20X">)</p>
<p>[cite_start]<strong>Proof Sketch (by Induction):</strong> [cite: 382-401]</p>
<p>이 증명은 <img src="https://latex.codecogs.com/png.latex?P(x_%7B%5Cle%20i%7D%20%7C%20pa_%7BX_%7B%5Cle%20i%7D%7D%5E-)">가 <img src="https://latex.codecogs.com/png.latex?%5Cprod_%7BX%20%5Cin%20X_%7B%5Cle%20i%7D%7D%20P(x%7Cpa_X)">와 같음을 보이는 귀납법을 사용합니다. 1. <strong>Base case:</strong> <img src="https://latex.codecogs.com/png.latex?i=1">일 때 성립함은 자명합니다. 2. <strong>Hypothesis:</strong> <img src="https://latex.codecogs.com/png.latex?i-1">까지 성립한다고 가정하고, <img src="https://latex.codecogs.com/png.latex?i">번째 단계에서 조건부 독립(d-separation)과 연쇄 법칙(Chain rule)을 사용하여 식을 전개합니다. 3. 핵심은 <img src="https://latex.codecogs.com/png.latex?P(pa_%7BX_i%7D'%20%7C%20x_%7B%3Ci%7D,%20pa_%7BX_%7B%3Ci%7D%7D%5E-)"> 항이 <img src="https://latex.codecogs.com/png.latex?P(pa_%7BX_i%7D'%20%7C%20pa_%7BX_%7B%3Ci%7D%7D%5E-)">로 단순화되는 과정에 있으며, 이는 가정된 그래프 구조(자손이 아님) 덕분에 성립합니다.</p>
<p>[cite_start]이 정리는 복잡한 다중 처치(Multiple Treatments) 상황에서도 부모 변수들을 적절히 조정하면 인과 효과를 식별할 수 있음을 보장합니다[cite: 414].</p>
<hr>
</section>
</section>
<section id="handling-latent-variables-latent-season-example" class="level1">
<h1>8. Handling Latent Variables: Latent Season Example</h1>
<p>마지막으로, 만약 중요한 교란 변수가 관측되지 않았다면(Latent) 어떻게 될까요? [cite_start]앞선 스프링클러 예제에서 <strong>Season이 관측 불가능한 잠재 변수</strong>라고 가정해 봅시다[cite: 419].</p>
<p>우리는 <img src="https://latex.codecogs.com/png.latex?Q_2%20=%20P(Wt%20%7C%20do(Sp=on))">을 계산하고 싶습니다. 원래 식은 다음과 같았습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?Q_2%20=%20%5Csum_%7Bsn,%20rn%7D%20P(sn)P(rn%7Csn)P(wt%7CSp=on,%20rn)"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?P(sn)">과 <img src="https://latex.codecogs.com/png.latex?P(rn%7Csn)">은 관측 불가능한 <img src="https://latex.codecogs.com/png.latex?sn">을 포함하고 있어 계산이 불가능해 보입니다. 하지만 수식을 정리해보면 놀라운 결과를 얻습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0AQ_2%20&amp;=%20%5Csum_%7Brn%7D%20P(wt%7CSp=on,%20rn)%20%5Csum_%7Bsn%7D%20P(sn)P(rn%7Csn)%20%5C%5C%0A&amp;=%20%5Csum_%7Brn%7D%20P(wt%7CSp=on,%20rn)%20%5Csum_%7Bsn%7D%20P(rn,%20sn)%20%5C%5C%0A&amp;=%20%5Csum_%7Brn%7D%20P(wt%7CSp=on,%20rn)%20P(rn)%0A%5Cend%7Baligned%7D%0A"> [cite_start][cite: 462-465]</p>
<p><strong>결론:</strong> 최종 식 <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Brn%7D%20P(wt%7CSp=on,%20rn)%20P(rn)">에는 관측 불가능한 <img src="https://latex.codecogs.com/png.latex?Season">이 사라졌습니다! 이는 <img src="https://latex.codecogs.com/png.latex?Season">을 몰라도, <img src="https://latex.codecogs.com/png.latex?Rain">과 <img src="https://latex.codecogs.com/png.latex?Sprinkler">만 관측하면 인과 효과를 계산할 수 있음을 의미합니다.</p>
<p>이 예시는 모든 교란 변수를 통제할 수 없는 상황에서도, 그래프 구조와 확률 법칙을 잘 활용하면 인과 효과가 <strong>식별 가능(Identifiable)</strong>할 수 있음을 시사합니다.</p>
<hr>
</section>
<section id="summary" class="level1">
<h1>Summary</h1>
<ol type="1">
<li><strong>인과 효과의 식별:</strong> 관측 데이터(<img src="https://latex.codecogs.com/png.latex?P(v)">)와 인과 그래프(<img src="https://latex.codecogs.com/png.latex?G">)를 통해 개입 효과(<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">)를 유일하게 결정하는 과정입니다.</li>
<li><strong>Truncated Factorization:</strong> <img src="https://latex.codecogs.com/png.latex?P(v%20%5Csetminus%20x%20%7C%20do(x))%20=%20%5Cprod_%7BV_i%20%5Cin%20V%20%5Csetminus%20X%7D%20P(v_i%20%7C%20pa_i)">. 모든 마르코프 모형의 기초가 되는 공식입니다.</li>
<li><strong>Adjustment Formula:</strong> <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))%20=%20%5Csum_%7Bpa_X%7D%20P(y%7Cx,%20pa_X)P(pa_X)">. 원인의 부모 변수를 조정하여 인과 효과를 계산하는 실용적인 공식입니다.</li>
<li><strong>잠재 변수:</strong> 변수가 숨겨져 있어도(Latent), 구조에 따라 인과 효과가 식별 가능할 수 있습니다.</li>
</ol>
<hr>
<section id="check-list-coverage-verification" class="level3">
<h3 class="anchored" data-anchor-id="check-list-coverage-verification">Check List: Coverage &amp; Verification</h3>
<ul>
<li><strong>SCM &amp; Intervention Definition:</strong> <img src="https://latex.codecogs.com/png.latex?%5Ccheckmark"> (Sec 2)</li>
<li><strong>The Challenge (Static vs Change):</strong> <img src="https://latex.codecogs.com/png.latex?%5Ccheckmark"> (Sec 1)</li>
<li><strong>Sprinkler Example (Obs vs Intervention):</strong> <img src="https://latex.codecogs.com/png.latex?%5Ccheckmark"> (Sec 3)</li>
<li><strong>Truncated Factorization Theory:</strong> <img src="https://latex.codecogs.com/png.latex?%5Ccheckmark"> (Sec 4)</li>
<li><strong>Identifiability Definition (Venn Diagram):</strong> <img src="https://latex.codecogs.com/png.latex?%5Ccheckmark"> (Sec 5)</li>
<li><strong>Identification in Markovian Models (Theorem):</strong> <img src="https://latex.codecogs.com/png.latex?%5Ccheckmark"> (Sec 6)</li>
<li><strong>Adjustment Formula (Singleton):</strong> <img src="https://latex.codecogs.com/png.latex?%5Ccheckmark"> (Sec 7.1)</li>
<li><strong>Adjustment Formula (Set of Treatments - Proof included):</strong> <img src="https://latex.codecogs.com/png.latex?%5Ccheckmark"> (Sec 7.2)</li>
<li><strong>Latent Variable Case (Derivation included):</strong> <img src="https://latex.codecogs.com/png.latex?%5Ccheckmark"> (Sec 8)</li>
</ul>
<p><strong>누락된 내용:</strong> 없음. 강의 자료의 모든 핵심 정리와 예제를 포함하였으며, 특히 Optional로 표시된 다중 처치(Set of Treatments) 증명 과정까지 상세히 기술하였습니다.</p>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L03/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 05. Adjustment Criterion (Part 1)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L05/part-01/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>인과 추론(Causal Inference)의 핵심 목표 중 하나는 관찰된 데이터 분포 <img src="https://latex.codecogs.com/png.latex?P(V)">로부터 개입 분포(Interventional Distribution) <img src="https://latex.codecogs.com/png.latex?P(Y%7Cdo(X))">를 식별(Identification)하는 것입니다. 이를 위한 가장 강력하고 널리 알려진 도구는 <strong>Back-door Criterion</strong>입니다.</p>
<p>하지만 Back-door Criterion은 충분조건(sufficient condition)일 뿐 필요조건(necessary condition)은 아닙니다. 즉, Back-door Criterion을 만족하지 못하더라도 <img src="https://latex.codecogs.com/png.latex?P(Y%7Cdo(X))">를 식별할 수 있는 경우가 존재합니다. [cite_start]이번 포스트에서는 Back-door Criterion을 복습하고, 왜 더 일반화된 <strong>Adjustment Criterion</strong>이 필요한지 그 동기(Motivation)와 한계(Tightness)를 구체적인 그래프 예시를 통해 살펴봅니다[cite: 5, 8, 13].</p>
<blockquote class="blockquote">
<p>[cite_start]<strong>Note:</strong> 본 포스트는 서울대학교 데이터사이언스 대학원 이상학 교수님의 “인과추론 및 실습” 강의 자료를 바탕으로 작성되었습니다[cite: 1, 2, 3].</p>
</blockquote>
<hr>
</section>
<section id="the-back-door-criterion-review" class="level1">
<h1>2. The Back-door Criterion (Review)</h1>
<p>[cite_start]Pearl(2000)이 제시한 Back-door Criterion은 공변량 집합 <img src="https://latex.codecogs.com/png.latex?Z">를 조정(adjustment)함으로써 인과 효과를 식별할 수 있는 조건을 제시합니다[cite: 38].</p>
<section id="definition" class="level2">
<h2 class="anchored" data-anchor-id="definition">2.1. Definition</h2>
<p>[cite_start]어떤 변수 집합 <img src="https://latex.codecogs.com/png.latex?Z">가 변수 쌍 <img src="https://latex.codecogs.com/png.latex?(X,%20Y)">에 대해 <strong>Back-door Criterion</strong>을 만족하려면 다음 두 가지 조건을 충족해야 합니다[cite: 18, 23, 32].</p>
<ol type="1">
<li>[cite_start]<strong>Condition (i) - No Descendants:</strong> <img src="https://latex.codecogs.com/png.latex?Z">의 어떤 노드도 <img src="https://latex.codecogs.com/png.latex?X">의 후손(descendant)이 아니어야 합니다[cite: 19, 24, 34].</li>
<li>[cite_start]<strong>Condition (ii) - Blocking Paths:</strong> <img src="https://latex.codecogs.com/png.latex?Z">는 <img src="https://latex.codecogs.com/png.latex?X">로 들어가는 화살표를 포함하는 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 모든 경로(path)를 차단(block)해야 합니다[cite: 26, 35].</li>
</ol>
</section>
<section id="identification-formula" class="level2">
<h2 class="anchored" data-anchor-id="identification-formula">2.2. Identification Formula</h2>
<p>[cite_start]만약 집합 <img src="https://latex.codecogs.com/png.latex?Z">가 위 조건을 만족한다면, <img src="https://latex.codecogs.com/png.latex?Y">에 대한 <img src="https://latex.codecogs.com/png.latex?X">의 인과 효과는 다음과 같이 식별 가능합니다[cite: 27, 36, 37].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(y%7Cx,z)P(z)%0A"></p>
<p>이 식은 우리가 <img src="https://latex.codecogs.com/png.latex?do">-calculus나 가상의 실험 없이, 관찰된 데이터의 조건부 확률 <img src="https://latex.codecogs.com/png.latex?P(y%7Cx,z)">와 주변 확률 <img src="https://latex.codecogs.com/png.latex?P(z)">만으로 인과 효과를 계산할 수 있음을 의미합니다.</p>
<hr>
</section>
</section>
<section id="why-no-descendants-simpsons-paradox" class="level1">
<h1>3. Why “No Descendants”? (Simpson’s Paradox)</h1>
<p>Back-door Criterion의 첫 번째 조건인 “조정 집합 <img src="https://latex.codecogs.com/png.latex?Z">에 <img src="https://latex.codecogs.com/png.latex?X">의 후손을 포함하지 말라”는 조건은 왜 필요할까요? [cite_start]이는 <strong>인과 경로(Causal Path)</strong>를 차단하지 않기 위해서입니다[cite: 100].</p>
<p>[cite_start]가장 유명한 예시인 심슨의 역설(Simpson’s Paradox)을 통해 이를 직관적으로 이해할 수 있습니다[cite: 40]. 아래 두 가지 그래프 구조를 비교해 봅시다.</p>
<section id="case-1-confounder-structure" class="level3">
<h3 class="anchored" data-anchor-id="case-1-confounder-structure">Case 1: Confounder Structure</h3>
<p>첫 번째 경우는 성별(<img src="https://latex.codecogs.com/png.latex?F">)이 약물 복용(<img src="https://latex.codecogs.com/png.latex?X">)과 회복(<img src="https://latex.codecogs.com/png.latex?Y">) 모두에 영향을 주는 <strong>교란 요인(Confounder)</strong>인 상황입니다.</p>
<p><img src="https://shsha0110.github.io/posts/lecture/L05/part-01/images/simpsons_paradox_confounder.png" class="img-fluid" alt="Figure 1: Confounder Structure. F(성별)는 X(약물)와 Y(회복)의 공통 원인이다. 점선 화살표는 교란 경로를 의미한다."> [cite_start]<em>(그림 설명: <img src="https://latex.codecogs.com/png.latex?F%20%5Cto%20X">, <img src="https://latex.codecogs.com/png.latex?F%20%5Cto%20Y">, <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Y"> 구조를 가짐. 여기서 <img src="https://latex.codecogs.com/png.latex?%5Cemptyset">은 Back-door를 만족하지 못하며, <img src="https://latex.codecogs.com/png.latex?%5C%7BF%5C%7D">를 조정해야 올바른 인과 효과를 추정할 수 있음[cite: 39, 53].)</em></p>
<p>이 경우 데이터를 합쳐서(Aggregated) 보면 안 되고, 성별(<img src="https://latex.codecogs.com/png.latex?F">)로 층화(stratify)하여 분석해야 합니다. 즉, <img src="https://latex.codecogs.com/png.latex?%5C%7BF%5C%7D">는 <strong>Admissible</strong> 합니다.</p>
</section>
<section id="case-2-mediator-structure" class="level3">
<h3 class="anchored" data-anchor-id="case-2-mediator-structure">Case 2: Mediator Structure</h3>
<p>두 번째 경우는 약물(<img src="https://latex.codecogs.com/png.latex?X">)이 혈압 등 중간 매개체(<img src="https://latex.codecogs.com/png.latex?F">)에 영향을 주고, 그것이 다시 회복(<img src="https://latex.codecogs.com/png.latex?Y">)에 영향을 주는 <strong>매개(Mediator)</strong> 상황입니다.</p>
<p><img src="https://shsha0110.github.io/posts/lecture/L05/part-01/images/simpsons_paradox_mediator.png" class="img-fluid" alt="Figure 2: Mediator Structure. X(약물)가 F(중간 요인)에 영향을 주고, F가 Y(회복)에 영향을 준다."> [cite_start]<em>(그림 설명: <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20F%20%5Cto%20Y"> 및 <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Y"> 구조. 여기서 <img src="https://latex.codecogs.com/png.latex?F">는 <img src="https://latex.codecogs.com/png.latex?X">의 후손(Descendant)이다. <img src="https://latex.codecogs.com/png.latex?F">를 조정해버리면 <img src="https://latex.codecogs.com/png.latex?X">에서 <img src="https://latex.codecogs.com/png.latex?Y">로 가는 인과 경로 중 하나를 차단하게 되어 전체 효과를 과소평가하게 된다[cite: 39].)</em></p>
<p>이 경우, <img src="https://latex.codecogs.com/png.latex?F">는 <img src="https://latex.codecogs.com/png.latex?X">의 후손이므로 Back-door Criterion의 조건 (i)을 위반합니다. 따라서 <img src="https://latex.codecogs.com/png.latex?%5C%7BF%5C%7D">는 <strong>Not Admissible</strong> 합니다. [cite_start]데이터를 합쳐서 보는 것(<img src="https://latex.codecogs.com/png.latex?%5Cemptyset"> is admissible)이 오히려 올바른 접근입니다[cite: 54, 55].</p>
</section>
<section id="data-example" class="level3">
<h3 class="anchored" data-anchor-id="data-example">Data Example</h3>
<p>[cite_start]강의 자료의 데이터 예시를 보면 구조적 차이의 중요성이 명확해집니다[cite: 41, 42].</p>
<ul>
<li><strong>Male (<img src="https://latex.codecogs.com/png.latex?F=0">)</strong>: Drug 60% vs No-Drug 70% (약물이 안 좋아 보임)</li>
<li><strong>Female (<img src="https://latex.codecogs.com/png.latex?F=1">)</strong>: Drug 20% vs No-Drug 30% (약물이 안 좋아 보임)</li>
<li><strong>Aggregated</strong>: Drug <img src="https://latex.codecogs.com/png.latex?%5Capprox"> 50% vs No-Drug <img src="https://latex.codecogs.com/png.latex?%5Capprox"> 40% (약물이 좋아 보임)</li>
</ul>
<p>구조가 Case 1(Confounder)이라면 층화된 결과(안 좋다)가 진실이고, Case 2(Mediator)라면 합쳐진 결과(좋다)가 진실입니다. 즉, <strong>데이터만으로는 인과 효과를 알 수 없으며, 인과 그래프(구조)에 따라 조정 대상이 달라집니다.</strong></p>
<hr>
</section>
</section>
<section id="conditional-back-door-criterion" class="level1">
<h1>4. Conditional Back-door Criterion</h1>
<p>Back-door Criterion은 특정 조건부 상황으로 확장될 수 있습니다. [cite_start]이를 <strong>Conditional Back-door Criterion</strong>이라 합니다[cite: 60].</p>
<p>우리가 특정 공변량 <img src="https://latex.codecogs.com/png.latex?W">가 주어진 상황에서의 <img src="https://latex.codecogs.com/png.latex?X">의 효과, 즉 <img src="https://latex.codecogs.com/png.latex?w">-specific effect인 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x),%20w)">를 알고 싶다고 가정해 봅시다. [cite_start]이때 측정 가능한 집합 <img src="https://latex.codecogs.com/png.latex?Z">가 있어 <img src="https://latex.codecogs.com/png.latex?W%20%5Ccup%20Z">가 Back-door Criterion을 만족한다면, 이 효과는 다음과 같이 식별됩니다[cite: 61, 63].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x),%20%5Cforall%20w)%20=%20%5Csum_%7Bz%7D%20P(y%7Cx,z,%20%5Cforall%20w)P(z%7C%5Cforall%20w)%20=%20P_x(y%7CW)%0A"></p>
<p>[cite_start]이 공식의 유도는 <img src="https://latex.codecogs.com/png.latex?do">-calculus에 대한 이해가 필요합니다[cite: 64].</p>
<hr>
</section>
<section id="tightness-of-the-back-door-criterion" class="level1">
<h1>5. Tightness of the Back-door Criterion</h1>
<p>이제 이번 포스트의 핵심 주제인 <strong>Back-door Criterion의 한계(Tightness)</strong>로 넘어갑니다. 질문의 핵심은 다음과 같습니다.</p>
<blockquote class="blockquote">
<p>“Back-door Criterion은 충분조건이다. 그렇다면 필요조건인가?” 즉, “Back-door를 만족하지 못하면 조정(Adjustment)으로 식별이 불가능한가?”</p>
</blockquote>
<p>정답은 <strong>“아니오”</strong> 입니다. [cite_start]Back-door Criterion은 충분하지만 필요조건은 아닙니다(Sufficient but not necessary)[cite: 95].</p>
<section id="counter-example-graph" class="level2">
<h2 class="anchored" data-anchor-id="counter-example-graph">5.1. Counter-Example Graph</h2>
<p>다음과 같은 인과 그래프를 고려해 봅시다. [cite_start]여기서 <img src="https://latex.codecogs.com/png.latex?X%20=%20%5C%7BX_1,%20X_2%5C%7D">이고 <img src="https://latex.codecogs.com/png.latex?Y">는 결과 변수입니다[cite: 76, 78].</p>
<p><img src="https://shsha0110.github.io/posts/lecture/L05/part-01/images/tightness_dag.png" class="img-fluid" alt="Figure 3: Counter-Example DAG for Back-door Criterion. X1 -> Z1 -> Z2 -> X2 -> Y 의 경로와 X1 -> Y 직접 경로가 존재하며, Z2와 Y 사이에 bidirected edge(confounder)가 존재한다."> [cite_start]<em>(그림 설명: <img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20Z_1%20%5Cto%20Z_2%20%5Cto%20X_2%20%5Cto%20Y">, <img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20Y">. 그리고 <img src="https://latex.codecogs.com/png.latex?Z_2%20%5Cleftrightarrow%20Y"> (점선) 관계가 존재함. <img src="https://latex.codecogs.com/png.latex?X%20=%20%5C%7BX_1,%20X_2%5C%7D">가 처리 변수 집합임[cite: 76, 79, 80, 81, 82, 83].)</em></p>
</section>
<section id="why-back-door-fails-here" class="level2">
<h2 class="anchored" data-anchor-id="why-back-door-fails-here">5.2. Why Back-door Fails here?</h2>
<p>이 그래프에서 가능한 모든 조정 변수 후보는 <img src="https://latex.codecogs.com/png.latex?%5C%7BZ_1,%20Z_2%5C%7D">입니다. [cite_start]그러나 <img src="https://latex.codecogs.com/png.latex?Z_1">과 <img src="https://latex.codecogs.com/png.latex?Z_2">는 모두 <img src="https://latex.codecogs.com/png.latex?X_1">의 후손(descendant)입니다[cite: 86].</p>
<ul>
<li>Back-door Criterion의 <strong>Condition (i)</strong>: “<img src="https://latex.codecogs.com/png.latex?Z">의 어떤 노드도 <img src="https://latex.codecogs.com/png.latex?X">의 후손이면 안 된다.”</li>
<li>[cite_start]이 그래프에서는 <img src="https://latex.codecogs.com/png.latex?X=%5C%7BX_1,%20X_2%5C%7D">이므로, <img src="https://latex.codecogs.com/png.latex?X_1">의 후손인 <img src="https://latex.codecogs.com/png.latex?Z_1,%20Z_2">를 조정 집합에 포함하는 순간 <strong>조건 (i)을 위반</strong>하게 됩니다[cite: 78].</li>
</ul>
<p>따라서, 이 그래프에서는 <strong>Back-door Admissible Set이 존재하지 않습니다.</strong></p>
</section>
<section id="but-adjustment-is-possible" class="level2">
<h2 class="anchored" data-anchor-id="but-adjustment-is-possible">5.3. But Adjustment IS Possible!</h2>
<p>[cite_start]놀랍게도, <img src="https://latex.codecogs.com/png.latex?do">-calculus나 다른 방법을 통해 유도해보면 이 그래프에서 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">는 여전히 표준 조정 공식(Standard Adjustment Formula) 형태로 식별 가능합니다[cite: 93, 94].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(y%7Cx,z)P(z)%0A"></p>
<p>이것이 시사하는 바는 명확합니다.</p>
<ol type="1">
<li>Back-door Criterion은 <strong>너무 보수적(strict)</strong>입니다.</li>
<li>[cite_start]<img src="https://latex.codecogs.com/png.latex?X">의 후손(descendant)이라 할지라도, 조정을 위해 사용될 수 있으며 심지어 <strong>필요한 경우</strong>도 있습니다[cite: 102].</li>
<li>[cite_start]특히, <strong><img src="https://latex.codecogs.com/png.latex?X">의 후손이면서 동시에 <img src="https://latex.codecogs.com/png.latex?X">의 조상(ancestor)인 변수</strong>(예: <img src="https://latex.codecogs.com/png.latex?X_1">의 후손이면서 <img src="https://latex.codecogs.com/png.latex?X_2">의 조상인 <img src="https://latex.codecogs.com/png.latex?Z_2">)들은 인과 경로를 방해하지 않으면서 교란을 제거하는 데 사용될 수 있습니다[cite: 103].</li>
</ol>
</section>
<section id="conclusion-motivation-for-adjustment-criterion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-motivation-for-adjustment-criterion">5.4. Conclusion: Motivation for Adjustment Criterion</h2>
<p>결국 우리는 Back-door Criterion보다 더 일반화된 기준이 필요합니다. [cite_start]“무조건 후손은 안 된다”가 아니라, <strong>“정말 피해야 할 변수는 무엇인가?”(What are the variables that we really need to avoid?)</strong>를 정의해야 합니다[cite: 104].</p>
<p>[cite_start]Condition (i)의 원래 목적은 <strong>인과 경로(Causal Path)를 보존(preserve)</strong>하는 것입니다[cite: 99, 100]. 따라서 후손이더라도 인과 경로를 막지 않는다면 조정 집합에 포함시킬 수 있어야 합니다. 이것이 바로 다음 포스트에서 다룰 <strong>Adjustment Criterion</strong>의 등장 배경입니다.</p>
<hr>
</section>
</section>
<section id="summary" class="level1">
<h1>6. Summary</h1>
<ul>
<li><strong>Back-door Criterion</strong>은 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 식별하는 강력한 도구이지만, <img src="https://latex.codecogs.com/png.latex?X">의 후손을 조정 집합에서 원천적으로 배제합니다.</li>
<li><strong>Simpson’s Paradox</strong> 예시는 후손(Mediator)을 통제하면 안 되는 이유를 잘 보여줍니다.</li>
<li>하지만 <strong>복잡한 그래프(Tightness example)</strong>에서는 <img src="https://latex.codecogs.com/png.latex?X">의 구성요소 사이에 있는 변수(<img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20Z%20%5Cto%20X_2">)들이 존재하며, 이들은 후손임에도 불구하고 조정이 필요하거나 가능할 수 있습니다.</li>
<li>Back-door Criterion은 충분조건이지만 필요조건이 아니며, 이를 보완하기 위해 더 일반적인 <strong>Adjustment Criterion</strong>이 필요합니다.</li>
</ul>
<p>다음 포스트에서는 어떤 후손이 허용되고 어떤 후손이 금지되는지 명확히 정의하는 <strong>Adjustment Criterion의 정의와 알고리즘</strong>에 대해 자세히 알아보겠습니다.</p>
<hr>
<section id="누락-방지-검증-missing-content-check" class="level3">
<h3 class="anchored" data-anchor-id="누락-방지-검증-missing-content-check">누락 방지 검증 (Missing Content Check)</h3>
<p>강의 자료(PDF 1-11p)를 기반으로 아래 항목들이 포함되었는지 확인합니다.</p>
<ul>
<li>[cite_start][x] <strong>Back-door Criterion의 정의 (조건 i, ii)</strong> [cite: 18, 19, 26]</li>
<li>[cite_start][x] <strong>Adjustment Formula 수식</strong> [cite: 37]</li>
<li>[cite_start][x] <strong>Simpson’s Paradox 예시 (표 및 그래프 구조 설명)</strong> [cite: 41, 42, 53, 55]</li>
<li>[cite_start][x] <strong>Conditional Back-door Criterion의 개념 및 수식</strong> [cite: 60, 63]</li>
<li>[cite_start][x] <strong>Tightness 예제 그래프 (<img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20Z%20%5Cto%20X_2"> 구조)</strong> [cite: 76, 78]</li>
<li>[cite_start][x] <strong>Back-door의 한계 설명 (후손이지만 조정 가능한 케이스 존재)</strong> [cite: 93, 94, 95]</li>
<li>[cite_start][x] <strong>Condition (i)의 원래 목적 (Causal path 보존)</strong> [cite: 99, 100]</li>
</ul>
<p><strong>Note on omitted content:</strong> PDF의 12페이지 이후(Algorithm, Theoretical Tool 등)는 제공된 파일 범위에 포함되지 않아 본 포스트에서는 다루지 않고 “다음 포스트”로 넘겼습니다. 제공된 1~11페이지 내의 내용은 모두 포함되었습니다.</p>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L05/part-01/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 05. Adjustment Criterion (Part 2)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L05/part-02/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>이전 포스트(Part 1)에서 우리는 <strong>Back-door Criterion</strong>이 인과 효과 식별을 위한 <strong>충분조건(Sufficient condition)</strong>이지만, <strong>필요조건(Necessary condition)</strong>은 아님을 확인했습니다. 즉, Back-door Criterion을 만족하지 못하더라도 변수들의 구조적 위치에 따라 여전히 조정(Adjustment)을 통해 인과 효과를 구할 수 있는 경우가 존재합니다.</p>
<p>이번 포스트에서는 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 표준 조정 공식(Standard Adjustment Formula)으로 식별하기 위한 <strong>필요충분조건(Necessary and Sufficient Condition)</strong>인 <strong>Adjustment Criterion</strong>에 대해 다룹니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AZ%20%5Ctext%7B%20satisfies%20Adjustment%20Criterion%7D%20%5Ciff%20P(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(y%7Cx,z)P(z)%0A"></p>
<p>[cite_start]이를 위해 <strong>Proper Causal Path</strong>라는 개념을 도입하고, 복잡한 그래프에서 유효한 조정 집합 <img src="https://latex.codecogs.com/png.latex?Z">를 찾아내는 알고리즘과 <strong>명시적 구성(Explicit Construction)</strong> 방법을 살펴봅니다[cite: 131, 134].</p>
<hr>
</section>
<section id="proper-causal-paths-pcp" class="level1">
<h1>2. Proper Causal Paths (PCP)</h1>
<p>Adjustment Criterion을 정의하기 전에, <strong>어떤 경로(Path)를 건드리면 안 되는지</strong>를 명확히 해야 합니다.</p>
<section id="definition" class="level2">
<h2 class="anchored" data-anchor-id="definition">2.1. Definition</h2>
<p>[cite_start]<strong>Proper Causal Path (진인과경로)</strong>는 <img src="https://latex.codecogs.com/png.latex?X">에서 출발하여 <img src="https://latex.codecogs.com/png.latex?Y">로 향하는 인과 경로(Directed path) 중, <strong>시작점인 <img src="https://latex.codecogs.com/png.latex?X">를 제외하고는 <img src="https://latex.codecogs.com/png.latex?X"> 집합의 다른 노드를 거치지 않는 경로</strong>를 의미합니다[cite: 138, 139].</p>
<ul>
<li><strong>Causal Path:</strong> 화살표의 방향이 일관되게 <img src="https://latex.codecogs.com/png.latex?X">에서 <img src="https://latex.codecogs.com/png.latex?Y">로 흐르는 경로.</li>
<li><strong>Proper:</strong> 경로상에 <img src="https://latex.codecogs.com/png.latex?X">의 다른 원소가 포함되지 않음.</li>
</ul>
<p><img src="https://shsha0110.github.io/posts/lecture/L05/part-02/images/proper_causal_path_example.png" class="img-fluid" alt="Figure 1: Proper vs Non-proper Causal Paths. X_1 \to W_3 \to Y와 X_2 \to W_2 \to Y는 Proper하다. 반면 X_1 \to W_1 \to X_2 \dots는 중간에 X_2를 거치므로 Non-proper하다."> [cite_start]<em>(그림 설명: <img src="https://latex.codecogs.com/png.latex?X=%5C%7BX_1,%20X_2%5C%7D">인 상황. <img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20W_3%20%5Cto%20Y">는 <img src="https://latex.codecogs.com/png.latex?X">의 다른 원소를 거치지 않으므로 Proper Causal Path이다. 반면 <img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20W_1%20%5Cto%20X_2%20%5Cto%20W_2%20%5Cto%20Y">는 경로 중간에 <img src="https://latex.codecogs.com/png.latex?X_2(%5Cin%20X)">가 포함되므로 Non-proper Causal Path이다.)</em> [cite: 146, 148]</p>
</section>
<section id="why-proper-causal-paths-matter" class="level2">
<h2 class="anchored" data-anchor-id="why-proper-causal-paths-matter">2.2. Why Proper Causal Paths Matter?</h2>
<p>우리가 구하고자 하는 것은 <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 <strong>총 효과(Total Effect)</strong>입니다. [cite_start]따라서 <img src="https://latex.codecogs.com/png.latex?X">에서 <img src="https://latex.codecogs.com/png.latex?Y">로 흐르는 인과적 흐름을 담고 있는 <strong>Proper Causal Path를 차단해서는 안 됩니다</strong>[cite: 160].</p>
<p>만약 Proper Causal Path 상에 있는 변수(Mediator)나 그 변수의 후손(Descendant)을 조정 집합 <img src="https://latex.codecogs.com/png.latex?Z">에 포함하면 어떻게 될까요? 간단한 체인 구조 <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20W%20%5Cto%20Y">와 <img src="https://latex.codecogs.com/png.latex?W%20%5Cto%20Z">가 있는 그래프를 가정해 봅시다. [cite_start]여기서 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))%20=%20P(y%7Cx)">입니다 (Back-door 경로가 없음)[cite: 152, 161].</p>
<p>하지만 우리가 <img src="https://latex.codecogs.com/png.latex?Z">(Mediator의 후손)에 대해 조정(Adjustment)을 수행하면 편향이 발생합니다. 이를 수식으로 확인해 봅시다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Csum_%7Bz%7D%20P(y%7Cx,z)P(z)%20&amp;=%20%5Csum_%7Bz,w%7D%20P(y%7Cx,z,w)P(w%7Cx,z)P(z)%20%5Cquad%20(%5Ctext%7BLaw%20of%20Total%20Probability%7D)%20%5C%5C%0A&amp;=%20%5Csum_%7Bz,w%7D%20P(y%7Cw)P(w%7Cx,z)P(z)%20%5Cquad%20(Y%20%5Cperp%5C!%5C!%5Cperp%20X,%20Z%20%7C%20W)%20%5C%5C%0A&amp;=%20%5Csum_%7Bw%7D%20P(y%7Cw)%20%5Csum_%7Bz%7D%20P(w%7Cx,z)P(z)%0A%5Cend%7Baligned%7D%0A"> [cite_start][cite: 162-165]</p>
<p>진정한 인과 효과는 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))%20=%20%5Csum_w%20P(y%7Cw)P(w%7Cx)">입니다. 하지만 위 식의 두 번째 항 <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bz%7D%20P(w%7Cx,z)P(z)">는 일반적으로 <img src="https://latex.codecogs.com/png.latex?P(w%7Cx)">와 다릅니다. [cite_start]이는 <img src="https://latex.codecogs.com/png.latex?P(z)%20%5Cneq%20P(z%7Cx)">이기 때문입니다[cite: 172, 174].</p>
<p>[cite_start]결국, Proper Causal Path 상의 변수나 그 후손을 조정하면 인과 효과 추정치가 <strong>왜곡(disturbed)</strong>됩니다[cite: 175].</p>
<hr>
</section>
</section>
<section id="the-adjustment-criterion" class="level1">
<h1>3. The Adjustment Criterion</h1>
<p>Shpitser et al.&nbsp;(2010)은 Back-door Criterion을 일반화하여 <strong>Adjustment Criterion</strong>을 제안했습니다. [cite_start]집합 <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?(X,%20Y)">에 대해 Admissible하기 위해서는 다음 두 조건을 만족해야 합니다[cite: 179].</p>
<section id="condition-i-preserve-causal-paths" class="level2">
<h2 class="anchored" data-anchor-id="condition-i-preserve-causal-paths">3.1. Condition (i): Preserve Causal Paths</h2>
<blockquote class="blockquote">
<p><strong>Condition (i):</strong> <img src="https://latex.codecogs.com/png.latex?Z">의 어떤 원소도 <img src="https://latex.codecogs.com/png.latex?X">에서 <img src="https://latex.codecogs.com/png.latex?Y">로 가는 <strong>Proper Causal Path</strong> 상에 있는 변수(<img src="https://latex.codecogs.com/png.latex?X"> 제외)의 후손(descendant)이 아니어야 한다.</p>
</blockquote>
<p><img src="https://latex.codecogs.com/png.latex?%0AZ%20%5Ccap%20De(W%20%5Csetminus%20X)%20=%20%5Cemptyset,%20%5Cquad%20%5Ctext%7Bfor%20any%20%7D%20W%20%5Ctext%7B%20on%20a%20proper%20causal%20path%7D%0A"></p>
<p>[cite_start]이 조건은 우리가 인과 경로를 실수로 차단하거나 왜곡하는 것을 방지합니다[cite: 180, 186]. 즉, “미래의 변수”를 통제하지 말라는 원칙을 더 엄밀하게 정의한 것입니다.</p>
</section>
<section id="condition-ii-block-spurious-paths" class="level2">
<h2 class="anchored" data-anchor-id="condition-ii-block-spurious-paths">3.2. Condition (ii): Block Spurious Paths</h2>
<blockquote class="blockquote">
<p><strong>Condition (ii):</strong> <img src="https://latex.codecogs.com/png.latex?Z">는 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 모든 <strong>Proper Non-causal Path</strong>를 차단(block)해야 한다.</p>
</blockquote>
<p><img src="https://latex.codecogs.com/png.latex?%0A(Y%20%5Cperp%5C!%5C!%5Cperp%20X%20%7C%20Z)_%7B%5Cmathcal%7BG%7D'%7D%0A"></p>
<p>여기서 <strong>Proper Non-causal Path</strong>란 <img src="https://latex.codecogs.com/png.latex?X">에서 시작하지만 인과 경로가 아닌(화살표가 <img src="https://latex.codecogs.com/png.latex?X">로 들어오거나 중간에 꺾이는) 경로들을 의미합니다. [cite_start]이것들은 교란(Confounding) 요인이므로 반드시 막아야 합니다[cite: 190, 197].</p>
<blockquote class="blockquote">
<p>[cite_start]<strong>Note:</strong> 초기 논문에서는 단순히 ’non-causal paths’라고 했으나, 이후 ’proper non-causal paths’로 수정되었습니다[cite: 198, 199].</p>
</blockquote>
<hr>
</section>
</section>
<section id="implementation-idea-the-mathcalg-method" class="level1">
<h1>4. Implementation Idea: The <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'"> Method</h1>
<p>Condition (ii)를 그래프상에서 직관적으로 검사하기 위해 보조 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">를 사용할 수 있습니다.</p>
<section id="step-1-forbidden-set-f-확인" class="level3">
<h3 class="anchored" data-anchor-id="step-1-forbidden-set-f-확인">Step 1: Forbidden Set (<img src="https://latex.codecogs.com/png.latex?F">) 확인</h3>
<p>먼저 Condition (i)에 위배되는 변수들을 찾습니다. Proper Causal Path 위에 있는 모든 변수(X 제외)와 그 후손들을 모아 집합 <img src="https://latex.codecogs.com/png.latex?F">를 만듭니다. [cite_start]<img src="https://latex.codecogs.com/png.latex?Z">는 <img src="https://latex.codecogs.com/png.latex?F">와 겹치면 안 됩니다[cite: 217, 218].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AF%20=%20De(W%20%5Csetminus%20X)_%7B%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D%7D%0A"></p>
</section>
<section id="step-2-construct-mathcalg" class="level3">
<h3 class="anchored" data-anchor-id="step-2-construct-mathcalg">Step 2: Construct <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'"></h3>
<p>원래 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D">에서 <strong>모든 Proper Causal Path의 첫 번째 엣지(Edge)를 제거</strong>합니다. [cite_start]이렇게 만든 그래프를 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">라고 합니다[cite: 227, 313].</p>
</section>
<section id="step-3-d-separation-test" class="level3">
<h3 class="anchored" data-anchor-id="step-3-d-separation-test">Step 3: D-separation Test</h3>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">에서 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">가 <img src="https://latex.codecogs.com/png.latex?Z">에 의해 d-separated 되는지 확인합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A(X%20%5Cperp%5C!%5C!%5Cperp%20Y%20%7C%20Z)_%7B%5Cmathcal%7BG%7D'%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">에서는 인과 경로가 끊겨 있으므로, 남은 연결은 모두 Non-causal Path입니다. [cite_start]만약 <img src="https://latex.codecogs.com/png.latex?Z">가 이들을 모두 막는다면 Condition (ii)가 만족됩니다[cite: 228, 314].</p>
<hr>
</section>
</section>
<section id="a-worked-example" class="level1">
<h1>5. A Worked Example</h1>
<p>복잡한 그래프 예시를 통해 실제로 적용해 봅시다. * <strong>Target:</strong> <img src="https://latex.codecogs.com/png.latex?X=%5C%7BX_1,%20X_2%5C%7D">, <img src="https://latex.codecogs.com/png.latex?Y=%5C%7BY_1,%20Y_2%5C%7D"> * [cite_start]<strong>Candidates:</strong> <img src="https://latex.codecogs.com/png.latex?Z=%5C%7BC,%20D,%20I%5C%7D">가 Admissible한가? [cite: 263]</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L05/part-02/images/complex_dag_example.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: Example Graph for Adjustment Criterion. <img src="https://latex.codecogs.com/png.latex?X=%5C%7BX_1,%20X_2%5C%7D">에서 <img src="https://latex.codecogs.com/png.latex?Y=%5C%7BY_1,%20Y_2%5C%7D">로 가는 복잡한 경로들이 얽혀 있다.</figcaption>
</figure>
</div>
<section id="step-1-identify-proper-causal-paths" class="level3">
<h3 class="anchored" data-anchor-id="step-1-identify-proper-causal-paths">Step 1: Identify Proper Causal Paths</h3>
<p><img src="https://latex.codecogs.com/png.latex?X">에서 <img src="https://latex.codecogs.com/png.latex?Y">로 가는 Proper Causal Path를 찾습니다. * <img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20Y_1"> * <img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20E%20%5Cto%20Y_2"> * <img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20D%20%5Cto%20I%20%5Cto%20Y_1"> (이 경로는 <img src="https://latex.codecogs.com/png.latex?X_2">를 안 거치므로 Proper) * <img src="https://latex.codecogs.com/png.latex?X_2%20%5Cto%20F%20%5Cto%20Y_2"> [cite_start]등이 있습니다[cite: 260].</p>
</section>
<section id="step-2-check-condition-i-forbidden-set" class="level3">
<h3 class="anchored" data-anchor-id="step-2-check-condition-i-forbidden-set">Step 2: Check Condition (i) (Forbidden Set)</h3>
<p>Proper Causal Path 위에 있는 중간 변수들은 <img src="https://latex.codecogs.com/png.latex?E,%20F"> 등입니다. * <img src="https://latex.codecogs.com/png.latex?E">의 후손: <img src="https://latex.codecogs.com/png.latex?%5C%7BE,%20Y_2%20%5Cdots%5C%7D"> * <img src="https://latex.codecogs.com/png.latex?F">의 후손: <img src="https://latex.codecogs.com/png.latex?%5C%7BF,%20H,%20Y_2%20%5Cdots%5C%7D"> 따라서 <img src="https://latex.codecogs.com/png.latex?Z">에 <img src="https://latex.codecogs.com/png.latex?E,%20F,%20H">가 포함되면 안 됩니다. [cite_start]우리의 후보 <img src="https://latex.codecogs.com/png.latex?Z=%5C%7BC,%20D,%20I%5C%7D">는 이들과 겹치지 않으므로 <strong>Condition (i) 만족</strong>[cite: 293, 294].</p>
</section>
<section id="step-3-check-condition-ii-via-mathcalg" class="level3">
<h3 class="anchored" data-anchor-id="step-3-check-condition-ii-via-mathcalg">Step 3: Check Condition (ii) via <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'"></h3>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">를 만들기 위해 Proper Causal Path의 첫 엣지를 자릅니다. * <img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20Y_1"> 제거 * <img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20D"> 제거 * <img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20E"> 제거 * <img src="https://latex.codecogs.com/png.latex?X_2%20%5Cto%20F"> 제거 [cite_start]등등[cite: 313].</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L05/part-02/images/g_prime_example.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3: The Modified Graph <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">. Proper Causal Path의 첫 번째 엣지들이 제거된 상태이다. 점선 화살표와 Back-door 경로들만 남았다.</figcaption>
</figure>
</div>
<p>이제 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">에서 <img src="https://latex.codecogs.com/png.latex?(X%20%5Cperp%5C!%5C!%5Cperp%20Y%20%7C%20%5C%7BC,%20D,%20I%5C%7D)">인지 확인합니다. <img src="https://latex.codecogs.com/png.latex?C,%20D,%20I">를 조건부로 주었을 때, 남은 교란 경로들이 모두 차단된다면 <img src="https://latex.codecogs.com/png.latex?Z">는 유효합니다. [cite_start]이 예제에서는 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">에서 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">가 분리되므로 <strong>Condition (ii) 만족</strong>입니다[cite: 333, 334].</p>
<hr>
</section>
</section>
<section id="explicit-construction-of-admissible-sets" class="level1">
<h1>6. Explicit Construction of Admissible Sets</h1>
<p>“매번 <img src="https://latex.codecogs.com/png.latex?Z">를 추측하고 검증해야 하나요?”라는 질문에 대한 답으로, 유효한 조정 집합을 <strong>직접 구성(Explicit Construction)</strong>하는 방법이 있습니다. [cite_start]이를 <strong>One-shot Verification</strong>이라고도 합니다[cite: 413].</p>
<section id="lemma-constructive-method" class="level3">
<h3 class="anchored" data-anchor-id="lemma-constructive-method">Lemma: Constructive Method</h3>
<p>만약 어떤 Admissible Set이 존재한다면, 다음 집합 <img src="https://latex.codecogs.com/png.latex?Z_0">도 반드시 Admissible합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AZ_0%20=%20An%5E%7B-%7D(X%20%5Ccup%20Y)%20%5Csetminus%20F%0A"></p>
<ul>
<li>[cite_start]<img src="https://latex.codecogs.com/png.latex?An%5E%7B-%7D(X%20%5Ccup%20Y)">: <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">의 조상(Ancestors)들의 집합 (<img src="https://latex.codecogs.com/png.latex?X,%20Y"> 자신 제외)[cite: 358, 363].</li>
<li>[cite_start]<img src="https://latex.codecogs.com/png.latex?F">: Condition (i)에 의해 금지된 변수들 (Proper Causal Path 상의 변수 및 후손)[cite: 354].</li>
</ul>
</section>
<section id="significance" class="level3">
<h3 class="anchored" data-anchor-id="significance">Significance</h3>
<p>[cite_start]이 정리가 강력한 이유는 <strong>“<img src="https://latex.codecogs.com/png.latex?Z_0">가 실패하면, 그 어떤 <img src="https://latex.codecogs.com/png.latex?Z">도 실패한다”</strong>는 점입니다[cite: 359, 412]. 즉, 우리는 <img src="https://latex.codecogs.com/png.latex?Z_0"> 딱 하나만 만들어보고 테스트하면 됩니다.</p>
</section>
<section id="apply-to-example" class="level3">
<h3 class="anchored" data-anchor-id="apply-to-example">Apply to Example</h3>
<p>위의 예제 그래프에 적용해 봅시다. 1. [cite_start]<strong>Forbidden Set (<img src="https://latex.codecogs.com/png.latex?F">):</strong> <img src="https://latex.codecogs.com/png.latex?%5C%7BE,%20F,%20H%5C%7D"> (PC Path 상의 변수와 그 후손)[cite: 402]. 2. [cite_start]<strong>Ancestors (<img src="https://latex.codecogs.com/png.latex?An%5E%7B-%7D">):</strong> <img src="https://latex.codecogs.com/png.latex?X,%20Y">의 조상을 모두 찾으면 <img src="https://latex.codecogs.com/png.latex?%5C%7BA,%20B,%20C,%20D,%20E,%20F,%20I%5C%7D"> 입니다[cite: 403]. 3. <strong>Construct <img src="https://latex.codecogs.com/png.latex?Z_0">:</strong> <img src="https://latex.codecogs.com/png.latex?Z_0%20=%20%5C%7BA,%20B,%20C,%20D,%20E,%20F,%20I%5C%7D%20%5Csetminus%20%5C%7BE,%20F,%20H%5C%7D%20=%20%5C%7BA,%20B,%20C,%20D,%20I%5C%7D"> 4. <strong>Verification:</strong> 이 <img src="https://latex.codecogs.com/png.latex?Z_0">가 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">에서 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">를 d-separation 시키는지 확인합니다. [cite_start]확인 결과 Admissible 합니다[cite: 404, 405].</p>
<hr>
</section>
</section>
<section id="summary" class="level1">
<h1>7. Summary</h1>
<ul>
<li><strong>Proper Causal Path:</strong> <img src="https://latex.codecogs.com/png.latex?X">에서 시작해 <img src="https://latex.codecogs.com/png.latex?Y">로 가는 경로 중, 다시 <img src="https://latex.codecogs.com/png.latex?X">를 거치지 않는 경로. 이 경로들은 인과 효과의 본질이므로 <strong>절대 차단하거나 조정해서는 안 됩니다.</strong></li>
<li><strong>Adjustment Criterion:</strong>
<ol type="1">
<li><ol type="i">
<li>Proper Causal Path 상의 변수(및 후손)를 <img src="https://latex.codecogs.com/png.latex?Z">에 포함하지 말 것.</li>
</ol></li>
<li><ol start="2" type="i">
<li><img src="https://latex.codecogs.com/png.latex?Z">는 모든 Proper Non-causal Path(교란 경로)를 차단할 것.</li>
</ol></li>
</ol></li>
<li><strong>Implementation:</strong> <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">(PC Path의 첫 엣지 제거)를 이용하면 Condition (ii)를 d-separation 문제로 쉽게 환원할 수 있습니다.</li>
<li><strong>Constructive Solution:</strong> <img src="https://latex.codecogs.com/png.latex?Z_0%20=%20An%5E%7B-%7D(X%20%5Ccup%20Y)%20%5Csetminus%20F">를 계산함으로써, 유효한 조정 집합의 존재 여부를 한 번에 파악할 수 있습니다.</li>
</ul>
<p>이로써 우리는 Back-door Criterion의 한계를 넘어, 그래프 구조만 주어진다면 언제, 무엇을 조정해야 하는지 완벽하게 판단할 수 있는 도구를 갖추게 되었습니다.</p>
<hr>
<section id="누락-방지-검증-missing-content-check" class="level3">
<h3 class="anchored" data-anchor-id="누락-방지-검증-missing-content-check">누락 방지 검증 (Missing Content Check)</h3>
<p>강의 자료(PDF 0502 파일)의 내용을 기반으로 아래 항목들이 포함되었는지 확인합니다.</p>
<ul>
<li>[cite_start][x] <strong>Adjustment Criterion 정의 (필요충분조건)</strong> [cite: 134]</li>
<li>[cite_start][x] <strong>Proper Causal Path 정의 및 예시</strong> [cite: 138-148]</li>
<li>[cite_start][x] <strong>Proper Causal Path 조정 시 발생하는 편향(Math Derivation)</strong> [cite: 162-176]</li>
<li>[cite_start][x] <strong>Adjustment Criterion의 두 가지 조건 (i), (ii)</strong> [cite: 179-197]</li>
<li>[cite_start][x] <strong>Implementation Idea (Forbidden Set <img src="https://latex.codecogs.com/png.latex?F">, Graph <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">)</strong> [cite: 202-234]</li>
<li>[cite_start][x] <strong>복잡한 그래프 예제 (Evaluating Set Z)</strong> [cite: 247-334]</li>
<li>[cite_start][x] <strong>Explicit Construction Lemma (<img src="https://latex.codecogs.com/png.latex?Z_0">) 및 예제 적용</strong> [cite: 353-405]</li>
<li>[cite_start][x] <strong>One-shot verification의 의미</strong> [cite: 412, 413]</li>
</ul>
<p><strong>Note:</strong> 제공된 PDF의 모든 핵심 내용(페이지 1-22)이 본 포스트에 반영되었습니다.</p>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L05/part-02/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 05. Adjustment Criterion (Part 3)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L05/part-03/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>이전 포스트들에서 우리는 <strong>Adjustment Criterion</strong>의 이론적 배경과 정의를 살펴보았습니다. 우리는 특정 변수 집합 <img src="https://latex.codecogs.com/png.latex?Z">가 주어졌을 때, 그것이 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 식별(Identification)하기 위해 유효한지(Admissible) 판별하는 방법을 알고 있습니다.</p>
<p>하지만 현실적인 인과 추론 문제에서는 단순히 “이 <img src="https://latex.codecogs.com/png.latex?Z">가 유효한가?”를 묻는 것을 넘어, <strong>“유효한 <img src="https://latex.codecogs.com/png.latex?Z">들을 어떻게 모두 찾을 것인가?”</strong> 또는 <strong>“어떤 <img src="https://latex.codecogs.com/png.latex?Z">를 선택하는 것이 최선인가?”</strong>라는 질문에 직면하게 됩니다.</p>
<section id="motivation-why-find-all-sets" class="level2">
<h2 class="anchored" data-anchor-id="motivation-why-find-all-sets">1.1. Motivation: Why Find All Sets?</h2>
<p>[cite_start]일반적으로 주어진 인과 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D">에서 Admissible Set은 하나가 아니라 여러 개 존재할 수 있습니다. [cite: 439] 그렇다면 우리는 왜 여러 집합을 고려해야 할까요?</p>
<ol type="1">
<li><strong>Measurement Cost (측정 비용):</strong> 어떤 변수는 측정하기 매우 비싸거나 위험할 수 있습니다.</li>
<li><strong>Variance (분산):</strong> 어떤 조정 집합은 다른 집합보다 추정량의 분산을 더 줄여줄 수 있습니다.</li>
<li>[cite_start]<strong>Availability &amp; Ethics:</strong> 개인정보 보호나 공정성 이슈로 특정 변수를 사용할 수 없을 수 있습니다. [cite: 444]</li>
</ol>
<blockquote class="blockquote">
<p><strong>Example:</strong> 어떤 질병(<img src="https://latex.codecogs.com/png.latex?X">)과 결과(<img src="https://latex.codecogs.com/png.latex?Y">) 사이의 인과 효과를 추정할 때, 유전적 조건(<img src="https://latex.codecogs.com/png.latex?A">)과 두통(<img src="https://latex.codecogs.com/png.latex?B">)이 모두 각각 유효한 조정 집합이라고 가정해 봅시다 (<img src="https://latex.codecogs.com/png.latex?%5C%7BA%5C%7D"> is admissible, <img src="https://latex.codecogs.com/png.latex?%5C%7BB%5C%7D"> is admissible). * <img src="https://latex.codecogs.com/png.latex?A"> (유전자): 검사 비용이 비쌈, 개인정보 이슈. * <img src="https://latex.codecogs.com/png.latex?B"> (두통): 설문으로 쉽게 확인 가능.</p>
<p>이 경우, 이론적으로는 둘 다 유효하지만 현실적으로는 <img src="https://latex.codecogs.com/png.latex?B">를 선택하는 것이 훨씬 유리합니다. [cite_start]따라서 우리는 <strong>가능한 모든 Admissible Set을 나열</strong>하고, 그중 비용-효율적인 것을 선택할 필요가 있습니다. [cite: 446-454]</p>
</blockquote>
<hr>
</section>
</section>
<section id="the-computational-challenge" class="level1">
<h1>2. The Computational Challenge</h1>
<p>문제는 그래프의 크기가 커질수록 가능한 부분집합의 개수가 기하급수적으로 늘어난다는 점입니다.</p>
<section id="exponential-search-space" class="level2">
<h2 class="anchored" data-anchor-id="exponential-search-space">2.1. Exponential Search Space</h2>
<p>변수가 <img src="https://latex.codecogs.com/png.latex?n">개일 때, 가능한 변수 조합은 <img src="https://latex.codecogs.com/png.latex?2%5En">개입니다. [cite_start]만약 우리가 “Magic Function” <img src="https://latex.codecogs.com/png.latex?f">를 가지고 있어서 모든 Admissible Set을 <img src="https://latex.codecogs.com/png.latex?O(1)"> 시간에 찾는다고 해도, 출력해야 할 집합의 개수 자체가 지수적으로 많다면 전체 실행 시간은 엄청나게 길어질 것입니다. [cite: 457]</p>
<p>따라서 우리의 목표는 “전체 실행 시간을 줄이는 것”이 아니라(이는 불가능할 수 있음), <strong>“첫 번째 답을 찾을 때까지, 그리고 하나의 답을 찾고 다음 답을 찾을 때까지 걸리는 시간”</strong>을 합리적으로 유지하는 것입니다.</p>
</section>
<section id="polynomial-delay" class="level2">
<h2 class="anchored" data-anchor-id="polynomial-delay">2.2. Polynomial Delay</h2>
<p>우리는 <strong>Polynomial Delay</strong> 알고리즘을 목표로 합니다. 알고리즘이 <img src="https://latex.codecogs.com/png.latex?O(n%5Ed)"> (단, <img src="https://latex.codecogs.com/png.latex?d">는 상수) 시간 내에 다음 작업을 수행한다면 Polynomial Delay를 가진다고 합니다.</p>
<ol type="1">
<li>프로그램 시작 후 첫 번째 출력을 내놓을 때까지.</li>
<li>하나의 출력을 내놓고 다음 출력을 내놓을 때까지.</li>
<li>마지막 출력을 내놓고 종료할 때까지.</li>
</ol>
<p><img src="https://shsha0110.github.io/posts/lecture/L05/part-03/images/polynomial_delay_timeline.png" class="img-fluid" alt="Figure 1: Concept of Polynomial Delay. 각 출력(s_1, s_2, \dots) 사이의 간격이 입력 크기 n의 다항식 시간 O(n^d) 이내로 제한된다."> [cite_start]<em>(그림 설명: 시간 축 위에서 알고리즘이 해(solution) <img src="https://latex.codecogs.com/png.latex?s_1,%20s_2,%20%5Cdots">를 출력하는 시점을 나타냄. 각 간격이 너무 길어지지 않도록 보장하는 것이 핵심임.)</em> [cite: 470-479]</p>
<hr>
</section>
</section>
<section id="theoretical-foundation-inclusion-restriction" class="level1">
<h1>3. Theoretical Foundation: Inclusion &amp; Restriction</h1>
<p>효율적인 탐색을 위해 “Divide and Conquer(분할 정복)” 전략을 사용할 것입니다. 이를 위해서는 탐색 공간의 특정 가지(branch)에 해가 존재하는지 빠르게(Polynomial time에) 판단할 수 있는 도구가 필요합니다.</p>
<section id="the-lemma" class="level2">
<h2 class="anchored" data-anchor-id="the-lemma">3.1. The Lemma</h2>
<p>우리가 찾고자 하는 분리 집합(Separating Set) <img src="https://latex.codecogs.com/png.latex?Z">가 다음 조건을 만족한다고 가정해 봅시다. <img src="https://latex.codecogs.com/png.latex?I%20%5Csubseteq%20Z%20%5Csubseteq%20R"> 즉, <img src="https://latex.codecogs.com/png.latex?Z">는 반드시 <img src="https://latex.codecogs.com/png.latex?I">를 포함(Include)해야 하고, <img src="https://latex.codecogs.com/png.latex?R">에 포함(Restrict)되어야 합니다.</p>
<p>이때, <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">를 분리하는 유효한 <img src="https://latex.codecogs.com/png.latex?Z">가 범위 <img src="https://latex.codecogs.com/png.latex?%5BI,%20R%5D"> 내에 존재하는지 확인하는 방법은 다음과 같습니다.</p>
<blockquote class="blockquote">
<p><strong>Lemma (Existence of Separator in Range):</strong> 범위 <img src="https://latex.codecogs.com/png.latex?I%20%5Csubseteq%20Z%20%5Csubseteq%20R"> 내에 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">를 분리하는 집합 <img src="https://latex.codecogs.com/png.latex?Z">가 <strong>존재한다면</strong>, 특수하게 구성된 집합 <strong><img src="https://latex.codecogs.com/png.latex?Z_0"></strong> 또한 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">를 분리한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?Z_0%20=%20An(X%20%5Ccup%20Y%20%5Ccup%20I)%20%5Ccap%20R"></p>
<p>[cite_start]반대로, <strong><img src="https://latex.codecogs.com/png.latex?Z_0">가 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">를 분리하지 못한다면, 해당 범위 내에 분리 집합은 존재하지 않는다.</strong> [cite: 493-498]</p>
</blockquote>
<p><img src="https://shsha0110.github.io/posts/lecture/L05/part-03/images/inclusion_restriction_venn.png" class="img-fluid" alt="Figure 2: Venn Diagram of Inclusion (I) and Restriction (R). Z는 I를 감싸고 R 내부에 있어야 한다. Z_0는 이 조건 하에서 구성 가능한 가장 ’조상’에 가까운 집합이다."> [cite_start]<em>(그림 설명: <img src="https://latex.codecogs.com/png.latex?I">를 포함하고 <img src="https://latex.codecogs.com/png.latex?R">에 속하는 <img src="https://latex.codecogs.com/png.latex?Z">들의 공간. <img src="https://latex.codecogs.com/png.latex?Z_0">는 <img src="https://latex.codecogs.com/png.latex?X,%20Y,%20I">의 조상(<img src="https://latex.codecogs.com/png.latex?An">)이면서 <img src="https://latex.codecogs.com/png.latex?R">에 속하는 교집합으로 정의됨.)</em> [cite: 492]</p>
</section>
<section id="significance" class="level2">
<h2 class="anchored" data-anchor-id="significance">3.2. Significance</h2>
<p>이 Lemma가 중요한 이유는 <strong>탐색의 가지치기(Pruning)</strong>를 가능하게 하기 때문입니다. 우리는 <img src="https://latex.codecogs.com/png.latex?Z_0">를 구성하고 d-separation을 검사하는 것을 <img src="https://latex.codecogs.com/png.latex?O(n+m)"> (그래프 탐색 시간) 내에 수행할 수 있습니다. [cite_start]만약 <img src="https://latex.codecogs.com/png.latex?Z_0">가 실패하면, 그 하위의 모든 조합을 일일이 확인하지 않고 즉시 탐색을 중단할 수 있습니다. [cite: 508-509]</p>
<hr>
</section>
</section>
<section id="the-algorithm-list-seps" class="level1">
<h1>4. The Algorithm: <code>list-seps</code></h1>
<p>이제 위 이론을 바탕으로 모든 Admissible Set을 찾는 알고리즘 <code>list-seps</code>를 정의합니다.</p>
<section id="setup" class="level2">
<h2 class="anchored" data-anchor-id="setup">4.1. Setup</h2>
<p>먼저, <strong>Adjustment Criterion</strong>의 조건 (i)(Proper Causal Path 보존)을 만족하기 위해, 절대 조정하면 안 되는 변수들의 집합 <img src="https://latex.codecogs.com/png.latex?F">를 정의합니다. 그리고 알고리즘 내부적으로 사용할 <img src="https://latex.codecogs.com/png.latex?F%5E+">를 정의합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?F%5E+%20=%20X%20%5Ccup%20Y%20%5Ccup%20F"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?F">: <img src="https://latex.codecogs.com/png.latex?X">를 제외한 Proper Causal Path 상의 변수들과 그들의 후손.</li>
<li><img src="https://latex.codecogs.com/png.latex?G'">: Proper Causal Path의 첫 번째 엣지를 모두 제거한 그래프. (Part 2에서 배운 내용)</li>
</ul>
<p>이제 우리는 <img src="https://latex.codecogs.com/png.latex?G'">에서 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">를 분리하되, <img src="https://latex.codecogs.com/png.latex?F%5E+">의 원소는 포함하지 않는 <img src="https://latex.codecogs.com/png.latex?Z">를 찾으면 됩니다. [cite_start]이는 초기 조건 <img src="https://latex.codecogs.com/png.latex?I=%5Cemptyset">, <img src="https://latex.codecogs.com/png.latex?R=V%20%5Csetminus%20F%5E+">로 설정하여 해결할 수 있습니다. [cite: 529-533]</p>
</section>
<section id="algorithm-structure-divide-and-conquer" class="level2">
<h2 class="anchored" data-anchor-id="algorithm-structure-divide-and-conquer">4.2. Algorithm Structure (Divide and Conquer)</h2>
<p>[cite_start]함수 <code>list-seps(G, X, Y, I, R)</code>은 다음과 같이 재귀적으로 동작합니다. [cite: 596-602, 696-704]</p>
<ol type="1">
<li><strong>Existence Check:</strong> 먼저 <code>exist-sep(G, X, Y, I, R)</code>을 호출합니다. (앞서 배운 Lemma 사용).
<ul>
<li>만약 <code>False</code>라면, 이 범위에 해가 없으므로 즉시 <strong>Return</strong> (가지치기).</li>
</ul></li>
<li><strong>Output Check:</strong> 만약 <img src="https://latex.codecogs.com/png.latex?I%20=%20R">이라면, 더 이상 선택의 여지가 없습니다. <img src="https://latex.codecogs.com/png.latex?I">가 유효한 집합이므로 <strong>Output <img src="https://latex.codecogs.com/png.latex?I"></strong>.</li>
<li><strong>Branching:</strong> 아직 결정되지 않은 변수 <img src="https://latex.codecogs.com/png.latex?W%20%5Cin%20R%20%5Csetminus%20I">를 하나 선택합니다.
<ul>
<li><strong>Case 1 (Include W):</strong> <img src="https://latex.codecogs.com/png.latex?W">를 조정 집합에 포함시킵니다. <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> <code>list-seps(G, X, Y, I</code> <img src="https://latex.codecogs.com/png.latex?%5Ccup"> <code>{W}, R)</code></li>
<li><strong>Case 2 (Exclude W):</strong> <img src="https://latex.codecogs.com/png.latex?W">를 조정 집합에서 배제합니다. <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> <code>list-seps(G, X, Y, I, R</code> <img src="https://latex.codecogs.com/png.latex?%5Csetminus"> <code>{W})</code></li>
</ul></li>
</ol>
<p>이 과정을 통해 유효한 집합이 있는 경로만 탐색하며(Polynomial Delay), 모든 해를 나열할 수 있습니다.</p>
<hr>
</section>
</section>
<section id="worked-example" class="level1">
<h1>5. Worked Example</h1>
<p>다음 그래프를 통해 알고리즘을 단계별로 추적해 봅시다.</p>
<p><img src="https://shsha0110.github.io/posts/lecture/L05/part-03/images/running_example_graph.png" class="img-fluid" alt="Figure 3: Running Example Graph. X \to C \to Y (Proper Causal Path), X \leftarrow A \to B \to Y, X \leftarrow D \leftarrow \dots 등의 구조를 가짐."> [cite_start]<em>(그림 설명: <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20C%20%5Cto%20Y">가 Proper Causal Path임. <img src="https://latex.codecogs.com/png.latex?A,%20B,%20D">는 교란 요인일 가능성이 있음. 점선 화살표는 Hidden Confounder 혹은 Back-door path를 의미.)</em> [cite: 535]</p>
<section id="step-1-initialize" class="level2">
<h2 class="anchored" data-anchor-id="step-1-initialize">Step 1: Initialize</h2>
<ul>
<li><strong>Forbidden Set (<img src="https://latex.codecogs.com/png.latex?F">):</strong> <img src="https://latex.codecogs.com/png.latex?C">는 Proper Causal Path 위에 있으므로 금지됩니다. <img src="https://latex.codecogs.com/png.latex?X,%20Y">도 포함할 수 없습니다.</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?F%5E+">:</strong> <img src="https://latex.codecogs.com/png.latex?%5C%7BX,%20Y,%20C%5C%7D"></li>
<li><strong>Initial Range:</strong>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?I%20=%20%5Cemptyset"></li>
<li><img src="https://latex.codecogs.com/png.latex?R%20=%20V%20%5Csetminus%20F%5E+%20=%20%5C%7BA,%20B,%20D%5C%7D"></li>
</ul></li>
<li>[cite_start]<strong>Graph <img src="https://latex.codecogs.com/png.latex?G'">:</strong> <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20C"> 엣지를 제거하여 Proper Causal Path를 끊습니다. [cite: 546-547]</li>
</ul>
</section>
<section id="step-2-recursion-tree-trace" class="level2">
<h2 class="anchored" data-anchor-id="step-2-recursion-tree-trace">Step 2: Recursion Tree Trace</h2>
<p>알고리즘은 변수를 하나씩 선택하며 <img src="https://latex.codecogs.com/png.latex?I">에 넣을지(<img src="https://latex.codecogs.com/png.latex?I%20%5Ccup%20W">), <img src="https://latex.codecogs.com/png.latex?R">에서 뺄지(<img src="https://latex.codecogs.com/png.latex?R%20%5Csetminus%20W">) 결정합니다.</p>
<ol type="1">
<li><strong>Start:</strong> <img src="https://latex.codecogs.com/png.latex?I=%5C%7B%5C%7D,%20R=%5C%7BA,%20B,%20D%5C%7D">. <code>exist-sep</code> 통과(True).</li>
<li><strong>Pick D:</strong>
<ul>
<li><strong>Branch Left (Include D):</strong> <img src="https://latex.codecogs.com/png.latex?I=%5C%7BD%5C%7D,%20R=%5C%7BA,%20B,%20D%5C%7D">.
<ul>
<li><strong>Pick A:</strong>
<ul>
<li><strong>Include A:</strong> <img src="https://latex.codecogs.com/png.latex?I=%5C%7BA,%20D%5C%7D,%20R=%5C%7BA,%20B,%20D%5C%7D">. … <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> Output <img src="https://latex.codecogs.com/png.latex?%5C%7BA,%20B,%20D%5C%7D,%20%5C%7BA,%20D%5C%7D">…</li>
<li><strong>Exclude A:</strong> <img src="https://latex.codecogs.com/png.latex?R=%5C%7BB,%20D%5C%7D">. …</li>
</ul></li>
</ul></li>
<li><strong>Branch Right (Exclude D):</strong> <img src="https://latex.codecogs.com/png.latex?R=%5C%7BA,%20B%5C%7D">.
<ul>
<li>여기서 만약 <img src="https://latex.codecogs.com/png.latex?D">가 없으면 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">를 분리할 수 없다고 가정해 봅시다.</li>
<li>[cite_start]그러면 <code>exist-sep</code>이 False를 반환하고, 이 가지(branch)는 더 이상 탐색하지 않고 <strong>Pruning</strong> 됩니다. [cite: 561-591]</li>
</ul></li>
</ul></li>
</ol>
</section>
<section id="step-3-result" class="level2">
<h2 class="anchored" data-anchor-id="step-3-result">Step 3: Result</h2>
<p>결과적으로 트리의 리프 노드(Leaf Node) 중에서 <img src="https://latex.codecogs.com/png.latex?I=R">인 지점들이 Admissible Set으로 출력됩니다. 예를 들어 <img src="https://latex.codecogs.com/png.latex?%5C%7BA,%20B,%20D%5C%7D,%20%5C%7BA,%20D%5C%7D,%20%5C%7BB,%20D%5C%7D"> 등이 출력될 수 있습니다. (구체적인 출력은 그래프의 d-separation 구조에 따라 결정됨).</p>
<hr>
</section>
</section>
<section id="complexity-analysis" class="level1">
<h1>6. Complexity Analysis</h1>
<p>이 알고리즘의 효율성은 다음과 같이 분석됩니다.</p>
<ol type="1">
<li><strong>Tree Depth:</strong> 트리의 깊이는 최대 변수의 개수 <img src="https://latex.codecogs.com/png.latex?n">입니다.</li>
<li><strong>Work per Node:</strong> 각 노드에서 <code>exist-sep</code>을 수행하는 데 <img src="https://latex.codecogs.com/png.latex?O(n+m)"> 시간이 걸립니다. (<img src="https://latex.codecogs.com/png.latex?Z_0"> 계산 및 d-sep 확인).</li>
<li><strong>Delay:</strong> 하나의 출력을 찾기 위해 트리의 깊이만큼 내려갔다가 다시 올라오는 과정을 거칩니다. 잘못된 길로 들어서더라도 <code>exist-sep</code> 덕분에 즉시 되돌아옵니다.
<ul>
<li>[cite_start]따라서, 출력과 출력 사이의 지연 시간(Delay)은 최악의 경우에도 <strong><img src="https://latex.codecogs.com/png.latex?O(n(n+m))"></strong>입니다. [cite: 707]</li>
</ul></li>
</ol>
<blockquote class="blockquote">
<p><strong>Conclusion:</strong> [cite_start]전체 해의 개수가 지수적일지라도, 우리는 <img src="https://latex.codecogs.com/png.latex?O(n%5E2)"> 정도의 합리적인 대기 시간으로 유효한 조정 집합들을 하나씩 끊임없이(stream) 얻을 수 있습니다. [cite: 708-709]</p>
</blockquote>
<hr>
</section>
<section id="summary" class="level1">
<h1>7. Summary</h1>
<ul>
<li><strong>Necessity:</strong> 비용, 윤리, 분산 등의 이유로 <em>모든</em> Admissible Set을 탐색하는 것이 필요합니다.</li>
<li><strong>Challenge:</strong> 단순 전수 조사는 지수 시간(<img src="https://latex.codecogs.com/png.latex?2%5En">)이 걸려 불가능합니다. 목표는 <strong>Polynomial Delay</strong>입니다.</li>
<li><strong>Key Tool:</strong> <img src="https://latex.codecogs.com/png.latex?I%20%5Csubseteq%20Z%20%5Csubseteq%20R"> 범위 내에 해가 존재하는지 판별하는 Lemma(<img src="https://latex.codecogs.com/png.latex?Z_0">)를 통해, 가망 없는 탐색 경로를 즉시 차단(Pruning)합니다.</li>
<li><strong>Algorithm:</strong> <code>list-seps</code>는 <img src="https://latex.codecogs.com/png.latex?I">(포함)와 <img src="https://latex.codecogs.com/png.latex?R">(제한)을 갱신하며 재귀적으로 탐색하되, Lemma를 활용해 효율성을 보장합니다.</li>
<li><strong>Performance:</strong> 이 알고리즘은 <img src="https://latex.codecogs.com/png.latex?O(n(n+m))">의 Delay를 보장하여, 대규모 그래프에서도 실용적으로 사용할 수 있습니다.</li>
</ul>
<p>이로써 Adjustment Criterion의 정의부터(Part 1, 2), 실제로 유효한 집합들을 찾아내는 알고리즘(Part 3)까지 모두 다루었습니다. 이제 여러분은 복잡한 인과 그래프가 주어져도 어떤 변수를 통제해야 하는지 완벽하게 분석할 수 있습니다.</p>
<hr>
<section id="누락-방지-검증-missing-content-check" class="level3">
<h3 class="anchored" data-anchor-id="누락-방지-검증-missing-content-check">누락 방지 검증 (Missing Content Check)</h3>
<p>강의 자료(PDF 0503 파일)의 내용을 기반으로 아래 항목들이 포함되었는지 확인합니다.</p>
<ul>
<li>[cite_start][x] <strong>Motivation:</strong> 측정 비용, 분산, 프라이버시 등 여러 집합을 찾아야 하는 이유 [cite: 444]</li>
<li>[cite_start][x] <strong>Computational Challenge:</strong> 지수적 탐색 공간과 “Polynomial Delay”의 정의 [cite: 470-473]</li>
<li>[cite_start][x] <strong>Theoretical Tool (Lemma):</strong> <img src="https://latex.codecogs.com/png.latex?I%20%5Csubseteq%20Z%20%5Csubseteq%20R"> 조건 하의 존재성 판별법 (<img src="https://latex.codecogs.com/png.latex?Z_0">) [cite: 493-496]</li>
<li>[cite_start][x] <strong>Algorithm Structure:</strong> <code>list-seps</code> 함수의 재귀적 구조 (Include/Exclude) [cite: 596-602]</li>
<li>[cite_start][x] <strong>Pruning Strategy:</strong> <code>exist-sep</code>을 이용한 가지치기 [cite: 650-654]</li>
<li>[cite_start][x] <strong>Running Example:</strong> 그래프 예시를 통한 <img src="https://latex.codecogs.com/png.latex?I,%20R"> 변화 추적 [cite: 546-590]</li>
<li>[cite_start][x] <strong>Time Complexity:</strong> <img src="https://latex.codecogs.com/png.latex?O(n(n+m))"> Delay 분석 [cite: 707]</li>
<li>[cite_start][x] <strong>Algorithm Setup:</strong> <img src="https://latex.codecogs.com/png.latex?F%5E+"> 정의 및 초기 조건 [cite: 530-531]</li>
</ul>
<p><strong>Note:</strong> 제공된 PDF의 모든 핵심 내용(페이지 1-22)이 본 포스트에 반영되었습니다.</p>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L05/part-03/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 05. Adjustment Criterion (Part 4)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L05/part-04/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>지금까지 우리는 Judea Pearl의 <strong>SCM(Structural Causal Model)</strong> 관점에서 인과 효과를 식별(Identification)하는 과정을 살펴보았습니다. Back-door Criterion부터 시작해, 더 일반화된 Adjustment Criterion, 그리고 유효한 조정 집합(Admissible Set)을 찾는 알고리즘까지 다루었습니다.</p>
<p>이번 마지막 포스트에서는 이 그래프 기반의 접근법이 통계학 및 경제학에서 널리 쓰이는 Rubin의 <strong>Potential Outcome Framework</strong>와 어떻게 연결되는지 설명합니다. 특히, 인과 추론의 핵심 가정인 <strong>Conditional Ignorability</strong>가 그래프 상에서 어떻게 정당화되는지 알아보고, Adjustment Criterion 전체 내용을 요약합니다.</p>
<hr>
</section>
<section id="connecting-with-ignorability" class="level1">
<h1>2. Connecting with Ignorability</h1>
<p>Potential Outcome(잠재적 결과) 프레임워크에서 인과 효과를 식별하기 위해 가장 중요하게 사용되는 가정은 <strong>Conditional Ignorability(조건부 무시 가능성)</strong>입니다.</p>
<section id="definition" class="level2">
<h2 class="anchored" data-anchor-id="definition">2.1. Definition</h2>
<p>Conditional Ignorability는 반사실적(Counterfactual) 표기법을 사용하여 다음과 같이 정의됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AY_%7Bx%7D%20%5Cperp%5C!%5C!%5Cperp%20X%20%5Cmid%20Z%0A"></p>
<p>[cite_start][cite: 723-724, 733]</p>
<p>여기서: * <img src="https://latex.codecogs.com/png.latex?Y_%7Bx%7D">: 처리가 <img src="https://latex.codecogs.com/png.latex?X=x">로 고정되었을 때의 잠재적 결과 (Potential Outcome) * <img src="https://latex.codecogs.com/png.latex?X">: 실제 관찰된 처리 (Treatment) * <img src="https://latex.codecogs.com/png.latex?Z">: 공변량 집합 (Covariates)</p>
<p>이 식의 의미는 <strong>“공변량 <img src="https://latex.codecogs.com/png.latex?Z">를 통제(Conditioning)했을 때, 잠재적 결과 <img src="https://latex.codecogs.com/png.latex?Y_x">는 처리 <img src="https://latex.codecogs.com/png.latex?X">의 할당과 독립적이다”</strong>라는 것입니다. 즉, <img src="https://latex.codecogs.com/png.latex?Z">가 주어지면, 처리를 받은 그룹과 받지 않은 그룹 간에 체계적인 차이(교란 요인에 의한 편향)가 사라져 마치 무작위 할당(Random Assignment)된 것과 같아짐을 의미합니다.</p>
</section>
<section id="mathematical-equivalence" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-equivalence">2.2. Mathematical Equivalence</h2>
<p>이 가정은 SCM의 <img src="https://latex.codecogs.com/png.latex?do">-calculus 관점에서 다음과 같은 확률적 동치로 표현됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%20%5Cmid%20do(x),%20z)%20=%20P(y%20%5Cmid%20x,%20z)%0A"></p>
<p>[cite_start][cite: 729, 734]</p>
<p>이 등식은 <strong>개입(Intervention)</strong> 후의 확률 분포가 <strong>관찰(Observation)</strong> 된 조건부 확률 분포와 같아짐을 보여줍니다. 즉, <img src="https://latex.codecogs.com/png.latex?Z">가 교란 요인을 모두 차단했다면, 단순히 데이터를 <img src="https://latex.codecogs.com/png.latex?Z">로 층화하여 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">의 관계를 보는 것만으로 인과 효과를 계산할 수 있다는 뜻입니다.</p>
</section>
<section id="the-role-of-adjustment-criterion" class="level2">
<h2 class="anchored" data-anchor-id="the-role-of-adjustment-criterion">2.3. The Role of Adjustment Criterion</h2>
<p>Potential Outcome 프레임워크에서는 연구자가 “우리는 필요한 모든 교란 요인 <img src="https://latex.codecogs.com/png.latex?Z">를 측정했다”고 <strong>가정(Assume)</strong>하고 분석을 시작하는 경우가 많습니다.</p>
<p>하지만 <strong>“그 가정이 타당한가?”</strong>, <strong>“어떤 <img src="https://latex.codecogs.com/png.latex?Z">를 포함해야 이 가정이 성립하는가?”</strong>라는 질문에 대해 Potential Outcome 프레임워크 자체만으로는 답하기 어려울 때가 있습니다.</p>
<p>여기서 <strong>Adjustment Criterion</strong>이 강력한 이론적 도구(Theoretical Tool)가 됩니다.</p>
<blockquote class="blockquote">
<p>[cite_start]“While this is usually ‘assumed’ to hold in the PO framework, the adjustment criterion provides a <strong>justification</strong> under what conditions such set exists based on a given model of reality.” [cite: 735]</p>
</blockquote>
<p>즉, 우리가 현실 세계에 대한 모델(Causal Graph)을 그릴 수 있다면, Adjustment Criterion은 <strong>Conditional Ignorability 가정이 성립하기 위한 <img src="https://latex.codecogs.com/png.latex?Z">의 조건</strong>을 수학적으로 증명해 줍니다. 그래프 상에서 <img src="https://latex.codecogs.com/png.latex?Z">가 Back-door/Adjustment Criterion을 만족한다면, <img src="https://latex.codecogs.com/png.latex?Y_x%20%5Cperp%5C!%5C!%5Cperp%20X%20%7C%20Z">는 가정이 아니라 <strong>정리(Theorem)</strong>로서 성립하게 됩니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L05/part-04/images/scm_po_bridge_diagram.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: The bridge between SCM and PO Frameworks. 그래프(Graph)를 통해 현실을 모델링하면, Adjustment Criterion이 Ignorability 가정을 정당화(Justify)해주고, 이를 통해 통계적 추정(Estimation)이 가능해진다.</figcaption>
</figure>
</div>
<hr>
</section>
</section>
<section id="summary-of-adjustment-criterion" class="level1">
<h1>3. Summary of Adjustment Criterion</h1>
<p>이제 Adjustment Criterion 시리즈 전체를 관통하는 핵심 내용을 요약해 보겠습니다.</p>
<section id="why-adjustment" class="level2">
<h2 class="anchored" data-anchor-id="why-adjustment">3.1. Why Adjustment?</h2>
<p>[cite_start]조정(Adjustment)은 데이터 과학 전반에서 인과 효과를 식별하기 위해 가장 널리 사용되는 기법입니다. [cite: 738, 744, 750, 756] 관찰 데이터에서 혼란 변수(Confounder)의 영향을 제거하여 인과적 결론을 도출하는 표준적인 방법론입니다.</p>
</section>
<section id="identification-principle" class="level2">
<h2 class="anchored" data-anchor-id="identification-principle">3.2. Identification Principle</h2>
<p>[cite_start]Back-door Criterion과 이를 일반화한 Adjustment Criterion은 어떤 변수 집합 <img src="https://latex.codecogs.com/png.latex?Z">를 조정해야 타당한지(validity)를 판단하는 <strong>원칙적인 조건(Principled condition)</strong>을 제공합니다. [cite: 739, 745, 751, 757]</p>
<ul>
<li><strong>Back-door Criterion:</strong> <img src="https://latex.codecogs.com/png.latex?X">의 후손을 제외하고, 모든 Back-door Path를 차단하라.</li>
<li><strong>Adjustment Criterion:</strong> <img src="https://latex.codecogs.com/png.latex?X">의 후손이라도 인과 경로(Proper Causal Path)를 방해하지 않으면 사용 가능하다. (Back-door의 Tightness 문제 해결)</li>
</ul>
</section>
<section id="algorithmic-discovery" class="level2">
<h2 class="anchored" data-anchor-id="algorithmic-discovery">3.3. Algorithmic Discovery</h2>
<p>[cite_start]우리는 그래프와 목표 인과 효과가 주어졌을 때, 유효한 조정 집합(Admissible sets)을 <strong>체계적이고 효율적으로(Systematically and Efficiently)</strong> 찾을 수 있습니다. [cite: 740, 746, 752, 758]</p>
<ul>
<li><strong>Constructive Method:</strong> <img src="https://latex.codecogs.com/png.latex?Z_0%20=%20An(X%20%5Ccup%20Y%20%5Ccup%20I)%20%5Ccap%20R"> 등의 공식을 통해 존재 여부를 즉시 확인 가능.</li>
<li><strong>Polynomial Delay Algorithm:</strong> 가능한 모든 유효 집합을 합리적인 시간 복잡도 내에서 나열 가능.</li>
</ul>
</section>
<section id="from-identification-to-estimation" class="level2">
<h2 class="anchored" data-anchor-id="from-identification-to-estimation">3.4. From Identification to Estimation</h2>
<p>식별(Identification)은 인과 추론의 첫 단계일 뿐입니다. [cite_start]유효한 조정 집합 <img src="https://latex.codecogs.com/png.latex?Z">를 찾았다면(Identification 단계 완료), 이제 유한한 샘플(Finite samples)로부터 목표 효과를 계산하는 <strong>추정(Estimation)</strong> 단계로 넘어가야 합니다. [cite: 741, 747, 753, 759]</p>
<p>대표적인 추정 기법은 다음과 같습니다: * <strong>IPW (Inverse Probability Weighting):</strong> 성향 점수(Propensity Score)를 이용한 가중치 부여. * <strong>Standardization (G-computation):</strong> 조건부 평균을 모델링하여 전체 평균 계산. * <strong>Doubly Robust Estimators:</strong> 위 두 방법을 결합하여 강건성 확보.</p>
<p>결국 Adjustment Criterion은 <strong>“무엇을 측정하고 모델링에 포함해야 하는가?”</strong>에 대한 명확한 가이드라인을 제시함으로써, 이후의 통계적 추정이 편향 없이 수행될 수 있는 기반을 마련해 줍니다.</p>
<hr>
</section>
</section>
<section id="conclusion" class="level1">
<h1>4. Conclusion</h1>
<p>이로써 Adjustment Criterion에 대한 긴 여정을 마칩니다. 우리는 그래프 이론에서 출발하여 알고리즘을 거쳐, 잠재적 결과(Potential Outcome)와의 연결고리까지 확인했습니다.</p>
<p>이 시리즈의 핵심 메시지는 다음과 같습니다: <strong>“데이터만으로는 인과관계를 말할 수 없다. 하지만 현실에 대한 가정(Graph)이 있다면, 우리는 수학적으로 올바른 통제 변수를 찾아낼 수 있다.”</strong></p>
<p>다음 시리즈에서는 식별된 인과 효과를 실제로 계산하는 <strong>추정(Estimation)</strong> 방법론에 대해 더 깊이 다뤄보도록 하겠습니다.</p>
<hr>
<section id="누락-방지-검증-missing-content-check" class="level3">
<h3 class="anchored" data-anchor-id="누락-방지-검증-missing-content-check">누락 방지 검증 (Missing Content Check)</h3>
<p>강의 자료(PDF 0504 파일)의 내용을 기반으로 아래 항목들이 포함되었는지 확인합니다.</p>
<ul>
<li><label><input type="checkbox" checked=""><strong>Conditional Ignorability 정의:</strong> <img src="https://latex.codecogs.com/png.latex?Y_x%20%5Cperp%5C!%5C!%5Cperp%20X%20%7C%20%5Bcite_start%5DZ"> 표기 및 의미 설명 [cite: 723-724, 733]</label></li>
<li>[cite_start][x] <strong>Counterfactual Notation과 SCM의 연결:</strong> <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x),z)%20=%20P(y%7Cx,z)"> 등식 [cite: 729, 734]</li>
<li>[cite_start][x] <strong>Adjustment Criterion의 역할:</strong> PO 프레임워크의 가정을 그래프 모델로 정당화(Justification)함 [cite: 735]</li>
<li>[cite_start][x] <strong>Summary - Popularity:</strong> Adjustment의 보편성 [cite: 738]</li>
<li>[cite_start][x] <strong>Summary - Validity:</strong> Back-door/Adjustment Criterion의 역할 [cite: 739]</li>
<li>[cite_start][x] <strong>Summary - Algorithm:</strong> 체계적인 탐색 가능성 [cite: 740]</li>
<li>[cite_start][x] <strong>Summary - Estimation:</strong> IPW 등 추정 기법과의 연계 [cite: 741]</li>
</ul>
<p><strong>Note:</strong> 제공된 PDF의 모든 핵심 내용(페이지 1-8)이 본 포스트에 반영되었습니다.</p>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L05/part-04/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 06. The Causal Calculus (Part 1)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L06/part-01/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<ul>
<li>인과추론(Causal Inference)의 핵심 목표 중 하나는 관측 데이터(Observational Data)로부터 개입(Intervention)의 효과를 추정하는 것입니다.</li>
<li>이를 <strong>식별(Identification)</strong> 문제라고 합니다.</li>
<li>우리는 변수 <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 인과적 효과를 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">로 표기합니다.</li>
<li>하지만 현실 세계에서 우리는 <img src="https://latex.codecogs.com/png.latex?do(x)">(강제적 개입)가 적용된 데이터가 아니라, 자연스럽게 발생한 결합 확률 분포 <img src="https://latex.codecogs.com/png.latex?P(V)">만을 관측할 수 있습니다.</li>
<li>이번 포스트에서는 Judea Pearl의 Causal Calculus 프레임워크를 기반으로, <strong>구조적 인과 모델(Semi-Markovian Models)</strong> 하에서 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 계산하는 체계적인 접근법을 다룹니다.</li>
<li>특히 다음 세 가지 대표적인 그래프 구조를 통해 식별 가능성(Identifiability)을 분석합니다.
<ul>
<li><ol type="1">
<li><strong>Back-door Graph:</strong> 식별 가능 (Identifiable)</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Bow Graph:</strong> 식별 불가능 (Non-Identifiable)</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Front-door Graph:</strong> 식별 가능 (Identifiable)</li>
</ol></li>
</ul></li>
</ul>
</section>
<section id="truncated-factorization-in-semi-markovian-models" class="level1">
<h1>2. Truncated Factorization in Semi-Markovian Models</h1>
<section id="structural-causal-model-scm" class="level2">
<h2 class="anchored" data-anchor-id="structural-causal-model-scm">2.1. Structural Causal Model (SCM)</h2>
<ul>
<li>변수 집합 <img src="https://latex.codecogs.com/png.latex?V">와 관측되지 않은 잠재 변수(Latent Variables) 집합 <img src="https://latex.codecogs.com/png.latex?U">가 있을 때, 구조적 인과 모델 <img src="https://latex.codecogs.com/png.latex?M">은 다음과 같은 함수들의 집합으로 정의됩니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0Av_i%20=%20f_i(pa_i,%20u_i),%20%5Cquad%20%5Ctext%7Bfor%20each%20%7D%20V_i%20%5Cin%20V%0A"></p>
<ul>
<li>여기서 <img src="https://latex.codecogs.com/png.latex?pa_i">는 <img src="https://latex.codecogs.com/png.latex?V_i">의 부모 변수(parents)를 의미합니다. 전체 결합 확률 분포 <img src="https://latex.codecogs.com/png.latex?P(v)">는 잠재 변수 <img src="https://latex.codecogs.com/png.latex?u">에 대한 합(또는 적분)을 통해 다음과 같이 표현됩니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(v)%20=%20%5Csum_%7Bu%7D%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%7C%20pa_i,%20u_i)%20P(u)%0A"></p>
</section>
<section id="interventions-and-truncated-factorization" class="level2">
<h2 class="anchored" data-anchor-id="interventions-and-truncated-factorization">2.2. Interventions and Truncated Factorization</h2>
<ul>
<li><p>변수 <img src="https://latex.codecogs.com/png.latex?X">에 특정 값 <img src="https://latex.codecogs.com/png.latex?x">를 강제로 할당하는 개입 <img src="https://latex.codecogs.com/png.latex?do(X=x)">가 발생하면, <img src="https://latex.codecogs.com/png.latex?X">를 결정하던 기존의 구조적 함수 <img src="https://latex.codecogs.com/png.latex?X%20%5Cleftarrow%20f_X(%5Cdots)">는 삭제되고 상수 <img src="https://latex.codecogs.com/png.latex?X=x">로 대체됩니다.</p></li>
<li><p>이를 그래프 관점에서는 <img src="https://latex.codecogs.com/png.latex?X">로 들어오는 모든 화살표를 제거하는 것으로 해석할 수 있습니다.</p></li>
<li><p>이때, 개입 후의 분포 <img src="https://latex.codecogs.com/png.latex?P(v'%7Cdo(x))">는 <strong>Truncated Factorization</strong> 공식에 의해 다음과 같이 주어집니다.</p></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(v'%7Cdo(x))%20=%20%5Csum_%7Bu%7D%20%5Cprod_%7BV_i%20%5Cin%20V%20%5Csetminus%20X%7D%20P(v_i%20%7C%20pa_i,%20u_i)%20P(u)%0A"></p>
<ul>
<li>즉, <img src="https://latex.codecogs.com/png.latex?X">와 관련된 확률 항만 제거되고 나머지 메커니즘은 불변(Invariant)한다는 가정입니다.</li>
<li>관심 있는 결과 변수 집합 <img src="https://latex.codecogs.com/png.latex?Y">에 대한 효과는 <img src="https://latex.codecogs.com/png.latex?V">에서 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">를 제외한 나머지 변수들에 대해 주변화(marginalization)하여 구할 수 있습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bv%20%5Csetminus%20(x%20%5Ccup%20y)%7D%20%5Csum_%7Bu%7D%20%5Cprod_%7BV_i%20%5Cin%20V%20%5Csetminus%20X%7D%20P(v_i%20%7C%20pa_i,%20u_i)%20P(u)%0A"></p>
<hr>
</section>
</section>
<section id="case-study-1-the-back-door-graph" class="level1">
<h1>3. Case Study 1: The Back-door Graph</h1>
<p>가장 기본적인 교란 요인(Confounder) 구조를 살펴보겠습니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L06/part-01/images/backdoor_graph_structure.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: Back-door Graph Structure. Z는 X와 Y의 공통 원인(Confounder)으로 작용하며, X에서 Y로 가는 직접 경로도 존재합니다. 이 구조에서는 Z가 Back-door path를 형성합니다.</figcaption>
</figure>
</div>
<section id="model-setup" class="level2">
<h2 class="anchored" data-anchor-id="model-setup">3.1. Model Setup</h2>
<p>이 모델의 SCM은 다음과 같습니다[cite: 28]. <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BH%7D%20=%20%5Cbegin%7Bcases%7D%0AZ%20%5Cleftarrow%20f_Z(u_z)%20%5C%5C%0AX%20%5Cleftarrow%20f_X(z,%20u_x)%20%5C%5C%0AY%20%5Cleftarrow%20f_Y(x,%20z,%20u_y)%0A%5Cend%7Bcases%7D%0A"></p>
<p>관측 분포 <img src="https://latex.codecogs.com/png.latex?P(v)">는 다음과 같이 분해됩니다[cite: 29]. <img src="https://latex.codecogs.com/png.latex?%0AP(x,%20y,%20z)%20=%20%5Csum_%7Bu%7D%20P(z%7Cu_z)%20P(x%7Cz,%20u_x)%20P(y%7Cx,%20z,%20u_y)%20P(u)%0A"></p>
</section>
<section id="derivation-of-intervention-distribution" class="level2">
<h2 class="anchored" data-anchor-id="derivation-of-intervention-distribution">3.2. Derivation of Intervention Distribution</h2>
<p>개입 <img src="https://latex.codecogs.com/png.latex?do(X=x)">가 발생하면, <img src="https://latex.codecogs.com/png.latex?X">의 결정 식은 <img src="https://latex.codecogs.com/png.latex?X=x">로 고정되고 <img src="https://latex.codecogs.com/png.latex?X">로 향하는 <img src="https://latex.codecogs.com/png.latex?Z">의 영향력은 사라집니다. 우리는 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 구하고자 합니다[cite: 40].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bu%7D%20P(z%7Cu_z)%20P(y%7Cx,%20z,%20u_y)%20P(u)%0A"></p>
<p>여기서 잠재 변수 <img src="https://latex.codecogs.com/png.latex?u">를 <img src="https://latex.codecogs.com/png.latex?u_z,%20u_x,%20u_y">로 나누어 합을 전개하면 다음과 같습니다[cite: 42].</p>
<ol type="1">
<li><strong>Decomposition:</strong> <img src="https://latex.codecogs.com/png.latex?%0A=%20%5Csum_%7Bu_z%7D%20P(z%7Cu_z)P(u_z)%20%5Csum_%7Bu_y%7D%20P(y%7Cx,z,u_y)P(u_y)%20%5Csum_%7Bu_x%7D%20P(u_x)%0A"></li>
<li><strong>Simplification:</strong> <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bu_x%7D%20P(u_x)%20=%201"> 이므로 소거됩니다. 또한 <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bu_z%7D%20P(z%7Cu_z)P(u_z)%20=%20P(z)"> 입니다.</li>
<li><strong>Result:</strong> <img src="https://latex.codecogs.com/png.latex?%0A=%20P(z)%20%5Csum_%7Bu_y%7D%20P(y%7Cx,z,u_y)%20P(u_y)%0A"> 이때, <img src="https://latex.codecogs.com/png.latex?P(y%7Cx,z)%20=%20%5Csum_%7Bu_y%7D%20P(y%7Cx,z,u_y)P(u_y)"> 이므로 최종적으로 다음과 같은 식을 얻습니다[cite: 45, 46].</li>
</ol>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(y%7Cx,%20z)%20P(z)%0A"></p>
<p>이것이 바로 유명한 <strong>Back-door Adjustment Formula</strong>입니다. <img src="https://latex.codecogs.com/png.latex?Z">를 통제(conditioning)하고 <img src="https://latex.codecogs.com/png.latex?Z">의 주변 확률로 가중 평균을 냄으로써 인과 효과를 식별할 수 있습니다[cite: 47].</p>
<hr>
</section>
</section>
<section id="case-study-2-the-bow-graph-non-identifiable" class="level1">
<h1>4. Case Study 2: The Bow Graph (Non-Identifiable)</h1>
<p>만약 관측되지 않은 교란 변수(Unobserved Confounder)가 존재하면 어떻게 될까요?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L06/part-01/images/bow_graph_structure.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: Bow Graph Structure. X에서 Y로 가는 직접 경로 외에, 관측되지 않은 교란 변수 U’이 X와 Y 모두에게 영향을 미치고 있습니다. 그래프 모양이 활(Bow)과 같아 Bow Graph라 불립니다.</figcaption>
</figure>
</div>
<section id="model-setup-1" class="level2">
<h2 class="anchored" data-anchor-id="model-setup-1">4.1. Model Setup</h2>
<p>Bow Graph의 SCM은 다음과 같습니다[cite: 55]. 여기서 <img src="https://latex.codecogs.com/png.latex?u'">은 관측 불가능한 공통 원인입니다. <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BH%7D%20=%20%5Cbegin%7Bcases%7D%0AX%20%5Cleftarrow%20f_X(u',%20u_x)%20%5C%5C%0AY%20%5Cleftarrow%20f_Y(x,%20u',%20u_y)%0A%5Cend%7Bcases%7D%0A"></p>
</section>
<section id="attempting-derivation" class="level2">
<h2 class="anchored" data-anchor-id="attempting-derivation">4.2. Attempting Derivation</h2>
<p><img src="https://latex.codecogs.com/png.latex?do(X=x)">에 대한 Truncated Factorization을 적용해 봅시다[cite: 66].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bu%7D%20P(y%7Cx,%20u',%20u_y)%20P(u)%0A"></p>
<p>이 식을 전개하면 다음과 같습니다[cite: 68, 69].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0AP(y%7Cdo(x))%20&amp;=%20%5Csum_%7Bu'%7D%20P(u')%20%5Cleft(%20%5Csum_%7Bu_y%7D%20P(y%7Cx,%20u',%20u_y)%20P(u_y)%20%5Cright)%20%5Cleft(%20%5Csum_%7Bu_x%7D%20P(u_x)%20%5Cright)%20%5C%5C%0A&amp;=%20%5Csum_%7Bu'%7D%20P(y%7Cx,%20u')%20P(u')%0A%5Cend%7Baligned%7D%0A"></p>
<p><strong>문제점:</strong> 위 식의 우변에 있는 <img src="https://latex.codecogs.com/png.latex?u'">은 관측되지 않는 잠재 변수입니다. 우리는 데이터에서 <img src="https://latex.codecogs.com/png.latex?P(u')">이나 <img src="https://latex.codecogs.com/png.latex?P(y%7Cx,%20u')">를 추정할 수 없습니다. 따라서 이 경우 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">는 관측 데이터 <img src="https://latex.codecogs.com/png.latex?P(x,y)">만으로는 <strong>식별 불가능(Non-Identifiable)</strong>합니다.</p>
<hr>
</section>
</section>
<section id="case-study-3-the-front-door-graph" class="level1">
<h1>5. Case Study 3: The Front-door Graph</h1>
<p>관측되지 않은 교란 변수 <img src="https://latex.codecogs.com/png.latex?U'">이 존재하더라도, <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이를 매개하는 변수 <img src="https://latex.codecogs.com/png.latex?Z">가 있다면 식별이 가능할 수 있습니다. 이를 <strong>Front-door Criterion</strong>이라 합니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L06/part-01/images/frontdoor_graph_structure.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3: Front-door Graph Structure. X와 Y 사이에 관측되지 않은 교란 변수 U’이 존재하여 직접적인 Back-door 조정은 불가능합니다. 그러나 X가 Z에 영향을 주고, Z가 Y에 영향을 주는 경로가 존재하며, Z는 U’의 영향을 받지 않습니다.</figcaption>
</figure>
</div>
<section id="model-setup-2" class="level2">
<h2 class="anchored" data-anchor-id="model-setup-2">5.1. Model Setup</h2>
<p>Front-door 모델의 구조는 다음과 같습니다[cite: 82]. <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BM%7D%20=%20%5Cbegin%7Bcases%7D%0AX%20%5Cleftarrow%20f_X(u_x,%20u')%20%5C%5C%0AZ%20%5Cleftarrow%20f_Z(x,%20u_z)%20%5C%5C%0AY%20%5Cleftarrow%20f_Y(z,%20u',%20u_y)%0A%5Cend%7Bcases%7D%0A"> 여기서 중요한 특징은 <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?u'">의 영향을 받지 않고 오직 <img src="https://latex.codecogs.com/png.latex?x">와 <img src="https://latex.codecogs.com/png.latex?u_z">에 의해서만 결정된다는 점입니다[cite: 82].</p>
</section>
<section id="step-by-step-derivation" class="level2">
<h2 class="anchored" data-anchor-id="step-by-step-derivation">5.2. Step-by-Step Derivation</h2>
<p>우리의 목표는 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 관측 가능한 확률들의 조합으로 표현하는 것입니다.</p>
<section id="step-1-truncated-factorization" class="level3">
<h3 class="anchored" data-anchor-id="step-1-truncated-factorization">Step 1: Truncated Factorization</h3>
<p>개입 후의 분포는 다음과 같습니다[cite: 91]. <img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bu%7D%20P(x%7Cu',%20u_x)%20P(z%7Cx,%20u_z)%20P(y%7Cz,%20u',%20u_y)%20P(u)%0A"> 하지만 개입 <img src="https://latex.codecogs.com/png.latex?do(X=x)"> 하에서 <img src="https://latex.codecogs.com/png.latex?P(x%7Cu',%20u_x)"> 항은 삭제되거나 1이 되므로(intervention에 의해 고정됨), 식은 다음과 같이 정리됩니다[cite: 95].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bu%7D%20P(z%7Cx,%20u_z)%20P(y%7Cz,%20u',%20u_y)%20P(u)%0A"></p>
</section>
<section id="step-2-grouping-terms" class="level3">
<h3 class="anchored" data-anchor-id="step-2-grouping-terms">Step 2: Grouping Terms</h3>
<p>잠재 변수들을 그룹화하여 전개합니다[cite: 96]. <img src="https://latex.codecogs.com/png.latex?%0A=%20%5Cleft(%20%5Csum_%7Bu_z%7D%20P(z%7Cx,%20u_z)%20P(u_z)%20%5Cright)%20%5Cleft(%20%5Csum_%7Bu',%20u_y%7D%20P(y%7Cz,%20u',%20u_y)%20P(u',%20u_y)%20%5Cright)%20%5Cleft(%20%5Csum_%7Bu_x%7D%20P(u_x)%20%5Cright)%0A"> 마지막 항은 1이 되어 사라집니다. 첫 번째 항은 <img src="https://latex.codecogs.com/png.latex?P(z%7Cx)">가 됩니다 (왜냐하면 <img src="https://latex.codecogs.com/png.latex?Z">는 <img src="https://latex.codecogs.com/png.latex?X"> 외의 다른 교란 변수 <img src="https://latex.codecogs.com/png.latex?U'">의 영향을 받지 않기 때문입니다).</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A=%20P(z%7Cx)%20%5Csum_%7Bu',%20u_y%7D%20P(y%7Cz,%20u',%20u_y)%20P(u_y%7Cu')%20P(u')%0A"></p>
<p>내부의 <img src="https://latex.codecogs.com/png.latex?u_y">에 대한 합을 계산하면 <img src="https://latex.codecogs.com/png.latex?P(y%7Cz,%20u')">이 됩니다[cite: 97, 98]. <img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(z%7Cx)%20%5Csum_%7Bu'%7D%20P(y%7Cz,%20u')%20P(u')%0A"> 아직 <img src="https://latex.codecogs.com/png.latex?u'">이 남아 있습니다. 이 식을 어떻게 관측 가능한 변수로 바꿀 수 있을까요?</p>
</section>
<section id="step-3-leveraging-x" class="level3">
<h3 class="anchored" data-anchor-id="step-3-leveraging-x">Step 3: Leveraging X’</h3>
<p>여기서 핵심 트릭은 <img src="https://latex.codecogs.com/png.latex?X">의 값을 <img src="https://latex.codecogs.com/png.latex?x'">로 관측했을 때의 정보를 이용하는 것입니다. <img src="https://latex.codecogs.com/png.latex?P(y%7Cz,%20x')">를 생각해 봅시다. <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?x'">일 때 <img src="https://latex.codecogs.com/png.latex?Z">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 관계를 이용해 <img src="https://latex.codecogs.com/png.latex?u'"> 항을 <img src="https://latex.codecogs.com/png.latex?x'">에 대한 식으로 변환할 수 있습니다. 유도 과정을 따라가면 다음과 같은 최종 식을 얻습니다 [cite: 130-134].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bu'%7D%20P(y%7Cz,%20u')%20P(u')%20=%20%5Csum_%7Bx'%7D%20P(y%7Cz,%20x')%20P(x')%0A"> <em>(상세 유도: <img src="https://latex.codecogs.com/png.latex?u'">은 <img src="https://latex.codecogs.com/png.latex?x'">와 독립적이지 않을 수 있지만, Back-door path를 차단하는 <img src="https://latex.codecogs.com/png.latex?z">와 <img src="https://latex.codecogs.com/png.latex?x">의 관계를 이용해 <img src="https://latex.codecogs.com/png.latex?P(u')"> 성분을 <img src="https://latex.codecogs.com/png.latex?P(x')"> 성분으로 대체하여 표현함)</em></p>
</section>
<section id="step-4-final-front-door-formula" class="level3">
<h3 class="anchored" data-anchor-id="step-4-final-front-door-formula">Step 4: Final Front-door Formula</h3>
<p>결과적으로 다음과 같은 식별 공식을 얻습니다[cite: 134].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(z%7Cx)%20%5Csum_%7Bx'%7D%20P(y%7Cz,%20x')%20P(x')%0A"></p>
<p>이 공식은 관측되지 않은 교란 변수 <img src="https://latex.codecogs.com/png.latex?U'">이 존재하더라도, <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Z%20%5Cto%20Y"> 경로를 통해 인과 효과를 두 단계로 나누어(<img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Z"> 그리고 <img src="https://latex.codecogs.com/png.latex?Z%20%5Cto%20Y">) 추정함으로써 전체 효과를 계산할 수 있음을 보여줍니다.</p>
<hr>
</section>
</section>
</section>
<section id="summary" class="level1">
<h1>6. Summary</h1>
<p>이번 포스트에서는 구조적 인과 모델과 Do-Calculus의 기초적인 식별 전략들을 살펴보았습니다.</p>
<ul>
<li><strong>Truncated Factorization:</strong> 개입이 발생했을 때 확률 분포가 어떻게 변하는지를 수식화한 기본 원리입니다.</li>
<li><strong>Back-door Criterion:</strong> 교란 요인을 관측할 수 있다면, 이를 통제(Conditioning)하여 인과 효과를 식별합니다. (<img src="https://latex.codecogs.com/png.latex?Z">로 조정)</li>
<li><strong>Front-door Criterion:</strong> 교란 요인을 관측할 수 없더라도, 매개 변수 <img src="https://latex.codecogs.com/png.latex?Z">가 존재하고 특정 조건을 만족하면 인과 효과를 식별할 수 있습니다. (<img src="https://latex.codecogs.com/png.latex?Z">와 <img src="https://latex.codecogs.com/png.latex?X'">로 조정)</li>
</ul>
<p>다음 포스트에서는 이러한 규칙들을 일반화한 <strong>General Do-Calculus Rules</strong>에 대해 더 깊이 다루도록 하겠습니다.</p>
<hr>
<section id="누락-방지-검증-체크리스트" class="level3">
<h3 class="anchored" data-anchor-id="누락-방지-검증-체크리스트">누락 방지 검증 체크리스트</h3>
<ul class="task-list">
<li><label><input type="checkbox" checked=""><strong>강의 핵심 개념 포함:</strong> Truncated Factorization, Back-door, Bow Graph, Front-door Graph 모두 포함됨.</label></li>
<li><label><input type="checkbox" checked=""><strong>수식 유도 과정:</strong> 결과 식뿐만 아니라 <img src="https://latex.codecogs.com/png.latex?u">에 대한 합(summation) 분해 과정을 단계별로 서술함.</label></li>
<li><label><input type="checkbox" checked=""><strong>이미지 Placeholder:</strong> 각 그래프(Triangle, Bow, Front-door)에 대한 이미지 삽입 구문 및 상세 설명 포함.</label></li>
<li><label><input type="checkbox" checked=""><strong>출처 표기:</strong> 강의 자료의 내용을 인용할 때마다 `` 형식을 준수함.</label></li>
<li><label><input type="checkbox" checked=""><strong>내용 범위:</strong> 제공된 PDF 텍스트가 Front-door Derivation(약 11페이지 분량)까지이므로, 해당 범위까지 충실히 작성하고 마무리함.</label></li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L06/part-01/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 06. The Causal Calculus (Part 2)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L06/part-02/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>이전 포스트들에서 우리는 Back-door와 Front-door 기준을 통해 특정 그래프 구조에서 인과 효과를 식별하는 방법을 배웠습니다. 하지만 모든 인과 모형이 이러한 표준적인 형태를 띠는 것은 아닙니다. 더욱 복잡한 그래프 구조에서 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 식별하기 위해서는 보다 일반화된 규칙이 필요합니다.</p>
<p>이번 포스트에서는 Judea Pearl의 <strong>Do-Calculus</strong>가 등장하게 된 배경과, 이를 구성하는 세 가지 핵심 통찰(Three Insights)에 대해 다룹니다. [cite_start]이는 인과적 질문(Query)을 관측 가능한 통계적 추정량(Estimand)으로 변환하는 체계적인(Systematic) 접근법의 기초가 됩니다[cite: 147].</p>
</section>
<section id="the-syntactical-goal-on-identification" class="level1">
<h1>2. The Syntactical Goal on Identification</h1>
<section id="the-problem-definition" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-definition">2.1. The Problem Definition</h2>
<p>Back-door와 Front-door 설정 모두에서 우리의 목표는 하나였습니다. [cite_start]바로 개입(Intervention)에 의한 확률 분포 <img src="https://latex.codecogs.com/png.latex?Q%20=%20P(y%7Cdo(x))">를 관측 데이터의 분포 <img src="https://latex.codecogs.com/png.latex?P(v)">만으로 계산 가능한 식(expression)으로 환원(reduce)하는 것입니다[cite: 152, 160].</p>
</section>
<section id="two-approaches" class="level2">
<h2 class="anchored" data-anchor-id="two-approaches">2.2. Two Approaches</h2>
<p>이 목표를 달성하기 위한 방법은 크게 두 가지로 나뉩니다.</p>
<ol type="1">
<li><p><strong>Algebraic Approach (Truncated Factorization):</strong> [cite_start]구조적 인과 모델(SCM)의 Truncated Factorization 공식을 사용하여, 잠재 변수 <img src="https://latex.codecogs.com/png.latex?U">가 포함되지 않은(U-free) 표현식을 유도하는 방법입니다[cite: 156, 161]. 이는 앞서 Back-door/Front-door 공식을 유도할 때 사용했던 방식입니다.</p></li>
<li><p><strong>Axiomatic Approach (Do-Calculus):</strong> [cite_start]잠재 변수 <img src="https://latex.codecogs.com/png.latex?U">를 직접 다루거나 매번 적분을 수행하는 대신, <img src="https://latex.codecogs.com/png.latex?do(%5Ccdot)"> 연산자를 포함한 식을 <img src="https://latex.codecogs.com/png.latex?do(%5Ccdot)">가 없는 식(do-free expression)으로 변환하는 <strong>일련의 규칙(rules) 또는 공리(axioms)</strong>를 사용하는 방법입니다[cite: 157, 162].</p></li>
</ol>
<p>[cite_start]우리는 이 두 번째 접근법, 즉 타겟 효과(Target Effect)와의 등가성을 유지하면서 <img src="https://latex.codecogs.com/png.latex?do"> 표현식을 체계적으로 변환할 수 있는 규칙에 관심을 가질 것입니다[cite: 163].</p>
</section>
</section>
<section id="prelude-conditional-independence-in-submodels" class="level1">
<h1>3. Prelude: Conditional Independence in Submodels</h1>
<p>본격적인 규칙을 다루기 전에, 개입 <img src="https://latex.codecogs.com/png.latex?do(X=x)">가 가해진 세상에서의 조건부 독립성이 그래프 상에서 어떻게 표현되는지 정의해야 합니다.</p>
<section id="submodel-mathcalh_x-and-graph-mathcalg_overlinex" class="level2">
<h2 class="anchored" data-anchor-id="submodel-mathcalh_x-and-graph-mathcalg_overlinex">3.1. Submodel <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BH%7D_x"> and Graph <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D"></h2>
<p>[cite_start]<img src="https://latex.codecogs.com/png.latex?do(X=x)">라는 행위는 모델 내에서 <img src="https://latex.codecogs.com/png.latex?X">를 결정하는 구조적 함수 <img src="https://latex.codecogs.com/png.latex?f_X">를 상수 <img src="https://latex.codecogs.com/png.latex?x">로 대체하는 것을 의미합니다[cite: 189, 201]. <img src="https://latex.codecogs.com/png.latex?%0AX%20%5Cleftarrow%20x%0A"> [cite_start]이를 그래프 관점에서 보면, 변수 <img src="https://latex.codecogs.com/png.latex?X">가 더 이상 다른 변수(부모 변수)들의 영향을 받지 않음을 의미합니다[cite: 196, 202]. 따라서 원래 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D">에서 <strong><img src="https://latex.codecogs.com/png.latex?X">로 들어오는 모든 화살표(incoming edges)를 제거</strong>한 그래프를 생각할 수 있으며, 이를 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">라고 표기합니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L06/part-02/images/submodel_graph_Gx_bar.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: Submodel Graph <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">. 점선 화살표는 원래 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D">에는 존재했으나, 개입 <img src="https://latex.codecogs.com/png.latex?do(X)">로 인해 <img src="https://latex.codecogs.com/png.latex?X">가 상수로 고정되면서 제거된 경로를 나타냅니다. <img src="https://latex.codecogs.com/png.latex?X">는 이제 외부 변수의 영향을 받지 않는 고립된 노드(부모가 없는 노드)처럼 행동합니다.</figcaption>
</figure>
</div>
</section>
<section id="independence-condition" class="level2">
<h2 class="anchored" data-anchor-id="independence-condition">3.2. Independence Condition</h2>
<p>개입된 세상 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BH%7D_x">에서의 조건부 독립성은 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">에서의 d-separation으로 해석할 수 있습니다. [cite_start]특히, <img src="https://latex.codecogs.com/png.latex?X">는 이제 상수 <img src="https://latex.codecogs.com/png.latex?x">로 고정되었으므로, 이는 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">에서 <img src="https://latex.codecogs.com/png.latex?X=x">로 조건부(conditioning)를 건 것과 유사하게 동작합니다[cite: 203, 219].</p>
<p>[cite_start]따라서, <img src="https://latex.codecogs.com/png.latex?do(x)"> 하에서의 조건부 독립성 <img src="https://latex.codecogs.com/png.latex?(A%20%5Cperp%5C!%5C!%5C!%5Cperp%20B%20%7C%20C)">는 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D"> 그래프상에서의 분리(separation)와 동치입니다[cite: 220, 221].</p>
</section>
</section>
<section id="three-insights-for-identification" class="level1">
<h1>4. Three Insights for Identification</h1>
<p>Do-Calculus의 세 가지 규칙은 다음의 세 가지 직관적인 상황(Insights)에서 유도됩니다.</p>
<section id="insight-1-addingremoving-observations" class="level2">
<h2 class="anchored" data-anchor-id="insight-1-addingremoving-observations">4.1. Insight 1: Adding/Removing Observations</h2>
<p>첫 번째 통찰은 <strong>“언제 관측 변수 <img src="https://latex.codecogs.com/png.latex?Z">를 무시해도 되는가?”</strong>에 대한 것입니다.</p>
<p>[cite_start]원래 모델에서는 <img src="https://latex.codecogs.com/png.latex?Z">와 <img src="https://latex.codecogs.com/png.latex?Y">가 서로 연관되어 있어 분리할 수 없다고 가정해 봅시다(예: <img src="https://latex.codecogs.com/png.latex?Z%20%5Cnot%5Cperp%5C!%5C!%5C!%5Cperp%20Y%20%7C%20X">)[cite: 226]. [cite_start]하지만 <img src="https://latex.codecogs.com/png.latex?X">에 개입을 가한 <img src="https://latex.codecogs.com/png.latex?do(X)"> 세상(즉, <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">)에서 <img src="https://latex.codecogs.com/png.latex?Y">와 <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?X">에 의해 d-separated 된다면, <img src="https://latex.codecogs.com/png.latex?Z">를 관측하는 것은 <img src="https://latex.codecogs.com/png.latex?Y">의 확률 분포에 아무런 추가 정보를 주지 않습니다[cite: 228, 229].</p>
<section id="the-rule" class="level3">
<h3 class="anchored" data-anchor-id="the-rule">The Rule</h3>
<p><img src="https://latex.codecogs.com/png.latex?%0A(Y%20%5Cperp%5C!%5C!%5C!%5Cperp%20Z%20%7C%20X)_%7B%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D%7D%20%5Cimplies%20P(y%7Cdo(x),%20z)%20=%20P(y%7Cdo(x))%0A"> 즉, 개입된 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">에서 조건부 독립이 성립하면, <img src="https://latex.codecogs.com/png.latex?do(x)"> 식에서 조건절의 <img src="https://latex.codecogs.com/png.latex?z">를 제거할 수 있습니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L06/part-02/images/insight1_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: Insight 1 Graph Structure. <img src="https://latex.codecogs.com/png.latex?X">에 개입하여 <img src="https://latex.codecogs.com/png.latex?X">로 들어오는 화살표가 제거된 상황(<img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">)입니다. 이 그래프에서 <img src="https://latex.codecogs.com/png.latex?X">가 주어졌을 때 <img src="https://latex.codecogs.com/png.latex?Z">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 모든 경로가 차단된다면(d-separated), <img src="https://latex.codecogs.com/png.latex?Z">는 <img src="https://latex.codecogs.com/png.latex?Y">에 대한 추가적인 정보를 제공하지 않습니다.</figcaption>
</figure>
</div>
</section>
<section id="derivation" class="level3">
<h3 class="anchored" data-anchor-id="derivation">Derivation</h3>
<p>Truncated Factorization을 이용해 이를 증명할 수 있습니다. 개입 분포 <img src="https://latex.codecogs.com/png.latex?P(y,z%7Cdo(x))">는 다음과 같이 주어집니다. <img src="https://latex.codecogs.com/png.latex?%0AP(y,z%7Cdo(x))%20=%20%5Csum_%7Bu%7D%20P(z%7Cu_z)%20P(y%7Cx,%20u_y,%20u')%20P(u)%20=%20P(z)%20%5Csum_%7Bu'%7D%20P(y%7Cx,%20u')%20P(u')%0A"> [cite_start][cite: 240]</p>
<p>이때 조건부 확률의 정의에 따라: <img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x),%20z)%20=%20%5Cfrac%7BP(y,z%7Cdo(x))%7D%7BP(z%7Cdo(x))%7D%0A"> [cite_start]분모인 <img src="https://latex.codecogs.com/png.latex?P(z%7Cdo(x))">를 계산해보면 <img src="https://latex.codecogs.com/png.latex?P(z)">가 나옵니다(모든 <img src="https://latex.codecogs.com/png.latex?y">에 대해 합을 취함)[cite: 252]. <img src="https://latex.codecogs.com/png.latex?%0AP(z%7Cdo(x))%20=%20%5Csum_%7By%7D%20P(z)%20%5Csum_%7Bu'%7D%20P(y%7Cx,%20u')%20P(u')%20=%20P(z)%20%5Ccdot%201%20=%20P(z)%0A"> [cite_start]따라서 분자와 분모의 <img src="https://latex.codecogs.com/png.latex?P(z)">가 약분되어 다음을 얻습니다[cite: 263]. <img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x),%20z)%20=%20%5Csum_%7Bu'%7D%20P(y%7Cx,%20u')%20P(u')%20=%20P(y%7Cdo(x))%0A"></p>
</section>
</section>
<section id="insight-2-actionobservation-exchange" class="level2">
<h2 class="anchored" data-anchor-id="insight-2-actionobservation-exchange">4.2. Insight 2: Action/Observation Exchange</h2>
<p>두 번째 통찰은 <strong>“언제 개입(Action)을 단순 관측(Observation)으로 바꿀 수 있는가?”</strong>입니다. [cite_start]이는 Back-door 기준의 핵심 논리와 맞닿아 있습니다[cite: 273, 286].</p>
<p>[cite_start]만약 <img src="https://latex.codecogs.com/png.latex?Z">를 관측한 상태에서, <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 영향이 오직 인과적 경로(causal paths)를 통해서만 전달되고 교란 요인(confounders)에 의한 영향이 없다면, <img src="https://latex.codecogs.com/png.latex?see(X=x)">는 <img src="https://latex.codecogs.com/png.latex?do(X=x)">와 동일한 효과를 갖습니다[cite: 284, 285].</p>
<section id="the-rule-1" class="level3">
<h3 class="anchored" data-anchor-id="the-rule-1">The Rule</h3>
<p>[cite_start]이 조건은 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Cunderline%7BX%7D%7D"> (X에서 <strong>나가는</strong> 화살표를 제거한 그래프)에서 확인합니다[cite: 288, 308]. <img src="https://latex.codecogs.com/png.latex?%0A(Y%20%5Cperp%5C!%5C!%5C!%5Cperp%20X%20%7C%20Z)_%7B%5Cmathcal%7BG%7D_%7B%5Cunderline%7BX%7D%7D%7D%20%5Cimplies%20P(y%7Cdo(x),%20z)%20=%20P(y%7Cx,%20z)%0A"> [cite_start]이것이 성립하면 <img src="https://latex.codecogs.com/png.latex?do(x)">를 일반 조건부 확률 <img src="https://latex.codecogs.com/png.latex?x">로 바꿀 수 있습니다 (Exchange of Action &amp; Observation)[cite: 294, 295].</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L06/part-02/images/insight2_graph_Gx_under.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3: Insight 2 Graph Structure (<img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Cunderline%7BX%7D%7D">). <img src="https://latex.codecogs.com/png.latex?X">에서 <img src="https://latex.codecogs.com/png.latex?Y">로 가는 직접적인 인과 경로(outgoing edge)를 제거한 그래프입니다. 이 상태에서 <img src="https://latex.codecogs.com/png.latex?Z">를 조건부로 했을 때 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">가 독립이라면(d-separated), <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 Back-door path가 모두 차단된 것입니다.</figcaption>
</figure>
</div>
</section>
<section id="derivation-1" class="level3">
<h3 class="anchored" data-anchor-id="derivation-1">Derivation</h3>
<p>Back-door adjustment가 성립하는 구조(<img src="https://latex.codecogs.com/png.latex?Z">가 Back-door path를 차단)를 가정합니다. <img src="https://latex.codecogs.com/png.latex?%0AP(y,%20z%7Cdo(x))%20=%20%5Csum_%7Bu%7D%20P(z%7Cu_z)%20P(y%7Cx,%20z,%20u_y)%20P(u)%20=%20P(z)%20P(y%7Cx,%20z)%0A"> [cite_start][cite: 297] [cite_start]마찬가지로 <img src="https://latex.codecogs.com/png.latex?P(z%7Cdo(x))%20=%20P(z)">입니다[cite: 305, 306]. 따라서 비율을 계산하면: <img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x),%20z)%20=%20%5Cfrac%7BP(z)P(y%7Cx,%20z)%7D%7BP(z)%7D%20=%20P(y%7Cx,%20z)%0A"> [cite_start][cite: 307].</p>
</section>
</section>
<section id="insight-3-addingremoving-actions" class="level2">
<h2 class="anchored" data-anchor-id="insight-3-addingremoving-actions">4.3. Insight 3: Adding/Removing Actions</h2>
<p>세 번째 통찰은 <strong>“언제 개입(Action) 자체가 결과에 아무런 영향을 주지 않아 무시할 수 있는가?”</strong>입니다.</p>
<p>[cite_start]매우 직관적인 사실은, 만약 <img src="https://latex.codecogs.com/png.latex?X">에서 <img src="https://latex.codecogs.com/png.latex?Z">로 가는 인과적 경로(causal path)가 전혀 없다면, <img src="https://latex.codecogs.com/png.latex?X">에 어떤 개입을 하더라도 <img src="https://latex.codecogs.com/png.latex?Z">의 분포는 변하지 않는다는 것입니다[cite: 311].</p>
<section id="the-rule-2" class="level3">
<h3 class="anchored" data-anchor-id="the-rule-2">The Rule</h3>
<p><img src="https://latex.codecogs.com/png.latex?%0A(Z%20%5Cperp%5C!%5C!%5C!%5Cperp%20X)_%7B%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D%7D%20%5Cimplies%20P(z%7Cdo(x))%20=%20P(z)%0A"> [cite_start]개입된 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">에서 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Z">가 독립이라면(즉, 연결된 경로가 없다면), <img src="https://latex.codecogs.com/png.latex?do(x)">라는 행위 자체를 식에서 제거할 수 있습니다[cite: 319, 321].</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L06/part-02/images/insight3_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 4: Insight 3 Graph Structure. <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Z"> 사이에 인과적 연결이 없는 상황을 묘사합니다. <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">에서 <img src="https://latex.codecogs.com/png.latex?X">에서 <img src="https://latex.codecogs.com/png.latex?Z">로 가는 경로가 없다면, <img src="https://latex.codecogs.com/png.latex?X">에 대한 조작은 <img src="https://latex.codecogs.com/png.latex?Z">의 분포에 영향을 미치지 않습니다.</figcaption>
</figure>
</div>
</section>
<section id="derivation-2" class="level3">
<h3 class="anchored" data-anchor-id="derivation-2">Derivation</h3>
<p>개입 분포 <img src="https://latex.codecogs.com/png.latex?P(z%7Cdo(x))">를 주변화(marginalization)를 통해 전개하면: <img src="https://latex.codecogs.com/png.latex?%0AP(z%7Cdo(x))%20=%20%5Csum_%7By%7D%20%5Csum_%7Bu%7D%20P(z%7Cu_%7Bzy%7D,%20u_%7Bzx%7D)%20P(y%7Cx,%20u_%7Bzy%7D)%20P(u)%0A"> [cite_start]여기서 <img src="https://latex.codecogs.com/png.latex?Z">의 결정 식에는 <img src="https://latex.codecogs.com/png.latex?x">가 관여하지 않으므로, <img src="https://latex.codecogs.com/png.latex?u">에 대한 합을 정리하면 <img src="https://latex.codecogs.com/png.latex?P(z)">가 그대로 유도됩니다[cite: 332]. <img src="https://latex.codecogs.com/png.latex?%0A=%20%5Csum_%7Bu%7D%20P(z%7Cu)%20P(u)%20=%20P(z)%0A"> (상세 유도 과정에서 <img src="https://latex.codecogs.com/png.latex?y">와 관련된 항들은 합쳐져서 1이 됩니다).</p>
</section>
</section>
</section>
<section id="summary" class="level1">
<h1>5. Summary</h1>
<p>이번 포스트에서는 복잡한 인과 효과 식별 문제를 풀기 위한 기초 작업으로 세 가지 통찰을 살펴보았습니다.</p>
<ol type="1">
<li><strong>Observation Removal:</strong> <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">에서 조건부 독립이면, 관측값 <img src="https://latex.codecogs.com/png.latex?z">를 조건절에서 제거 가능.</li>
<li><strong>Action to Observation:</strong> <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Cunderline%7BX%7D%7D">에서 조건부 독립이면, <img src="https://latex.codecogs.com/png.latex?do(x)">를 <img src="https://latex.codecogs.com/png.latex?x">로 변환 가능.</li>
<li><strong>Action Removal:</strong> <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">에서 독립이면, <img src="https://latex.codecogs.com/png.latex?do(x)"> 자체를 제거 가능.</li>
</ol>
<p>이 세 가지 통찰은 다음 포스트에서 다룰 <strong>Do-Calculus의 3가지 공식 규칙(The 3 Rules of Do-Calculus)</strong>으로 정식화됩니다. 이 규칙들은 인과 추론의 “미분 적분학”과 같은 역할을 하여, 그래프 구조만 주어진다면 어떤 복잡한 인과 효과도 식별 가능한지 판별하고 계산할 수 있게 해줍니다.</p>
<hr>
<section id="누락-방지-검증-체크리스트" class="level3">
<h3 class="anchored" data-anchor-id="누락-방지-검증-체크리스트">누락 방지 검증 체크리스트</h3>
<ul>
<li><strong>포함된 내용:</strong>
<ul>
<li>[cite_start][x] 식별(Identification)의 구문론적 목표 (Syntactical Goal) 및 두 가지 접근법 (Algebraic vs Axiomatic) [cite: 151, 156, 163]</li>
<li>[cite_start][x] Submodel <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BH%7D_x">와 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">의 정의 및 조건부 독립성의 의미 [cite: 188, 196, 220]</li>
<li>[cite_start][x] <strong>Insight 1:</strong> Adding/Removing Observations의 조건, 규칙, 유도 과정 [cite: 229, 240, 263]</li>
<li>[cite_start][x] <strong>Insight 2:</strong> Action/Observation Exchange의 조건, 규칙(<img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Cunderline%7BX%7D%7D"> 사용), 유도 과정 [cite: 287, 297, 307]</li>
<li>[cite_start][x] <strong>Insight 3:</strong> Adding/Removing Actions의 조건, 규칙, 유도 과정 [cite: 319, 332]</li>
<li><label><input type="checkbox" checked="">각 개념에 대응하는 Markdown 이미지 Placeholder 및 상세 캡션</label></li>
</ul></li>
<li><strong>생략된 내용:</strong>
<ul>
<li>없음. 제공된 PDF 범위(Slide 6 ~ 12) 내의 모든 핵심 이론과 수식 유도를 포함함.</li>
</ul></li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L06/part-02/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
</channel>
</rss>
