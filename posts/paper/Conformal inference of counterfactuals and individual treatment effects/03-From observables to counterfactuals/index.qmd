---
title: "관측된 데이터 너머: 공변량 변화와 가중 컨포멀 추론"
subtitle: "Paper Review: Conformal inference of counterfactuals and individual treatment effects (Section 3.1 - 3.2)"
author: "Reviewer"
date: "2026-01-22"
categories: [Causal Inference, Conformal Prediction, Machine Learning]
format:
  html:
    toc: true
    number-sections: true
    math: true
---

## 들어가며

이전 포스트에서는 개별 처치 효과(ITE)의 불확실성을 정량화하기 위해 **예측 구간(Prediction Interval)**을 생성해야 함을 역설했습니다. 하지만 여기에는 현실적인 장벽이 존재합니다. 우리가 가진 데이터는 '처치를 받은 사람($T=1$)'의 결과뿐인데, 우리가 예측하고 싶은 대상은 '전체 인구'이거나 '처치를 받지 않은 사람'일 수 있기 때문입니다.

이번 포스트에서는 이러한 **분포의 불일치(Covariate Shift)** 문제를 정의하고, 이를 **가중 컨포멀 추론(Weighted Conformal Inference)**을 통해 수학적으로 어떻게 보정하는지 단계별로 살펴보겠습니다.

---

## 관측 데이터와 반사실 간의 괴리 (Counterfactuals and Covariate Shift)

### 문제의 본질: 훈련 데이터와 타겟 데이터의 불일치

우리의 목표는 잠재적 결과 $Y(1)$과 $Y(0)$에 대한 예측 구간을 만드는 것입니다. [cite_start]이때 우리는 **강한 무시 가능성(Strong Ignorability)** 가정을 바탕으로 오직 관측된 데이터 $(Y^{obs}, T, X)$만을 사용합니다[cite: 226].

* $Y(1)$의 구간을 추정하기 위해: 처치군 ($T=1$) 데이터만 사용 가능.
* $Y(0)$의 구간을 추정하기 위해: 대조군 ($T=0$) 데이터만 사용 가능.

하지만 여기서 문제가 발생합니다. **데이터를 학습하는 분포**와 **예측을 적용하려는 타겟 분포**가 서로 다릅니다. 이를 수식으로 표현해 보겠습니다.

### 수학적 정의: Covariate Shift

[cite_start]우리가 $Y(1)$을 학습할 때 사용하는 처치군 데이터의 결합 분포는 다음과 같습니다[cite: 234].

$$
P_{Train} = P_{X|T=1} \times P_{Y(1)|X}
$$

[cite_start]하지만 우리가 결과를 일반화하여 적용하고 싶은 타겟 분포(예: 전체 인구)는 다음과 같습니다[cite: 236].

$$
P_{Target} = Q_X \times P_{Y(1)|X}
$$

여기서 주목할 점은 **조건부 결과 분포 $P_{Y(1)|X}$는 동일하다**는 것입니다. 즉, $X$가 주어졌을 때 결과가 나오는 메커니즘(생물학적 반응 등)은 변하지 않습니다. 유일한 차이는 **공변량 $X$의 분포($P_{X|T=1}$ vs $Q_X$)**에 있습니다.

[cite_start]이러한 현상을 머신러닝에서는 **공변량 변화(Covariate Shift)**라고 부릅니다[cite: 237].

![Image: covariate_shift_diagram.png]
*Figure 1: Covariate Shift의 개념도. 학습 데이터(Treated)는 특정 영역(예: 고연령층)에 치우쳐 있을 수 있지만, 타겟(Target)은 전체 인구를 포함한다. 회귀 곡선(조건부 평균)은 같더라도 데이터 밀도가 달라 예측 구간 보정이 필요하다.*

일반적인 머신러닝 방법론들은 훈련 데이터와 테스트 데이터의 분포가 같다고 가정($P_{Train} = P_{Target}$)하기 때문에, 이 상황에서 그대로 적용하면 잘못된 커버리지(Coverage)를 산출하게 됩니다.

---

## 해결책: 가중 컨포멀 추론 (Weighted Conformal Inference)

[cite_start]이 문제를 해결하기 위해 논문은 Tibshirani et al.(2019b)이 제안한 **가중 컨포멀 추론**을 도입합니다[cite: 238].

### 표준 컨포멀 추론의 한계

[cite_start]표준적인 컨포멀 추론(Standard Conformal Inference)은 데이터가 i.i.d.일 때, 임의의 예측 모델(예: Quantile Regression)의 잔차(Residual)를 보정하여 다음을 만족하는 구간 $\hat{C}(X)$를 생성합니다[cite: 243].

$$
\mathbb{P}_{(X,Y) \sim P_X \times P_{Y|X}}(Y \in \hat{C}(X)) \ge 1 - \alpha
$$

[cite_start]보통 **Conformal Quantile Regression (CQR)**을 사용하여 다음과 같은 형태의 구간을 만듭니다[cite: 247].

$$
\hat{C}(x) = [\hat{q}_{\alpha_{lo}}(x) - \eta, \hat{q}_{\alpha_{hi}}(x) + \eta]
$$

여기서 $\eta$는 보정 상수입니다. 하지만 분포가 다를 경우($P_{Train} \neq P_{Target}$), 이 단순한 보정은 실패합니다.

### 가중치(Likelihood Ratio)의 도입

[cite_start]우리는 타겟 분포 $Q_X$ 하에서의 커버리지를 보장해야 합니다[cite: 252]. [cite_start]이를 위해 두 분포 사이의 비율인 **우도비(Likelihood Ratio)**를 가중치로 사용합니다[cite: 255].

$$
w(x) = \frac{dQ_X(x)}{dP_{X|T=1}(x)}
$$

이 가중치 $w(x)$는 "타겟 분포에서 $x$가 관측될 확률이 학습 분포에 비해 얼마나 높은가"를 나타냅니다.

---

## 알고리즘 상세: Weighted Split-CQR

[cite_start]논문에서 제안하는 **Algorithm 1 (Weighted split-CQR)**의 작동 원리를 단계별로 분석해 보겠습니다[cite: 262].

### Step 1: 데이터 분할 (Data Splitting)
전체 데이터를 훈련 집합(Training fold, $\mathcal{Z}_{tr}$)과 캘리브레이션 집합(Calibration fold, $\mathcal{Z}_{ca}$)으로 나눕니다.
* **훈련 집합:** 분위수 회귀 모델 $\hat{q}(\cdot)$와 가중치 함수 $\hat{w}(\cdot)$를 학습하는 데 사용합니다.
* **캘리브레이션 집합:** 모델의 예측 오차를 측정하여 구간을 보정하는 데 사용합니다.

### Step 2: 비적합 점수 계산 (Non-conformity Scores)
캘리브레이션 데이터 $i \in \mathcal{I}_{ca}$에 대해, 실제 값 $Y_i$가 예측된 구간 $[\hat{q}_{\alpha_{lo}}, \hat{q}_{\alpha_{hi}}]$ 밖으로 얼마나 벗어났는지 점수($V_i$)를 계산합니다.

$$
V_i = \max \{ \hat{q}_{\alpha_{lo}}(X_i) - Y_i, \quad Y_i - \hat{q}_{\alpha_{hi}}(X_i) \}
$$

* $V_i > 0$: 실제 값이 예측 구간 밖에 있음 (오차 발생).
* $V_i \le 0$: 실제 값이 예측 구간 안에 있음.

### Step 3: 가중치 계산 (Weight Computation)
캘리브레이션 데이터 각각에 대해 가중치를 계산합니다.

$$
W_i = \hat{w}(X_i)
$$

### Step 4: 정규화된 확률 계산 (Normalized Probabilities) **[핵심]**
새로운 데이터 포인트(Test point) $x$가 주어졌을 때, 이 점에서의 예측 구간을 구하기 위해 가중치를 정규화합니다. 이때 테스트 포인트의 가중치 $\hat{w}(x)$도 함께 고려합니다.

$$
\hat{p}_i(x) = \frac{W_i}{\sum_{j \in \mathcal{I}_{ca}} W_j + \hat{w}(x)}, \quad \forall i \in \mathcal{I}_{ca}
$$

$$
\hat{p}_{\infty}(x) = \frac{\hat{w}(x)}{\sum_{j \in \mathcal{I}_{ca}} W_j + \hat{w}(x)}
$$

* **의미:** 만약 테스트 포인트 $x$가 타겟 분포에서 아주 희귀한 값이라면($\hat{w}(x) \approx 0$), $\hat{p}_\infty(x)$는 작아지고 기존 캘리브레이션 데이터들의 영향력이 커집니다. 반대라면 테스트 포인트 자체의 불확실성이 크게 반영됩니다.

### Step 5: 가중 분위수 계산 (Weighted Quantile)
다음과 같은 이산 분포(Discrete Distribution)를 구성하고, 이 분포의 $(1-\alpha)$ 분위수를 찾아 보정값 $\eta(x)$로 설정합니다.

$$
\sum_{i \in \mathcal{I}_{ca}} \hat{p}_i(x) \delta_{V_i} + \hat{p}_{\infty}(x) \delta_{\infty}
$$

여기서 $\delta$는 디랙 델타 함수입니다. 즉, 가중치 $\hat{p}_i(x)$를 반영하여 에러 점수 $V_i$들을 줄 세운 뒤, 상위 $(1-\alpha)$ 지점에 해당하는 에러 값을 찾는 과정입니다.

### 최종 출력
구해진 $\eta(x)$를 이용하여 최종 예측 구간을 생성합니다.

$$
\hat{C}(x) = [\hat{q}_{\alpha_{lo}}(x) - \eta(x), \quad \hat{q}_{\alpha_{hi}}(x) + \eta(x)]
$$

![Image: weighted_cqr_process.png]
*Figure 2: Weighted Split-CQR 프로세스. 캘리브레이션 데이터의 에러(Score)들에 가중치를 부여하여 히스토그램을 그리고, 타겟 커버리지(1-alpha)를 만족하는 지점(Quantile)을 동적으로 결정한다.*

---

## 이론적 보장 (Theoretical Guarantee)

[cite_start]이 알고리즘은 강력한 이론적 성질을 가집니다 (Proposition 1)[cite: 268].

1.  **가중치를 정확히 아는 경우 ($\hat{w} = w$):**
    데이터 분포에 대한 어떠한 가정 없이도, 유한한 샘플에서 타겟 분포에 대한 커버리지(Equation 10)를 **완벽하게 보장**합니다.
    $$\mathbb{P}_{(X,Y) \sim Q_X \times P_{Y|X}}(Y \in \hat{C}(X)) \ge 1 - \alpha$$

2.  **가중치를 추정해야 하는 경우 ($\hat{w} \neq w$):**
    [cite_start]가중치 추정에 오차가 있더라도, 그 오차($\Delta_w$)만큼만 커버리지가 벗어납니다[cite: 274].
    $$\text{Coverage} \ge 1 - \alpha - \Delta_w$$
    이는 이 방법론이 가중치 추정의 정확도에 의존하지만, 어느 정도의 오차는 허용하는 강건함(Robustness)을 가짐을 의미합니다.

## 요약

이번 섹션에서는 인과추론에서 피할 수 없는 **공변량 변화(Covariate Shift)** 문제를 해결하기 위해 **가중 컨포멀 추론**을 사용하는 방법을 다루었습니다.

* 우리는 $P_{Train}$에서 학습하지만 $P_{Target}$을 예측해야 합니다.
* 두 분포의 비율($w(x)$)을 이용하여 캘리브레이션 데이터의 에러 분포를 재조정(Reweighting)합니다.
* 이 방식은 모델이 완벽하지 않아도, 수학적으로 타겟 분포에 대한 유효한 예측 구간을 보장해 줍니다.

다음 단계에서는 이 가중치 $w(x)$가 인과추론의 **성향 점수(Propensity Score)**와 어떻게 연결되는지 구체적으로 살펴보게 될 것입니다.

***
**Reference:**
Lei, L., & Candès, E. J. (2021). Conformal inference of counterfactuals and individual treatment effects. *Journal of the Royal Statistical Society: Series B (Statistical Methodology)*, 83(5), 911-938.

---
title: "성향 점수의 역할과 이중 강건성(Double Robustness)"
subtitle: "Paper Review: Conformal inference of counterfactuals and individual treatment effects (Section 3.3 - 3.5)"
author: "Reviewer"
date: "2026-01-22"
categories: [Causal Inference, Propensity Score, Double Robustness]
format:
  html:
    toc: true
    number-sections: true
    math: true
---

## 들어가며

이전 포스트에서는 공변량 변화(Covariate Shift)를 해결하기 위해 **가중 컨포멀 추론(Weighted Conformal Inference)**을 도입했습니다. 핵심은 학습 분포와 타겟 분포의 비율인 가중치 $w(x)$를 어떻게 설정하느냐였습니다.

이번 포스트에서는 인과추론의 꽃이라 불리는 **성향 점수(Propensity Score)**가 이 가중치와 어떻게 수학적으로 연결되는지 살펴보고, 이 방법론이 가진 두 가지 강력한 성질인 **완전성(Exactness)**과 **이중 강건성(Double Robustness)**에 대해 알아보겠습니다.

---

## 성향 점수(Propensity Score)의 역할

### 성향 점수와 IPW의 관계

Rosenbaum & Rubin(1983)이 제안한 성향 점수 $e(x)$는 공변량이 주어졌을 때 처치를 받을 확률로 정의됩니다.

$$
e(x) = \mathbb{P}(T=1 | X=x)
$$

전통적인 인과추론에서 평균 처치 효과(ATE)를 추정할 때 사용하는 **역성향 점수 가중법(IPW, Inverse Propensity Weighting)**은 다음과 같은 가중치를 사용합니다.

* 처치군 ($T=1$): $w_1(x) = \frac{1}{e(x)}$
* 대조군 ($T=0$): $w_0(x) = \frac{1}{1-e(x)}$

### 가중 컨포멀 추론에서의 유도 과정

놀랍게도, 가중 컨포멀 추론에서 필요한 공변량 변화 비율(Likelihood Ratio)은 IPW 가중치와 정확히 일치합니다. 이를 수학적으로 유도해 보겠습니다.

우리가 $Y(1)$에 대한 ATE 타입의 구간을 구한다고 가정합시다.
* **Target Distribution:** 전체 모집단 ($P_X$)
* **Sampling Distribution:** 처치군 ($P_{X|T=1}$)

베이즈 정리(Bayes' Formula)를 적용하면 가중치 $w_1(x)$는 다음과 같습니다.

$$
\begin{align}
w_1(x) &= \frac{dP_X(x)}{dP_{X|T=1}(x)} \\
       &= \frac{dP_X(x)}{\frac{P(T=1|X=x)dP_X(x)}{P(T=1)}} \\
       &= \frac{P(T=1)}{e(x)}
\end{align}
$$

여기서 $P(T=1)$은 상수입니다. 가중 컨포멀 추론 알고리즘은 가중치의 **상수배(Rescaling)에 불변(Invariant)**하므로, 분자를 무시하면 다음과 같이 귀결됩니다.

$$
w_1(x) \propto \frac{1}{e(x)}
$$

즉, **가중 컨포멀 추론은 본질적으로 IPW 추정 방식과 동일한 가중치 체계를 공유**합니다.

### 다양한 추론 목표에 따른 가중치 요약

논문에서는 ATE뿐만 아니라 ATT(처치군 대상 효과), ATC(대조군 대상 효과), 그리고 일반화(Generalizability) 상황까지 아우르는 가중치 표를 제시합니다.

| 추론 목표 (Inferential Target) | $w_1(x)$ (for $Y(1)$) | $w_0(x)$ (for $Y(0)$) |
| :--- | :--- | :--- |
| **ATE** (전체 평균) | $1/e(x)$ | $1/(1-e(x))$ |
| **ATT** (처치군 평균) | $1$ (가중치 불필요) | $e(x)/(1-e(x))$ |
| **ATC** (대조군 평균) | $(1-e(x))/e(x)$ | $1$ |
| **General** (외부 타겟 $Q$) | $\frac{dQ}{dP}(x) \cdot \frac{1}{e(x)}$ | $\frac{dQ}{dP}(x) \cdot \frac{1}{1-e(x)}$ |

*Table 1: 다양한 인과추론 목표에 따른 가중치 함수 요약. IPW 추정량에서 쓰이는 가중치와 정확히 일치한다.*

---

## 무작위 대조군 연구(RCT)에서의 완전성 (Exactness)

### 완전한 성향 점수, 완전한 커버리지

**무작위 대조군 연구(Randomized Controlled Trials, RCT)**에서는 연구자가 처치 확률을 설계하므로 성향 점수 $e(x)$를 정확히 알고 있습니다.

* **완전 무작위 배정(Completely Randomized):** $e(x) = 0.5$ (상수). 가중치가 일정하므로 일반적인(Unweighted) 컨포멀 추론을 사용해도 됩니다.
* **층화 무작위 배정(Stratified Randomized):** $e(x)$가 공변량(예: 연령, 성별)에 따라 다르지만, 그 값은 정확히 알고 있습니다.

이 경우, 가중 컨포멀 추론은 유한한 샘플(Finite Samples)에서도 **정확한(Exact) 커버리지**를 보장합니다.

$$
\mathbb{P}(Y(1) \in \hat{C}(X)) \ge 1 - \alpha
$$

이 보장은 결과 모델(Conditional Quantile Model)을 얼마나 엉터리로 만들었는지와 상관없이 성립합니다.

### 겹침 조건(Overlap Condition) 위반에 대한 강건성

IPW와 같은 점 추정 방식은 $e(x) \approx 0$ 또는 $1$인 경우(Overlap이 부족한 경우) 가중치가 무한대로 발산하여 추정량이 매우 불안정해집니다.

하지만 컨포멀 추론은 이 상황에서 매우 직관적이고 안전하게 반응합니다. 가중치가 무한대로 가면 구간의 길이도 무한대로 늘어납니다 ($\hat{C}(x) = (-\infty, \infty)$).
* **의미:** "이 영역에는 데이터가 없어 정보를 알 수 없으므로, 구간을 무한히 넓게 잡겠다."
* **결과:** 정보는 없지만, 여전히 정답을 포함할 확률($1-\alpha$)은 수학적으로 지켜집니다.

---

## 관찰 연구에서의 이중 강건성 (Double Robustness)

관찰 연구(Observational Study)에서는 성향 점수 $e(x)$를 모르기 때문에 데이터로부터 추정해야 합니다($\hat{e}(x)$). 이때 발생하는 불확실성을 가중 컨포멀 추론은 어떻게 처리할까요?

이 방법론은 **이중 강건성(Doubly Robust Property)**을 가집니다. 즉, 다음 두 가지 조건 중 **하나만** 만족해도 근사적으로(Approximately) 올바른 커버리지를 보장합니다.

1.  **성향 점수 모델이 정확할 때 ($\hat{e}(x) \approx e(x)$)**
2.  **결과 모델(Quantile)이 정확할 때 ($\hat{q}(x) \approx q(x)$)**

### 직관적 증명 (Intuitive Justification)

**Case 1: 성향 점수 모델이 정확함 ($\hat{e} \approx e$)**
이 경우, 우리가 계산한 가중치가 참(Oracle) 가중치와 거의 같아집니다. 따라서 결과 모델 $\hat{q}(x)$가 아무리 부정확하더라도, 가중 컨포멀 추론의 기본 원리에 의해 커버리지가 보장됩니다.

**Case 2: 결과 모델이 정확함 ($\hat{q} \approx q$)**
이 부분이 흥미롭습니다. 성향 점수(가중치)가 틀렸더라도, 결과 모델이 정확하다면 어떻게 될까요?
참 조건부 분위수 $q_{\beta}(x)$를 정확히 추정했다면, 비적합 점수(Non-conformity score) $V_i$의 분포가 다음과 같이 됩니다.

$$
\begin{align}
V_i &\approx \max \{ q_{\alpha_{lo}}(X_i) - Y_i, \ Y_i - q_{\alpha_{hi}}(X_i) \} \\
\mathbb{P}(V_i \le 0 | X_i) &\approx \mathbb{P}(Y_i \in [q_{\alpha_{lo}}, q_{\alpha_{hi}}]) = 1 - \alpha
\end{align}
$$

즉, $0$이라는 값이 점수 분포의 $(1-\alpha)$ 분위수가 됩니다. 따라서 알고리즘이 계산하는 보정값 $\eta(x)$는 $0$에 가까워지며, 최종 구간은 참 분위수 구간으로 수렴하게 되어 커버리지를 만족합니다.

![Image: double_robustness_diagram.png]
*Figure 1: 이중 강건성의 개념도. x축은 성향 점수 모델의 오차, y축은 결과 모델의 오차를 나타낸다. 두 축 중 하나만 0에 가까우면(L자 형태), 전체 커버리지 에러는 낮게 유지된다.*

### Theorem 1: 수학적 보장

논문의 정리 1(Theorem 1)은 이를 공식화합니다.
샘플 사이즈 $N, n \to \infty$ 일 때, 다음 조건 중 하나가 성립하면:
1.  $\hat{e}_N(X) \to e(X)$ (성향 점수 일치)
2.  $\hat{q}_{\beta, N}(X) \to q_{\beta}(X)$ (분위수 일치)

다음과 같은 커버리지를 보장합니다.

$$
\lim_{N,n \to \infty} \mathbb{P}(Y(1) \in \hat{C}_{N,n}(X)) \ge 1 - \alpha
$$

또한, 조건 2(결과 모델 정확)가 만족될 경우에는 평균 커버리지뿐만 아니라 **조건부 커버리지(Conditional Coverage)**까지 근사적으로 보장됨을 보일 수 있습니다.

$$
\lim_{N,n \to \infty} \mathbb{P}(\text{Coverage Error} | X) = 0
$$

## 요약

이번 섹션의 핵심은 **"가중치(Weighting)"**와 **"강건성(Robustness)"**입니다.

1.  가중 컨포멀 추론의 가중치는 **IPW의 성향 점수 가중치**와 본질적으로 같습니다.
2.  성향 점수를 아는 RCT에서는 **유한 표본에서도 완벽한 커버리지**를 제공합니다.
3.  성향 점수를 모르는 관찰 연구에서는 **성향 점수 모델** 혹은 **결과 예측 모델** 중 하나만 잘 맞으면 커버리지가 보장되는 **이중 강건성**을 가집니다.

이는 점 추정(Point Estimation)에서의 이중 강건성(일치성 보장) 개념을 구간 추정(Interval Estimation, 커버리지 보장)으로 성공적으로 확장한 사례라 할 수 있습니다.

***
**Reference:**
Lei, L., & Candès, E. J. (2021). Conformal inference of counterfactuals and individual treatment effects. *Journal of the Royal Statistical Society: Series B (Statistical Methodology)*, 83(5), 911-938.

---
title: "이론에서 현실로: 시뮬레이션을 통한 성능 검증"
subtitle: "Paper Review: Conformal inference of counterfactuals and individual treatment effects (Section 3.6)"
author: "Reviewer"
date: "2026-01-22"
categories: [Causal Inference, Simulation, Benchmarking]
format:
  html:
    toc: true
    number-sections: true
    math: true
---

## 들어가며

지금까지 우리는 이론적으로 개별 처치 효과(ITE)의 구간을 추정하는 방법과 그에 따른 성질(이중 강건성 등)을 살펴보았습니다. 이번 포스트에서는 **"그래서 실제로 잘 작동하는가?"**라는 질문에 답하기 위해 수행된 수치 실험(Numerical Experiments) 결과를 상세히 뜯어보겠습니다.

저자들은 **Causal Forest**, **X-learner**, **BART** 등 현존하는 강력한 방법론들과 자신들의 **Weighted Split-CQR**을 비교하며, 특히 데이터가 복잡할 때(고차원, 상관관계 존재, 이분산성) 어떤 차이가 발생하는지 집중 조명합니다.

---

## 실험 설계 (Experimental Setup)

실험은 Wager and Athey (2018)의 설정을 변형하여 진행되었습니다. 데이터 생성 과정(Data Generating Process)을 수학적으로 정의해 보겠습니다.

### 데이터 생성 메커니즘

1.  **공변량 (Covariates) $X$**:
    $d$차원의 벡터 $X = (X_1, \dots, X_d)^T$는 다음과 같이 생성됩니다.
    
    $$
    X_j = \Phi(X'_j)
    $$
    
    여기서 $\Phi$는 표준 정규분포의 누적 분포 함수(CDF)이며, $X'$는 평균이 0이고 분산이 1인 다변량 가우시안 분포를 따릅니다. 공변량 간의 상관계수는 $\text{Cov}(X'_j, X'_{j'}) = \rho$ 입니다.

2.  **잠재적 결과 (Potential Outcomes)**:
    문제의 단순화를 위해, 처치를 받지 않았을 때의 결과 $Y(0)$는 0으로 고정합니다.
    
    $$
    Y(0) \equiv 0
    $$
    
    처치를 받았을 때의 결과 $Y(1)$은 다음과 같이 구성됩니다.
    
    $$
    \mathbb{E}[Y(1)|X] = f(X_1)f(X_2), \quad \text{where } f(x) = \frac{2}{1 + \exp\{-12(x-0.5)\}}
    $$
    
    $$
    Y(1) = \mathbb{E}[Y(1)|X] + \sigma(X)\epsilon, \quad \epsilon \sim N(0, 1)
    $$

3.  **성향 점수 (Propensity Score)**:
    충분한 겹침(Overlap)을 보장하기 위해 다음과 같이 설정합니다.
    
    $$
    e(x) = \frac{1}{4} (1 + \beta_{2,4}(X_1))
    $$
    
    여기서 $\beta_{2,4}$는 베타 분포(2, 4)의 CDF입니다. 이 설정은 $e(x) \in [0.25, 0.5]$ 범위를 보장합니다.

### 8가지 시나리오 (Scenarios)

데이터의 복잡성에 따른 성능 변화를 보기 위해 총 $2 \times 2 \times 2 = 8$가지 시나리오를 구성했습니다.

* **차원 (Dimension):** 저차원 ($d=10$) vs 고차원 ($d=100$)
* **상관관계 (Correlation):** 독립 ($\rho=0$) vs 상관 ($\rho=0.9$)
* **오차 분산 (Errors):** 등분산 ($\sigma^2(x)=1$) vs 이분산 ($\sigma^2(x) = -\log X_1$)

특히 **이분산(Heteroscedasticity)** 설정이 중요합니다. $X_1$이 0에 가까울수록 분산이 무한대로 커지기 때문에, 불확실성 추정이 매우 까다로워집니다.

---

## 비교 방법론 (Competitors)

본 실험에서는 다음 방법론들의 95% 구간 추정 성능을 비교합니다.

1.  **Causal Forest (CF):** `grf` 패키지 사용. CATE의 분산을 추정하지만 ITE용은 아님.
2.  **X-learner:** `causalToolbox` 패키지 사용. 부트스트랩 기반 CATE 분산 추정. 역시 ITE용은 아님.
3.  **BART (Bayesian Additive Regression Trees):** `bartMachine` 패키지. 베이지안 신용 구간(Credible Interval) 및 예측 구간(Prediction Interval) 생성 가능. 가장 강력한 경쟁자.
4.  **Weighted Split-CQR (제안 방법):** 기본 학습기(Learner)로 다음 3가지를 각각 사용.
    * Quantile Random Forest (CQR-RF)
    * Quantile Gradient Boosting (CQR-Boosting)
    * BART (CQR-BART)

---

## 결과 분석 1: 커버리지 성능 (Coverage Performance)

가장 중요한 지표는 **"생성된 구간이 실제 값을 95% 확률로 포함하는가?"**입니다.

### 이론적 보장과 실제 (Table 2)

먼저 각 방법론이 이론적으로 무엇을 보장하는지 살펴봅시다.

![Table 2: Summary of coverage guarantees](Table_2_Summary_of_coverage_guarantees_in_theory_and_simulation.png)
*Table 2: 이론적(위) 및 시뮬레이션(아래)에서의 커버리지 보장 요약. CF와 X-learner는 애초에 ITE 커버리지를 보장하지 않으며, 오직 CQR만이 모든 상황에서 ITE 커버리지를 달성함.*

### CATE 커버리지 (Figure 1)

CATE(조건부 평균)에 대한 커버리지를 먼저 봅니다.

![Figure 1: Empirical 95% coverage of CATE](Figure_1_Empirical_95_percent_coverage_of_CATE.png)
*Figure 1: CATE에 대한 95% 커버리지 결과. 빨간 수직선(1.00 근처)이 목표치. CF와 X-learner는 고차원/이분산 상황에서 성능이 크게 떨어짐. 반면 CQR은 다소 보수적(과도한 커버리지)이지만 목표치를 항상 상회함.*

* **CF, X-learner:** 모든 시나리오에서 낮은 커버리지를 보이며, 고차원($d=100$)에서 더 악화됩니다.
* **CQR:** CATE를 직접 타겟팅하지 않음에도 불구하고(ITE를 타겟팅하므로 구간이 더 넓음), 모든 시나리오에서 안전한 커버리지를 보여줍니다.

### ITE 커버리지 (Figure 2) - 핵심 결과

논문의 진짜 목표인 **개별 처치 효과(ITE)**에 대한 커버리지입니다.

![Figure 2: Empirical 95% coverage of ITE](Figure_2_Empirical_95_percent_coverage_of_ITE.png)
*Figure 2: ITE에 대한 95% 커버리지 결과. 이것이 이 논문의 핵심이다. CQR 계열(상단 3개)만이 모든 시나리오(특히 맨 오른쪽의 이분산+상관관계)에서 95% 선을 지킨다.*

* **CF, X-learner:** ITE를 커버하도록 설계되지 않았으므로 당연히 실패합니다. (CATE 구간을 ITE 구간으로 오해해서는 안 된다는 것을 보여줍니다.)
* **BART:** 등분산(Homoscedastic) 상황에서는 완벽합니다. 하지만 **이분산 + 상관관계(Heteroscedastic + Corr.)** 상황에서는 커버리지가 무너집니다.
* **CQR:** 어떤 기본 학습기를 쓰든, 차원/상관관계/분산 구조에 상관없이 **거의 정확한 95% 커버리지**를 달성합니다.

---

## 결과 분석 2: 구간의 길이 (Interval Length)

커버리지가 높다고 무조건 좋은 것은 아닙니다. 구간이 $(-\infty, \infty)$라면 커버리지는 100%겠지만 쓸모가 없으니까요. 구간은 **짧을수록 좋습니다.**

![Figure 3: Lengths of interval estimates for ITE](Figure_3_Lengths_of_interval_estimates_for_ITE.png)
*Figure 3: ITE 구간의 평균 길이. 파란 수직선은 Oracle(이상적인) 길이. CQR-BART가 BART와 거의 유사한 길이를 보이면서도 더 나은 커버리지를 제공함을 알 수 있다.*

* **CF, X-learner:** 구간이 매우 짧습니다. 그래서 커버리지(Figure 2)가 망가진 것입니다.
* **BART:** 등분산 상황에서 가장 효율적(짧은) 구간을 만듭니다.
* **CQR-BART:** BART를 기본 학습기로 사용한 CQR은 순수 BART와 **거의 비슷한 구간 길이**를 가집니다. 즉, **"정보의 손실 없이(길이 유지) 정확성(커버리지)만 보정했다"**는 뜻입니다.

---

## 결과 분석 3: 조건부 커버리지 (Conditional Coverage)

마지막으로, 데이터의 특성(여기서는 분산의 크기)에 따라 커버리지가 어떻게 변하는지 확인합니다. 이상적으로는 분산이 크든 작든 일정한 커버리지를 유지해야 합니다.

![Figure 4: Estimated conditional coverage of ITE](Figure_4_Estimated_conditional_coverage_of_ITE.png)
*Figure 4: 조건부 분산(x축)에 따른 ITE 커버리지(y축) 변화. x축의 오른쪽으로 갈수록 노이즈가 심한 데이터이다. BART(가운데)는 노이즈가 커지면 커버리지가 급격히 떨어지지만, CQR(오른쪽)은 이를 잘 방어하고 있다.*

* **상황:** $d=10$, 이분산 설정. $x_1$ 값에 따라 분산이 변함.
* **BART:** 분산이 큰 영역(그래프의 오른쪽)으로 갈수록 커버리지가 급격히 하락합니다.
* **CQR-RF/Boosting:** 분산의 크기와 관계없이 95% 수준을 견고하게 유지합니다. 이것이 바로 **Conformal Inference의 적응력(Adaptability)**입니다.

---

## 결론 및 요약

Section 3.6의 실험 결과는 다음과 같이 요약할 수 있습니다.

1.  **CATE 추정기 $\neq$ ITE 구간 추정기:** Causal Forest나 X-learner 같은 CATE 전용 방법론을 ITE 불확실성 추정에 그대로 사용하면 위험합니다.
2.  **BART의 한계:** BART는 강력하지만, 데이터가 복잡하고(상관관계 존재) 노이즈가 불균일할 때(이분산) 신뢰성을 잃을 수 있습니다.
3.  **Weighted Split-CQR의 승리:**
    * **강건성 (Robustness):** 어떤 시나리오에서도 목표 커버리지(95%)를 지켰습니다.
    * **효율성 (Efficiency):** 구간의 길이를 불필요하게 늘리지 않으면서도 정확도를 확보했습니다.
    * **유연성 (Flexibility):** RF, Boosting, BART 등 어떤 알고리즘 위에 얹어도 성능을 향상시킵니다.

이로써 이 논문이 제안한 방법론이 이론적으로만 아름다운 것이 아니라, 실전 데이터 분석에서도 매우 강력한 도구가 될 수 있음이 증명되었습니다.

***
**Reference:**
Lei, L., & Candès, E. J. (2021). Conformal inference of counterfactuals and individual treatment effects. *Journal of the Royal Statistical Society: Series B (Statistical Methodology)*, 83(5), 911-938.