---
title: "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.3)"
subtitle: "4.3. Conformal Risk Control"
author: "유성현"
date: "2026-01-16"
categories: [Paper Review]
format:
  html:
    toc: true
    number-sections: false
    code-fold: show
---

# Introduction: Beyond Coverage

* 지금까지 우리가 다룬 Conformal Prediction의 핵심 보장은 다음과 같은 형태였습니다.

$$ \mathbb{P}(Y_{test} \notin \mathcal{C}(X_{test})) \le \alpha $$

* 즉, "정답을 놓칠 확률(Miscoverage rate)"을 $\alpha$ 이하로 묶는 것이었습니다.
* 하지만 현실의 많은 머신러닝 문제에서는 단순히 "맞았다/틀렸다"의 이진(Binary) 에러보다 더 복잡한 **손실(Loss)**을 제어해야 할 때가 많습니다.
    * **의료 영상 분할(Tumor Segmentation)**: 암 영역을 조금이라도 놓치면(False Negative) 치명적입니다. 픽셀 단위의 재현율(Recall)을 보장해야 할 수 있습니다.
    * **다중 라벨 분류(Multilabel Classification)**: 여러 개의 태그 중 90% 이상을 맞추기를 원할 수 있습니다 (F1-score 등).

* **Conformal Risk Control (CRC)**은 이러한 요구를 반영하여, 임의의 유계 손실 함수(Bounded Loss Function)의 기댓값을 제어하는 기법입니다.

$$
\mathbb{E}[l(\mathcal{C}(X_{test}), Y_{test})] \le \alpha
$$

# Problem Formulation

* 우리의 목표는 모델의 출력 집합 $\mathcal{C}(X)$가 커질수록 **손실(Loss)이 줄어드는** 상황에서, 기대 손실(Expected Risk)이 사용자 지정 허용치 $\alpha$ 이하가 되도록 하는 파라미터를 찾는 것입니다.

## Key Components

* 1.  **Nested Sets ($\mathcal{C}_\lambda$)**:
    * 우리는 파라미터 $\lambda$를 조절하여 예측 집합의 크기(보수적인 정도)를 조절합니다.
    * $\lambda$가 커질수록 예측 집합 $\mathcal{C}_\lambda(x)$는 더 커지고(더 많은 후보를 포함), 따라서 더 안전해집니다(Conservative).

* 2.  **Monotone Loss Function ($l$)**:
    * 손실 함수 $l(\mathcal{C}, Y)$는 집합 $\mathcal{C}$가 커질수록 감소하거나 같아야 합니다 (Non-increasing).
    * 또한, 손실값은 어떤 상한선 $B$를 넘지 않아야 합니다 ($l \in (-\infty, B]$).

    $$ \lambda_1 \le \lambda_2 \implies l(\mathcal{C}_{\lambda_1}(x), y) \ge l(\mathcal{C}_{\lambda_2}(x), y) $$

# The Algorithm

* CRC의 알고리즘은 기존 CP와 매우 유사하지만, Quantile 대신 **경험적 리스크(Empirical Risk)**를 사용한다는 점이 다릅니다.

## Step 1: Calculate Empirical Risk
* Calibration 데이터셋 $(X_1, Y_1), \dots, (X_n, Y_n)$에 대해, 특정 파라미터 $\lambda$를 썼을 때의 평균 손실(Empirical Risk)을 계산하는 함수 $\hat{R}(\lambda)$를 정의합니다.

$$
\hat{R}(\lambda) = \frac{1}{n} \sum_{i=1}^{n} l(\mathcal{C}_{\lambda}(X_i), Y_i)
$$

* 이 함수는 $\lambda$가 증가함에 따라 손실이 감소하는 우하향 곡선을 그립니다.

## Step 2: Find Optimal $\lambda$
* 우리는 기대 손실이 $\alpha$ 이하가 되기를 원합니다.
* 하지만 유한한 데이터($n$)로 인한 불확실성을 고려해야 하므로, 단순히 $\hat{R}(\lambda) \le \alpha$가 되는 지점을 찾으면 안 됩니다.

* 대신, 다음과 같이 **보정된 기준(Conservative Target)**을 사용합니다.

$$
\hat{\lambda} = \inf \left\{ \lambda : \hat{R}(\lambda) \le \alpha - \frac{B - \alpha}{n} \right\}
$$

* **$B$**: 손실 함수의 최댓값 (Upper Bound)
* **Correction Term ($\frac{B-\alpha}{n}$)**: 데이터 개수 $n$이 적을 때 더 보수적으로 $\lambda$를 선택하게 만드는 항입니다. $n$이 무한대로 가면 이 항은 0이 되어 $\alpha$에 수렴합니다.

![Figure: Conformal Risk Control의 개념도. 파란색 실선은 $\lambda$에 따른 경험적 리스크 $\hat{R}(\lambda)$를 나타낸다. 목표 리스크 $\alpha$에서 보정항 $\frac{B-\alpha}{n}$만큼을 뺀 점선과 만나는 지점에서 $\hat{\lambda}$를 결정한다.](./images/risk_control_visualization.png)

# Example: Multilabel Classification

* 다중 라벨 분류 문제를 예로 들어보겠습니다. 
* 하나의 이미지가 '사람', '차', '신호등' 등 여러 클래스($Y_i \subseteq \{1, \dots, K\}$)를 가질 수 있습니다.

* 1.  **Prediction Set**:
    * 모델이 각 클래스에 대해 예측한 점수 $f(X)_k$가 임계값 $1-\lambda$ 이상인 클래스들을 담습니다.
    $$ \mathcal{C}_\lambda(x) = \{ k : f(x)_k \ge 1-\lambda \} $$
        * $\lambda$가 클수록 임계값이 낮아져 더 많은 클래스가 선택됨

* 2.  **Loss Function**:
    * "전체 정답 태그 중 놓친 태그의 비율"을 손실로 정의합니다.
    $$ l(\mathcal{C}, Y) = 1 - \frac{|Y \cap \mathcal{C}|}{|Y|} $$
    * 이 값은 0(모두 맞춤)과 1(하나도 못 맞춤) 사이이므로 $B=1$입니다.

* 3.  **Applying CRC**:
    * 사용자가 $\alpha=0.1$로 설정했다면, 위 알고리즘을 통해 구한 $\hat{\lambda}$를 사용했을 때 **"평균적으로 정답 태그의 90% 이상을 포함"**하는 예측 집합을 얻게 됩니다.

# Theoretical Guarantee

* 이 알고리즘은 다음 정리에 의해 수학적으로 보장됩니다.

> **Theorem 2 (Conformal Risk Control)**
>
> 데이터가 i.i.d.이고 손실 함수가 단조 감소(Monotone)한다면, 위 알고리즘으로 선택된 $\hat{\lambda}$에 대해 다음이 성립한다.
>
> $$ \mathbb{E}[l(\mathcal{C}_{\hat{\lambda}}(X_{test}), Y_{test})] \le \alpha $$

* 이 정리는 CP가 단순히 "에러율 제어"를 넘어, FNR, False Discovery Rate 등 **비즈니스에 중요한 다양한 KPI를 직접 제어**할 수 있는 도구로 확장됨을 의미합니다.

---
**Next Step**: 지금까지 지도 학습(Supervised Learning) 환경에서의 CP를 다루었습니다. 다음 포스트에서는 정답 라벨이 없는 비지도 학습 환경, 특히 **Section 4.4 Outlier Detection**에 CP를 어떻게 적용하는지 알아보겠습니다.