{
  "hash": "42c3fe572cae1a242e4a8a8b0c37f81b",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"[Causal Inference] 13. IV (Part 3)\"\ndescription: \"Linear 2SLS vs. Deep IV\"\nauthor: \"유성현\"\ndate: \"2026-01-18\"\ncategories: [Causal Inference]\nformat:\n  html:\n    toc: true\n    number-sections: false\n    code-fold: show\n    math: true\njupyter: python3\n---\n\n# Introduction\n\n* 데이터를 다루다 보면 선형(Linear) 모델로는 설명하기 힘든 복잡한 인과관계를 마주하게 됩니다.\n\n* 전통적인 **2단계 최소제곱법(2SLS)**은 강력한 도구이지만, 다음과 같은 한계가 있습니다.\n    * 1.  처치(Treatment)와 결과(Outcome)의 관계를 **선형**으로 가정합니다.\n    * 2.  공변량(Covariate)과 처치 변수 간의 복잡한 **상호작용**을 포착하기 어렵습니다.\n\n* 이번 포스트에서는 Hartford et al.(2017)이 제안한 **Deep IV** 방법론을 소개하고, 가격($P$)과 판매량($Y$)의 비선형적 관계를 시뮬레이션 데이터를 통해 추정해보겠습니다.\n\n## The Problem Formulation\n\n* 우리가 해결하고자 하는 인과추론 문제는 다음과 같은 구조적 방정식(Structural Equation)으로 정의됩니다.\n\n$$Y = g(P, X) + \\epsilon$$\n\n* 이 수식이 실제 현실에서 어떤 의미를 갖는지, 논문에서 제시한 **항공권 가격 결정 시나리오**를 통해 살펴보겠습니다.\n\n## Motivating Example: Airline Ticket Pricing\n\n* 항공사가 티켓 가격($P$)을 책정하고 그에 따른 판매량($Y$)을 분석한다고 가정해 봅시다. \n* 우리의 목표는 \"가격을 올렸을 때 판매량이 실제로 얼마나 줄어드는가?\"(인과 효과)를 알아내는 것입니다.\n* 하지만 단순히 데이터를 관찰하면 **내생성(Endogeneity)** 문제로 인해 잘못된 결론에 도달하게 됩니다.\n\n* **교란 변수 ($E$, Confounder):** \n    * 예를 들어 '비즈니스 컨퍼런스'나 '휴가철' 같은 수요 급증 요인이 있다고 합시다. \n    * 이 요인은 **가격($P$)**을 높이게 만들고(항공사가 가격을 올림), 동시에 **판매량($Y$)**도 높입니다(사람들이 비싸도 삼). \n    * 그 결과, 데이터상으로는 **\"가격이 비싼데도 판매량이 높네?\"**라는 양의 상관관계가 나타나, 가격의 부정적 효과를 과소평가하게 됩니다.\n\n* 이 고리를 끊기 위해 우리는 **도구 변수 ($Z$, Instrument)**를 도입합니다.\n\n![Figure: Causal Graph (DAG) 인과 관계를 도식화하면 다음과 같습니다.](./images/dag.png)\n\n---\n\n# 1. Import Libarary\n\n* 실습에 필요한 라이브러리를 불러옵니다.\n\n::: {#libarary-import .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.distributions as D\nimport torch.nn.functional as F\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\n```\n:::\n\n\n---\n\n# 2. Data Generation\n\n* 먼저 내생성과 비선형성이 존재하는 가상의 데이터를 생성합니다.\n* 상황은 다음과 같습니다.\n    * **가격($P$)**이 오르면 **판매량($Y$)**은 줄어듭니다.\n    * 하지만 **성수기($X$)**에는 가격도 비싸고 판매량도 많아, 단순 회귀 시 양의 상관관계(편향)가 관찰됩니다.\n    * 실제 인과 효과는 특정 가격 이상에서 급격히 판매량이 떨어지는 **S자 곡선(Sigmoid)** 형태입니다.\n\n::: {#data-generation-function .cell execution_count=2}\n``` {.python .cell-code}\ndef generate_data(n, seed=42):\n    np.random.seed(seed)\n    \n    # 1. 외생 변수 생성\n    # X: 공변량 (성수기 여부)\n    x = np.random.uniform(0, 1, n) \n    # Z: 도구변수 (연료비)\n    z = np.random.uniform(0, 1, n) \n    # E: 교란 변수\n    e = np.random.normal(0, 1, n)   \n\n    # 2. 처치 변수 (P) 생성\n    p = 10 + (60 * z) + (20 * x) + (5 * e) + np.random.normal(0, 1, n)\n\n    # 3. 결과 변수 (Y) 생성\n    # True Structural Function: g(p, x)\n    def true_structural_function(p_val, x_val):\n        threshold = 35 + (40 * x_val) # X에 따라 임계값이 변함 (Heterogeneity)\n        base_effect = 150 / (1 + np.exp(0.8 * (p_val - threshold)))\n        return base_effect + (50 * x_val)\n        \n    y_structural = true_structural_function(p, x)\n    y = y_structural + (10 * e) + np.random.normal(0, 2, n)\n\n    return (z.reshape(-1, 1), x.reshape(-1, 1), p.reshape(-1, 1), y.reshape(-1, 1), true_structural_function)\n```\n:::\n\n\n::: {#data-generation .cell execution_count=3}\n``` {.python .cell-code}\n# 1. 데이터 생성\nZ_data, X_data, P_data, Y_data, true_func = generate_data(n=100)\n\n# 2. Scaler 선언\nscaler_z = StandardScaler()\nscaler_x = StandardScaler()\nscaler_p = StandardScaler()\nscaler_y = StandardScaler()\n\n# 3. Fitting & Transform\nZ_scaled = scaler_z.fit_transform(Z_data)\nX_scaled = scaler_x.fit_transform(X_data)\nP_scaled = scaler_p.fit_transform(P_data)\nY_scaled = scaler_y.fit_transform(Y_data)\n\n# 4. 텐서 변환\nZ = torch.tensor(Z_scaled, dtype=torch.float32)\nX = torch.tensor(X_scaled, dtype=torch.float32)\nP = torch.tensor(P_scaled, dtype=torch.float32)\nY = torch.tensor(Y_scaled, dtype=torch.float32)\n```\n:::\n\n\n::: {#cell-data-visualization .cell execution_count=4}\n``` {.python .cell-code}\n# 스타일 설정\nsns.set_style(\"whitegrid\")\nplt.rcParams['figure.figsize'] = (18, 12)\nplt.rcParams['font.size'] = 12\n\n# 데이터 1차원 변환\nz_flat = Z_data.flatten()\nx_flat = X_data.flatten()\np_flat = P_data.flatten()\ny_flat = Y_data.flatten()\n\nfig, axes = plt.subplots(2, 2)\nfig.suptitle('DeepIV Simulation: Non-linear Causal Inference', fontsize=22, weight='bold')\n\n# ---------------------------------------------------------\n# (A) First Stage Strength: 도구 변수(Z) -> 처치(P)\n# ---------------------------------------------------------\nsns.regplot(x=z_flat, y=p_flat, ax=axes[0, 0], \n            scatter_kws={'alpha': 0.05, 'color': 'navy'}, line_kws={'color': 'red'})\naxes[0, 0].set_title('(A) First Stage Relevance: Instrument(Z) -> Treatment(P)', fontsize=14, weight='bold')\naxes[0, 0].set_xlabel('Instrument Z (Fuel Cost)')\naxes[0, 0].set_ylabel('Treatment P (Price)')\naxes[0, 0].text(0.05, 0.9, f\"Corr(Z, P): {np.corrcoef(z_flat, p_flat)[0,1]:.2f}\\nStrong Relevance\", \n                transform=axes[0, 0].transAxes, bbox=dict(facecolor='white', alpha=0.9))\n\n# ---------------------------------------------------------\n# (B) Confounding Bias: 가격(P) vs 판매량(Y) (관측 데이터)\n# ---------------------------------------------------------\n# X(성수기 여부)가 P와 Y 모두를 증가시키는 교란(Confounding) 현상 시각화\nscatter = axes[0, 1].scatter(p_flat, y_flat, c=x_flat, cmap='coolwarm', alpha=0.3, s=15)\naxes[0, 1].set_title('(B) Confounding Bias: Observed P vs Y', fontsize=14, weight='bold')\naxes[0, 1].set_xlabel('Price P')\naxes[0, 1].set_ylabel('Sales Y')\ncbar = plt.colorbar(scatter, ax=axes[0, 1])\ncbar.set_label('Confounder X (Seasonality)', rotation=270, labelpad=15)\naxes[0, 1].text(0.05, 0.05, \"Endogeneity Present:\\nHigh X causes High P & High Y\", \n                transform=axes[0, 1].transAxes, bbox=dict(facecolor='white', alpha=0.9))\n\n# ---------------------------------------------------------\n# (C) Covariate Distribution: 공변량(X) -> 가격(P)\n# ---------------------------------------------------------\nsns.kdeplot(x=p_flat, hue=(x_flat > 0.5), fill=True, ax=axes[1, 0], palette='coolwarm')\naxes[1, 0].set_title('(C) P Distribution by Seasonality (X)', fontsize=14, weight='bold')\naxes[1, 0].set_xlabel('Treatment P (Price)')\naxes[1, 0].legend(['High Season (X>0.5)', 'Low Season (X<=0.5)'])\n\n# ---------------------------------------------------------\n# (D) The \"True\" Causal Curve (Ground Truth)\n# ---------------------------------------------------------\ndef get_true_effect_consistent(p_input, x_val):\n    threshold = 35 + (40 * x_val)\n    base_effect = 150 / (1 + np.exp(0.8 * (p_input - threshold)))\n    return base_effect + (50 * x_val)\n\np_range = np.linspace(p_flat.min(), p_flat.max(), 300)\n\naxes[1, 1].scatter(p_flat, y_flat, color='gray', alpha=0.05, label='Observed Samples')\n\n# 시나리오별 True Curve 그리기\n# X=0.1 (비수기), X=0.5 (평균), X=0.9 (성수기)\nlines_x = [0.1, 0.5, 0.9]\ncolors = ['blue', 'green', 'red']\nlabels = ['Low Season (X=0.1)', 'Avg Season (X=0.5)', 'High Season (X=0.9)']\n\nfor lx, c, lbl in zip(lines_x, colors, labels):\n    y_true = get_true_effect_consistent(p_range, lx)\n    axes[1, 1].plot(p_range, y_true, color=c, linewidth=2.5, linestyle='--', label=f'True: {lbl}')\n\naxes[1, 1].set_title('(D) Ground Truth: Heterogeneous S-Curves', fontsize=14, weight='bold')\naxes[1, 1].set_xlabel('Treatment P (Price)')\naxes[1, 1].set_ylabel('Outcome Y (Sales)')\naxes[1, 1].legend(loc='upper right', frameon=True, framealpha=0.9)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/data-visualization-output-1.png){#data-visualization width=1712 height=1130}\n:::\n:::\n\n\n---\n\n# 3. Benchmark: Linear 2SLS\n\n* 비교를 위해 전통적인 Linear 2SLS를 먼저 수행합니다.\n*  `scikit-learn`을 사용하여 2단계 회귀분석을 진행합니다.\n    * 1. Stage 1: Predict $P$ using $Z, X$\n    * 2. Stage 2: Regress Y on $\\hat{P}, X$ \n\n::: {#linear-2sls .cell execution_count=5}\n``` {.python .cell-code}\n# [Stage 1] P ~ Z + X\n# 도구변수(Z)와 공변량(X)를 사용하여 내생변수(P)를 예측.\nZX_data = np.concatenate((Z_data, X_data), axis=1)\nstage1_model = LinearRegression()\nstage1_model.fit(ZX_data, P_data)\n\n# P_hat (Hat P): 내생성이 제거된 P의 부분\nP_hat = stage1_model.predict(ZX_data)\n\n# [Stage 2] Y ~ P_hat + X\n# 예측된 처치(P_hat)와 공변량(X)를 사용하여 결과(Y)를 예측.\nPX_hat_data = np.concatenate((P_hat, X_data), axis=1)\nstage2_model = LinearRegression()\nstage2_model.fit(PX_hat_data, Y_data)\n\nprint(\"Linear 2SLS Training Complete.\")\nprint(f\"Estimated Causal Effect (Coefficient of P): {stage2_model.coef_[0][0]:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear 2SLS Training Complete.\nEstimated Causal Effect (Coefficient of P): -3.1744\n```\n:::\n:::\n\n\n---\n\n# 4. Deep IV Implementation\n\n* 구현에 들어가기에 앞서, **\"왜 굳이 두 개의 신경망이 필요한가?\"**를 수학적으로 짚고 넘어갑시다.\n\n## Mathematical Intuition: Why Two Stages?\n\n* 우리의 목표는 인과 함수 $g(P, X)$를 찾는 것입니다. \n* 하지만 앞서 보았듯 $Y = g(P, X) + \\epsilon$ 식에서 바로 회귀분석을 할 수 없습니다. \n* 오차항 $\\epsilon$이 $P$와 상관관계가 있기 때문입니다.\n\n* 이 문제를 해결하기 위해, 우리는 식의 양변에 **도구 변수 $Z$와 공변량 $X$에 대한 조건부 기댓값(Conditional Expectation)**을 취합니다.\n\n$$E[Y | X, Z] = E[g(P, X) + \\epsilon | X, Z]$$\n\n* 기댓값의 선형성(Linearity)에 의해 우변을 분리할 수 있습니다.\n\n$$E[Y | X, Z] = E[g(P, X) | X, Z] + \\underbrace{E[\\epsilon | X, Z]}_{= 0}$$\n\n* **도구 변수의 정의(외생성)**에 의해, 도구 변수는 오차항과 공변량이 주어진 경우 독립입니다. \n* 따라서 $z \\perp \\epsilon | x \\Longrightarrow E[\\epsilon | X, Z] = 0$이 되어 오차항이 사라집니다.\n\n* 이제 남은 식을 적분 형태로 풀어서 쓰면 다음과 같습니다.\n\n$$E[Y | X, Z] = \\int g(p, x) dF(p | x, z)$$\n\n* 이 식은 Deep IV 모델의 청사진이 됩니다.\n    * 1.  **$F(p | x, z)$:** 우변의 적분을 계산하려면, $Z$와 $X$가 주어졌을 때 $P$가 어떻게 분포하는지 알아야 합니다. $\\rightarrow$ **Stage 1 (Treatment Network)**\n    * 2.  **$g(p, x)$:** 위 등식을 만족시키는 미지의 함수 $g$를 찾아야 합니다. $\\rightarrow$ **Stage 2 (Outcome Network)**\n\n* 결국 Deep IV는 **\"1단계에서 추정한 분포($F$)를 이용해 2단계 함수($g$)를 적분했을 때, 그 결과가 실제 관측된 $Y$의 평균과 일치하도록\"** 학습하는 과정입니다.\n\n---\n\n## Stage 1: Mixture Density Network (MDN)\n\n* Deep IV의 첫 번째 단계는 'Treatment Network'를 구축하는 것입니다. \n* 이 단계의 핵심은 전통적인 방식과의 차이점을 이해하는 데 있습니다.\n\n### 1.1. Why Density Estimation? (Point vs. Distribution)\n\n* 전통적인 **Linear 2SLS** 1단계에서는 도구변수($Z$)와 공변량($X$)을 사용하여 처치 변수의 **평균(Mean)**을 예측합니다.\n$$\\hat{P}_{2SLS} = E[P | Z, X] \\approx \\alpha Z + \\beta X$$\n* 이는 $P$와 $Z$의 관계가 선형적이고, 오차가 등분산(Homoscedastic)을 가진다는 강력한 가정을 전제로 합니다.\n\n* 하지만 논문(Hartford et al., 2017)에서는 현실 데이터가 이보다 훨씬 복잡하다고 지적합니다.\n* 가격($P$) 결정 과정은 다봉형(Multimodal)일 수도 있고, 시기($X$)에 따라 변동성(Variance)이 달라질 수도 있습니다. \n* 따라서 단순한 평균값 하나로는 정보 손실이 발생합니다.\n\n* **Deep IV의 1단계 목표**는 $P$의 값을 하나로 예측하는 것이 아니라, $Z$와 $X$가 주어졌을 때 $P$가 가질 수 있는 **조건부 확률 분포(Conditional Probability Distribution)** 전체를 추정하는 것입니다.\n\n### 1.2. The Mixture Density Network (MDN)\n\n* 복잡한 분포를 유연하게 추정하기 위해, Deep IV는 **MDN(Mixture Density Network)** 구조를 사용합니다. \n* 이는 신경망의 출력을 이용해 **가우시안 혼합 모델(Gaussian Mixture Model, GMM)**의 파라미터를 구성하는 방식입니다.\n\n$$\\hat{F}(p|z,x) = \\sum_{k=1}^{K} \\pi_k(z,x) \\mathcal{N}(p ; \\mu_k(z,x), \\sigma_k^2(z,x))$$\n\n* 이 수식의 의미는 다음과 같습니다.\n\n* **$\\mathcal{N}$ (Normal Distribution):** $K$개의 정규분포를 섞어서 복잡한 분포를 표현합니다.\n* **신경망의 역할:** 입력($Z, X$)을 받아 각 정규분포의 파라미터 3가지를 출력합니다.\n    1.  **$\\pi_k$ (Mixing Coefficient):** $k$번째 정규분포가 선택될 확률 (가중치, $\\sum \\pi_k = 1$)\n    2.  **$\\mu_k$ (Mean):** $k$번째 정규분포의 중심 (평균)\n    3.  **$\\sigma_k$ (Standard Deviation):** $k$번째 정규분포의 퍼짐 정도 (분산)\n\n### 1.3. Deep IV Architecture: Treatment Network\n* 논문에서 제시하는 네트워크 구조를 도식화하면 다음과 같습니다.\n    * 1.  **Input:** 도구변수($Z$)와 공변량($X$)이 신경망에 들어갑니다.\n    * 2.  **Hidden Layers:** 데이터의 비선형적인 패턴을 학습합니다.\n    * 3.  **Output Heads:** 마지막 층은 세 갈래로 나뉩니다.\n        * `Softmax` $\\rightarrow$ $\\pi$ (가중치)\n        * `Linear` $\\rightarrow$ $\\mu$ (평균)\n        * `Softplus` $\\rightarrow$ $\\sigma$ (표준편차, 양수 제약)\n\n::: {#deep-iv-stage1-model .cell execution_count=6}\n``` {.python .cell-code}\nclass FirstStageMDN(nn.Module):\n    def __init__(self, input_dim, num_gaussians=5):\n        super().__init__()\n        self.shared_layer = nn.Sequential(\n            nn.Linear(input_dim, 64),\n            nn.ReLU(),\n            nn.Linear(64, 64),\n            nn.ReLU()\n        )\n        self.pi_head = nn.Linear(64, num_gaussians)     # 혼합 계수\n        self.mu_head = nn.Linear(64, num_gaussians)     # 평균\n        self.sigma_head = nn.Linear(64, num_gaussians)  # 표준편차\n\n    def forward(self, x, z):\n        # 1. 입력 결합\n        # Shape: (Batch, x_dim) + (Batch, z_dim) -> (Batch, input_dim)\n        inputs = torch.cat([x, z], dim=1)\n        \n        # 2. 특징 추출\n        # Shape: (Batch, input_dim) -> (Batch, 64)\n        features = self.shared_layer(inputs)\n        \n        # 3. 파라미터 추정 (K=num_gaussians)\n        # Pi: (Batch, K)\n        pi = F.softmax(self.pi_head(features), dim=1)\n        # Mu: (Batch, K)\n        mu = self.mu_head(features)\n        # Sigma: (Batch, K)\n        sigma = F.softplus(self.sigma_head(features)) + 1e-5\n        \n        return pi, mu, sigma\n\n    def sample(self, pi, mu, sigma, n_samples=1):\n        mix = D.Categorical(probs=pi)\n        comp = D.Normal(loc=mu, scale=sigma)\n        gmm = D.MixtureSameFamily(mix, comp)\n        \n        # 샘플링 수행\n        if n_samples == 1:\n            # Shape: (Batch) -> (Batch, 1)\n            return gmm.sample().unsqueeze(-1)\n        else:\n            # Shape: (n_samples, Batch) -> (Batch, n_samples)\n            return gmm.sample((n_samples,)).permute(1, 0)\n```\n:::\n\n\n### 1.4. Optimization Objective (Negative Log-Likelihood)\n\n* 이 신경망을 학습시키기 위해 사용하는 손실 함수는 **음의 로그 우도(Negative Log-Likelihood, NLL)**입니다.\n\n$$\\mathcal{L}_1(\\phi) = - \\sum_{i=1}^{N} \\log \\left( \\sum_{k=1}^{K} \\pi_k(z_i, x_i) \\cdot \\frac{1}{\\sqrt{2\\pi}\\sigma_k(z_i, x_i)} \\exp \\left( -\\frac{(p_i - \\mu_k(z_i, x_i))^2}{2\\sigma_k^2(z_i, x_i)} \\right) \\right)$$\n\n* 쉽게 말해, **\"실제 관측된 가격 데이터($p_i$)가 우리 모델의 확률 분포에서 등장할 확률을 최대화하라\"**는 뜻입니다. \n* 이를 통해 신경망은 데이터가 뭉쳐 있는 곳(Mode)과 퍼져 있는 정도(Variance)를 정확하게 학습하게 됩니다.\n\n::: {#deep-iv-stage1-loss-function .cell execution_count=7}\n``` {.python .cell-code}\ndef first_stage_loss_fn(pi, mu, sigma, p):\n    # 1. 로그 확률 밀도 계산 (Log Probability)\n    # Shape: (Batch, K)\n    m = D.Normal(loc=mu, scale=sigma)\n    log_probs_component = m.log_prob(p)\n    \n    # 2. 가중치 반영 및 Log-Sum-Exp\n    # Shape: (Batch, K) -> (Batch,)\n    weighted_log_probs = torch.log(pi + 1e-8) + log_probs_component\n    log_likelihood = torch.logsumexp(weighted_log_probs, dim=1)\n    \n    # 3. NLL 평균 (Scalar)\n    return -torch.mean(log_likelihood)\n```\n:::\n\n\n---\n\n## Stage 2: Outcome Network\n\n* 1단계에서 우리는 가격($P$)이 형성되는 확률 분포 $\\hat{F}(P|Z,X)$를 얻었습니다. \n* 이제 두 번째 단계에서는 이를 바탕으로 **진짜 인과 함수(Causal Function)** $g(P, X)$를 찾아낼 차례입니다.\n\n### 2.1. The Structural Equation\n\n* 우리의 목표는 다음 식을 만족하는 함수 $g$를 찾는 것입니다.\n\n$$E[Y | Z, X] = \\int g(p, x) dF(p | z, x)$$\n\n* 이 식은 **\"도구변수($Z$)와 공변량($X$)이 주어졌을 때, 예상되는 판매량($Y$)의 평균은, 가능한 모든 가격($p$)에 대해 해당 가격일 확률과 그 때의 판매량을 곱해서 더한(적분한) 것과 같다\"**는 의미입니다.\n\n* 여기서 중요한 점은 우리가 1단계 모델(MDN)을 통해 분포 $F$를 이미 알고 있다는 것입니다. \n* 따라서 남은 미지수인 함수 $g$를 신경망으로 근사할 수 있습니다.\n\n### 2.2. The Loss Function (Inverse Problem)\n\n* 2단계 신경망(Outcome Network)을 학습시키기 위한 손실 함수는 다음과 같이 정의됩니다.\n$$L(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} \\left( y_i - \\int g_{\\theta}(p, x_i) d\\hat{F}_{\\phi}(p | z_i, x_i) \\right)^2$$\n    * **$y_i$:** 실제 관측된 결과 (Target)\n    * **$\\int g_{\\theta} d\\hat{F}_{\\phi}$:** 1단계 모델의 분포를 반영한 예측값 (Prediction)\n\n* 이 손실 함수의 핵심 아이디어는 **\"내생성이 있는 개별 $P$값 하나를 믿는 대신, 1단계 모델이 예측한 $P$의 '분포 전체'를 믿겠다\"**는 것입니다. \n* 분포를 적분하여 얻은 기댓값이 실제 $Y$와 일치하도록 강제함으로써, 오차항($\\epsilon$)의 영향을 상쇄시킵니다.\n\n### 2.3. Deep IV Architecture: Outcome Network\n* 2단계 네트워크의 작동 방식은 다음과 같습니다.\n    * 1.  **Input:** 1단계 분포에서 샘플링된 $\\hat{P}$와 공변량 $X$를 입력받습니다.\n    * 2.  **Hidden Layers:** 인과 함수 $g(P,X)$의 형태(예: 비선형 S자 곡선)를 학습합니다.\n    * 3.  **Output:** 예측된 $Y$값을 출력합니다.\n\n::: {#deep-iv-stage2-model .cell execution_count=8}\n``` {.python .cell-code}\nclass SecondStageH(nn.Module):\n    def __init__(self, x_dim, p_dim=1, output_dim=1):\n        super().__init__()\n        input_dim = x_dim + p_dim\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, 128),\n            nn.ReLU(),\n            nn.Linear(128, 128),\n            nn.ReLU(),\n            nn.Linear(128, output_dim)\n        )\n        \n    def forward(self, p, x):\n        # 입력 결합\n        # Shape: (Batch, S, p_dim) + (Batch, S, x_dim) -> (Batch, S, input_dim)\n        inputs = torch.cat([p, x], dim=-1) \n        return self.net(inputs)\n```\n:::\n\n\n### 2.4. Monte Carlo Approximation\n\n* 현실적으로 딥러닝 학습 중에 복잡한 적분($\\int$)을 매번 계산하는 것은 불가능에 가깝습니다. \n* 따라서 Deep IV는 **몬테카를로 샘플링(Monte Carlo Sampling)**을 사용하여 적분을 근사합니다.\n$$\\int g_{\\theta}(p, x_i) d\\hat{F}_{\\phi}(p | z_i, x_i) \\approx \\frac{1}{S} \\sum_{s=1}^{S} g_{\\theta}(\\hat{p}^{(s)}, x_i)$$\n    * 여기서 $\\hat{p}^{(s)}$는 1단계 MDN 모델에서 샘플링한 값들입니다 ($\\hat{p}^{(s)} \\sim \\hat{F}_{\\phi}$).\n    * $S$는 샘플 개수입니다 (보통 10~30개 사용).\n\n* 즉, **\"1단계 모델이 시뮬레이션한 가상의 가격들($\\hat{p}$)을 2단계 모델에 넣어보고, 그 평균값이 실제 판매량($y$)과 비슷해지도록\"** 학습하는 것입니다. \n\n::: {#deep-iv-stage2-loss-function .cell execution_count=9}\n``` {.python .cell-code}\ndef second_stage_loss_fn(treatment_net, outcome_net, pi, mu, sigma, x, y, num_samples=32):\n    # 1. 몬테카를로 샘플링\n    # Shape: (Batch, S) -> (Batch, S, 1)\n    p_samples = treatment_net.sample(pi, mu, sigma, n_samples=num_samples).unsqueeze(-1).detach()\n    \n    # 2. 공변량 차원 확장\n    # Shape: (Batch, x_dim) -> (Batch, S, x_dim)\n    batch_size, x_dim = x.shape\n    x_expanded = x.unsqueeze(1).expand(-1, num_samples, -1)\n    \n    # 3. 결과 예측 (Outcome Network Forward)\n    # Shape: (Batch, S, 1) + (Batch, S, x_dim) -> (Batch, S, 1)\n    y_pred_samples = outcome_net(p_samples, x_expanded)\n    \n    # 4. 기댓값 근사 (Sample Mean)\n    # Shape: (Batch, S, 1) -> (Batch, 1)\n    y_pred_expectation = y_pred_samples.mean(dim=1)\n    \n    # 5. 손실 계산 (MSE)\n    # Shape: (Batch, 1) vs (Batch, 1) -> Scalar\n    loss = F.mse_loss(y_pred_expectation, y.view(-1, 1))\n    \n    return loss\n```\n:::\n\n\n## Training Procedure\n\n* Deep IV의 학습은 일반적인 지도 학습(Supervised Learning)과는 다르게, **순차적인 두 단계(Sequential Two-Stage Process)**로 진행됩니다.\n\n#### Phase 1: Distribution Learning (Treatment Network)\n* 첫 번째 단계에서는 **Treatment Network**만을 학습시킵니다.\n    * **목표:** 도구변수($Z$)와 공변량($X$)을 보고, 처치변수($P$)가 어떻게 분포하는지 완벽하게 모사하는 것입니다.\n    * **학습 방법:** `NLL Loss`를 최소화하여 실제 데이터 $P$가 모델의 확률 분포 안에 위치할 확률을 높입니다.\n    * **주의점:** 이때 결과변수 $Y$는 전혀 사용하지 않습니다.\n\n#### Transition: The Freeze\n* 1단계 학습이 끝나면 Treatment Network의 파라미터($\\phi$)를 **동결(Freeze)**합니다.\n* 이제 1단계 모델은 더 이상 학습 대상이 아니라, 내생성이 제거된 가상의 처치값 $\\hat{P}$를 생성해내는 **시뮬레이터(Generator)** 역할을 수행합니다.\n\n#### Phase 2: Causal Learning (Outcome Network)\n* 두 번째 단계에서는 **Outcome Network**를 학습시킵니다.\n    * **입력:** 실제 관측된 $P$를 사용하는 것이 아니라, **동결된 1단계 모델에서 샘플링한 $\\hat{P}$**를 사용합니다.\n    * **목표:** $\\hat{P}$를 입력받았을 때의 예측값 평균이 실제 $Y$와 가까워지도록 합니다.\n    * **학습 방법:** `MSE Loss`를 최소화하여 인과 함수 $g(P, X)$를 근사합니다.\n\n::: {#training .cell execution_count=10}\n``` {.python .cell-code}\n# -----------------------------------------------------\n# [Stage 1] Treatment Network Training (Z + X -> P distribution)\n# -----------------------------------------------------\ntreatment_net = FirstStageMDN(\n    input_dim=X.shape[-1] + Z.shape[-1], \n    num_gaussians=5\n)\n\nopt1 = optim.Adam(treatment_net.parameters(), lr=1e-4)\nepochs_stage1 = 1000\n\nprint(f\"Starting Stage 1 Training (Epochs: {epochs_stage1})...\")\n\ntreatment_net.train()\nfor epoch in range(epochs_stage1):\n    # 1. Forward Pass\n    pi, mu, sigma = treatment_net(X, Z)\n    # 2. Loss Calculation (Negative Log Likelihood)\n    loss1 = first_stage_loss_fn(pi, mu, sigma, P)\n    # 3. Optimization\n    opt1.zero_grad()\n    loss1.backward()\n    opt1.step()\n    \n    if (epoch + 1) % 100 == 0:\n        print(f\"[Stage 1] Epoch [{epoch+1}/{epochs_stage1}] | Loss: {loss1:.4f} | Avg Sigma: {sigma.mean().item():.4f}\")\n\n# -----------------------------------------------------\n# [Transition] Freeze Stage 1\n# -----------------------------------------------------\ntreatment_net.eval()\nfor param in treatment_net.parameters():\n    param.requires_grad = False\nprint(\"Stage 1 Freezed.\")\n\n# -----------------------------------------------------\n# [Stage 2] Outcome Network Training (Resampled P + X -> Y)\n# -----------------------------------------------------\noutcome_net = SecondStageH(\n    x_dim=X.shape[-1], \n    p_dim=1, \n    output_dim=1\n)\n\nopt2 = optim.Adam(outcome_net.parameters(), lr=1e-4)\nepochs_stage2 = 1000\n\nprint(f\"\\nStarting Stage 2 Training (Epochs: {epochs_stage2})...\")\n\noutcome_net.train()\nfor epoch in range(epochs_stage2):\n    total_loss = 0\n\n    with torch.no_grad():\n        pi, mu, sigma = treatment_net(X, Z)\n    \n    # 2단계 Loss 계산\n    loss2 = second_stage_loss_fn(\n        treatment_net=treatment_net,\n        outcome_net=outcome_net, \n        pi=pi, \n        mu=mu, \n        sigma=sigma, \n        x=X, \n        y=Y, \n        num_samples=20 \n    )\n    # Optimization\n    opt2.zero_grad()\n    loss2.backward()\n    opt2.step()\n\n    \n    if (epoch + 1) % 100 == 0:\n        print(f\"[Stage 2] Epoch [{epoch+1}/{epochs_stage2}] | Loss: {loss2:.4f}\")\n   \nprint(\"Deep IV Training Complete.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStarting Stage 1 Training (Epochs: 1000)...\n[Stage 1] Epoch [100/1000] | Loss: 1.2856 | Avg Sigma: 0.7154\n[Stage 1] Epoch [200/1000] | Loss: 0.9596 | Avg Sigma: 0.7089\n[Stage 1] Epoch [300/1000] | Loss: 0.4444 | Avg Sigma: 0.5747\n[Stage 1] Epoch [400/1000] | Loss: 0.0173 | Avg Sigma: 0.4232\n[Stage 1] Epoch [500/1000] | Loss: -0.0957 | Avg Sigma: 0.3575\n[Stage 1] Epoch [600/1000] | Loss: -0.1652 | Avg Sigma: 0.3127\n[Stage 1] Epoch [700/1000] | Loss: -0.2732 | Avg Sigma: 0.2715\n[Stage 1] Epoch [800/1000] | Loss: -0.5004 | Avg Sigma: 0.2285\n[Stage 1] Epoch [900/1000] | Loss: -0.6765 | Avg Sigma: 0.2038\n[Stage 1] Epoch [1000/1000] | Loss: -0.8385 | Avg Sigma: 0.1843\nStage 1 Freezed.\n\nStarting Stage 2 Training (Epochs: 1000)...\n[Stage 2] Epoch [100/1000] | Loss: 0.1417\n[Stage 2] Epoch [200/1000] | Loss: 0.1078\n[Stage 2] Epoch [300/1000] | Loss: 0.0914\n[Stage 2] Epoch [400/1000] | Loss: 0.0852\n[Stage 2] Epoch [500/1000] | Loss: 0.0758\n[Stage 2] Epoch [600/1000] | Loss: 0.0701\n[Stage 2] Epoch [700/1000] | Loss: 0.0658\n[Stage 2] Epoch [800/1000] | Loss: 0.0679\n[Stage 2] Epoch [900/1000] | Loss: 0.0682\n[Stage 2] Epoch [1000/1000] | Loss: 0.0615\nDeep IV Training Complete.\n```\n:::\n:::\n\n\n---\n\n## 5. Result Visualization\n\n* 학습된 모델이 실제 인과 효과 곡선(Ground Truth)을 얼마나 잘 복원했는지 확인합니다.\n* 테스트는 **성수기와 비성수기의 중간($X=0.5$)** 조건을 가정합니다.\n\n::: {#cell-visualization .cell execution_count=11}\n``` {.python .cell-code}\n# ===========================================================\n# 1. 테스트 데이터 생성\n# ===========================================================\np_min, p_max = P_data.min(), P_data.max()\np_test = np.linspace(p_min, p_max, 200).reshape(-1, 1)\n\nfixed_x_val = 0.5\nx_test = np.full_like(p_test, fixed_x_val)\n\ndef true_structural_function(p_val, x_val):\n    threshold = 35 + (40 * x_val)\n    base_effect = 150 / (1 + np.exp(0.8 * (p_val - threshold)))\n    return base_effect + (50 * x_val)\n        \ntrue_y = true_structural_function(p_test, x_test)\n\n# ===========================================================\n# 2. Linear 2SLS 예측\n# ===========================================================\npx_test_linear = np.concatenate((p_test, x_test), axis=1)\nlinear_pred = stage2_model.predict(px_test_linear)\n\n# ===========================================================\n# 3. DeepIV 예측\n# ===========================================================\noutcome_net.eval()\n\np_test_scaled = scaler_p.transform(p_test)\nx_test_scaled = scaler_x.transform(x_test)\np_tensor = torch.tensor(p_test_scaled, dtype=torch.float32)\nx_tensor = torch.tensor(x_test_scaled, dtype=torch.float32)\n\nwith torch.no_grad():\n    y_pred_scaled = outcome_net(p_tensor, x_tensor)    \n    deep_pred = scaler_y.inverse_transform(y_pred_scaled.numpy())\n\n# ===========================================================\n# 4. 최종 시각화\n# ===========================================================\nplt.figure(figsize=(12, 8))\n\n# 배경: 관측 데이터\nplt.scatter(P_data, Y_data, color='gray', alpha=0.1, s=10, label='Observed Data')\n\n# 1. Ground Truth (검은 실선)\nplt.plot(p_test, true_y, 'k-', linewidth=3, label='Ground Truth')\n\n# 2. Linear 2SLS (빨간 점선)\nplt.plot(p_test, linear_pred, 'r--', linewidth=2.5, label='Linear 2SLS')\n\n# 3. Deep IV (파란 실선)\nplt.plot(p_test, deep_pred, 'b-', linewidth=2.5, label='Deep IV')\n\nplt.title(f\"Causal Effect Estimation: Non-linear Pricing (at Seasonality X={fixed_x_val})\", fontsize=16, weight='bold')\nplt.xlabel(\"Treatment: Ticket Price (P)\", fontsize=13)\nplt.ylabel(\"Outcome: Sales (Y)\", fontsize=13)\nplt.legend(fontsize=12, loc='upper right', framealpha=0.9)\nplt.grid(True, alpha=0.3, linestyle='--')\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Comparison of Causal Effect Estimation](index_files/figure-html/visualization-output-1.png){#visualization width=1138 height=755}\n:::\n:::\n\n\n## Conclusion\n\n* 결과 그래프에서 볼 수 있듯이:\n    * 1. **Linear 2SLS**는 데이터의 비선형성을 무시하고 단순한 직선으로 효과를 추정하여, 가격 임계값 근처에서의 급격한 수요 변화를 포착하지 못합니다.\n    * 2. **Deep IV**는 실제 인과 곡선(Ground Truth)인 S자 형태를 매우 정확하게 복원해냈습니다.\n\n* 이는 비선형성이 강하게 의심될 때, 딥러닝 기반의 인과추론 방법론이 강력한 대안이 될 수 있음을 시사합니다.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}