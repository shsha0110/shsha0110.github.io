---
title: "[Causal Inference] Appendix 03. Soft-Intervention and σ-calculus (Part 3)"
description: "Comparisons to do-calculus"
author: "유성현"
date: "2026-02-07"
categories: [Causal Inference]
format:
  html:
    toc: true
    number-sections: false
    code-fold: show
    math: true
---

# 1. Introduction: Why Soft Interventions?

인과추론(Causal Inference)에서 가장 널리 알려진 개념은 Pearl의 **do-calculus**입니다. 이는 변수 $X$를 특정 값 $x$로 강제로 고정하는 **Atomic Intervention**($do(X=x)$)을 다룹니다. 하지만 현실 세계의 개입은 변수를 특정 값으로 완벽하게 고정하기보다, 변수의 확률 분포를 변화시키는 형태가 더 많습니다. [cite_start]이를 **Soft Intervention** 또는 **Stochastic Intervention**이라고 하며, 이를 다루기 위한 체계를 **$\sigma$-calculus**라고 합니다[cite: 1, 2, 5].

이번 포스트에서는 강의 자료를 바탕으로 Soft Intervention의 동기, do-calculus와의 비교, 그리고 구체적인 계산 규칙과 예시를 심도 있게 다룹니다.

## 1.1 Atomic vs. Soft Intervention

가장 중요한 차이점은 개입 후 변수의 **결정론적(Deterministic) 성질** 여부입니다.

* **Atomic Intervention ($do(x)$)**: $X$가 특정 값으로 고정되므로, $X$는 더 이상 확률 변수가 아니라 상수가 됩니다. 따라서 다음이 성립합니다.
    $$P(y|do(x), w) = P(y|do(x), w, x)$$
    [cite_start]$X$가 이미 결정되어 있으므로 조건부 확률에 $x$를 추가해도 정보량의 변화가 없습니다[cite: 9, 10].

* **Soft Intervention ($\sigma_X$)**: 개입 후에도 $X$는 여전히 확률 변수로 남아 있습니다. 예를 들어, "공부 시간을 늘리도록 장려한다"는 개입은 공부 시간을 특정 값으로 고정하는 것이 아니라 분포를 바꿀 뿐입니다. 따라서 일반적으로 다음 부등식이 성립합니다.
    $$P(y; \sigma_X) \neq P(y|x; \sigma_X)$$
    [cite_start]즉, 개입 상황($\sigma_X$)에서도 $X$의 구체적인 값 $x$를 관측하는 것은 $Y$에 대한 추가적인 정보를 제공합니다[cite: 11, 13].

# 2. Comparison: do-calculus vs. $\sigma$-calculus

Soft Intervention을 다루는 $\sigma$-calculus는 do-calculus의 세 가지 규칙을 일반화한 형태입니다. 핵심은 **조건부 독립(Conditional Independence)**을 확인해야 하는 그래프의 조건이 다르다는 점입니다. [cite_start]Soft Intervention은 그래프 구조를 단순히 끊어내는 것이 아니라 의존성을 유지하거나 변경할 수 있으므로, **Pre-intervention Graph(원래 그래프)**와 **Post-intervention Graph(개입된 그래프)** 모두에서 독립성을 확인해야 할 때가 많습니다[cite: 20, 28, 35].

## Rule 1: Insertion/Deletion of Observations

변수 집합 $Z$를 조건부에서 제거하거나 추가할 수 있는 규칙입니다.

* **do-calculus**:
    $$P(y|do(x), w, t) = P(y|do(x), w) \quad \text{if } (Y \perp T | W, X) \text{ in } G_{\overline{X}}$$
    [cite_start]$X$로 들어오는 화살표를 제거한 그래프 $G_{\overline{X}}$에서 d-separation이 성립해야 합니다[cite: 17].

* **$\sigma$-calculus**:
    $$P(y|w, t; \sigma_X) = P(y|w; \sigma_X) \quad \text{if } (Y \perp T | W) \text{ in } G_{\sigma_X}$$
    [cite_start]개입이 명시된 그래프 $G_{\sigma_X}$에서 조건부 독립이 성립해야 합니다[cite: 18, 19]. [cite_start]여기서 그래프 $G_{\sigma_X}$는 개입의 구체적인 명세(specification)에 따라 달라집니다[cite: 20].

## Rule 2: Action/Observation Exchange

개입(Action)을 관측(Observation)으로 바꾸거나 그 반대로 할 수 있는 규칙입니다. (Backdoor criterion과 관련됨).

* **do-calculus**:
    $$P(y|do(x), w) = P(y|x, w) \quad \text{if } (Y \perp X | W) \text{ in } G_{\underline{X}}$$
    [cite_start]$X$에서 나가는 화살표를 제거한 그래프 $G_{\underline{X}}$에서 독립성이 성립해야 합니다[cite: 24, 25].

* **$\sigma$-calculus**:
    $$P(y|x, w; \sigma_X) = P(y|x, w)$$
    이 식은 $\sigma_X$ 하에서의 조건부 확률이 자연 상태(Natural Regime)의 조건부 확률과 같음을 의미합니다. [cite_start]이를 위해서는 다음 두 그래프 **모두**에서 독립성이 성립해야 합니다[cite: 26, 27].
    1.  $G_{\sigma_X}$ (개입된 그래프)
    2.  $G_{\underline{X}}$ (do-calculus의 조건과 유사한 그래프 맥락)

    > [cite_start]**Note:** 독립성은 Pre-intervention 그래프와 Post-intervention 그래프 모두에서 유지되어야 합니다[cite: 28].

## Rule 3: Insertion/Deletion of Actions

개입 자체를 제거(무시)할 수 있는 규칙입니다.

* **do-calculus**:
    $$P(y|do(x), w) = P(y|w) \quad \text{if } (Y \perp X | W) \text{ in } G_{\overline{X(W)}}$$
    [cite_start][cite: 32].

* **$\sigma$-calculus**:
    $$P(y|w; \sigma_X) = P(y|w)$$
    개입 $\sigma_X$가 $Y$의 주변 확률(marginal probability)에 영향을 주지 않는 경우입니다. [cite_start]이 역시 다음 두 조건에서 독립성이 확인되어야 합니다[cite: 33, 34].
    1.  $G_{\sigma_X \overline{X(W)}}$
    2.  $G_{\overline{X(W)}}$

# 3. Case Study: Revisiting Rule 2 (Failure Case)

Rule 2를 적용할 때, 단순히 do-calculus의 직관만으로 접근하면 오류가 발생할 수 있습니다. 아래 예시를 살펴봅시다.

![Figure 1: Rule 2 적용을 위한 그래프 구조 비교. 왼쪽은 원본 그래프, 오른쪽은 개입 상황을 나타낸 그래프이다.](./images/rule2_failure_graph.png)

위 그림과 같은 구조에서 $X_1$에 대한 개입을 고려할 때, 우리는 다음 등식을 확인하고 싶습니다.

$$P(y|x_1; \sigma_{X_1, X_2}) \stackrel{?}{=} P(y|x_1; \sigma_{X_2})$$
[cite_start][cite: 38, 39, 41]

[cite_start]Rule 2를 적용하여 $do(X_1)$ 혹은 $\sigma_{X_1}$을 일반 관측 조건 $x_1$으로 바꾸려면, **오른쪽의 두 그래프(Pre & Post) 모두에서 $X_1$과 $Y$ 사이의 Backdoor path가 없어야 합니다**[cite: 42].

[cite_start]하지만 자료에 따르면, 첫 번째 그래프에서는 성립할지 몰라도 두 번째 그래프(혹은 그 반대)와의 조건 불일치로 인해 **Rule 2를 적용할 수 없습니다**[cite: 43]. 즉, Soft Intervention에서는 개입으로 인해 변수 간의 의존성 구조가 미묘하게 남거나 변형될 수 있으므로 훨씬 엄격한 그래프 검사가 필요합니다.

# 4. Detailed Example: The Tutoring Intervention

자원이 제한된 학교에서 학생들의 성적($Y$)을 올리기 위해 튜터링($X$)을 제공하는 상황을 가정해 봅시다.

## 4.1 Scenario Setup

* **Variables**:
    * $W$: 학생의 이전 GPA (High=1, Low=0)
    * $Z$: 학생의 학습 동기 (Unobserved or Observed intermediate)
    * $X$: 튜터링 여부 (Tutoring=1, No=0)
    * $Y$: 최종 성적
* [cite_start]**Problem**: 자원이 제한적이므로, **GPA가 낮은 학생($W=0$)에게만 튜터링을 의무화**하고 싶습니다[cite: 54, 55].

이를 수식으로 표현하면 새로운 정책(Hypothesized Regime) $\sigma_X$는 다음과 같습니다.
$$P^*(X=1|W=0) = 1, \quad P^*(X=1|W=1) = 0$$
[cite_start]즉, $\sigma_X = \mathbb{1}[W=0]$ 와 같이 결정론적인 정책(policy)이 됩니다 (물론 확률적으로 설정할 수도 있습니다)[cite: 56, 63].

## 4.2 Graphical Models

이 시나리오는 두 가지 그래프로 표현됩니다.

![Figure 2: Natural Regime (왼쪽)과 Hypothesized Regime (오른쪽). 왼쪽은 자연 상태에서의 인과 관계를 보여주며, 오른쪽은 W(GPA)에 따라 X(Tutoring)가 결정되는 새로운 정책이 개입된 상태를 보여준다.](./images/tutoring_graphs.png)

* [cite_start]**Natural Regime ($G$)**: $W \to Z \to X$, $W \to X$ 등의 자연스러운 흐름이 존재[cite: 61].
* **Hypothesized Regime ($G_{\sigma_X}$)**: 튜터링 $X$가 오직 GPA $W$에 의해서만 결정되도록 개입함 ($W \to X$). [cite_start]기존의 $Z \to X$ 같은 연결은 끊어지거나 정책에 의해 재정의됨[cite: 64, 68].

## 4.3 Derivation of $P(y; \sigma_X)$

[cite_start]우리의 목표는 새로운 정책을 도입했을 때의 $Y$ 분포, 즉 $P(y; \sigma_X)$를 구하는 것입니다[cite: 71, 85].

### Step 1: Factorization using Chain Rule
먼저 $\sigma_X$ 하에서의 결합 확률분포를 모든 변수에 대해 전개합니다.
$$P(y; \sigma_X) = \sum_{w,z,x} P(y, x, z, w; \sigma_X)$$
이를 조건부 확률의 연쇄 법칙(Chain Rule)으로 분해합니다.
$$P(y; \sigma_X) = \sum_{w,z,x} P(y|x,z,w; \sigma_X) P(x|z,w; \sigma_X) P(z|w; \sigma_X) P(w; \sigma_X)$$
[cite_start][cite: 86]

### Step 2: Applying Invariance and Rules
이제 각 항을 분석하여 자연 상태의 확률(데이터로 추정 가능한 값)로 변환합니다.

1.  **Mechanism of $Y$ ($P(y|x,z,w; \sigma_X)$)**:
    $Y$는 $X, Z, W$의 결과입니다. $X$를 결정하는 정책이 바뀌었을 뿐, $X, Z, W$가 주어졌을 때 $Y$가 생성되는 메커니즘(자연 법칙)은 변하지 않았습니다.
    $$P(y|x,w,z; \sigma_X) = P(y|x,w,z)$$
    (이는 Rule 2의 변형 혹은 자율성 가정에 해당) [cite_start][cite: 87].

2.  **Policy of $X$ ($P(x|w, z; \sigma_X)$)**:
    새로운 정책 $\sigma_X$ 하에서 튜터링 $X$는 오직 $W$(GPA)에 의해서만 결정됩니다. 따라서 $Z$와는 독립이 됩니다.
    $$P(x|w, z; \sigma_X) = P(x|w; \sigma_X)$$
    [cite_start]이 값은 우리가 설계한 정책($P^*(X|W)$)이므로 **Known Value**입니다[cite: 86].

3.  **Distribution of Prior Variables ($P(z, w; \sigma_X)$)**:
    $W$와 $Z$는 $X$의 상위(upstream) 변수들입니다. $X$에 개입한다고 해서 그 원인이 되는 $W$나 $Z$의 분포가 변하지는 않습니다 (Rule 3의 개념).
    $$P(z|w; \sigma_X) P(w; \sigma_X) = P(z|w) P(w) = P(w, z)$$
    [cite_start][cite: 87].

### Step 3: Final Expression
위의 결과들을 종합하면 최종 식은 다음과 같습니다.

$$P(y; \sigma_X) = \sum_{w,z,x} \underbrace{P(y|x,w,z)}_{\text{Data}} \underbrace{P(x|w; \sigma_X)}_{\text{Policy}} \underbrace{P(w,z)}_{\text{Data}}$$

[cite_start]이 식은 관측 데이터($P(y|x,w,z), P(w,z)$)와 우리가 설정한 정책($P(x|w; \sigma_X)$)만을 이용하여, 개입 후의 결과 $P(y; \sigma_X)$를 계산할 수 있음을 보여줍니다[cite: 87].

![Figure 3: Derivation Flow. W, Z는 Natural Regime을 따르고(Rule 3), X는 새로운 Policy를 따르며, Y는 변수들이 주어졌을 때의 기존 메커니즘(Rule 2)을 따른다.](./images/derivation_flow.png)

# 5. Summary

Soft Intervention ($\sigma$-calculus)은 현실적인 정책 개입을 모형화하는 강력한 도구입니다.

1.  **유연성**: $do(x)$처럼 변수를 고정하지 않고, 조건부 확률 분포 $P(X|W)$를 변경하는 정책을 평가할 수 있습니다.
2.  **엄격함**: $do$-calculus보다 독립성 조건이 까다롭습니다. Pre-intervention 그래프뿐만 아니라 Post-intervention 그래프($G_{\sigma_X}$)에서의 구조적 변화도 고려해야 합니다.
3.  **계산 가능성**: 적절한 그래프 조건이 충족된다면, 복잡한 개입 효과($P(y; \sigma_X)$)를 관측 데이터와 정책 함수의 조합으로 분해하여 계산할 수 있습니다.

---

### 누락 방지 검증 체크리스트

* [x] **개념 정의**: Atomic vs. Soft Intervention의 결정론적 차이 설명 (Introduction)
* [x] **$\sigma$-calculus 규칙**: Rule 1, 2, 3의 정의와 $do$-calculus와의 비교 (Section 2)
* [x] **그래프 조건**: Pre-intervention 및 Post-intervention 그래프 모두에서 독립성 확인 필요성 강조 (Section 2, 3)
* [x] **실패 예시**: Rule 2가 적용되지 않는 구체적 사례 설명 (Section 3, Page 6 내용)
* [x] **상세 예제**: 튜터링(GPA) 예제의 시나리오, 그래프 변화, 수식 유도 과정 전체 포함 (Section 4, Page 7-10 내용)
* [x] **수식 유도**: Chain rule부터 최종 식까지 단계별 전개 (Section 4.3)