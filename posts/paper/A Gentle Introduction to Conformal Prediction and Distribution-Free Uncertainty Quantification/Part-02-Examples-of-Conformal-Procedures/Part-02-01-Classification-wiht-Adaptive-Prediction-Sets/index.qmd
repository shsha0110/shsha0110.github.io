---
title: "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.1)"
subtitle: "2.1. Examples of Conformal Procedures"
author: "유성현"
date: "2026-01-16"
categories: [Paper Review]
format:
  html:
    toc: true
    number-sections: false
    code-fold: show
---

# Introduction: Why Adaptive?

* 이전 포스트(Section 1)에서 다룬 기본적인 Conformal Prediction 방법은 단순하고 강력하지만 한 가지 단점이 있습니다.
* 기존 방식(Naive method)은 단순히 $1 - \hat{f}(x)_y$를 점수로 사용하기 때문에, 모든 클래스에 대해 고정된 임계값(Threshold)을 적용하는 경향이 있습니다.

* 이로 인해 다음과 같은 문제가 발생합니다:
  * 1.  **Hard Inputs (어려운 이미지)**: 모델이 헷갈려하는 경우에도 예측 집합이 충분히 커지지 않아 정답을 놓칠 수 있습니다 (Under-coverage).
  * 2.  **Easy Inputs (쉬운 이미지)**: 모델이 확신하는 경우에도 예측 집합이 불필요하게 클 수 있습니다 (Over-coverage).

* 우리는 입력 이미지의 난이도에 따라 **어려우면 집합을 크게, 쉬우면 집합을 작게** 만드는 **Adaptive Prediction Sets (APS)** 기법을 도입하여 이 문제를 해결할 것입니다.

# The Intuition: "Water-filling" Approach

* APS의 핵심 아이디어는 직관적입니다.
* 만약 모델의 예측 확률 $\hat{f}(x)$가 완벽하다면, 우리는 확률이 높은 클래스부터 순서대로 골라 담으면서 그 **확률의 합(Cumulative Sum)이 $1-\alpha$ (예: 90%)를 넘기는 순간** 멈추면 됩니다.

$$
\sum_{j=1}^{k} \hat{f}(x)_{\pi_j(x)} \ge 1 - \alpha
$$

* 여기서 $\pi(x)$는 확률이 높은 순서대로 정렬된 클래스의 순열(Permutation)입니다.
* 이 방식은 "컵에 물(확률)을 $90\%$가 찰 때까지 붓는 것"과 유사합니다.
* **쉬운 문제**: 확률 분포가 뾰족(Peaked)하므로, 1~2개만 담아도 금방 $90\%$가 찹니다. $\rightarrow$ **Small Set**
* **어려운 문제**: 확률 분포가 평평(Flat)하므로, 여러 개를 담아야 $90\%$가 찹니다. $\rightarrow$ **Large Set**

* 하지만 실제 모델의 확률 $\hat{f}(x)$는 완벽하지 않으므로(Overconfident/Underconfident), 단순히 $1-\alpha$에서 끊으면 커버리지를 보장할 수 없습니다. 
* 따라서 **Conformal Prediction을 사용하여 이 "멈추는 지점(Threshold)"을 보정**해야 합니다.

![Figure 4: Adaptive Prediction Sets (APS) 알고리즘의 시각화. 확률이 높은 클래스(Fox squirrel, Gray fox...)부터 순서대로 누적 합을 구하고, 그 합이 보정된 분위수(Quantile)를 넘을 때까지 클래스를 포함시킨다.](./images/figure4_aps_visualization.png)

# Mathematical Formulation

* 이제 이를 수학적으로 엄밀하게 정의해보겠습니다.

## 1. Defining the Score Function
* APS를 위한 Score Function $s(x, y)$는 **"정답 클래스 $y$를 포함시키기 위해, 확률 상위 몇 번째 클래스까지 내려가야 하는가?"**를 누적 확률로 나타냅니다.

* 먼저, 입력 $x$에 대해 모델이 예측한 확률을 내림차순으로 정렬하는 순열 함수 $\pi(x)$를 정의합니다.
$$ \hat{f}(x)_{\pi_1(x)} \ge \hat{f}(x)_{\pi_2(x)} \ge \dots \ge \hat{f}(x)_{\pi_K(x)} $$

* 이때, 정답 클래스 $y$가 정렬된 순서상 $k$번째에 위치한다고 가정합시다 ($y = \pi_k(x)$).
* Score $s(x, y)$는 $y$까지의 누적 확률 질량(Cumulative Probability Mass)으로 정의됩니다:

$$
s(x,y) = \sum_{j=1}^{k} \hat{f}(x)_{\pi_j(x)}
$$

* **의미**: "모델이 가장 가능성 높다고 생각하는 것부터 정답 $y$가 나올 때까지 확률을 다 더한 값"입니다.
  * 만약 모델이 정답을 1순위로 예측했다면, $s(x,y)$는 작을 것입니다.
  * 만약 모델이 정답을 하위권으로 예측했다면, $s(x,y)$는 1에 가까워질 것입니다.

## 2. Calibration (Finding $\hat{q}$)
* 이제 Calibration 데이터셋 $(X_1, Y_1), \dots, (X_n, Y_n)$에 대해 위 점수들을 계산합니다.
* 그리고 다음 식을 만족하는 분위수(Quantile) $\hat{q}$를 찾습니다.

$$
\hat{q} = \text{Quantile}\left( \frac{\lceil (n+1)(1-\alpha) \rceil}{n} ; \{s_1, \dots, s_n\} \right)
$$

* 이 $\hat{q}$는 "정답을 포함하기 위해 누적 확률을 어디까지 허용해야 하는가?"에 대한 통계적 임계값입니다.

## 3. Constructing the Prediction Set
* 새로운 테스트 데이터 $X_{test}$에 대해 예측 집합 $\mathcal{C}(X_{test})$는 누적 확률이 $\hat{q}$를 넘어서는 지점까지의 모든 클래스를 포함하여 구성됩니다.

$$
\mathcal{C}(x) = \{ \pi_1(x), \dots, \pi_k(x) \}
$$

* 여기서 $k$는 다음을 만족하는 가장 작은 정수입니다:
$$
\text{sup} \left\{ k' : \sum_{j=1}^{k'} \hat{f}(x)_{\pi_j(x)} < \hat{q} \right\} + 1
$$
* 즉, 누적 합이 $\hat{q}$를 초과하는 순간까지 포함합니다.

# Implementation Steps

* Python 코드로 구현할 때의 핵심 로직은 다음과 같습니다.

![Figure 5: Adaptive Prediction Sets 구현을 위한 Python 코드 예시. `argsort`를 통해 정렬하고 `cumsum`을 통해 누적 확률을 계산하는 과정이 포함되어 있다.](./images/figure5_aps_python_code.png)

1.  **Softmax & Sort**: 모델 출력값(Softmax)을 구하고 `argsort`를 이용해 내림차순 정렬합니다.
2.  **Cumulative Sum**: 정렬된 확률값들의 누적 합(`cumsum`)을 계산합니다.
3.  **Calculate Scores (Calibration)**: 정답 라벨 위치에서의 누적 합을 가져와 $s_i$를 구하고, Quantile $\hat{q}$를 계산합니다.
4.  **Prediction (Test)**: 테스트 데이터의 누적 합이 $\hat{q}$보다 작거나 같은 클래스들을 선택합니다. (엄밀하게는 $\hat{q}$를 넘는 첫 번째 클래스까지 포함해야 함)

# Summary

* **Adaptive Prediction Sets (APS)**는 불확실성을 더 지능적으로 다루는 방법입니다.
* 단순히 모델의 Softmax 값 하나만 보는 것이 아니라, **전체 확률 분포의 형상(Shape)**을 고려합니다.
* 그 결과, **쉬운 샘플에는 작은 집합**을, **어려운 샘플에는 큰 집합**을 할당하여 사용자가 모델의 신뢰도를 직관적으로 파악할 수 있게 해줍니다.
* 이 모든 과정에서도 $1-\alpha$라는 통계적 커버리지는 엄격하게 보장됩니다.

---
**Next Step**: 다음 포스트에서는 연속적인 값을 예측하는 회귀(Regression) 문제에서 불확실성 구간을 구하는 **Conformalized Quantile Regression**에 대해 알아보겠습니다.