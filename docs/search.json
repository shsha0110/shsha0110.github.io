[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/index.html",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/index.html",
    "title": "실전 검증: ACIC 2018 데이터와 NLSM 실제 사례 분석",
    "section": "",
    "text": "이전 포스트(Section 3)까지 우리는 데이터셋에 이미 존재하는 대상(In-sample)에 대해, 관측되지 않은 반사실(Counterfactual)을 추론하여 ITE 구간을 구하는 법을 배웠습니다.\n하지만 현실의 문제는 더 어렵습니다. 병원에 새로운 환자가 찾아왔습니다. 이 환자는 아직 처치를 받지도(Treat), 받지 않지도(Control) 않았습니다. 즉, \\(Y(1)\\)과 \\(Y(0)\\)가 모두 미지수(Missing)입니다.\n이번 포스트에서는 Section 4에서 제안하는, 두 잠재적 결과가 모두 없는 새로운 대상에 대해 ITE 신뢰 구간을 구축하는 세 가지 접근법(Naive, Nested-Inexact, Nested-Exact)을 살펴보겠습니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/index.html#들어가며",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/index.html#들어가며",
    "title": "실전 검증: ACIC 2018 데이터와 NLSM 실제 사례 분석",
    "section": "",
    "text": "이전 포스트(Section 3)까지 우리는 데이터셋에 이미 존재하는 대상(In-sample)에 대해, 관측되지 않은 반사실(Counterfactual)을 추론하여 ITE 구간을 구하는 법을 배웠습니다.\n하지만 현실의 문제는 더 어렵습니다. 병원에 새로운 환자가 찾아왔습니다. 이 환자는 아직 처치를 받지도(Treat), 받지 않지도(Control) 않았습니다. 즉, \\(Y(1)\\)과 \\(Y(0)\\)가 모두 미지수(Missing)입니다.\n이번 포스트에서는 Section 4에서 제안하는, 두 잠재적 결과가 모두 없는 새로운 대상에 대해 ITE 신뢰 구간을 구축하는 세 가지 접근법(Naive, Nested-Inexact, Nested-Exact)을 살펴보겠습니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/index.html#나이브-접근법-a-naive-approach",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/index.html#나이브-접근법-a-naive-approach",
    "title": "실전 검증: ACIC 2018 데이터와 NLSM 실제 사례 분석",
    "section": "2 나이브 접근법 (A Naive Approach)",
    "text": "2 나이브 접근법 (A Naive Approach)\n가장 직관적이고 단순한 방법은 앞서 배운 반사실 추론 도구를 각각 적용하는 것입니다.\n\n2.1 논리적 구조\n\n새로운 환자 \\(X\\)에 대해 \\(Y(1)\\)의 예측 구간 \\([\\hat{Y}^L(1), \\hat{Y}^R(1)]\\)을 구합니다.\n동일한 환자 \\(X\\)에 대해 \\(Y(0)\\)의 예측 구간 \\([\\hat{Y}^L(0), \\hat{Y}^R(0)]\\)을 구합니다.\n두 구간의 차(Difference)를 이용하여 ITE 구간을 구성합니다.\n\n\n\n2.2 수학적 정의\nITE 구간 \\(\\hat{C}_{ITE}(x)\\)는 다음과 같이 정의됩니다.\n\\[\n\\hat{C}_{ITE}(x) = [\\hat{Y}^L(1;x) - \\hat{Y}^R(0;x), \\quad \\hat{Y}^R(1;x) - \\hat{Y}^L(0;x)]\n\\]\n\n하한(Lower Bound): \\(Y(1)\\)의 최소값 - \\(Y(0)\\)의 최대값 (최악의 경우)\n상한(Upper Bound): \\(Y(1)\\)의 최대값 - \\(Y(0)\\)의 최소값 (최상의 경우)\n\n\n\n2.3 한계점\n만약 각 반사실 구간이 \\(1-\\alpha/2\\) 수준의 커버리지를 가진다면, 이 나이브 구간은 \\(1-\\alpha\\) 수준의 ITE 커버리지를 보장합니다.\n하지만 이 방식은 구간이 지나치게 넓어지는(Conservative) 경향이 있습니다. \\(Y(1)\\)과 \\(Y(0)\\) 사이의 상관관계를 고려하지 않고, 가장 극단적인 경우를 가정하여 구간을 빼버리기 때문입니다.\n![Image: naive_approach_diagram.png] Figure 1: 나이브 접근법의 도식화. 두 개의 독립적인 구간을 단순히 빼서 ITE 구간을 만들면, 불확실성이 과도하게 합쳐져 구간이 매우 넓어진다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/index.html#중첩-접근법-a-nested-approach",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/index.html#중첩-접근법-a-nested-approach",
    "title": "실전 검증: ACIC 2018 데이터와 NLSM 실제 사례 분석",
    "section": "3 중첩 접근법 (A Nested Approach)",
    "text": "3 중첩 접근법 (A Nested Approach)\n저자들은 나이브 방식의 한계를 극복하기 위해 중첩(Nested) 접근법을 제안합니다. 이 방법은 데이터를 두 번 활용하여, ITE에 대한 “대리 구간(Surrogate Interval)”을 먼저 만들고 이를 학습하는 방식입니다.\n\n3.1 데이터 분할 전략 (Data Splitting)\n전체 데이터를 두 개의 폴드(Fold 1, Fold 2)로 나눕니다.\n\nFold 1 (Training): 반사실 구간 모델(\\(\\hat{C}_1(x), \\hat{C}_0(x)\\))을 학습하는 데 사용합니다 (Section 3의 방법론 적용).\nFold 2 (Inference): 학습된 모델을 적용하여 각 개체의 ITE 구간을 추론하고, 이를 다시 학습 데이터로 활용합니다.\n\n\n\n3.2 대리 구간(Surrogate Interval) 생성\nFold 2에 있는 개체 \\(i\\)는 \\(T_i\\)와 \\(Y_i^{obs}\\)를 알고 있습니다. 이를 이용해 개인별 ITE 구간 \\(\\hat{C}_i\\)를 다음과 같이 계산합니다.\n\\[\n\\hat{C}_{ITE}(X_i; T_i, Y_i^{obs}) =\n\\begin{cases}\nY_i^{obs} - \\hat{C}_0(X_i) & \\text{if } T_i = 1 \\\\\n\\hat{C}_1(X_i) - Y_i^{obs} & \\text{if } T_i = 0\n\\end{cases}\n\\]\n\n설명:\n\n처치군(\\(T=1\\))은 \\(Y(1)\\)을 이미 알고 있습니다. 따라서 \\(Y(0)\\)에 대한 예측 구간만 구해서 관측값에서 빼줍니다.\n대조군(\\(T=0\\))은 \\(Y(0)\\)를 이미 알고 있습니다. 따라서 \\(Y(1)\\)에 대한 예측 구간을 구해서 관측값을 빼줍니다.\n\n\n![Image: nested_approach_table.png] Figure 2: 중첩 접근법의 데이터 흐름 (Table 3 참조). Fold 1에서 모델을 만들고, Fold 2에서 실제 관측값과 결합하여 ITE 구간을 완성한다.\n\n\n3.3 커버리지 보장 증명\n이렇게 만든 대리 구간 \\(\\hat{C}_i\\)가 실제 ITE를 포함할 확률은 얼마나 될까요?\n\\[\n\\begin{align}\n\\mathbb{P}(Y_i(1) - Y_i(0) \\in \\hat{C}_i) &= \\mathbb{P}(T_i=1)\\mathbb{P}(Y_i(0) \\in \\hat{C}_0(X_i) | T_i=1) \\\\\n&+ \\mathbb{P}(T_i=0)\\mathbb{P}(Y_i(1) \\in \\hat{C}_1(X_i) | T_i=0)\n\\end{align}\n\\]\n만약 우리가 Fold 1에서 만든 구간들이 각각 조건부 커버리지 \\(1-\\alpha\\)를 만족한다면(식 14), 위 식에 의해 대리 구간 \\(\\hat{C}_i\\) 역시 ITE를 \\(1-\\alpha\\) 확률로 포함하게 됩니다(식 15)."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/index.html#중첩-프레임워크-하에서의-두-가지-방법론",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/index.html#중첩-프레임워크-하에서의-두-가지-방법론",
    "title": "실전 검증: ACIC 2018 데이터와 NLSM 실제 사례 분석",
    "section": "4 중첩 프레임워크 하에서의 두 가지 방법론",
    "text": "4 중첩 프레임워크 하에서의 두 가지 방법론\n이제 우리는 Fold 2 데이터셋을 통해 입력 \\(X_i\\)와 출력 구간 \\(\\hat{C}_i\\)의 쌍 \\((X_i, \\hat{C}_i)\\)를 확보했습니다. 이제 새로운 데이터 \\(X\\)가 들어왔을 때 어떤 구간을 내놓을지 결정해야 합니다.\n\n4.1 1. 부정확한 방법 (The Inexact Method)\n가장 실용적인 방법은 머신러닝을 이용해 구간의 경계를 직접 예측하는 것입니다.\n\n방법: \\(\\hat{C}_i\\)의 왼쪽 끝점(\\(L\\))과 오른쪽 끝점(\\(R\\))을 타겟 변수로 삼아, \\(X_i\\)에 대해 회귀 모델을 학습합니다.\n예시: 왼쪽 끝점의 40% 분위수, 오른쪽 끝점의 60% 분위수를 예측하는 모델 등.\n특징:\n\n장점: 나이브 접근법보다 훨씬 짧고 효율적인 구간을 생성합니다.\n단점: “부정확(Inexact)”하다고 명명된 이유는, 최종 예측 결과에 대한 엄밀한 유한 샘플 커버리지 보장(Finite-sample guarantee)이 없기 때문입니다.\n\n\n\n\n4.2 2. 정확한 방법 (The Exact Method)\n엄격한 안전성이 요구되는 의료/금융 분야를 위해, 저자들은 2차 컨포멀 추론(Secondary Conformal Inference)을 제안합니다.\n\n목표: 새로운 입력 \\(X\\)에 대해, 앞서 구한 대리 구간 \\(C\\)를 포함할 확률이 \\(1-\\gamma\\)인 구간의 구간(Interval expansion) \\(\\hat{\\mathcal{C}}(X)\\)를 찾는 것입니다.\n\n\\[\n\\mathbb{P}(C \\subset \\hat{\\mathcal{C}}(X)) \\ge 1 - \\gamma\n\\]\n이를 만족하면 최종적으로 ITE를 놓칠 확률은 \\(\\alpha + \\gamma\\) 이하로 통제됩니다.\n\\[\n\\mathbb{P}(\\text{ITE Error}) \\le \\alpha (\\text{Step 1 Error}) + \\gamma (\\text{Step 2 Error})\n\\]\n\n4.2.1 Algorithm 2: 구간 결과를 위한 컨포멀 추론\n저자들은 단순한 보정(Bonferroni) 대신, 구간의 왼쪽(\\(C^L\\))과 오른쪽(\\(C^R\\))을 동시에 보정하는 알고리즘을 제시합니다.\n\n점수 계산 (Score \\(V_i\\)): 예측된 구간 \\([\\hat{m}^L, \\hat{m}^R]\\)이 실제 대리 구간 \\([C^L, C^R]\\)을 얼마나 벗어났는지 계산합니다. \\[V_i = \\max \\{ \\hat{m}^L(X_i) - C_i^L, \\quad C_i^R - \\hat{m}^R(X_i) \\}\\]\n보정값 (\\(\\eta\\)) 산출: \\(V_i\\)들의 분포에서 \\((1-\\gamma)\\) 분위수를 찾아 보정합니다.\n최종 구간: \\([\\hat{m}^L(x) - \\eta, \\hat{m}^R(x) + \\eta]\\)\n\n이 “정확한 방법”을 사용하면, 새로운 환자에 대해서도 수학적으로 증명된 커버리지를 가진 ITE 구간을 제공할 수 있습니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/index.html#요약",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/index.html#요약",
    "title": "실전 검증: ACIC 2018 데이터와 NLSM 실제 사례 분석",
    "section": "5 요약",
    "text": "5 요약\nSection 4는 인과추론의 가장 어려운 단계인 완전한 미지수(Out-of-sample ITE)를 다룹니다.\n\n\n\n\n\n\n\n\n\n접근법\n설명\n장점\n단점\n\n\n\n\nNaive\n\\(Y(1)\\) 구간 - \\(Y(0)\\) 구간\n구현이 쉬움\n구간이 너무 넓어 쓸모가 적음\n\n\nNested (Inexact)\nITE 대리 구간(\\(\\hat{C}_i\\))을 ML로 학습\n구간이 짧고 효율적임\n수학적 보장이 완벽하지 않음\n\n\nNested (Exact)\n대리 구간에 대해 다시 Conformal 적용\n이중 보장(\\(\\alpha+\\gamma\\)) 가능\nInexact보다 구간이 다소 넓을 수 있음\n\n\n\n실제 적용 시에는 데이터의 양과 리스크 허용 범위에 따라 Nested-Inexact (실용성 중시) 혹은 Nested-Exact (안전성 중시)를 선택하여 사용할 수 있습니다.\n\nReference: Lei, L., & Candès, E. J. (2021). Conformal inference of counterfactuals and individual treatment effects. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 83(5), 911-938."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/index.html#들어가며-1",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/index.html#들어가며-1",
    "title": "실전 검증: ACIC 2018 데이터와 NLSM 실제 사례 분석",
    "section": "6 들어가며",
    "text": "6 들어가며\n이론적으로 완벽해 보이는 방법론도 실제 데이터 앞에서는 무력할 수 있습니다. 특히, 인과추론의 가장 큰 난제인 “두 잠재적 결과가 모두 결측된 새로운 대상(Out-of-sample)”에 대한 ITE 구간 추정은 검증이 더욱 까다롭습니다.\n저자들은 이를 검증하기 위해 두 가지 단계의 실험을 설계했습니다. 1. 정답(Ground Truth)을 아는 상황: ACIC 2018 워크숍 데이터를 기반으로 한 합성 데이터 실험. 2. 정답을 모르는 상황: 실제 NLSM(National Study of Learning Mindsets) 데이터 분석."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/index.html#acic-2018-데이터를-활용한-성능-평가-empirical-performance",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/index.html#acic-2018-데이터를-활용한-성능-평가-empirical-performance",
    "title": "실전 검증: ACIC 2018 데이터와 NLSM 실제 사례 분석",
    "section": "7 ACIC 2018 데이터를 활용한 성능 평가 (Empirical Performance)",
    "text": "7 ACIC 2018 데이터를 활용한 성능 평가 (Empirical Performance)\n\n7.1 데이터 생성 메커니즘 (Data Generating Process)\n저자들은 2018 Atlantic Causal Inference Conference (ACIC) 워크숍에서 사용된 데이터를 기반으로 실험을 설계했습니다. 이 데이터는 실제 대규모 교육 실험인 NLSM의 특성을 모방하여 만들어졌습니다.\n커버리지(Coverage)를 정확히 평가하려면 실제값(\\(Y(1), Y(0)\\))을 알아야 하므로, 저자들은 다음과 같은 과정을 통해 합성 데이터를 생성했습니다.\nStep 1: 기저 함수 학습 전체 데이터를 \\(\\mathcal{Z}_1\\) (20%)과 \\(\\mathcal{Z}_2\\) (80%)로 나눕니다. \\(\\mathcal{Z}_1\\)을 이용해 \\(Y(0)\\)의 평균 함수 \\(\\hat{m}_0(x)\\)를 Random Forest로 학습합니다.\nStep 2: 이분산성(Heteroscedasticity) 모델링 데이터의 현실성을 높이기 위해 오차의 분산이 공변량에 따라 달라지게 설정합니다. Quantile Random Forest를 이용해 조건부 사분위수 범위(Interquartile Range) \\(\\hat{r}_0(x)\\)와 \\(\\hat{r}_1(x)\\)를 추정합니다.\nStep 3: 잠재적 결과 생성 (수학적 정의) 새로운 공변량 \\(X_i\\)에 대해, 잠재적 결과는 다음과 같이 생성됩니다.\n\\[\n\\begin{align}\nY_i(0) &= \\hat{m}_0(X_i) + 0.5 \\hat{r}_0(X_i) \\epsilon_{i0} \\\\\nY_i(1) &= \\hat{m}_0(X_i) + \\tau(X_i) + 0.5 \\hat{r}_1(X_i) \\epsilon_{i1}\n\\end{align}\n\\]\n\n\\(\\tau(x)\\): 사전에 정의된 참 CATE 함수.\n\\(\\epsilon_{i0}, \\epsilon_{i1} \\sim N(0, 1)\\): 독립적인 표준 정규분포 노이즈.\n이 식은 평균 효과뿐만 아니라 분산의 구조까지 반영된 정교한 생성 방식입니다.\n\nStep 4: 성향 점수 및 관측 데이터 생성 성향 점수 \\(\\hat{e}(x)\\)를 추정하고, 이를 0.1과 0.9 사이로 잘라낸(Truncate) 뒤, 베르누이 시행을 통해 처치 여부 \\(T_i\\)를 결정합니다.\n\\[\nT_i \\sim \\text{Bernoulli}(\\hat{e}(X_i))\n\\]\n\n\n7.2 비교 방법론 및 실험 설정\n\nTraining: \\(n=1000\\)개의 샘플로 학습.\nTesting: 5000개의 새로운 샘플에 대해 ITE 구간 추정 (오직 \\(X\\)만 제공됨).\n비교 대상:\n\nCQR 계열: Naive, Exact Nested, Inexact Nested (제안 방법).\nBART 계열: Naive, Inexact Nested.\n벤치마크: Causal Forest, X-learner (ITE용이 아님을 감안).\n\n\n\n\n7.3 실험 결과 1: 커버리지와 구간 길이\n Figure 5: (왼쪽) ITE 구간의 커버리지. 빨간 선은 목표인 95%. (오른쪽) 구간의 평균 길이. 파란 선은 Oracle 길이.\n핵심 결과 분석: 1. Naive 방법들의 보수성: CQR(Naive)와 BART(Naive)는 100%에 가까운 커버리지를 보이지만, 구간의 길이가 매우 깁니다(오른쪽 패널). 이는 두 구간을 단순히 뺐기 때문에 불확실성이 과대평가되었음을 의미합니다. 2. Inexact Nested CQR의 우수성: 제안된 Inexact Nested CQR은 목표치인 95% 커버리지를 정확히 달성하면서도, 구간의 길이가 Naive 방식이나 Exact 방식보다 훨씬 짧고 효율적입니다. 3. 경쟁자들의 실패: * BART(Inexact): 목표 커버리지(95%)에 도달하지 못했습니다. * Causal Forest / X-learner: ITE가 아닌 CATE를 추정하도록 설계되었기에, ITE의 불확실성을 담기에는 구간이 턱없이 좁고 커버리지가 매우 낮습니다.\n\n\n7.4 실험 결과 2: 조건부 커버리지의 안정성\n데이터의 분산(Variance)이나 효과의 크기(CATE)가 달라질 때 커버리지가 유지되는지 확인합니다.\n Figure 6: 조건부 분산(위쪽 행)과 CATE 크기(아래쪽 행)에 따른 조건부 커버리지 변화.\n\nInexact CQR (맨 오른쪽): 분산이 커지거나(x축 오른쪽), CATE가 변해도 커버리지가 비교적 안정적으로 유지됩니다.\nInexact BART (두 번째 열): 조건부 분산이 커질수록 커버리지가 급격히 떨어지는 약점을 보입니다. 이는 Section 3.6의 결과와 일치하며, BART가 이분산성(Heteroscedasticity) 데이터에서 불확실성 추정에 취약함을 재확인시켜 줍니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/index.html#실제-데이터-재분석-nlsm-re-analysing-nlsm-data",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/index.html#실제-데이터-재분석-nlsm-re-analysing-nlsm-data",
    "title": "실전 검증: ACIC 2018 데이터와 NLSM 실제 사례 분석",
    "section": "8 실제 데이터 재분석: NLSM (Re-analysing NLSM data)",
    "text": "8 실제 데이터 재분석: NLSM (Re-analysing NLSM data)\n\n8.1 분석 개요\nNLSM(National Study of Learning Mindsets)은 학생들의 학습 태도에 대한 개입 효과를 연구한 대규모 실험입니다. 실제 데이터이므로 개별 학생의 참 ITE(\\(Y_i(1)-Y_i(0)\\))는 알 수 없습니다(Ground Truth 부재).\n하지만 저자들은 제안한 Inexact CQR (w/ BART learner) 방법을 적용하여 탐색적 분석(Exploratory Analysis)을 수행했습니다. 이는 실제 환경에서 이 방법론이 어떻게 의사결정을 도울 수 있는지 보여줍니다.\n\n\n8.2 분석 방법: 교차 예측 (Cross-Prediction)\n데이터를 두 폴드 \\(\\mathcal{Z}_1, \\mathcal{Z}_2\\)로 나눈 뒤, 서로가 서로의 테스트 셋이 되도록 교차하여 ITE 구간을 생성했습니다. 이를 100회 반복하여 변동성을 반영했습니다.\n\n\n8.3 분석 결과 및 해석\n Figure 7: NLSM 데이터 분석 결과. (a) 유의수준 alpha에 따른 구간 길이. (b) 구간의 하한이 양수인 비율(긍정적 효과). (c) 구간의 상한이 음수인 비율(부정적 효과).\n\n구간의 길이 (패널 a): 허용 오차 수준(\\(\\alpha\\))이 커질수록(즉, 신뢰 수준이 낮아질수록) 구간의 길이는 줄어듭니다. 이는 통계적으로 자연스러운 현상입니다.\n긍정적 효과의 발견 (패널 b): \\(\\alpha &gt; 0.25\\) (신뢰수준 75% 미만)일 때부터 구간의 하한이 0보다 큰(Positive Lower Bound) 케이스들이 나타나기 시작합니다.\n\n의미: “이 학생에게 개입을 하면 학습 태도가 개선될 것이다”라고 어느 정도 확신을 가지고 말할 수 있는 학생들의 비율입니다.\n\n부정적 효과의 부재 (패널 c): \\(\\alpha\\)를 0.5까지 높여도 구간의 상한이 0보다 작은(Negative Upper Bound) 케이스는 거의 없습니다.\n\n의미: 이 개입(Intervention)이 학생에게 악영향을 끼친다는 증거는 발견되지 않았습니다.\n\n\n\n\n8.4 실무적 시사점\n이 분석은 정책 결정자에게 매우 유용한 가이드를 제공합니다. * 안전한 개입: 부정적 효과가 관측되지 않으므로, 부작용 걱정 없이 프로그램을 시행할 수 있는 근거가 됩니다. * 타겟팅: 긍정적 효과가 확실시되는 하위 그룹을 식별하여 자원을 집중할 수 있습니다. * 이 모든 판단은 점 추정(Point Estimate)이 아닌, 신뢰할 수 있는 구간(Interval Estimate)에 기반하므로 훨씬 더 안전합니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/index.html#결론-conclusion",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/index.html#결론-conclusion",
    "title": "실전 검증: ACIC 2018 데이터와 NLSM 실제 사례 분석",
    "section": "9 결론 (Conclusion)",
    "text": "9 결론 (Conclusion)\n이 논문은 인과추론의 영역을 ‘평균의 점 추정’에서 ‘개인의 구간 추정’으로 확장했습니다.\n\n방법론의 확장: 가중 컨포멀 추론(Weighted Conformal Inference)을 통해 관측 데이터의 공변량 변화(Covariate Shift)를 보정했습니다.\n이중 강건성: 성향 점수 혹은 결과 모델 중 하나만 정확해도 커버리지가 보장됨을 입증했습니다.\n현실적 적용: 데이터가 완전히 없는 새로운 대상에 대해서도 중첩(Nested) 접근법을 통해 효율적인 ITE 구간을 생성할 수 있음을 보였습니다.\n성능 입증: 합성 데이터와 실제 데이터 분석을 통해, 기존의 Causal Forest나 BART보다 불확실성 정량화 측면에서 우월함을 증명했습니다.\n\n결국 이 연구는 “불확실성을 고려한 안전하고 정밀한 의사결정”이라는 인과추론의 궁극적 목표에 한 걸음 더 다가가게 해 줍니다.\n\nReference: Lei, L., & Candès, E. J. (2021). Conformal inference of counterfactuals and individual treatment effects. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 83(5), 911-938."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/02-From point estimates to interval estimates/index.html",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/02-From point estimates to interval estimates/index.html",
    "title": "점 추정을 넘어 구간 추정으로: 인과추론의 불확실성을 다루는 법",
    "section": "",
    "text": "이전 포스트에서는 왜 우리가 ’평균’을 넘어 ’개인’에 집중해야 하는지 살펴보았습니다. 이번 포스트(Section 2)에서는 이를 수학적으로 정식화(Formalization)하고, 기존의 점 추정(Point Estimate) 방식이 왜 불확실성을 담아내기에 부족한지, 그리고 우리가 목표로 하는 구간 추정(Interval Estimate)의 정의가 무엇인지 구체적으로 파고들어 보겠습니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/02-From point estimates to interval estimates/index.html#들어가며",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/02-From point estimates to interval estimates/index.html#들어가며",
    "title": "점 추정을 넘어 구간 추정으로: 인과추론의 불확실성을 다루는 법",
    "section": "",
    "text": "이전 포스트에서는 왜 우리가 ’평균’을 넘어 ’개인’에 집중해야 하는지 살펴보았습니다. 이번 포스트(Section 2)에서는 이를 수학적으로 정식화(Formalization)하고, 기존의 점 추정(Point Estimate) 방식이 왜 불확실성을 담아내기에 부족한지, 그리고 우리가 목표로 하는 구간 추정(Interval Estimate)의 정의가 무엇인지 구체적으로 파고들어 보겠습니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/02-From point estimates to interval estimates/index.html#문제-설정-problem-setup",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/02-From point estimates to interval estimates/index.html#문제-설정-problem-setup",
    "title": "점 추정을 넘어 구간 추정으로: 인과추론의 불확실성을 다루는 법",
    "section": "2 문제 설정 (Problem Setup)",
    "text": "2 문제 설정 (Problem Setup)\n\n2.1 잠재적 결과 프레임워크 (Potential Outcome Framework)\n논문은 Neyman(1923)과 Rubin(1974)이 정립한 잠재적 결과 프레임워크를 따릅니다. \\(n\\)명의 대상에 대해 다음과 같은 변수들을 정의합니다.\n\n\\(T_i \\in \\{0, 1\\}\\): 이진 처치 변수 (Treatment Indicator). (예: 1=약 복용, 0=미복용)\n\\((Y_i(1), Y_i(0))\\): 잠재적 결과 쌍.\n\n\\(Y_i(1)\\): 처치를 받았을 때의 결과.\n\\(Y_i(0)\\): 처치를 받지 않았을 때의 결과.\n\n\\(X_i\\): 공변량 벡터 (Covariates, 예: 나이, 성별, 혈압 등).\n\n우리는 데이터가 I.I.D. (Independent and Identically Distributed) 가정하에 생성된다고 봅니다.\n\\[\n(Y_i(1), Y_i(0), T_i, X_i) \\stackrel{i.i.d}{\\sim} (Y(1), Y(0), T, X)\n\\]\n\n\n2.2 관측된 데이터와 ITE의 정의\n현실에서는 SUTVA(Stable Unit Treatment Value Assumption) 가정하에, 각 개인에 대해 오직 하나의 결과만 관측됩니다. 이를 관측된 결과(Observed Outcome, \\(Y_i^{obs}\\))라고 합니다.\n\\[\nY_i^{obs} = \\begin{cases}\nY_i(1) & \\text{if } T_i = 1 \\\\\nY_i(0) & \\text{if } T_i = 0\n\\end{cases}\n\\]\n우리가 알고 싶은 개별 처치 효과(ITE, Individual Treatment Effect) \\(\\tau_i\\)는 다음과 같이 정의됩니다.\n\\[\n\\tau_i \\triangleq Y_i(1) - Y_i(0)\n\\]\n핵심 문제: 정의상, 우리는 \\(Y_i(1)\\)과 \\(Y_i(0)\\) 중 하나만 관측할 수 있습니다. 나머지 하나는 결측(Missing)됩니다. 따라서 ITE는 관측 불가능하며(Unobserved), 오직 추론만 가능합니다.\n\n\n2.3 강력한 무시 가능성 (Strong Ignorability)\n이 논문은 분석을 위해 강력한 무시 가능성(Strong Ignorability) 가정을 사용합니다.\n\\[\n(Y(1), Y(0)) \\perp T \\mid X\n\\]\n이는 공변량 \\(X\\)가 주어졌을 때, 처치 할당(\\(T\\))이 잠재적 결과와 독립적이라는 뜻입니다. 즉, 측정되지 않은 교란 변수(Unmeasured Confounders)가 없음을 의미합니다.\n![Image: strong_ignorability_dag.png] Figure 1: 강력한 무시 가능성을 나타내는 인과 다이어그램(DAG). X가 주어졌을 때 T와 Y(t) 사이에는 직접적인 연결(Confounder)이 없다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/02-From point estimates to interval estimates/index.html#기존의-추론-목표-cate와-그-한계",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/02-From point estimates to interval estimates/index.html#기존의-추론-목표-cate와-그-한계",
    "title": "점 추정을 넘어 구간 추정으로: 인과추론의 불확실성을 다루는 법",
    "section": "3 기존의 추론 목표: CATE와 그 한계",
    "text": "3 기존의 추론 목표: CATE와 그 한계\n\n3.1 CATE의 정의 및 유도\n기존 연구들은 대부분 조건부 평균 처치 효과(CATE) \\(\\tau(x)\\)를 추정하는 데 집중했습니다.\n\\[\n\\tau(x) \\triangleq \\mathbb{E}[Y(1) - Y(0) \\mid X = x]\n\\]\n이를 분해하면 두 조건부 평균 함수 \\(m_1(x)\\)와 \\(m_0(x)\\)의 차이로 표현할 수 있습니다.\n\\[\n\\begin{align}\n\\tau(x) &= \\mathbb{E}[Y(1) \\mid X=x] - \\mathbb{E}[Y(0) \\mid X=x] \\\\\n        &= m_1(x) - m_0(x)\n\\end{align}\n\\]\n[수학적 유도: 관측 데이터로의 연결] 강력한 무시 가능성 가정(\\((Y(1), Y(0)) \\perp T \\mid X\\)) 덕분에, 우리는 잠재적 결과의 평균을 관측된 데이터의 평균으로 대체할 수 있습니다.\n\\[\n\\begin{align}\nm_1(x) &= \\mathbb{E}[Y(1) \\mid X=x] \\\\\n       &= \\mathbb{E}[Y(1) \\mid X=x, T=1] \\quad (\\because \\text{Ignorability}) \\\\\n       &= \\mathbb{E}[Y^{obs} \\mid X=x, T=1]\n\\end{align}\n\\]\n마찬가지로 \\(m_0(x) = \\mathbb{E}[Y^{obs} \\mid X=x, T=0]\\) 입니다. 이로써 인과 추론 문제는 통계적 회귀(Regression) 문제가 됩니다.\n\n\n3.2 CATE의 한계\n\n불확실성 과소평가: 고차원 회귀 함수(\\(m(x)\\)) 주변의 신뢰대(Confidence Band)를 만드는 것은 매우 까다롭습니다. 일반적인 근사법이나 리샘플링 기법은 변동성을 과소평가하는 경향이 있습니다.\n분위수(Quantile)의 혼동: 평균 대신 분위수를 사용하는 CQTE(Conditional Quantile Treatment Effect)를 고려할 수도 있습니다. 하지만 주의해야 할 점은 “차이의 분위수(Quantile of Difference)”와 “분위수의 차이(Difference of Quantiles)”는 전혀 다르다는 것입니다.\n\n우리가 알고 싶은 것: Quantile of \\((Y(1) - Y(0))\\)\nCQTE: Quantile\\((Y(1))\\) - Quantile\\((Y(0))\\)\n전자는 \\(Y(1)\\)과 \\(Y(0)\\)의 결합 분포(Joint Distribution)를 알아야만 식별 가능한데, 이는 관측이 불가능합니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/02-From point estimates to interval estimates/index.html#새로운-목표-구간-추정-interval-estimates",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/02-From point estimates to interval estimates/index.html#새로운-목표-구간-추정-interval-estimates",
    "title": "점 추정을 넘어 구간 추정으로: 인과추론의 불확실성을 다루는 법",
    "section": "4 새로운 목표: 구간 추정 (Interval Estimates)",
    "text": "4 새로운 목표: 구간 추정 (Interval Estimates)\n\n4.1 커버리지(Coverage) 기준\n이 연구의 목표는 단순히 점 값을 맞추는 것이 아니라, 실제 값(ITE 혹은 잠재적 결과)을 포함할 확률이 보장되는 예측 구간(Prediction Interval)을 만드는 것입니다.\n예를 들어, \\(Y(1)\\)에 대한 예측 구간 \\(\\hat{C}_1(X)\\)는 다음을 만족해야 합니다. (사전에 지정된 레벨 \\(\\alpha\\)에 대해)\n\\[\n\\mathbb{P}(Y(1) \\in \\hat{C}_1(X)) \\ge 1 - \\alpha\n\\]\n마찬가지로, ITE인 \\(Y(1)-Y(0)\\)에 대한 구간 \\(\\hat{C}_{ITE}(X)\\)는 다음을 만족해야 합니다.\n\\[\n\\mathbb{P}(Y(1) - Y(0) \\in \\hat{C}_{ITE}(X)) \\ge 1 - \\alpha\n\\]\n![Image: prediction_interval_concept.png] Figure 2: 점 추정(Point Estimate) vs 구간 추정(Interval Estimate). 점 추정은 하나의 선으로 나타나지만, 구간 추정은 데이터가 포함될 범위를 띠(Band) 형태로 제공하여 불확실성을 시각화한다.\n\n\n4.2 오라클(Oracle) 구간과 현실\n만약 우리가 \\(Y(1)\\)의 조건부 분포를 완벽하게 안다면, 참 분위수(True Quantiles) \\(q_{\\beta}(x)\\)를 이용해 최적의 구간을 만들 수 있습니다.\n\\[\nC_1(x) = [q_{\\alpha/2}(x), q_{1-\\alpha/2}(x)]\n\\]\n하지만 현실에서는 제한된 샘플 크기와 모델 불확실성 때문에 참 분위수를 알 수 없습니다. 이를 추정치로 대체하면 커버리지를 보장하기 어렵습니다. 저자들은 Conformal Inference를 통해 이 문제를 해결하고자 합니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/02-From point estimates to interval estimates/index.html#일반화된-커버리지-기준-general-coverage-criteria",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/02-From point estimates to interval estimates/index.html#일반화된-커버리지-기준-general-coverage-criteria",
    "title": "점 추정을 넘어 구간 추정으로: 인과추론의 불확실성을 다루는 법",
    "section": "5 일반화된 커버리지 기준 (General Coverage Criteria)",
    "text": "5 일반화된 커버리지 기준 (General Coverage Criteria)\n\n5.1 ATE vs ATT\n전통적인 인과추론에서는 전체 평균(ATE)보다 처치군 평균 처치 효과(ATT, Average Treatment Effect on the Treated)를 선호하는 경우가 많습니다.\n\\[\n\\text{ATT} = \\mathbb{E}[Y(1) - Y(0) \\mid T=1]\n\\]\n이에 맞춰 커버리지 기준도 조건부 확률로 수정할 수 있습니다.\n\\[\n\\mathbb{P}(Y(t) \\in \\hat{C}_t(X) \\mid T=1) \\ge 1 - \\alpha\n\\]\n이는 \\(X\\)의 분포를 모집단 전체가 아닌, 처치를 받은 집단(\\(T=1\\))의 분포로 한정하여 평가하겠다는 의미입니다.\n\n\n5.2 일반화 (Transportability)\n더 나아가, 연구 대상 집단(Study Population)과 우리가 결과를 적용하고자 하는 타겟 집단(Target Population)이 다를 수 있습니다 (Covariate Shift). 이를 위해 저자들은 타겟 분포 \\(Q_X\\)를 도입한 일반화된 커버리지 기준을 제안합니다.\n\\[\n\\mathbb{P}_{(X, Y(t)) \\sim Q_X \\times P_{Y(t)|X}} (Y(t) \\in \\hat{C}_t(X)) \\ge 1 - \\alpha\n\\]\n\n\\(Q_X\\): 타겟 집단의 공변량 분포.\n이 식은 \\(Q_X\\)를 어떻게 설정하느냐에 따라 전체 인구(ATE 관점), 처치군(ATT 관점), 혹은 완전히 새로운 외부 집단(Generalizability/External Validity)에 대한 구간 추정을 모두 포괄합니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/02-From point estimates to interval estimates/index.html#요약",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/02-From point estimates to interval estimates/index.html#요약",
    "title": "점 추정을 넘어 구간 추정으로: 인과추론의 불확실성을 다루는 법",
    "section": "6 요약",
    "text": "6 요약\nSection 2에서는 CATE와 같은 점 추정치가 가진 불확실성 표현의 한계를 지적하고, 이를 극복하기 위해 ITE에 대한 유효한 예측 구간을 생성하는 것을 목표로 설정했습니다.\n\n기존: \\(E[Y(1)-Y(0)|X]\\) (평균) 추정에 집중 -&gt; 불확실성 정보 부족.\n제안: \\(P(Y(1)-Y(0) \\in C(X)) \\ge 1-\\alpha\\) (구간) 생성에 집중 -&gt; 리스크 관리 가능.\n\n다음 섹션(Section 3)부터는 실제로 관측된 데이터(Observables)를 이용해 어떻게 관측되지 않은 반사실적 결과(Counterfactuals)의 구간을 만들어낼지 구체적인 방법론을 다루게 됩니다.\n\nReference: Lei, L., & Candès, E. J. (2021). Conformal inference of counterfactuals and individual treatment effects. [cite_start]Journal of the Royal Statistical Society: Series B (Statistical Methodology), 83(5), 911-938. [cite: 107, 108]"
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/01-From average effects to individual effects/index.html",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/01-From average effects to individual effects/index.html",
    "title": "평균을 넘어 개인으로: 인과추론의 새로운 패러다임과 Conformal Inference",
    "section": "",
    "text": "인과추론(Causal Inference) 분야에서 지난 수십 년간 가장 지배적인 목표는 평균 처치 효과(ATE, Average Treatment Effect)를 추정하는 것이었습니다. 하지만 ATE는 집단 전체에 대한 거친 요약(coarse summary)일 뿐, 개별 환자나 대상에게 적용할 때는 치명적인 한계를 드러낼 수 있습니다.\n논문에서는 아주 직관적인 예시를 듭니다. 어떤 신약이 있다고 가정해 봅시다.\n\n시나리오: * 환자의 70%: 완치됨 (긍정적 효과) * 환자의 30%: 증상이 훨씬 악화됨 (부정적 효과)\n\n이 경우, 단순 평균을 내면 “효과가 있다”는 긍정적인 ATE가 도출될 수 있습니다. 하지만 이 약을 승인해야 할까요? [cite_start]30%의 환자에게는 독이 될 수 있는 약을 획일적으로 처방하는 것은 위험합니다[cite: 36, 37].\n[cite_start]이처럼 “One-size-fits-all(만능)” 접근법은 불충분하며, 임상적 특성과 개인의 선호에 맞춘 개별 처치 효과(ITE, Individual Treatment Effect)의 추정이 필수적입니다[cite: 42]."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/01-From average effects to individual effects/index.html#들어가며-평균의-함정",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/01-From average effects to individual effects/index.html#들어가며-평균의-함정",
    "title": "평균을 넘어 개인으로: 인과추론의 새로운 패러다임과 Conformal Inference",
    "section": "",
    "text": "인과추론(Causal Inference) 분야에서 지난 수십 년간 가장 지배적인 목표는 평균 처치 효과(ATE, Average Treatment Effect)를 추정하는 것이었습니다. 하지만 ATE는 집단 전체에 대한 거친 요약(coarse summary)일 뿐, 개별 환자나 대상에게 적용할 때는 치명적인 한계를 드러낼 수 있습니다.\n논문에서는 아주 직관적인 예시를 듭니다. 어떤 신약이 있다고 가정해 봅시다.\n\n시나리오: * 환자의 70%: 완치됨 (긍정적 효과) * 환자의 30%: 증상이 훨씬 악화됨 (부정적 효과)\n\n이 경우, 단순 평균을 내면 “효과가 있다”는 긍정적인 ATE가 도출될 수 있습니다. 하지만 이 약을 승인해야 할까요? [cite_start]30%의 환자에게는 독이 될 수 있는 약을 획일적으로 처방하는 것은 위험합니다[cite: 36, 37].\n[cite_start]이처럼 “One-size-fits-all(만능)” 접근법은 불충분하며, 임상적 특성과 개인의 선호에 맞춘 개별 처치 효과(ITE, Individual Treatment Effect)의 추정이 필수적입니다[cite: 42]."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/01-From average effects to individual effects/index.html#cate의-등장과-그-한계",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/01-From average effects to individual effects/index.html#cate의-등장과-그-한계",
    "title": "평균을 넘어 개인으로: 인과추론의 새로운 패러다임과 Conformal Inference",
    "section": "2 CATE의 등장과 그 한계",
    "text": "2 CATE의 등장과 그 한계\n\n2.1 CATE란 무엇인가?\nITE의 중요성이 대두되면서, 연구자들은 조건부 평균 처치 효과(CATE, Conditional Average Treatment Effect)에 주목하기 시작했습니다. CATE는 특정 공변량(covariate, \\(X\\))을 가진 하위 그룹의 평균적인 효과를 의미합니다.\n\\[\n\\tau(x) = \\mathbb{E}[Y(1) - Y(0) | X = x]\n\\]\n여기서 \\(Y(1)\\)은 처치를 받았을 때의 잠재적 결과, \\(Y(0)\\)는 받지 않았을 때의 결과입니다. [cite_start]머신러닝 알고리즘을 활용해 이 CATE를 유연하게 추정하려는 시도가 많았습니다[cite: 16].\n!(placeholder_image_1.png) Figure 1: 평균 처치 효과(ATE)와 조건부 평균 처치 효과(CATE)의 차이. ATE는 전체의 평균을 보지만, CATE는 변수 X에 따른 효과의 분포를 추정한다.\n\n\n2.2 점 추정(Point Estimate)의 위험성\n하지만 본 논문의 저자들은 CATE 역시 충분하지 않다고 지적합니다. CATE는 여전히 ‘조건부 평균(Expectation)’에 불과하기 때문입니다. 의사결정, 특히 의료나 공공 정책과 같이 민감한 분야에서는 “평균적으로 어떠한가”보다 “불확실성이 어느 정도인가”가 훨씬 중요합니다.\n[cite_start]저자들은 CATE 추정만으로는 놓치게 되는 두 가지 핵심적인 변동성(Variability)을 강조합니다[cite: 48].\n\n반응 변수의 내재적 변동성 (Aleatoric Uncertainty): 회귀 함수(regression function) 주변에 데이터가 얼마나 퍼져 있는가? 공변량 \\(X\\)가 ITE의 변동을 완벽하게 설명하지 못한다면 여전히 큰 불확실성이 남습니다.\n추정량의 변동성 (Epistemic Uncertainty): 유한한 표본(finite samples)으로 인해 발생하는 CATE 추정값 자체의 오차입니다.\n\n이 두 가지를 모두 통제하려면, (1) 공변량이 ITE의 변동을 거의 완벽하게 설명해야 하고, (2) 모든 \\(X\\) 값에 대해 CATE를 완벽하게 추정할 수 있어야 합니다. [cite_start]현실적으로 이는 불가능에 가깝습니다[cite: 49, 50]."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/01-From average effects to individual effects/index.html#불확실성-정량화-신뢰구간의-필요성",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/01-From average effects to individual effects/index.html#불확실성-정량화-신뢰구간의-필요성",
    "title": "평균을 넘어 개인으로: 인과추론의 새로운 패러다임과 Conformal Inference",
    "section": "3 불확실성 정량화: 신뢰구간의 필요성",
    "text": "3 불확실성 정량화: 신뢰구간의 필요성\n[cite_start]미국 FDA는 약물 승인을 위해 단순한 점 추정치가 아닌, 충분한 증거를 보장하는 신뢰구간(Confidence Interval) 또는 p-value를 요구합니다[cite: 57]. 하지만 기존의 머신러닝 기반 CATE 추정 방법들은 이러한 불확실성 정량화(Uncertainty Quantification)에서 꽤 저조한 성능을 보입니다.\n[cite_start]심지어 베이지안 방법론을 포함한 최신 기법들도 간단하고 매끄러운 모형(smooth models)에서조차 목표하는 커버리지(coverage)를 달성하지 못하는 경우가 많습니다[cite: 61].\n\n3.1 제안하는 해결책: Conformal Inference\n[cite_start]이 논문은 Conformal Inference(컨포멀 추론) 아이디어를 차용하여, 잠재적 결과(Potential Outcome) 프레임워크 하에서 신뢰할 수 있는 ITE 예측 구간(Prediction Interval)을 생성하는 방법을 제안합니다[cite: 19, 62].\n!(placeholder_image_2.png) Figure 2: Conformal Inference의 기본 개념. 데이터 분포에 대한 가정 없이, 유한한 샘플에서 실제 값이 포함될 확률(예: 90%)을 보장하는 구간을 생성한다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/01-From average effects to individual effects/index.html#해결해야-할-두-가지-도전-과제",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/01-From average effects to individual effects/index.html#해결해야-할-두-가지-도전-과제",
    "title": "평균을 넘어 개인으로: 인과추론의 새로운 패러다임과 Conformal Inference",
    "section": "4 해결해야 할 두 가지 도전 과제",
    "text": "4 해결해야 할 두 가지 도전 과제\n[cite_start]ITE에 대한 신뢰 구간을 만들기 위해 논문은 문제를 두 가지 단계로 나눕니다[cite: 63, 64, 65].\n\n4.1 Challenge 1: 연구 대상자(In-sample)를 위한 구간 추정\n데이터셋에 존재하는 대상(\\(i\\))에 대해 ITE 구간을 만드는 것입니다. * 문제: 각 대상에 대해 \\(Y_i(1)\\) 혹은 \\(Y_i(0)\\) 중 하나만 관측됩니다(Fundamental Problem of Causal Inference). * 접근법: 관측되지 않은 잠재적 결과(Counterfactual)를 추론하는 문제로 귀결됩니다.\n\n\n4.2 Challenge 2: 새로운 대상(Out-of-sample)을 위한 구간 추정\n연구에 참여하지 않은 완전히 새로운 대상에 대해 ITE 구간을 만드는 것입니다. * 문제: 이들은 \\(Y(1)\\)과 \\(Y(0)\\)가 둘 다 관측되지 않습니다. * 접근법: 두 잠재적 결과를 동시에 모델링할 수 없으므로 훨씬 더 어려운 문제입니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/01-From average effects to individual effects/index.html#핵심-아이디어의-논리적-전개-step-by-step",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/01-From average effects to individual effects/index.html#핵심-아이디어의-논리적-전개-step-by-step",
    "title": "평균을 넘어 개인으로: 인과추론의 새로운 패러다임과 Conformal Inference",
    "section": "5 핵심 아이디어의 논리적 전개 (Step-by-Step)",
    "text": "5 핵심 아이디어의 논리적 전개 (Step-by-Step)\n논문의 Section 1은 구체적인 수식보다는 방법론의 논리적 구조를 설명하는 데 집중합니다. [cite_start]저자들이 제안하는 방법이 어떻게 첫 번째 Challenge(반사실적 추론)를 해결하여 ITE 구간으로 연결되는지 단계별로 정리해 보겠습니다[cite: 70, 71].\n\n5.1 Step 1: 반사실적(Counterfactual) 결과의 추론\n어떤 환자 \\(i\\)가 처치(\\(T_i=1\\))를 받았고 결과 \\(Y_i(1)\\)이 관측되었다고 가정해 봅시다. 우리가 알고 싶은 ITE는 다음과 같습니다.\n\\[\n\\tau_i = Y_i(1) - Y_i(0)\n\\]\n여기서 \\(Y_i(1)\\)은 이미 알고 있는 상수(observed)입니다. 따라서 \\(\\tau_i\\)를 아는 것은 오직 미지의 값인 \\(Y_i(0)\\)(Counterfactual)를 추론하는 것에 달려 있습니다.\n\n\n5.2 Step 2: 예측 구간 생성\nConformal Inference를 사용하여, 미지의 \\(Y_i(0)\\)가 포함될 확률이 \\(1-\\alpha\\)인 예측 구간 \\(\\hat{C}_0(X_i)\\)를 생성합니다.\n\\[\n\\mathbb{P}(Y_i(0) \\in \\hat{C}_0(X_i)) \\ge 1 - \\alpha\n\\]\n\n\n5.3 Step 3: 구간의 이동(Shifting)을 통한 ITE 구간 도출\n이제 관측된 \\(Y_i(1)\\)을 이용하여 위에서 구한 구간을 이동(shift)시킵니다. 부등식을 재배열하면 자연스럽게 ITE(\\(\\tau_i\\))에 대한 구간이 도출됩니다.\n\\[\nY_i(0) \\in \\hat{C}_0(X_i) \\iff Y_i(1) - \\tau_i \\in \\hat{C}_0(X_i)\n\\]\n이를 \\(\\tau_i\\)에 대해 정리하면:\n\\[\n\\tau_i \\in Y_i(1) - \\hat{C}_0(X_i)\n\\]\n즉, “관측되지 않은 잠재적 결과에 대한 신뢰 구간을 구하면, 이를 관측된 결과와 대조하여 ITE의 신뢰 구간으로 변환할 수 있다”는 것이 핵심 논리입니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/01-From average effects to individual effects/index.html#결론-및-요약",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/01-From average effects to individual effects/index.html#결론-및-요약",
    "title": "평균을 넘어 개인으로: 인과추론의 새로운 패러다임과 Conformal Inference",
    "section": "6 결론 및 요약",
    "text": "6 결론 및 요약\n이 논문의 Section 1은 단순히 평균 효과(ATE)나 조건부 평균(CATE)을 추정하는 것을 넘어, 개별 효과(ITE)의 불확실성을 정량화하는 것이 왜 필수적인지 역설합니다.\n특히 저자들은 자신들의 방법론이 이중 강건성(Doubly Robust Property)을 가짐을 강조합니다. [cite_start]이는 (1) 성향 점수(Propensity Score) 모델이 정확하거나, (2) 조건부 분위수(Conditional Quantiles) 모델이 정확하다면, 둘 중 하나만 만족해도 평균 커버리지(Average Coverage)가 보장된다는 강력한 성질입니다[cite: 21].\n다음 포스트에서는 이 개념들이 구체적인 수식과 알고리즘(Section 2 이후)으로 어떻게 구현되는지 살펴보겠습니다.\n\nReference: Lei, L., & Candès, E. J. (2021). Conformal inference of counterfactuals and individual treatment effects. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 83(5), 911-938."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-04-Conformalizing-Bayes/index.html",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-04-Conformalizing-Bayes/index.html",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.4)",
    "section": "",
    "text": "Bayesian Neural Network와 같은 베이지안 모델들은 불확실성 정량화(Uncertainty Quantification) 분야에서 매우 매력적인 도구입니다.\n이들은 사전 지식(Prior)을 반영할 수 있고, 예측의 결과물로 단일 값이 아닌 분포(Posterior Predictive Density)를 제공하기 때문입니다.\n하지만 베이지안 모델에는 치명적인 약점이 있습니다.\n“모델의 가정(Prior, Likelihood function 등)이 완벽하게 맞아야만” 예측된 불확실성이 정확하다는 점입니다.\n현실의 복잡한 데이터에서 이러한 가정이 완벽히 들어맞기는 어렵습니다.\nConformalizing Bayes는 베이지안 모델의 정보량을 그대로 활용하되, Conformal Prediction을 통해 “가정이 틀렸더라도” 통계적 커버리지를 보장하는 강력한 방법론입니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-04-Conformalizing-Bayes/index.html#ideal-scenario",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-04-Conformalizing-Bayes/index.html#ideal-scenario",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.4)",
    "section": "Ideal Scenario",
    "text": "Ideal Scenario\n\n만약 우리가 만든 베이지안 모델 \\(\\hat{f}(y|x)\\) (입력 \\(x\\)가 주어졌을 때 \\(y\\)의 사후 확률 밀도)가 완벽하다면, 최적의 예측 집합 \\(S(x)\\)는 단순히 밀도 함수(Density)가 높은 영역을 잘라내어 만들 수 있습니다.\n\n\\[\nS(x) = \\{ y : \\hat{f}(y|x) &gt; t \\}\n\\]\n\n여기서 임계값 \\(t\\)는 해당 영역의 적분값이 \\(1-\\alpha\\)가 되도록 설정합니다. \\[\\int_{y \\in S(x)} \\hat{f}(y|x) dy = 1-\\alpha\\]\n이를 Highest Posterior Density (HPD) Region이라고도 합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-04-Conformalizing-Bayes/index.html#reality",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-04-Conformalizing-Bayes/index.html#reality",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.4)",
    "section": "Reality",
    "text": "Reality\n\n하지만 우리는 모델 \\(\\hat{f}\\)가 완벽하다고 보장할 수 없습니다.\n따라서 위 방식으로 구한 집합은 실제로는 90%를 커버하지 못할 수도(Under-coverage), 너무 넓을 수도(Over-coverage) 있습니다.\n우리는 베이지안 모델의 \\(\\hat{f}(y|x)\\)를 “진짜 확률”이 아니라 “유용한 불확실성 점수(Heuristic Score)”로 간주하고, CP를 적용하여 올바른 임계값(Threshold)을 찾을 것입니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-04-Conformalizing-Bayes/index.html#step-1-define-score-function",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-04-Conformalizing-Bayes/index.html#step-1-define-score-function",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.4)",
    "section": "Step 1: Define Score Function",
    "text": "Step 1: Define Score Function\n\n우리는 모델이 예측한 사후 확률 밀도(Posterior Predictive Density)가 높을수록 에러가 작다(확실하다)고 봅니다.\nConformal Score는 “불확실한 정도”를 나타내야 하므로, 밀도 함수의 음수(Negative)를 취합니다. \\[\ns(x, y) = - \\hat{f}(y|x)\n\\]\n\n\\(\\hat{f}(y|x)\\)가 높음 (모델이 정답을 확신함) \\(\\rightarrow\\) Score \\(s\\)는 매우 작은 음수.\n\\(\\hat{f}(y|x)\\)가 낮음 (모델이 정답을 예측 못함) \\(\\rightarrow\\) Score \\(s\\)는 큰 값(0에 가까운 값 혹은 양수)."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-04-Conformalizing-Bayes/index.html#step-2-calibration-finding-hatq",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-04-Conformalizing-Bayes/index.html#step-2-calibration-finding-hatq",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.4)",
    "section": "Step 2: Calibration (Finding \\(\\hat{q}\\))",
    "text": "Step 2: Calibration (Finding \\(\\hat{q}\\))\n\nCalibration 데이터 \\((X_1, Y_1), \\dots, (X_n, Y_n)\\)에 대해 점수들을 계산하고, \\(1-\\alpha\\) 분위수 \\(\\hat{q}\\)를 찾습니다.\n\n\\[\n\\hat{q} = \\text{Quantile}\\left( \\frac{\\lceil (n+1)(1-\\alpha) \\rceil}{n} ; \\{s_1, \\dots, s_n\\} \\right)\n\\]\n\n여기서 구한 \\(\\hat{q}\\)는 “밀도 함수를 어디서 잘라야(Thresholding) 하는가?”에 대한 보정된 기준선이 됩니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-04-Conformalizing-Bayes/index.html#step-3-construct-prediction-set",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-04-Conformalizing-Bayes/index.html#step-3-construct-prediction-set",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.4)",
    "section": "Step 3: Construct Prediction Set",
    "text": "Step 3: Construct Prediction Set\n\n새로운 입력 \\(X_{test}\\)에 대해, Score가 \\(\\hat{q}\\) 이하인(즉, 밀도가 \\(-\\hat{q}\\) 이상인) 모든 \\(y\\)를 포함합니다.\n\n\\[\n\\mathcal{C}(x) = \\{ y : s(x, y) \\le \\hat{q} \\} = \\{ y : -\\hat{f}(y|x) \\le \\hat{q} \\}\n\\]\n\n이를 정리하면 최종 예측 집합은 다음과 같습니다:\n\n\\[\n\\mathcal{C}(x) = \\{ y : \\hat{f}(y|x) \\ge -\\hat{q} \\}\n\\]\n\n즉, 보정된 임계값 \\(-\\hat{q}\\)보다 확률 밀도가 높은 모든 \\(y\\)의 집합(Superlevel Set)을 구성합니다.\n\n\n\n\nFigure 10: Conformalized Bayes 알고리즘 시각화. 사후 확률 밀도 함수(Posterior Predictive Density) \\(\\hat{f}(y|x)\\)를 Conformal Prediction으로 구한 임계값 \\(-\\hat{q}\\)에서 잘라(Slicing), 그 위의 영역을 예측 집합으로 삼는다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-03-Conformalizing-Scalar-Uncertainty-Estimates/index.html",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-03-Conformalizing-Scalar-Uncertainty-Estimates/index.html",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.3)",
    "section": "",
    "text": "이전 포스트에서 다룬 Conformalized Quantile Regression (CQR)은 매우 강력하지만, 두 개의 Quantile을 학습시켜야 한다는 조건이 있습니다.\n하지만 실무에서는 종종 평균(\\(\\mu\\))과 분산(\\(\\sigma^2\\))만을 예측하는 더 단순한 모델을 사용하거나, 혹은 모델 앙상블의 분산 등을 불확실성 지표로 삼기도 합니다.\n이번 포스트에서는 이러한 단일 스칼라 불확실성 지표(Scalar Uncertainty Estimate)를 활용하여 통계적으로 유효한 예측 구간을 생성하는 방법을 알아봅니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-03-Conformalizing-Scalar-Uncertainty-Estimates/index.html#step-1-define-score-function",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-03-Conformalizing-Scalar-Uncertainty-Estimates/index.html#step-1-define-score-function",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.3)",
    "section": "Step 1: Define Score Function",
    "text": "Step 1: Define Score Function\n\nCalibration 데이터 \\((X_i, Y_i)\\)에 대해 다음과 같은 Score를 정의합니다.\n\n\\[\ns(x, y) = \\frac{|y - \\hat{f}(x)|}{u(x)}\n\\]\n\n분자 \\(|y - \\hat{f}(x)|\\): 실제 모델의 예측 오차(절대값)입니다.\n분모 \\(u(x)\\): 모델이 스스로 추정한 불확실성입니다.\n의미: “모델이 예상한 불확실성 대비 실제 오차의 비율”입니다.\n\n만약 모델이 불확실하다고 판단(\\(u(x)\\) 큼)했는데 오차도 크다면, \\(s\\)는 적절한 값을 가집니다.\n만약 모델이 확실하다고 판단(\\(u(x)\\) 작음)했는데 오차가 크다면, \\(s\\)는 매우 커집니다 (Penalty)."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-03-Conformalizing-Scalar-Uncertainty-Estimates/index.html#step-2-calibration-get-hatq",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-03-Conformalizing-Scalar-Uncertainty-Estimates/index.html#step-2-calibration-get-hatq",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.3)",
    "section": "Step 2: Calibration (Get \\(\\hat{q}\\))",
    "text": "Step 2: Calibration (Get \\(\\hat{q}\\))\n\n계산된 점수들 \\(s_1, \\dots, s_n\\)에 대해 \\(1-\\alpha\\) 분위수(Quantile) \\(\\hat{q}\\)를 구합니다.\n\n\\[\n\\hat{q} = \\text{Quantile}\\left( \\frac{\\lceil (n+1)(1-\\alpha) \\rceil}{n} ; \\{s_1, \\dots, s_n\\} \\right)\n\\]\n\n여기서 구해진 \\(\\hat{q}\\)는 “불확실성 지표 \\(u(x)\\)에 곱해야 할 보정 계수(Multiplier)” 역할을 합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-03-Conformalizing-Scalar-Uncertainty-Estimates/index.html#step-3-construct-prediction-interval",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-03-Conformalizing-Scalar-Uncertainty-Estimates/index.html#step-3-construct-prediction-interval",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.3)",
    "section": "Step 3: Construct Prediction Interval",
    "text": "Step 3: Construct Prediction Interval\n\n새로운 입력 \\(X_{test}\\)에 대한 예측 구간은 중심 예측값 \\(\\hat{f}(x)\\)에서 불확실성 지표 \\(u(x)\\)의 \\(\\hat{q}\\)배만큼 벌려준 구간이 됩니다.\n\n\\[\n\\mathcal{C}(x) = [\\hat{f}(x) - \\hat{q}u(x), \\quad \\hat{f}(x) + \\hat{q}u(x)]\n\\]\n\n유도 과정 (Derivation of Validity)\n\n이 구간이 왜 \\(1-\\alpha\\) 커버리지를 보장하는지 살펴보겠습니다.\n\n\nCalibration 단계에서 \\(\\hat{q}\\)를 구했으므로, 새로운 데이터에 대해 다음 확률이 성립합니다. \\[ \\mathbb{P}[s(X_{test}, Y_{test}) \\le \\hat{q}] \\ge 1 - \\alpha \\]\nScore \\(s\\)의 정의를 대입합니다. \\[ \\mathbb{P}\\left[ \\frac{|Y_{test} - \\hat{f}(X_{test})|}{u(X_{test})} \\le \\hat{q} \\right] \\ge 1 - \\alpha \\]\n양변에 \\(u(X_{test})\\)를 곱합니다 (불확실성은 항상 양수이므로 부등호 유지). \\[ \\mathbb{P}\\left[ |Y_{test} - \\hat{f}(X_{test})| \\le \\hat{q}u(X_{test}) \\right] \\ge 1 - \\alpha \\]\n절대값을 풉니다. \\[ \\mathbb{P}\\left[ -\\hat{q}u(X_{test}) \\le Y_{test} - \\hat{f}(X_{test}) \\le \\hat{q}u(X_{test}) \\right] \\ge 1 - \\alpha \\]\n\\(Y_{test}\\)에 대해 정리하면 최종 구간이 도출됩니다. \\[ \\mathbb{P}\\left[ \\hat{f}(X_{test}) - \\hat{q}u(X_{test}) \\le Y_{test} \\le \\hat{f}(X_{test}) + \\hat{q}u(X_{test}) \\right] \\ge 1 - \\alpha \\]\n\n\n\n\nFigure 8: Uncertainty Scalar를 이용한 예측 구간 시각화. 중심 예측값 \\(\\hat{f}(x)\\)를 기준으로, 위아래로 \\(\\hat{q}u(x)\\)만큼 벌어진 대칭적인 구간을 형성한다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-01-Conformal-Prediction/index.html",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-01-Conformal-Prediction/index.html",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 1)",
    "section": "",
    "text": "딥러닝 모델과 같은 Black-box 머신러닝 모델들은 의료 진단이나 자율 주행과 같은 High-risk 환경에서 일상적으로 사용되고 있습니다.\n하지만 이러한 모델들은 종종 잘못된 예측을 내놓으면서도 높은 확신(Overconfidence)을 보이는 문제가 있습니다.\nConformal Prediction(CP)는 이러한 모델의 예측에 대해 통계적으로 엄밀한 불확실성 구간(Uncertainty Sets/Intervals)을 생성하는 방법론입니다.\nCP의 가장 큰 장점은 다음과 같습니다:\n\nDistribution-free: 데이터의 분포에 대한 가정(가우시안 분포 등)이 필요하지 않습니다.\nModel-agnostic: 뉴럴 네트워크를 포함한 어떤 학습된 모델(Pre-trained model)에도 적용 가능합니다.\nFinite-sample guarantee: 무한한 데이터가 아닌, 유한한 샘플 수에서도 통계적 커버리지(\\(1-\\alpha\\))를 보장합니다.\n\n이 글에서는 논문 “A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification”의 핵심 내용을 바탕으로 CP의 원리와 구현 방법을 정리합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-01-Conformal-Prediction/index.html#step-1-calibration-data-준비",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-01-Conformal-Prediction/index.html#step-1-calibration-data-준비",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 1)",
    "section": "Step 1: Calibration Data 준비",
    "text": "Step 1: Calibration Data 준비\n\n학습에 사용되지 않은 \\(n\\)개의 데이터 쌍 \\((X_1, Y_1), \\dots, (X_n, Y_n)\\)을 준비합니다.\n이 데이터는 교환 가능(Exchangeable), 일반적으로는 i.i.d. 가정만 만족하면 됩니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-01-Conformal-Prediction/index.html#step-2-conformal-score-계산",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-01-Conformal-Prediction/index.html#step-2-conformal-score-계산",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 1)",
    "section": "Step 2: Conformal Score 계산",
    "text": "Step 2: Conformal Score 계산\n\n각 Calibration 데이터에 대해 모델이 얼마나 “잘못” 예측했는지를 나타내는 Conformal Score \\(s_i\\)를 계산합니다.\n분류 문제에서 가장 일반적인 점수 함수는 다음과 같습니다:\n\n\\[\ns_i = 1 - \\hat{f}(X_i)_{Y_i}\n\\]\n\n여기서 \\(\\hat{f}(X_i)_{Y_i}\\)는 정답 클래스 \\(Y_i\\)에 대한 모델의 Softmax 확률입니다.\n모델이 정답을 확신할수록 \\(\\hat{f}(X_i)_{Y_i} \\approx 1\\)이므로 점수 \\(s_i\\)는 0에 가까워집니다.\n모델이 틀렸거나 불확실할수록 점수 \\(s_i\\)는 커집니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-01-Conformal-Prediction/index.html#step-3-quantile-구하기",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-01-Conformal-Prediction/index.html#step-3-quantile-구하기",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 1)",
    "section": "Step 3: Quantile 구하기",
    "text": "Step 3: Quantile 구하기\n\n우리는 새로운 데이터가 들어왔을 때, 모델의 불확실성(Score)이 어느 수준 이하이어야 안심할 수 있는지를 결정해야 합니다.\n이를 위해 계산된 점수들 \\(s_1, \\dots, s_n\\)의 분포에서 \\(\\hat{q}\\) (Quantile) 값을 찾습니다.\n엄밀한 커버리지를 보장하기 위해 다음과 같은 보정된 분위수(Adjusted Quantile)를 사용합니다:\n\n\\[\n\\hat{q} = \\text{Quantile}\\left( \\frac{\\lceil (n+1)(1-\\alpha) \\rceil}{n} ; \\{s_1, \\dots, s_n\\} \\right)\n\\]\n\n이 \\(\\hat{q}\\) 값은 “전체 데이터의 \\((1-\\alpha)\\) 비율이 이 점수보다 낮다”는 경계선 역할을 합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-01-Conformal-Prediction/index.html#step-4-prediction-set-구성-inference",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-01-Conformal-Prediction/index.html#step-4-prediction-set-구성-inference",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 1)",
    "section": "Step 4: Prediction Set 구성 (Inference)",
    "text": "Step 4: Prediction Set 구성 (Inference)\n\n이제 새로운 테스트 데이터 \\(X_{test}\\)가 들어오면, 예측 집합 \\(\\mathcal{C}(X_{test})\\)를 다음과 같이 구성합니다:\n\n\\[\n\\mathcal{C}(X_{test}) = \\{ y : 1 - \\hat{f}(X_{test})_y \\le \\hat{q} \\} = \\{ y : \\hat{f}(X_{test})_y \\ge 1 - \\hat{q} \\}\n\\]\n\n즉, 모델의 예측 확률이 \\(1-\\hat{q}\\) 이상인 모든 클래스를 후보로 포함시킵니다.\n\n\n\n\nFigure 2: Conformal Prediction의 전체 프로세스 도식화 및 Python 코드 예시. (1) Score 계산, (2) Quantile 계산, (3) Prediction Set 구성의 3단계로 이루어진다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-03-Conformal-Risk-Control/index.html",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-03-Conformal-Risk-Control/index.html",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.3)",
    "section": "",
    "text": "지금까지 우리가 다룬 Conformal Prediction의 핵심 보장은 다음과 같은 형태였습니다.\n\n\\[ \\mathbb{P}(Y_{test} \\notin \\mathcal{C}(X_{test})) \\le \\alpha \\]\n\n즉, “정답을 놓칠 확률(Miscoverage rate)”을 \\(\\alpha\\) 이하로 묶는 것이었습니다.\n하지만 현실의 많은 머신러닝 문제에서는 단순히 “맞았다/틀렸다”의 이진(Binary) 에러보다 더 복잡한 손실(Loss)을 제어해야 할 때가 많습니다.\n\n의료 영상 분할(Tumor Segmentation): 암 영역을 조금이라도 놓치면(False Negative) 치명적입니다. 픽셀 단위의 재현율(Recall)을 보장해야 할 수 있습니다.\n다중 라벨 분류(Multilabel Classification): 여러 개의 태그 중 90% 이상을 맞추기를 원할 수 있습니다 (F1-score 등).\n\nConformal Risk Control (CRC)은 이러한 요구를 반영하여, 임의의 유계 손실 함수(Bounded Loss Function)의 기댓값을 제어하는 기법입니다.\n\n\\[\n\\mathbb{E}[l(\\mathcal{C}(X_{test}), Y_{test})] \\le \\alpha\n\\]"
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-03-Conformal-Risk-Control/index.html#key-components",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-03-Conformal-Risk-Control/index.html#key-components",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.3)",
    "section": "Key Components",
    "text": "Key Components\n\n\nNested Sets (\\(\\mathcal{C}_\\lambda\\)):\n\n\n우리는 파라미터 \\(\\lambda\\)를 조절하여 예측 집합의 크기(보수적인 정도)를 조절합니다.\n\\(\\lambda\\)가 커질수록 예측 집합 \\(\\mathcal{C}_\\lambda(x)\\)는 더 커지고(더 많은 후보를 포함), 따라서 더 안전해집니다(Conservative).\n\n\nMonotone Loss Function (\\(l\\)):\n\n\n손실 함수 \\(l(\\mathcal{C}, Y)\\)는 집합 \\(\\mathcal{C}\\)가 커질수록 감소하거나 같아야 합니다 (Non-increasing).\n또한, 손실값은 어떤 상한선 \\(B\\)를 넘지 않아야 합니다 (\\(l \\in (-\\infty, B]\\)).\n\n\\[ \\lambda_1 \\le \\lambda_2 \\implies l(\\mathcal{C}_{\\lambda_1}(x), y) \\ge l(\\mathcal{C}_{\\lambda_2}(x), y) \\]"
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-03-Conformal-Risk-Control/index.html#step-1-calculate-empirical-risk",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-03-Conformal-Risk-Control/index.html#step-1-calculate-empirical-risk",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.3)",
    "section": "Step 1: Calculate Empirical Risk",
    "text": "Step 1: Calculate Empirical Risk\n\nCalibration 데이터셋 \\((X_1, Y_1), \\dots, (X_n, Y_n)\\)에 대해, 특정 파라미터 \\(\\lambda\\)를 썼을 때의 평균 손실(Empirical Risk)을 계산하는 함수 \\(\\hat{R}(\\lambda)\\)를 정의합니다.\n\n\\[\n\\hat{R}(\\lambda) = \\frac{1}{n} \\sum_{i=1}^{n} l(\\mathcal{C}_{\\lambda}(X_i), Y_i)\n\\]\n\n이 함수는 \\(\\lambda\\)가 증가함에 따라 손실이 감소하는 우하향 곡선을 그립니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-03-Conformal-Risk-Control/index.html#step-2-find-optimal-lambda",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-03-Conformal-Risk-Control/index.html#step-2-find-optimal-lambda",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.3)",
    "section": "Step 2: Find Optimal \\(\\lambda\\)",
    "text": "Step 2: Find Optimal \\(\\lambda\\)\n\n우리는 기대 손실이 \\(\\alpha\\) 이하가 되기를 원합니다.\n하지만 유한한 데이터(\\(n\\))로 인한 불확실성을 고려해야 하므로, 단순히 \\(\\hat{R}(\\lambda) \\le \\alpha\\)가 되는 지점을 찾으면 안 됩니다.\n대신, 다음과 같이 보정된 기준(Conservative Target)을 사용합니다.\n\n\\[\n\\hat{\\lambda} = \\inf \\left\\{ \\lambda : \\hat{R}(\\lambda) \\le \\alpha - \\frac{B - \\alpha}{n} \\right\\}\n\\]\n\n\\(B\\): 손실 함수의 최댓값 (Upper Bound)\nCorrection Term (\\(\\frac{B-\\alpha}{n}\\)): 데이터 개수 \\(n\\)이 적을 때 더 보수적으로 \\(\\lambda\\)를 선택하게 만드는 항입니다. \\(n\\)이 무한대로 가면 이 항은 0이 되어 \\(\\alpha\\)에 수렴합니다.\n\n\n\n\nFigure: Conformal Risk Control의 개념도. 파란색 실선은 \\(\\lambda\\)에 따른 경험적 리스크 \\(\\hat{R}(\\lambda)\\)를 나타낸다. 목표 리스크 \\(\\alpha\\)에서 보정항 \\(\\frac{B-\\alpha}{n}\\)만큼을 뺀 점선과 만나는 지점에서 \\(\\hat{\\lambda}\\)를 결정한다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-05-Conformal-Prediction-Under-Covariate-Shift/index.html",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-05-Conformal-Prediction-Under-Covariate-Shift/index.html",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.5)",
    "section": "",
    "text": "지금까지 우리가 배운 모든 Conformal Prediction(CP) 방법론은 하나의 강력한 가정에 의존하고 있습니다.\n바로 “테스트 데이터가 Calibration 데이터와 동일한 분포(i.i.d.)에서 왔다”는 가정입니다.\n하지만 현실은 그렇지 않습니다. 과거의 데이터가 미래를 완벽하게 대변하지 못하는 경우가 많습니다.\n\n의료 진단: 학습 데이터는 성인과 유아의 비율이 50:50이었는데, 실제 병원에는 성인이 95% 방문할 수 있습니다.\n자율 주행: 아침(밝음)에 데이터를 수집하여 학습했는데, 실제 주행은 오후(어두움)에 이루어질 수 있습니다.\n\n이러한 분포의 변화 중 Covariate Shift는 입력 변수 \\(X\\)의 분포 \\(P(X)\\)는 바뀌지만, 입력과 출력 사이의 관계 \\(P(Y|X)\\)는 유지되는 상황을 말합니다.\n이번 포스트에서는 Weighted Conformal Prediction을 사용하여 이러한 변화 속에서도 커버리지를 보장하는 방법을 알아봅니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-05-Conformal-Prediction-Under-Covariate-Shift/index.html#step-1-likelihood-ratio-calculation",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-05-Conformal-Prediction-Under-Covariate-Shift/index.html#step-1-likelihood-ratio-calculation",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.5)",
    "section": "Step 1: Likelihood Ratio Calculation",
    "text": "Step 1: Likelihood Ratio Calculation\n\n먼저, 두 분포 사이의 비율(Likelihood Ratio)을 계산하는 함수 \\(w(x)\\)를 정의합니다. \\[\nw(x) = \\frac{d\\mathcal{P}_{test}(x)}{dP(x)}\n\\]\n\n\\(w(x) &gt; 1\\): 해당 샘플 \\(x\\)는 학습 때보다 테스트 때 더 자주 등장합니다 (중요함).\n\\(w(x) &lt; 1\\): 해당 샘플 \\(x\\)는 테스트 때 덜 등장합니다 (덜 중요함)."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-05-Conformal-Prediction-Under-Covariate-Shift/index.html#step-2-compute-normalized-weights",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-05-Conformal-Prediction-Under-Covariate-Shift/index.html#step-2-compute-normalized-weights",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.5)",
    "section": "Step 2: Compute Normalized Weights",
    "text": "Step 2: Compute Normalized Weights\n\n새로운 테스트 포인트 \\(x\\)가 들어왔을 때, 이 \\(x\\)와 기존 Calibration 데이터 \\(X_i\\)들에게 부여할 확률 질량(Probability Mass)을 재계산합니다.\n\n\\[\np_i^w(x) = \\frac{w(X_i)}{\\sum_{j=1}^{n} w(X_j) + w(x)}\n\\]\n\\[\np_{test}^w(x) = \\frac{w(x)}{\\sum_{j=1}^{n} w(X_j) + w(x)}\n\\]\n\n기존 CP에서는 모든 데이터가 \\(\\frac{1}{n+1}\\)의 동등한 확률을 가졌습니다.\nWeighted CP에서는 \\(w(\\cdot)\\)에 비례하여 확률을 다르게 배정합니다.\n즉, 테스트 분포와 유사한 데이터일수록 \\(p_i\\)가 커집니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-05-Conformal-Prediction-Under-Covariate-Shift/index.html#step-3-weighted-quantile-calculation",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-05-Conformal-Prediction-Under-Covariate-Shift/index.html#step-3-weighted-quantile-calculation",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.5)",
    "section": "Step 3: Weighted Quantile Calculation",
    "text": "Step 3: Weighted Quantile Calculation\n\n이제 가장 중요한 단계인 Quantile 계산입니다.\n기존에는 단순히 점수를 정렬하고 \\((1-\\alpha)\\) 지점을 찾았지만, 이제는 가중치가 반영된 누적 분포(Weighted CDF)를 사용해야 합니다. \\[\n\\hat{q}(x) = \\inf \\left\\{ s_j : \\sum_{i=1}^{j} p_i^w(x) \\mathbb{I}\\{s_i \\le s_j\\} \\ge 1-\\alpha \\right\\}\n\\]\n\n여기서 \\(s_j\\)는 오름차순으로 정렬된 Calibration Score라고 가정합니다.\n\n즉, 가중치 \\(p_i^w(x)\\)들을 순서대로 더해가다가, 그 합이 \\(1-\\alpha\\)를 넘기는 순간의 점수를 \\(\\hat{q}(x)\\)로 선택합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-02-Class-Conditional-Conformal-Prediction/index.html",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-02-Class-Conditional-Conformal-Prediction/index.html",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.2)",
    "section": "",
    "text": "머신러닝 분류 문제, 특히 의료 진단과 같은 분야에서는 클래스 불균형(Class Imbalance)이 흔하게 발생합니다.\n예를 들어, 암 진단 모델을 개발한다고 가정해봅시다.\n\n정상(Normal): 데이터의 95%\n암(Cancer): 데이터의 5%\n\n우리가 일반적인 Conformal Prediction을 사용하여 95% 커버리지를 달성했다고 칩시다.\n가장 쉬운 달성 방법은 무엇일까요?\n“그냥 모든 환자를 ’정상’이라고 예측하고, 암 환자는 다 틀리는 것”입니다.\n이렇게 해도 (정상 95% + 암 0%) / 100% \\(\\approx\\) 95% 커버리지는 달성됩니다.\n하지만 이는 재앙입니다.\n우리는 암 환자에 대해서도 똑같이 95%의 정확도로 정답을 포함시키기를 원합니다.\nClass-Conditional Conformal Prediction은 바로 이 문제, 즉 모든 정답 클래스(Ground Truth Class)에 대해 균등한 커버리지를 보장하기 위한 방법입니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-02-Class-Conditional-Conformal-Prediction/index.html#step-1-stratify-calibration-data-by-class",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-02-Class-Conditional-Conformal-Prediction/index.html#step-1-stratify-calibration-data-by-class",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.2)",
    "section": "Step 1: Stratify Calibration Data by Class",
    "text": "Step 1: Stratify Calibration Data by Class\n\nCalibration 데이터셋을 실제 정답 클래스(Ground Truth Class)별로 나눕니다.\n\n\\[\nS^{(k)} = \\{ (X_j, Y_j) : Y_j = k \\}\n\\]"
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-02-Class-Conditional-Conformal-Prediction/index.html#step-2-calibrate-per-class",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-02-Class-Conditional-Conformal-Prediction/index.html#step-2-calibrate-per-class",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.2)",
    "section": "Step 2: Calibrate per Class",
    "text": "Step 2: Calibrate per Class\n\n각 클래스 \\(k\\)에 대해 독립적으로 Quantile \\(\\hat{q}^{(k)}\\)를 계산합니다.\n\n\n클래스 \\(k\\)에 속하는 데이터들의 Score \\(s^{(k)}_1, \\dots, s^{(k)}_{n^{(k)}}\\)를 모읍니다.\n\n\n해당 클래스의 데이터 수 \\(n^{(k)}\\)를 기준으로 보정된 분위수를 구합니다: \\[\n\\hat{q}^{(k)} = \\text{Quantile}\\left( \\frac{\\lceil (n^{(k)}+1)(1-\\alpha) \\rceil}{n^{(k)}} ; \\{s^{(k)}_1, \\dots, s^{(k)}_{n^{(k)}}\\} \\right)\n\\]\n\n\n결과적으로 우리는 클래스 개수만큼의 임계값 \\(\\hat{q}^{(1)}, \\dots, \\hat{q}^{(K)}\\)를 얻습니다.\n\n샘플이 적거나 모델이 어려워하는 클래스(예: 암)는 임계값이 높게(보수적으로) 설정될 것입니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-02-Class-Conditional-Conformal-Prediction/index.html#step-3-inference-iterative-check",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-02-Class-Conditional-Conformal-Prediction/index.html#step-3-inference-iterative-check",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.2)",
    "section": "Step 3: Inference (Iterative Check)",
    "text": "Step 3: Inference (Iterative Check)\n\n이 부분이 4.1절(Group-Balanced)과 가장 다릅니다.\n테스트 시점에는 입력 \\(X_{test}\\)의 진짜 클래스(True Class)가 무엇인지 모릅니다.\n따라서 “해당 그룹의 \\(\\hat{q}\\)를 가져다 쓰는” 방식은 불가능합니다.\n대신, 우리는 “만약 정답이 클래스 \\(y\\)라면?”이라는 가정을 모든 후보 클래스에 대해 수행합니다.\n예측 집합 \\(\\mathcal{C}(x)\\)는 다음 조건을 만족하는 모든 클래스 \\(y\\)를 포함합니다: \\[\n\\mathcal{C}(x) = \\{ y : s(x, y) \\le \\hat{q}^{(y)} \\}\n\\]\n\n후보 클래스 \\(y\\)가 ‘암’이라면? \\(\\rightarrow\\) \\(s(x, \\text{암})\\)을 계산하고, 이를 ’암’ 클래스의 임계값 \\(\\hat{q}^{(\\text{암})}\\)과 비교합니다.\n후보 클래스 \\(y\\)가 ‘정상’이라면? \\(\\rightarrow\\) \\(s(x, \\text{정상})\\)을 계산하고, 이를 ’정상’ 클래스의 임계값 \\(\\hat{q}^{(\\text{정상})}\\)과 비교합니다.\n\n각 클래스마다 자신만의 기준(Threshold)을 통과해야 집합에 들어갈 수 있는 것입니다.\n\n\n\n\nFigure: Class-Conditional Conformal Prediction의 개념도. Calibration 데이터를 색깔(클래스)별로 나누어 각각의 분포 \\(\\hat{q}^{(1)}, \\hat{q}^{(2)}\\)를 구한다. 추론 시에는 각 후보 클래스 \\(y\\)가 자신의 기준 \\(\\hat{q}^{(y)}\\)를 만족하는지 확인한다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-01-Evaluating-Adaptivity/index.html",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-01-Evaluating-Adaptivity/index.html",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 3.1)",
    "section": "",
    "text": "지금까지 우리는 Conformal Prediction(CP)을 통해 \\(1-\\alpha\\)의 커버리지를 보장하는 예측 집합을 만드는 법을 배웠습니다.\n하지만 “평균적으로 90% 정답을 포함한다(Marginal Coverage)”는 사실만으로는 충분하지 않습니다.\n예를 들어, 어떤 의사가 쉬운 환자에게는 100% 정확한 진단을 내리지만, 어려운 희귀병 환자에게는 0%의 정확도를 보인다면 어떨까요?\n전체 평균으로는 90% 정확도일지 몰라도, 이는 좋은 시스템이라 할 수 없습니다.\n좋은 CP 알고리즘은 쉬운 입력에는 작은 집합(Small Sets)을, 어려운 입력에는 큰 집합(Large Sets)을 출력해야 합니다. 이를 Adaptivity(적응성)라고 합니다.\n이번 포스트에서는 내 모델이 얼마나 “적응적(Adaptive)”인지 평가하는 구체적인 지표들을 알아봅니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-01-Evaluating-Adaptivity/index.html#feature-stratified-coverage-fsc",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-01-Evaluating-Adaptivity/index.html#feature-stratified-coverage-fsc",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 3.1)",
    "section": "2.1 Feature-stratified Coverage (FSC)",
    "text": "2.1 Feature-stratified Coverage (FSC)\n\n데이터의 특성(Feature)에 따라 그룹을 나누어 커버리지를 측정하는 방법입니다.\n예를 들어 인종(Race), 나이대(Age), 혹은 이미지의 밝기 등으로 데이터를 그룹화(\\(g=1, \\dots, G\\))합니다.\n각 그룹 \\(\\mathcal{I}_g\\)에 속한 데이터들의 커버리지를 계산하고, 가장 성능이 안 좋은 그룹(Minimum Coverage)을 찾습니다.\n\n\\[\n\\text{FSC metric} = \\min_{g \\in \\{1, \\dots, G\\}} \\frac{1}{|\\mathcal{I}_g|} \\sum_{i \\in \\mathcal{I}_g} \\mathbb{I}\\{ Y_i \\in \\mathcal{C}(X_i) \\}\n\\]\n\n만약 완벽한 Conditional Coverage라면, 이 값은 \\(1-\\alpha\\)에 근접해야 합니다.\n이 값이 \\(1-\\alpha\\)보다 현저히 낮다면, 특정 그룹(예: 야간 주행 이미지)에서 모델이 실패하고 있음을 의미합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-01-Evaluating-Adaptivity/index.html#size-stratified-coverage-ssc",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-01-Evaluating-Adaptivity/index.html#size-stratified-coverage-ssc",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 3.1)",
    "section": "2.2 Size-stratified Coverage (SSC)",
    "text": "2.2 Size-stratified Coverage (SSC)\n\n하지만 어떤 Feature가 중요한지 모를 때는 어떻게 할까요?\n이때 사용할 수 있는 아주 일반적이고 강력한 방법이 “예측 집합의 크기”로 그룹을 나누는 것입니다.\n\n그룹 1: 집합 크기가 1인 데이터들 (\\(\\mathcal{C}(x)| = 1\\))\n그룹 2: 집합 크기가 2인 데이터들\n…\n\n모델이 “이건 정말 어려워서 후보를 10개나 뽑았어”라고 말한 경우(집합 크기 10), 실제로도 그 안에 정답이 90% 확률로 들어 있어야 합니다.\n\n\\[\n\\text{SSC metric} = \\min_{g \\in \\{ \\text{set sizes} \\}} \\frac{1}{|\\mathcal{I}_g|} \\sum_{i \\in \\mathcal{I}_g} \\mathbb{I}\\{ Y_i \\in \\mathcal{C}(X_i) \\}\n\\]\n\n이 지표는 사용자가 사전에 그룹을 정의할 필요가 없으므로(Feature-agnostic), 어떤 상황에서도 바로 적용해볼 수 있는 훌륭한 진단 도구입니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-03-Checking-for-Correct-Coverage/index.html",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-03-Checking-for-Correct-Coverage/index.html",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 3.3)",
    "section": "",
    "text": "Conformal Prediction(CP)을 구현했다면, 가장 먼저 해야 할 일은 “이게 정말 작동하는가?”를 확인하는 것입니다.\n즉, 우리가 설정한 목표 커버리지(예: 90%)가 실제 테스트 데이터에서도 지켜지는지 검증해야 합니다.\n하지만 단순히 한 번의 테스트 셋 결과만 보고 “90.1%니까 성공!”이라고 단정 짓기는 어렵습니다.\n데이터의 무작위성 때문에 우연히 잘 나왔을 수도, 우연히 못 나왔을 수도 있기 때문입니다.\n따라서 우리는 여러 번의 실험(Trials)을 통해 커버리지 분포를 확인해야 합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-03-Checking-for-Correct-Coverage/index.html#efficiency-trick-score-caching",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-03-Checking-for-Correct-Coverage/index.html#efficiency-trick-score-caching",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 3.3)",
    "section": "Efficiency Trick: Score Caching",
    "text": "Efficiency Trick: Score Caching\n\n하지만 \\(R\\)번(예: 100번)이나 모델을 다시 학습시키거나 추론(Inference)을 돌리는 것은 계산 비용이 매우 큽니다.\n여기서 중요한 팁은 Conformal Score를 미리 계산해두는 것(Caching)입니다.\nCP 알고리즘은 Score값(\\(s_i\\))들의 순위에만 의존합니다.\n데이터가 어느 셋(Calibration vs Validation)에 속하느냐에 따라 역할만 달라질 뿐, 각 데이터 포인트의 Score 값 자체는 변하지 않습니다.\n따라서 다음과 같이 효율적으로 검증할 수 있습니다:\n\n\nPre-computation: 전체 데이터에 대해 Score를 미리 한 번만 계산합니다.\n\n\nShuffle & Split: 계산된 Score 배열만 무작위로 섞어서 나눕니다.\n\n\nEvaluate: 나누어진 Score들로 Quantile을 구하고 커버리지를 계산합니다.\n\n\n이 방식을 사용하면 딥러닝 모델을 매번 돌릴 필요가 없어 검증 속도가 수백 배 빨라집니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-03-Checking-for-Correct-Coverage/index.html#code-explanation",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-03-Checking-for-Correct-Coverage/index.html#code-explanation",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 3.3)",
    "section": "Code Explanation",
    "text": "Code Explanation\n\n\nLoad/Compute Scores: get_scores(X, Y)를 통해 모든 데이터의 Score를 계산하고 저장합니다.\n\n\nLoop \\(R\\) times:\n\n\nnp.random.shuffle(scores): Score들을 섞습니다.\ncalib, val = scores[:n], scores[n:]: \\(n\\)개는 Calibration용, 나머지는 검증용으로 나눕니다.\nqhat: Calibration Score들로 Quantile을 계산합니다.\nmean(): Validation Score들이 qhat보다 작은 비율(Coverage)을 계산합니다.\n\n\nCheck: coverages.mean()이 \\(1-\\alpha\\)와 비슷한지 확인하고, 히스토그램을 그립니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-03/index.html",
    "href": "posts/lecture/L08/causal-inference-08-part-03/index.html",
    "title": "[Causal Inference] 08. Partial Identification (Part 3)",
    "section": "",
    "text": "지난 포스트들에서 우리는 Natural Bounds와 도구 변수(IV)를 활용한 식별 범위 추정에 대해 알아보았습니다.\n이번 포스트에서는 Partial Identification 시리즈의 마지막으로, Backdoor 기준을 만족하는 변수들이 부분적으로만 관측될 때(Partially-observed) 어떻게 인과 효과의 범위를 구할 수 있는지 살펴봅니다.\n이는 데이터가 서로 다른 소스에서 수집되어 결합 분포(Joint Distribution)를 완전히 알 수 없는 현실적인 상황(예: \\(X, Y\\) 데이터와 \\(U\\) 데이터가 따로 있을 때)에서 매우 유용한 접근법입니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-03/index.html#목표-식-재구성",
    "href": "posts/lecture/L08/causal-inference-08-part-03/index.html#목표-식-재구성",
    "title": "[Causal Inference] 08. Partial Identification (Part 3)",
    "section": "4.1 목표 식 재구성",
    "text": "4.1 목표 식 재구성\n\nBackdoor 공식을 조건부 확률 정의에 따라 풀어쓰면 다음과 같습니다.\n\n\\[\n\\begin{aligned}\nP(y|do(x)) &= \\sum_{w, u} P(y|x, w, u)P(w, u) \\\\\n&= \\sum_{w, u} \\frac{P(x, y, w, u)P(w, u)}{P(x, w, u)}\n\\end{aligned}\n\\]\n\n이 식의 구성 요소들을 각각 미지수로 정의하여 최적화 문제를 설계합니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-03/index.html#파라미터-정의",
    "href": "posts/lecture/L08/causal-inference-08-part-03/index.html#파라미터-정의",
    "title": "[Causal Inference] 08. Partial Identification (Part 3)",
    "section": "4.2 파라미터 정의",
    "text": "4.2 파라미터 정의\n\n각 \\((w, u)\\) 조합에 대해 다음 세 가지 변수를 정의합니다.\n\n\n\\(a_{w,u} = P(x, y, w, u)\\): 전체 결합 확률의 일부\n\n\n\\(b_{w,u} = P(w, u)\\): 교란 변수들의 결합 확률\n\n\n\\(c_{w,u} = P(x, w, u)\\): 처치와 교란 변수들의 결합 확률\n\n\n이제 우리의 목표 함수(Objective Function)는 다음과 같습니다.\n\n\\[\n\\text{min / max } \\sum_{w, u} \\frac{a_{w,u} \\cdot b_{w,u}}{c_{w,u}}\n\\]"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-03/index.html#제약-조건-constraints",
    "href": "posts/lecture/L08/causal-inference-08-part-03/index.html#제약-조건-constraints",
    "title": "[Causal Inference] 08. Partial Identification (Part 3)",
    "section": "4.3 제약 조건 (Constraints)",
    "text": "4.3 제약 조건 (Constraints)\n\n우리가 관측한 데이터(\\(P(X,Y,W)\\)와 \\(P(U)\\))는 이 미지수들의 합으로 표현되어야 합니다. 이것이 최적화 문제의 제약 조건이 됩니다.\n\n관측 데이터와의 일치:\n\n\n\\(\\sum_u a_{w,u} = P(x, y, w)\\)\n\\(\\sum_u b_{w,u} = P(w)\\)\n\\(\\sum_u c_{w,u} = P(x, w)\\)\n\n\n확률의 기본 성질 (Fréchet Inequalities):\n\n\n\\(P(w, u) = \\sum_x P(x, w, u) = \\sum_x \\sum_y P(x, y, w, u)\\)이므로 \\[b_{w, u} \\ge c_{w,u} \\ge a_{w, u}\\]\n결합 확률은 개별 확률보다 클 수 없고, 합집합 확률보다 작을 수 없다는 성질을 이용해 각 파라미터의 범위를 제한합니다.\n\\(a_{w,u} = P(x, y, w, u)\\)의 경우, \\[\\max\\{0, P(x, y, w) + P(u) - 1\\} \\le a_{w,u} \\le \\min\\{P(x, y, w), P(u)\\}\\]\n\\(b_{w,u} = P(w, u)\\)의 경우, \\[\\max\\{0, P(w) + P(u) - 1\\} \\le b_{w,u} \\le \\min\\{P(w), P(u)\\}\\]\n\\(c_{w, u} = P(x, w, u)\\)의 경우, \\[\\max\\{0, P(x, w) + P(u) - 1\\} \\le c_{w,u} \\le \\min\\{P(x, w), P(u)\\}\\]\n\n이러한 제약 조건 하에서 목표 함수를 최적화하면, Natural Bounds보다 좁은 범위(Valid Bounds)를 얻을 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-03/index.html#요약",
    "href": "posts/lecture/L08/causal-inference-08-part-03/index.html#요약",
    "title": "[Causal Inference] 08. Partial Identification (Part 3)",
    "section": "5.1 요약",
    "text": "5.1 요약\n\n\nNatural Bounds: 그래프 구조에 대한 최소한의 가정만으로 구하는 가장 넓은 범위.\n\n\nCanonical Type Model (IV): 도구 변수가 있을 때, 비관측 변수 \\(U\\)를 유한한 반응 유형(Response Types)으로 나누어 선형 계획법(LP)으로 해결.\n\n\nPartially-observed Covariates: 데이터가 파편화되어 있을 때, 확률 분포의 제약 조건을 이용한 최적화 문제로 해결."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-03/index.html#추가적인-연구-주제들",
    "href": "posts/lecture/L08/causal-inference-08-part-03/index.html#추가적인-연구-주제들",
    "title": "[Causal Inference] 08. Partial Identification (Part 3)",
    "section": "5.2 추가적인 연구 주제들",
    "text": "5.2 추가적인 연구 주제들\n\nPartial Identification은 여전히 활발히 연구되고 있는 분야입니다. 더 깊이 있는 학습을 위해 다음 논문들을 참고할 수 있습니다.\n\n\n연속 변수(Continuous variables)에서의 Bound: Zhang and Bareinboim (2022)\n\n\nHigh Dimensional Data: Li and Pearl (2022)\n\n\n비순응(Non-Compliance) 분석: Balke and Pearl (1997), Chickering and Pearl (1996)\n\n\nNote: 더 복잡한 구조(예: 또 다른 Canonical Type Model)에서도 유사한 방식의 접근이 가능합니다.\n\n\n식별 불가능하다고 해서 분석을 멈추는 것이 아니라, “데이터가 허용하는 한계 내에서 최선의 정보”를 뽑아내는 것이 바로 Partial Identification의 핵심입니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-01/index.html",
    "href": "posts/lecture/L08/causal-inference-08-part-01/index.html",
    "title": "[Causal Inference] 08. Partial Identification (Part 1)",
    "section": "",
    "text": "이전까지 우리는 인과 효과 \\(P(y|do(x))\\)를 관측 데이터 \\(P(v)\\)로부터 정확한 하나의 값(Point estimate)으로 계산할 수 있는지, 즉 식별 가능성(Identifiability)을 따졌습니다.\n하지만 현실의 많은 문제에서는 그래프 구조상 식별이 불가능한 경우(Non-identifiable)가 많습니다.\n이때 우리는 포기하는 대신 “그렇다면 인과 효과가 존재할 수 있는 범위(Bound)라도 알 수 없을까?”라는 질문을 던지게 됩니다.\n이것이 바로 부분 식별(Partial Identification) 문제입니다.\n\n\n\n\nFigure 1: Identification Process Flowchart. 식별 엔진이 ’No’를 반환했을 때, 구간 [a, b]를 찾는 과정으로 넘어가는 흐름도.\n\n\n\nNote: 식별 불가능(No) 판정이 났을 때, 우리는 0과 1 사이의 어딘가에 존재하는 구간 \\([a(y;x), b(y;x)]\\)를 찾게 됩니다. *"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-01/index.html#문제-설정",
    "href": "posts/lecture/L08/causal-inference-08-part-01/index.html#문제-설정",
    "title": "[Causal Inference] 08. Partial Identification (Part 1)",
    "section": "3.1 문제 설정",
    "text": "3.1 문제 설정\n다음과 같이 \\(X\\)와 \\(Y\\) 사이에 비관측 교란 변수 \\(U\\)가 존재하는 가장 일반적인 그래프를 가정해 봅시다.\n\n\n\nFigure 2: Basic Confounded Graph. X와 Y가 U에 의해 교란된 구조.\n\n\n\n우리의 목표는 \\(P(x, y)\\)가 주어졌을 때, \\(P(y|do(x))\\)의 범위를 구하는 것입니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-01/index.html#theorem",
    "href": "posts/lecture/L08/causal-inference-08-part-01/index.html#theorem",
    "title": "[Causal Inference] 08. Partial Identification (Part 1)",
    "section": "3.2 Theorem",
    "text": "3.2 Theorem\n\n관측 분포 \\(P(x, y)\\)가 주어졌을 때, 인과 효과 \\(P(y|do(x))\\)는 다음 구간 안에 존재합니다.\n\n\\[\nP(y, x) \\le P(y|do(x)) \\le P(y, x) + 1 - P(x)\n\\]\n\n하한 (Lower Bound): \\(a(y;x) = P(y, x)\\)\n상한 (Upper Bound): \\(b(y;x) = P(y, x) + 1 - P(x)\\)\n\n직관적 해석\n\n이 수식은 데이터를 통해 “확실히 아는 것”과 “모르는 것”을 구분하는 것으로 이해할 수 있습니다.\n우리가 \\(do(x)\\)를 했을 때, 원래 자연스럽게 \\(X=x\\)를 선택했던 사람들은 관측 데이터 \\(P(y, x)\\)와 똑같이 행동할 것입니다. 이는 최소한 보장되는 비율입니다 (하한).\n반면, 원래 \\(X \\ne x\\)였던 사람들(처치를 받지 않은 비율 \\(P(x')\\))이 강제로 처치를 받았을 때 어떻게 행동할지는 데이터로 알 수 없습니다.\n상한의 논리: “처치 받지 않은 비율(\\(P(x')\\))에 속하는 사람들이 강제로 처치를 받았을 때, 모두가 \\(Y=y\\)로 변화한다(성공한다)”고 가장 긍정적으로 가정하면 최댓값이 됩니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-01/index.html#유도-과정-derivation",
    "href": "posts/lecture/L08/causal-inference-08-part-01/index.html#유도-과정-derivation",
    "title": "[Causal Inference] 08. Partial Identification (Part 1)",
    "section": "3.3 유도 과정 (Derivation)",
    "text": "3.3 유도 과정 (Derivation)\n\n왜 저런 범위가 나오는지 수식으로 살펴봅시다. 구조적 인과 모델(SCM)에서 \\(P(y|do(x))\\)는 다음과 같이 정의됩니다.\n\n\\[\nP(y|do(x)) = \\sum_u P(y|x, u)P(u)\n\\]\n\n확률의 성질을 이용하여 \\(P(u)\\)를 두 부분으로 나눌 수 있습니다: \\(P(u) = P(u, x) + \\{P(u) - P(u, x)\\}\\). 이를 식에 대입하면:\n\n\\[\n\\begin{aligned}\nP(y|do(x)) &= \\sum_u P(y|x, u) [P(u, x) + \\{P(u) - P(u, x)\\}] \\\\\n&= \\underbrace{\\sum_u P(y|x, u)P(u, x)}_{\\text{Part A}} + \\underbrace{\\sum_u P(y|x, u)\\{P(u) - P(u, x)\\}}_{\\text{Part B}}\n\\end{aligned}\n\\]\n\n여기서 Part A를 정리하면:\n\n\\[\n\\text{Part A} = \\sum_u P(y|x, u)P(x|u)P(u) = \\sum_u P(y, x, u) = P(y, x)\n\\]\n\n즉, Part A는 우리가 관측 가능한 데이터 \\(P(y, x)\\)와 같습니다. 이제 Part B 때문에 범위가 생깁니다.\n\n\n3.3.1 하한 (Lower Bound) 유도\n\n\\(P(y|x, u)\\)는 확률이므로 \\(0 \\le P(y|x, u) \\le 1\\).\n\\(P(u) = \\sum_x P(u, x)\\)이므로 \\(P(u) \\ge P(u, x)\\).\n\n\\[\n\\begin{aligned}\nP(y|do(x)) &= \\sum_u P(y|x, u)P(u, x) + \\sum_u P(y|x, u)\\{P(u) - P(u, x)\\} \\\\\n&= P(y,x) + \\sum_u P(y|x, u)\\{P(u) - P(u, x)\\} \\\\\n&\\ge P(y, x) + 0 = P(y, x) \\\\\n\\end{aligned}\n\\]\n\n\n3.3.2 상한 (Upper Bound) 유도\n\n\\(P(y|x, u)\\)는 확률이므로 \\(0 \\le P(y|x, u) \\le 1\\).\n\nPart B의 조건부 확률이 모두 1일 때 전체 값은 최대가 됩니다. \\[\n\\begin{aligned}\nP(y|do(x)) &= \\sum_u P(y|x, u)P(u, x) + \\sum_u P(y|x, u)\\{P(u) - P(u, x)\\} \\\\\n&= P(y,x) + \\sum_u P(y|x, u)\\{P(u) - P(u, x)\\} \\\\\n&\\le P(y, x) + \\sum_u \\{P(u) - P(u, x)\\} \\\\\n&= P(y, x) + 1 - P(x)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-01/index.html#범위의-타당성-증명-tightness",
    "href": "posts/lecture/L08/causal-inference-08-part-01/index.html#범위의-타당성-증명-tightness",
    "title": "[Causal Inference] 08. Partial Identification (Part 1)",
    "section": "3.4 범위의 타당성 증명 (Tightness)",
    "text": "3.4 범위의 타당성 증명 (Tightness)\n\n구한 범위 \\([P(y, x), P(y, x) + 1 - P(x)]\\)가 Tight하다는 것은, 추가적인 가정 없이는 이 범위를 더 좁힐 수 없음을 의미합니다.\n이를 증명하기 위해, 관측 데이터 \\(P(x, y)\\)와 완벽히 일치하면서(Compatible), 인과 효과가 각각 하한값과 상한값을 갖는 두 개의 가상 모델(\\(M^{(1)}, M^{(2)}\\))을 만들어낼 수 있음을 보이면 됩니다.\n\n\n3.4.1 모델 설계 전략\n\n두 모델 모두 \\(U \\sim P(u)\\)와 \\(X \\leftarrow f_X(u)\\)는 동일하게 두고, \\(Y\\)를 결정하는 함수 \\(f_Y(x, u)\\)만 다르게 설정합니다.\n\n\\[\nf_Y(x, u) =\n\\begin{cases}\nf_Y^{\\text{observation}}(x, u) & \\text{if } x = f_X(u) \\quad \\text{(관측된 경우)} \\\\\nf_Y^{\\text{counterfactual}}(x, u) & \\text{if } x \\ne f_X(u) \\quad \\text{(반사실적 경우)}\n\\end{cases}\n\\]\n\n\n3.4.2 Case 분류\n\n우리는 상황을 두 가지 케이스로 나눌 수 있습니다.\n\nCase 1 (Observation): \\(x = f_X(u)\\).\n\n즉, 개인이 원래 \\(x\\)를 선택하려던 경우입니다.\n이 경우 모델은 관측 데이터와 일치해야 하므로 선택의 여지가 없습니다.\n\nCase 2 (Counterfactual): \\(x \\ne f_X(u)\\).\n\n즉, 원래 다른 것을 하려던 사람에게 억지로 \\(x\\)를 시킬 때입니다.\n이 부분은 데이터로 관측되지 않으므로, 우리가 임의로 0(실패) 또는 1(성공)을 부여하여 범위를 만듭니다.\n\n\n\n\n\n3.4.3 두 모델의 구성\n\n모델 \\(\\mathcal{M}_x^{(1)}\\) (하한 모델):\n\nCase 2일 때 무조건 \\(Y=0\\)을 출력하게 설정합니다.\n인과 효과: \\(P^{(1)}(y=1|do(x)) = P(y=1, x) + 0 = \\text{Lower Bound}\\)\n\n모델 \\(\\mathcal{M}_x^{(2)}\\) (상한 모델):\n\nCase 2일 때 무조건 \\(Y=1\\)을 출력하게 설정합니다.\n인과 효과: \\(P^{(2)}(y=1|do(x)) = P(y=1, x) + 1- P(x) = \\text{Upper Bound}\\)\n\n\n\n두 모델 모두 관측 상황(Case 1)에서는 동일하게 작동하므로 \\(P(x, y)\\) 분포는 같습니다.\n하지만 \\(do(x)\\) 개입 시(Case 2), \\(U\\)와 \\(X\\)가 일치할 필요가 없으므로 \\(\\mathcal{M}_x^{(1)}\\)와 \\(\\mathcal{M}_x^{(2)}\\)가 \\(Y = 1\\) 일 때, 다른 확률을 가질 수 있습니다.\n\n\\[\n\\begin{aligned}\nP^{(i)}(Y = 1|do(x)) &= \\sum_{u} P^{(i)}(Y = 1|do(x), u)P(u|do(x)) \\\\\n&= \\sum_{u} P^{(i)}(Y = 1|x, u)P(u) && \\because \\text{Rule 2, Rule 3}\\\\\n&= P^{(i)}(Y = 1|x, f_X(U) = x)P(f_X(U) = x) \\\\\n&\\quad + P^{(i)}(Y = 1|x, f_X(U) \\neq x)P(f_X(U) \\neq x) \\\\\n&= P^{(i)}(Y = 1|x)P(x) + \\mathbf{1}[i = 2]\\{1 - P(x)\\} \\\\\n&= P^{(i)}(x, Y = 1) + \\mathbf{1}[i = 2](1 - P(x))\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\nP^{(1)}(Y = 1|do(x)) &= a(y;x) = P(y = 1, x) \\quad \\text{while} \\\\\nP^{(2)}(Y = 1|do(x)) &= b(y;x) = P(y = 1, x) + 1 - P(x)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-03/index.html",
    "href": "posts/lecture/L13/causal-inference-13-part-03/index.html",
    "title": "[Causal Inference] 13. IV (Part 3)",
    "section": "",
    "text": "데이터를 다루다 보면 선형(Linear) 모델로는 설명하기 힘든 복잡한 인과관계를 마주하게 됩니다.\n전통적인 2단계 최소제곱법(2SLS)은 강력한 도구이지만, 다음과 같은 한계가 있습니다.\n\n\n처치(Treatment)와 결과(Outcome)의 관계를 선형으로 가정합니다.\n\n\n공변량(Covariate)과 처치 변수 간의 복잡한 상호작용을 포착하기 어렵습니다.\n\n\n이번 포스트에서는 Hartford et al.(2017)이 제안한 Deep IV 방법론을 소개하고, 가격(\\(P\\))과 판매량(\\(Y\\))의 비선형적 관계를 시뮬레이션 데이터를 통해 추정해보겠습니다.\n\n\n\n\n우리가 해결하고자 하는 인과추론 문제는 다음과 같은 구조적 방정식(Structural Equation)으로 정의됩니다.\n\n\\[Y = g(P, X) + \\epsilon\\]\n\n이 수식이 실제 현실에서 어떤 의미를 갖는지, 논문에서 제시한 항공권 가격 결정 시나리오를 통해 살펴보겠습니다.\n\n\n\n\n\n항공사가 티켓 가격(\\(P\\))을 책정하고 그에 따른 판매량(\\(Y\\))을 분석한다고 가정해 봅시다.\n우리의 목표는 “가격을 올렸을 때 판매량이 실제로 얼마나 줄어드는가?”(인과 효과)를 알아내는 것입니다.\n하지만 단순히 데이터를 관찰하면 내생성(Endogeneity) 문제로 인해 잘못된 결론에 도달하게 됩니다.\n교란 변수 (\\(E\\), Confounder):\n\n예를 들어 ‘비즈니스 컨퍼런스’나 ’휴가철’ 같은 수요 급증 요인이 있다고 합시다.\n이 요인은 가격(\\(P\\))을 높이게 만들고(항공사가 가격을 올림), 동시에 판매량(\\(Y\\))도 높입니다(사람들이 비싸도 삼).\n그 결과, 데이터상으로는 “가격이 비싼데도 판매량이 높네?”라는 양의 상관관계가 나타나, 가격의 부정적 효과를 과소평가하게 됩니다.\n\n이 고리를 끊기 위해 우리는 도구 변수 (\\(Z\\), Instrument)를 도입합니다.\n\n\n\n\nFigure: Causal Graph (DAG) 인과 관계를 도식화하면 다음과 같습니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-03/index.html#the-problem-formulation",
    "href": "posts/lecture/L13/causal-inference-13-part-03/index.html#the-problem-formulation",
    "title": "[Causal Inference] 13. IV (Part 3)",
    "section": "",
    "text": "우리가 해결하고자 하는 인과추론 문제는 다음과 같은 구조적 방정식(Structural Equation)으로 정의됩니다.\n\n\\[Y = g(P, X) + \\epsilon\\]\n\n이 수식이 실제 현실에서 어떤 의미를 갖는지, 논문에서 제시한 항공권 가격 결정 시나리오를 통해 살펴보겠습니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-03/index.html#motivating-example-airline-ticket-pricing",
    "href": "posts/lecture/L13/causal-inference-13-part-03/index.html#motivating-example-airline-ticket-pricing",
    "title": "[Causal Inference] 13. IV (Part 3)",
    "section": "",
    "text": "항공사가 티켓 가격(\\(P\\))을 책정하고 그에 따른 판매량(\\(Y\\))을 분석한다고 가정해 봅시다.\n우리의 목표는 “가격을 올렸을 때 판매량이 실제로 얼마나 줄어드는가?”(인과 효과)를 알아내는 것입니다.\n하지만 단순히 데이터를 관찰하면 내생성(Endogeneity) 문제로 인해 잘못된 결론에 도달하게 됩니다.\n교란 변수 (\\(E\\), Confounder):\n\n예를 들어 ‘비즈니스 컨퍼런스’나 ’휴가철’ 같은 수요 급증 요인이 있다고 합시다.\n이 요인은 가격(\\(P\\))을 높이게 만들고(항공사가 가격을 올림), 동시에 판매량(\\(Y\\))도 높입니다(사람들이 비싸도 삼).\n그 결과, 데이터상으로는 “가격이 비싼데도 판매량이 높네?”라는 양의 상관관계가 나타나, 가격의 부정적 효과를 과소평가하게 됩니다.\n\n이 고리를 끊기 위해 우리는 도구 변수 (\\(Z\\), Instrument)를 도입합니다.\n\n\n\n\nFigure: Causal Graph (DAG) 인과 관계를 도식화하면 다음과 같습니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-03/index.html#mathematical-intuition-why-two-stages",
    "href": "posts/lecture/L13/causal-inference-13-part-03/index.html#mathematical-intuition-why-two-stages",
    "title": "[Causal Inference] 13. IV (Part 3)",
    "section": "Mathematical Intuition: Why Two Stages?",
    "text": "Mathematical Intuition: Why Two Stages?\n\n우리의 목표는 인과 함수 \\(g(P, X)\\)를 찾는 것입니다.\n하지만 앞서 보았듯 \\(Y = g(P, X) + \\epsilon\\) 식에서 바로 회귀분석을 할 수 없습니다.\n오차항 \\(\\epsilon\\)이 \\(P\\)와 상관관계가 있기 때문입니다.\n이 문제를 해결하기 위해, 우리는 식의 양변에 도구 변수 \\(Z\\)와 공변량 \\(X\\)에 대한 조건부 기댓값(Conditional Expectation)을 취합니다.\n\n\\[E[Y | X, Z] = E[g(P, X) + \\epsilon | X, Z]\\]\n\n기댓값의 선형성(Linearity)에 의해 우변을 분리할 수 있습니다.\n\n\\[E[Y | X, Z] = E[g(P, X) | X, Z] + \\underbrace{E[\\epsilon | X, Z]}_{= 0}\\]\n\n도구 변수의 정의(외생성)에 의해, 도구 변수는 오차항과 공변량이 주어진 경우 독립입니다.\n따라서 \\(z \\perp \\epsilon | x \\Longrightarrow E[\\epsilon | X, Z] = 0\\)이 되어 오차항이 사라집니다.\n이제 남은 식을 적분 형태로 풀어서 쓰면 다음과 같습니다.\n\n\\[E[Y | X, Z] = \\int g(p, x) dF(p | x, z)\\]\n\n이 식은 Deep IV 모델의 청사진이 됩니다.\n\n\n\\(F(p | x, z)\\): 우변의 적분을 계산하려면, \\(Z\\)와 \\(X\\)가 주어졌을 때 \\(P\\)가 어떻게 분포하는지 알아야 합니다. \\(\\rightarrow\\) Stage 1 (Treatment Network)\n\n\n\\(g(p, x)\\): 위 등식을 만족시키는 미지의 함수 \\(g\\)를 찾아야 합니다. \\(\\rightarrow\\) Stage 2 (Outcome Network)\n\n\n결국 Deep IV는 “1단계에서 추정한 분포(\\(F\\))를 이용해 2단계 함수(\\(g\\))를 적분했을 때, 그 결과가 실제 관측된 \\(Y\\)의 평균과 일치하도록” 학습하는 과정입니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-03/index.html#stage-1-mixture-density-network-mdn",
    "href": "posts/lecture/L13/causal-inference-13-part-03/index.html#stage-1-mixture-density-network-mdn",
    "title": "[Causal Inference] 13. IV (Part 3)",
    "section": "Stage 1: Mixture Density Network (MDN)",
    "text": "Stage 1: Mixture Density Network (MDN)\n\nDeep IV의 첫 번째 단계는 ’Treatment Network’를 구축하는 것입니다.\n이 단계의 핵심은 전통적인 방식과의 차이점을 이해하는 데 있습니다.\n\n\n1.1. Why Density Estimation? (Point vs. Distribution)\n\n전통적인 Linear 2SLS 1단계에서는 도구변수(\\(Z\\))와 공변량(\\(X\\))을 사용하여 처치 변수의 평균(Mean)을 예측합니다. \\[\\hat{P}_{2SLS} = E[P | Z, X] \\approx \\alpha Z + \\beta X\\]\n이는 \\(P\\)와 \\(Z\\)의 관계가 선형적이고, 오차가 등분산(Homoscedastic)을 가진다는 강력한 가정을 전제로 합니다.\n하지만 논문(Hartford et al., 2017)에서는 현실 데이터가 이보다 훨씬 복잡하다고 지적합니다.\n가격(\\(P\\)) 결정 과정은 다봉형(Multimodal)일 수도 있고, 시기(\\(X\\))에 따라 변동성(Variance)이 달라질 수도 있습니다.\n따라서 단순한 평균값 하나로는 정보 손실이 발생합니다.\nDeep IV의 1단계 목표는 \\(P\\)의 값을 하나로 예측하는 것이 아니라, \\(Z\\)와 \\(X\\)가 주어졌을 때 \\(P\\)가 가질 수 있는 조건부 확률 분포(Conditional Probability Distribution) 전체를 추정하는 것입니다.\n\n\n\n1.2. The Mixture Density Network (MDN)\n\n복잡한 분포를 유연하게 추정하기 위해, Deep IV는 MDN(Mixture Density Network) 구조를 사용합니다.\n이는 신경망의 출력을 이용해 가우시안 혼합 모델(Gaussian Mixture Model, GMM)의 파라미터를 구성하는 방식입니다.\n\n\\[\\hat{F}(p|z,x) = \\sum_{k=1}^{K} \\pi_k(z,x) \\mathcal{N}(p ; \\mu_k(z,x), \\sigma_k^2(z,x))\\]\n\n이 수식의 의미는 다음과 같습니다.\n\\(\\mathcal{N}\\) (Normal Distribution): \\(K\\)개의 정규분포를 섞어서 복잡한 분포를 표현합니다.\n신경망의 역할: 입력(\\(Z, X\\))을 받아 각 정규분포의 파라미터 3가지를 출력합니다.\n\n\\(\\pi_k\\) (Mixing Coefficient): \\(k\\)번째 정규분포가 선택될 확률 (가중치, \\(\\sum \\pi_k = 1\\))\n\\(\\mu_k\\) (Mean): \\(k\\)번째 정규분포의 중심 (평균)\n\\(\\sigma_k\\) (Standard Deviation): \\(k\\)번째 정규분포의 퍼짐 정도 (분산)\n\n\n\n\n1.3. Deep IV Architecture: Treatment Network\n\n논문에서 제시하는 네트워크 구조를 도식화하면 다음과 같습니다.\n\n\nInput: 도구변수(\\(Z\\))와 공변량(\\(X\\))이 신경망에 들어갑니다.\n\n\nHidden Layers: 데이터의 비선형적인 패턴을 학습합니다.\n\n\nOutput Heads: 마지막 층은 세 갈래로 나뉩니다.\n\n\nSoftmax \\(\\rightarrow\\) \\(\\pi\\) (가중치)\nLinear \\(\\rightarrow\\) \\(\\mu\\) (평균)\nSoftplus \\(\\rightarrow\\) \\(\\sigma\\) (표준편차, 양수 제약)\n\n\n\n\n\nCode\nclass FirstStageMDN(nn.Module):\n    def __init__(self, input_dim, num_gaussians=5):\n        super().__init__()\n        self.shared_layer = nn.Sequential(\n            nn.Linear(input_dim, 64),\n            nn.ReLU(),\n            nn.Linear(64, 64),\n            nn.ReLU()\n        )\n        self.pi_head = nn.Linear(64, num_gaussians)     # 혼합 계수\n        self.mu_head = nn.Linear(64, num_gaussians)     # 평균\n        self.sigma_head = nn.Linear(64, num_gaussians)  # 표준편차\n\n    def forward(self, x, z):\n        # 1. 입력 결합\n        # Shape: (Batch, x_dim) + (Batch, z_dim) -&gt; (Batch, input_dim)\n        inputs = torch.cat([x, z], dim=1)\n        \n        # 2. 특징 추출\n        # Shape: (Batch, input_dim) -&gt; (Batch, 64)\n        features = self.shared_layer(inputs)\n        \n        # 3. 파라미터 추정 (K=num_gaussians)\n        # Pi: (Batch, K)\n        pi = F.softmax(self.pi_head(features), dim=1)\n        # Mu: (Batch, K)\n        mu = self.mu_head(features)\n        # Sigma: (Batch, K)\n        sigma = F.softplus(self.sigma_head(features)) + 1e-5\n        \n        return pi, mu, sigma\n\n    def sample(self, pi, mu, sigma, n_samples=1):\n        mix = D.Categorical(probs=pi)\n        comp = D.Normal(loc=mu, scale=sigma)\n        gmm = D.MixtureSameFamily(mix, comp)\n        \n        # 샘플링 수행\n        if n_samples == 1:\n            # Shape: (Batch) -&gt; (Batch, 1)\n            return gmm.sample().unsqueeze(-1)\n        else:\n            # Shape: (n_samples, Batch) -&gt; (Batch, n_samples)\n            return gmm.sample((n_samples,)).permute(1, 0)\n\n\n\n\n1.4. Optimization Objective (Negative Log-Likelihood)\n\n이 신경망을 학습시키기 위해 사용하는 손실 함수는 음의 로그 우도(Negative Log-Likelihood, NLL)입니다.\n\n\\[\\mathcal{L}_1(\\phi) = - \\sum_{i=1}^{N} \\log \\left( \\sum_{k=1}^{K} \\pi_k(z_i, x_i) \\cdot \\frac{1}{\\sqrt{2\\pi}\\sigma_k(z_i, x_i)} \\exp \\left( -\\frac{(p_i - \\mu_k(z_i, x_i))^2}{2\\sigma_k^2(z_i, x_i)} \\right) \\right)\\]\n\n쉽게 말해, “실제 관측된 가격 데이터(\\(p_i\\))가 우리 모델의 확률 분포에서 등장할 확률을 최대화하라”는 뜻입니다.\n이를 통해 신경망은 데이터가 뭉쳐 있는 곳(Mode)과 퍼져 있는 정도(Variance)를 정확하게 학습하게 됩니다.\n\n\n\nCode\ndef first_stage_loss_fn(pi, mu, sigma, p):\n    # 1. 로그 확률 밀도 계산 (Log Probability)\n    # Shape: (Batch, K)\n    m = D.Normal(loc=mu, scale=sigma)\n    log_probs_component = m.log_prob(p)\n    \n    # 2. 가중치 반영 및 Log-Sum-Exp\n    # Shape: (Batch, K) -&gt; (Batch,)\n    weighted_log_probs = torch.log(pi + 1e-8) + log_probs_component\n    log_likelihood = torch.logsumexp(weighted_log_probs, dim=1)\n    \n    # 3. NLL 평균 (Scalar)\n    return -torch.mean(log_likelihood)"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-03/index.html#stage-2-outcome-network",
    "href": "posts/lecture/L13/causal-inference-13-part-03/index.html#stage-2-outcome-network",
    "title": "[Causal Inference] 13. IV (Part 3)",
    "section": "Stage 2: Outcome Network",
    "text": "Stage 2: Outcome Network\n\n1단계에서 우리는 가격(\\(P\\))이 형성되는 확률 분포 \\(\\hat{F}(P|Z,X)\\)를 얻었습니다.\n이제 두 번째 단계에서는 이를 바탕으로 진짜 인과 함수(Causal Function) \\(g(P, X)\\)를 찾아낼 차례입니다.\n\n\n2.1. The Structural Equation\n\n우리의 목표는 다음 식을 만족하는 함수 \\(g\\)를 찾는 것입니다.\n\n\\[E[Y | Z, X] = \\int g(p, x) dF(p | z, x)\\]\n\n이 식은 “도구변수(\\(Z\\))와 공변량(\\(X\\))이 주어졌을 때, 예상되는 판매량(\\(Y\\))의 평균은, 가능한 모든 가격(\\(p\\))에 대해 해당 가격일 확률과 그 때의 판매량을 곱해서 더한(적분한) 것과 같다”는 의미입니다.\n여기서 중요한 점은 우리가 1단계 모델(MDN)을 통해 분포 \\(F\\)를 이미 알고 있다는 것입니다.\n따라서 남은 미지수인 함수 \\(g\\)를 신경망으로 근사할 수 있습니다.\n\n\n\n2.2. The Loss Function (Inverse Problem)\n\n2단계 신경망(Outcome Network)을 학습시키기 위한 손실 함수는 다음과 같이 정의됩니다. \\[L(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} \\left( y_i - \\int g_{\\theta}(p, x_i) d\\hat{F}_{\\phi}(p | z_i, x_i) \\right)^2\\]\n\n\\(y_i\\): 실제 관측된 결과 (Target)\n\\(\\int g_{\\theta} d\\hat{F}_{\\phi}\\): 1단계 모델의 분포를 반영한 예측값 (Prediction)\n\n이 손실 함수의 핵심 아이디어는 “내생성이 있는 개별 \\(P\\)값 하나를 믿는 대신, 1단계 모델이 예측한 \\(P\\)의 ’분포 전체’를 믿겠다”는 것입니다.\n분포를 적분하여 얻은 기댓값이 실제 \\(Y\\)와 일치하도록 강제함으로써, 오차항(\\(\\epsilon\\))의 영향을 상쇄시킵니다.\n\n\n\n2.3. Deep IV Architecture: Outcome Network\n\n2단계 네트워크의 작동 방식은 다음과 같습니다.\n\n\nInput: 1단계 분포에서 샘플링된 \\(\\hat{P}\\)와 공변량 \\(X\\)를 입력받습니다.\n\n\nHidden Layers: 인과 함수 \\(g(P,X)\\)의 형태(예: 비선형 S자 곡선)를 학습합니다.\n\n\nOutput: 예측된 \\(Y\\)값을 출력합니다.\n\n\n\n\n\nCode\nclass SecondStageH(nn.Module):\n    def __init__(self, x_dim, p_dim=1, output_dim=1):\n        super().__init__()\n        input_dim = x_dim + p_dim\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, 128),\n            nn.ReLU(),\n            nn.Linear(128, 128),\n            nn.ReLU(),\n            nn.Linear(128, output_dim)\n        )\n        \n    def forward(self, p, x):\n        # 입력 결합\n        # Shape: (Batch, S, p_dim) + (Batch, S, x_dim) -&gt; (Batch, S, input_dim)\n        inputs = torch.cat([p, x], dim=-1) \n        return self.net(inputs)\n\n\n\n\n2.4. Monte Carlo Approximation\n\n현실적으로 딥러닝 학습 중에 복잡한 적분(\\(\\int\\))을 매번 계산하는 것은 불가능에 가깝습니다.\n따라서 Deep IV는 몬테카를로 샘플링(Monte Carlo Sampling)을 사용하여 적분을 근사합니다. \\[\\int g_{\\theta}(p, x_i) d\\hat{F}_{\\phi}(p | z_i, x_i) \\approx \\frac{1}{S} \\sum_{s=1}^{S} g_{\\theta}(\\hat{p}^{(s)}, x_i)\\]\n\n여기서 \\(\\hat{p}^{(s)}\\)는 1단계 MDN 모델에서 샘플링한 값들입니다 (\\(\\hat{p}^{(s)} \\sim \\hat{F}_{\\phi}\\)).\n\\(S\\)는 샘플 개수입니다 (보통 10~30개 사용).\n\n즉, “1단계 모델이 시뮬레이션한 가상의 가격들(\\(\\hat{p}\\))을 2단계 모델에 넣어보고, 그 평균값이 실제 판매량(\\(y\\))과 비슷해지도록” 학습하는 것입니다.\n\n\n\nCode\ndef second_stage_loss_fn(treatment_net, outcome_net, pi, mu, sigma, x, y, num_samples=32):\n    # 1. 몬테카를로 샘플링\n    # Shape: (Batch, S) -&gt; (Batch, S, 1)\n    p_samples = treatment_net.sample(pi, mu, sigma, n_samples=num_samples).unsqueeze(-1).detach()\n    \n    # 2. 공변량 차원 확장\n    # Shape: (Batch, x_dim) -&gt; (Batch, S, x_dim)\n    batch_size, x_dim = x.shape\n    x_expanded = x.unsqueeze(1).expand(-1, num_samples, -1)\n    \n    # 3. 결과 예측 (Outcome Network Forward)\n    # Shape: (Batch, S, 1) + (Batch, S, x_dim) -&gt; (Batch, S, 1)\n    y_pred_samples = outcome_net(p_samples, x_expanded)\n    \n    # 4. 기댓값 근사 (Sample Mean)\n    # Shape: (Batch, S, 1) -&gt; (Batch, 1)\n    y_pred_expectation = y_pred_samples.mean(dim=1)\n    \n    # 5. 손실 계산 (MSE)\n    # Shape: (Batch, 1) vs (Batch, 1) -&gt; Scalar\n    loss = F.mse_loss(y_pred_expectation, y.view(-1, 1))\n    \n    return loss"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-03/index.html#training-procedure",
    "href": "posts/lecture/L13/causal-inference-13-part-03/index.html#training-procedure",
    "title": "[Causal Inference] 13. IV (Part 3)",
    "section": "Training Procedure",
    "text": "Training Procedure\n\nDeep IV의 학습은 일반적인 지도 학습(Supervised Learning)과는 다르게, 순차적인 두 단계(Sequential Two-Stage Process)로 진행됩니다.\n\n\nPhase 1: Distribution Learning (Treatment Network)\n\n첫 번째 단계에서는 Treatment Network만을 학습시킵니다.\n\n목표: 도구변수(\\(Z\\))와 공변량(\\(X\\))을 보고, 처치변수(\\(P\\))가 어떻게 분포하는지 완벽하게 모사하는 것입니다.\n학습 방법: NLL Loss를 최소화하여 실제 데이터 \\(P\\)가 모델의 확률 분포 안에 위치할 확률을 높입니다.\n주의점: 이때 결과변수 \\(Y\\)는 전혀 사용하지 않습니다.\n\n\n\n\nTransition: The Freeze\n\n1단계 학습이 끝나면 Treatment Network의 파라미터(\\(\\phi\\))를 동결(Freeze)합니다.\n이제 1단계 모델은 더 이상 학습 대상이 아니라, 내생성이 제거된 가상의 처치값 \\(\\hat{P}\\)를 생성해내는 시뮬레이터(Generator) 역할을 수행합니다.\n\n\n\nPhase 2: Causal Learning (Outcome Network)\n\n두 번째 단계에서는 Outcome Network를 학습시킵니다.\n\n입력: 실제 관측된 \\(P\\)를 사용하는 것이 아니라, 동결된 1단계 모델에서 샘플링한 \\(\\hat{P}\\)를 사용합니다.\n목표: \\(\\hat{P}\\)를 입력받았을 때의 예측값 평균이 실제 \\(Y\\)와 가까워지도록 합니다.\n학습 방법: MSE Loss를 최소화하여 인과 함수 \\(g(P, X)\\)를 근사합니다.\n\n\n\n\nCode\n# -----------------------------------------------------\n# [Stage 1] Treatment Network Training (Z + X -&gt; P distribution)\n# -----------------------------------------------------\ntreatment_net = FirstStageMDN(\n    input_dim=X.shape[-1] + Z.shape[-1], \n    num_gaussians=5\n)\n\nopt1 = optim.Adam(treatment_net.parameters(), lr=1e-4)\nepochs_stage1 = 1000\n\nprint(f\"Starting Stage 1 Training (Epochs: {epochs_stage1})...\")\n\ntreatment_net.train()\nfor epoch in range(epochs_stage1):\n    # 1. Forward Pass\n    pi, mu, sigma = treatment_net(X, Z)\n    # 2. Loss Calculation (Negative Log Likelihood)\n    loss1 = first_stage_loss_fn(pi, mu, sigma, P)\n    # 3. Optimization\n    opt1.zero_grad()\n    loss1.backward()\n    opt1.step()\n    \n    if (epoch + 1) % 100 == 0:\n        print(f\"[Stage 1] Epoch [{epoch+1}/{epochs_stage1}] | Loss: {loss1:.4f} | Avg Sigma: {sigma.mean().item():.4f}\")\n\n# -----------------------------------------------------\n# [Transition] Freeze Stage 1\n# -----------------------------------------------------\ntreatment_net.eval()\nfor param in treatment_net.parameters():\n    param.requires_grad = False\nprint(\"Stage 1 Freezed.\")\n\n# -----------------------------------------------------\n# [Stage 2] Outcome Network Training (Resampled P + X -&gt; Y)\n# -----------------------------------------------------\noutcome_net = SecondStageH(\n    x_dim=X.shape[-1], \n    p_dim=1, \n    output_dim=1\n)\n\nopt2 = optim.Adam(outcome_net.parameters(), lr=1e-4)\nepochs_stage2 = 1000\n\nprint(f\"\\nStarting Stage 2 Training (Epochs: {epochs_stage2})...\")\n\noutcome_net.train()\nfor epoch in range(epochs_stage2):\n    total_loss = 0\n\n    with torch.no_grad():\n        pi, mu, sigma = treatment_net(X, Z)\n    \n    # 2단계 Loss 계산\n    loss2 = second_stage_loss_fn(\n        treatment_net=treatment_net,\n        outcome_net=outcome_net, \n        pi=pi, \n        mu=mu, \n        sigma=sigma, \n        x=X, \n        y=Y, \n        num_samples=20 \n    )\n    # Optimization\n    opt2.zero_grad()\n    loss2.backward()\n    opt2.step()\n\n    \n    if (epoch + 1) % 100 == 0:\n        print(f\"[Stage 2] Epoch [{epoch+1}/{epochs_stage2}] | Loss: {loss2:.4f}\")\n   \nprint(\"Deep IV Training Complete.\")\n\n\nStarting Stage 1 Training (Epochs: 1000)...\n[Stage 1] Epoch [100/1000] | Loss: 1.2246 | Avg Sigma: 0.7426\n[Stage 1] Epoch [200/1000] | Loss: 0.8651 | Avg Sigma: 0.6943\n[Stage 1] Epoch [300/1000] | Loss: 0.4267 | Avg Sigma: 0.5430\n[Stage 1] Epoch [400/1000] | Loss: 0.0645 | Avg Sigma: 0.3683\n[Stage 1] Epoch [500/1000] | Loss: -0.1064 | Avg Sigma: 0.2715\n[Stage 1] Epoch [600/1000] | Loss: -0.4534 | Avg Sigma: 0.1886\n[Stage 1] Epoch [700/1000] | Loss: -0.7542 | Avg Sigma: 0.1364\n[Stage 1] Epoch [800/1000] | Loss: -0.9869 | Avg Sigma: 0.1000\n[Stage 1] Epoch [900/1000] | Loss: -1.2780 | Avg Sigma: 0.0781\n[Stage 1] Epoch [1000/1000] | Loss: -1.1258 | Avg Sigma: 0.0643\nStage 1 Freezed.\n\nStarting Stage 2 Training (Epochs: 1000)...\n[Stage 2] Epoch [100/1000] | Loss: 0.1575\n[Stage 2] Epoch [200/1000] | Loss: 0.0995\n[Stage 2] Epoch [300/1000] | Loss: 0.0867\n[Stage 2] Epoch [400/1000] | Loss: 0.0775\n[Stage 2] Epoch [500/1000] | Loss: 0.0773\n[Stage 2] Epoch [600/1000] | Loss: 0.0631\n[Stage 2] Epoch [700/1000] | Loss: 0.0811\n[Stage 2] Epoch [800/1000] | Loss: 0.0609\n[Stage 2] Epoch [900/1000] | Loss: 0.0585\n[Stage 2] Epoch [1000/1000] | Loss: 0.0580\nDeep IV Training Complete."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-03/index.html#result-visualization",
    "href": "posts/lecture/L13/causal-inference-13-part-03/index.html#result-visualization",
    "title": "[Causal Inference] 13. IV (Part 3)",
    "section": "Result Visualization",
    "text": "Result Visualization\n\n학습된 모델이 실제 인과 효과 곡선(Ground Truth)을 얼마나 잘 복원했는지 확인합니다.\n테스트는 성수기와 비성수기의 중간(\\(X=0.5\\)) 조건을 가정합니다.\n\n\n\nCode\n# ===========================================================\n# 1. 테스트 데이터 생성\n# ===========================================================\np_min, p_max = P_data.min(), P_data.max()\np_test = np.linspace(p_min, p_max, 200).reshape(-1, 1)\n\nfixed_x_val = 0.5\nx_test = np.full_like(p_test, fixed_x_val)\n\ndef true_structural_function(p_val, x_val):\n    threshold = 35 + (40 * x_val)\n    base_effect = 150 / (1 + np.exp(0.8 * (p_val - threshold)))\n    return base_effect + (50 * x_val)\n        \ntrue_y = true_structural_function(p_test, x_test)\n\n# ===========================================================\n# 2. Linear 2SLS 예측\n# ===========================================================\npx_test_linear = np.concatenate((p_test, x_test), axis=1)\nlinear_pred = stage2_model.predict(px_test_linear)\n\n# ===========================================================\n# 3. DeepIV 예측\n# ===========================================================\noutcome_net.eval()\n\np_test_scaled = scaler_p.transform(p_test)\nx_test_scaled = scaler_x.transform(x_test)\np_tensor = torch.tensor(p_test_scaled, dtype=torch.float32)\nx_tensor = torch.tensor(x_test_scaled, dtype=torch.float32)\n\nwith torch.no_grad():\n    y_pred_scaled = outcome_net(p_tensor, x_tensor)    \n    deep_pred = scaler_y.inverse_transform(y_pred_scaled.numpy())\n\n# ===========================================================\n# 4. 최종 시각화\n# ===========================================================\nplt.figure(figsize=(12, 8))\n\n# 배경: 관측 데이터\nplt.scatter(P_data, Y_data, color='gray', alpha=0.1, s=10, label='Observed Data')\n\n# 1. Ground Truth (검은 실선)\nplt.plot(p_test, true_y, 'k-', linewidth=3, label='Ground Truth')\n\n# 2. Linear 2SLS (빨간 점선)\nplt.plot(p_test, linear_pred, 'r--', linewidth=2.5, label='Linear 2SLS')\n\n# 3. Deep IV (파란 실선)\nplt.plot(p_test, deep_pred, 'b-', linewidth=2.5, label='Deep IV')\n\nplt.title(f\"Causal Effect Estimation: Non-linear Pricing (at Seasonality X={fixed_x_val})\", fontsize=16, weight='bold')\nplt.xlabel(\"Treatment: Ticket Price (P)\", fontsize=13)\nplt.ylabel(\"Outcome: Sales (Y)\", fontsize=13)\nplt.legend(fontsize=12, loc='upper right', framealpha=0.9)\nplt.grid(True, alpha=0.3, linestyle='--')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nComparison of Causal Effect Estimation"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-03/index.html#conclusion",
    "href": "posts/lecture/L13/causal-inference-13-part-03/index.html#conclusion",
    "title": "[Causal Inference] 13. IV (Part 3)",
    "section": "Conclusion",
    "text": "Conclusion\n\n결과 그래프에서 볼 수 있듯이:\n\n\nLinear 2SLS는 데이터의 비선형성을 무시하고 단순한 직선으로 효과를 추정하여, 가격 임계값 근처에서의 급격한 수요 변화를 포착하지 못합니다.\n\n\nDeep IV는 실제 인과 곡선(Ground Truth)인 S자 형태를 매우 정확하게 복원해냈습니다.\n\n\n이는 비선형성이 강하게 의심될 때, 딥러닝 기반의 인과추론 방법론이 강력한 대안이 될 수 있음을 시사합니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "",
    "text": "인과추론에서 우리가 관심을 가지는 것은 처치(Treatment, \\(X\\))가 결과(Outcome, \\(Y\\))에 미치는 인과적 효과(\\(\\beta_1\\))를 추정하는 것입니다.\n하지만 많은 경우 관찰되지 않은 교란 요인(Unobserved Confounder)이 존재하여 단순한 회귀분석(OLS)으로는 편향된 추정치를 얻게 됩니다.\n이때 사용할 수 있는 강력한 도구가 바로 도구변수(Instrumental Variable, IV)입니다.\n이 글에서는 선형 가정(Linear Assumption) 하에서의 IV, 특히 2SLS (Two-Stage Least Squares) 접근법과 그 유도 과정을 다룹니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#인과-모형-causal-graph",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#인과-모형-causal-graph",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "2.1. 인과 모형 (Causal Graph)",
    "text": "2.1. 인과 모형 (Causal Graph)\n\n우선 변수들 간의 관계를 DAG(Directed Acyclic Graph)로 표현하면 다음과 같습니다.\n\n\n\n\nFigure 1: IV Causal Graph. Z는 도구변수, X는 처치, Y는 결과, W는 공변량, ε는 관찰되지 않은 오차항을 의미합니다.\n\n\n\n\\(Z\\): 도구변수 (Instrument)\n\\(X\\): 처치변수 (Treatment) - Endogenous (내생적)\n\\(Y\\): 결과변수 (Outcome)\n\\(W\\): 공변량 (Covariates) - Exogenous (외생적)\n\\(\\epsilon\\): 오차항 (Error term/Unobserved Confounders)"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#선형-모형과-ols의-한계",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#선형-모형과-ols의-한계",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "2.2. 선형 모형과 OLS의 한계",
    "text": "2.2. 선형 모형과 OLS의 한계\n\n전통적인 선형 모형은 다음과 같이 설정됩니다.\n\n\\[Y_i = \\beta_0 + \\beta_1 X_i + \\beta_2 W_i + \\epsilon_i\\]\n\n여기서 우리의 관심 추정량(estimand)은 \\(X_i\\)의 계수인 \\(\\beta_1\\)입니다.\n하지만 Challenge가 발생합니다.\n오차항 \\(\\epsilon_i\\)가 처치 변수 \\(X_i\\)와 상관관계를 가질 때(Dependent/Confounded), 이를 내생성(Endogeneity)이 있다고 합니다.\n\n\nNote:\n\nEndogenous (내생변수): \\(Y\\)와 관련된 교란요인(confounder)과 상관관계가 있는 변수 (\\(X\\))\nExogenous (외생변수): 교란요인과 상관관계가 없는 변수 (\\(W\\))\n\n\n\n만약 \\(X\\)가 내생적이라면, \\(\\beta_1\\)에 대한 직접적인 OLS(Ordinary Least Squares) 추정량은 편향(Biased)됩니다.\n즉, \\(Cov(X, \\epsilon) \\neq 0\\)인 상황입니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#iv의-조건",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#iv의-조건",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "3.1. IV의 조건",
    "text": "3.1. IV의 조건\n\n이 문제를 해결하기 위해 도입하는 도구변수 벡터 \\(Z\\) (\\(K\\)차원)는 다음 두 가지 조건을 만족해야 합니다.\n\n\nRelevance (관련성): 도구변수 \\(Z\\)는 처치 \\(X\\)와 관련이 있어야 합니다. (그래프 상에서 \\(Z \\rightarrow X\\) 경로 존재)\nExclusion Restriction (배제 제약) & Independence: 도구변수 \\(Z\\)는 오직 \\(X\\)를 통해서만 \\(Y\\)에 영향을 미쳐야 하며, 교란요인 \\(\\epsilon\\)과 독립이어야 합니다.\n\n\\(\\epsilon_i \\perp W_i\\)\n\\(\\epsilon_i \\perp Z_i | W_i\\)\n즉, \\(\\epsilon_i \\perp (Z_i, W_i)\\)"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#식별-identification",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#식별-identification",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "3.2. 식별 (Identification)",
    "text": "3.2. 식별 (Identification)\n도구변수의 개수(\\(K\\))와 내생변수의 개수에 따라 모델의 식별 상태가 달라집니다.\n\nOver-identified (과잉 식별): \\(K &gt; 1\\) (도구변수가 내생변수보다 많음)\nJust-identified (적정 식별): \\(K = 1\\) (도구변수와 내생변수 개수가 같음)"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#just-indentified-no-covariates",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#just-indentified-no-covariates",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "4.1. Just-indentified, No Covariates",
    "text": "4.1. Just-indentified, No Covariates\n\nJust-identified 케이스 (\\(K=1\\))를 기준으로 세 가지 해석 방식을 살펴보겠습니다.\n이때 공변량(W)는 없다고 가정합니다.\n결론적으로 이 세 가지는 모두 동일한 \\(\\beta_1\\) 값을 도출합니다.\n\n\n4.1.1. 공분산의 비율 (Ratio of Covariance)\n\n가장 직관적인 IV 추정량은 \\(Y\\)와 \\(Z\\)의 공분산을 \\(X\\)와 \\(Z\\)의 공분산으로 나눈 것입니다.\n\n\\[\\hat{\\beta}_{1, iv} = \\frac{\\widehat{Cov}(Y_i, Z_i)}{\\widehat{Cov}(X_i, Z_i)} = \\frac{\\frac{1}{N}\\sum(Y_i - \\bar{Y})(Z_i - \\bar{Z})}{\\frac{1}{N}\\sum(X_i - \\bar{X})(Z_i - \\bar{Z})}\\]\n\nWald Estimator (Binary IV의 경우):\n\n만약 도구변수 \\(Z\\)가 0과 1만 가지는 이진 변수라면, 이는 Wald Estimator가 됩니다. \\[\\hat{\\beta}_{1, iv} = \\frac{\\bar{Y}_1 - \\bar{Y}_0}{\\bar{X}_1 - \\bar{X}_0}\\]\n여기서 \\(\\bar{Y}_z, \\bar{X}_z\\)는 \\(Z=z\\)인 그룹 내에서의 평균을 의미합니다.\n\n\n\n\n4.1.2. 간접 최소제곱법 (Indirect Least Squares, ILS)\n\nILS는 두 개의 축약형(Reduced form) 회귀식을 이용하는 방식입니다.\n\n\nReduced Form 1 (\\(Y\\) on \\(Z\\)): \\(Y_i = \\pi_{10} + \\pi_{11} Z_i + \\epsilon_{1i}\\)\nReduced Form 2 (\\(X\\) on \\(Z\\)): \\(X_i = \\pi_{20} + \\pi_{21} Z_i + \\epsilon_{2i}\\)\n\n\nILS 추정량은 두 회귀계수의 비율로 정의됩니다.\n\n\\[\\hat{\\beta}_{1, ils} = \\frac{\\hat{\\pi}_{11}}{\\hat{\\pi}_{21}}\\]\n\n\n4.1.3. 2단계 최소제곱법 (Two Stage Least Squares, 2SLS)\n\n가장 널리 쓰이는 직관적인 방법으로, \\(X\\)에서 내생성을 제거한 후 회귀분석을 수행하는 방식입니다.\nStage 1: 내생변수 \\(X\\)를 도구변수 \\(Z\\)로 예측합니다. (OLS 수행) \\[X_i = \\pi_0 + \\pi_1 Z_i + \\epsilon_i\\] \\[\\Longrightarrow \\hat{X}_i = \\hat{\\pi}_0 + \\hat{\\pi}_1 Z_i\\]\nStage 2: 원래의 \\(X\\) 대신 예측된 \\(\\hat{X}\\)를 사용하여 결과 모형을 추정합니다. \\[Y_i = \\pi_2 + \\pi_3 \\hat{X}_i + \\epsilon_i\\] 여기서 구해진 \\(\\hat{\\pi}_3\\)가 바로 2SLS 추정량 \\(\\hat{\\beta}_{1, 2sls}\\)입니다.\n\n\nIntuition:\n1단계를 통해 \\(X\\)의 변동 중 \\(Z\\)에 의해 설명되는 부분(즉, 오차항 \\(\\epsilon\\)과 상관없는 “unconfounded portion”)만을 추출하여 2단계에서 인과 효과를 추정하는 것입니다.\n\n\n\n4.1.4. 결론\n\n위의 세 방식에 따른 추정치는 모두 동일합니다.\n\n\\[\\hat{\\beta}_{1, iv} = \\hat{\\beta}_{1, ils} = \\hat{\\beta}_{1, 2sls}\\]"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#just-indentified-with-covariates",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#just-indentified-with-covariates",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "4.2. Just-indentified, With Covariates",
    "text": "4.2. Just-indentified, With Covariates\n\nJust-identified 케이스 (\\(K=1\\))를 기준으로 두 가지 해석 방식을 살펴보겠습니다.\n이때 공변량(W)을 함께 고려합니다.\n결론적으로 이 두 가지는 모두 동일한 \\(\\beta_1\\) 값을 도출합니다.\n\n\n4.2.2. 간접 최소제곱법 (Indirect Least Squares, ILS)\n\nILS는 두 개의 축약형(Reduced form) 회귀식을 이용하는 방식입니다.\n\n\nReduced Form 1 (\\(Y\\) on \\(Z\\)): \\(Y_i = \\pi_{10} + \\pi_{11} Z_i + \\pi_{12} W_i + \\epsilon_{1i}\\)\nReduced Form 2 (\\(X\\) on \\(Z\\)): \\(X_i = \\pi_{20} + \\pi_{21} Z_i + \\pi_{22} Z_i + \\epsilon_{2i}\\)\n\n\nILS 추정량은 두 회귀계수의 비율로 정의됩니다.\n\n\\[\\hat{\\beta}_{1, ils} = \\frac{\\hat{\\pi}_{11}}{\\hat{\\pi}_{21}}\\]\n\n\n4.2.2. 2단계 최소제곱법 (Two Stage Least Squares, 2SLS)\n\n가장 널리 쓰이는 직관적인 방법으로, \\(X\\)에서 내생성을 제거한 후 회귀분석을 수행하는 방식입니다.\nStage 1: 내생변수 \\(X\\)를 도구변수 \\(Z\\)로 예측합니다. (OLS 수행) \\[X_i = \\pi_0 + \\pi_1 Z_i + \\pi_2 W_i + \\epsilon_{1i}\\] \\[\\Longrightarrow \\hat{X}_i = \\hat{\\pi}_0 + \\hat{\\pi}_1 Z_i + \\hat{\\pi}_2 W_i \\]\nStage 2: 원래의 \\(X\\) 대신 예측된 \\(\\hat{X}\\)를 사용하여 결과 모형을 추정합니다. \\[Y_i = \\beta_0 + \\beta_1 \\hat{X}_i + \\beta_2 W_i + \\epsilon_{2i}\\] 여기서 구해진 \\(\\hat{\\beta}_1\\)이 바로 2SLS 추정량 \\(\\hat{\\beta}_{1, 2sls}\\)입니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#설정-setup",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#설정-setup",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "5.1. 설정 (Setup)",
    "text": "5.1. 설정 (Setup)\n\n우리는 다음 두 식을 관찰할 수 있습니다.\n\n\nFirst Stage (X에 대한 식): \\[X_i = \\pi_0 + \\pi_1 Z_i + \\pi_2 W_i + \\epsilon_{1i}\\]\nStructural Model (Y에 대한 식): \\[Y_i = \\beta_0 + \\beta_1 {X}_i + \\underbrace{\\beta_2 {W}_i + \\epsilon_{2i}}_{\\eta_{i}}\\]\n\n\n가정: \\(Cov[X_i, \\eta_i] \\neq 0\\) (내생성 존재), 하지만 \\(Cov[\\eta_i, Z_i] = 0\\) (도구변수의 외생성)."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#iv-estimator-유도-ratio-방식",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#iv-estimator-유도-ratio-방식",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "5.2. IV Estimator 유도 (Ratio 방식)",
    "text": "5.2. IV Estimator 유도 (Ratio 방식)\n\n\\(Y_i\\) 식의 양변과 \\(Z_i\\)의 공분산을 취해봅시다.\n\n\\[\n\\begin{aligned}\nCov[Y_i, Z_i] &= Cov[\\beta_0 + \\beta_1 X_i + \\eta_i, \\; Z_i] \\\\\n&= \\beta_1 Cov[X_i, Z_i] + \\underbrace{Cov[\\eta_i, Z_i]}_{0 \\text{ (by assumption)}} \\\\\n&= \\beta_1 Cov[X_i, Z_i]\n\\end{aligned}\n\\]\n\n따라서, \\(\\beta_1\\)에 대해 정리하면 다음과 같습니다.\n\n\\[\\beta_1 = \\frac{Cov[Y_i, Z_i]}{Cov[X_i, Z_i]} = \\frac{Cov[Y_i, Z_i] / Var[Z_i]}{Cov[X_i, Z_i] / Var[Z_i]} = \\frac{\\text{Reduced form slope}}{\\text{First stage slope}}\\]\n\n이 유도 과정은 ILS 방식(\\(\\pi_{11}/\\pi_{21}\\))과 정확히 일치함을 보여줍니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#sls-estimator-유도-substitution-방식",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#sls-estimator-유도-substitution-방식",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "5.3. 2SLS Estimator 유도 (Substitution 방식)",
    "text": "5.3. 2SLS Estimator 유도 (Substitution 방식)\n\n2SLS가 어떻게 작동하는지 수식 대입을 통해 확인해 봅시다.\n\\(Y\\) 식의 \\(X_i\\) 자리에 First Stage 식(\\(\\pi_0 + \\pi_1 Z_i + \\pi_2 W_i + \\epsilon_{1i}\\))을 대입합니다.\n\n\\[\n\\begin{aligned}\nY_i &= \\beta_0 + \\beta_1 {X}_i + \\beta_2 {W}_i + \\epsilon_{2i} \\\\\n&= \\beta_0 + \\beta_1(\\pi_0 + \\pi_1 Z_i + \\pi_2 W_i + \\epsilon_{1i}) + \\beta_2 {W}_i + \\epsilon_{2i} \\\\\n&= \\beta_0 + \\beta_1 (\\pi_0 + \\pi_1 Z_i + \\pi_2 {W}_i) + \\beta_2 {W}_i + \\underbrace{\\beta_1 \\epsilon_{1i} + \\epsilon_{2i}}_{\\xi_i} \\\\\n\\end{aligned}\n\\]\n\n이를 다시 정리하면, \\(\\pi_0 + \\pi_1 Z_i + \\pi_2 {W}_i\\) 부분은 \\(E[X_i | W_i, Z_i]\\) 즉, \\(\\hat{X}_i\\)의 핵심 부분임을 알 수 있습니다.\n\n\\[Y_i = \\beta_0 + \\underbrace{\\beta_1 E[X_i | W_i, Z_i]}_{\\hat{X_i}} + \\beta_2 W_i + \\xi_i\\]\n\n결국 \\(Y\\)를 \\(\\hat{X}\\)와 \\(W\\)에 대해 회귀분석하는 형태가 되며, 이때 \\(\\hat{X}\\)의 계수는 원래 식의 \\(\\beta_1\\)이 됩니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#recap-matrix-notation-for-ols-regression",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#recap-matrix-notation-for-ols-regression",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "6.1. Recap (Matrix Notation for OLS Regression)",
    "text": "6.1. Recap (Matrix Notation for OLS Regression)\n\n6.1.1. 선형 회귀 모형의 행렬 표현\n\n먼저, 선형 회귀 모형을 행렬 형태로 정의해 봅시다. 기본 식은 다음과 같습니다.\n\n\\[\ny = X\\beta + u\n\\]\n\n여기서 각 변수가 의미하는 바를 구체적인 행렬로 풀어서 쓰면 다음과 같습니다. \\(X\\)는 \\(n \\times k\\) 행렬(matrix)입니다.\n\n\\[\ny = \\begin{pmatrix} y_1 \\\\ \\vdots \\\\ y_n \\end{pmatrix}, \\quad\nX = \\begin{pmatrix} x'_1 \\\\ \\vdots \\\\ x'_n \\end{pmatrix}\n= \\begin{pmatrix}\n1 & x_{12} & \\cdots & x_{1k} \\\\\n\\vdots & \\vdots & \\vdots & \\vdots \\\\\n1 & x_{n2} & \\cdots & x_{nk}\n\\end{pmatrix}, \\quad\nu = \\begin{pmatrix} u_1 \\\\ \\vdots \\\\ u_n \\end{pmatrix}\n\\]\n\n\n\n6.1.2. 최소자승법(OLS) 추정량\n\n우리의 목표는 오차의 제곱합을 최소화하는 \\(\\beta\\)의 추정량, 즉 \\(b\\)를 찾는 것입니다.\n이를 위해 목적 함수 \\(S(b)\\)를 다음과 같이 정의합니다.\n이는 관측값(\\(y\\))과 예측값(\\(Xb\\)) 차이의 제곱합입니다.\n\n\\[\nS(b) = (y - Xb)'(y - Xb)\n\\]\n\nOLS 추정량 \\(\\hat{\\beta}\\)는 이 \\(S(b)\\)를 최소화하는 값입니다.\n\n\\[\n\\hat{\\beta} = \\underset{b \\in \\mathbb{R}^k}{\\arg \\min} \\, S(b) = (X'X)^{-1}X'y\n\\]\n\n\n6.1.3. 유도 과정 (Derivation)\n\n\\(S(b)\\)를 최소화하기 위해 \\(b\\)에 대해 미분을 수행합니다.\n\n\n1단계: 1계 조건 (First Order Condition, FOC)\n\n목적 함수를 \\(b\\)로 미분했을 때 0이 되어야 합니다.\n행렬 미분 공식을 적용하면 다음과 같습니다.\n\n\\[\n\\begin{aligned}\n\\text{FOC : } \\quad \\frac{\\partial S(b)}{\\partial b} &= -2X'y + 2X'Xb \\\\\n&= -2X'(y - Xb) = 0\n\\end{aligned}\n\\]\n\n\n2단계: 정규 방정식 (Normal Equation)과 해 구하기\n\n1계 조건(FOC)에 따라, 최적의 추정량 \\(\\hat{\\beta}\\)는 다음의 정규 방정식(Normal Equation)을 만족해야 합니다.\n\n\\[\nX'(y - X\\hat{\\beta}) = 0\n\\]\n\n이 식을 \\(\\hat{\\beta}\\)에 대해 정리해 봅시다.\n\\(X\\)가 Full Rank를 가진다고 가정하면, 역행렬이 존재하므로 유일한 해(unique solution)를 구할 수 있습니다.\n\n\\[\n\\begin{aligned}\nX'y - X'X\\hat{\\beta} &= 0 \\\\\nX'X\\hat{\\beta} &= X'y \\\\\n\\therefore \\quad \\hat{\\beta} &= (X'X)^{-1}X'y\n\\end{aligned}\n\\]\n\n\n\n6.1.4 기하학적 해석 (Geometric Interpretation)\n\n행렬 \\(X\\)를 열 벡터(column vector)들의 집합으로 생각해보겠습니다.\n\n\\[\nX = (x_1, ..., x_k)\n\\]\n\n여기서 \\(x_i\\)는 \\(X\\)의 \\(i\\)번째 열 벡터를 의미합니다.\n이때 종속변수 벡터 \\(y\\)와 설명변수 벡터들 \\(x_1, ..., x_k\\)는 모두 \\(n\\)차원 유클리드 공간 \\(\\mathbb{R}^n\\) 상의 점(혹은 벡터)들입니다.\n\n\n1. Range Space (열공간)의 정의\n\n\\(X\\)의 Range Space (또는 Column Space, 열공간)인 \\(\\mathcal{R}(X)\\)는 다음과 같이 정의됩니다.\n\n\\[\n\\begin{aligned}\n\\mathcal{R}(X) &= \\{ c \\in \\mathbb{R}^n : c = Xb \\text{ for } b \\in \\mathbb{R}^k \\} \\\\\n&= \\{ c \\in \\mathbb{R}^n : c = x_1b_1 + \\cdots + x_kb_k, \\quad b = (b_1, ..., b_k)' \\in \\mathbb{R}^k \\}\n\\end{aligned}\n\\]\n\n즉, \\(\\mathcal{R}(X)\\)는 \\(X\\)의 열 벡터(\\(x_1, ..., x_k\\))들의 선형 결합(linear combination)으로 만들 수 있는 모든 가능한 벡터들의 집합을 의미합니다.\n수학적으로는 \\(X\\)의 열들에 의해 생성(span)된 \\(\\mathbb{R}^n\\)의 선형 부분공간(linear subspace)입니다.\n\n\n\n2. 회귀분석(Regression)에서의 의미\n\n이 기하학적 정의는 회귀분석의 목표를 명확하게 보여줍니다.\n우리가 구하고자 하는 예측값 \\(\\hat{y} = Xb\\)는 정의상 반드시 \\(\\mathcal{R}(X)\\) 안에 존재해야 합니다.\n하지만 실제 관측값 \\(y\\)는 오차(error) 때문에 일반적으로 \\(\\mathcal{R}(X)\\) 바깥에 위치합니다.\n따라서 회귀분석(Regression Problem)은 기하학적으로 다음과 같이 해석됩니다:\n\n\n“\\(\\mathcal{R}(X)\\) 공간 안에 있는 수많은 점들 중에서, 실제 데이터 \\(y\\)와 가장 가까운 점(closest point)을 찾는 과정”\n\n\n이 ’가장 가까운 점’을 찾기 위해 우리는 수직 투영(Orthogonal Projection)을 사용하게 되며, 이것이 바로 최소자승법(OLS)의 원리입니다.\n\n\n\n\nFigure 2: Geometric Interpretation."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#estimating-2sls-models",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#estimating-2sls-models",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "6.2. Estimating 2SLS Models",
    "text": "6.2. Estimating 2SLS Models\n\n1. 모형 설정 및 변수 정의\n\n2SLS(Two-Stage Least Squares) 모형을 추정하기 위해 변수들을 다음과 같이 정의합니다.\n\\(\\mathbf{y}\\): 종속 변수 벡터 (\\(n \\times 1\\))\n\\(\\mathbf{X}\\): 내생 변수(Endogenous variables) 행렬 (\\(n \\times k_1\\))\n\\(\\mathbf{W}\\): 외생 변수(Exogenous regressors) 행렬 (\\(n \\times k_2\\))\n\\(\\mathbf{Z}\\): 도구 변수(Instruments) 행렬. 여기에는 외생 변수 \\(\\mathbf{W}\\)가 포함됩니다. (\\(\\mathbf{Z} = [\\mathbf{Z}_1 \\; \\mathbf{W}]\\))\n우리의 목표는 아래의 2SLS 추정량을 유도하는 것입니다.\n\n\\[\n\\hat{\\Gamma}_{2SLS} = \\left( [\\hat{\\mathbf{X}}\\; \\mathbf{W}]' [\\hat{\\mathbf{X}}\\; \\mathbf{W}] \\right)^{-1} [\\hat{\\mathbf{X}}\\; \\mathbf{W}]' \\mathbf{y}\n\\]\n\n여기서 \\([\\hat{\\mathbf{X}}\\; \\mathbf{W}]\\)는 1단계 회귀분석을 통해 예측된 내생변수 \\(\\hat{\\mathbf{X}}\\)와 기존의 외생변수 \\(\\mathbf{W}\\)를 합친 새로운 설명변수 행렬 (\\(n \\times (k_1 + k_2)\\))입니다.\n이를 원소별로 풀어서 쓰면 다음과 같습니다. \\[\n[\\hat{\\mathbf{X}}\\; \\mathbf{W}] =\n\\begin{pmatrix}\n\\hat{x}_{1,1} & \\cdots & \\hat{x}_{1,k_1} & w_{1,1} & \\cdots & w_{1,k_2} \\\\\n\\vdots & \\ddots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\hat{x}_{n,1} & \\cdots & \\hat{x}_{n,k_1} & w_{n,1} & \\cdots & w_{n,k_2}\n\\end{pmatrix}\n\\]\n\n좌측 블록(\\(\\hat{\\mathbf{X}}\\))은 도구변수(\\(\\mathbf{Z}\\))로 예측된 값들로 구성되어 있고, 우측 블록(\\(\\mathbf{W}\\))은 원래의 외생변수 값들이 그대로 들어갑니다.\n\n\n\n\n\n2. 사영 행렬(Projection Matrix) \\(P_Z\\) 의 도입\n\n도구변수 \\(\\mathbf{Z}\\)에 의한 사영 행렬(Projection Matrix)을 \\(P_Z\\)라고 표기하겠습니다.\n\n\\[\nP_Z = \\mathbf{Z}(\\mathbf{Z}'\\mathbf{Z})^{-1}\\mathbf{Z}'\n\\]\n\n이 행렬 \\(P_Z\\)은 다음과 같은 매우 중요한 두 가지 성질을 가집니다.\n\n\n대칭성 (Symmetric): \\(P_Z' = P_Z\\)\n\n\n멱등성 (Idempotent): \\(P_ZP_Z = P_Z\\)"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#a-부분의-유도-행렬의-곱",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#a-부분의-유도-행렬의-곱",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "3. A 부분의 유도 (행렬의 곱)",
    "text": "3. A 부분의 유도 (행렬의 곱)\n\n추정량의 앞부분인 역행렬 내부, 즉 \\(A = [\\hat{\\mathbf{X}}\\; \\mathbf{W}]' [\\hat{\\mathbf{X}}\\; \\mathbf{W}]\\)를 정리해 봅시다.\n1단계 예측값 \\(\\hat{\\mathbf{X}}\\)는 \\(\\mathbf{X}\\)를 투영한 것이므로 \\(\\hat{\\mathbf{X}} = P_Z\\mathbf{X}\\)입니다.\n외생변수 \\(\\mathbf{W}\\)는 도구변수 \\(\\mathbf{Z}\\)에 포함되므로 \\(R(W) \\subset R(Z)\\) 투영해도 자신이 됩니다. 즉, \\(P_Z\\mathbf{W} = \\mathbf{W}\\)입니다.\n따라서 전체 설명변수 행렬은 \\(P_Z\\)를 묶어 다음과 같이 쓸 수 있습니다.\n\n\\[\n\\begin{aligned} \\\\\n[\\hat{\\mathbf{X}} \\quad \\mathbf{W}] &= [P_Z\\mathbf{X} \\quad P_Z\\mathbf{W}] \\\\\n&= P_Z [\\mathbf{X} \\quad \\mathbf{W}]\n\\end{aligned}\n\\]\n\n이제 편의상 전체 설명변수 행렬을 \\(\\mathbf{R} = [\\mathbf{X} \\quad \\mathbf{W}]\\)라 정의하고 \\(A\\)를 다시 쓰면: \\[A = (P_Z\\mathbf{R})' (P_Z\\mathbf{R})\\]\n\n이때 \\(P_Z\\mathbf{R}\\)는 원래의 변수 행렬(\\(\\mathbf{R}\\))을 도구변수 공간에 투영(\\(P_Z\\))시킨 결과라고 해석할 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#b-부분의-유도-y와의-곱",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#b-부분의-유도-y와의-곱",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "4. B 부분의 유도 (\\(y\\)와의 곱)",
    "text": "4. B 부분의 유도 (\\(y\\)와의 곱)\n\n추정량의 뒷부분인 \\(B = [\\hat{\\mathbf{X}}\\; \\mathbf{W}]' \\mathbf{y}\\) 도 동일한 방식으로 작성합니다.\n\n\\[B = (P_Z\\mathbf{R})' \\mathbf{y}\\]"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-01/index.html#최종-결과-2sls-추정량",
    "href": "posts/lecture/L13/causal-inference-13-part-01/index.html#최종-결과-2sls-추정량",
    "title": "[Causal Inference] 13. IV (Part 1)",
    "section": "5. 최종 결과: 2SLS 추정량",
    "text": "5. 최종 결과: 2SLS 추정량\n\n위의 \\(A\\)와 \\(B\\) 결과를 합치면 다음과 같습니다.\n\n\\[\n\\begin{aligned}\n\\hat{\\Gamma}_{2SLS} &= A^{-1} B \\\\\n&= [(P_Z\\mathbf{R})' (P_Z\\mathbf{R})]^{-1} (P_Z\\mathbf{R})' \\mathbf{y}\n\\end{aligned}\n\\]\n\n이 식은 “원래의 변수 행렬(\\(\\mathbf{R}\\))을 도구변수 공간에 투영(\\(P_Z\\))시킨 뒤, 그 투영된 변수들을 사용하여 OLS를 수행하는 것”과 수학적으로 동일함을 보여줍니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "",
    "text": "지난 포스트들에서 우리는 이중차분법(DiD)을 통해 인과효과를 추정하는 방법을 배웠습니다.\n하지만 DiD를 적용하기 어려운 상황이 종종 발생합니다. 바로 “적절한 통제 집단(Control Group)을 찾기 어려울 때”입니다.\n예를 들어, 캘리포니아 주가 담배 규제 정책(Proposition 99)을 시행했을 때, 나머지 49개 주 전체를 평균 내어 비교하는 것이 공정할까요?\n캘리포니아와 인구 구조, 경제 규모, 흡연 문화가 비슷한 단일한 주는 존재하지 않을지도 모릅니다.\n이번 포스트에서는 이러한 문제를 해결하기 위해, 여러 통제 집단을 적절히 섞어 “가상의 도플갱어(Synthetic Control)”를 만들어내는 통제집단합성법(Synthetic Control Method, SCM)에 대해 알아봅니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#단순-비교의-함정",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#단순-비교의-함정",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "1.1 단순 비교의 함정",
    "text": "1.1 단순 비교의 함정\n\n가장 단순한 방법은 “캘리포니아”와 “나머지 미국 전체(Rest of the U.S.)”의 담배 판매량을 비교하는 것입니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#합성-캘리포니아-synthetic-california의-등장",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#합성-캘리포니아-synthetic-california의-등장",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "1.2 합성 캘리포니아 (Synthetic California)의 등장",
    "text": "1.2 합성 캘리포니아 (Synthetic California)의 등장\n\nSCM은 다른 주들의 데이터를 가중 평균(Weighted Average)하여, 1988년 이전의 캘리포니아와 거의 완벽하게 겹치는 가상의 캘리포니아를 만들어냅니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#mathematical-framework",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#mathematical-framework",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "2. Mathematical Framework",
    "text": "2. Mathematical Framework\n\nSCM을 수식으로 엄밀하게 정의해 봅시다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#setup",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#setup",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "2.1 Setup",
    "text": "2.1 Setup\n\n단일 처치 집단: \\(i=1\\) (캘리포니아)\n통제 집단 풀(Donor Pool): \\(i=2, \\dots, J+1\\) (나머지 주들)\n시간: \\(T_0\\) (개입 이전 기간), \\(T\\) (전체 기간)\n목표: 개입 이후(\\(t &gt; T_0\\))의 처치 효과 \\(\\tau_{1t}\\) 추정 \\[\\tau_{1t} = Y_{1t}(1) - Y_{1t}(0)\\]\n여기서 \\(Y_{1t}(1)\\)은 관찰되지만, 정책이 없었을 때의 결과인 \\(Y_{1t}(0)\\)은 결측된 반사실(Missing Counterfactual)입니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#합성-통제-집단-구성-weights-construction",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#합성-통제-집단-구성-weights-construction",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "2.2 합성 통제 집단 구성 (Weights Construction)",
    "text": "2.2 합성 통제 집단 구성 (Weights Construction)\n\nSCM의 핵심은 통제 집단 유닛들에 부여할 가중치 벡터 \\(W = (w_2, \\dots, w_{J+1})'\\)를 찾는 것입니다.\n이 가중치는 다음 두 가지 제약 조건을 만족해야 합니다.\n\n\n비음수 조건 (Non-negative): \\(w_j \\ge 0\\)\n\n\n합의 조건 (Sum to one): \\(\\sum_{j=2}^{J+1} w_j = 1\\)\n\n\n이 제약 조건들은 합성 통제 집단이 데이터들의 볼록 껍질(Convex Hull) 내부에 존재하게 하여, 내삽(Interpolation)을 수행하도록 강제합니다.\n즉, 데이터의 범위를 벗어나는 과도한 외삽(Extrapolation)을 방지합니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#최적화-문제-optimization",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#최적화-문제-optimization",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "2.3 최적화 문제 (Optimization)",
    "text": "2.3 최적화 문제 (Optimization)\n\nSCM의 핵심은 “어떤 주(State)를 얼마나 섞을 것인가?”를 결정하는 최적의 가중치 벡터 \\(W^*\\)를 찾는 것입니다.\n\n\n2.3.1 목적 함수 (Objective Function)\n\n우리는 개입 이전 기간(\\(t \\le T_0\\)) 동안, 처치 집단과 합성 통제 집단 사이의 차이(Distance)를 최소화하고자 합니다.\n이를 위한 목적 함수는 다음과 같이 구성됩니다.\n\n\\[\nW^* = \\underset{W}{\\mathrm{argmin}} \\sqrt{ \\underbrace{\\sum_{m=1}^{k} v_m \\left( X_{1m} - \\sum_{j=2}^{J+1} w_j X_{jm} \\right)^2}_{\\text{예측 변수들의 가중 거리 합}} }\n\\]\n\n여기서 \\(X_{1m}\\)과 \\(X_{jm}\\)은 각각 처치 집단과 통제 집단의 예측 변수(Pre-treatment outcomes 및 Covariates)를 의미하며, 수식의 의미는 다음과 같습니다.\n\n결과 변수 추세 매칭 (Outcome Matching):\n\n\n개입 이전의 결과 변수(예: 연도별 담배 판매량) 추세가 처치 집단과 최대한 겹치도록 만듭니다.\n과거의 궤적을 잘 모사해야 미래의 반사실(Counterfactual)도 신뢰할 수 있습니다.\n\n\n공변량 매칭 (Covariate Matching):\n\n\n단순히 결과값의 패턴만 맞추는 것이 아니라, 결과에 영향을 미치는 근본적인 특성(예: GDP, 인구 비중, 소득 수준 등)까지 유사하게 맞춥니다.\n이는 모델이 우연히 시계열 패턴만 맞추는 과적합(Overfitting)을 방지하고, 구조적인 유사성을 보장합니다.\n\n\n\n\n2.3.2 제약 조건 (Constraints)\n\n찾아낸 가중치 \\(W = (w_2, \\dots, w_{J+1})'\\)는 반드시 다음 두 가지 조건을 만족해야 합니다.\n비음수 조건 (\\(w_j \\ge 0\\)): 회귀분석과 달리 음의 가중치를 허용하지 않습니다. \\[\nw_j \\ge 0\n\\]\n합의 조건 (\\(\\sum w_j = 1\\)): 모든 가중치의 합은 1이어야 합니다. \\[\n\\sum_{j=2}^{J+1} w_j = 1\n\\]\n의미:\n\n이 제약 조건들로 인해 합성 대조군은 데이터의 볼록 껍질(Convex Hull) 내에서 생성됩니다.\n즉, 합성 대조군은 통제 집단들의 ‘엄밀한 내삽(Interpolation)’ 결과물이 되며, 데이터 범위를 벗어나는 외삽(Extrapolation)의 위험을 차단합니다.\n\n\n\n\n2.3.3 변수 중요도 행렬 (\\(V\\) Matrix)\n\n위 수식의 \\(v_m\\)은 각 변수 \\(m\\)이 합성에 얼마나 기여해야 하는지를 결정하는 중요도 가중치입니다.\n모든 변수가 예측에 동일하게 중요하지 않습니다. 예를 들어, 흡연량을 예측할 때 ’지난해 흡연량’이 ’GDP’보다 더 중요할 수 있습니다.\n실제 분석에서는 이중 최적화(Nested Optimization) 과정을 거칩니다.\n\nInner Step: \\(V\\)가 주어졌을 때, 차이를 최소화하는 \\(W\\)를 찾습니다.\nOuter Step: 개입 이전 기간의 예측 오차(MSPE)를 가장 낮추는 최적의 변수 중요도 \\(V\\)를 찾아냅니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#model-based-justification",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#model-based-justification",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "3.1. Model-based Justification",
    "text": "3.1. Model-based Justification\n\nSCM이 단순히 “비슷해 보이는” 대상을 섞는 것이 아니라, 수학적으로 타당한 인과추론 도구인 이유는 무엇일까요?\nAbadie et al. (2010)은 두 가지 모형을 통해 SCM의 강력함을 증명했습니다.\n\n\n모형 1: 상호작용 요인 모형 (Interacted Factor Model)\n\n가장 널리 인용되는 SCM의 기반 모형입니다.\n결과 변수 \\(Y_{it}(0)\\)가 관찰 가능한 요인뿐만 아니라, 관찰되지 않는 ‘시간에 따라 변하는 요인’에 의해 결정된다고 가정합니다.\n\n\\[\nY_{it}(0) = \\underbrace{\\delta_t}_{\\text{Time FE}} + \\underbrace{\\boldsymbol{Z}_i' \\boldsymbol{\\beta}_t}_{\\text{Covariates}} + \\underbrace{\\alpha_i}_{\\text{Unit FE}} + \\underbrace{\\boldsymbol{\\lambda}_t \\boldsymbol{\\mu}_i}_{\\text{Latent Factors}} + \\epsilon_{it}\n\\]\n\n이 수식의 각 항은 다음을 의미합니다.\n\n\\(\\delta_t\\): 모든 유닛에 공통적으로 영향을 미치는 시간 충격 (예: 글로벌 경제 위기).\n\\(\\boldsymbol{Z}_i' \\boldsymbol{\\beta}_t\\): 관찰 가능한 공변량(\\(Z\\))이 시간에 따라 미치는 영향(\\(\\beta_t\\))이 변할 수 있음을 허용.\n\\(\\alpha_i\\): 유닛 고유의 고정 효과 (기존 DiD가 통제하는 부분).\n\\(\\boldsymbol{\\lambda}_t \\boldsymbol{\\mu}_i\\) (핵심): 관찰되지 않는 공통 요인(\\(\\lambda_t\\))과 각 유닛의 요인 적재값(\\(\\mu_i\\))의 곱입니다.\n\n이는 시간 가변적 교란 요인(Time-varying Confounding)을 구조적으로 모형화한 것입니다.\n예를 들어, \\(\\lambda_t\\)가 ’기술 발전 속도’라면 \\(\\mu_i\\)는 해당 주(State)의 ’기술 수용성’이 될 수 있으며, 이 효과는 시간에 따라 달라집니다.\n\n\n기존의 이중차분법(DiD)은 \\(\\alpha_i\\)(시간 불변 요인)만 제거할 수 있습니다.\n하지만 SCM은 적절한 가중치(\\(W\\))를 통해 \\(\\boldsymbol{\\lambda}_t \\boldsymbol{\\mu}_i\\) 항까지 상쇄시킬 수 있어, 평행 추세 가정이 위배되는 상황에서도 편향 없는 추정이 가능합니다.\n\n\n\n모형 2: 자기회귀 모형 (Autoregressive Model)\n\n두 번째 정당화 논리는 데이터가 자기회귀(AR) 과정을 따른다는 가정에서 출발합니다.\n즉, 현재의 결과가 과거의 결과에 의존하는 경우입니다.\n\n\\[\nY_{i, t+1}(0) = \\alpha_t Y_{it}(0) + \\beta_{t+1} \\boldsymbol{Z}_{i, t+1} + u_{i, t+1}\n\\] \\[\n\\boldsymbol{Z}_{i, t+1} = \\gamma_t Y_{it}(0) + \\Pi_t \\boldsymbol{Z}_{it} + \\boldsymbol{v}_{i, t+1}\n\\]\n\n이 모형은 고정 효과(Fixed Effects) 없이도, 과거의 결과값(\\(Y_{it}\\))과 공변량(\\(Z\\))을 완벽하게 매칭하면 미래의 경로도 예측할 수 있음을 시사합니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#scm의-추정-성질-scm-properties",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#scm의-추정-성질-scm-properties",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "3.2 SCM의 추정 성질 (SCM Properties)",
    "text": "3.2 SCM의 추정 성질 (SCM Properties)\n\n위의 모형들 하에서, 만약 우리가 개입 이전 기간의 결과(\\(Y\\))와 공변량(\\(Z\\))을 완벽하게 균형 맞추는 가중치 \\(w^*\\)를 찾을 수 있다면 다음과 같은 성질이 성립합니다.\n\n\\[\n\\sum_{j=2}^{J+1} w_j^* Y_{jt} = Y_{1t} \\quad \\text{and} \\quad \\sum_{j=2}^{J+1} w_j^* \\boldsymbol{Z}_j = \\boldsymbol{Z}_1\n\\]\n\n이 조건이 충족될 때, 개입 이후 시점(\\(t &gt; T_0\\))에 대한 반사실 추정량 \\(\\hat{Y}_{1t}(0)\\)은 다음과 같은 특징을 가집니다.\n\n\nUnder Model 1 (점근적 일치성):\n\n개입 이전 기간(\\(T_0\\))이 길어질수록(\\(T_0 \\to \\infty\\)), 편향(Bias)이 0으로 수렴합니다.\n즉, \\(\\hat{Y}_{1t}(0) \\to Y_{1t}(0)\\)이 되어, 과거 데이터를 길게 확보할수록 추정이 정확해집니다.\n\nUnder Model 2 (비편향성):\n\n자기회귀 모형 하에서는 단기간의 개입 이전 데이터만으로도 비편향 추정량(\\(\\mathbb{E}[\\hat{Y}_{1t}(0)] = \\mathbb{E}[Y_{1t}(0)]\\))을 얻을 수 있습니다.\n\n\n\n결론적으로 SCM은 “과거의 궤적(Trajectory)을 오랫동안, 그리고 정확하게 흉내 낼 수 있다면 미래의 궤적 또한 신뢰할 수 있다”는 수학적 보장을 가지고 있습니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#볼록성convexity의-기하학적-의미",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#볼록성convexity의-기하학적-의미",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "3.3 볼록성(Convexity)의 기하학적 의미",
    "text": "3.3 볼록성(Convexity)의 기하학적 의미\n\nSCM은 데이터를 ‘섞어서’ 만드는 것이므로 기하학적으로는 다면체 내부의 한 점을 찾는 것과 같습니다.\n\n\n\n\nFigure: \\(X_1\\)(검은 점)을 \\(X_0\\)(빨간 점들)의 조합으로 표현할 때, \\(X_1\\)이 빨간 점들이 이루는 다면체(Triangle) 내부에 있어야 안전한 추론(Interpolation)이 가능합니다. 외부에 있다면 SCM 적용에 주의가 필요합니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#편향-보정-bias-correction",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#편향-보정-bias-correction",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "4.1 편향 보정 (Bias Correction)",
    "text": "4.1 편향 보정 (Bias Correction)\n\n현실에서는 개입 이전 기간(\\(T_0\\))에도 처치 집단과 합성 대조군이 완벽하게 일치하지 않을 수 있습니다(Imperfect Pre-treatment Fit).\n이 경우 추정치에 편향이 발생합니다.\n이를 해결하기 위해 Augmented SCM (ASCM)이 제안되었습니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-03/index.html#ascm-공식",
    "href": "posts/lecture/L15/causal-inference-15-part-03/index.html#ascm-공식",
    "title": "[Causal Inference] 15. DiD & SCM (Part 3)",
    "section": "4.2 ASCM 공식",
    "text": "4.2 ASCM 공식\n\nASCM은 기존 SCM 추정치에 회귀분석을 이용한 보정항을 추가합니다. \\[\n\\hat{Y}_{1t}^{aug}(0) = \\underbrace{\\sum_{j=2}^{J+1} w_j Y_{jt}}_{\\text{Original SCM}} + \\underbrace{\\left( \\hat{m}_{1t} - \\sum_{j=2}^{J+1} w_j \\hat{m}_{jt} \\right)}_{\\text{Bias Correction}}\n\\]\n\n\\(\\hat{m}_{it}\\): 공변량 등을 이용해 예측한 결과값 (Ridge Regression 등을 사용)\n이 보정항은 합성 대조군이 설명하지 못하는 잔여 차이를 회귀 모델로 메꿔주는 역할을 합니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-01/index.html",
    "href": "posts/lecture/L04/causal-inference-04-part-01/index.html",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 1)",
    "section": "",
    "text": "이번 포스트에서는 인과추론에서 가장 핵심적인 개념 중 하나인 교란(Confounding)과 이를 해결하기 위한 백도어 기준(Back-door Criterion)으로 나아가기 전, 식별 가능성(Identification Problem)에 대해 다시 한번 짚어보고자 합니다.\n강의 자료는 서울대학교 데이터사이언스대학원 이상학 교수님의 “Confounding and Backdoor” 수업 자료를 바탕으로 합니다\n\n\n\nRecap(Identification Problem) and Example of Identifiable and Non-identifiable Effects\nConfounding Bias\nBack-door Criterion\nEvaluation"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-01/index.html#목차",
    "href": "posts/lecture/L04/causal-inference-04-part-01/index.html#목차",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 1)",
    "section": "",
    "text": "Recap(Identification Problem) and Example of Identifiable and Non-identifiable Effects\nConfounding Bias\nBack-door Criterion\nEvaluation"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-01/index.html#설정-setup",
    "href": "posts/lecture/L04/causal-inference-04-part-01/index.html#설정-setup",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 1)",
    "section": "4.1 설정 (Setup)",
    "text": "4.1 설정 (Setup)\n아래와 같은 “Bow-tie” 형태의 그래프를 고려합니다. 여기서 \\(U_{XY}\\)는 \\(X\\)와 \\(Y\\)에 동시에 영향을 주는 관측되지 않은 교란 변수(Unobserved Confounder)입니다.\n\n\n\nFigure 3. Causal Graph with Unobserved Confounder\n\n\n두 모델 \\(\\mathcal{H}^{(1)}\\)과 \\(\\mathcal{H}^{(2)}\\)는 다음과 같은 구조적 방정식(Structural Equations)을 갖습니다. 여기서 \\(U_Y, U_{XY}\\)는 모두 베르누이 분포(동전 던지기, \\(p=0.5\\))를 따릅니다.\n\n4.1.1 Model 1 (\\(\\mathcal{H}^{(1)}\\))\n\\[\n\\begin{cases}\nX \\leftarrow U_{XY} \\\\\nY \\leftarrow (X \\oplus U_{XY}) \\lor U_Y\n\\end{cases}\n\\] * 여기서 \\(\\oplus\\)는 XOR 연산, \\(\\lor\\)는 OR 연산을 의미합니다.\n\n\n4.1.2 Model 2 (\\(\\mathcal{H}^{(2)}\\))\n\\[\n\\begin{cases}\nX \\leftarrow U_{XY} \\\\\nY \\leftarrow U_Y\n\\end{cases}\n\\] * 모델 2에서는 \\(X\\)가 \\(Y\\)에 아무런 영향을 주지 않습니다 (끊어진 인과 관계)."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-01/index.html#관측-분포의-일치-observational-equivalence",
    "href": "posts/lecture/L04/causal-inference-04-part-01/index.html#관측-분포의-일치-observational-equivalence",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 1)",
    "section": "4.2 관측 분포의 일치 (Observational Equivalence)",
    "text": "4.2 관측 분포의 일치 (Observational Equivalence)\n놀랍게도 두 모델은 관측 데이터 상으로는 완벽하게 동일합니다.\n\nModel 1의 경우: 구조 방정식을 보면 \\(X\\)는 \\(U_{XY}\\)와 같습니다. 따라서 \\(X \\oplus U_{XY}\\)는 항상 \\(0\\)이 됩니다 (\\(X\\)와 \\(U_{XY}\\)가 같으므로). \\[Y = 0 \\lor U_Y = U_Y\\] 결국 관측 환경에서는 \\(Y\\)가 오직 \\(U_Y\\)에 의해서만 결정됩니다\nModel 2의 경우: 정의상 \\(Y \\leftarrow U_Y\\)이므로, 역시 \\(Y\\)는 \\(U_Y\\)에 의해 결정됩니다.\n\n결과적으로 두 모델 모두 \\(P(Y=1) = P(U_Y=1) = 0.5\\)이며, \\(X\\)와 \\(Y\\)의 결합 분포 표(Truth Table)도 완전히 일치합니다\n\n\n\n\n\n\n\n\n\n\n\\(U_Y\\)\n\\(U_{XY}\\) (\\(=X\\))\n\\(Y^{(1)}\\) (Model 1)\n\\(Y^{(2)}\\) (Model 2)\n\\(P(u)\\)\n\n\n\n\n0\n0\n0\n0\n1/4\n\n\n0\n1\n0\n0\n1/4\n\n\n1\n0\n1\n1\n1/4\n\n\n1\n1\n1\n1\n1/4"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-01/index.html#인과-효과의-불일치-interventional-differences",
    "href": "posts/lecture/L04/causal-inference-04-part-01/index.html#인과-효과의-불일치-interventional-differences",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 1)",
    "section": "4.3 인과 효과의 불일치 (Interventional Differences)",
    "text": "4.3 인과 효과의 불일치 (Interventional Differences)\n이제 \\(do(x)\\) 연산을 통해 실제로 인과 효과를 계산해 보면 두 모델의 차이가 드러납니다. \\(do(x)\\)는 \\(X\\)를 강제로 특정 값으로 고정하는 것이므로, 더 이상 \\(X\\)는 \\(U_{XY}\\)의 영향을 받지 않습니다.\n\n\n\nFigure 4. Causal Graph with Unobserved Confounder\n\n\n우리는 \\(P(y=1 | do(x=0))\\)을 계산해 보겠습니다\n\n4.3.1 Case 1: Model \\(\\mathcal{H}^{(1)}\\)\n구조 방정식: \\(Y \\leftarrow (x \\oplus U_{XY}) \\lor U_Y\\). 여기서 \\(x=0\\)으로 고정했습니다.\n\n\\(U_{XY}=0, U_Y=0 \\Rightarrow Y = (0 \\oplus 0) \\lor 0 = 0\\)\n\\(U_{XY}=0, U_Y=1 \\Rightarrow Y = (0 \\oplus 0) \\lor 1 = 1\\) (\\(U_Y=1\\) 이면 어차피 \\(Y=1\\))\n\\(U_{XY}=1, U_Y=0 \\Rightarrow Y = (0 \\oplus 1) \\lor 0 = 1\\) (\\(U_{XY}=1 \\nRightarrow X=1\\) 이므로, 여기서 차이 발생!)\n\\(U_{XY}=1, U_Y=1 \\Rightarrow Y = (0 \\oplus 1) \\lor 1 = 1\\) (\\(U_Y=1\\) 이면 어차피 \\(Y=1\\))\n\n4가지 경우 중 3가지 경우에 \\(Y=1\\)이 됩니다. \\[\\therefore P^{(1)}(y=1|do(x=0)) = \\frac{3}{4}\\]\n\n\n4.3.2 Case 2: Model \\(\\mathcal{H}^{(2)}\\)\n구조 방정식: \\(Y \\leftarrow U_Y\\). \\(X\\)의 값과 상관없이 \\(Y\\)는 \\(U_Y\\)를 따릅니다.\n\n\\(U_Y=0 \\Rightarrow Y=0\\)\n\\(U_Y=1 \\Rightarrow Y=1\\)\n\n\\[\\therefore P^{(2)}(y=1|do(x=0)) = \\frac{1}{2}\\]"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-01/index.html#결론",
    "href": "posts/lecture/L04/causal-inference-04-part-01/index.html#결론",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 1)",
    "section": "4.4 결론",
    "text": "4.4 결론\n\n\n\n\\(Y\\)\n\\(P^{(1)}(Y|do(x))\\)\n\\(P^{(2)}(Y|do(x))\\)\n\n\n\n\n0\n\\(\\frac{1}{4}\\)\n\\(\\frac{1}{2}\\)\n\n\n1\n\\(\\frac{3}{4}\\)\n\\(\\frac{1}{2}\\)\n\n\n\n두 모델은 동일한 인과 그래프와 동일한 관측 분포 \\(P(v)\\)를 가지지만, 계산된 인과 효과 \\(P(y|do(x))\\)는 \\(\\frac{3}{4}\\)와 \\(\\frac{1}{2}\\)로 서로 다릅니다\n\nEven though both models induce \\(I\\) (Graph) and have the same \\(P(v)\\), the effect \\(P^{(1)}(y|do(x)) \\neq P^{(2)}(y|do(x))\\).\n\n이는 주어진 그래프 구조(Unobserved Confounder가 존재하는 경우)만으로는 데이터에서 인과 효과를 유일하게 식별해낼 수 없음을(Non-identifiable) 의미합니다. 이러한 경우, 추가적인 가정이나 데이터를 통한 식별 전략이 필요합니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-02/index.html",
    "href": "posts/lecture/L04/causal-inference-04-part-02/index.html",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 2)",
    "section": "",
    "text": "지난 포스트에서는 인과 효과의 식별 가능성(Identifiability)에 대해 다루었습니다. 이번에는 현실 데이터 분석에서 가장 빈번하게 마주치는 문제이자, 인과추론이 필요한 가장 큰 이유 중 하나인 교란 편향(Confounding Bias)에 대해 구체적인 예시를 통해 알아보겠습니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-02/index.html#단순-관측-직관과-반대되는-결과",
    "href": "posts/lecture/L04/causal-inference-04-part-02/index.html#단순-관측-직관과-반대되는-결과",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 2)",
    "section": "2.1 1. 단순 관측: 직관과 반대되는 결과",
    "text": "2.1 1. 단순 관측: 직관과 반대되는 결과\n\n수집한 데이터를 단순히 산점도(Scatter Plot)로 그려보았더니 놀라운 결과가 나타났습니다.\n\n\n\n\nFigure 1. Observed Correlation between Exercise and Cholesterol\n\n\n\n관측 결과: 운동을 많이 하는 사람일수록 콜레스테롤 수치가 더 높게 나타납니다.\n의문: \\(P(\\text{cholesterol} | \\text{exercise})\\)를 보면, 운동이 콜레스테롤을 높이는 것처럼 보입니다. 과연 “더 많은 운동 \\(\\Rightarrow\\) 콜레스테롤 증가”라고 결론 내릴 수 있을까요?"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-02/index.html#교란-변수의-발견-나이age",
    "href": "posts/lecture/L04/causal-inference-04-part-02/index.html#교란-변수의-발견-나이age",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 2)",
    "section": "2.2 2. 교란 변수의 발견: 나이(Age)",
    "text": "2.2 2. 교란 변수의 발견: 나이(Age)\n\n이 이상한 현상을 이해하기 위해, 우리는 데이터에 숨겨진 제3의 변수인 ‘나이(Age)’를 색상으로 구분하여 다시 시각화해보았습니다.\n\n\n\n\nFigure 2. Scatter Plot Stratified by Age\n\n\n\n그래프를 자세히 보면 다음과 같은 패턴이 드러납니다:\n\n나이와 운동: 나이가 많은 사람(노란색 계열)들이 건강 관리를 위해 운동을 더 많이 하는 경향이 있습니다.\n나이와 콜레스테롤: 동시에, 나이가 많을수록 자연적으로 콜레스테롤 수치가 높습니다.\n\n즉, ‘나이’가 운동량(\\(X\\))과 콜레스테롤(\\(Y\\)) 모두에 영향을 미치는 교란 변수(Confounder)로 작용하고 있었던 것입니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-02/index.html#계층별-분석-인과-효과의-확인",
    "href": "posts/lecture/L04/causal-inference-04-part-02/index.html#계층별-분석-인과-효과의-확인",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 2)",
    "section": "2.3 3. 계층별 분석: 인과 효과의 확인",
    "text": "2.3 3. 계층별 분석: 인과 효과의 확인\n\n이제 나이(Age)를 고정한 상태에서 운동과 콜레스테롤의 관계를 다시 살펴봅시다.\n\n\n\n\nFigure 3. True Causal Effect within Age Groups\n\n\n\n각 연령대 그룹(같은 색깔) 내부를 들여다보면, 운동을 많이 할수록 콜레스테롤 수치가 낮아지는 것을 명확히 볼 수 있습니다.\n결론: 운동의 진짜 인과 효과는 콜레스테롤을 낮추는 것입니다. (\\(More\\ exercise \\Rightarrow Lower\\ Cholesterol\\))"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-02/index.html#복잡한-인과-그래프에서의-문제",
    "href": "posts/lecture/L04/causal-inference-04-part-02/index.html#복잡한-인과-그래프에서의-문제",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 2)",
    "section": "4.1 복잡한 인과 그래프에서의 문제",
    "text": "4.1 복잡한 인과 그래프에서의 문제\n\n다음과 같이 복잡한 인과 그래프를 고려해 봅시다.\n\n\n\n\nFigure 4. A Complex Causal Graph\n\n\n\nGoal: 변수 \\(Z_1, ..., Z_k\\)가 측정되었을 때, \\(X\\)가 \\(Y\\)에 미치는 인과 효과 \\(Q = P(y|do(x))\\)를 찾아내는 것.\n여기서 중요한 질문이 생깁니다.\n\n“부모 변수(Parents) 중 일부만 관측되었을 때, 타겟 인과 효과 \\(Q\\)를 식별할 수 있는가?”"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-02/index.html#주의해야-할-구조-collider",
    "href": "posts/lecture/L04/causal-inference-04-part-02/index.html#주의해야-할-구조-collider",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 2)",
    "section": "4.2 주의해야 할 구조: Collider",
    "text": "4.2 주의해야 할 구조: Collider\n\n그래프 분석 시 주의해야 할 점은 단순히 모든 변수를 통제(Conditioning)한다고 좋은 것이 아니라는 점입니다.\n예를 들어 위 그래프에서 \\(Z_4\\)와 같은 변수를 살펴봅시다.\n\n\nNote: \\(Z_4\\)는 \\(Z_1\\)과 \\(Z_2\\)의 화살표를 동시에 받는 Collider (\\(Z_1 \\rightarrow Z_4 \\leftarrow Z_2\\))입니다. \\(Z_4\\)를 조건부(given)로 잡을 경우, 오히려 \\(Z_1\\)과 \\(Z_2\\) 사이에 길이 뚫리는 현상이 발생하여 새로운 편향을 만들 수 있습니다.\n\n\n따라서 우리는 어떤 변수를 조정 집합(Adjustment Set)에 넣어야 편향을 제거하고 올바른 인과 효과를 구할 수 있는지 판단하는 체계적인 기준이 필요합니다. 이것이 바로 다음 포스트에서 다룰 Back-door Criterion입니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-04/index.html",
    "href": "posts/lecture/L04/causal-inference-04-part-04/index.html",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 4)",
    "section": "",
    "text": "지난 포스트에서는 Back-door Criterion을 통해 어떤 공변량 집합 \\(Z\\)를 보정(Adjustment)해야 인과 효과 \\(P(y|do(x))\\)를 식별할 수 있는지 알아보았습니다.\n\n\\[P(y|do(x)) = \\sum_{z} P(y|x,z)P(z)\\]\n\n이번 포스트에서는 이 식을 실제 데이터(Practice)에서 어떻게 평가하고 계산하는지, 특히 계산 복잡도 문제를 해결하기 위한 Inverse Probability Weighting (IPW) 기법에 대해 다룹니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-04/index.html#derivation",
    "href": "posts/lecture/L04/causal-inference-04-part-04/index.html#derivation",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 4)",
    "section": "3.1 Derivation",
    "text": "3.1 Derivation\n\n기존의 Back-door Adjustment 식을 베이즈 정리와 결합 확률 법칙을 이용해 재구성해 봅시다.\n\n\\[\n\\begin{align}\nP(y|do(x)) &= \\sum_{z} P(y|x,z)P(z) \\\\\n&= \\sum_{z} \\frac{P(y,x,z)}{P(x,z)} P(z) \\\\\n&= \\sum_{z} \\frac{P(y,x,z)}{P(x|z)P(z)} P(z) \\\\\n&= \\sum_{z} \\frac{P(y,x,z)}{P(x|z)} \\quad\n\\end{align}\n\\]\n\n이제 우리는 \\(P(z)\\)를 따로 추정하거나 모든 \\(z\\)에 대해 합을 구할 필요 없이, 결합 확률 \\(P(y,x,z)\\)를 \\(P(x|z)\\)로 나눈 형태로 식을 단순화했습니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-04/index.html#propensity-score-gz",
    "href": "posts/lecture/L04/causal-inference-04-part-04/index.html#propensity-score-gz",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 4)",
    "section": "3.2 Propensity Score \\(g(z)\\)",
    "text": "3.2 Propensity Score \\(g(z)\\)\n\n위 식의 분모에 있는 \\(P(x|z)\\)는 공변량 \\(Z\\)가 주어졌을 때 원인 변수 \\(X\\)가 할당될 확률을 의미하며, 이를 Propensity Score라고 부릅니다.\n보통 \\(g(z)\\)로 표기하며 로지스틱 회귀(Logistic Regression) 등의 모델을 사용하여 추정합니다.\n\n\\[g(z) = P(X=x|Z=z)\\]"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-04/index.html#핵심-포인트",
    "href": "posts/lecture/L04/causal-inference-04-part-04/index.html#핵심-포인트",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 4)",
    "section": "4.1 핵심 포인트",
    "text": "4.1 핵심 포인트\n\n\\(\\mathbb{1}(\\cdot)\\) (Indicator Function): 조건이 참이면 1, 거짓이면 0을 반환하는 함수입니다.\n시간 복잡도 \\(O(N)\\): 가장 마지막 식을 보면, 더 이상 \\(Z\\)의 모든 조합에 대해 합을 구할 필요가 없습니다. 단순히 관측된 \\(N\\)개의 데이터 샘플을 한 번씩만 순회하며 가중치(\\(1/g(z_i)\\))를 더하면 계산이 끝납니다. 이것이 IPW가 강력한 이유입니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-04/index.html#시간-복잡도의-개선",
    "href": "posts/lecture/L04/causal-inference-04-part-04/index.html#시간-복잡도의-개선",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 4)",
    "section": "4.2 시간 복잡도의 개선",
    "text": "4.2 시간 복잡도의 개선\n\n이 방식의 가장 큰 장점은 계산 효율성입니다.\n고차원 \\(Z\\)에 대해 적분하거나 합을 구하는 대신, 샘플 수 \\(N\\)에 비례하는 선형 시간(\\(O(N)\\)) 만에 계산이 가능합니다."
  },
  {
    "objectID": "posts/lecture/L16/part-05/index.html",
    "href": "posts/lecture/L16/part-05/index.html",
    "title": "[Causal Inference] 16. Causal Discovery (Part 5)",
    "section": "",
    "text": "인과 추론(Causal Inference)에서 가장 근본적인 질문 중 하나는 “상관관계는 인과관계가 아니다”라는 명제에서 출발합니다. 두 변수 \\(X\\)와 \\(Y\\)가 통계적으로 종속되어 있을 때, 우리는 이것이 \\(X \\to Y\\) 때문인지, \\(Y \\to X\\) 때문인지, 혹은 잠재적 교란 변수(confounder) 때문인지 데이터만으로는 완벽하게 구분하기 어렵습니다.\n[cite_start]기존의 Constraint-based approach (예: PC algorithm)는 조건부 독립성 검정(Conditional Independence Test)을 통해 인과 그래프의 뼈대(Skeleton)와 V-structure를 찾아내지만, Markov Equivalence Class에 속하는 그래프들(같은 조건부 독립성을 가지는 그래프들) 사이에서는 방향을 결정할 수 없다는 한계가 있습니다 [cite: 1-11].\n이번 포스트에서는 이러한 한계를 극복하기 위해 함수적 인과 모델(Functional Causal Models, FCM)을 다룹니다. 이 방법론들은 데이터 생성 과정(Data Generating Process)에 대한 추가적인 가정(비선형성 또는 비정규성)을 도입하여, \\(X \\to Y\\)와 \\(Y \\to X\\)의 비대칭성(Asymmetry)을 찾아냅니다.\n\n\n\nFigure: 인과 방향의 식별 문제. 왼쪽은 \\(X \\to Y\\), 오른쪽은 \\(Y \\to X\\)를 나타낸다. 단순히 두 변수의 결합 분포만 보아서는(가운데 VS), 두 인과 구조를 구별하기 어려운 경우가 많다."
  },
  {
    "objectID": "posts/lecture/L16/part-05/index.html#the-concept",
    "href": "posts/lecture/L16/part-05/index.html#the-concept",
    "title": "[Causal Inference] 16. Causal Discovery (Part 5)",
    "section": "2.1 The Concept",
    "text": "2.1 The Concept\n두 변수 \\(X, Y\\)에 대해 다음과 같은 가법 잡음 모델(ANM)을 가정해 봅시다.\n\\[y = f_y(x) + u_y \\quad \\text{where} \\quad x \\perp\\!\\!\\perp u_y\\]\n[cite_start]여기서 핵심 아이디어는 “올바른 인과 방향으로 모델을 적합하면 잡음(Residual)이 원인 변수와 독립이지만, 반대 방향으로 적합하면 독립이 성립하지 않는다”는 것입니다 [cite: 96-105].\n만약 실제 데이터 생성 과정이 \\(X \\to Y\\)라면: 1. Hypothesis 1 (\\(X \\to Y\\)): \\(y = f_y(x) + u_y\\) 로 모델링했을 때, 잔차 \\(\\hat{u}_y\\)는 \\(x\\)와 독립입니다 (\\(x \\perp\\!\\!\\perp u_y\\)). 2. Hypothesis 2 (\\(Y \\to X\\)): 반대로 \\(x = g_x(y) + u_x\\) 로 모델링하면, 일반적으로 잔차 \\(\\hat{u}_x\\)는 \\(y\\)와 독립이지 않습니다 (\\(y \\not\\perp\\!\\!\\perp u_x\\)).\n[cite_start]이 비대칭성은 \\(f\\)가 비선형(Non-linear)일 때 대부분 성립합니다[cite: 128].\n\n\n\nFigure: ANM의 작동 원리. (상단) 실제 인과 관계가 \\(X \\to Y\\)일 때 비선형 함수를 적합하면 잔차가 \\(X\\)와 독립적이다. (하단) 반대로 \\(Y \\to X\\)로 가정하고 적합하면, 잔차의 분포가 \\(Y\\)의 값에 따라 달라지는(종속적인) 패턴을 보인다."
  },
  {
    "objectID": "posts/lecture/L16/part-05/index.html#algorithm",
    "href": "posts/lecture/L16/part-05/index.html#algorithm",
    "title": "[Causal Inference] 16. Causal Discovery (Part 5)",
    "section": "2.2 Algorithm",
    "text": "2.2 Algorithm\n[cite_start]ANM을 이용한 인과 발견 알고리즘은 다음과 같이 수행됩니다 [cite: 200-211]:\n\nFit Forward: 데이터 \\((x_i, y_i)\\)에 대해 \\(y\\)를 \\(x\\)의 함수로 회귀분석하여 \\(\\hat{f}_y\\)를 구합니다. (좋아하는 ML 알고리즘 사용 가능)\nCompute Residuals: \\(\\hat{u}_y = y - \\hat{f}_y(x)\\)를 계산합니다.\nTest Independence: \\(\\hat{u}_y\\)와 \\(x\\)가 독립인지 검정합니다 (예: HSIC test).\nFit Backward: 반대로 \\(x\\)를 \\(y\\)의 함수로 회귀분석하여 \\(\\hat{f}_x\\)를 구하고, 잔차 \\(\\hat{u}_x = x - \\hat{f}_x(y)\\)를 계산합니다.\nTest Independence: \\(\\hat{u}_x\\)와 \\(y\\)가 독립인지 검정합니다.\nDecide: 한쪽 방향만 독립성이 성립하면 그 방향을 인과 방향으로 채택합니다."
  },
  {
    "objectID": "posts/lecture/L16/part-05/index.html#extension-post-nonlinear-pnl-model",
    "href": "posts/lecture/L16/part-05/index.html#extension-post-nonlinear-pnl-model",
    "title": "[Causal Inference] 16. Causal Discovery (Part 5)",
    "section": "2.3 Extension: Post-Nonlinear (PNL) Model",
    "text": "2.3 Extension: Post-Nonlinear (PNL) Model\nANM은 관측된 변수에 노이즈가 직접 더해진다고 가정합니다. [cite_start]이를 더 일반화한 것이 Post-Nonlinear Model (PNL)입니다 [cite: 226-228].\n\\[x_2 = f_2(f_1(x_1) + e_2)\\]\n여기서 \\(f_2\\)는 역함수가 존재하는(invertible) 함수라고 가정합니다. [cite_start]이 경우 노이즈 \\(e_2\\)는 다음과 같이 표현됩니다[cite: 234]:\n\\[e_2 = f_2^{-1}(x_2) - f_1(x_1)\\]\n[cite_start]이 모델의 식별(Identifiability)은 \\(x_1\\)과 추정된 잔차 \\(\\hat{e}_2\\) 사이의 상호정보량(Mutual Information)을 최소화하는 문제, 즉 Constrained Nonlinear ICA 문제로 귀결됩니다 [cite: 243-244].\n\\[I(x_1, \\hat{e}_2) = -\\mathbb{E}\\log p_{\\hat{e}_2}(\\hat{e}_2) - \\mathbb{E}\\log|l'_2(x_2)| + H(x_1) - H(x_1, x_2)\\]\n여기서 \\(l_2\\)는 \\(f_2^{-1}\\)에 대응하는 함수입니다. [cite_start]Zhang and Hyvarinen (2009)은 아주 특수한 경우를 제외하고는 PNL 모델이 식별 가능함을 보였습니다[cite: 246]."
  },
  {
    "objectID": "posts/lecture/L16/part-05/index.html#why-non-gaussian",
    "href": "posts/lecture/L16/part-05/index.html#why-non-gaussian",
    "title": "[Causal Inference] 16. Causal Discovery (Part 5)",
    "section": "3.1 Why Non-Gaussian?",
    "text": "3.1 Why Non-Gaussian?\n선형 모델 \\(Y = bX + \\epsilon\\)과 \\(X = b_Y Y + \\epsilon_Y\\)를 생각해 봅시다. 만약 \\(X\\)와 \\(\\epsilon\\)이 모두 Gaussian(정규분포)이라면, 결합 분포 \\(P(X, Y)\\)는 다변량 정규분포가 됩니다. 다변량 정규분포는 대칭적인 타원 형태를 띠기 때문에, \\(X\\)축을 기준으로 보나 \\(Y\\)축을 기준으로 보나 구조적 차이를 발견할 수 없습니다. [cite_start]즉, Gaussian case는 식별 불가능(Unidentifiable)합니다 [cite: 276, 296-298].\n하지만 변수들이 Non-Gaussian(예: Uniform, Super-Gaussian)이라면 이야기가 달라집니다. 결합 분포의 형태가 한쪽 방향으로는 독립성을 유지하지만, 역방향으로는 찌그러지거나 종속적인 패턴을 보이게 됩니다.\n\n\n\nFigure: Gaussian vs Non-Gaussian의 식별 가능성. (Case 1) 데이터가 Gaussian일 때는 회귀선을 어느 방향으로 그어도 잔차 분포가 대칭적이라 구별이 불가능하다. (Case 2, 3) 데이터가 Uniform이나 Super-Gaussian일 때는, 올바른 인과 방향(\\(X \\to Y\\))에서의 잔차는 독립적이지만, 역방향의 잔차는 명확한 종속성을 보인다."
  },
  {
    "objectID": "posts/lecture/L16/part-05/index.html#mathematical-formulation",
    "href": "posts/lecture/L16/part-05/index.html#mathematical-formulation",
    "title": "[Causal Inference] 16. Causal Discovery (Part 5)",
    "section": "3.2 Mathematical Formulation",
    "text": "3.2 Mathematical Formulation\n[cite_start]LiNGAM은 데이터를 다음과 같은 행렬 형태로 모델링합니다 [cite: 368-372]. 변수 벡터를 \\(x\\), 인접 행렬(Adjacency Matrix)을 \\(B\\), 외생 잡음 벡터를 \\(e\\)라고 할 때:\n\\[x = Bx + e\\]\n이 식을 \\(x\\)에 대해 정리하면 다음과 같습니다:\n\\[(I - B)x = e\\] \\[x = (I - B)^{-1}e\\]\n여기서 \\(B\\)는 인과 그래프가 DAG(Directed Acyclic Graph)이므로, 변수들을 인과 순서(Topological order)대로 재배열하면 Strictly Lower Triangular Matrix가 될 수 있습니다. 이는 \\(I-B\\)가 역행렬을 가짐을 보장합니다."
  },
  {
    "objectID": "posts/lecture/L16/part-05/index.html#the-ica-connection-the-trick",
    "href": "posts/lecture/L16/part-05/index.html#the-ica-connection-the-trick",
    "title": "[Causal Inference] 16. Causal Discovery (Part 5)",
    "section": "3.3 The ICA Connection (The “Trick”)",
    "text": "3.3 The ICA Connection (The “Trick”)\n[cite_start]위 식 \\(x = (I - B)^{-1}e\\)를 자세히 보면, 이는 독립 성분 분석(Independent Component Analysis, ICA)의 기본 문제와 동일합니다 [cite: 316-322].\nICA 모델은 관측된 신호 \\(x\\)가 서로 독립인 원천 신호 \\(s\\)들의 선형 결합 \\(x = As\\)로 이루어져 있다고 봅니다. LiNGAM에서는: * 관측 신호 \\(x\\): 데이터 변수들 * 원천 신호 \\(s\\): 서로 독립인 오차항 \\(e\\) (비정규분포 가정) * Mixing Matrix \\(A\\): \\((I - B)^{-1}\\)\n[cite_start]따라서, ICA 알고리즘을 \\(x\\)에 적용하면 Mixing Matrix \\(A\\)를 추정할 수 있고, 이를 통해 \\(B\\)를 역산할 수 있습니다 [cite: 363-365]."
  },
  {
    "objectID": "posts/lecture/L16/part-05/index.html#lingam-algorithm-steps",
    "href": "posts/lecture/L16/part-05/index.html#lingam-algorithm-steps",
    "title": "[Causal Inference] 16. Causal Discovery (Part 5)",
    "section": "3.4 LiNGAM Algorithm Steps",
    "text": "3.4 LiNGAM Algorithm Steps\n[cite_start]Shimizu (2006)가 제안한 LiNGAM 알고리즘의 핵심 단계는 다음과 같습니다 [cite: 375-391]:\n\nICA Execution: 데이터 행렬 \\(X\\)에 대해 ICA를 수행하여 \\(X = W_{ICA}^{-1} S\\) 꼴의 분해를 얻습니다. 여기서 \\(S\\)는 독립 성분(오차항 추정치)입니다.\nPermutation & Scaling: ICA는 성분의 순서(Permutation)와 스케일(Scaling)을 결정하지 못하는 불확정성이 있습니다.\n\n\\(W_{ICA}\\)의 행을 재배열(Permute)하고 스케일링하여, 대각 성분이 모두 0이 아닌 행렬 \\(\\tilde{W}\\)를 만듭니다.\nLiNGAM의 가정(\\(x = Bx + e\\))에 맞추기 위해, \\(I - B\\) 형태가 되도록 정규화합니다.\n\nRecover B: 최종적으로 \\(B = I - W_{final}\\)을 계산합니다.\nCausal Order: \\(B\\)가 하삼각행렬(Lower Triangular)에 가깝도록 변수 순서를 재배열하면 인과 순서(Causal Order)를 얻을 수 있습니다.\n\n\n\n\nFigure: LiNGAM의 도식적 이해. 관측된 변수 \\(x_1, x_2, x_3\\)는 독립적인 에러 \\(e_1, e_2, e_3\\)들의 선형 결합으로 표현된다. ICA를 통해 섞여 있는 에러들을 분리해냄으로써 원래의 인과 구조인 화살표 방향을 역추적한다."
  },
  {
    "objectID": "posts/lecture/L16/part-05/index.html#score-matching-and-leaf-identification",
    "href": "posts/lecture/L16/part-05/index.html#score-matching-and-leaf-identification",
    "title": "[Causal Inference] 16. Causal Discovery (Part 5)",
    "section": "4.1 Score Matching and Leaf Identification",
    "text": "4.1 Score Matching and Leaf Identification\nMontagna et al. (2023)[cite_start]은 Score Matching 기법을 사용하여 잎 노드(Leaf node, 자식이 없는 노드)를 식별하는 방법을 제안했습니다 [cite: 406-410].\n\nKey Idea: ANM \\(X_i = f_i(PA_i) + N_i\\) 에서, 어떤 노드 \\(X_i\\)가 Leaf라면, 해당 노드의 잡음 \\(N_i\\)는 해당 노드의 점수 함수(Score function, \\(\\nabla \\log p(X)\\))와 직접적인 관련이 있습니다.\n[cite_start]구체적으로, \\(X_i\\)가 Leaf일 필요충분조건은 다음과 관련된 기댓값이 0이 되는 것입니다[cite: 420]: \\[X_i \\text{ is a leaf} \\iff \\mathbb{E}[(h^*(R_i) - s_i(X))^2] = 0\\] 여기서 \\(s_i(X)\\)는 Score function의 성분이며, \\(R_i\\)는 회귀 잔차입니다.\n\n이 성질을 이용하면 전체 그래프에서 Leaf를 하나씩 찾아 제거(peeling)해 나가는 방식으로 인과 순서(Topological Sort)를 복원할 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L16/part-03/index.html",
    "href": "posts/lecture/L16/part-03/index.html",
    "title": "[Causal Inference] 16. Causal Discovery (Part 3)",
    "section": "",
    "text": "1. Introduction\n이전 포스트에서 다룬 PC Algorithm은 Causal Discovery의 기념비적인 알고리즘이지만, 현실 데이터에 적용할 때는 몇 가지 강력한 가정과 구조적 한계에 부딪힙니다.\n\nFaithfulness Violation: 데이터가 완벽하게 Faithful 하지 않다면 잘못된 V-structure를 학습할 수 있습니다.\nOrder Dependency: 변수의 입력 순서에 따라 결과 그래프가 달라지는 불안정성이 존재합니다.\nCausal Sufficiency: 관측되지 않은 교란 변수(Latent Confounder)가 존재할 경우, DAG 모델로 이를 표현할 수 없습니다.\n\n[cite_start]이번 포스트에서는 이러한 문제들을 해결하기 위해 제안된 PC 알고리즘의 확장판들(Conservative PC, Order-Independent PC)과, Causal Sufficiency 가정을 완화한 FCI 알고리즘에 대해 다룹니다[cite: 648, 677, 705].\n\n\n\n2. Conservative PC (CPC)\n[cite_start]Ramsey, Spirtes, Zhang (2006)이 제안한 Conservative PC (CPC) 알고리즘은 Faithfulness 가정의 위배에 강건(Robust)하도록 설계되었습니다[cite: 649].\n\n2.1 Decomposition of Faithfulness\n[cite_start]CPC는 Faithfulness 가정을 두 가지로 세분화하여 접근합니다[cite: 650, 654].\n\nAdjacency Faithfulness: 두 변수가 인접해 있다면(Adjacent), 어떠한 조건부 집합(Separator)으로도 독립이 되지 않는다.\n\n위배 시: 실제로는 엣지가 있는데 데이터상에서 독립으로 나타나 엣지가 사라지는 문제 발생.\n\nOrientation Faithfulness:\n\n[cite_start]만약 \\(X \\rightarrow Z \\leftarrow Y\\) (Unshielded Collider)라면, \\(Z\\)를 포함하는 \\(V \\setminus \\{X, Y\\}\\)의 모든 부분집합에 대해 \\(X\\)와 \\(Y\\)는 종속적이어야 한다[cite: 655].\n[cite_start]그렇지 않다면(Non-collider), \\(Z\\)를 포함하는 어떠한 분리 집합(Separator)도 \\(X\\)와 \\(Y\\)를 분리하지 못해야 한다(즉, 분리 집합은 \\(Z\\)를 포함해서는 안 된다)[cite: 656].\n\n\n\n\n2.2 Algorithm Logic\n기존 PC 알고리즘은 \\(X-Z-Y\\) 구조에서 \\(X\\)와 \\(Y\\)를 분리하는 단 하나의 Separator \\(S\\)만 찾으면, \\(Z \\notin S\\) 여부만 확인하고 즉시 Collider 여부를 결정했습니다. 이는 데이터에 노이즈가 있거나 Faithfulness가 약하게 위배될 때 오류를 범할 수 있습니다.\n[cite_start]CPC는 이를 보완하기 위해 모든 가능한 부분집합을 확인합니다[cite: 663].\n\n\\(X\\)와 \\(Y\\)의 잠재적 부모(neighbors)들의 모든 부분집합을 검사하여 \\(X\\)와 \\(Y\\)를 독립시키는 집합들을 찾습니다.\nDecision Rule:\n\n[cite_start]Collider (\\(X \\rightarrow Z \\leftarrow Y\\)): 발견된 모든 Separator \\(S\\)가 \\(Z\\)를 포함하지 않는 경우[cite: 664].\n[cite_start]Non-Collider: 발견된 모든 Separator \\(S\\)가 \\(Z\\)를 포함하는 경우[cite: 665].\nUnfaithful (Ambiguous): 어떤 Separator는 \\(Z\\)를 포함하고, 어떤 것은 포함하지 않는 경우. [cite_start]이 경우 해당 Triple은 “Unfaithful”로 마킹하고 방향을 결정하지 않습니다[cite: 666].\n\n\n\n\n\nFigure 1: CPC의 결과 예시. 그래프상의 밑줄(또는 X표시)된 부분은 알고리즘이 “Unfaithful”하다고 판단하여 방향을 결정하지 않고 남겨둔 Unshielded Triple을 나타낸다.\n\n\n[cite_start]이러한 보수적인 접근을 통해 CPC는 방향성 결정 오류를 줄이고 더 신뢰할 수 있는 골격(Skeleton)과 방향을 제시합니다[cite: 669].\n\n\n\n\n3. Order-Independent PC\n\n3.1 The Problem: Variable Ordering\n표준 PC 알고리즘은 변수의 순서(Variable Ordering)에 민감합니다. 알고리즘이 \\(X_1, X_2, \\dots, X_n\\) 순서로 엣지 삭제를 검토한다고 할 때, 초기에 \\(X_1\\) 관련 엣지가 삭제되면 \\(X_1\\)은 더 이상 다른 변수의 Separator 후보가 될 수 없습니다. [cite_start]즉, 엣지를 즉시 삭제(Remove immediately)하는 방식 때문에, 변수를 어떤 순서로 입력하느냐에 따라 최종 그래프의 골격(Skeleton)이 달라질 수 있습니다[cite: 679, 680].\n[cite_start]이로 인해 잘못된 독립성 검정 결과(False Negative)가 발생하면 오류가 파급될 수 있습니다[cite: 686].\n\n\n\nFigure 2: 변수 순서에 따른 PC 알고리즘 결과의 불안정성. y축은 서로 다른 변수 정렬(ordering)을 나타내며, x축은 엣지의 존재 여부이다. 동일한 데이터임에도 변수 순서만 바꾸면 검은색 띠(발견된 엣지)의 패턴이 달라지는 것을 볼 수 있다.\n\n\n\n\n3.2 Solution: PC-Stable & Majority Rule\n[cite_start]Colombo와 Maathuis (2014)는 이를 해결하기 위해 Order-Independent PC (PC-Stable)를 제안했습니다[cite: 684, 700].\n\nPC-Stable (Stable Edge Removal):\n\n특정 단계(Separation set 크기 \\(k\\))가 진행되는 동안에는, 발견된 독립성에 의해 엣지를 삭제하더라도 즉시 그래프에서 지우지 않고 마킹만 해둡니다.\n\\(k\\) 단계의 모든 변수 쌍에 대한 검사가 끝난 뒤에 일괄적으로 엣지를 삭제합니다.\n[cite_start]이렇게 하면 해당 단계 내에서는 모든 변수가 동등한 Separator 후보 자격을 유지하므로 순서 의존성이 사라집니다[cite: 701].\n\nMajority Rule:\n\n[cite_start]CPC가 너무 보수적(Restrictive)이라 방향을 거의 결정하지 못하는 경우를 대비해, “Unfaithful”로 마킹하는 대신 다수결 원칙(Majority-rule)을 적용하여 더 많이 지지되는 쪽으로 방향을 결정하는 방법도 제안되었습니다[cite: 702, 703].\n\n\n\n\n\n\n4. Fast Causal Inference (FCI) Algorithm\n지금까지의 알고리즘은 Causal Sufficiency (관측되지 않은 교란 변수가 없음)를 가정했습니다. 하지만 현실에서는 측정하지 못한 공통 원인 \\(U\\)가 존재하는 경우가 빈번합니다. 이 경우 PC 알고리즘은 잘못된 엣지를 그리거나 스퓨리어스 관계를 인과관계로 오인할 수 있습니다.\n\n4.1 Latent Confounders Example\n[cite_start]다음과 같은 실제 인과 구조(True Graph)가 있다고 가정해 봅시다 [cite: 707-711]. \\[X \\rightarrow Y \\leftarrow U \\rightarrow Z \\leftarrow W\\] 여기서 \\(U\\)는 관측되지 않는 Latent Variable입니다.\n\n\n\nFigure 3: Latent Confounder가 존재할 때의 구조 학습. (A) 실제 그래프에는 관측되지 않은 U가 Y와 Z에 영향을 미친다. (B) 조건부 독립성 테스트 결과로 엣지가 제거된 상태. (C) FCI 알고리즘의 결과물로, 양방향 화살표 등이 포함된 PAG 형태를 띤다.\n\n\n\nObservation: \\(Y\\)와 \\(Z\\)는 \\(U\\) 때문에 종속적입니다. 하지만 \\(U\\)를 관측할 수 없으므로, \\(Y\\)와 \\(Z\\)를 분리할 수 있는 관측 변수 집합은 존재하지 않습니다.\nResult: PC 알고리즘은 \\(Y-Z\\) 사이에 엣지가 있다고 판단할 것입니다(False Positive).\n\n\n\n4.2 FCI Output: PAGs\nFCI 알고리즘은 이러한 상황을 처리하여 PAG (Partial Ancestral Graph)를 출력합니다. [cite_start]PAG는 단순한 DAG보다 더 풍부한 엣지 정보를 담고 있습니다[cite: 725].\nEdge Meanings in PAGs: 1. [cite_start]Adjustedness (\\(X_1 \\text{ and } X_2\\) are not adjacent): 두 변수는 조건부 독립이 성립하여 엣지가 없음[cite: 728]. 2. [cite_start]Ancestral Relationship (\\(X_1 \\rightarrow X_2\\)): \\(X_1\\)은 \\(X_2\\)의 원인(Ancestror)임[cite: 738]. 3. Latent Confounding (\\(X_1 \\leftrightarrow X_2\\)): \\(X_1\\)이 \\(X_2\\)의 원인이 아니고, \\(X_2\\)도 \\(X_1\\)의 원인이 아님. [cite_start]대신 두 변수 사이에 잠재적 공통 원인(Latent Common Cause)이 존재함[cite: 741, 742]. 4. [cite_start]Uncertainty (\\(X_1 \\circ\\!\\!-\\!\\!o X_2\\)): 데이터만으로는 꼬리(Tail)인지 머리(Arrowhead)인지 확신할 수 없음 [cite: 730-733].\n[cite_start]FCI를 위 예시에 적용하면, \\(Y\\)와 \\(Z\\) 사이의 관계를 \\(Y \\leftrightarrow Z\\)로 추론하여, 직접적인 인과관계가 아니라 숨겨진 요인이 있음을 시사하게 됩니다[cite: 721].\n\n\n\n\n5. Summary & Conclusion\n[cite_start]이번 포스트에서는 Constraint-Based Structure Learning의 심화 주제들을 다루었습니다[cite: 744].\n\nConservative PC (CPC): Faithfulness 가정이 깨지는 상황을 대비해, 충돌하는 증거가 있을 때 방향 결정을 보류(Unfaithful marking)하여 강건성을 높입니다.\nOrder-Independent PC: 변수 입력 순서에 따라 결과가 바뀌는 문제를 해결하기 위해, 엣지 삭제를 단계별로 지연(Stable)시키거나 다수결 원칙을 도입합니다.\nFCI Algorithm: Causal Sufficiency 가정이 없을 때(즉, Latent Confounder가 있을 때), 이를 양방향 엣지(\\(\\leftrightarrow\\)) 등으로 표현하는 PAG를 학습합니다.\n\n[cite_start]Constraint-Based 방법론은 조건부 독립성 검정(Conditional Independence Test)이 정확하다면 이론적으로 완전(Complete)합니다[cite: 746]. [cite_start]실제 구현에서는 데이터의 특성(선형/비선형, 연속/이산)에 맞는 적절한 CI Test(Partial Correlation, Fisher’s Exact Test, Kernel-based Test 등)를 선택하는 것이 중요합니다[cite: 747].\n\n\nChecklist: Content Verification\n\nConservative PC (CPC):\n\nDefinition (Adjacency/Orientation Faithfulness): 포함됨 (Section 2.1).\nAlgorithm Logic (Check all subsets): 포함됨 (Section 2.2).\nOutcome (“Unfaithful” triple): 포함됨 (Section 2.2).\n\nOrder-Independent PC:\n\nProblem (Order dependency): 포함됨 (Section 3.1).\nSolution (Stable edge removal / Majority rule): 포함됨 (Section 3.2).\nVisual Evidence (Plot): 포함됨 (Section 3.1).\n\nFCI Algorithm:\n\nMotivation (Latent Confounder \\(U\\)): 포함됨 (Section 4.1).\nExample (\\(X \\to Y \\leftarrow U \\to Z \\leftarrow W\\)): 포함됨 (Section 4.1).\nOutput (PAGs definitions): 포함됨 (Section 4.2).\n\nSummary: 포함됨 (Section 5).\nImages: Figure 1 (CPC), Figure 2 (Order Dependency), Figure 3 (FCI) 삽입 완료.\nCitations: 각 문장 및 불릿 포인트에 형식 적용 완료."
  },
  {
    "objectID": "posts/lecture/L16/part-01/index.html",
    "href": "posts/lecture/L16/part-01/index.html",
    "title": "[Causal Inference] 16. Causal Discovery (Part 1)",
    "section": "",
    "text": "1. Introduction: Causal Inference vs. Causal Discovery\n인과추론(Causal Inference)의 세계는 크게 두 가지 연구 주제로 나뉩니다. [cite_start]우리가 흔히 접하는 인과추론은 인과 그래프(Causal Diagram, \\(\\mathcal{G}\\))가 이미 주어져 있다고 가정하고, 특정 개입(Intervention, \\(do(x)\\))이 결과에 미치는 확률분포 \\(P_x(y)\\)를 추정하는 문제입니다[cite: 12, 13, 14, 15, 19].\n하지만 현실에서는 인과 그래프 자체를 알 수 없는 경우가 많습니다. Causal Discovery (혹은 Structure Learning)는 이 역문제(Inverse Problem)를 다룹니다. [cite_start]즉, 관측된 데이터의 확률분포 \\(P(\\mathbf{V})\\)로부터 데이터 생성 과정을 가장 잘 설명하는 인과 그래프 \\(\\mathcal{G}\\)를 찾아내는 과정입니다[cite: 22, 23, 24, 25, 35].\n\n\n\nFigure 1: Causal Inference와 Causal Discovery의 차이. 왼쪽(Causal Inference)은 그래프 \\(G\\)가 주어졌을 때 \\(P(V)\\) 혹은 \\(P_x(y)\\)를 구하는 과정이고, 오른쪽(Causal Discovery)은 데이터 \\(P(V)\\)로부터 미지의 그래프 \\(G\\)를 귀납적으로 추론하는 과정이다.\n\n\n\nThe Difficulty: Correlation is not Causation\n“상관관계는 인과관계를 의미하지 않는다”는 명제는 Causal Discovery가 왜 어려운지를 단적으로 보여줍니다. [cite_start]예를 들어, ’수탉의 울음(Rooster)’과 ’일출(Sun)’이라는 두 변수가 완벽하게 상관관계를 갖는 데이터가 있다고 가정해 봅시다[cite: 29].\n데이터 테이블이 아래와 같이 주어졌을 때: \\[\n\\begin{array}{cc}\n\\text{Rooster} & \\text{Sun} \\\\\n0 & 0 \\\\\n1 & 1 \\\\\n0 & 0 \\\\\n\\vdots & \\vdots\n\\end{array}\n\\] 이 데이터만으로는 \\(Rooster \\rightarrow Sun\\)인지, \\(Sun \\rightarrow Rooster\\)인지, 아니면 제3의 요인이 둘 다를 유발하는지 구별할 수 없습니다. [cite_start]데이터 \\(P(\\mathbf{V})\\)와 호환(Consistent)되는 그래프의 후보는 여러 개가 존재할 수 있으며, Causal Discovery의 목표는 이 후보군(Equivalence Class)을 찾아내는 것입니다[cite: 30, 31, 32, 36].\n\n\n\n\n2. DAG Models & Causal Sufficiency\nCausal Discovery를 수행하기 위해서는 먼저 모델에 대한 정의와 가정이 필요합니다. [cite_start]우리는 변수 집합 \\(\\mathbf{V}\\)에 대한 인과 구조를 DAG (Directed Acyclic Graph)로 표현합니다[cite: 40, 41].\n\nDefinition: Causal Structure\n[cite_start]변수 집합 \\(\\mathbf{V}\\)의 인과 구조는 DAG로 표현되며, 각 노드는 변수에 대응하고 방향성이 있는 엣지(Edge)는 변수 간의 직접적인 함수적 관계(Direct functional relationship)를 나타냅니다[cite: 41].\n\n\nAssumption: Causal Sufficiency\n가장 강력하면서도 기본적인 가정은 Causal Sufficiency입니다. [cite_start]이는 우리가 분석하는 변수 집합 \\(\\mathbf{V}\\) 내의 변수들에 영향을 미치는 관측되지 않은 교란 변수(Unmeasured Confounder)가 존재하지 않는다는 가정입니다[cite: 43]. [cite_start]만약 이 가정이 위배된다면(즉, Latent Confounder가 있다면), 우리는 DAG 대신 양방향 엣지가 포함된 더 복잡한 그래프 모델(예: ADMG)을 고려해야 합니다[cite: 43].\n\n\n\n\n3. Connection between Graph and Distribution\n그래프 \\(\\mathcal{G}\\)와 데이터의 확률분포 \\(P(\\mathbf{V})\\)를 연결하는 세 가지 핵심 정의가 있습니다. [cite_start]DAG 모델에서는 이 세 가지가 서로 밀접하게 연관됩니다[cite: 46].\n\n\n\nFigure 2: 5개의 변수 A, B, C, D, E로 구성된 DAG 예시. A가 B와 C의 원인이 되고, B와 C가 D의 원인이 되며, D가 E의 원인이 되는 구조를 보여준다.\n\n\n\n1. Factorization (인수분해)\n[cite_start]확률분포 \\(P(\\mathbf{V})\\)는 그래프상의 부모 노드(Parents) 조건부 확률들의 곱으로 표현될 수 있습니다[cite: 52]. \\[P(A, B, C, D, E) = P(E|D)P(D|B,C)P(C|A)P(B|A)P(A)\\]\n\n\n2. Local Markov Property\n[cite_start]DAG의 각 변수는 자신의 부모가 주어졌을 때, 자신의 자손(Descendants)이 아닌 모든 변수와 조건부 독립입니다[cite: 53]. \\[(C \\perp\\!\\!\\!\\perp B \\mid A), \\quad (D \\perp\\!\\!\\!\\perp A \\mid B, C), \\quad (E \\perp\\!\\!\\!\\perp A, B, C \\mid D)\\]\n\n\n3. Global Markov Property (\\(d\\)-separation)\n[cite_start]가장 일반적인 성질로, 그래프상에서 \\(d\\)-separation된 두 변수 집합은 확률분포상에서도 조건부 독립(Conditional Independence)이어야 함을 의미합니다[cite: 54, 55].\n\\[\\text{A is } d\\text{-separated from B given C in } \\mathcal{G} \\implies (A \\perp\\!\\!\\!\\perp B \\mid C) \\text{ in } P(\\mathbf{V})\\]\n[cite_start]이 성질은 그래프의 구조적 분리(\\(d\\)-separation)가 데이터의 통계적 독립성으로 나타난다는 것을 보장합니다[cite: 56].\n\n\n\n\n4. The Challenge of Structure Learning\nStructure Learning은 “데이터의 독립성 정보(\\(P(\\mathbf{V})\\))를 보고 그래프의 구조(\\(\\mathcal{G}\\))를 역으로 알아내는 것”입니다. 하지만 여기서 논리적인 장벽에 부딪힙니다.\n[cite_start]Global Markov Property는 일방향 함의(One-way implication)입니다. [cite: 59] \\[d\\text{-separation}_{\\mathcal{G}} \\implies \\text{Independence}_{P}\\] 이 명제의 대우를 취하면 다음과 같습니다: \\[\\text{Dependence}_{P} \\implies d\\text{-connection}_{\\mathcal{G}}\\]\n즉, 데이터에서 두 변수가 종속적이라면 그래프상에서 연결되어 있어야 합니다. 하지만, 데이터에서 독립이라고 해서 반드시 그래프에서 끊어져 있어야 한다는 보장은 없습니다. [cite_start]예를 들어, 모든 노드가 서로 연결된 완전 연결 그래프(Fully Connected Graph)는 어떠한 \\(d\\)-separation도 없으므로, 데이터의 어떠한 독립성 정보와도 모순되지 않습니다(vacuously true)[cite: 65]. 따라서 단순히 Global Markov Property만으로는 수많은 가능한 그래프 중 가장 합리적인 하나를 특정할 수 없습니다.\n우리는 데이터의 독립성을 그래프의 비연결성(separation)으로 해석하기 위해 역방향의 가정이 필요합니다.\n\n\n\n5. Faithfulness Assumption\n[cite_start]Structure Learning을 가능하게 하기 위해 도입된 핵심 가정이 바로 Faithfulness(충실성)입니다[cite: 74].\n\nDefinition: Faithfulness\n\\[A \\text{ is } d\\text{-separated from } B \\text{ given } C \\text{ in } \\mathcal{G} \\iff (A \\perp\\!\\!\\!\\perp B \\mid C) \\text{ in } P(\\mathbf{V})\\] [cite_start]즉, 그래프에서의 \\(d\\)-separation과 확률분포에서의 조건부 독립이 필요충분조건이 된다고 가정하는 것입니다[cite: 75, 76].\n이 가정이 있다면: * 데이터에서 관측된 독립성 \\(\\rightarrow\\) 그래프에서의 엣지 제거 (\\(d\\)-separation) * 데이터에서 관측된 종속성 \\(\\rightarrow\\) 그래프에서의 엣지 연결 (\\(d\\)-connection)\n이 가능해져 그래프를 복원할 수 있게 됩니다.\n\n\nJustification & Limitations\nFaithfulness는 얼마나 타당한 가정일까요? [cite_start]이론적으로, 무작위로 생성된 확률분포 \\(P(\\mathbf{V})\\)가 Unfaithful할 확률은 0(measure zero)입니다[cite: 80]. 즉, 대부분의 분포는 Faithful 합니다. 하지만 현실적인 문제들이 존재합니다: 1. [cite_start]Finite Samples: 데이터가 유한할 때, 실제로는 연결되어 있지만 효과가 매우 미미한 경우(Nearly Unfaithful)를 통계적으로 독립과 구별하기 어렵습니다[cite: 82]. 2. [cite_start]Homeostasis (항상성): 자연계, 특히 생물학적 시스템에서는 진화적 이유로 상쇄 효과(Cancellation)가 발달하여 Unfaithful한 상황이 드물지 않게 발생할 수 있습니다[cite: 83].\n\n\n\n\n6. Violation of Faithfulness (Example)\n[cite_start]Faithfulness가 위배되는 대표적인 사례는 서로 다른 경로의 인과 효과가 정확히 상쇄(Cancel out)되어, 실제로는 인과관계가 있음에도 데이터상으로는 독립으로 나타나는 경우입니다[cite: 87, 88].\n다음과 같은 구조적 방정식 모델(Structural Equation Model)을 고려해 봅시다.\n\nModel Setup\n\nGraph: \\(X \\rightarrow Z\\), \\(X \\rightarrow Y\\), \\(Z \\rightarrow Y\\) (Triangle structure)\nParameters:\n\n\\(X \\rightarrow Z\\): 계수 \\(+1\\)\n\\(Z \\rightarrow Y\\): 계수 \\(-1\\)\n\\(X \\rightarrow Y\\): 계수 \\(+1\\) (Direct effect)\n\n\n\n\n\nFigure 3: Faithfulness 위배 예시 그래프. X는 Y에 직접 영향을 미치고(계수 +1), Z를 통해서도 영향을 미친다(X-&gt;Z 계수 +1, Z-&gt;Y 계수 -1).\n\n\n[cite_start]수식으로 표현하면[cite: 95, 96, 97]: \\[\n\\begin{align}\nX &= \\epsilon_X \\\\\nZ &= 1 \\cdot X + \\epsilon_Z \\\\\nY &= 1 \\cdot X - 1 \\cdot Z + \\epsilon_Y\n\\end{align}\n\\] 여기서 오차항 \\(\\epsilon\\)들은 서로 독립입니다.\n\n\nDerivation of Cancellation\n[cite_start]이제 \\(Y\\)를 \\(X\\)와 \\(\\epsilon\\)들에 대해 정리해 봅시다[cite: 99, 100, 101]. \\[\n\\begin{align}\nY &= X - Z + \\epsilon_Y \\\\\n  &= X - (X + \\epsilon_Z) + \\epsilon_Y \\\\\n  &= X - X - \\epsilon_Z + \\epsilon_Y \\\\\n  &= -\\epsilon_Z + \\epsilon_Y\n\\end{align}\n\\] [cite_start]결과적으로 \\(Y\\)는 \\(X\\)라는 항을 포함하지 않게 됩니다[cite: 102]. [cite_start]따라서 \\(Cov(X, Y) = 0\\)이 되고, 만약 가우시안 분포를 따른다면 \\(X\\)와 \\(Y\\)는 통계적으로 독립입니다[cite: 103].\n\n\nConclusion\n\nData (\\(P(\\mathbf{V})\\)): \\(X \\perp\\!\\!\\!\\perp Y\\) (독립)\nGraph (\\(\\mathcal{G}\\)): \\(X\\)와 \\(Y\\)는 \\(d\\)-connected (연결됨)\n\n데이터만 보면 \\(X\\)와 \\(Y\\) 사이에 아무런 관계가 없어 보여 엣지를 제거하게 되지만, 실제로는 두 개의 경로(\\(X \\to Y\\)와 \\(X \\to Z \\to Y\\))가 서로를 완벽하게 상쇄하고 있었던 것입니다. 이것이 바로 Faithfulness 위배 사례입니다.\n\n\n\n\n7. Summary\n이번 포스트에서는 Causal Discovery의 기초 개념과 핵심 가정을 다루었습니다.\n\nCausal Discovery: 데이터로부터 인과 그래프를 역추적하는 비지도 학습 문제.\nDAG Models: Factorization, Local Markov, Global Markov 성질을 통해 그래프와 분포를 연결.\nStructure Learning의 난점: 분포의 독립성은 그래프의 분리를 암시하지 않음 (Global Markov는 일방향).\nFaithfulness 가정: \\(d\\)-separation \\(\\iff\\) Conditional Independence를 가정함으로써 역추론을 가능하게 함. 하지만 경로 상쇄(Cancellation) 등의 예외가 존재할 수 있음.\n\n다음 포스트에서는 이러한 가정하에 실제로 그래프를 찾아내는 알고리즘들(PC Algorithm 등)에 대해 다루겠습니다.\n\n\nChecklist: Content Verification\n\nCausal Inference vs Discovery: 포함됨 (Section 1).\nRooster/Sun Example: 포함됨 (Section 1).\nDefinition of Structure Learning: 포함됨 (Section 1, 4).\nDAG Definition & Causal Sufficiency: 포함됨 (Section 2).\n3 Properties (Factorization, Local/Global Markov): 포함됨 (Section 3).\nOne-way Implication Problem: 포함됨 (Section 4).\nFaithfulness Definition: 포함됨 (Section 5).\nFaithfulness Nuances (Finite sample, Measure zero): 포함됨 (Section 5).\nViolation Example (Mathematical Derivation): 포함됨 (Section 6).\n누락된 내용: 강의 자료 전체(Slide 1~14)를 커버하였으며, 논리적 흐름을 위해 순서를 일부 재배치하였으나 핵심 개념 누락 없음."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html",
    "href": "posts/lecture/L16/part-06/index.html",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "",
    "text": "시계열 데이터(Time Series Data)는 유전체학(mRNA 발현), 신경심리학(fMRI 신호), 금융, 기상학 등 수많은 과학적 탐구의 기반이 됩니다. 인과추론(Causal Inference) 관점에서 시계열 데이터는 “원인은 결과보다 시간적으로 선행한다(Temporal Precedence)”는 강력한 단서를 제공하기 때문에 매력적입니다.\n하지만 동시에 시계열 데이터는 다음과 같은 고유한 난제들을 안고 있습니다.\n\nTime lags & Spurious Associations: 시차(Time lag)가 존재하며, 과거의 변수들이 현재의 여러 변수에 동시에 영향을 미칠 때 허위 상관(Spurious Association)이 발생하기 쉽습니다.\nSampling Rate: 실제 인과 과정보다 데이터 수집 속도가 느릴 경우, 인과 관계가 왜곡되어 보일 수 있습니다.\nNon-stationarity: 데이터의 분포나 인과 구조 자체가 시간에 따라 변할 수 있습니다.\n\n\n\n\nFigure: 시계열 인과 구조와 허위 상관의 예시. X1, X2, X3, X4가 시간 축을 따라 전개될 때, 검은색 화살표(Causal links)는 실제 인과관계를 나타내며, 회색 점선 화살표(Spurious associations)는 공통된 과거 원인 등에 의해 관측되는 허위 상관을 의미한다.\n\n\n이번 포스트에서는 시계열 데이터에서 인과 구조를 발견(Causal Discovery)하는 대표적인 방법론인 Granger Causality, PCMCI, TiMINo, 그리고 DYNOTEARS에 대해 심도 있게 다룹니다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#definition-and-intuition",
    "href": "posts/lecture/L16/part-06/index.html#definition-and-intuition",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "2.1. Definition and Intuition",
    "text": "2.1. Definition and Intuition\nGranger Causality는 시계열 인과추론의 가장 고전적이고 기초적인 개념입니다. Clive Granger는 인과성을 예측 가능성(Predictability)의 관점에서 정의했습니다.\n\nGranger Causality의 정의: 어떤 시계열 \\(X\\)의 과거 정보를 포함했을 때, \\(Y\\)의 미래를 예측하는 오차(Prediction Error)가 줄어든다면, \\(X\\)는 \\(Y\\)를 “Granger-cause” 한다고 말합니다.\n\n수식으로 엄밀하게 정의하면 다음과 같습니다. 전체 정보 집합 \\(V = \\{X, Y\\} \\cup Z\\)에 대하여, 다음 조건이 성립하면 \\(X\\)는 \\(Y\\)에 대해 Granger Non-causal입니다.\n\\[\nY_{t+1} \\perp\\!\\!\\perp X^t \\mid Y^t, Z^t\n\\]\n여기서 \\(X^t = \\{X_1, X_2, \\dots, X_t\\}\\)는 시점 \\(t\\)까지의 \\(X\\)의 모든 과거 정보를 의미합니다. 즉, \\(Y\\)와 \\(Z\\)의 과거를 모두 알고 있는 상태에서 \\(X\\)의 과거 정보가 \\(Y_{t+1}\\)의 확률 분포에 아무런 추가 정보를 주지 못한다면 인과관계가 없다고 봅니다. 반대의 경우, \\(X\\)는 \\(Y\\)를 Granger-cause 한다고 합니다.\n\n\n\nFigure: Granger Causality의 기본 아이디어 도식. N과 B라는 두 시계열이 있을 때, 과거의 N값들이 현재의 B값을 설명하는 데 유의미한지, 혹은 그 반대인지를 시차(Lag)를 고려하여 파악하는 구조를 보여준다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#vector-autoregressive-var-models",
    "href": "posts/lecture/L16/part-06/index.html#vector-autoregressive-var-models",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "2.2. Vector Autoregressive (VAR) Models",
    "text": "2.2. Vector Autoregressive (VAR) Models\n실증 분석에서 Granger Causality는 주로 벡터 자기회귀(Vector Autoregressive, VAR) 모형을 통해 검정됩니다.\n\\(p\\)차 VAR 모형, 즉 \\(VAR(p)\\)는 다음과 같이 표현됩니다.\n\nUnivariate Case\n\\[\nX_t = c + A_1 X_{t-1} + A_2 X_{t-2} + \\dots + A_p X_{t-p} + e_t\n\\]\n\n\nMultivariate Case\n다변량 시계열 \\(X_t = (X_{1,t}, \\dots, X_{d,t})^T\\)에 대하여: \\[\nX_{j,t} = \\sum_{u=1}^{\\infty} \\sum_{k=1}^{d} A_{jk,u} X_{k, t-u} + \\epsilon_{j,t}\n\\]\n여기서 \\(A_{jk,u}\\)는 시차 \\(u\\)에서 변수 \\(k\\)가 변수 \\(j\\)에 미치는 영향력을 나타내는 계수입니다.\n\n\nTesting for Causality\nVAR 모형에서 \\(X_i\\)가 \\(X_j\\)를 Granger-cause 하지 않는다는 조건은 다음과 동치입니다.\n\\[\nA_{ji, u} = 0 \\quad \\text{for all lags } u &gt; 0\n\\]\n즉, \\(X_j\\)를 예측하는 식에서 \\(X_i\\)의 모든 과거 항들의 계수가 0이어야 합니다. 이는 \\(X_j\\)를 전체 과거 정보 \\(X^{t-1}\\)로 예측했을 때의 평균제곱오차(MSE)와, \\(X_i\\)를 제외한 정보 \\(X_{-i}^{t-1}\\)로 예측했을 때의 MSE를 비교하여 검정할 수 있습니다.\n\\[\n\\text{var}(X_{j,t} \\mid X^{t-1}) = \\text{var}(X_{j,t} \\mid X_{-i}^{t-1})\n\\]\n\n\n\n\n\n\nWarning\n\n\n\n주의사항: Granger Causality는 “인과(Causality)”라는 용어를 사용하지만, 근본적으로는 예측 유용성에 관한 개념입니다. 잠재 변수(Confounder)가 존재하거나 시간 집계(Temporal aggregation)가 발생할 경우, 실제 인과관계와 다른 결론을 낼 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#motivation",
    "href": "posts/lecture/L16/part-06/index.html#motivation",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "3.1. Motivation",
    "text": "3.1. Motivation\n전통적인 PC 알고리즘(Peter-Clark algorithm)을 시계열에 그대로 적용하면 문제가 발생합니다. 변수의 수가 많고 시차(Lag)가 길어지면 조건부 독립성 검정(Conditional Independence Test)을 수행해야 할 조건부 집합(Conditioning set)의 크기가 지나치게 커집니다. 이는 통계적 검정력(Power)을 떨어뜨리고, 결과적으로 False Positives(잘못된 인과 발견)를 양산합니다.\nPCMCI 알고리즘은 조건부 집합을 최적화하여 검정력은 높이고 False Discovery Rate는 제어하기 위해 고안되었습니다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#two-stage-algorithm",
    "href": "posts/lecture/L16/part-06/index.html#two-stage-algorithm",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "3.2. Two-Stage Algorithm",
    "text": "3.2. Two-Stage Algorithm\nPCMCI는 이름에서 알 수 있듯이 PC 단계(\\(PC_1\\))와 MCI(Momentary Conditional Independence) 단계로 구성됩니다.\n\nStep 1: \\(PC_1\\) Stage (Parent Selection)\n이 단계의 목표는 각 변수 \\(X_t^j\\)에 대한 잠정적인 부모 집합(Superset of parents) \\(\\hat{Pa}(X_t^j)\\)를 찾는 것입니다. * 표준 PC 알고리즘의 변형을 사용하되, 인접성(Adjacency)만 파악합니다. * 모든 가능한 분리 집합(Separator)을 테스트하는 대신, 상관관계가 가장 강한 \\(k\\)개의 변수만을 조건부로 사용하여 효율성을 높입니다. * 이 단계가 끝나면 실제 부모 변수들이 포함되지만, 일부 허위 부모(Spurious parents)들도 포함되어 있을 수 있습니다.\n\n\nStep 2: MCI Stage (Refining)\n\\(PC_1\\) 단계에서 구한 잠정적 부모 집합을 이용하여, 정밀한 조건부 독립성 검정을 수행합니다. 이를 Momentary Conditional Independence (MCI) 검정이라고 합니다.\n검정하고자 하는 관계가 \\(X_{t-\\tau}^i \\to X_t^j\\)일 때, 다음의 조건부 독립성을 검정합니다.\n\\[\nX_t^j \\perp\\!\\!\\perp X_{t-\\tau}^i \\mid \\hat{Pa}(X_t^j) \\setminus \\{X_{t-\\tau}^i\\}, \\hat{Pa}(X_{t-\\tau}^i)\n\\]\n여기서 주목할 점은 조건부 집합에 \\(X_t^j\\)의 부모뿐만 아니라 원인 변수인 \\(X_{t-\\tau}^i\\)의 부모 \\(\\hat{Pa}(X_{t-\\tau}^i)\\)까지 포함시킨다는 것입니다. 이는 시계열 데이터의 자기상관(Autocorrelation)으로 인한 허위 발견을 억제하는 데 핵심적인 역할을 합니다.\n\n\n\nFigure: PCMCI의 MCI 단계 도식. X^j_t에 대한 인과를 검정할 때, 단순히 X^j의 과거값만 조건부로 거는 것이 아니라, 잠재적 원인 변수인 X^i_{t-tau}의 부모 변수들까지 함께 조건부로 걸어줌으로써(Double Conditioning) 시계열의 자기상관 효과를 제거하는 과정을 보여준다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#algorithm-detail",
    "href": "posts/lecture/L16/part-06/index.html#algorithm-detail",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "3.3. Algorithm Detail",
    "text": "3.3. Algorithm Detail\nMCI 단계에서의 구체적인 절차는 다음과 같습니다.\n\n모든 \\(i, j\\)와 시차 \\(\\tau\\)에 대해 \\(X_{t-\\tau}^i\\)가 \\(X_t^j\\)의 잠정 부모 집합 \\(\\hat{Pa}(X_t^j)\\)에 속하는지 확인합니다.\n속한다면, MCI 조건부 독립성 검정을 수행하여 p-value를 계산합니다.\np-value가 유의수준 \\(\\alpha\\)보다 크다면(독립이라면), \\(X_{t-\\tau}^i\\)를 부모 집합에서 제거합니다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#key-idea-independent-noise",
    "href": "posts/lecture/L16/part-06/index.html#key-idea-independent-noise",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "4.1. Key Idea: Independent Noise",
    "text": "4.1. Key Idea: Independent Noise\nGranger Causality나 PC 알고리즘은 주로 조건부 독립성에 의존하지만, TiMINo (Time Series Models with Independent Noise)는 함수적 인과 모형(Functional Causal Model)의 구조적 가정을 활용합니다.\n핵심 아이디어는 “올바른 인과 방향으로 모델을 적합(Fit)했을 때만 잔차(Residual)가 독립적인 노이즈가 된다”는 것입니다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#timino-definition",
    "href": "posts/lecture/L16/part-06/index.html#timino-definition",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "4.2. TiMINo Definition",
    "text": "4.2. TiMINo Definition\n시계열 \\(X_t = (X_t^i)_{i \\in V}\\)가 TiMINo를 만족한다는 것은, 각 변수 \\(X_t^i\\)가 자신의 부모 변수들의 함수와 독립적인 노이즈의 결합으로 표현됨을 의미합니다.\n\\[\nX_t^i = f_i \\left( (Pa_p^i)_{t-p}, \\dots, (Pa_0^i)_t, N_t^i \\right)\n\\]\n여기서 \\(N_t^i\\)는 모든 \\(i\\)와 \\(t\\)에 대해 결합 독립(Jointly Independent)입니다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#timino-theorem-algorithm",
    "href": "posts/lecture/L16/part-06/index.html#timino-theorem-algorithm",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "4.3. TiMINo Theorem & Algorithm",
    "text": "4.3. TiMINo Theorem & Algorithm\nPeters et al.은 함수 \\(f_i\\)가 식별 가능한 함수 클래스(예: Linear non-Gaussian, Additive Noise Model 등)에 속하거나 시간 구조가 명확할 때, 전체 인과 그래프(Full Time Graph)를 복원할 수 있음을 증명했습니다.\n알고리즘은 다음과 같은 절차를 따릅니다 (Counter-intuitive하지만 효과적임):\n\n모든 변수 \\(k \\in S\\)에 대해, 나머지 변수들을 입력으로 하는 TiMINo 모델을 적합합니다.\n잔차(Residual)가 입력 변수들과 독립인지 검정합니다.\n가장 의존성이 약한(Weakest dependence), 즉 독립성 가정에 가장 가까운 변수 \\(k^*\\)를 선택합니다. (이 변수는 인과 구조상 가장 하위(Sink)에 위치할 가능성이 높습니다.)\n\\(k^*\\)를 집합 \\(S\\)에서 제거하고, 순서(Order)를 기록합니다.\n이 과정을 반복하여 변수들의 위상학적 순서(Topological Order)를 찾고, 불필요한 부모를 제거(Pruning)합니다.\n\n논문에서는 모델 \\(f_i\\)로 GAM(Generalized Additive Model), Gaussian Processes 등을 고려했으며, 선형 모형을 사용할 경우 TS-LiNGAM은 TiMINo의 특수한 형태가 됩니다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#from-notears-to-dynotears",
    "href": "posts/lecture/L16/part-06/index.html#from-notears-to-dynotears",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "5.1. From NOTEARS to DYNOTEARS",
    "text": "5.1. From NOTEARS to DYNOTEARS\nNOTEARS는 인과 구조 학습(Structure Learning)을 조합 최적화 문제(Combinatorial Optimization)가 아닌 연속 최적화 문제(Continuous Optimization)로 변환하여 획기적인 발전을 이룬 알고리즘입니다. DYNOTEARS는 이를 시계열 데이터로 확장한 버전입니다."
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#structural-vector-autoregression-svar",
    "href": "posts/lecture/L16/part-06/index.html#structural-vector-autoregression-svar",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "5.2. Structural Vector Autoregression (SVAR)",
    "text": "5.2. Structural Vector Autoregression (SVAR)\nDYNOTEARS는 구조적 벡터 자기회귀(SVAR) 모형을 가정합니다. \\(Y_1, \\dots, Y_p\\)를 \\(X\\)의 시차(Lagged) 버전 데이터라고 할 때:\n\\[\nX = XW + Y_1 A_1 + \\dots + Y_p A_p + Z\n\\]\n\n\\(W\\): 동시간대(Contemporaneous) 인과 관계 행렬 (Acyclicity 제약 필요)\n\\(A_k\\): 시차 \\(k\\)에서의 인과 관계 행렬 (제약 없음)\n\\(Z\\): 노이즈"
  },
  {
    "objectID": "posts/lecture/L16/part-06/index.html#optimization-problem",
    "href": "posts/lecture/L16/part-06/index.html#optimization-problem",
    "title": "[Causal Inference] 16. Causal Discovery (Part 6)",
    "section": "5.3. Optimization Problem",
    "text": "5.3. Optimization Problem\n목표는 데이터 적합도(Data fidelity)를 높이면서, \\(W\\)가 DAG(Directed Acyclic Graph) 조건을 만족하도록 하는 \\(W\\)와 \\(A\\)를 찾는 것입니다.\n\\[\n\\min_{W, A} F(W, A) = \\underbrace{l(W, A)}_{\\text{Loss}} + \\underbrace{\\lambda_W \\|W\\|_1 + \\lambda_A \\|A\\|_1}_{\\text{Sparsity}} + \\underbrace{\\frac{\\rho}{2} h(W)^2 + \\alpha h(W)}_{\\text{Augmented Lagrangian for Acyclicity}}\n\\]\n\nLoss Function: \\(l(W, A) = \\frac{1}{2n} \\| X - XW - YA \\|_F^2\\) (Frobenius norm, 최소제곱오차)\nAcyclicity Constraint: \\(h(W) = \\text{tr}(e^{W \\circ W}) - d = 0\\). 이 값이 0이면 \\(W\\)는 사이클이 없는 그래프입니다.\n\nDYNOTEARS는 시차 데이터(\\(Y\\))를 포함하되, 비순환성(Acyclicity) 제약은 동시간대 행렬 \\(W\\)에만 적용한다는 점이 핵심입니다 (과거가 현재에 영향을 주는 것은 사이클이 아니기 때문입니다)."
  },
  {
    "objectID": "posts/lecture/L16/part-04/index.html",
    "href": "posts/lecture/L16/part-04/index.html",
    "title": "[Causal Inference] 16. Causal Discovery (Part 4)",
    "section": "",
    "text": "1. Introduction: From Constraints to Scores\n이전 포스트들에서 다룬 Constraint-based Approach (PC 알고리즘 등)는 데이터의 조건부 독립성(Conditional Independence) 검정을 통해 그래프를 깎아나가는 방식이었습니다. 이 방법은 직관적이지만, 독립성 검정의 오류가 누적될 수 있고 데이터가 적을 때 불안정하다는 단점이 있습니다.\n이번 포스트에서는 완전히 다른 접근 방식인 Score-based Approach를 다룹니다. [cite_start]이 방법은 인과 구조 학습을 최적화 문제(Optimization Problem)로 바라봅니다[cite: 757, 772].\n\nGoal: 데이터(\\(D\\))와 그래프 구조(\\(\\mathcal{G}\\))가 얼마나 잘 맞는지를 평가하는 Score Function을 정의하고,\nSearch: 이 점수를 최대화(혹은 최소화)하는 그래프 구조를 탐색합니다.\n\n또한, 이산적인 그래프 탐색의 한계를 극복하기 위해 최근 제안된 연속 최적화 기반의 NOTEARS 알고리즘까지 다뤄보겠습니다.\n\n\n\n2. Intuition: Data Fit vs. Simplicity\n[cite_start]Score-based Learning의 핵심 철학은 “데이터를 잘 설명하면서도(Data Fit), 구조적으로 간단한(Simplicity) 모델을 찾자”는 것입니다[cite: 757].\n\n2.1 The Concept of Scoring\n데이터셋 \\(D\\)가 주어졌을 때, 각 후보 그래프 \\(\\mathcal{G}\\)에 대해 점수를 매깁니다.\n\n\n\nFigure 1: Score-based Learning의 직관. 여러 후보 그래프(DAG)들이 주어졌을 때, 데이터와 가장 잘 부합하는 그래프에 높은 점수를 부여하고 선택하는 과정을 보여준다.\n\n\n\n[cite_start]Missing Arcs: 실제 존재하는 인과관계를 놓치면 데이터의 패턴을 설명하지 못하므로 점수가 낮아져야 합니다[cite: 793].\n[cite_start]Extra Arcs: 불필요한 엣지를 추가하면 과적합(Overfitting)이 발생하므로 패널티를 받아야 합니다[cite: 876].\n\n\n\n2.2 Likelihood as a Measure of Fit\n가장 먼저 떠올릴 수 있는 점수는 우도(Likelihood)입니다. [cite_start]DAG 모델의 결합 확률 분포는 다음과 같이 분해(Factorization)됩니다[cite: 821].\n\\[P(\\mathbf{V}) = \\prod_{i=1}^{d} P(V_i \\mid Pa_{\\mathcal{G}}(V_i))\\]\n[cite_start]이에 대한 로그 우도(Log-Likelihood) 함수는 다음과 같습니다[cite: 824]:\n\\[l(\\theta; D) = \\sum_{j=1}^{n} \\sum_{i=1}^{d} \\log P_{\\theta_i}(v_i^{(j)} \\mid pa_i^{(j)})\\]\n여기서 \\(n\\)은 샘플 수, \\(d\\)는 변수의 개수입니다. [cite_start]이 식은 각 변수별로 독립적으로 계산하여 합산할 수 있다는 Decomposable 특성을 가집니다[cite: 828].\n\n\n\n\n3. The Problem with Likelihood & BIC\n하지만 단순히 우도만 사용하면 치명적인 문제가 발생합니다.\n\n3.1 The Overfitting Problem\n[cite_start]다음 두 그래프를 비교해 봅시다 [cite: 797-803].\n\nTrue Graph (Left): \\(A \\rightarrow B \\leftarrow C\\) (V-structure). 여기서 \\(A \\perp\\!\\!\\!\\perp C\\)입니다.\nProposed Graph (Right): \\(A \\rightarrow B \\leftarrow C\\) 에 \\(A \\rightarrow C\\) 엣지가 추가된 완전 그래프(Fully connected).\n\n\n\n\nFigure 2: Likelihood 비교의 문제점. 왼쪽의 True Graph(Sparse)와 오른쪽의 Fully Connected Graph를 비교할 때, 오른쪽 그래프는 왼쪽 그래프의 모든 독립성 조건을 포함(Submodel)하므로 Likelihood는 항상 오른쪽이 더 높거나 같다.\n\n\n오른쪽 그래프(Complete Graph)는 왼쪽 그래프(True Graph)를 포함하는 Supermodel입니다. 즉, 파라미터 수가 더 많고 표현력이 더 큽니다. [cite_start]따라서 최대 우도 추정(MLE)을 수행하면, 항상 엣지가 많은 그래프의 우도가 더 높게 나옵니다 [cite: 870-873].\n[cite_start]결국 Likelihood만을 점수로 사용하면 항상 완전 그래프(Complete Graph)가 선택되는 과적합 문제가 발생합니다[cite: 876].\n\n\n3.2 Bayesian Information Criterion (BIC)\n[cite_start]이 문제를 해결하기 위해 모델의 복잡도(파라미터 수)에 벌점(Penalty)을 부과하는 BIC 점수를 사용합니다[cite: 884].\n\\[BIC(\\mathcal{G}) = -2 \\cdot l(\\hat{\\theta}; D) + m \\cdot \\log(n)\\]\n\n\\(-2 \\cdot l(\\hat{\\theta}; D)\\): 데이터 적합도 (낮을수록 좋음, 즉 우도가 높을수록 좋음)\n\\(m\\): 그래프의 파라미터(엣지) 수\n\\(\\log(n)\\): 샘플 크기에 따른 가중치\n\nBIC는 낮을수록 좋은 점수입니다. [cite_start]\\(m \\cdot \\log(n)\\) 항이 일종의 정규화(Regularization) 역할을 하여 불필요한 엣지 추가를 억제합니다[cite: 888].\n\n\n\n\n4. Greedy Equivalence Search (GES)\n점수 함수(Score Function)가 정의되었으니, 이제 최적의 그래프를 찾아야 합니다. [cite_start]하지만 \\(d\\)개의 노드로 만들 수 있는 DAG의 수는 \\(d\\)에 대해 지수적으로(super-exponentially) 증가하므로 모든 그래프를 다 계산하는 것은 불가능합니다[cite: 893].\n[cite_start]따라서 효율적인 탐색 알고리즘이 필요한데, 그중 가장 대표적인 것이 GES (Greedy Equivalence Search)입니다[cite: 899].\n\n4.1 Search Space: Markov Equivalence Class\nGES의 가장 큰 특징은 개별 DAG가 아니라 Markov Equivalence Class (MEC) 단위로 탐색을 수행한다는 점입니다. 이는 통계적으로 구별 불가능한 그래프들을 묶어서 처리함으로써 탐색 효율을 높입니다.\n\n\n4.2 Algorithm Steps\n[cite_start]GES는 크게 두 단계로 구성됩니다[cite: 907, 918].\n\nPhase 1: Forward Equivalence Search (Addition)\n\n[cite_start]시작: 엣지가 하나도 없는 그래프(Empty Graph)에서 시작합니다[cite: 903].\n동작: 현재 상태에서 엣지를 하나 추가하여 만들 수 있는 모든 Equivalence Class 중, BIC 점수를 가장 많이 개선(감소)시키는 클래스로 이동합니다.\n종료: 더 이상 점수가 개선되지 않을 때까지 반복합니다.\n\n\n\nPhase 2: Backward Equivalence Search (Removal)\n\n시작: Phase 1에서 얻은 그래프에서 시작합니다.\n동작: 현재 상태에서 엣지를 하나 제거하여 만들 수 있는 클래스 중, 점수를 가장 많이 개선시키는 곳으로 이동합니다.\n종료: 점수 개선이 멈추면 종료하고 최종 클래스를 반환합니다.\n\n\n\n\n4.3 Understanding the Move\n“엣지를 추가한다”는 것은 단순히 선을 긋는 것보다 복잡합니다. 시작 DAG에 따라 도착하는 Equivalence Class가 달라질 수 있기 때문입니다.\n[cite_start]예시[cite: 910]: 현재 상태가 \\(\\{A \\rightarrow B, C\\}\\) (엣지 \\(A-B\\)만 존재)라고 합시다. 여기에 \\(C\\)와 \\(B\\)를 연결하는 엣지를 추가한다고 할 때: 1. \\(A \\rightarrow B \\leftarrow C\\) (V-structure) 클래스로 이동할 수도 있고, 2. \\(\\{A \\leftarrow B \\leftarrow C, A \\rightarrow B \\rightarrow C, \\dots\\}\\) 와 같은 Non-collider 클래스로 이동할 수도 있습니다.\n\n\n\nFigure 3: GES 알고리즘의 탐색 과정. 엣지를 추가(Addition phase)하거나 제거(Removal phase)할 때, 단순 DAG가 아닌 Equivalence Class 단위로 상태가 변화하는 것을 도식화함.\n\n\n\n\n4.4 Theoretical Guarantee\n[cite_start]Chickering (2002)은 데이터가 무한히 많아지면(\\(n \\rightarrow \\infty\\)) GES가 True Equivalence Class를 정확하게 찾아냄(Consistent)을 증명했습니다[cite: 937].\n\n\n\n\n5. Continuous Optimization: NOTEARS\nGES와 같은 조합 탐색(Combinatorial Search) 방식은 여전히 계산 비용이 높습니다. [cite_start]2018년, Zheng et al.은 이산적인 그래프 탐색 문제를 연속적인 최적화 문제(Continuous Optimization)로 변환하는 획기적인 방법인 NOTEARS를 제안했습니다[cite: 940].\n\n5.1 Formulation\n목표는 데이터 \\(X\\)를 선형 변환 \\(W\\)로 설명하는 것입니다 (\\(X \\approx XW\\)). 여기서 \\(W\\)는 인접 행렬(Adjacency Matrix) 역할을 합니다.\n기존의 문제는 다음과 같습니다: \\[\\min_{W} \\ell(W; X) + \\lambda \\|W\\|_1 \\quad \\text{subject to } W \\in \\text{DAGs}\\] DAG 제약조건은 이산적이라 미분이 불가능했습니다.\n\n\n5.2 The Trace Constraint\n[cite_start]NOTEARS의 핵심 기여는 DAG 제약조건을 미분 가능한 등식 제약조건으로 바꾼 것입니다[cite: 944].\n\\[\\text{Subject to: } h(W) = \\text{tr}(e^{W \\circ W}) - d = 0\\]\n\n\\(W \\circ W\\): 행렬의 원소별 제곱(Hadamard product)을 통해 음수 가중치도 양수로 처리합니다.\n\\(e^A\\): 행렬 지수 함수 (Matrix Exponential) \\(e^A = I + A + \\frac{A^2}{2!} + \\dots\\)\n직관: 인접 행렬 \\(A\\)의 \\(k\\)승(\\(A^k\\))의 대각 성분(trace)은 길이가 \\(k\\)인 사이클(Cycle)의 개수와 관련이 있습니다. 만약 그래프가 DAG라면 어떠한 길이의 사이클도 없어야 하므로, 모든 \\(k\\)에 대해 trace가 0이어야 합니다 (대각 성분이 0).\n[cite_start]이 식은 \\(W\\)가 DAG일 때만 정확히 0이 되고, 사이클이 있으면 양수가 됩니다[cite: 953].\n\n\n\n5.3 Final Optimization Problem\n[cite_start]이제 문제는 표준적인 제약 최적화 문제가 됩니다[cite: 950].\n\\[\\min_{W \\in \\mathbb{R}^{d \\times d}} \\frac{1}{2n} \\|X - XW\\|_F^2 + \\lambda \\|W\\|_1\\] \\[\\text{subject to } \\text{tr}(e^{W \\circ W}) - d = 0\\]\n이 문제는 Augmented Lagrangian Method 등의 일반적인 최적화 기법을 사용하여 효율적으로 풀 수 있습니다.\n\n\n\nFigure 4: NOTEARS의 아이디어. 이산적인 그래프 공간을 탐색하는 대신, 연속적인 가중치 행렬 W 공간에서 Loss를 최소화하며, Trace 제약조건을 통해 Cycle이 없는 방향으로 최적화를 수행한다.\n\n\n\n\n\n\n6. Summary\n이번 포스트에서는 Score-based Structure Learning을 다루었습니다.\n\nScore Function: Likelihood는 과적합 문제가 있으므로, 파라미터 수에 패널티를 주는 BIC 등을 사용합니다.\nCombinatorial Search: 가능한 모든 그래프를 탐색하는 것은 불가능하므로, Equivalence Class 단위를 탐색하는 GES 알고리즘을 사용합니다. 이는 점근적으로(asymptotically) 정확성을 보장합니다.\nContinuous Optimization: 최근에는 NOTEARS와 같이 DAG 제약조건을 미분 가능한 함수(\\(\\text{tr}(e^W)\\))로 변환하여 딥러닝/최적화 기법을 적용하는 연구가 활발합니다.\n\nScore-based 방법은 Constraint-based 방법에 비해 데이터 노이즈에 강건하고, 최적화 관점에서 문제를 풀 수 있다는 장점이 있습니다. 하지만 여전히 거대한 탐색 공간과 Local Optima 문제는 도전 과제로 남아 있습니다.\n\n\nChecklist: Content Verification\n\nScore-based Concept: 포함됨 (Section 2).\n\nMotivation (Fit vs Simplicity): 포함됨.\nLikelihood Definition: 포함됨.\nExample (Submodel vs Supermodel): 포함됨 (Section 3.1).\n\nBIC Score:\n\nProblem with raw Likelihood (Overfitting): 포함됨.\nFormula (\\(-2L + m \\log n\\)): 포함됨 (Section 3.2).\nInterpretation: 포함됨.\n\nGES Algorithm:\n\nSearch Space (Equivalence Classes): 포함됨 (Section 4.1).\nPhases (Addition/Removal): 포함됨 (Section 4.2).\nMove logic (Example \\(B \\leftarrow C\\)): 포함됨 (Section 4.3).\nCompleteness Theorem: 포함됨 (Section 4.4).\n\nNOTEARS (Continuous Optimization):\n\nMotivation: 포함됨 (Section 5).\nAcyclicity Constraint (\\(\\text{tr}(e^{W \\circ W}) - d = 0\\)): 수식 및 직관(Cycle counting) 포함됨 (Section 5.2).\nOptimization Objective: 포함됨 (Section 5.3).\n\nVisuals: Figure 1~4에 대한 캡션 및 Markdown 문법 적용 완료.\nCitations: 각 주요 진술에 대해 형식 적용 완료."
  },
  {
    "objectID": "posts/lecture/L16/part-02/index.html",
    "href": "posts/lecture/L16/part-02/index.html",
    "title": "[Causal Inference] 16. Causal Discovery (Part 2)",
    "section": "",
    "text": "1. Introduction: Constraint-Based Approach\n이전 포스트에서는 Causal Discovery를 위한 핵심 가정인 Faithfulness에 대해 다루었습니다. [cite_start]이번 포스트에서는 이 가정을 바탕으로 실제 데이터에서 인과 그래프(DAG)를 찾아내는 대표적인 방법론인 Constraint-Based Structure Learning을 다룹니다[cite: 107, 113].\n[cite_start]이 방법론의 핵심 아이디어는 다음과 같습니다[cite: 115]: 1. 데이터에서 성립하는 제약 조건(Constraints), 즉 조건부 독립성(Conditional Independencies, CIs)을 찾아냅니다. 2. 이 제약 조건들과 모순되는 그래프들을 후보군에서 제거합니다. 3. 남은 그래프(또는 그래프들의 집합)를 결과로 반환합니다.\n이 과정의 가장 대표적인 알고리즘인 PC Algorithm을 통해, 어떻게 데이터만으로 인과 구조를 복원할 수 있는지 단계별로 살펴보겠습니다.\n\n\n\n2. Motivating Example: Reconstructing a Graph\nPC 알고리즘의 정식 절차를 다루기 전에, 4개의 변수 \\(W, X, Y, Z\\)로 구성된 구체적인 예시를 통해 직관을 얻어보겠습니다.\n\n2.1 The True Model (Target)\n우리가 찾고자 하는 정답(True DAG)은 다음과 같은 구조라고 가정합니다.\n\n\n\nFigure 1: True Generating DAG. W는 X와 Y의 공통 원인이며(Fork), X와 Y는 Z의 원인이다(Collider). 이 그래프는 Diamond 형태를 띤다.\n\n\n이 그래프 구조 \\(\\mathcal{G}\\)가 암시하는 조건부 독립성은 무엇일까요? \\(d\\)-separation 기준을 적용해보면: * \\(X\\)와 \\(Y\\)는 \\(W\\)를 통해 연결(Fork: \\(X \\leftarrow W \\rightarrow Y\\))되어 있고, \\(Z\\)를 통해 연결(Collider: \\(X \\rightarrow Z \\leftarrow Y\\))되어 있습니다. * Collider인 \\(Z\\)를 조건부로 주지 않으면 \\(Z\\) 경로는 막힙니다. * Fork인 \\(W\\)를 조건부로 주면 \\(W\\) 경로는 막힙니다.\n[cite_start]따라서, 이 그래프가 강제하는 유일한 조건부 독립성(CI)은 다음과 같습니다[cite: 136]: \\[X \\perp\\!\\!\\!\\perp Y \\mid W\\]\n\n\n2.2 Finding the Skeleton (Adjacency Search)\n이제 우리는 그래프를 모른 채, 데이터로부터 \\(X \\perp\\!\\!\\!\\perp Y \\mid W\\)라는 사실만 발견했다고 가정합니다.\nStep 1: Start with a Complete Graph [cite_start]아무런 정보가 없을 때, 우리의 최선의 추측은 모든 변수가 서로 연결된 완전 무방향 그래프(Undirected Complete Graph)입니다[cite: 194, 195].\n\n\n\nFigure 2: Initial State. 4개의 노드(W, X, Y, Z)가 모두 서로 무방향 엣지로 연결된 완전 그래프 상태.\n\n\nStep 2: Remove Edges based on CI 우리는 데이터에서 \\(X \\perp\\!\\!\\!\\perp Y \\mid W\\)를 관측했습니다. 두 변수가 조건부로 독립이라는 것은, 두 변수 사이에 직접적인 엣지가 없음을 의미합니다. [cite_start]따라서 \\(X\\)와 \\(Y\\) 사이의 엣지를 제거할 수 있습니다[cite: 221, 231].\n\n제거된 엣지: \\(X - Y\\)\n남은 구조: Skeleton (방향이 없는 뼈대)\n\n이 과정을 통해 얻은 그래프를 Skeleton이라고 합니다.\n\n\n2.3 Orienting Edges (Finding V-structures)\n뼈대를 찾았으니 이제 화살표의 방향을 찾을 차례입니다. 여기서 핵심 단서는 Collider (V-structure)입니다.\n우리는 \\(X - Z - Y\\)가 연결되어 있고 \\(X\\)와 \\(Y\\)는 직접 연결되지 않은(non-adjacent) “Unshielded Triple” 형태임을 알고 있습니다. 이때, \\(X\\)와 \\(Y\\)를 독립으로 만든 조건 집합(Separating Set, \\(S\\))이 무엇인지 확인합니다.\n\n우리는 \\(S = \\{W\\}\\)임을 알고 있습니다.\n[cite_start]중요한 점은 \\(Z\\)가 \\(S\\)에 포함되지 않는다는 것입니다 (\\(Z \\notin \\{W\\}\\))[cite: 316].\n\n만약 \\(Z\\)가 \\(X \\rightarrow Z \\rightarrow Y\\) (Chain)나 \\(X \\leftarrow Z \\rightarrow Y\\) (Fork)의 중앙 노드였다면, \\(X\\)와 \\(Y\\)를 독립시키기 위해 반드시 \\(Z\\)를 조건부로 걸어야(Conditioning) 합니다. 하지만 \\(Z\\)를 조건부로 걸지 않았음에도 \\(X\\)와 \\(Y\\)가 독립이 되었다는 것은, 역으로 \\(Z\\)가 Collider (\\(X \\rightarrow Z \\leftarrow Y\\))임을 의미합니다. (Collider는 조건부로 걸면 오히려 경로가 열리기 때문입니다.)\n[cite_start]따라서 우리는 \\(X \\rightarrow Z\\) 와 \\(Y \\rightarrow Z\\)로 방향을 확정할 수 있습니다[cite: 292, 299].\n\n\n\nFigure 3: Orientation Step. X와 Y 사이의 엣지는 제거되었고, Z가 X와 Y를 독립시키는 조건 집합에 포함되지 않았으므로 Z 방향으로 모이는 V-structure(Collider)를 형성한다.\n\n\n\n\n2.4 Propagating Directions\n이제 \\(Z\\)와 관련된 엣지는 방향이 정해졌습니다. 남은 것은 \\(W\\)와 연결된 엣지들(\\(W-X, W-Y\\))입니다. 만약 \\(X \\rightarrow W\\)라면, \\(Z \\leftarrow X \\rightarrow W\\)가 됩니다. 하지만 \\(W \\rightarrow X\\)라면?\n여기서 Acyclicity (비순환성) 제약이나 추가적인 독립성 정보를 활용할 수 있습니다. 하지만 더 강력한 논리는 “추가적인 V-structure가 없어야 한다”는 것입니다. 만약 \\(W \\rightarrow X\\)가 아니라 \\(X \\rightarrow W\\)이고, 동시에 \\(Y \\rightarrow W\\)라면 \\(W\\)도 또 다른 Collider가 됩니다. 하지만 우리는 데이터 탐색 단계에서 \\(W\\)가 Collider라는 증거(즉, \\(X\\)와 \\(Y\\)가 \\(W\\)를 모를 때 독립이고 알면 종속이 되는 현상)를 찾지 못했습니다.\n따라서 기존에 발견된 V-structure 외에 새로운 V-structure를 만들지 않기 위해, 그리고 Cycle을 방지하기 위해 나머지 엣지들의 방향을 추론합니다. 이 예시에서는 \\(W \\rightarrow X\\), \\(W \\rightarrow Y\\)로 방향이 결정됩니다.\n\n\n\n\n3. Markov Equivalence Class\n위의 예시에서는 운 좋게 모든 방향을 특정할 수 있었습니다. 하지만 언제나 모든 엣지의 방향을 알 수 있는 것은 아닙니다.\n\n3.1 Observational Equivalence\n데이터의 확률 분포(독립성 정보)만으로는 구별할 수 없는 서로 다른 DAG들이 존재할 수 있습니다. [cite_start]이를 Observationally Equivalent 또는 Markov Equivalent하다고 합니다[cite: 410].\n[cite_start]예를 들어, 다음 세 그래프는 모두 동일한 조건부 독립성(\\(X \\perp\\!\\!\\!\\perp Y \\mid Z\\))을 갖습니다[cite: 390]: 1. \\(X \\rightarrow Z \\rightarrow Y\\) (Chain) 2. \\(X \\leftarrow Z \\leftarrow Y\\) (Chain) 3. \\(X \\leftarrow Z \\rightarrow Y\\) (Fork)\n하지만 \\(X \\rightarrow Z \\leftarrow Y\\) (Collider)는 \\(X \\perp\\!\\!\\!\\perp Y\\) (Marginally Independent)이므로 위 셋과 구별됩니다.\n\n\n3.2 Theorem (Verma and Pearl)\n[cite_start]두 DAG가 통계적으로 구별 불가능(Markov Equivalent)할 필요충분조건은 다음과 같습니다[cite: 419, 420]: 1. Skeleton이 동일하고, 2. Unshielded Colliders (V-structures)가 동일해야 한다.\n이러한 동치류(Equivalence Class)를 하나의 그래프로 표현한 것을 CPDAG (Completed Partially Directed Acyclic Graph) 또는 Pattern이라고 합니다. [cite_start]CPDAG에서는 방향이 확정된 엣지는 화살표(\\(\\rightarrow\\))로, 결정되지 않은 엣지는 무방향(\\(-\\))으로 표시합니다[cite: 425].\n\n\n\n\n4. The PC Algorithm\n[cite_start]Spirtes와 Glymour가 제안한 PC Algorithm은 위의 과정을 일반화하여 \\(n\\)개의 변수에 대해 효율적으로 구조를 학습하는 알고리즘입니다[cite: 509].\n\nStep 1: Skeleton Identification\n\n완전 무방향 그래프로 시작합니다.\n인접한 모든 변수 쌍 \\((A, B)\\)에 대해 조건부 독립성 검사(CI Test)를 수행합니다.\n[cite_start]조건 집합 \\(S\\)의 크기(\\(i\\))를 0부터 시작하여 하나씩 늘려갑니다[cite: 513].\n\n만약 어떤 \\(S\\)에 대해 \\((A \\perp\\!\\!\\!\\perp B \\mid S)\\)가 성립하면, 엣지 \\(A-B\\)를 제거합니다.\n[cite_start]이때의 \\(S\\)를 \\(sepset(\\{A, B\\})\\)로 저장해둡니다[cite: 524].\n\\(S\\)는 \\(A\\)와 \\(B\\)의 인접 노드(neighbors) 중에서 선택합니다.\n\n\n\n\nStep 2: V-Structure Identification (Collider)\n\nSkeleton에서 서로 인접하지 않은 \\(A, B\\)와, 둘 다와 인접한 공통 이웃 \\(C\\)를 찾습니다 (\\(A - C - B\\)).\n만약 \\(C\\)가 \\(sepset(\\{A, B\\})\\)에 포함되지 않는다면, \\(C\\)는 Collider입니다.\n[cite_start]따라서 \\(A \\rightarrow C \\leftarrow B\\)로 방향을 설정합니다[cite: 525, 539].\n\n\n\nStep 3: Orientation Propagation (Meek’s Rules)\nV-structure로 밝혀진 방향들을 기반으로, 논리적으로 가능한 나머지 방향들을 확정합니다. [cite_start]이때 Meek’s Rules라고 불리는 4가지 규칙을 반복 적용합니다[cite: 547]. [cite_start]이 규칙들은 Cycle을 생성하지 않고 새로운 V-structure를 만들지 않는다는 원칙하에 작동합니다[cite: 544, 545].\n\nRule 1: Avoid New Collider\n\n상황: \\(A \\rightarrow B - C\\) 이고 \\(A, C\\)는 연결되지 않음.\n조치: \\(B \\rightarrow C\\) 로 방향 설정.\n[cite_start]이유: 만약 \\(C \\rightarrow B\\)라면 \\(A \\rightarrow B \\leftarrow C\\)가 되어 새로운 V-structure가 생기는데, 이는 Step 2에서 발견되지 않았으므로 모순입니다[cite: 560].\n\n\n\n\nFigure 4: Meek’s Rule 1. A-&gt;B-C 상황에서 B-&gt;C로 방향을 주지 않으면 새로운 Collider가 형성되므로 B-&gt;C로 강제한다.\n\n\n\n\nRule 2: Avoid Cycle\n\n상황: \\(A \\rightarrow C \\rightarrow B\\) (Chain)가 있고 \\(A - B\\)가 연결됨.\n조치: \\(A \\rightarrow B\\) 로 방향 설정.\n[cite_start]이유: 만약 \\(B \\rightarrow A\\)라면 \\(A \\rightarrow C \\rightarrow B \\rightarrow A\\)로 이어지는 Cycle이 형성되므로 불가능합니다[cite: 576].\n\n\n\n\nFigure 5: Meek’s Rule 2. A-&gt;C-&gt;B 경로가 존재할 때 A-B 엣지는 A-&gt;B여야 한다. 그렇지 않으면 Cycle이 발생한다.\n\n\n\n\nRule 3: Double Triangle\n\n상황: \\(A - C \\rightarrow B\\), \\(A - D \\rightarrow B\\)가 있고 \\(A - B\\)가 연결됨 (\\(C, D\\)는 비연결).\n조치: \\(A \\rightarrow B\\) 로 방향 설정.\n[cite_start]이유: 만약 \\(B \\rightarrow A\\)라면, Rule 1이나 Cycle 문제 등에 의해 \\(C, D\\)와의 관계에서 모순이 발생하여 Cycle이 형성됩니다[cite: 590, 606].\n\n\n\nRule 4: Complex Cycle\n\n상황: \\(A - C \\rightarrow D\\) 및 \\(C \\rightarrow D \\rightarrow B\\) 등의 복잡한 구조.\n[cite_start]조치: \\(A \\rightarrow B\\) 로 방향 설정[cite: 613].\n\n\n\n\n\n\n5. Summary\n이번 포스트에서는 데이터로부터 인과 그래프를 도출하는 PC Algorithm을 상세히 살펴보았습니다.\n\nConstraint-Based Approach: 조건부 독립성(CI)을 제약 조건으로 사용하여 불가능한 그래프를 소거합니다.\nLogic:\n\nSkeleton: \\(X \\perp\\!\\!\\!\\perp Y \\mid S\\) \\(\\implies\\) 엣지 제거.\nV-structure: \\(X-Z-Y\\)이고 \\(Z \\notin S\\) \\(\\implies\\) \\(X \\rightarrow Z \\leftarrow Y\\).\nPropagation: Cycle과 새로운 V-structure 방지를 위한 Meek’s Rules 적용.\n\nResult: 결과물은 Markov Equivalence Class를 표현하는 CPDAG 형태입니다. 즉, 데이터만으로는 방향을 알 수 없는 엣지가 남아있을 수 있습니다.\n\nPC 알고리즘은 강력하지만, 데이터의 샘플 수가 적거나 변수가 많아지면 CI Test의 오류가 누적될 수 있다는 단점도 있습니다. 다음 단계에서는 이러한 제약 기반 방법 외에 점수 기반(Score-based) 접근법 등을 고려해볼 수 있습니다.\n\n\nChecklist: Content Verification\n\nConstraint-Based Idea: 포함됨 (Section 1).\nMotivating Example (W,X,Y,Z): 포함됨 (Section 2).\n\nTrue Graph (Diamond): 포함됨.\nCI (\\(X \\perp Y | W\\)): 포함됨.\nSkeleton Logic: 포함됨.\nOrientation (Collider test logic): 포함됨.\n\nMarkov Equivalence Class: 포함됨 (Section 3).\n\nDefinition: 포함됨.\nTheorem (Skeleton + V-structures): 포함됨.\nCPDAG: 포함됨.\n\nPC Algorithm Steps: 포함됨 (Section 4).\n\nStep 1 (Skeleton search by increasing \\(|S|\\)): 포함됨.\nStep 2 (V-structures with \\(sepset\\)): 포함됨.\nStep 3 (Meek’s Rules): 포함됨.\n\nMeek’s Rules (1-4): 상세 설명 및 논리(이유) 포함됨 (Section 4).\nImages: Markdown 이미지 문법 사용 및 캡션 포함.\n누락된 내용: Slide 1의 Overview에 나온 Score-based, Parametric 등은 본 PDF의 주 내용이 아니므로 서론/결론에서 언급만 하고 상세 설명은 생략함 (본문의 초점 유지)."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-03/index.html",
    "href": "posts/lecture/L04/causal-inference-04-part-03/index.html",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 3)",
    "section": "",
    "text": "지난 포스트에서는 교란 편향(Confounding Bias)이 인과 효과 추정을 방해하는 주된 요인임을 살펴보았습니다.\n그렇다면 우리는 복잡한 인과 그래프(DAG)에서 어떤 변수들의 집합(\\(Z\\))을 조절(Control/Adjustment)해야 이 편향을 제거할 수 있을까요?\n이번 포스트에서는 그 해답이 되는 Back-door Criterion(백도어 기준)의 정의와 이를 이용한 보정 공식을 다룹니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-03/index.html#definition",
    "href": "posts/lecture/L04/causal-inference-04-part-03/index.html#definition",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 3)",
    "section": "2.1 Definition",
    "text": "2.1 Definition\n\n주어진 인과 그래프 \\(G\\)에서 변수 \\(X\\)와 \\(Y\\)에 대해, 변수들의 집합 \\(Z\\)가 다음 두 가지 조건을 만족할 때, \\(Z\\)는 Back-door Criterion을 만족한다고 정의합니다.\n\n\n(i) No node in \\(Z\\) is a descendant of \\(X\\). (\\(Z\\)에 속한 어떤 변수도 \\(X\\)의 자손이 아니어야 합니다.)\n(ii) \\(Z\\) blocks every path between \\(X\\) and \\(Y\\) that contains an arrow into \\(X\\). (\\(Z\\)는 \\(X\\)로 들어오는 화살표를 포함하는 \\(X\\)와 \\(Y\\) 사이의 모든 경로를 차단해야 합니다.)"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-03/index.html#의미-해석",
    "href": "posts/lecture/L04/causal-inference-04-part-03/index.html#의미-해석",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 3)",
    "section": "2.2 의미 해석",
    "text": "2.2 의미 해석\n\n조건 (i)은 \\(X\\)의 결과(Effect)로 나타나는 변수를 통제하지 말라는 뜻입니다. \\(X\\)의 자손을 통제하면 \\(X\\)가 \\(Y\\)에 미치는 실제 인과 경로를 막아버리거나 새로운 편향을 만들 수 있기 때문입니다.\n조건 (ii)의 “arrow into \\(X\\)”는 소위 백도어 경로(Back-door Path)를 의미합니다. 이는 \\(X\\)의 원인이 되는 변수들에 의해 생성되는 비인과적 상관관계(Spurious Correlation)의 경로입니다. 이 경로를 차단함으로써 우리는 \\(X\\)에서 \\(Y\\)로 나가는 순수한 인과적 경로만 남길 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-03/index.html#분석-포인트",
    "href": "posts/lecture/L04/causal-inference-04-part-03/index.html#분석-포인트",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 3)",
    "section": "5.1 분석 포인트",
    "text": "5.1 분석 포인트\n\n이 그래프에서 \\(X\\)와 \\(Y\\) 사이의 백도어 경로를 차단해야 합니다. \\(X\\)에서 나가는 화살표를 지운 그래프(\\(G_{\\underline{X}}\\))를 상상했을 때 \\(X\\)와 \\(Y\\)가 d-separation 되는지 확인하는 것과 같습니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-03/index.html#가능한-z-집합의-예시",
    "href": "posts/lecture/L04/causal-inference-04-part-03/index.html#가능한-z-집합의-예시",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 3)",
    "section": "5.2 가능한 \\(Z\\) 집합의 예시",
    "text": "5.2 가능한 \\(Z\\) 집합의 예시\n\n\\(Z = \\{Z_4, Z_2\\}\\)\n\\(Z = \\{Z_4, Z_5\\}\\)\n\\(Z = \\{Z_4, Z_2, Z_5\\}\\)"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-03/index.html#주의할-점-collider-z_4",
    "href": "posts/lecture/L04/causal-inference-04-part-03/index.html#주의할-점-collider-z_4",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 3)",
    "section": "5.3 주의할 점: Collider (\\(Z_4\\))",
    "text": "5.3 주의할 점: Collider (\\(Z_4\\))\n\n위 그래프에서 \\(Z_4\\)는 \\(Z_1 \\to Z_4 \\leftarrow Z_2\\) 구조를 갖는 Collider입니다.\n만약 \\(Z_4\\)를 집합에 포함하지 않으면, \\(Z_1 - Z_4 - Z_2\\) 경로는 자연스럽게 막혀(Blocked) 있습니다.\n하지만 \\(Z_4\\)를 집합에 포함시켜 조건부로 잡으면(Conditioning), 오히려 \\(Z_1\\)과 \\(Z_2\\) 사이의 경로가 열리게 됩니다\n따라서 \\(Z_4\\)를 조정 변수로 사용할 때는, 이로 인해 열리는 다른 경로(\\(Z_1 \\dots Z_2\\))를 막아줄 추가적인 변수(\\(Z_2\\) 등)를 함께 포함해야 합니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-03/index.html#case-z-emptyset-no-confounding",
    "href": "posts/lecture/L04/causal-inference-04-part-03/index.html#case-z-emptyset-no-confounding",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 3)",
    "section": "5.4 Case: \\(Z = \\emptyset\\) (No Confounding)",
    "text": "5.4 Case: \\(Z = \\emptyset\\) (No Confounding)\n\n만약 \\(X\\)로 들어오는 백도어 경로가 아예 없는 그래프라면 어떨까요?\n\n\n\n\nFigure 3. Case where no adjustment is needed\n\n\n\n이 경우 공집합 \\(Z = \\emptyset\\)도 Back-door Criterion을 만족합니다.\n즉, 별도의 조정 없이 관측된 조건부 확률이 곧 인과 효과가 됩니다.\n\n\\[P(y|x) = P(y|do(x))\\]\n\n이것이 바로 “교란이 없으면 상관관계는 인과관계이다(Correlation is Causation)”가 성립하는 유일한 순간입니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-03/index.html#recap-adjustment-by-direct-parents",
    "href": "posts/lecture/L04/causal-inference-04-part-03/index.html#recap-adjustment-by-direct-parents",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 3)",
    "section": "6.1 Recap: Adjustment by Direct Parents",
    "text": "6.1 Recap: Adjustment by Direct Parents\n\n일반적으로 \\(X\\)의 모든 직접적인 부모(Direct Parents, \\(Pa_X\\))를 통제하면 Back-door Criterion을 항상 만족합니다.\n\n\\[P(y|do(x)) = \\sum_{pa_X} P(y | x, pa_X) P(pa_X)\\]\n\n하지만 모든 부모 변수를 관측하는 것은 현실적으로 어려울 수 있습니다.\n그렇다면, 부모가 아닌 Back-door Criterion을 만족하는 임의의 집합 \\(Z\\)를 통제해도 왜 동일한 결과가 나올까요?\n아래 증명은 Direct Parents Adjustment 공식에서 시작하여 Back-door Adjustment 공식으로 유도되는 과정을 보여줍니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-03/index.html#가정-assumptions",
    "href": "posts/lecture/L04/causal-inference-04-part-03/index.html#가정-assumptions",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 3)",
    "section": "6.2 가정 (Assumptions)",
    "text": "6.2 가정 (Assumptions)\n\n집합 \\(Z\\)가 Back-door criterion을 만족한다고 가정합시다.\nLet \\(Z^- = Z \\setminus Pa_X\\) (부모 변수를 제외한 나머지 \\(Z\\)의 요소들).\n\n\nCondition (i): \\(Z\\)의 어떤 노드도 \\(X\\)의 자손이 아님. \\[\\Rightarrow X \\perp (Z \\setminus Pa_X) \\mid Pa_X\\] \\[\\Rightarrow P(z^{-} | x, pa_{X}) = P(z^{-} | pa_{X})\\]\n\n“미래는 과거를 바꿀 수 없다”는 원리입니다.\n인과 그래프에서 부모(\\(Pa_{X}\\))와 \\(Z\\)는 \\(X\\)보다 먼저 일어난 일(또는 원인)이고, \\(X\\)는 그 결과입니다.\n이미 부모(\\(Pa_{X}\\))의 상태를 다 알고 있다면, 결과인 \\(X\\)가 무엇이든 간에 그 원인이나 별개의 사건인 \\(Z\\)의 확률은 변하지 않습니다.\n\nCondition (ii): \\(Z\\)는 \\(X\\)로 들어오는 모든 뒷문 경로를 차단함. \\[\\Rightarrow Y \\perp (Pa_X \\setminus Z) \\mid Z, X\\] \\[\\Rightarrow P(y | x, pa_{X}, z^{-}) = P(y | x, z)\\] (\\(Z\\)와 \\(X\\)가 주어졌을 때, \\(Y\\)는 \\(Z\\)에 포함되지 않은 나머지 부모들과 독립이다)\n\n“Z가 이미 충분한 정보를 담고 있다”는 원리입니다.\n원래 \\(Y\\)를 예측하려면 교란 요인인 모든 부모들(\\(Pa_{X}\\))을 다 봐야 합니다. 하지만 \\(Z\\)가 ’백도어 기준’을 만족한다는 것은, \\(Z\\)가 부모들이 \\(Y\\)에 미치는 교란을 대신해서 다 막아주고 있다는 뜻입니다.\n따라서 일단 \\(Z\\)를 알고 나면, 굳이 \\(Z\\)에 포함되지 않은 나머지 부모들(\\(Pa_{X}\\))을 추가로 더 안다고 해서 \\(Y\\)에 대한 예측이 달라지지 않습니다. \\(Z\\)가 그 역할을 완벽히 대체했기 때문입니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-03/index.html#증명-derivation",
    "href": "posts/lecture/L04/causal-inference-04-part-03/index.html#증명-derivation",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 3)",
    "section": "6.3 증명 (Derivation)",
    "text": "6.3 증명 (Derivation)\n\n부모 변수를 통한 조정(Adjustment by Direct Parents) 공식에서 시작합니다.\n\n\\[\n\\begin{aligned}\nP(y|do(x)) &= \\sum_{pa_X} P(y|x, pa_X)P(pa_X) \\\\\n&= \\sum_{z^-, pa_X} P(y|x, pa_X, z^-)P(z^-|x, pa_X)P(pa_X) && \\because \\text{Expand by } Z^- \\text{ (Total Probability)} \\\\\n&= \\sum_{z^-, pa_X} P(y|x, z)P(z^-|pa_X)P(pa_X) && \\because \\text{Apply Assumptions Condition (i) \\& (ii)} \\\\\n&= \\sum_{z^-, pa_X} P(y|x, z)P(z^-, pa_X) && \\because \\text{Chain Rule } P(A|B)P(B) = P(A,B) \\\\\n&= \\sum_{z} P(y|x, z) \\sum_{pa_X \\setminus z} P(z^-, pa_X) && \\because \\text{Rearrange Summation } (Z \\cup (Pa_X \\setminus Z) = \\{Z, Pa_X\\}) \\\\\n&= \\sum_{z} P(y|x, z)P(z) && \\because \\text{Marginalize out } Pa_X \\setminus Z\n\\end{aligned}\n\\]\n\n결론: \n\n\nAdjustment by \\(Z\\) is equivalent to adjustment by direct parents whenever \\(Z\\) is back-door admissible.\n\n\n즉, \\(Z\\)가 Back-door criterion만 만족한다면, 직접적인 부모를 모두 측정하지 못하더라도 \\(Z\\)를 통해 인과 효과를 정확히 계산할 수 있음이 수학적으로 증명됩니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-05/index.html",
    "href": "posts/lecture/L04/causal-inference-04-part-05/index.html",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 5)",
    "section": "",
    "text": "이전 포스트들에서 배운 교란(Confounding)과 Back-door Criterion을 실제 코드로 구현해 보는 시간입니다.\n특히 심슨의 역설(Simpson’s Paradox) 상황을 시뮬레이션하고, DoWhy 라이브러리의 성향 점수 층화(Propensity Score Stratification) 방법을 통해 올바른 인과 효과를 추정해 봅니다."
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-05/index.html#모델-정의-및-식별-modeling-identification",
    "href": "posts/lecture/L04/causal-inference-04-part-05/index.html#모델-정의-및-식별-modeling-identification",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 5)",
    "section": "5.1 모델 정의 및 식별 (Modeling & Identification)",
    "text": "5.1 모델 정의 및 식별 (Modeling & Identification)\n\n인과 그래프(Graph)를 정의하고 Back-door 기준을 통해 식별 가능성을 확인합니다.\n\n\n\nCode\n# 단계 1: 모델 정의 (Causal Graph 생성)\nmodel = CausalModel(\n    data=df,\n    treatment='Exercise',\n    outcome='Cholesterol',\n    common_causes=['Age'] # 교란 변수 지정\n)\n\n# 단계 2: 식별 (Identification)\nidentified_estimand = model.identify_effect()\nprint(identified_estimand)\n\n\nEstimand type: EstimandType.NONPARAMETRIC_ATE\n\n### Estimand : 1\nEstimand name: backdoor\nEstimand expression:\n     d                         \n───────────(E[Cholesterol|Age])\nd[Exercise]                    \nEstimand assumption 1, Unconfoundedness: If U→{Exercise} and U→Cholesterol then P(Cholesterol|Exercise,Age,U) = P(Cholesterol|Exercise,Age)\n\n### Estimand : 2\nEstimand name: iv\nNo such variable(s) found!\n\n### Estimand : 3\nEstimand name: frontdoor\nNo such variable(s) found!"
  },
  {
    "objectID": "posts/lecture/L04/causal-inference-04-part-05/index.html#인과-효과-추정-estimation-stratification",
    "href": "posts/lecture/L04/causal-inference-04-part-05/index.html#인과-효과-추정-estimation-stratification",
    "title": "[Causal Inference] 04. Confounding and Backdoor (Part 5)",
    "section": "5.2 인과 효과 추정 (Estimation: Stratification)",
    "text": "5.2 인과 효과 추정 (Estimation: Stratification)\n\n여기서는 성향 점수 층화(Propensity Score Stratification) 방법을 사용합니다. 나이가 비슷하여 운동할 확률(성향 점수)이 유사한 사람들끼리 묶어서 비교하는 방식입니다.\n\n\n\nCode\n# 단계 3: 추정 (Estimation)\n# num_strata=5: 데이터를 성향 점수에 따라 5개 구간으로 나눔\nestimate = model.estimate_effect(\n    identified_estimand,\n    method_name=\"backdoor.propensity_score_stratification\",\n    method_params={'num_strata': 5, 'clipping_threshold': 5}\n)\n\nprint(\"=\"*50)\nprint(f\"2. 인과 효과 추정 (Causal Estimate): {estimate.value:.4f}\")\nprint(f\"   -&gt; 실제 효과 (-10.0)에 매우 근접함\")\nprint(\"=\"*50)\n\n\n==================================================\n2. 인과 효과 추정 (Causal Estimate): -9.1264\n   -&gt; 실제 효과 (-10.0)에 매우 근접함\n=================================================="
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-02/index.html",
    "href": "posts/lecture/L15/causal-inference-15-part-02/index.html",
    "title": "[Causal Inference] 15. DiD & SCM (Part 2)",
    "section": "",
    "text": "지난 포스트에서 다룬 표준 이중차분법(Standard DiD)은 강력하지만, 중요한 가정을 전제로 합니다.\n바로 “평행 추세(Parallel Trends)” 가정입니다.\n하지만 이 가정은 결과 변수(\\(Y\\))의 선형성(Linearity)에 의존적이라는 한계가 있습니다.\n예를 들어, 소득(\\(Y\\))에 대해서는 평행 추세가 성립하더라도, 로그 소득(\\(\\log Y\\))에 대해서는 성립하지 않을 수 있습니다(Not invariant to nonlinear transformations).\n만약 정책 효과가 소득 구간별로 다르게 나타난다면(예: 저소득층에게 더 큰 효과), 평균값의 변화만 보는 선형 DiD는 이러한 분포의 변화를 놓치게 됩니다.\n이번 포스트에서는 이러한 선형성 가정을 완화하고, 분포 전체의 변화를 추정할 수 있는 비선형 이중차분법(Nonlinear DiD), 일명 Changes-in-Changes (CiC) 모델에 대해 알아봅니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-02/index.html#시각적-설명",
    "href": "posts/lecture/L15/causal-inference-15-part-02/index.html#시각적-설명",
    "title": "[Causal Inference] 15. DiD & SCM (Part 2)",
    "section": "시각적 설명",
    "text": "시각적 설명\n\n아래 그림은 통제 집단(Control)과 처치 집단(Treated)의 누적 분포 함수(CDF)가 시간이 지남에 따라 어떻게 변하는지를 보여줍니다.\n\n\n\n\nFigure: \\(x\\)축은 결과값, \\(y\\)축은 확률(0~1)을 나타냅니다. \\(r_0(q)\\)와 \\(r_1(q)\\)는 각각 통제 집단과 처치 집단에서 특정 분위수 \\(q\\)에 해당하는 값의 시간적 변화(매핑)를 의미합니다.\n\n\n\n통제 집단의 변화 (\\(r_0(q)\\)): \\(t=0\\) 시점의 \\(q\\) 분위수 값이 \\(t=1\\) 시점에 어떻게 변했는지 보여줍니다.\n가정: 처치 집단이 처치를 받지 않았더라면, “시간에 따른 분위수의 변화 양상”이 통제 집단과 동일했을 것이라고 가정합니다.\n즉, 통제 집단에서의 매핑(화살표)을 처치 집단에 그대로 적용하여 반사실(Counterfactual)을 구성합니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-02/index.html#분포-함수-distribution-functions",
    "href": "posts/lecture/L15/causal-inference-15-part-02/index.html#분포-함수-distribution-functions",
    "title": "[Causal Inference] 15. DiD & SCM (Part 2)",
    "section": "2.1 분포 함수 (Distribution Functions)",
    "text": "2.1 분포 함수 (Distribution Functions)\n\n우선, 각 집단(\\(G_i=g\\))과 시점(\\(t\\))에서의 잠재적 결과(Potential Outcome) \\(Y(0)\\)(처치받지 않음)의 누적 분포 함수를 정의합니다. \\[\nF_{gt}(y) = P(Y_{it}(0) \\le y | G_i = g)\n\\]\n\n\\(g \\in \\{0, 1\\}\\textit{(0: 통제, 1: 처치)}\\)\n\\(t \\in \\{0, 1\\}\\textit{(0: 전, 1: 후)}\\)\n\n우리가 관찰할 수 있는 분포들은 \\(F_{00}, F_{01}, F_{10}\\)입니다.\n처치 집단의 사후 결과인 \\(F_{11}\\)은 처치(\\(Y(1)\\))를 받은 상태이므로, 처치를 받지 않았을 상태(\\(Y(0)\\))인 \\(F_{11}\\)은 반사실(Counterfactual)로서 식별해야 할 대상입니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-02/index.html#분위수-처치-효과-quantile-treatment-effect-qte",
    "href": "posts/lecture/L15/causal-inference-15-part-02/index.html#분위수-처치-효과-quantile-treatment-effect-qte",
    "title": "[Causal Inference] 15. DiD & SCM (Part 2)",
    "section": "2.2 분위수 처치 효과 (Quantile Treatment Effect, QTE)",
    "text": "2.2 분위수 처치 효과 (Quantile Treatment Effect, QTE)\n\n우리의 목표는 특정 분위수 \\(q\\)에서의 처치 효과 \\(\\tau(q)\\)를 구하는 것입니다. \\[\n\\tau(q) = \\underbrace{\\tilde{F}_{11}^{-1}(q)}_{\\text{관측값}} - \\underbrace{F_{11}^{-1}(q)}_{\\text{반사실(추정값)}}\n\\]\n\n\\(\\tilde{F}_{11}(y) = P(Y_{i1}(1) \\le y | G_i = 1)\\):\n\n실제로 관측된 처치 집단의 사후 결과 분포 (\\(Y(1)\\)).\n\n\\(F_{11}(y)\\):\n\n우리가 추정해야 할 처치 집단의 반사실적 사후 결과 분포 (\\(Y(0)\\))."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-02/index.html#식별-가정-identification-assumption",
    "href": "posts/lecture/L15/causal-inference-15-part-02/index.html#식별-가정-identification-assumption",
    "title": "[Causal Inference] 15. DiD & SCM (Part 2)",
    "section": "3.1 식별 가정 (Identification Assumption)",
    "text": "3.1 식별 가정 (Identification Assumption)\n\n모든 분위수 \\(q \\in [0, 1]\\)에 대하여 다음이 성립한다고 가정합니다.\n\n\\[\nF_{01}(F_{00}^{-1}(q)) = F_{11}(F_{10}^{-1}(q))\n\\]\n\n이 수식의 의미를 단계별로 풀어보겠습니다.\n\n\n좌변 (\\(F_{01}(F_{00}^{-1}(q))\\)):\n\n\n통제 집단에서 시점 0에 \\(q\\) 분위수에 해당하는 값(\\(F_{00}^{-1}(q)\\))을 찾습니다.\n그 값이 시점 1의 분포(\\(F_{01}\\))에서 차지하는 위치(확률)를 봅니다.\n즉, 통제 집단에서 시간이 흐름에 따라 순위(Rank)가 어떻게 변했는지를 나타냅니다.\n\n\n우변 (\\(F_{11}(F_{10}^{-1}(q))\\)):\n\n\n처치 집단에서도 동일하게, 시점 0에 \\(q\\) 분위수에 해당하는 값(\\(F_{10}^{-1}(q)\\))을 찾습니다.\n그 값이 시점 1의 반사실 분포(\\(F_{11}\\))에서 갖게 될 위치를 나타냅니다.\n\n\n결론: “시간에 따른 상대적 위치(Rank)의 변화 함수”는 두 집단 간에 동일하다는 것입니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-02/index.html#반사실-분포-f_11y의-유도-과정",
    "href": "posts/lecture/L15/causal-inference-15-part-02/index.html#반사실-분포-f_11y의-유도-과정",
    "title": "[Causal Inference] 15. DiD & SCM (Part 2)",
    "section": "3.2 반사실 분포 \\(F_{11}(y)\\)의 유도 과정",
    "text": "3.2 반사실 분포 \\(F_{11}(y)\\)의 유도 과정\n\n우리는 \\(F_{11}(y)\\)를 구하고 싶습니다. 위 식별 가정을 이용하여 이를 \\(y\\)에 대한 함수로 정리해 봅시다.\n단계 1: 목표 변수 설정\n\n우변의 \\(F_{11}(\\cdot)\\) 안에 있는 \\(F_{10}^{-1}(q)\\)를 \\(y\\)라고 둡니다.\n즉, 어떤 결과값 \\(y\\)가 처치 집단의 사전 시점(\\(t=0\\))에서 갖는 누적 확률(분위수)을 \\(q'\\)라고 합시다.\n\n\n\\[\ny = F_{10}^{-1}(q') \\iff q' = F_{10}(y)\n\\]\n\n단계 2: 가정식에 대입\n\n식별 가정 식의 \\(q\\) 자리에 \\(q' = F_{10}(y)\\)를 대입합니다. \\[\nF_{01}(F_{00}^{-1}(q')) = F_{11}(F_{10}^{-1}(q'))\n\\]\n여기에 \\(q'\\)와 \\(y\\)의 관계를 적용하면: \\[\nF_{01}(F_{00}^{-1}(F_{10}(y))) = F_{11}(y)\n\\]\n\n단계 3: 결과 도출\n따라서, 처치 집단이 처치를 받지 않았을 때(\\(t=1\\))의 잠재적 분포 \\(F_{11}(y)\\)는 관찰 가능한 데이터(\\(F_{01}, F_{00}, F_{10}\\))만으로 다음과 같이 식별됩니다.\n\n\\[\nF_{11}(y) = F_{01}\\left[ F_{00}^{-1} \\{ F_{10}(y) \\} \\right]\n\\]"
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-02/index.html#해석",
    "href": "posts/lecture/L15/causal-inference-15-part-02/index.html#해석",
    "title": "[Causal Inference] 15. DiD & SCM (Part 2)",
    "section": "3.3 해석",
    "text": "3.3 해석\n\n이 최종 수식은 다음과 같은 알고리즘으로 이해할 수 있습니다.\n\n\n\\(F_{10}(y)\\): 처치 집단의 \\(t=0\\) 시점에서 결과값 \\(y\\)의 분위수(Rank)를 찾습니다.\n\n\n\\(F_{00}^{-1}(\\cdot)\\): 통제 집단의 \\(t=0\\) 시점에서 동일한 분위수를 가진 결과값을 찾습니다. (집단 간 비교 기준점 확보)\n\n\n\\(F_{01}(\\cdot)\\): 그 결과값이 통제 집단의 \\(t=1\\) 시점에서 갖는 새로운 분위수를 확인합니다. (시간 효과 반영)\n\n\n\\(F_{11}(y)\\): 이 “변환된 분위수”가 바로 처치 집단(\\(t=1\\))에서 \\(y\\)가 가질 누적 확률입니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-02/index.html#요약-및-시사점",
    "href": "posts/lecture/L15/causal-inference-15-part-02/index.html#요약-및-시사점",
    "title": "[Causal Inference] 15. DiD & SCM (Part 2)",
    "section": "4. 요약 및 시사점",
    "text": "4. 요약 및 시사점\n\n비선형 DiD(CiC)는 평균값 비교에 그치는 기존 DiD의 한계를 넘어, 정책이 전체 소득 분포나 특정 분위수(예: 하위 10%)에 미치는 영향을 정밀하게 분석할 수 있게 해줍니다.\n장점:\n\n로그 변환 등 결과 변수의 비선형 변환에 영향을 받지 않습니다(Invariant).\n평균뿐만 아니라 분포 전체의 처치 효과(QTE)를 추정할 수 있습니다.\n\n조건:\n\n연속적인 결과 변수에 적합하며, 역함수(\\(F^{-1}\\))가 존재해야 하므로 분포 함수가 강단조증가(strictly increasing)해야 한다는 조건이 필요할 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "",
    "text": "이번 포스트에서는 인과추론의 가장 강력하고 널리 쓰이는 도구 중 하나인 이중차분법(Differences in Differences, DiD)에 대해 다룹니다.\n특히 잠재적 결과(Potential Outcomes) 프레임워크를 기반으로 DiD 추정량이 도출되는 과정을 수학적으로 엄밀하게 살펴보겠습니다.\n\n\n참고 자료: 본 포스트는 이상학 교수님의 “Differences in Differences & Synthetic Control Method” 강의 자료를 바탕으로 재구성되었습니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html#basic-setup",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html#basic-setup",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "1.1 Basic Setup",
    "text": "1.1 Basic Setup\n\n두 개의 그룹과 두 개의 시점이 있다고 가정해 봅시다.\n집단 (Groups):\n\n\\(G_i = 1\\): 처치 집단 (Treated Group, 예: 최저임금이 인상된 뉴저지주)\n\\(G_i = 0\\): 통제 집단 (Control Group, 예: 최저임금이 동결된 펜실베이니아주)\n\n시점 (Time Periods):\n\n\\(t = 0\\): 개입 이전 (Pre-period)\n\\(t = 1\\): 개입 이후 (Post-period)"
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html#potential-outcomes",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html#potential-outcomes",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "1.2 Potential Outcomes",
    "text": "1.2 Potential Outcomes\n\n\\(Y_{it}(x)\\)를 시점 \\(t\\)에서 처치 상태가 \\(x\\)일 때 개인 \\(i\\)의 잠재적 결과라고 정의합니다.\n우리가 실제로 관찰하는 결과 \\(Y_{it}\\)는 일치성(Consistency) 가정에 의해 다음과 같이 표현됩니다.\n\n\\[\nY_{it} = G_{it}Y_{it}(1) + (1-G_{it})Y_{it}(0)\n\\]\n\n아래 테이블은 DiD 디자인에서 관측되는 잠재적 결과(Potential Outcomes)의 기댓값을 나타냅니다.\n\n\n\n\n\n\n\n\n\n\nPre-period (\\(t=0\\))\nPost-period (\\(t=1\\))\n\n\n\n\nTreated group (\\(G_i=1\\))\n\\(\\color{purple}{\\mathbb{E}[Y_{i0}(0) \\mid G_i=1]}\\)\n\\(\\color{green}{\\mathbb{E}[Y_{i1}(1) \\mid G_i=1]}\\)\n\n\nControl group (\\(G_i=0\\))\n\\(\\color{orange}{\\mathbb{E}[Y_{i0}(0) \\mid G_i=0]}\\)\n\\(\\color{blue}{\\mathbb{E}[Y_{i1}(0) \\mid G_i=0]}\\)"
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html#att",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html#att",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "1.3 ATT",
    "text": "1.3 ATT\n\n우리의 목표는 처치 집단에 대한 평균 처치 효과(ATT: Average Treatment Effect on the Treated)를 구하는 것입니다.\n\n\\[\n\\tau_{ATT} = \\mathbb{E}[{\\color{green}{Y_{i1}(1)}} - {\\color{red}{Y_{i1}(0)}} | G_i=1]\n\\]\n\n이 식을 풀면 다음과 같습니다. \\[\n\\tau_{ATT} = \\underbrace{\\color{green}{\\mathbb{E}[Y_{i0}(0) \\mid G_i=1]}}_{\\text{(a) 관찰 가능}} - \\underbrace{\\color{red}{\\mathbb{E}[Y_{i1}(0) | G_i=1]}}_{\\text{(b) 반사실 (관찰 불가)}}\n\\]\n\n(a): 처치를 받은 집단의 처치 후 결과이므로 데이터에서 관찰할 수 있습니다.\n(b):\n\n문제의 핵심입니다.\n처치를 받은 집단이 만약 처치를 받지 않았더라면 겪었을 결과입니다.\n이는 현실에 존재하지 않으므로, 적절한 대조군을 통해 추정해야 합니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html#three-control-strategies",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html#three-control-strategies",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "2. Three Control Strategies",
    "text": "2. Three Control Strategies\n\n반사실 \\(\\mathbb{E}[Y_{i1}(0) | G_i=1]\\)을 대체하기 위해 우리는 어떤 전략을 취할 수 있을까요?\n\n\n\n\nFigure: \\(x\\)축은 시간(Time), \\(y\\)축은 평균 결과(Average Outcome)를 나타내며, 처치 집단과 통제 집단의 변화 추이를 시각화한 그래프입니다.\n\n\n\n전략 1: 전후 비교 (Before-and-After Design)\n\n처치 집단의 개입 이전 시점(\\(t=0\\)) 결과를 반사실로 사용하는 방법입니다.\n\n\\[\n{\\color{red}{\\mathbb{E}[Y_{i1}(0) | G_i=1]}} \\approx {\\color{purple}{\\mathbb{E}[Y_{i0}(0) | G_i=1]}}\n\\]\n\n가정: 시간이 지나도 결과에 자연적인 변화(Trend)가 없어야 합니다.\n한계: 경기 변동이나 계절적 요인 등 시간의 흐름에 따른 변화를 무시합니다.\n\n\n\n전략 2: 횡단면 비교 (Cross-sectional Design)\n\n가장 단순한 접근은 처치 후 시점(\\(t=1\\))에서 통제 집단의 결과를 반사실로 사용하는 것입니다.\n\n\\[\n{\\color{red}{\\mathbb{E}[Y_{i1}(0) | G_i=1]}} \\approx {\\color{blue}{\\mathbb{E}[Y_{i1}(0) | G_i=0]}}\n\\]\n\n가정: 처치 여부가 결과와 독립적이어야 합니다 (Selection Bias가 없어야 함).\n한계: 두 집단은 처치 여부 외에도 원래부터 다른 특성을 가질 수 있습니다. 예를 들어, 뉴저지와 펜실베이니아는 경제 상황이 다를 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html#평행-추세-가정-parallel-trends-assumption",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html#평행-추세-가정-parallel-trends-assumption",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "3.1 평행 추세 가정 (Parallel Trends Assumption)",
    "text": "3.1 평행 추세 가정 (Parallel Trends Assumption)\n\nDiD의 핵심 가정입니다.\n“처치가 없었더라면, 처치 집단의 평균 결과 변화량은 통제 집단의 변화량과 같았을 것”이라는 가정입니다.\n수식으로는 다음과 같습니다: \\[\n\\mathbb{E}[{\\color{red}{Y_{i1}(0)}} - {\\color{purple}{Y_{i0}(0)}} | G_i=1] = \\mathbb{E}[{\\color{blue}{Y_{i1}(0)}} -  {\\color{orange}{Y_{i0}(0)}} | G_i=0]\n\\]\n이 가정을 이용해 우리가 모르는 반사실을 유도해 봅시다.\n위 식을 이항하면 반사실 \\(\\mathbb{E}[Y_{i1}(0) | G_i=1]\\)은 다음과 같이 표현됩니다.\n\n\\[\n\\underbrace{{\\color{red}{\\mathbb{E}[Y_{i1}(0) | G_i=1]}}}_{\\text{반사실}} = \\underbrace{{\\color{purple}{\\mathbb{E}[Y_{i0}(0) | G_i=1]}}}_{\\text{처치집단 초기값}} + \\underbrace{({\\color{blue}{\\mathbb{E}[Y_{i1}(0) | G_i=0]}} - {\\color{orange}{\\mathbb{E}[Y_{i0}(0) | G_i=0]}})}_{\\text{통제집단의 시간 추세}}\n\\]\n\n즉, 처치 집단의 초기값에 통제 집단에서 관찰된 ’시간에 따른 변화분(Trend)’을 더해주면, 처치 집단이 처치를 받지 않았을 때의 결과를 추정할 수 있습니다.\n\n\n\n\nFigure: 점선으로 표시된 부분은 평행 추세 가정에 기반하여 생성된 Counterfactual 지점입니다. 처치 집단(빨간색)의 실제 결과와 점선(Counterfactual)의 차이가 바로 인과 효과입니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html#did-identification-result",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html#did-identification-result",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "3.2 DiD Identification Result",
    "text": "3.2 DiD Identification Result\n\n이제 ATT 식에 위에서 구한 반사실을 대입해 보겠습니다.\n\n\\[\n\\begin{aligned}\n\\tau_{ATT} &= {\\color{green}{\\mathbb{E}[Y_{i1} | G_i=1]}} - {\\color{red}{\\mathbb{E}[Y_{i1}(0) | G_i=1]}} \\\\\n&= {\\color{green}{\\mathbb{E}[Y_{i1} | G_i=1]}} - \\left({\\color{purple}{\\mathbb{E}[Y_{i0} | G_i=1]}} + ({\\color{blue}{\\mathbb{E}[Y_{i1} | G_i=0]}} - {\\color{orange}{\\mathbb{E}[Y_{i0} | G_i=0]}}) \\right) \\\\\n&= \\left( {\\color{green}{\\mathbb{E}[Y_{i1} | G_i=1]}} - {\\color{purple}{\\mathbb{E}[Y_{i0} | G_i=1]}} \\right) - \\left( {\\color{blue}{\\mathbb{E}[Y_{i1} | G_i=0]}} - {\\color{orange}{\\mathbb{E}[Y_{i0} | G_i=0]}} \\right)\n\\end{aligned}\n\\]\n\n이 수식이 의미하는 바는 명확합니다:\n\n\nFirst Difference: 처치 집단의 전후 차이를 구합니다 (시간 효과 + 처치 효과).\n\n\nSecond Difference: 통제 집단의 전후 차이를 구합니다 (순수 시간 효과).\n\n\nDifference-in-Differences: 1번에서 2번을 빼면 순수한 처치 효과(Treatment Effect)만 남습니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html#이원-고정-효과-모형-two-way-fixed-effects-model",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html#이원-고정-효과-모형-two-way-fixed-effects-model",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "4.1 이원 고정 효과 모형 (Two-way Fixed Effects Model)",
    "text": "4.1 이원 고정 효과 모형 (Two-way Fixed Effects Model)\n\n단순한 평균의 차감 계산이 아니라, 회귀분석을 이용하면 표준오차(Standard Error)를 계산하고 다른 공변량을 통제하기 용이합니다.\n\n\n4.1.1 회귀식의 정의\n\n패널 데이터(혹은 반복 횡단면 데이터)에 대해 다음과 같은 선형 회귀식을 설정합니다.\n\n\\[\nY_{it} = \\alpha + \\gamma G_i + \\beta t + \\tau X_{it} + \\epsilon_{it}\n\\]\n\n여기서 변수들의 정의는 다음과 같습니다.\n\n\\(G_i\\): 집단 더미 (Group Dummy). 처치 집단이면 1, 통제 집단이면 0.\n\\(t\\): 시점 더미 (Time Dummy). 개입 이후(Post)면 1, 이전(Pre)이면 0.\n\\(X_{it}\\): 상호작용항 (Interaction Term). \\(G_i \\times t\\)와 동일하며, ‘처치 집단이면서 동시에 개입 이후인 경우’에만 1을 갖습니다.\n\n\n\n\n4.1.2 계수의 유도 과정 (Derivation)\n\n이 식을 이용해 4가지 경우의 수(처치/통제 \\(\\times\\) 전/후)에 대한 기댓값 \\(E[Y_{it}]\\)를 계산해보면 각 계수의 의미가 명확해집니다.\n\n\n\n\n\n\n\n\n\n\n\n\n구분\n시점 (\\(t\\))\n집단 (\\(G_i\\))\n상호작용 (\\(X_{it}\\))\n기댓값 \\(E[Y_{it}]\\)\n의미\n\n\n\n\n통제 집단 / 전\n0\n0\n0\n\\(\\alpha\\)\n베이스라인\n\n\n통제 집단 / 후\n1\n0\n0\n\\(\\alpha + \\beta\\)\n시간의 흐름에 따른 자연적 변화 (\\(\\beta\\)) 반영\n\n\n처치 집단 / 전\n0\n1\n0\n\\(\\alpha + \\gamma\\)\n집단 간의 고유한 차이 (\\(\\gamma\\)) 반영\n\n\n처치 집단 / 후\n1\n1\n1\n\\(\\alpha + \\gamma + \\beta + \\tau\\)\n시간(\\(\\beta\\)) + 집단(\\(\\gamma\\)) + 정책효과(\\(\\tau\\))\n\n\n\n\n\n4.1.3 이중차분 (Difference-in-Differences) 계산\n\n위의 표를 바탕으로 DiD 연산을 수행해 봅시다.\n\n시간 전후 차이 (After - Before):\n\n\n통제 집단의 변화: \\((\\alpha + \\beta) - \\alpha = \\mathbf{\\beta}\\) (순수 시간 효과)\n처치 집단의 변화: \\((\\alpha + \\gamma + \\beta + \\tau) - (\\alpha + \\gamma) = \\mathbf{\\beta + \\tau}\\) (시간 효과 + 처치 효과)\n\n\n집단 간 차이 (Treated - Control):\n\n\n변화량의 차이: \\((\\beta + \\tau) - \\beta = \\mathbf{\\tau}\\)\n\n결론적으로 회귀계수 \\(\\tau\\)는 우리가 구하고자 하는 이중차분 추정량(ATT)과 정확히 일치합니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html#실제-사례-card-krueger-1994",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html#실제-사례-card-krueger-1994",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "4.2 실제 사례: Card & Krueger (1994)",
    "text": "4.2 실제 사례: Card & Krueger (1994)\n\n최저임금 인상이 고용에 미치는 영향을 분석한 고전적인 연구입니다.\nQuestion: 최저임금을 올리면 고용이 감소하는가?\nSetting: 1992년 뉴저지(NJ)는 최저임금을 $4.25에서 $5.05로 인상(처치 집단), 펜실베이니아(PA)는 동결(통제 집단).\nResult: 두 주(State)의 패스트푸드점 고용 변화를 DiD로 분석한 결과, 통념과 달리 고용 감소 효과가 뚜렷하지 않음을 보였습니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html#ashenfelters-dip",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html#ashenfelters-dip",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "5.1 Ashenfelter’s Dip",
    "text": "5.1 Ashenfelter’s Dip\n\n직업 훈련 프로그램 등의 효과를 분석할 때 자주 나타나는 현상입니다.\n처치를 받기 직전에 소득이 일시적으로 급락하는 현상을 말합니다.\n이 경우 처치 이전의 추세가 평행하지 않을 수 있으므로 주의해야 합니다."
  },
  {
    "objectID": "posts/lecture/L15/causal-inference-15-part-01/index.html#위조-검증-falsification-test",
    "href": "posts/lecture/L15/causal-inference-15-part-01/index.html#위조-검증-falsification-test",
    "title": "[Causal Inference] 15. DiD & SCM (Part 1)",
    "section": "5.2 위조 검증 (Falsification Test)",
    "text": "5.2 위조 검증 (Falsification Test)\n\n평행 추세 가정을 간접적으로 검증하기 위해 개입 이전 시점(Pre-treatment period)들의 데이터를 사용합니다.\n개입이 없었던 과거 기간 동안에도 두 집단의 추세가 평행했는지 확인하는 것입니다. 만약 과거에도 추세가 달랐다면, 미래에도 달랐을 가능성이 높습니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "",
    "text": "지난 포스트에서 선형 모형(Linear Model) 가정 하의 IV를 다루었다면, 이번에는 무작위 실험(Randomized Experiment)에서 배정된 처치를 따르지 않는 ’불순응(Noncompliance)’이 발생했을 때의 IV 접근법을 다룹니다.\n경제학에서 도구변수(IV)는 주로 무작위 실험이 아닌 관찰 연구(Observational Study)에서 ’자연 실험(Natural Experiment)’의 일종으로 사용됩니다.\n좋은 도구변수 \\(Z\\)가 되기 위해서는 다음 두 가지 조건을 만족해야 합니다.\n\nRelevance (관련성): 도구변수 \\(Z\\)는 처치 \\(X\\)에 강한 영향을 미쳐야 합니다. (\\(Cov(X,Z)\\)가 커야 함). 그렇지 않으면(Weak IV), 추정량의 분산이 매우 커집니다.\nExclusion Restriction (배제 제약): 도구변수 \\(Z\\)는 결과 \\(Y\\)에 직접적인 영향을 미치지 않아야 하며, 오직 \\(X\\)를 통해서만 영향을 주어야 합니다.\n\n\n\n\n\nFigure 1: IV DAG regarding Noncompliance. Z(배정)가 X(실제 처치)를 통해 Y(결과)에 영향을 미치는 구조입니다. 점선 화살표는 잠재적 교란 요인을 의미합니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html#변수-정의",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html#변수-정의",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "2.1. 변수 정의",
    "text": "2.1. 변수 정의\n\n\\(Z_i\\) (Instrument/Assignment): 처치 배정 여부 (0 또는 1). 무작위 배정(Random Assignment)을 가정합니다.\n\\(X_i\\) (Treatment Received): 실제 처치를 받았는지 여부. \\(Z\\) 이후에 결정되므로(Post-treatment), \\(Z\\)에 따른 잠재적 결과를 가집니다.\n\n\\(X_i(z)\\): \\(Z=z\\)일 때 개인이 받게 될 처치 여부.\n\n\\(Y_i\\) (Outcome): 결과 변수.\n\n\\(Y_i(z, x)\\): 배정이 \\(z\\)이고 실제 처치가 \\(x\\)일 때의 잠재적 결과.\n일반적으로 Exclusion Restriction 가정 하에서 \\(Y_i(z=0, x) = Y_i(z=0, 1)\\)이므로 \\(Y_i(x)\\)로 표기.\n\n우리가 관측하는 데이터는 \\(Z_i, X_i = X_i(Z_i), Y_i = Y_i(Z_i)\\) 입니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html#순응-유형-compliance-types",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html#순응-유형-compliance-types",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "2.2. 순응 유형 (Compliance Types)",
    "text": "2.2. 순응 유형 (Compliance Types)\n\n사람들이 처치 배정(\\(Z\\))에 어떻게 반응하여 실제 처치(\\(X\\))를 받는지에 따라 4가지 잠재적 집단(Latent Subgroups)으로 나눌 수 있습니다.\n이를 \\(X_i(0)\\)와 \\(X_i(1)\\)의 조합으로 정의합니다.\n\n\n\n\n\n\n\n\n\n\nType\n\\(X_i(0)\\)\n\\(X_i(1)\\)\nDescription\n\n\n\n\nNever-taker\n0\n0\n배정을 받든 안 받든 처치를 받지 않음\n\n\nComplier\n0\n1\n배정받으면 처치 받고, 안 받으면 안 받음 (순응자)\n\n\nDefier\n1\n0\n배정과 반대로 행동함 (청개구리)\n\n\nAlways-taker\n1\n1\n배정을 받든 안 받든 항상 처치를 받음\n\n\n\n\nNote: 우리는 각 개인의 진짜 Type(\\(S\\))을 완벽하게 알 수 없습니다. 예를 들어 관측된 데이터에서 \\(Z=1, X=1\\)인 사람은 ’Complier’일 수도 있고 ’Always-taker’일 수도 있습니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html#itt-intent-to-treat-effects",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html#itt-intent-to-treat-effects",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "3.1. ITT (Intent-To-Treat) Effects",
    "text": "3.1. ITT (Intent-To-Treat) Effects\n\nITT 효과는 처치 배정(\\(Z\\))이 결과(\\(Y\\))에 미치는 인과적 효과입니다.\n개인의 순응 유형(\\(S\\))은 \\(Z\\)에 따라 변하지 않는 ’Baseline Characteristic’으로 간주할 수 있습니다.\n각 유형 \\(s \\in \\{c, n, a, d\\}\\)에 대한 ITT 효과는 다음과 같습니다. \\[ITT_s = \\mathbb{E}[Y_i(1) - Y_i(0) | S_i = s]\\]\n전체 모집단에 대한 Global ITT는 각 유형별 ITT의 가중 평균으로 표현됩니다. \\[\n\\begin{aligned}\nITT &= \\mathbb{E_s}[\\mathbb{E}[Y_i(1) - Y_i(0) | S_i = s]] \\\\\n&= \\pi_c ITT_c + \\pi_n ITT_n + \\pi_a ITT_a + \\pi_d ITT_d\n\\end{aligned}\n\\]\n\n여기서 \\(\\pi_s\\)는 각 유형의 구성 비율입니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html#식별을-위한-가정-assumptions",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html#식별을-위한-가정-assumptions",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "3.2. 식별을 위한 가정 (Assumptions)",
    "text": "3.2. 식별을 위한 가정 (Assumptions)\n\n비모수적 식별(Nonparametric Identification)을 위해 다음 3가지 핵심 가정이 필요합니다.\nAssumption 1: Random Assignment (무작위 배정) \\[\\{Y_i(0), Y_i(1), X_i(0), X_i(1)\\} \\perp Z_i\\]\n\n도구변수 \\(Z\\)가 잠재적 결과들과 독립이라는 가정입니다.\n\nAssumption 2: Strong Monotonicity (강한 단조성)\n\n\nNo Defiers:\n\n\n모든 \\(i\\)에 대해 \\(X_i(1) \\ge X_i(0)\\)\n우리의 예시에서는 \\(Z, X \\in \\{0, 1\\}\\) 이므로, \\(X_i(1) = 1 \\ge X_i(0) = 0\\)\n즉, 배정을 받았을 때 처치를 받을 확률이 배정을 안 받았을 때보다 작아지지는 않는다는 것입니다.\n이 가정에 의해 \\(\\pi_d = 0\\)이 됩니다.\n\n\nExistence of Compliers:\n\n\n\\(0 &lt; P(X_i=1 | Z_i=1) &lt; 1\\)\nComplier가 존재해야 합니다.\n\n\nAssumption 3: Exclusion Restriction (ER) for Noncompliers\n\n불순응자(Never-taker, Always-taker)에게는 배정(\\(Z\\)) 자체가 결과(\\(Y\\))에 영향을 주지 않아야 합니다.\n이들은 어차피 \\(Z\\)와 상관없이 동일한 \\(X\\)를 선택하기 때문입니다. \\[Y_i(1) = Y_i(0) \\quad \\text{for } S_i \\in \\{n, a\\}\\]\n따라서, \\(ITT_n = 0\\), \\(ITT_a = 0\\) 입니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html#유도-과정",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html#유도-과정",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "4.1. 유도 과정",
    "text": "4.1. 유도 과정\n\n원래 식: \\[ITT = \\pi_c ITT_c + \\pi_n ITT_n + \\pi_a ITT_a + \\pi_d ITT_d\\]\n\n\nMonotonicity 가정 적용: Defier가 없으므로 \\(\\pi_d = 0\\). \\[\\Rightarrow ITT = \\pi_c ITT_c + \\pi_n ITT_n + \\pi_a ITT_a\\]\nExclusion Restriction 가정 적용: Noncomplier의 ITT는 0이므로 \\(ITT_n = 0, ITT_a = 0\\). \\[\\Rightarrow ITT = \\pi_c ITT_c\\]\n\n\n결국 전체 ITT 효과는 Complier의 비율(\\(\\pi_c\\)) \\(\\times\\) Complier의 ITT 효과(\\(ITT_c\\))가 됩니다.\n이를 \\(ITT_c\\)에 대해 정리하면 다음과 같습니다.\n\n\\[ITT_c = \\frac{ITT}{\\pi_c}\\]\n\n이때, Complier에게는 \\(Z=X\\)이므로, \\(ITT_c\\)는 곧 Complier가 처치를 받았을 때의 인과 효과인 CACE가 됩니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html#complier-비율-pi_c-추정",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html#complier-비율-pi_c-추정",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "4.2. Complier 비율 (\\(\\pi_c\\)) 추정",
    "text": "4.2. Complier 비율 (\\(\\pi_c\\)) 추정\n\n관측된 데이터로 \\(\\pi_c\\)를 어떻게 구할까요?\n\n\\[\n\\begin{aligned}\n\\mathbb{E}[X_i | Z_i = 1] &= \\pi_c \\cdot 1 + \\pi_a \\cdot 1 + \\pi_n \\cdot 0 \\quad (\\text{Complier \\& Always-taker}) \\\\\n\\mathbb{E}[X_i | Z_i = 0] &= \\pi_c \\cdot 0 + \\pi_a \\cdot 1 + \\pi_n \\cdot 0 \\quad (\\text{Always-taker only})\n\\end{aligned}\n\\]\n\n두 식을 빼면:\n\n\\[\\mathbb{E}[X_i | Z_i = 1] - \\mathbb{E}[X_i | Z_i = 0] = \\pi_c\\]\n\n이것은 \\(Z\\)가 \\(X\\)에 미치는 ITT 효과(\\(ITT_X\\))와 같습니다.\n\n\\[ITT_X = \\mathbb{E}[X_i(1) - X_i(0)] = \\pi_c\\]"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html#cace-late-공식",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html#cace-late-공식",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "4.3. CACE / LATE 공식",
    "text": "4.3. CACE / LATE 공식\n\n최종적으로 CACE는 다음과 같이 두 ITT의 비율로 표현됩니다.\n\n\\[CACE \\equiv \\mathbb{E}[Y_i(1) - Y_i(0) | S_i = c] = \\frac{ITT_Y}{ITT_X} = \\frac{\\mathbb{E}[Y|Z=1] - \\mathbb{E}[Y|Z=0]}{\\mathbb{E}[X|Z=1] - \\mathbb{E}[X|Z=0]}\\]\n\n이는 Imbens and Angrist (1994)에서 제시한 LATE (Local Average Treatment Effect)와 동일한 개념입니다. “Local”인 이유는 전체 모집단이 아닌 Complier라는 특정 하위 집단에 대한 효과이기 때문입니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html#잠재적-결과의-식별-identification-of-potential-outcomes",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html#잠재적-결과의-식별-identification-of-potential-outcomes",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "4.4. 잠재적 결과의 식별 (Identification of Potential Outcomes)",
    "text": "4.4. 잠재적 결과의 식별 (Identification of Potential Outcomes)\n\nCACE를 계산하기 위해서는 Complier 집단의 잠재적 결과 평균(\\(\\mathbb{E}[Y_i(1)|c]\\)와 \\(\\mathbb{E}[Y_i(0)|c]\\))을 알아야 합니다.\n하지만 우리는 누가 Complier인지 개별적으로 알 수 없습니다.\n대신, 관측 가능한 집단(\\(Z, X\\))의 평균 결과가 어떤 잠재적 집단들의 혼합으로 이루어져 있는지 분해함으로써 이를 역추적할 수 있습니다.\n\n\n1. \\(Z=0, X=0\\) 집단 (Compliers + Never-takers)\n\n배정을 받지 않았고 처치도 받지 않은 그룹입니다.\n이들은 \\(Z=0\\)일 때 \\(X=0\\)인 Complier와 Never-taker로 구성됩니다. \\[\n\\mathbb{E}[Y_i | X_i = 0, Z_i = 0] = \\frac{\\pi_c}{\\pi_c + \\pi_n} \\cdot \\mathbb{E}[Y_i(0) | \\text{complier}] + \\frac{\\pi_n}{\\pi_c + \\pi_n} \\cdot \\mathbb{E}[Y_i(0) | \\text{never-taker}]\n\\]\n\n\n\n2. \\(Z=1, X=0\\) 집단 (Never-takers Only)\n\n배정을 받았으나(\\(Z=1\\)) 처치를 받지 않은(\\(X=0\\)) 그룹입니다.\nComplier라면 처치를 받았을 것이므로, 이 그룹은 순수하게 Never-taker들입니다. \\[\n\\mathbb{E}[Y_i | X_i = 0, Z_i = 1] = \\mathbb{E}[Y_i(0) | \\text{never-taker}]\n\\]\n\n\n\n3. \\(Z=0, X=1\\) 집단 (Always-takers Only)\n\n배정을 받지 않았는데도(\\(Z=0\\)) 처치를 받은(\\(X=1\\)) 그룹입니다.\nComplier라면 처치를 안 받았을 것이므로, 이 그룹은 순수하게 Always-taker들입니다. \\[\n\\mathbb{E}[Y_i | X_i = 1, Z_i = 0] = \\mathbb{E}[Y_i(1) | \\text{always-taker}]\n\\]\n\n\n\n4. \\(Z=1, X=1\\) 집단 (Compliers + Always-takers)\n\n배정을 받았고 처치도 받은 그룹입니다.\n이들은 \\(Z=1\\)일 때 \\(X=1\\)인 Complier와 Always-taker로 구성됩니다. \\[\n\\mathbb{E}[Y_i | X_i = 1, Z_i = 1] = \\frac{\\pi_c}{\\pi_c + \\pi_a} \\cdot \\mathbb{E}[Y_i(1) | \\text{complier}] + \\frac{\\pi_a}{\\pi_c + \\pi_a} \\cdot \\mathbb{E}[Y_i(1) | \\text{always-taker}]\n\\]\n\n\n결론: 위 식들을 연립하면, 관측 가능한 데이터로부터 미지수인 \\(\\mathbb{E}[Y_i(0) | \\text{complier}]\\)와 \\(\\mathbb{E}[Y_i(1) | \\text{complier}]\\)를 비모수적으로 식별(Nonparametrically Identify)할 수 있으며, 이를 통해 최종적으로 CACE를 구할 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html#one-sided-noncompliance-단측-불순응",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html#one-sided-noncompliance-단측-불순응",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "5.1. One-sided Noncompliance (단측 불순응)",
    "text": "5.1. One-sided Noncompliance (단측 불순응)\n\n실험 설계상 통제 집단(\\(Z=0\\))은 절대 처치를 받을 수 없는 경우(예: 신약 임상시험)입니다.\n즉, Always-taker가 없습니다(\\(X_i(0)=0\\)).\n이 경우 \\(\\sum X_i(1-Z_i) = 0\\) 이 되며 공식은 조금 더 단순해집니다.\n\n\\[\n\\begin{aligned}\n\\widehat{CACE} &= \\frac{\\widehat{E}[Y|Z=1] - \\widehat{E}[Y|Z=0]}{\\widehat{E}[X|Z=1]} \\\\\n&= \\frac{\\frac{\\sum Y_i Z_i}{\\sum Z_i} - \\frac{\\sum Y_i (1-Z_i)}{\\sum (1-Z_i)}}{\\frac{\\sum X_i Z_i}{\\sum Z_i}}\n\\end{aligned}\n\\]\n* 분모는 처치 집단 중 실제로 처치를 받은 사람의 비율"
  },
  {
    "objectID": "posts/lecture/L13/causal-inference-13-part-02/index.html#two-sided-noncompliance-양측-불순응",
    "href": "posts/lecture/L13/causal-inference-13-part-02/index.html#two-sided-noncompliance-양측-불순응",
    "title": "[Causal Inference] 13. IV (Part 2)",
    "section": "5.2. Two-sided Noncompliance (양측 불순응)",
    "text": "5.2. Two-sided Noncompliance (양측 불순응)\n\n일반적인 경우(Wald Estimator 형태)입니다.\n\n\\[\\widehat{CACE} = \\frac{\\widehat{E}[Y|Z=1] - \\widehat{E}[Y|Z=0]}{\\widehat{E}[X|Z=1] - \\widehat{E}[X|Z=0]}\\]"
  },
  {
    "objectID": "posts/lecture/L01/causal-inference-01/index.html",
    "href": "posts/lecture/L01/causal-inference-01/index.html",
    "title": "[Causal Inference] 01. Introduction",
    "section": "",
    "text": "데이터사이언스대학원(GSDS) 이상학 교수님의 “데이터사이언스를 위한 인과추론” 강의 1강을 정리한 포스트입니다. 왜 우리가 머신러닝을 넘어 인과추론을 배워야 하는지, 그리고 그 핵심 프레임워크인 Judea Pearl의 인과 계층에 대해 다룹니다."
  },
  {
    "objectID": "posts/lecture/L01/causal-inference-01/index.html#상관관계correlation는-인과관계causation가-아니다",
    "href": "posts/lecture/L01/causal-inference-01/index.html#상관관계correlation는-인과관계causation가-아니다",
    "title": "[Causal Inference] 01. Introduction",
    "section": "1. 상관관계(Correlation)는 인과관계(Causation)가 아니다",
    "text": "1. 상관관계(Correlation)는 인과관계(Causation)가 아니다\n통계학 수업을 들었다면 누구나 한 번쯤 들어봤을 문장입니다. 하지만 실제 데이터 분석에서 우리는 이 함정에 너무나 쉽게 빠집니다. 강의 자료에 나온 재미있는 예시들을 살펴봅시다.\n\n(1) 자폐증과 유기농 식품 판매량\n미국 내 자폐증(Autism) 진단 수와 유기농 식품 판매량의 추이를 그린 그래프입니다.\n\n\n\nAutism vs Organic Food Sales\n\n\n두 변수의 상관계수(\\(r\\))는 무려 0.9971입니다. 그렇다면 유기농 식품이 자폐증의 원인일까요? 당연히 아닙니다. 단순히 시간이 흐르며 두 지표가 같이 상승했을 뿐입니다. 이를 허위 상관(Spurious Correlation)이라고 합니다.\n\n\n(2) 소방관이 많으면 불이 커진다?\n데이터를 보면 투입된 소방관의 수(\\(X\\))와 화재의 크기(\\(Y\\))는 아주 강한 양의 상관관계를 가집니다.\n\\[Y = \\beta X + \\beta_0\\]\n단순 회귀분석을 돌리면 \\(\\beta\\)(기울기)는 양수가 나옵니다. 그렇다면 화재 피해를 줄이기 위해 소방관을 줄여야 할까요? 상식적으로 말이 안 됩니다. 사실은 화재가 크기 때문에(Cause) 소방관이 많이 출동한 것(Effect)이거나, 건물의 크기 같은 제3의 요인이 작용했을 것입니다. 데이터(\\(X, Y\\))만 봐서는 이 인과의 방향을 알 수 없습니다."
  },
  {
    "objectID": "posts/lecture/L01/causal-inference-01/index.html#심슨의-역설-simpsons-paradox-데이터는-거짓말을-한다",
    "href": "posts/lecture/L01/causal-inference-01/index.html#심슨의-역설-simpsons-paradox-데이터는-거짓말을-한다",
    "title": "[Causal Inference] 01. Introduction",
    "section": "2. 심슨의 역설 (Simpson’s Paradox): 데이터는 거짓말을 한다",
    "text": "2. 심슨의 역설 (Simpson’s Paradox): 데이터는 거짓말을 한다\n가장 충격적이었던 예시는 심슨의 역설입니다. 어떤 신약(Drug)의 회복률(Recovery Rate)을 분석한 데이터입니다.\n\n상황 1: 전체 데이터 (Total)\n\n\n\n\n회복(Y)\n미회복(\\(\\neg Y\\))\n회복률(Rate)\n\n\n\n\n약 복용 (Drug)\n20\n20\n50%\n\n\n미복용 (No Drug)\n16\n24\n40%\n\n\n\n전체로 보면 약을 먹었을 때 회복률이 더 높습니다(50% &gt; 40%). 의사는 약을 처방해야 할 것 같습니다.\n\n\n상황 2: 성별로 나누어 본 데이터 (Stratified by Sex)\n하지만 남성과 여성으로 데이터를 쪼개서 보면 이야기가 달라집니다.\n\n남성 (Male): 약 복용(60%) &lt; 미복용(70%)\n여성 (Female): 약 복용(20%) &lt; 미복용(30%)\n\n남성 그룹에서도, 여성 그룹에서도 약을 안 먹는 게 회복률이 더 높습니다. 전체 데이터에서는 약이 좋다고 하는데, 쪼개보니 약이 나쁘다고 합니다. 도대체 의사는 어떤 테이블을 믿어야 할까요?\n\n\n결론: 인과 그래프(Causal Graph)가 필요하다\n정답은 “데이터만으로는 알 수 없다”입니다. 성별(\\(F\\)), 약 복용(\\(X\\)), 회복(\\(Y\\)) 사이의 인과 구조가 어떻게 그려지느냐에 따라 우리가 봐야 할 테이블이 달라집니다. 이것이 바로 우리가 단순히 데이터(\\(P(Y|X)\\))를 보는 것을 넘어, 인과 구조(Structure)를 고민해야 하는 이유입니다."
  },
  {
    "objectID": "posts/lecture/L01/causal-inference-01/index.html#pearl의-인과-계층-pearls-causal-hierarchy",
    "href": "posts/lecture/L01/causal-inference-01/index.html#pearl의-인과-계층-pearls-causal-hierarchy",
    "title": "[Causal Inference] 01. Introduction",
    "section": "3. Pearl의 인과 계층 (Pearl’s Causal Hierarchy)",
    "text": "3. Pearl의 인과 계층 (Pearl’s Causal Hierarchy)\nJudea Pearl은 인과추론의 수준을 세 단계의 사다리(Ladder)로 정의했습니다.\n\nLevel 1: 관찰 (Association / Seeing)\n\n질문: “What is?” (만약 \\(X\\)를 본다면, \\(Y\\)는 어떨까?)\n수식: \\(P(y|x)\\)\n특징: 기존의 머신러닝(Deep Learning, Decision Tree 등)이 가장 잘하는 영역입니다. 데이터의 상관성을 파악합니다.\n\n\n\nLevel 2: 개입 (Intervention / Doing)\n\n질문: “What if I do?” (만약 내가 \\(X\\)를 강제로 시킨다면, \\(Y\\)는 어떻게 될까?)\n수식: \\(P(y | do(x))\\)\n특징: 여기서부터 진짜 인과추론의 영역입니다. 단순히 \\(X\\)를 관찰하는 것(\\(x\\))과, 실험자가 개입하여 값을 바꾸는 것(\\(do(x)\\))은 다릅니다. 강화학습(RL)이나 A/B 테스트가 여기에 속합니다.\n\n\n\nLevel 3: 반사실 (Counterfactuals / Imagining)\n\n질문: “What if I had acted differently?” (그때 내가 다른 선택을 했더라면, 결과는 달라졌을까?)\n수식: \\(P(y_x | x', y')\\)\n특징: 이미 일어난 일(\\(x', y'\\))을 바탕으로, 일어나지 않은 가상의 세계(\\(y_x\\))를 추론합니다. 인간만이 가진 고도의 추론 능력인 회고(Retrospection)와 상상(Imagining)의 영역입니다."
  },
  {
    "objectID": "posts/lecture/L01/causal-inference-01/index.html#마치며",
    "href": "posts/lecture/L01/causal-inference-01/index.html#마치며",
    "title": "[Causal Inference] 01. Introduction",
    "section": "4. 마치며",
    "text": "4. 마치며\n기존의 머신러닝은 Level 1 (Association)에 머물러 있었습니다. 하지만 진정한 지능(Intelligent Agent)이나 정책 결정(Policy Making)을 위해서는 Level 2, 3의 추론이 필수적입니다. 이번 강의를 통해 단순히 데이터를 예측(Prediction)하는 것을 넘어, 세상의 작동 원리(Mechanism)를 이해하는 인과추론의 세계로 나아가고자 합니다.\nReference: * Prof. Sanghack Lee, Causal Inference for Data Science, GSDS SNU. * Judea Pearl et al., Causal Inference in Statistics: A Primer."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-04/index.html",
    "href": "posts/lecture/L08/causal-inference-08-part-04/index.html",
    "title": "[Causal Inference] 08. Partial Identification (Part 4)",
    "section": "",
    "text": "이번 포스트에서는 실험 설계에서 흔히 발생하는 비순응(Non-compliance) 문제를 다룹니다.\n할당된 처치(\\(Z\\))와 실제 받은 처치(\\(X\\))가 일치하지 않는 상황에서, 인과 효과(ATE)를 식별하고 추정하는 다양한 방법들을 코드로 구현하고 비교해 봅니다.\n주요 내용은 다음과 같습니다.\n\n\n데이터 생성 (Data Generation): Compliance Type과 Response Type을 기반으로 가상 데이터 생성\n점 추정 (Point Estimate): 도구변수(IV)를 활용한 LATE 추정 (DoWhy 라이브러리 활용)\n구간 추정 (Interval Estimate):\n\nNatural Bounds (Manski): 가정 없이 관측 데이터만으로 도출한 구간\nIV Natural Bounds: 도구변수 가정을 추가했을 때의 구간\nBalke-Pearl Bounds (LP): 선형 계획법(Linear Programming)을 이용한 최적 구간\n\n결과 비교 및 시각화"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-04/index.html#왜-점-추정이-가능한가-단조성-가정-the-role-of-monotonicity",
    "href": "posts/lecture/L08/causal-inference-08-part-04/index.html#왜-점-추정이-가능한가-단조성-가정-the-role-of-monotonicity",
    "title": "[Causal Inference] 08. Partial Identification (Part 4)",
    "section": "왜 점 추정이 가능한가? (단조성 가정, The Role of Monotonicity)",
    "text": "왜 점 추정이 가능한가? (단조성 가정, The Role of Monotonicity)\n\n일반적인 도구변수 추정량(Wald Estimator)은 다음과 같습니다.\n\n\\[\n\\beta_{IV} = \\frac{E[Y|Z=1] - E[Y|Z=0]}{E[X|Z=1] - E[X|Z=0]}\n\\]\n\n이 수식이 인과 효과로 해석되려면 Defiers가 없어야 합니다.\n즉, (처방)일 때 (미복용)이고, (미처방)일 때 (복용)인 사람이 없다는 단조성 가정(\\(X_{i}(1) \\ge X_{i}(0)\\))이 필요합니다.\n이 가정이 성립할 때, 추정량은 Compliers(순응자) 집단의 평균 처치 효과로 식별됩니다.\n\n\n\nCode\n# ==============================================================================\n# 2. Point Estimate: DoWhy를 이용한 LATE 추정\n# ==============================================================================\ndef point_estimate(df):\n    \"\"\"\n    DoWhy 라이브러리를 사용하여 IV(도구변수) 추정량을 계산합니다.\n    \"\"\"\n    # 1. Causal Model 정의 (Graph)\n    # Z -&gt; X -&gt; Y, U -&gt; X, U -&gt; Y (U는 Unobserved Confounder)\n    model = CausalModel(\n        data=df,            # 데이터\n        treatment='X',      # 원인 변수 (약 복용 여부)\n        outcome='Y',        # 결과 변수 (완치 여부)\n        instruments=['Z'],  # 도구 변수 (의사 처방)\n        common_causes=[]    # 공통 원인 (교란 변수 U)\n    )\n    \n    # 2. 식별 (Identification)\n    identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n    \n    # 3. 추정 (Estimation) - Wald Estimator (IV 방식)\n    estimate = model.estimate_effect(\n        identified_estimand,\n        method_name=\"iv.instrumental_variable\"\n    )\n    \n    return estimate.value"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-04/index.html#linear-programming-formulation-the-matrix-view",
    "href": "posts/lecture/L08/causal-inference-08-part-04/index.html#linear-programming-formulation-the-matrix-view",
    "title": "[Causal Inference] 08. Partial Identification (Part 4)",
    "section": "Linear Programming Formulation: The Matrix View",
    "text": "Linear Programming Formulation: The Matrix View\n\n우리가 작성한 solve_lp 함수는 수학적으로 거대한 연립방정식(\\(A\\mathbf{x} = \\mathbf{b}\\))을 조립하여 푸는 과정입니다.\n이를 행렬식으로 시각화하면 다음과 같습니다.\n\n\\[\n\\underbrace{\n\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n\\hdashline\n1 & 0 & 0 & \\dots & 0 \\\\\n0 & 1 & 1 & \\dots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & 0 & \\dots & 1\n\\end{bmatrix}\n}_{A_{eq} \\; (9 \\times 16)}\n\\times\n\\underbrace{\n\\begin{bmatrix}\nq_{00} \\\\\nq_{01} \\\\\nq_{02} \\\\\n\\vdots \\\\\nq_{33}\n\\end{bmatrix}\n}_{\\mathbf{q} \\; (16 \\times 1)}\n=\n\\underbrace{\n\\begin{bmatrix}\n1 \\\\\n\\hdashline\nP(y=0, x=0 | z=0) \\\\\nP(y=0, x=0 | z=1) \\\\\n\\vdots \\\\\nP(y=1, x=1 | z=1)\n\\end{bmatrix}\n}_{\\mathbf{b}_{eq} \\; (9 \\times 1)}\n\\]"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-04/index.html#구성-요소-상세-설명",
    "href": "posts/lecture/L08/causal-inference-08-part-04/index.html#구성-요소-상세-설명",
    "title": "[Causal Inference] 08. Partial Identification (Part 4)",
    "section": "구성 요소 상세 설명",
    "text": "구성 요소 상세 설명\n\n1. 미지수 벡터 \\(\\mathbf{q}\\) (The Unknowns)\n우리가 찾고 싶은 16가지 잠재 유형(Canonical Types)의 비율입니다. \\[\\mathbf{q} = [q_{00}, q_{01}, \\dots, q_{33}]^T\\] 현실에서는 관측할 수 없지만, 이 값들이 모여서 실제 데이터를 만들어냅니다.\n\n\n2. 계수 행렬 \\(A_{eq}\\) (The Logic)\n우리가 세운 Canonical Model의 논리를 담고 있는 “출석부”입니다. \\[A_{eq} \\in \\{0, 1\\}^{9 \\times 16}\\]\n\n1행 (Sum Constraint): “모든 \\(q\\)의 합은 1이어야 한다.” (모두 1)\n2~9행 (Model Constraint): “특정 관측 상황(\\(Z, X, Y\\))을 만들어내는 유형(\\(q\\))들만 1로 표시한다.”\n\n예: \\(Z=0\\)일 때 \\(X=0, Y=0\\)이 되려면, \\(q_{00}\\) (Never-taker & Never-recover) 등이 참여해야 함.\n\n\n\n\n3. 상수 벡터 \\(\\mathbf{b}_{eq}\\) (The Data)\n우리가 수집한 실제 관측 데이터(Observed Probabilities)입니다. \\[\\mathbf{b}_{eq} = [1, \\hat{P}_{00.0}, \\dots, \\hat{P}_{11.1}]^T\\] 이 값들이 연립방정식의 “정답지(Target)” 역할을 하여, 미지수 \\(\\mathbf{q}\\)가 현실과 동떨어지지 않게 붙잡아줍니다.\n\n\n최적화 목표 (Objective Function)\n이 제약조건(\\(A_{eq}\\mathbf{q} = \\mathbf{b}_{eq}\\))을 만족하는 수많은 \\(\\mathbf{q}\\) 중에서, 다음을 최소화(또는 최대화)하는 조합을 찾습니다.\n\\[\\min_{\\mathbf{q}} \\; ( \\mathbf{c}^T \\mathbf{q} ) = \\min \\sum_{j,k} c_{jk} q_{jk}\\]\n여기서 \\(\\mathbf{c}\\)는 인과 효과(ATE)를 계산하는 가중치 벡터입니다. \\[\\mathbf{c} = [\\dots, \\underbrace{+1}_{\\text{Helped}}, \\dots, \\underbrace{-1}_{\\text{Hurt}}, \\dots]\\]\n\n\nCode\n# ==============================================================================\n# 3. Interval Estimate: Linear Programming (Balke-Pearl Bounds)\n# ==============================================================================\ndef lp_bounds(df):\n    # 1. 관측 확률 계산\n    # p_yx.z = P(X = x, Y = y | Z = z) 가 계산됨.\n    p_obs = df.groupby(['Y', 'X', 'Z']).size() / df.groupby('Z').size()\n    p_obs_dict = {idx: val for idx, val in p_obs.items()}\n    \n    # 2. 최적화 함수 정의 (앞서 작성한 로직)\n    def solve_lp(objective_coef):\n        num_vars = 16\n        \n        # 제약조건 A_eq(좌변), b_eq(우변) 생성\n        A_eq = []\n        b_eq = []\n        \n        # (1) 확률 총합 = 1\n        A_eq.append([1] * num_vars)\n        b_eq.append(1)\n        \n        # (2) 관측 데이터 정합성 (8개 방정식)\n        for z in [0, 1]:\n            for x in [0, 1]:\n                for y in [0, 1]:\n                    row = [0] * num_vars\n                    target_prob = p_obs_dict.get((y, x, z), 0)\n                    \n                    # 16개 유형에 대해 Canonical Model 매핑\n                    for j in range(4): # Compliance\n                        for k in range(4): # Response\n                            rx = [j//2, j%2] # [X|Z=0, X|Z=1]\n                            ry = [k//2, k%2] # [Y|X=0, Y|X=1]\n                            if (rx[z] == x) and (ry[x] == y) :\n                                row[4 * j + k] = 1\n                                \n                    A_eq.append(row)\n                    b_eq.append(target_prob)\n                    \n        # LP 실행\n        bounds = [(0, 1) for _ in range(num_vars)]\n        res = linprog(objective_coef, A_eq=A_eq, b_eq=b_eq, bounds=bounds)\n        return res.fun\n\n    # 3. 목적 함수 설정 (ATE = Helped - Hurt)\n    # ATE = P(Y = 1 | do(X = 1)) - P(Y = 1 | do(X = 0))\n    #     = {P(Helped) + P(Always-recover)} - {P(Hurt) + P(Always-recover)}\n    #     = P(Helped) - P(Hurt)\n    coef_ate_min = []\n    coef_ate_max = []\n    for j in range(4):\n        for k in range(4):\n            val = 1 if k==1 else (-1 if k==2 else 0)\n            coef_ate_min.append(val)\n            coef_ate_max.append(-val)\n            \n    # 4. 결과 도출\n    min_ate = solve_lp(coef_ate_min)\n    max_ate = -solve_lp(coef_ate_max) # 부호 원복\n    \n    return min_ate, max_ate"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-04/index.html#natural-bounds",
    "href": "posts/lecture/L08/causal-inference-08-part-04/index.html#natural-bounds",
    "title": "[Causal Inference] 08. Partial Identification (Part 4)",
    "section": "5. Natural Bounds",
    "text": "5. Natural Bounds\n비교를 위해 더 넓은 구간을 가지는 Natural Bounds를 계산합니다.\n\nIV Natural Bounds: 도구변수가 있을 때의 최악의 경우(Worst-case) 구간\nPure Manski Bounds: 도구변수 없이 관측 데이터 \\(P(Y, X)\\)만으로 계산한 구간 (가장 넓음)\n\n\n\nCode\n# ==============================================================================\n# 4.1 Natural Bounds\n# ==============================================================================\ndef calculate_natural_bounds_iv(df):\n    p_xy_z = df.groupby(['Y', 'X', 'Z']).size() / df.groupby('Z').size()\n    \n    def get_p_xy_z(y, x, z):\n        return p_xy_z.get((y, x, z), 0)\n    \n    def get_p_x_z(x, z):\n        return get_p_xy_z(0, x, z) + get_p_xy_z(1, x, z)\n\n    # 1. P(Y=1 | do(X=1)) Bounds \n    # a = max_z P(y, x | z)\n    # b = min_z P(y, x | z) + 1 - P(x | z)\n    lower_do1 = max(get_p_xy_z(1, 1, 0), get_p_xy_z(1, 1, 1))\n    upper_do1 = min(get_p_xy_z(1, 1, 0) + 1 - get_p_x_z(1, 0), \n                    get_p_xy_z(1, 1, 1) + 1 - get_p_x_z(1, 1))\n    \n    # 2. P(Y=1 | do(X=0)) Bounds\n    lower_do0 = max(get_p_xy_z(1, 0, 0), get_p_xy_z(1, 0, 1))\n    upper_do0 = min(get_p_xy_z(1, 0, 0) + 1 - get_p_x_z(0, 0), \n                    get_p_xy_z(1, 0, 1) + 1 - get_p_x_z(0, 1))\n    \n    # 3. ATE Bounds (Worst Case)\n    # ATE = do(1) - do(0)\n    # Min ATE = Min(do1) - Max(do0)\n    # Max ATE = Max(do1) - Min(do0)\n    nat_min = lower_do1 - upper_do0\n    nat_max = upper_do1 - lower_do0\n    \n    return nat_min, nat_max\n\n# ==============================================================================\n# 4.2 Natural Bounds\n# ==============================================================================\ndef calculate_natural_bounds(df):\n    p_xy = df.groupby(['Y', 'X']).size() / len(df)\n    \n    def get_p_xy(y, x):\n        return p_xy.get((y, x), 0)\n\n    def get_p_x(x):\n        return get_p_xy(0, x) + get_p_xy(1, x)\n        \n    # 1. P(Y=1 | do(X=1)) Bounds \n    # a = P(y, x)\n    # b = P(y, x) + 1 - P(x)\n    lower_do1 = get_p_xy(1, 1)\n    upper_do1 = get_p_xy(1, 1) + 1 - get_p_x(1)\n    # 2. P(Y=1 | do(X=0)) Bounds \n    lower_do0 = get_p_xy(1, 0)\n    upper_do0 = get_p_xy(1, 0) + 1 - get_p_x(0)\n    \n    # 3. ATE Bounds (Worst Case)\n    # ATE = do(1) - do(0)\n    # Min ATE = Min(do1) - Max(do0)\n    # Max ATE = Max(do1) - Min(do0)\n    nat_min = lower_do1 - upper_do0\n    nat_max = upper_do1 - lower_do0\n    \n    return nat_min, nat_max"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-04/index.html#strong-iv-scenario",
    "href": "posts/lecture/L08/causal-inference-08-part-04/index.html#strong-iv-scenario",
    "title": "[Causal Inference] 08. Partial Identification (Part 4)",
    "section": "7.1 Strong IV Scenario",
    "text": "7.1 Strong IV Scenario\n\n첫 번째는 Strong IV 상황입니다.\nComplier의 비율이 약 80%로 매우 높고, Never-taker나 Defier의 비율이 낮습니다.\n즉, 의사의 처방(Z)이 실제 복용 여부(X)를 매우 강력하게 결정합니다.\n\n\n\nCode\n# 1. Data Generation\nprobs = np.array([\n    # Ry=0(Never) Ry=1(Helped) Ry=2(Hurt) Ry=3(Always)\n    # -------------------------------------------------------\n    [0.05,        0.05,        0.00,      0.00],   # Never-taker (Rx=0)\n    [0.10,        0.60,        0.05,      0.05],   # Complier (Rx=1)\n    [0.00,        0.00,        0.00,      0.00],   # Defier (Rx=2)\n    [0.05,        0.05,        0.00,      0.00]    # Always-taker (Rx=3)\n])\n\ndf, true_ate, probs = generate_class_scenario_data(probs) \n\n# 2. Point Estimate\npoint_est = point_estimate(df)\n\n# 3. Interval Estimate (LP)\nlp_min, lp_max = lp_bounds(df)\n\n# 4. Natural Bounds\nnat_min, nat_max = calculate_natural_bounds_iv(df)\nmanski_min, manski_max = calculate_natural_bounds(df)\n\n# 5. Visualization\ncompare_and_visualize(\n    df=df, \n    true_ate=true_ate, \n    point_est=point_est, \n    lp_bounds=(lp_min, lp_max), \n    nat_bounds=(nat_min, nat_max), \n    manski_bounds=(manski_min, manski_max),\n    probs_matrix=probs\n)\n\n\n\n\n\n\n\n\n\nTrue ATE      : 0.6500\nDoWhy Estimate: 0.6853\n------------------------------\n1. Pure Manski (No Z) : [-0.1769, 0.8231] (Width: 1.0000)\n2. IV Natural (With Z) : [0.4991, 0.6972] (Width: 0.1981)\n3. Balke-Pearl (LP)   : [0.4991, 0.6972] (Width: 0.1981)\n\n\n\n해석\n\nComplier 비중: 약 80%로, 도구변수 \\(Z\\)가 \\(X\\)를 강력하게 설명합니다.\nLP Bounds: 너비가 약 0.20으로 매우 좁게 형성되었습니다. 이는 관측 데이터만으로도 True ATE의 범위를 상당히 좁힐 수 있음을 의미합니다.\nEstimates: Point Estimate (LATE)가 True ATE에 매우 근접해 있습니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-04/index.html#weak-iv-scenario",
    "href": "posts/lecture/L08/causal-inference-08-part-04/index.html#weak-iv-scenario",
    "title": "[Causal Inference] 08. Partial Identification (Part 4)",
    "section": "7.2 Weak IV Scenario",
    "text": "7.2 Weak IV Scenario\n\n두 번째는 Weak IV 상황입니다.\nComplier의 비율이 5%로 극히 낮고, Never-taker(약 35%)와 Always-taker(약 40%)의 비율이 매우 높습니다.\n즉, 의사가 처방을 하든 말든(Z), 사람들은 대부분 자기 맘대로 행동하므로 도구변수가 무력합니다.\n\n\n\nCode\n# 1. Data Generation\nprobs = np.array([\n    # Ry=0(Never) Ry=1(Helped) Ry=2(Hurt) Ry=3(Always)\n    # -------------------------------------------------------\n    [0.10,        0.10,        0.05,      0.10],   # Never-taker (Rx=0)\n    [0.01,        0.02,        0.01,      0.01],   # Complier (Rx=1)\n    [0.05,        0.05,        0.05,      0.05],   # Defier (Rx=2)\n    [0.10,        0.10,        0.10,      0.10]    # Always-taker (Rx=3)\n])\n\ndf, true_ate, probs = generate_class_scenario_data(probs) \n\n# 2. Point Estimate\npoint_est = point_estimate(df)\n\n# 3. Interval Estimate (LP)\nlp_min, lp_max = lp_bounds(df)\n\n# 4. Natural Bounds\nnat_min, nat_max = calculate_natural_bounds_iv(df)\nmanski_min, manski_max = calculate_natural_bounds(df)\n\n# 5. Visualization\ncompare_and_visualize(\n    df=df, \n    true_ate=true_ate, \n    point_est=point_est, \n    lp_bounds=(lp_min, lp_max), \n    nat_bounds=(nat_min, nat_max), \n    manski_bounds=(manski_min, manski_max),\n    probs_matrix=probs\n)\n\n\n\n\n\n\n\n\n\nTrue ATE      : 0.0600\nDoWhy Estimate: -0.1393\n------------------------------\n1. Pure Manski (No Z) : [-0.4769, 0.5231] (Width: 1.0000)\n2. IV Natural (With Z) : [-0.4082, 0.4322] (Width: 0.8404)\n3. Balke-Pearl (LP)   : [-0.4082, 0.4322] (Width: 0.8404)\n\n\n\n해석\n\nComplier 비중: 5%에 불과하여 \\(Z\\)와 \\(X\\)의 상관관계가 매우 약합니다.\nLP Bounds: 너비가 0.84로 매우 넓습니다. 이는 1.0(전체 가능한 범위)에 가까운 수치로, 도구변수 가정을 도입했음에도 불구하고 ATE에 대해 “거의 아무것도 모르는 상태”와 다를 바 없습니다.\nEstimates: Point Estimate (LATE)가 True ATE와 큰 차이를 보이고, 부호가 다르다. 이는 분모(\\(E[X∣Z=1]−E[X∣Z=0]\\))가 0에 가까워지면서 추정량이 불안정해지기 때문입니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-02/index.html",
    "href": "posts/lecture/L08/causal-inference-08-part-02/index.html",
    "title": "[Causal Inference] 08. Partial Identification (Part 2)",
    "section": "",
    "text": "지난 포스트에서는 가장 일반적인 형태의 비관측 교란 상황에서 Natural Bounds를 구하는 법을 배웠습니다.\n이번에는 인과추론에서 매우 중요한 환경인 도구 변수(Instrumental Variable, IV)가 주어졌을 때, 인과 효과의 범위를 어떻게 더 좁힐 수 있는지 알아봅니다.\n특히, 이 문제를 해결하기 위해 Canonical Type Models (CTM)을 도입하고, 이를 선형 계획법(Linear Programming) 문제로 변환하여 최적의 범위(Tight Bounds)를 찾아내는 과정을 다룹니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-02/index.html#natural-bounds-iv-모델",
    "href": "posts/lecture/L08/causal-inference-08-part-02/index.html#natural-bounds-iv-모델",
    "title": "[Causal Inference] 08. Partial Identification (Part 2)",
    "section": "2.1 Natural Bounds (IV 모델)",
    "text": "2.1 Natural Bounds (IV 모델)\n\n관측 분포 \\(P(X, Y|Z)\\)가 주어졌을 때, 인과 효과 \\(P(y|do(x))\\)는 구간 \\([a(y, x), b(y, x)]\\) 안에 존재합니다. 여기서 각 경계값은 다음과 같습니다.\n\n\\[\na(y, x) = \\max_z P(y, x|z)\n\\] \\[\nb(y, x) = \\min_z [P(y, x|z) + 1 - P(x|z)]\n\\]\n\n모델 \\(\\mathcal{M}_z\\)에 Natural Bounds를 적용하면 아래와 같습니다.\n\n우선 Natural Bounds 식에서 시작합니다. \\[\nP(y, x) \\le P(y|do(x)) \\le P(y, x) + 1 - P(x)\n\\]\n\\(do(z)\\)를 한 그래프에서도 Natural Bounds는 성립하므로, \\[\nP(y, x|do(z)) \\le P(y|do(x,z)) \\le P(y, x|do(z)) + 1 - P(x|do(z))\n\\]\nRule 2에 의해 \\(Z\\)에 대한 개입은 관찰과 같으므로 특정 \\(z\\)값에 대해 다음 부등식이 성립합니다.\n추가로 \\(X\\)에 대한 개입이 이루어진 상황에서 도구변수 \\(Z\\)가 \\(Y\\)에 직접적인 영향을 주지 않으므로 \\(P(y∣do(x),z)=P(y∣do(x))\\) 입니다.\n어떤 \\(z\\)값을 택하든 인과 효과는 동일해야 한다는 것입니다. \\[\nP(y, x|z) \\le P(y|do(x)) \\le P(y, x|z) + 1 - P(x|z)\n\\]\n따라서 도구변수 값에 따른 Bounds의 교집합(intersection)이 Natural Bounds가 됩니다.\n\n\n\n\n\nFigure 2: Natural Bounds of IV Model. 도구변수의 값에 따른 인과효과 범위의 교집합이 Natural Bounds가 됩니다.\n\n\n\n하지만 Natural Bounds는 이론적 한계까지 좁혀지지 않은 상태(Not Tight)입니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-02/index.html#모델-집합-정의-model-definition",
    "href": "posts/lecture/L08/causal-inference-08-part-02/index.html#모델-집합-정의-model-definition",
    "title": "[Causal Inference] 08. Partial Identification (Part 2)",
    "section": "3.1 모델 집합 정의 (Model Definition)",
    "text": "3.1 모델 집합 정의 (Model Definition)\n\n주어진 그래프 구조와 호환되는 모든 구조적 인과 모델(SCM)의 집합을 \\(\\mathbf{M}\\)이라고 합시다.\n모델 \\(\\mathscr{M}\\)은 다음과 같이 정의됩니다.\n\n\\[\n\\mathscr{M} = \\begin{cases}\nU \\sim P(U) \\\\\nZ \\leftarrow f_Z(U_Z) \\\\\nX \\leftarrow f_X(Z, U) \\\\\nY \\leftarrow f_Y(X, U)\n\\end{cases}\n\\]"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-02/index.html#최적화-문제-optimization-problem",
    "href": "posts/lecture/L08/causal-inference-08-part-02/index.html#최적화-문제-optimization-problem",
    "title": "[Causal Inference] 08. Partial Identification (Part 2)",
    "section": "3.2 최적화 문제 (Optimization Problem)",
    "text": "3.2 최적화 문제 (Optimization Problem)\n\n관측 데이터 \\(P(x, y|z)\\)가 주어졌을 때, 참(True) 인과 효과 \\(P(y|do(x))\\)는 다음 최적화 문제로 정의된 구간 \\([a(y; x), b(y; x)]\\) 내에 존재해야 합니다.\n\n\\[\na(y; x) = \\min_{\\mathscr{M} \\in \\mathbf{M} \\mid P_{\\mathscr{M}}(y,x|z) = P(x,y|z)} P_{\\mathscr{M}}(y|do(x))\n\\]\n\\[\nb(y; x) = \\max_{\\mathscr{M} \\in \\mathbf{M} \\mid P_{\\mathscr{M}}(y,x|z) = P(x,y|z)} P_{\\mathscr{M}}(y|do(x))\n\\]\n\n\\(\\mathscr{M} \\in \\mathbf{M} \\mid P_{\\mathscr{M}}(y,x|z) = P(x,y|z)\\)는 가상 모델(\\(\\mathscr{M}\\)) 중, 그 모델이 만들어내는 통계(\\(P_{\\mathscr{M}}\\))가 실제 관측된 데이터(\\(P\\))와 정확히 일치하는 모델만을 고려함을 의미합니다.\nDifficulty: 이 최적화 문제를 해결하는 것은 다음과 같은 이유로 어렵습니다.\n\n\n함수 집합 \\(\\mathbf{F}\\) (\\(f_X, f_Y\\) 등)의 모수적 형태(parametric form)가 주어지지 않았습니다.\n\n\n잠재 변수의 분포 \\(P(U)\\)를 알 수 없습니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-02/index.html#반응-변수-response-variables",
    "href": "posts/lecture/L08/causal-inference-08-part-02/index.html#반응-변수-response-variables",
    "title": "[Causal Inference] 08. Partial Identification (Part 2)",
    "section": "4.1 반응 변수 (Response Variables)",
    "text": "4.1 반응 변수 (Response Variables)\n\n변수 \\(X\\)와 \\(Y\\)가 부모 변수의 값에 따라 어떻게 반응하는지를 결정하는 잠재적 특성을 \\(R_X, R_Y\\)라고 정의합시다.\n\n\n4.1.1 \\(R_X\\): 배정(\\(Z\\))에 대한 순응 유형\n\n\\(Z\\)가 \\(0\\) 또는 \\(1\\)일 때, \\(X\\)가 어떻게 반응하는지에 따라 총 4가지 유형(\\(2^2\\))이 존재합니다.\n\nNever-taker (\\(R_X=0\\)): 배정과 상관없이 처치를 받지 않음 (\\(Z=0 \\to X=0, Z=1 \\to X=0\\))\nComplier (\\(R_X=1\\)): 배정된 대로 따름 (\\(Z=0 \\to X=0, Z=1 \\to X=1\\))\nDefier (\\(R_X=2\\)): 배정과 반대로 행동함 (\\(Z=0 \\to X=1, Z=1 \\to X=0\\))\nAlways-taker (\\(R_X=3\\)): 배정과 상관없이 무조건 처치를 받음 (\\(Z=0 \\to X=1, Z=1 \\to X=1\\))\n\n\n\n\n4.1.2 \\(R_Y\\): 처치(\\(X\\))에 대한 반응 유형\n\n마찬가지로 \\(X\\)가 \\(0\\) 또는 \\(1\\)일 때, 결과 \\(Y\\)가 어떻게 나오는지에 따라 4가지 유형이 있습니다.\n\nNever-recover (\\(R_Y=0\\)): 약을 먹든 안 먹든 낫지 않음.\nHelped (\\(R_Y=1\\)): 약을 먹으면 낫고, 안 먹으면 안 나음 (인과 효과 있음).\nHurt (\\(R_Y=2\\)): 약을 먹으면 오히려 아프고, 안 먹어야 나음.\nAlways-recover (\\(R_Y=3\\)): 약을 먹든 안 먹든 항상 나음.\n\n\n\n\n\nFigure 3: Partition of U. U의 공간이 Rx와 Ry의 조합(총 16가지)에 의해 분할되는 모습을 나타낸 그림.\n\n\n\nNote: \\(U\\)는 \\(R_X\\)(4가지)와 \\(R_Y\\)(4가지)의 조합인 총 16개의 영역으로 나뉩니다.*\n\n\n\n4.1.3 동치 정리 (Equivalence Theorem)\n\n\n\nFigure 4: IV Model and Canonical Model. IV 모델에 대응되는 Canonical 모델의 모습.\n\n\n\nTheorem: 모든 IV 모델은 그에 상응하는 Canonical Type Model로 변환될 수 있으며, 동일한 관측 분포와 인과 효과를 가집니다.\n\n\nFor any IV model \\(\\mathscr{M}_{1}\\), there exists a canonical type model \\(\\mathscr{M}_{2}\\) such that \\(P_{\\mathscr{M}_{1}}(x,y|z) = P_{\\mathscr{M}_{2}}(x,y|z)\\), \\(P_{\\mathscr{M}_{1}}(y|do(x)) = P_{\\mathscr{M}_{2}}(y|do(x))\\)\n\n\n이 정리는 우리가 복잡하고 무한한 형태의 \\(U\\)를 고려할 필요 없이, 유한한 16개의 파라미터(\\(R_X, R_Y\\)의 결합 분포)만 최적화하면 된다는 것을 보장합니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-02/index.html#파라미터-정의-r_x-r_y-rightarrow-q_j-k",
    "href": "posts/lecture/L08/causal-inference-08-part-02/index.html#파라미터-정의-r_x-r_y-rightarrow-q_j-k",
    "title": "[Causal Inference] 08. Partial Identification (Part 2)",
    "section": "5.1 파라미터 정의 (\\((R_{x}, R_{y}) \\rightarrow q_{j, k}\\))",
    "text": "5.1 파라미터 정의 (\\((R_{x}, R_{y}) \\rightarrow q_{j, k}\\))\n\n우리가 찾아야 할 미지수는 \\(R_X\\)와 \\(R_Y\\)의 결합 확률분포입니다.\n\n\\[\nq_{j,k} = P(R_X=j, R_Y=k), \\quad j,k \\in \\{0,1,2,3\\}\n\\]\n\n총 16개의 \\(q_{j,k}\\)가 있으며, 이들의 합은 1이어야 합니다.\n\n\\[\n\\sum_{j} \\sum_{k} q_{j,k} = 1\n\\]"
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-02/index.html#관측-데이터와의-연결-q_jk-rightarrow-px-x-y-y-z-z",
    "href": "posts/lecture/L08/causal-inference-08-part-02/index.html#관측-데이터와의-연결-q_jk-rightarrow-px-x-y-y-z-z",
    "title": "[Causal Inference] 08. Partial Identification (Part 2)",
    "section": "5.2 관측 데이터와의 연결 (\\(q_{jk} \\rightarrow P(X = x, Y = y | Z = z)\\))",
    "text": "5.2 관측 데이터와의 연결 (\\(q_{jk} \\rightarrow P(X = x, Y = y | Z = z)\\))\n\n관측된 데이터 \\(P_{yx.z} = P(X=x, Y=y | Z=z)\\)는 \\(q_{j,k}\\)들의 선형 결합으로 표현됩니다.\n예를 들어, \\(P(Y=0, X=0 | Z=0)\\)인 경우를 봅시다.\n\n\\(Z=0\\)일 때 \\(X=0\\)이 되려면: Never-taker(\\(R_{x}=0\\)) 또는 Complier(\\(R_{x}=1\\))여야 합니다.\n\\(X=0\\)일 때 \\(Y=0\\)이 되려면: 처치를 안 받았을 때 안 나아야 하므로 Never-recover(\\(R_{y}=0\\)) 또는 Helped(\\(R_{y}=1\\))여야 합니다.\n\n따라서 해당 \\(q_{j,k}\\)들을 모두 더하면: \\[\nP_{00.0} = q_{00} + q_{01} + q_{10} + q_{11}\n\\]\n이와 같은 방식으로 8개의 관측 확률(\\(P_{yx.z}\\))을 모두 \\(q\\)에 대한 선형 방정식으로 만들 수 있습니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-02/index.html#인과-효과-q_j-k-rightarrow-py-dox",
    "href": "posts/lecture/L08/causal-inference-08-part-02/index.html#인과-효과-q_j-k-rightarrow-py-dox",
    "title": "[Causal Inference] 08. Partial Identification (Part 2)",
    "section": "5.3 인과 효과 (\\(q_{j, k} \\rightarrow P(Y | do(x))\\))",
    "text": "5.3 인과 효과 (\\(q_{j, k} \\rightarrow P(Y | do(x))\\))\n\n우리가 알고 싶은 인과 효과 \\(P(Y=1 | do(X=1))\\) 또한 \\(q_{j,k}\\)의 합으로 표현됩니다.\n\n\\[\n\\begin{aligned}\nP(Y=1 | do(X=1)) &= P(R_Y \\in \\{\\text{Helped, Always-recover}\\}) \\\\\n&= P(R_Y=1) + P(R_Y=3) \\\\\n&= \\sum_{j=0}^3 (q_{j1} + q_{j3})\n\\end{aligned}\n\\]\n\n\\(do(x)\\)의 의미\n\n\\(do(X=x)\\)는 \\(R_X\\)의 성향을 무시하고(무력화하고) 강제로 처치를 가하는 것입니다.\n따라서 인과 효과를 계산할 때는 \\(R_X\\)에 대한 조건 없이, 오직 \\(Y\\)가 처치 \\(x\\)에 어떻게 반응하는지(\\(R_Y\\))만 고려하면 됩니다."
  },
  {
    "objectID": "posts/lecture/L08/causal-inference-08-part-02/index.html#해결-및-결과",
    "href": "posts/lecture/L08/causal-inference-08-part-02/index.html#해결-및-결과",
    "title": "[Causal Inference] 08. Partial Identification (Part 2)",
    "section": "5.4 해결 및 결과",
    "text": "5.4 해결 및 결과\n\nCanonical Type Model을 도입함으로써, 우리는 무한한 차원의 문제를 16개의 변수(\\(q_{j,k}\\))를 가진 선형 계획법(Linear Programming) 문제로 변환했습니다.\n이를 구체적인 수식으로 살펴보겠습니다.\n\n\n5.4.1 최적화 문제 정의 (Optimization Setup)\n\n목표: 관측 데이터(\\(P\\))와 확률의 공리(\\(\\sum q = 1, q \\ge 0\\))를 만족하면서, 인과 효과를 최소화/최대화하는 \\(q\\)의 조합을 찾는 것입니다.\n\n\n5.4.1.1 목적 함수 (Objective Function):\n\n예를 들어, \\(P(Y=1 | do(X=0))\\)의 범위를 구한다고 가정해 봅시다.\n\\(X=0\\)으로 처치를 고정했을 때 \\(Y=1\\)이 나오는 반응 유형은 Hurt(\\(R_{y}=2\\))와 Always-recover(\\(R_{y}=3\\))입니다.\n따라서 목적 함수는 다음과 같습니다.\n\n\\[\n\\min_\\mathbf{q} \\sum_{j=0}^3 (q_{j2} + q_{j3}) \\quad \\text{또는} \\quad \\max_\\mathbf{q} \\sum_{j=0}^3 (q_{j2} + q_{j3})\n\\]\n\n\n5.4.1.2 제약 조건 (Constraints):\n\n관측확률에 대한 선형 등식: \\[\n\\begin{aligned}\np_{00.0} &= q_{00} + q_{01} + q_{10} + q_{11} \\\\\np_{00.1} &= q_{00} + q_{01} + q_{20} + q_{21} \\\\\n&\\vdots \\\\\np_{11.1} &= q_{12} + q_{13} + q_{32} + q_{33}\n\\end{aligned}\n\\]\n확률의 공리: \\(\\sum_{j,k} q_{j,k} = 1\\), \\(q_{j,k} \\ge 0\\)\n\n\n\n5.4.1.3 Closed-form Solution\n\n이 선형 계획법 문제를 심플렉스 알고리즘 등으로 풀면, Closed-form Solution를 얻을 수 있습니다.\n인과 효과 \\(P(Y=1 | do(X=0))\\)의 하한(Lower Bound)은 다음 값들 중 최댓값(\\(\\max\\))으로 결정됩니다.\n\n\\[\nP(Y=1 | do(X=0)) \\ge \\max \\begin{cases}\np_{10.0} \\\\\np_{10.1} \\\\\np_{10.0} + p_{11.0} - p_{00.1} - p_{11.1} \\\\\np_{01.0} + p_{10.0} - p_{00.1} - p_{01.1} \\\\\n\\end{cases}\n\\]\n\\[\nP(Y=1 | do(X=0)) \\le \\min \\begin{cases}\n1 - p_{00.0} \\\\\n1 - p_{00.1} \\\\\np_{10.0} + p_{11.0} + p_{01.1} + p_{10.1} \\\\\np_{01.0} + p_{10.0} + p_{10.1} + p_{11.1} \\\\\n\\end{cases}\n\\]\n\n\n\n5.4.2 결과의 의미\n\n위 수식은 복잡해 보이지만 중요한 함의를 갖습니다.\n\n\n데이터만으로 계산 가능: 우변의 모든 항(\\(p_{yx.z}\\))은 관측 데이터로부터 바로 구할 수 있는 값들입니다.\n\n\nTightness: 이 범위는 IV 모델의 가정(\\(Z \\perp U\\) 등)을 수학적으로 완벽하게 반영한 결과입니다. 따라서 추가적인 가정이 없다면 이보다 더 좁은 범위를 찾는 것은 불가능합니다.\n\n\nNote: Natural Bounds는 단순히 관측된 확률의 교집합만 고려하지만, Balke-Pearl Bounds(LP)는 도구 변수의 구조적 정보를 최적화 과정에 반영하여 훨씬 더 정보가 풍부한(Informative) 결과를 제공합니다.*"
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-02-The-Effect-of-the-Size-of-the-Calibration-Set/index.html",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-02-The-Effect-of-the-Size-of-the-Calibration-Set/index.html",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 3.2)",
    "section": "",
    "text": "Conformal Prediction(CP)을 실제 서비스에 배포할 때, 엔지니어가 가장 먼저 마주하는 실무적인 질문은 이것입니다.\n\n\n“Calibration Set(\\(n\\))의 크기는 얼마나 커야 할까요? 100개면 충분한가요, 아니면 1,000개가 필요한가요?”\n\n\n이론적으로 CP의 커버리지 보장(\\(1-\\alpha\\))은 \\(n\\)의 크기와 상관없이 성립합니다(Finite-sample guarantee).\n하지만 직관적으로 생각했을 때, 데이터가 많을수록 더 안정적일 것이라 예상할 수 있습니다.\n이번 포스트에서는 Calibration Set의 크기 \\(n\\)이 예측 구간의 안정성(Stability)에 미치는 영향을 수학적으로 분석하고, 실무적인 가이드라인(\\(n \\approx 1000\\))을 제시합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-02-The-Effect-of-the-Size-of-the-Calibration-Set/index.html#the-theoretical-guarantee-validity",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-02-The-Effect-of-the-Size-of-the-Calibration-Set/index.html#the-theoretical-guarantee-validity",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 3.2)",
    "section": "The Theoretical Guarantee (Validity)",
    "text": "The Theoretical Guarantee (Validity)\n\n놀랍게도, CP의 커버리지 보장 정리(Theorem 1)는 모든 \\(n\\)에 대해 성립합니다.\nCalibration 데이터가 단 10개뿐이라도, 새로운 데이터에 대한 평균 커버리지는 \\(1-\\alpha\\)를 만족합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-02-The-Effect-of-the-Size-of-the-Calibration-Set/index.html#the-catch-stability",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-02-The-Effect-of-the-Size-of-the-Calibration-Set/index.html#the-catch-stability",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 3.2)",
    "section": "The Catch (Stability)",
    "text": "The Catch (Stability)\n\n하지만 여기에는 중요한 디테일이 숨어 있습니다.\n우리가 보장하는 것은 “Calibration Set을 무한히 새로 뽑았을 때의 평균”입니다.\n하지만 현실에서 우리는 단 하나의 고정된 Calibration Set을 사용합니다.\n만약 우리가 운이 나빠서 이상한(Bias된) 데이터가 섞인 Calibration Set을 뽑았다면 어떨까요?\n이 고정된 데이터셋으로 학습된 CP 모델을 무한한 테스트 데이터에 적용했을 때의 실제 커버리지는 \\(1-\\alpha\\)와 정확히 일치하지 않을 수 있습니다.\n즉, Calibration Set 자체의 무작위성(Randomness) 때문에 실제 커버리지는 확률 변수(Random Quantity)가 됩니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-02-The-Effect-of-the-Size-of-the-Calibration-Set/index.html#required-sample-size-calculation",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-02-The-Effect-of-the-Size-of-the-Calibration-Set/index.html#required-sample-size-calculation",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 3.2)",
    "section": "Required Sample Size Calculation",
    "text": "Required Sample Size Calculation\n\n만약 더 엄격한 기준(예: 99% 확률로 오차 1% 이내)이 필요하다면, 다음 표를 참고하여 필요한 \\(n\\)을 역산할 수 있습니다.\n\n\n\n\n허용 오차 (\\(\\epsilon\\))\n필요한 \\(n\\) (신뢰도 90%)\n\n\n\n\n0.1 (10%)\n22\n\n\n0.05 (5%)\n102\n\n\n0.01 (1%)\n2,491\n\n\n0.005 (0.5%)\n9,812\n\n\n\n\n일반적인 기준인 90% 신뢰도(\\(\\delta=0.1\\))에서 목표 커버리지와의 오차를 1%(\\(\\epsilon=0.01\\)) 이내로 줄이려면 약 2,500개의 데이터가 필요합니다.\n하지만 5% 오차(\\(\\epsilon=0.05\\))를 허용한다면 102개로도 충분합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-01-Group-Balanced-Conformal-Prediction/index.html",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-01-Group-Balanced-Conformal-Prediction/index.html",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.1)",
    "section": "",
    "text": "지금까지 우리는 전체 데이터셋에 대해 평균적으로 \\(1-\\alpha\\)의 커버리지를 보장하는 방법(Marginal Coverage)을 배웠습니다.\n하지만 현실 세계, 특히 의료나 금융 같은 민감한 분야에서는 “평균적인 성공”만으로는 충분하지 않습니다.\n예를 들어, 어떤 질병 진단 AI가 백인 환자에게는 99%의 정확도를 보이지만, 유색 인종 환자에게는 80%의 정확도밖에 보이지 않는다고 가정해봅시다.\n이 경우 백인 환자가 다수라면 전체 평균 정확도는 90%를 넘길 수 있겠지만, 이는 공정하지 못한(Unfair) 시스템입니다.\nGroup-Balanced Conformal Prediction은 이러한 문제를 해결하기 위해, 데이터 내의 특정 그룹(인종, 성별, 연령대 등) 각각에 대해 독립적으로 커버리지를 보장하는 기법입니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-01-Group-Balanced-Conformal-Prediction/index.html#step-1-stratify-calibration-data",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-01-Group-Balanced-Conformal-Prediction/index.html#step-1-stratify-calibration-data",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.1)",
    "section": "Step 1: Stratify Calibration Data",
    "text": "Step 1: Stratify Calibration Data\n\nCalibration 데이터셋을 그룹별로 나눕니다.\n그룹 \\(g\\)에 속하는 데이터들만 모아서 부분집합을 만듭니다.\n\n\\[\nS^{(g)} = \\{ (X_j, Y_j) : X_{j,1} = g \\}\n\\]"
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-01-Group-Balanced-Conformal-Prediction/index.html#step-2-calibrate-per-group",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-01-Group-Balanced-Conformal-Prediction/index.html#step-2-calibrate-per-group",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.1)",
    "section": "Step 2: Calibrate per Group",
    "text": "Step 2: Calibrate per Group\n\n각 그룹 \\(g\\)에 대해 독립적으로 Quantile \\(\\hat{q}^{(g)}\\)를 계산합니다.\n\n그룹 \\(g\\) 데이터에 대한 Conformal Score들을 계산합니다: \\[s^{(g)}_1, \\dots, s^{(g)}_{n^{(g)}}\\]\n\n\n해당 그룹의 데이터 개수 \\(n^{(g)}\\)를 기준으로 보정된 분위수를 구합니다: \\[\n\\hat{q}^{(g)} = \\text{Quantile}\\left( \\frac{\\lceil (n^{(g)}+1)(1-\\alpha) \\rceil}{n^{(g)}} ; \\{s^{(g)}_1, \\dots, s^{(g)}_{n^{(g)}}\\} \\right)\n\\]\n\n결과적으로 우리는 그룹의 개수만큼 서로 다른 임계값(Threshold) \\(\\hat{q}^{(1)}, \\dots, \\hat{q}^{(G)}\\)를 얻게 됩니다.\n\n모델이 잘 맞추는 쉬운 그룹은 \\(\\hat{q}\\)가 작을 것이고 (작은 예측 집합),\n모델이 어려워하는 그룹은 \\(\\hat{q}\\)가 클 것입니다 (큰 예측 집합)."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-01-Group-Balanced-Conformal-Prediction/index.html#step-3-inference",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-01-Group-Balanced-Conformal-Prediction/index.html#step-3-inference",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.1)",
    "section": "Step 3: Inference",
    "text": "Step 3: Inference\n\n새로운 테스트 데이터 \\(X_{test}\\)가 들어오면, 먼저 이 데이터가 어느 그룹에 속하는지(\\(X_{test,1}\\)) 확인합니다.\n그리고 해당 그룹에 맞는 임계값 \\(\\hat{q}^{(X_{test,1})}\\)을 사용하여 예측 집합을 구성합니다.\n\n\\[\n\\mathcal{C}(x) = \\{ y : s(x, y) \\le \\hat{q}^{(x_1)} \\}\n\\]\n\n\n\nFigure: Group-Balanced Conformal Prediction의 개념도. 전체 데이터를 파란색 그룹과 초록색 그룹으로 나누고, 각각의 분포(Histogram)에서 별도의 Quantile \\(\\hat{q}^{(1)}, \\hat{q}^{(2)}\\)를 계산하여 적용한다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-04-Outlier-Detection/index.html",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-04-Outlier-Detection/index.html",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.4)",
    "section": "",
    "text": "이전까지 우리는 입력 \\(X\\)와 정답 \\(Y\\)가 있는 지도 학습 환경을 다루었습니다.\n하지만 \\(Y\\) 라벨이 없는 경우, 특히 “정상 데이터 분포에서 벗어난 이상치(Outlier)”를 탐지해야 하는 상황은 어떻게 해야 할까요?\n\n공장 설비의 이상 진동 감지\n네트워크 침입 탐지\n불량품 검출\n\n이러한 Outlier Detection (Anomaly Detection) 문제에서도 Conformal Prediction을 활용하면, “정상 데이터를 이상치라고 오판할 확률(False Positive Rate)”을 통계적으로 제어할 수 있습니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-04-Outlier-Detection/index.html#step-1-define-heuristic-score-function",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-04-Outlier-Detection/index.html#step-1-define-heuristic-score-function",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.4)",
    "section": "Step 1: Define Heuristic Score Function",
    "text": "Step 1: Define Heuristic Score Function\n\n비지도 학습 모델(예: One-class SVM, Isolation Forest, Autoencoder의 Reconstruction Error 등)을 사용하여, 데이터 포인트가 이상치일수록 커지는 점수 함수 \\(s(x)\\)를 정의합니다. \\[ s(x): \\mathcal{X} \\rightarrow \\mathbb{R} \\]\n\n\\(s(x)\\)가 큼 \\(\\rightarrow\\) 이상치(Outlier)일 가능성 높음\n\\(s(x)\\)가 작음 \\(\\rightarrow\\) 정상(Inlier)일 가능성 높음"
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-04-Outlier-Detection/index.html#step-2-calibration",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-04-Outlier-Detection/index.html#step-2-calibration",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.4)",
    "section": "Step 2: Calibration",
    "text": "Step 2: Calibration\n\n깨끗한 데이터셋 \\(X_1, \\dots, X_n\\)에 대해 점수들을 계산합니다. \\[ s_i = s(X_i), \\quad i=1, \\dots, n \\]\n그리고 이 점수들의 분포에서 \\(1-\\alpha\\) 분위수(Quantile)에 해당하는 임계값 \\(\\hat{q}\\)를 계산합니다.\n\n\\[\n\\hat{q} = \\text{Quantile}\\left( \\{s_1, \\dots, s_n\\} ; \\frac{\\lceil (n+1)(1-\\alpha) \\rceil}{n} \\right)\n\\]"
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-04-Outlier-Detection/index.html#step-3-detection-inference",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-04-Outlier-Detection/index.html#step-3-detection-inference",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.4)",
    "section": "Step 3: Detection (Inference)",
    "text": "Step 3: Detection (Inference)\n\n새로운 테스트 데이터 \\(X_{test}\\)가 들어오면 점수 \\(s(X_{test})\\)를 계산하고, 임계값 \\(\\hat{q}\\)와 비교하여 판정합니다.\n\n\\[\n\\mathcal{C}(x) = \\begin{cases} \\text{inlier} & \\text{if } s(x) \\le \\hat{q} \\\\ \\text{outlier} & \\text{if } s(x) &gt; \\hat{q} \\end{cases}\n\\]"
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-06-Conformal-Prediction-Under-Distribution-Shift/index.html",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-06-Conformal-Prediction-Under-Distribution-Shift/index.html",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.6)",
    "section": "",
    "text": "이전 포스트(4.5절)에서는 입력 분포가 변하는 Covariate Shift를 다루었습니다.\n하지만 그보다 더 다루기 까다로운 것은 Distribution Drift(분포 표류)입니다.\nDistribution Drift는 데이터의 분포가 시간이 지남에 따라 서서히(Slowly varying), 혹은 알 수 없는 방식으로 변하는 현상을 말합니다.\n\n주식 시장: 10년 전의 시장 상황과 오늘의 시장 상황은 전혀 다릅니다.\n센서 데이터: 기계가 노후화되면서 센서의 측정값 분포가 서서히 달라집니다.\n\n이런 시계열(Time-series) 문제에서는 “과거의 모든 데이터가 미래를 예측하는 데 동등하게 중요하다”는 i.i.d. 가정이 성립하지 않습니다.\n1년 전 데이터보다 어제의 데이터가 훨씬 중요하기 때문입니다.\n이번 포스트에서는 최신 데이터에 더 큰 가중치를 부여하는 Weighted Conformal Prediction을 통해 이 문제를 해결하는 방법을 알아봅니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-06-Conformal-Prediction-Under-Distribution-Shift/index.html#step-1-define-weight-schedule",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-06-Conformal-Prediction-Under-Distribution-Shift/index.html#step-1-define-weight-schedule",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.6)",
    "section": "Step 1: Define Weight Schedule",
    "text": "Step 1: Define Weight Schedule\n\n사용자는 도메인 지식에 기반하여 “오래된 데이터를 얼마나 잊을 것인가”를 결정하는 가중치 스케줄을 정의합니다.\n가장 널리 쓰이는 두 가지 방법은 다음과 같습니다:\n\nRolling Window (Sliding Window):\n\n\n최근 \\(K\\)개의 데이터만 사용하고, 나머지는 버립니다. \\[ w_i^{\\text{fixed}} = \\mathbb{I}\\{i \\ge n - K\\} \\]\n\n\nExponential Decay (Smooth Decay):\n\n\n과거 데이터의 영향력을 지수적으로 감소시킵니다. \\[ w_i^{\\text{decay}} = \\gamma^{n-i+1} \\quad (0 &lt; \\gamma &lt; 1) \\]\n예: \\(\\gamma = 0.99\\)라면 바로 직전 데이터는 1, 그 전은 0.99, 그 전은 \\(0.98 \\dots\\) 가중치를 가짐."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-06-Conformal-Prediction-Under-Distribution-Shift/index.html#step-2-normalize-weights",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-06-Conformal-Prediction-Under-Distribution-Shift/index.html#step-2-normalize-weights",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.6)",
    "section": "Step 2: Normalize Weights",
    "text": "Step 2: Normalize Weights\n\n정의된 가중치 \\(w_i\\)를 전체 합이 1이 되도록 정규화(Normalize)합니다.\n이때 테스트 포인트 \\(X_{test}\\)의 가중치 \\(w_{test}\\)도 포함하여 계산합니다.\n\n보통 \\(w_{test}=1\\)로 둠.\n\n\n\\[\n\\tilde{w}_i = \\frac{w_i}{\\sum_{j=1}^{n} w_j + 1}\n\\]"
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-06-Conformal-Prediction-Under-Distribution-Shift/index.html#step-3-weighted-quantile",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-06-Conformal-Prediction-Under-Distribution-Shift/index.html#step-3-weighted-quantile",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.6)",
    "section": "Step 3: Weighted Quantile",
    "text": "Step 3: Weighted Quantile\n\n정규화된 가중치를 사용하여 보정된 분위수(Quantile) \\(\\hat{q}\\)를 계산합니다.\nCalibration Score \\(s_i\\)들을 오름차순 정렬했을 때, 누적 가중치 합이 \\(1-\\alpha\\)를 넘는 지점을 찾습니다.\n\n\\[\n\\hat{q} = \\inf \\left\\{ q : \\sum_{i=1}^{n} \\tilde{w}_i \\mathbb{I}\\{s_i \\le q\\} \\ge 1-\\alpha \\right\\}\n\\]"
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 6)",
    "section": "",
    "text": "지금까지 우리가 다룬 방식은 Split Conformal Prediction (Inductive CP)이었습니다.\n이 방식은 데이터를 학습용(Train)과 보정용(Calibration)으로 나누어 사용합니다.\n\n장점: 계산이 매우 빠릅니다. 모델을 딱 한 번만 학습시키면 됩니다.\n단점: 데이터를 쪼개야 하므로 통계적 효율성(Statistical Efficiency)이 떨어집니다. 보정용 데이터는 학습에 기여하지 못하고, 학습용 데이터는 보정에 기여하지 못하기 때문입니다.\n\n데이터가 매우 귀하거나(예: 희귀병 임상 데이터), 예측의 정확도가 비용보다 훨씬 중요한 상황이라면 어떨까요?\n이때 우리는 계산 비용을 감수하더라도 모든 데이터를 학습과 보정에 동시에 사용하는 Full Conformal Prediction (Transductive CP)을 고려해야 합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html#step-1-loop-over-all-possible-labels",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html#step-1-loop-over-all-possible-labels",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 6)",
    "section": "Step 1: Loop over all possible labels",
    "text": "Step 1: Loop over all possible labels\n\n테스트 포인트 \\(X_{n+1}\\)에 대해, 가능한 모든 정답 후보 \\(y \\in \\mathcal{Y}\\) (예: 분류 문제의 모든 클래스)에 대해 다음 과정을 반복합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html#step-2-augment-and-retrain",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html#step-2-augment-and-retrain",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 6)",
    "section": "Step 2: Augment and Retrain",
    "text": "Step 2: Augment and Retrain\n\n기존 데이터셋에 가상의 데이터 포인트 \\((X_{n+1}, y)\\)를 추가하여 확장된 데이터셋을 만듭니다.\n그리고 이 데이터셋으로 모델 \\(\\hat{f}^y\\)를 처음부터 다시 학습시킵니다.\n\n\\[ \\text{Train } \\hat{f}^y \\text{ on } \\{(X_1, Y_1), \\dots, (X_n, Y_n), (X_{n+1}, y)\\} \\]\n\n주의: 이때 사용하는 학습 알고리즘은 데이터의 순서에 영향을 받지 않는 대칭적(Symmetric) 알고리즘이어야 합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html#step-3-compute-scores",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html#step-3-compute-scores",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 6)",
    "section": "Step 3: Compute Scores",
    "text": "Step 3: Compute Scores\n\n학습된 모델 \\(\\hat{f}^y\\)를 사용하여, 확장된 데이터셋 내의 모든 포인트(\\(i=1 \\dots n+1\\))에 대해 Conformal Score를 계산합니다.\n\n\\[ s_i^y = s(X_i, Y_i, \\hat{f}^y) \\quad \\text{for } i=1, \\dots, n \\] \\[ s_{n+1}^y = s(X_{n+1}, y, \\hat{f}^y) \\]"
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html#step-4-compute-quantile",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html#step-4-compute-quantile",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 6)",
    "section": "Step 4: Compute Quantile",
    "text": "Step 4: Compute Quantile\n\n이 \\(n+1\\)개의 점수들 사이에서 \\(s_{n+1}^y\\)의 위치를 확인합니다.\n정확히는 \\(1-\\alpha\\) 분위수 \\(\\hat{q}^y\\)를 계산하여, \\(s_{n+1}^y\\)가 이 안에 들어오는지 확인합니다.\n\n\\[ \\hat{q}^y = \\text{Quantile}\\left( \\{s_1^y, \\dots, s_{n+1}^y\\} ; \\frac{\\lceil (n+1)(1-\\alpha) \\rceil}{n+1} \\right) \\]"
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html#step-5-construct-prediction-set",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html#step-5-construct-prediction-set",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 6)",
    "section": "Step 5: Construct Prediction Set",
    "text": "Step 5: Construct Prediction Set\n\n위 조건을 만족하는(즉, 기존 데이터들과 잘 섞이는) 모든 \\(y\\)를 예측 집합에 포함시킵니다.\n\n\\[ \\mathcal{C}(X_{n+1}) = \\{ y \\in \\mathcal{Y} : s_{n+1}^y \\le \\hat{q}^y \\} \\]"
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html#the-null-hypothesis-of-exchangeability",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html#the-null-hypothesis-of-exchangeability",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 6)",
    "section": "The Null Hypothesis of Exchangeability",
    "text": "The Null Hypothesis of Exchangeability\n\n우리가 테스트 데이터 \\(X_{n+1}\\)에 대해 어떤 가상의 정답 \\(y\\)를 부여했을 때, 핵심 질문은 이것입니다.\n\n\n“이 데이터 포인트 \\((X_{n+1}, y)\\)가 기존 데이터들과 구별되지 않고 잘 섞이는가?”\n\n\n이를 통계적 가설 검정의 언어로 표현하면 다음과 같습니다.\n귀무가설 (\\(H_0\\)): 데이터들 \\(Z_1, \\dots, Z_{n+1}\\)은 교환 가능(Exchangeable)하다.\n즉, 데이터의 순서를 뒤섞어도 그 결합 확률 분포는 변하지 않는다.\n\n여기서 \\(Z_i = (X_i, Y_i)\\)입니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html#the-test-statistic-p-value",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html#the-test-statistic-p-value",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 6)",
    "section": "The Test Statistic & P-value",
    "text": "The Test Statistic & P-value\n\n이 귀무가설을 기각하기 위해, 우리는 데이터가 얼마나 “튀는지”를 측정하는 검정 통계량 \\(T\\)를 정의합니다.\nFull CP에서는 Nonconformity Score (\\(s\\))가 바로 이 역할을 합니다.\n\n\\[ T(Z) = s(X, Y) \\]\n\n점수 \\(s\\)가 클수록 해당 데이터는 다른 데이터들과 이질적이라는(Exchangeability를 위반한다는) 증거가 됩니다.\n우리는 관측된 데이터의 점수가, 데이터를 무작위로 섞었을 때 나올 수 있는 점수들과 비교해서 얼마나 큰지 p-value를 계산합니다.\n\n\\[ p = \\frac{\\sum_{\\sigma \\in S_{n+1}} \\mathbb{1}\\{ T(Z_{\\sigma(1)}, \\dots, Z_{\\sigma(n+1)}) \\ge T(Z_{observed}) \\}}{(n+1)!} \\]\n\n하지만 Full CP에서는 모든 순열을 다 계산할 필요 없이, 각 데이터 포인트의 점수 \\(s_i\\)들의 순위(Rank)만 보면 됩니다.\n따라서 p-value는 다음과 같이 단순화됩니다.\n\n\\[ p(y) = \\frac{1}{n+1} \\sum_{i=1}^{n+1} \\mathbb{1}\\{ s_i^y \\ge s_{n+1}^y \\} \\]"
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html#decision-rule-validity-theorem",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html#decision-rule-validity-theorem",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 6)",
    "section": "Decision Rule (Validity Theorem)",
    "text": "Decision Rule (Validity Theorem)\n\n순열 검정의 핵심 정리에 따르면, 귀무가설(\\(H_0\\))이 참일 때 p-value는 균등 분포(Uniform Distribution)를 따릅니다. 따라서 다음이 성립합니다.\n\n\nTheorem (Validity of Permutation Test)\n모든 \\(\\tau \\in [0, 1]\\)과 모든 교환 가능한 분포 \\(P\\)에 대해: \\[ \\mathbb{P}_P(p \\le \\tau) \\le \\tau \\]\n\n\n우리는 허용 가능한 에러율 \\(\\alpha\\)를 설정했으므로, p-value가 \\(\\alpha\\)보다 작으면(너무 희박한 확률이면) 귀무가설을 기각합니다.\n\\(p(y) \\le \\alpha\\) (기각): “\\(y\\)를 정답이라고 가정했더니, 이 데이터는 상위 \\(\\alpha\\)% 안에 들 만큼 너무 이상해. \\(y\\)는 정답이 아닌 것 같아.” \\(\\rightarrow\\) 예측 집합에서 제외.\n\\(p(y) &gt; \\alpha\\) (채택): “\\(y\\)를 정답이라고 가정해도, 데이터가 전체 무리 속에 자연스럽게 섞여 들어가네. \\(y\\)는 정답일 수도 있어.” \\(\\rightarrow\\) 예측 집합에 포함.\n결국 Full CP의 예측 집합 \\(\\mathcal{C}(X_{n+1})\\)은 “순열 검정에서 기각되지 않고 살아남은 모든 \\(y\\)들의 모임”입니다.\n이것이 바로 Full CP가 수학적으로 엄밀한 커버리지를 보장하는 이유입니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html#the-cost",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html#the-cost",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 6)",
    "section": "The Cost",
    "text": "The Cost\n\n이 방법의 가장 큰 문제는 계산 비용입니다.\n테스트 데이터가 하나 들어올 때마다, 그리고 후보 클래스 \\(K\\)개마다 매번 모델을 재학습해야 합니다.\n총 학습 횟수: \\((n+1) \\times K\\)\n따라서 딥러닝과 같이 학습이 오래 걸리는 모델이나, 회귀 문제(Regression)처럼 후보 \\(y\\)가 무한히 많은 경우에는 그대로 적용하기 어렵습니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html#the-benefit",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-06-Full-Conformal-Prediction/index.html#the-benefit",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 6)",
    "section": "The Benefit",
    "text": "The Benefit\n\n하지만 데이터를 나누지 않고 \\(n\\)개를 모두 사용하므로, 예측 집합이 더 작고 효율적(Sharp)입니다.\nSplit CP보다 정보 손실이 적어, 데이터가 적은 상황에서는 훨씬 강력한 성능을 발휘합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-02-Conformalized-Quantile-Regression/index.html",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-02-Conformalized-Quantile-Regression/index.html",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.2)",
    "section": "",
    "text": "이전 포스트에서는 분류(Classification) 문제에 대한 Conformal Prediction을 다루었습니다.\n이번에는 연속적인 값(Continuous Output)을 예측하는 회귀(Regression) 문제로 넘어가 보겠습니다.\n회귀 문제에서 우리의 목표는 입력 \\(x\\)에 대해 단순히 하나의 예측값 \\(\\hat{y}\\)를 내놓는 것이 아니라, 정답 \\(y\\)가 포함될 확률이 \\(1-\\alpha\\) (예: 90%)인 예측 구간(Prediction Interval)을 생성하는 것입니다.\n\n\\[\n\\mathcal{C}(x) = [\\text{Lower Bound}, \\text{Upper Bound}]\n\\]\n\n이를 위해 가장 효과적인 베이스 모델 중 하나인 Quantile Regression을 사용하고, CP를 통해 이를 보정하는 Conformalized Quantile Regression (CQR) 기법을 알아보겠습니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-02-Conformalized-Quantile-Regression/index.html#concept",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-02-Conformalized-Quantile-Regression/index.html#concept",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.2)",
    "section": "Concept",
    "text": "Concept\n\n일반적인 회귀 모델은 평균(Mean)을 예측(MSE Loss 사용)하지만, Quantile Regression은 조건부 분포의 특정 분위수(Quantile)를 예측합니다.\n90%의 커버리지를 목표로 한다면, 우리는 양쪽 꼬리에서 5%씩을 제외한 구간을 알고 싶을 것입니다. 즉, 다음 두 가지 분위수를 학습합니다:\n\nLower Quantile: \\(\\alpha/2 = 0.05\\) (5% 지점)\nUpper Quantile: \\(1 - \\alpha/2 = 0.95\\) (95% 지점)\n\n모델이 완벽하다면, 정답 \\(y\\)는 90%의 확률로 이 구간 \\([\\hat{t}_{\\alpha/2}(x), \\hat{t}_{1-\\alpha/2}(x)]\\) 사이에 존재해야 합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-02-Conformalized-Quantile-Regression/index.html#quantile-loss-pinball-loss",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-02-Conformalized-Quantile-Regression/index.html#quantile-loss-pinball-loss",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.2)",
    "section": "Quantile Loss (Pinball Loss)",
    "text": "Quantile Loss (Pinball Loss)\n\n이러한 분위수를 학습하기 위해 Quantile Loss (Pinball Loss)를 사용합니다.\n\n\\[\nL_{\\gamma}(\\hat{t}_{\\gamma}, y) = (y - \\hat{t}_{\\gamma})\\gamma \\mathbb{1}\\{y &gt; \\hat{t}_{\\gamma}\\} + (\\hat{t}_{\\gamma} - y)(1-\\gamma)\\mathbb{1}\\{y \\le \\hat{t}_{\\gamma}\\}\n\\]\n\n\\(\\gamma\\): 타겟 분위수 (예: 0.05 또는 0.95)\n이 손실 함수를 사용하여 뉴럴 네트워크 등 어떤 모델이든 특정 분위수를 예측하도록 학습시킬 수 있습니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-02-Conformalized-Quantile-Regression/index.html#step-1-define-score-function",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-02-Conformalized-Quantile-Regression/index.html#step-1-define-score-function",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.2)",
    "section": "Step 1: Define Score Function",
    "text": "Step 1: Define Score Function\n\nCalibration 데이터 \\((X_i, Y_i)\\)에 대해, 정답 \\(Y_i\\)가 학습된 구간 \\([\\hat{t}_{\\alpha/2}(X_i), \\hat{t}_{1-\\alpha/2}(X_i)]\\) 밖으로 얼마나 나갔는지를 측정하는 Score를 정의합니다.\n\n\\[\ns(x, y) = \\max \\{ \\hat{t}_{\\alpha/2}(x) - y, \\quad y - \\hat{t}_{1-\\alpha/2}(x) \\}\n\\]\n\n이 식의 의미를 직관적으로 살펴봅시다:\n\nCase 1: \\(y\\)가 구간 안에 있을 때:\n\n\\(\\hat{t}_{\\text{lower}} &lt; y &lt; \\hat{t}_{\\text{upper}}\\) 이므로, 두 항 모두 음수가 됩니다.\n\\(s(x, y) &lt; 0\\) (즉, 안전함)\n\nCase 2: \\(y\\)가 구간 밖(위쪽)에 있을 때:\n\n\\(y &gt; \\hat{t}_{\\text{upper}}\\) 이므로 \\(y - \\hat{t}_{\\text{upper}}\\) 가 양수가 됩니다.\n\\(s(x, y) &gt; 0\\) (즉, 위험함/에러)\n\n\n즉, 점수 \\(s\\)가 클수록 정답이 예측 구간을 크게 벗어났음을 의미합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-02-Conformalized-Quantile-Regression/index.html#step-2-calibration-get-hatq",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-02-Conformalized-Quantile-Regression/index.html#step-2-calibration-get-hatq",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.2)",
    "section": "Step 2: Calibration (Get \\(\\hat{q}\\))",
    "text": "Step 2: Calibration (Get \\(\\hat{q}\\))\n\n계산된 점수들 \\(s_1, \\dots, s_n\\)의 분포에서 \\(1-\\alpha\\) 분위수 \\(\\hat{q}\\)를 찾습니다.\n\n\\[\n\\hat{q} = \\text{Quantile}\\left( \\frac{\\lceil (n+1)(1-\\alpha) \\rceil}{n} ; \\{s_1, \\dots, s_n\\} \\right)\n\\]\n\n만약 모델이 불확실성을 과소평가했다면(구간이 너무 좁으면), 많은 \\(y\\)가 구간 밖에 있을 것이고 \\(s\\)값들이 커져서 양수의 \\(\\hat{q}\\)가 나옵니다.\n만약 모델이 불확실성을 과대평가했다면(구간이 너무 넓으면), \\(s\\)값들이 대부분 음수일 것이고 음수의 \\(\\hat{q}\\)가 나옵니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-02-Conformalized-Quantile-Regression/index.html#step-3-construct-prediction-interval",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-02-Conformalized-Quantile-Regression/index.html#step-3-construct-prediction-interval",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.2)",
    "section": "Step 3: Construct Prediction Interval",
    "text": "Step 3: Construct Prediction Interval\n\n최종적으로 새로운 입력 \\(X_{test}\\)에 대한 예측 구간을 생성할 때, 원래 구간을 \\(\\hat{q}\\)만큼 조정합니다.\n\n\\[\n\\mathcal{C}(X_{test}) = [\\hat{t}_{\\alpha/2}(X_{test}) - \\hat{q}, \\quad \\hat{t}_{1-\\alpha/2}(X_{test}) + \\hat{q}]\n\\]\n\n\\(\\hat{q} &gt; 0\\): 원래 구간이 너무 좁았으므로, 양쪽으로 \\(\\hat{q}\\)만큼 넓힙니다.\n\\(\\hat{q} &lt; 0\\): 원래 구간이 너무 넓었으므로, 양쪽으로 \\(|\\hat{q}|\\)만큼 좁힙니다.\n\n\n\n\nFigure 6: CQR 알고리즘의 시각화. 원래의 Quantile Regression 구간(파란색 영역)을 Calibration을 통해 얻은 상수 \\(\\hat{q}\\)만큼 확장하거나 축소하여 최종 Prediction Set을 생성한다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-01-Classification-wiht-Adaptive-Prediction-Sets/index.html",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-01-Classification-wiht-Adaptive-Prediction-Sets/index.html",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.1)",
    "section": "",
    "text": "이전 포스트(Section 1)에서 다룬 기본적인 Conformal Prediction 방법은 단순하고 강력하지만 한 가지 단점이 있습니다.\n기존 방식(Naive method)은 단순히 \\(1 - \\hat{f}(x)_y\\)를 점수로 사용하기 때문에, 모든 클래스에 대해 고정된 임계값(Threshold)을 적용하는 경향이 있습니다.\n이로 인해 다음과 같은 문제가 발생합니다:\n\n\nHard Inputs (어려운 이미지): 모델이 헷갈려하는 경우에도 예측 집합이 충분히 커지지 않아 정답을 놓칠 수 있습니다 (Under-coverage).\n\n\nEasy Inputs (쉬운 이미지): 모델이 확신하는 경우에도 예측 집합이 불필요하게 클 수 있습니다 (Over-coverage).\n\n\n우리는 입력 이미지의 난이도에 따라 어려우면 집합을 크게, 쉬우면 집합을 작게 만드는 Adaptive Prediction Sets (APS) 기법을 도입하여 이 문제를 해결할 것입니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-01-Classification-wiht-Adaptive-Prediction-Sets/index.html#defining-the-score-function",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-01-Classification-wiht-Adaptive-Prediction-Sets/index.html#defining-the-score-function",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.1)",
    "section": "1. Defining the Score Function",
    "text": "1. Defining the Score Function\n\nAPS를 위한 Score Function \\(s(x, y)\\)는 “정답 클래스 \\(y\\)를 포함시키기 위해, 확률 상위 몇 번째 클래스까지 내려가야 하는가?”를 누적 확률로 나타냅니다.\n먼저, 입력 \\(x\\)에 대해 모델이 예측한 확률을 내림차순으로 정렬하는 순열 함수 \\(\\pi(x)\\)를 정의합니다. \\[ \\hat{f}(x)_{\\pi_1(x)} \\ge \\hat{f}(x)_{\\pi_2(x)} \\ge \\dots \\ge \\hat{f}(x)_{\\pi_K(x)} \\]\n이때, 정답 클래스 \\(y\\)가 정렬된 순서상 \\(k\\)번째에 위치한다고 가정합시다 (\\(y = \\pi_k(x)\\)).\nScore \\(s(x, y)\\)는 \\(y\\)까지의 누적 확률 질량(Cumulative Probability Mass)으로 정의됩니다:\n\n\\[\ns(x,y) = \\sum_{j=1}^{k} \\hat{f}(x)_{\\pi_j(x)}\n\\]\n\n의미: “모델이 가장 가능성 높다고 생각하는 것부터 정답 \\(y\\)가 나올 때까지 확률을 다 더한 값”입니다.\n\n만약 모델이 정답을 1순위로 예측했다면, \\(s(x,y)\\)는 작을 것입니다.\n만약 모델이 정답을 하위권으로 예측했다면, \\(s(x,y)\\)는 1에 가까워질 것입니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-01-Classification-wiht-Adaptive-Prediction-Sets/index.html#calibration-finding-hatq",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-01-Classification-wiht-Adaptive-Prediction-Sets/index.html#calibration-finding-hatq",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.1)",
    "section": "2. Calibration (Finding \\(\\hat{q}\\))",
    "text": "2. Calibration (Finding \\(\\hat{q}\\))\n\n이제 Calibration 데이터셋 \\((X_1, Y_1), \\dots, (X_n, Y_n)\\)에 대해 위 점수들을 계산합니다.\n그리고 다음 식을 만족하는 분위수(Quantile) \\(\\hat{q}\\)를 찾습니다.\n\n\\[\n\\hat{q} = \\text{Quantile}\\left( \\frac{\\lceil (n+1)(1-\\alpha) \\rceil}{n} ; \\{s_1, \\dots, s_n\\} \\right)\n\\]\n\n이 \\(\\hat{q}\\)는 “정답을 포함하기 위해 누적 확률을 어디까지 허용해야 하는가?”에 대한 통계적 임계값입니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-01-Classification-wiht-Adaptive-Prediction-Sets/index.html#constructing-the-prediction-set",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-01-Classification-wiht-Adaptive-Prediction-Sets/index.html#constructing-the-prediction-set",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.1)",
    "section": "3. Constructing the Prediction Set",
    "text": "3. Constructing the Prediction Set\n\n새로운 테스트 데이터 \\(X_{test}\\)에 대해 예측 집합 \\(\\mathcal{C}(X_{test})\\)는 누적 확률이 \\(\\hat{q}\\)를 넘어서는 지점까지의 모든 클래스를 포함하여 구성됩니다.\n\n\\[\n\\mathcal{C}(x) = \\{ \\pi_1(x), \\dots, \\pi_k(x) \\}\n\\]\n\n여기서 \\(k\\)는 다음을 만족하는 가장 작은 정수입니다: \\[\n\\text{sup} \\left\\{ k' : \\sum_{j=1}^{k'} \\hat{f}(x)_{\\pi_j(x)} &lt; \\hat{q} \\right\\} + 1\n\\]\n즉, 누적 합이 \\(\\hat{q}\\)를 초과하는 순간까지 포함합니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 5)",
    "section": "",
    "text": "지금까지 우리는 Conformal Prediction(CP)의 다양한 이론적 확장(Extension)들을 다루었습니다.\n이제 이 도구들이 실제 머신러닝 문제에서 어떻게 작동하는지 확인할 차례입니다.\n이번 포스트에서는 논문의 Section 5에서 소개된 5가지의 구체적인 적용 사례를 살펴봅니다.\n각 사례는 단순한 분류/회귀를 넘어, Risk Control, Distribution Shift, Outlier Detection 등 현실적인 난제들을 어떻게 해결하는지 보여줍니다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html#problem-setup",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html#problem-setup",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 5)",
    "section": "Problem Setup",
    "text": "Problem Setup\n\n이미지 안에 있는 모든 객체를 맞추는 다중 라벨 분류(Multilabel Classification) 문제입니다.\n단순히 정답을 포함하는 것을 넘어, “정답 객체 중 90% 이상을 찾아내라(Recall \\(\\ge\\) 90%)”와 같은 요구사항이 있을 때 사용합니다.\n이를 위해 False Negative Rate (FNR)를 제어합니다.\n\nDataset: Microsoft COCO (Common Objects in Context)\nGoal: 실제 객체들(\\(Y\\)) 중 모델이 예측한 집합(\\(\\mathcal{C}\\))에 포함되지 않은 비율(FNR)을 \\(\\alpha\\) 이하로 유지."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html#methodology-conformal-risk-control",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html#methodology-conformal-risk-control",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 5)",
    "section": "Methodology: Conformal Risk Control",
    "text": "Methodology: Conformal Risk Control\n\n여기서는 Section 4.3에서 다룬 Conformal Risk Control(CRC)을 사용합니다.\n\nPrediction Set Construction:\n\n\n모델의 예측 확률 \\(\\hat{f}(x)\\)가 임계값 \\(\\lambda\\) 이상인 클래스들을 선택합니다. \\[ \\mathcal{C}_\\lambda(x) = \\{ k : \\hat{f}(x)_k \\ge \\lambda \\} \\]\n\n\\(\\lambda\\)가 작을수록 더 많은 클래스를 포함하므로 보수적이 됨.\n\n\n\nLoss Function (\\(l_{FNR}\\)):\n\n\n예측 집합이 정답을 얼마나 놓쳤는지를 정의합니다. \\[l_{FNR}(\\mathcal{C}_\\lambda(x), y) = 1 - \\frac{|\\mathcal{C}_\\lambda(x) \\cap y|}{|y|}\\]\n만약 정답 \\(y=\\{\\text{사람, 차}\\}\\)인데 예측 \\(\\mathcal{C}=\\{\\text{사람}\\}\\)이라면, 교집합은 1개, 정답은 2개이므로 손실은 \\(1 - 1/2 = 0.5\\)입니다.\n\n\n\nThreshold Optimization:\n\nCalibration Set에서 경험적 리스크가 \\(\\alpha\\) (보정항 포함) 이하가 되는 \\(\\hat{\\lambda}\\)를 찾습니다. \\[ \\hat{\\lambda} = \\inf \\left\\{ \\lambda : \\frac{1}{n}\\sum_{i=1}^n l_{FNR}(\\mathcal{C}_\\lambda(X_i), Y_i) \\le \\alpha - \\frac{1-\\alpha}{n} \\right\\} \\]\n\n\n\n\n\nFigure: MS COCO 데이터셋에 대한 Multilabel Classification 결과 (\\(\\alpha=0.1\\)). 빨간색 텍스트는 놓친 정답(False Negative), 파란색은 잘못 예측한 오답(False Positive), 검은색은 맞춘 정답(True Positive)을 나타낸다. 평균적으로 90% 이상의 정답 라벨을 찾아내고 있다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html#problem-setup-1",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html#problem-setup-1",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 5)",
    "section": "Problem Setup",
    "text": "Problem Setup\n\n의료 영상에서 종양(Tumor) 부위를 픽셀 단위로 분할(Segmentation)하는 문제입니다.\n여기서도 핵심은 “종양 픽셀을 놓치지 않는 것”입니다. 즉, 픽셀 단위의 FNR 제어가 필요합니다.\n\nDataset: Gut Polyps dataset\nGoal: 전체 종양 픽셀 중 예측 마스크가 커버하지 못한 비율을 제어."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html#methodology",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html#methodology",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 5)",
    "section": "Methodology",
    "text": "Methodology\n\nMultilabel Classification과 원리는 동일하지만, 대상이 클래스에서 픽셀로 바뀝니다.\n\nOutput: \\(M \\times N\\) 크기의 확률 맵 \\(\\hat{f}(x)\\).\n\n\nPrediction Mask: 각 픽셀 \\((i,j)\\)에 대해 확률이 \\(\\lambda\\) 이상이면 종양으로 예측. \\[\\mathcal{C}_\\lambda(x) = \\{ (i,j) : \\hat{f}(x)_{(i,j)} \\ge \\lambda \\}\\]\n\n\nLoss Function: \\[l(\\mathcal{C}, Y) = \\frac{\\text{\\# of missed tumor pixels}} {\\text{total \\# of tumor pixels}}\\]\n\n이 방법을 적용하면 의사는 “이 AI가 표시한 영역 안에 실제 종양의 90%가 포함되어 있다”는 확신을 가지고 진단에 임할 수 있습니다.\n\n\n\n\nFigure: 종양 분할(Tumor Segmentation) 결과 (\\(\\alpha=0.1\\)). 붉은 영역은 모델이 놓친 종양 부위(False Negative)이다. CRC를 통해 놓치는 부위를 통계적으로 최소화할 수 있다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html#problem-setup-2",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html#problem-setup-2",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 5)",
    "section": "Problem Setup",
    "text": "Problem Setup\n\n시간의 흐름에 따라 기온(Temperature)을 예측하는 시계열 회귀 문제입니다.\n시간이 지남에 따라 계절이 바뀌고 기후가 변하므로, 데이터는 i.i.d.가 아니며 분포가 표류(Distribution Drift)합니다.\n\nDataset: Yandex Weather Prediction (Shifts Project)\nChallenge: 과거 데이터와 현재 데이터의 상관관계가 변함."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html#methodology-weighted-conformal-prediction",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html#methodology-weighted-conformal-prediction",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 5)",
    "section": "Methodology: Weighted Conformal Prediction",
    "text": "Methodology: Weighted Conformal Prediction\n\nSection 4.6의 분포 표류(Distribution Drift) 대응법을 사용합니다.\n\nScore Function:\n\n\n예측값 \\(\\hat{f}(X_t)\\)와 불확실성 추정값 \\(\\hat{u}(X_t)\\)를 이용한 정규화된 잔차(Normalized Residual)를 사용합니다. \\[ s_t = \\frac{|Y_t - \\hat{f}(X_t)|}{\\hat{u}(X_t)} \\]\n\n\nWeighted Quantile:\n\n\n최근 \\(K\\)개의 데이터만 사용하는 Sliding Window 방식을 적용합니다.\n가중치 \\(w_{t'} = \\mathbb{I}\\{t' \\ge t - K\\}\\)를 사용하여, 오래된 데이터는 과감히 버리고 최근 데이터 분포에만 맞춥니다. \\[ \\hat{q}_t = \\text{Quantile}_{\\text{weighted}}(s_{t-K}, \\dots, s_{t-1}) \\]\n\n결과적으로 급격한 기온 변화나 계절 변화가 발생했을 때, 일반 CP보다 훨씬 빠르게 적응하여 적절한 커버리지를 회복합니다.\n\n\n\n\nFigure: 시계열 기온 예측 결과. (왼쪽) 일반 CP(주황색)는 분포 변화 시 커버리지가 무너지지만, Weighted CP(파란색)는 빠르게 회복하여 목표 커버리지(0.9)를 유지한다. (오른쪽) 예측된 구간의 시각화."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html#problem-setup-3",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html#problem-setup-3",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 5)",
    "section": "Problem Setup",
    "text": "Problem Setup\n\n온라인 댓글이 유해한지(Toxic) 아닌지를 판별하는 문제입니다.\n정상적인 대화(Non-toxic) 데이터만 잔뜩 있는 상태에서, 새로운 댓글이 정상 범주를 벗어난(Outlier/Toxic) 것인지 탐지합니다.\n\nDataset: Jigsaw Multilingual Toxic Comment Classification\nGoal: 정상 댓글을 유해하다고 잘못 판별할 확률(False Positive Rate)을 \\(\\alpha\\) 이하로 제어. (Type-1 Error Control)"
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html#methodology-conformal-outlier-detection",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html#methodology-conformal-outlier-detection",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 5)",
    "section": "Methodology: Conformal Outlier Detection",
    "text": "Methodology: Conformal Outlier Detection\n\nSection 4.4의 방법을 적용합니다.\n\nHeuristic Model: BERT 기반의 유해성 점수 예측 모델 \\(f(x) \\in [0, 1]\\).\n\n\nCalibration: 정상 댓글(Non-toxic) \\(n\\)개에 대해 점수 \\(s_i = f(X_i)\\)를 계산하고 Quantile \\(\\hat{q}\\)를 구합니다.\n\n\nDetection: \\[ \\mathcal{C}(x) = \\begin{cases} \\text{Normal} & \\text{if } f(x) \\le \\hat{q} \\\\ \\text{Toxic (Outlier)} & \\text{if } f(x) &gt; \\hat{q} \\end{cases} \\]\n\n이 방식은 “이 댓글은 유해합니다”라고 경보를 울릴 때, 그 경보가 오작동일 확률을 수학적으로 보장해줍니다.\n\n\n\n\nFigure: 유해 댓글 탐지 예시 (\\(\\alpha=0.1\\)). 다국어 댓글에 대해 정상 댓글을 유해하다고 잘못 분류할 확률을 10%로 제한하면서, 실제 유해 댓글의 70%를 성공적으로 잡아냈다."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html#problem-setup-4",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html#problem-setup-4",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 5)",
    "section": "Problem Setup",
    "text": "Problem Setup\n\n모델이 확신할 수 없을 때는 “모르겠습니다(I don’t know)”라고 대답을 거부(Abstain)하는 시스템입니다.\n목표는 대답을 거부하지 않고 예측을 내놓았을 때의 정확도가 \\(\\ge 1-\\alpha\\)가 되도록 하는 것입니다.\n\nDataset: ImageNet\nGoal: Selective Accuracy \\(\\ge 90\\%\\)."
  },
  {
    "objectID": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html#methodology-learn-then-test",
    "href": "posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-05-Worked-Examples/index.html#methodology-learn-then-test",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 5)",
    "section": "Methodology: Learn then Test",
    "text": "Methodology: Learn then Test\n\n이 문제는 정확도(Accuracy)가 임계값 \\(\\lambda\\)에 따라 단조 증가(Monotone)하지 않을 수 있기 때문에, 표준 CRC 대신 Learn then Test (Appendix A 내용) 프레임워크를 사용합니다.\n\nRisk Definition: \\[ R(\\lambda) = \\mathbb{P}(\\text{Error} \\mid \\text{Confidence} \\ge \\lambda) \\]\n\n\n조건부 확률이므로 직접 제어하기 까다롭습니다.\n\n\nEmpirical Estimate & Upper Bound:\n\n\nCalibration Set에서 특정 신뢰도 \\(\\lambda\\) 이상인 샘플들의 에러율 \\(\\hat{R}(\\lambda)\\)를 계산합니다.\n이 에러율은 이항 분포(Binomial Distribution)를 따르므로, 클로퍼-피어슨(Clopper-Pearson) 구간 등을 이용해 에러율의 보수적 상한선(Upper Bound) \\(\\hat{R}^+(\\lambda)\\)을 구합니다.\n\n\nScan & Select: \\(\\hat{R}^+(\\lambda) \\le \\alpha\\)를 만족하는 가장 작은 \\(\\lambda\\)를 선택합니다.\n\n결과적으로 모델은 자신이 없으면 대답을 회피하고, 대답을 했을 때는 매우 높은 정확도를 보장하게 됩니다.\n\n\n\n\nFigure: ImageNet에 대한 Selective Classification 결과. (왼쪽) \\(\\lambda\\)가 커질수록(가로축), 예측을 수행하는 비율(주황색)은 줄어들지만, 정확도(파란색)는 올라간다. 점선은 목표 정확도 90%를 달성하는 지점을 나타낸다. (오른쪽) 모델이 예측한 예시(가오리)와 기권을 선택한 예시(여우)."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html",
    "title": "이론에서 현실로: 시뮬레이션을 통한 성능 검증",
    "section": "",
    "text": "이전 포스트에서는 개별 처치 효과(ITE)의 불확실성을 정량화하기 위해 예측 구간(Prediction Interval)을 생성해야 함을 역설했습니다. 하지만 여기에는 현실적인 장벽이 존재합니다. 우리가 가진 데이터는 ’처치를 받은 사람(\\(T=1\\))’의 결과뿐인데, 우리가 예측하고 싶은 대상은 ’전체 인구’이거나 ’처치를 받지 않은 사람’일 수 있기 때문입니다.\n이번 포스트에서는 이러한 분포의 불일치(Covariate Shift) 문제를 정의하고, 이를 가중 컨포멀 추론(Weighted Conformal Inference)을 통해 수학적으로 어떻게 보정하는지 단계별로 살펴보겠습니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#들어가며",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#들어가며",
    "title": "이론에서 현실로: 시뮬레이션을 통한 성능 검증",
    "section": "",
    "text": "이전 포스트에서는 개별 처치 효과(ITE)의 불확실성을 정량화하기 위해 예측 구간(Prediction Interval)을 생성해야 함을 역설했습니다. 하지만 여기에는 현실적인 장벽이 존재합니다. 우리가 가진 데이터는 ’처치를 받은 사람(\\(T=1\\))’의 결과뿐인데, 우리가 예측하고 싶은 대상은 ’전체 인구’이거나 ’처치를 받지 않은 사람’일 수 있기 때문입니다.\n이번 포스트에서는 이러한 분포의 불일치(Covariate Shift) 문제를 정의하고, 이를 가중 컨포멀 추론(Weighted Conformal Inference)을 통해 수학적으로 어떻게 보정하는지 단계별로 살펴보겠습니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#관측-데이터와-반사실-간의-괴리-counterfactuals-and-covariate-shift",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#관측-데이터와-반사실-간의-괴리-counterfactuals-and-covariate-shift",
    "title": "이론에서 현실로: 시뮬레이션을 통한 성능 검증",
    "section": "2 관측 데이터와 반사실 간의 괴리 (Counterfactuals and Covariate Shift)",
    "text": "2 관측 데이터와 반사실 간의 괴리 (Counterfactuals and Covariate Shift)\n\n2.1 문제의 본질: 훈련 데이터와 타겟 데이터의 불일치\n우리의 목표는 잠재적 결과 \\(Y(1)\\)과 \\(Y(0)\\)에 대한 예측 구간을 만드는 것입니다. [cite_start]이때 우리는 강한 무시 가능성(Strong Ignorability) 가정을 바탕으로 오직 관측된 데이터 \\((Y^{obs}, T, X)\\)만을 사용합니다[cite: 226].\n\n\\(Y(1)\\)의 구간을 추정하기 위해: 처치군 (\\(T=1\\)) 데이터만 사용 가능.\n\\(Y(0)\\)의 구간을 추정하기 위해: 대조군 (\\(T=0\\)) 데이터만 사용 가능.\n\n하지만 여기서 문제가 발생합니다. 데이터를 학습하는 분포와 예측을 적용하려는 타겟 분포가 서로 다릅니다. 이를 수식으로 표현해 보겠습니다.\n\n\n2.2 수학적 정의: Covariate Shift\n[cite_start]우리가 \\(Y(1)\\)을 학습할 때 사용하는 처치군 데이터의 결합 분포는 다음과 같습니다[cite: 234].\n\\[\nP_{Train} = P_{X|T=1} \\times P_{Y(1)|X}\n\\]\n[cite_start]하지만 우리가 결과를 일반화하여 적용하고 싶은 타겟 분포(예: 전체 인구)는 다음과 같습니다[cite: 236].\n\\[\nP_{Target} = Q_X \\times P_{Y(1)|X}\n\\]\n여기서 주목할 점은 조건부 결과 분포 \\(P_{Y(1)|X}\\)는 동일하다는 것입니다. 즉, \\(X\\)가 주어졌을 때 결과가 나오는 메커니즘(생물학적 반응 등)은 변하지 않습니다. 유일한 차이는 공변량 \\(X\\)의 분포(\\(P_{X|T=1}\\) vs \\(Q_X\\))에 있습니다.\n[cite_start]이러한 현상을 머신러닝에서는 공변량 변화(Covariate Shift)라고 부릅니다[cite: 237].\n![Image: covariate_shift_diagram.png] Figure 1: Covariate Shift의 개념도. 학습 데이터(Treated)는 특정 영역(예: 고연령층)에 치우쳐 있을 수 있지만, 타겟(Target)은 전체 인구를 포함한다. 회귀 곡선(조건부 평균)은 같더라도 데이터 밀도가 달라 예측 구간 보정이 필요하다.\n일반적인 머신러닝 방법론들은 훈련 데이터와 테스트 데이터의 분포가 같다고 가정(\\(P_{Train} = P_{Target}\\))하기 때문에, 이 상황에서 그대로 적용하면 잘못된 커버리지(Coverage)를 산출하게 됩니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#해결책-가중-컨포멀-추론-weighted-conformal-inference",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#해결책-가중-컨포멀-추론-weighted-conformal-inference",
    "title": "이론에서 현실로: 시뮬레이션을 통한 성능 검증",
    "section": "3 해결책: 가중 컨포멀 추론 (Weighted Conformal Inference)",
    "text": "3 해결책: 가중 컨포멀 추론 (Weighted Conformal Inference)\n[cite_start]이 문제를 해결하기 위해 논문은 Tibshirani et al.(2019b)이 제안한 가중 컨포멀 추론을 도입합니다[cite: 238].\n\n3.1 표준 컨포멀 추론의 한계\n[cite_start]표준적인 컨포멀 추론(Standard Conformal Inference)은 데이터가 i.i.d.일 때, 임의의 예측 모델(예: Quantile Regression)의 잔차(Residual)를 보정하여 다음을 만족하는 구간 \\(\\hat{C}(X)\\)를 생성합니다[cite: 243].\n\\[\n\\mathbb{P}_{(X,Y) \\sim P_X \\times P_{Y|X}}(Y \\in \\hat{C}(X)) \\ge 1 - \\alpha\n\\]\n[cite_start]보통 Conformal Quantile Regression (CQR)을 사용하여 다음과 같은 형태의 구간을 만듭니다[cite: 247].\n\\[\n\\hat{C}(x) = [\\hat{q}_{\\alpha_{lo}}(x) - \\eta, \\hat{q}_{\\alpha_{hi}}(x) + \\eta]\n\\]\n여기서 \\(\\eta\\)는 보정 상수입니다. 하지만 분포가 다를 경우(\\(P_{Train} \\neq P_{Target}\\)), 이 단순한 보정은 실패합니다.\n\n\n3.2 가중치(Likelihood Ratio)의 도입\n[cite_start]우리는 타겟 분포 \\(Q_X\\) 하에서의 커버리지를 보장해야 합니다[cite: 252]. [cite_start]이를 위해 두 분포 사이의 비율인 우도비(Likelihood Ratio)를 가중치로 사용합니다[cite: 255].\n\\[\nw(x) = \\frac{dQ_X(x)}{dP_{X|T=1}(x)}\n\\]\n이 가중치 \\(w(x)\\)는 “타겟 분포에서 \\(x\\)가 관측될 확률이 학습 분포에 비해 얼마나 높은가”를 나타냅니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#알고리즘-상세-weighted-split-cqr",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#알고리즘-상세-weighted-split-cqr",
    "title": "이론에서 현실로: 시뮬레이션을 통한 성능 검증",
    "section": "4 알고리즘 상세: Weighted Split-CQR",
    "text": "4 알고리즘 상세: Weighted Split-CQR\n[cite_start]논문에서 제안하는 Algorithm 1 (Weighted split-CQR)의 작동 원리를 단계별로 분석해 보겠습니다[cite: 262].\n\n4.1 Step 1: 데이터 분할 (Data Splitting)\n전체 데이터를 훈련 집합(Training fold, \\(\\mathcal{Z}_{tr}\\))과 캘리브레이션 집합(Calibration fold, \\(\\mathcal{Z}_{ca}\\))으로 나눕니다. * 훈련 집합: 분위수 회귀 모델 \\(\\hat{q}(\\cdot)\\)와 가중치 함수 \\(\\hat{w}(\\cdot)\\)를 학습하는 데 사용합니다. * 캘리브레이션 집합: 모델의 예측 오차를 측정하여 구간을 보정하는 데 사용합니다.\n\n\n4.2 Step 2: 비적합 점수 계산 (Non-conformity Scores)\n캘리브레이션 데이터 \\(i \\in \\mathcal{I}_{ca}\\)에 대해, 실제 값 \\(Y_i\\)가 예측된 구간 \\([\\hat{q}_{\\alpha_{lo}}, \\hat{q}_{\\alpha_{hi}}]\\) 밖으로 얼마나 벗어났는지 점수(\\(V_i\\))를 계산합니다.\n\\[\nV_i = \\max \\{ \\hat{q}_{\\alpha_{lo}}(X_i) - Y_i, \\quad Y_i - \\hat{q}_{\\alpha_{hi}}(X_i) \\}\n\\]\n\n\\(V_i &gt; 0\\): 실제 값이 예측 구간 밖에 있음 (오차 발생).\n\\(V_i \\le 0\\): 실제 값이 예측 구간 안에 있음.\n\n\n\n4.3 Step 3: 가중치 계산 (Weight Computation)\n캘리브레이션 데이터 각각에 대해 가중치를 계산합니다.\n\\[\nW_i = \\hat{w}(X_i)\n\\]\n\n\n4.4 Step 4: 정규화된 확률 계산 (Normalized Probabilities) [핵심]\n새로운 데이터 포인트(Test point) \\(x\\)가 주어졌을 때, 이 점에서의 예측 구간을 구하기 위해 가중치를 정규화합니다. 이때 테스트 포인트의 가중치 \\(\\hat{w}(x)\\)도 함께 고려합니다.\n\\[\n\\hat{p}_i(x) = \\frac{W_i}{\\sum_{j \\in \\mathcal{I}_{ca}} W_j + \\hat{w}(x)}, \\quad \\forall i \\in \\mathcal{I}_{ca}\n\\]\n\\[\n\\hat{p}_{\\infty}(x) = \\frac{\\hat{w}(x)}{\\sum_{j \\in \\mathcal{I}_{ca}} W_j + \\hat{w}(x)}\n\\]\n\n의미: 만약 테스트 포인트 \\(x\\)가 타겟 분포에서 아주 희귀한 값이라면(\\(\\hat{w}(x) \\approx 0\\)), \\(\\hat{p}_\\infty(x)\\)는 작아지고 기존 캘리브레이션 데이터들의 영향력이 커집니다. 반대라면 테스트 포인트 자체의 불확실성이 크게 반영됩니다.\n\n\n\n4.5 Step 5: 가중 분위수 계산 (Weighted Quantile)\n다음과 같은 이산 분포(Discrete Distribution)를 구성하고, 이 분포의 \\((1-\\alpha)\\) 분위수를 찾아 보정값 \\(\\eta(x)\\)로 설정합니다.\n\\[\n\\sum_{i \\in \\mathcal{I}_{ca}} \\hat{p}_i(x) \\delta_{V_i} + \\hat{p}_{\\infty}(x) \\delta_{\\infty}\n\\]\n여기서 \\(\\delta\\)는 디랙 델타 함수입니다. 즉, 가중치 \\(\\hat{p}_i(x)\\)를 반영하여 에러 점수 \\(V_i\\)들을 줄 세운 뒤, 상위 \\((1-\\alpha)\\) 지점에 해당하는 에러 값을 찾는 과정입니다.\n\n\n4.6 최종 출력\n구해진 \\(\\eta(x)\\)를 이용하여 최종 예측 구간을 생성합니다.\n\\[\n\\hat{C}(x) = [\\hat{q}_{\\alpha_{lo}}(x) - \\eta(x), \\quad \\hat{q}_{\\alpha_{hi}}(x) + \\eta(x)]\n\\]\n![Image: weighted_cqr_process.png] Figure 2: Weighted Split-CQR 프로세스. 캘리브레이션 데이터의 에러(Score)들에 가중치를 부여하여 히스토그램을 그리고, 타겟 커버리지(1-alpha)를 만족하는 지점(Quantile)을 동적으로 결정한다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#이론적-보장-theoretical-guarantee",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#이론적-보장-theoretical-guarantee",
    "title": "이론에서 현실로: 시뮬레이션을 통한 성능 검증",
    "section": "5 이론적 보장 (Theoretical Guarantee)",
    "text": "5 이론적 보장 (Theoretical Guarantee)\n[cite_start]이 알고리즘은 강력한 이론적 성질을 가집니다 (Proposition 1)[cite: 268].\n\n가중치를 정확히 아는 경우 (\\(\\hat{w} = w\\)): 데이터 분포에 대한 어떠한 가정 없이도, 유한한 샘플에서 타겟 분포에 대한 커버리지(Equation 10)를 완벽하게 보장합니다. \\[\\mathbb{P}_{(X,Y) \\sim Q_X \\times P_{Y|X}}(Y \\in \\hat{C}(X)) \\ge 1 - \\alpha\\]\n가중치를 추정해야 하는 경우 (\\(\\hat{w} \\neq w\\)): [cite_start]가중치 추정에 오차가 있더라도, 그 오차(\\(\\Delta_w\\))만큼만 커버리지가 벗어납니다[cite: 274]. \\[\\text{Coverage} \\ge 1 - \\alpha - \\Delta_w\\] 이는 이 방법론이 가중치 추정의 정확도에 의존하지만, 어느 정도의 오차는 허용하는 강건함(Robustness)을 가짐을 의미합니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#요약",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#요약",
    "title": "이론에서 현실로: 시뮬레이션을 통한 성능 검증",
    "section": "6 요약",
    "text": "6 요약\n이번 섹션에서는 인과추론에서 피할 수 없는 공변량 변화(Covariate Shift) 문제를 해결하기 위해 가중 컨포멀 추론을 사용하는 방법을 다루었습니다.\n\n우리는 \\(P_{Train}\\)에서 학습하지만 \\(P_{Target}\\)을 예측해야 합니다.\n두 분포의 비율(\\(w(x)\\))을 이용하여 캘리브레이션 데이터의 에러 분포를 재조정(Reweighting)합니다.\n이 방식은 모델이 완벽하지 않아도, 수학적으로 타겟 분포에 대한 유효한 예측 구간을 보장해 줍니다.\n\n다음 단계에서는 이 가중치 \\(w(x)\\)가 인과추론의 성향 점수(Propensity Score)와 어떻게 연결되는지 구체적으로 살펴보게 될 것입니다.\n\nReference: Lei, L., & Candès, E. J. (2021). Conformal inference of counterfactuals and individual treatment effects. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 83(5), 911-938."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#들어가며-1",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#들어가며-1",
    "title": "이론에서 현실로: 시뮬레이션을 통한 성능 검증",
    "section": "7 들어가며",
    "text": "7 들어가며\n이전 포스트에서는 공변량 변화(Covariate Shift)를 해결하기 위해 가중 컨포멀 추론(Weighted Conformal Inference)을 도입했습니다. 핵심은 학습 분포와 타겟 분포의 비율인 가중치 \\(w(x)\\)를 어떻게 설정하느냐였습니다.\n이번 포스트에서는 인과추론의 꽃이라 불리는 성향 점수(Propensity Score)가 이 가중치와 어떻게 수학적으로 연결되는지 살펴보고, 이 방법론이 가진 두 가지 강력한 성질인 완전성(Exactness)과 이중 강건성(Double Robustness)에 대해 알아보겠습니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#성향-점수propensity-score의-역할",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#성향-점수propensity-score의-역할",
    "title": "이론에서 현실로: 시뮬레이션을 통한 성능 검증",
    "section": "8 성향 점수(Propensity Score)의 역할",
    "text": "8 성향 점수(Propensity Score)의 역할\n\n8.1 성향 점수와 IPW의 관계\nRosenbaum & Rubin(1983)이 제안한 성향 점수 \\(e(x)\\)는 공변량이 주어졌을 때 처치를 받을 확률로 정의됩니다.\n\\[\ne(x) = \\mathbb{P}(T=1 | X=x)\n\\]\n전통적인 인과추론에서 평균 처치 효과(ATE)를 추정할 때 사용하는 역성향 점수 가중법(IPW, Inverse Propensity Weighting)은 다음과 같은 가중치를 사용합니다.\n\n처치군 (\\(T=1\\)): \\(w_1(x) = \\frac{1}{e(x)}\\)\n대조군 (\\(T=0\\)): \\(w_0(x) = \\frac{1}{1-e(x)}\\)\n\n\n\n8.2 가중 컨포멀 추론에서의 유도 과정\n놀랍게도, 가중 컨포멀 추론에서 필요한 공변량 변화 비율(Likelihood Ratio)은 IPW 가중치와 정확히 일치합니다. 이를 수학적으로 유도해 보겠습니다.\n우리가 \\(Y(1)\\)에 대한 ATE 타입의 구간을 구한다고 가정합시다. * Target Distribution: 전체 모집단 (\\(P_X\\)) * Sampling Distribution: 처치군 (\\(P_{X|T=1}\\))\n베이즈 정리(Bayes’ Formula)를 적용하면 가중치 \\(w_1(x)\\)는 다음과 같습니다.\n\\[\n\\begin{align}\nw_1(x) &= \\frac{dP_X(x)}{dP_{X|T=1}(x)} \\\\\n       &= \\frac{dP_X(x)}{\\frac{P(T=1|X=x)dP_X(x)}{P(T=1)}} \\\\\n       &= \\frac{P(T=1)}{e(x)}\n\\end{align}\n\\]\n여기서 \\(P(T=1)\\)은 상수입니다. 가중 컨포멀 추론 알고리즘은 가중치의 상수배(Rescaling)에 불변(Invariant)하므로, 분자를 무시하면 다음과 같이 귀결됩니다.\n\\[\nw_1(x) \\propto \\frac{1}{e(x)}\n\\]\n즉, 가중 컨포멀 추론은 본질적으로 IPW 추정 방식과 동일한 가중치 체계를 공유합니다.\n\n\n8.3 다양한 추론 목표에 따른 가중치 요약\n논문에서는 ATE뿐만 아니라 ATT(처치군 대상 효과), ATC(대조군 대상 효과), 그리고 일반화(Generalizability) 상황까지 아우르는 가중치 표를 제시합니다.\n\n\n\n\n\n\n\n\n추론 목표 (Inferential Target)\n\\(w_1(x)\\) (for \\(Y(1)\\))\n\\(w_0(x)\\) (for \\(Y(0)\\))\n\n\n\n\nATE (전체 평균)\n\\(1/e(x)\\)\n\\(1/(1-e(x))\\)\n\n\nATT (처치군 평균)\n\\(1\\) (가중치 불필요)\n\\(e(x)/(1-e(x))\\)\n\n\nATC (대조군 평균)\n\\((1-e(x))/e(x)\\)\n\\(1\\)\n\n\nGeneral (외부 타겟 \\(Q\\))\n\\(\\frac{dQ}{dP}(x) \\cdot \\frac{1}{e(x)}\\)\n\\(\\frac{dQ}{dP}(x) \\cdot \\frac{1}{1-e(x)}\\)\n\n\n\nTable 1: 다양한 인과추론 목표에 따른 가중치 함수 요약. IPW 추정량에서 쓰이는 가중치와 정확히 일치한다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#무작위-대조군-연구rct에서의-완전성-exactness",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#무작위-대조군-연구rct에서의-완전성-exactness",
    "title": "이론에서 현실로: 시뮬레이션을 통한 성능 검증",
    "section": "9 무작위 대조군 연구(RCT)에서의 완전성 (Exactness)",
    "text": "9 무작위 대조군 연구(RCT)에서의 완전성 (Exactness)\n\n9.1 완전한 성향 점수, 완전한 커버리지\n무작위 대조군 연구(Randomized Controlled Trials, RCT)에서는 연구자가 처치 확률을 설계하므로 성향 점수 \\(e(x)\\)를 정확히 알고 있습니다.\n\n완전 무작위 배정(Completely Randomized): \\(e(x) = 0.5\\) (상수). 가중치가 일정하므로 일반적인(Unweighted) 컨포멀 추론을 사용해도 됩니다.\n층화 무작위 배정(Stratified Randomized): \\(e(x)\\)가 공변량(예: 연령, 성별)에 따라 다르지만, 그 값은 정확히 알고 있습니다.\n\n이 경우, 가중 컨포멀 추론은 유한한 샘플(Finite Samples)에서도 정확한(Exact) 커버리지를 보장합니다.\n\\[\n\\mathbb{P}(Y(1) \\in \\hat{C}(X)) \\ge 1 - \\alpha\n\\]\n이 보장은 결과 모델(Conditional Quantile Model)을 얼마나 엉터리로 만들었는지와 상관없이 성립합니다.\n\n\n9.2 겹침 조건(Overlap Condition) 위반에 대한 강건성\nIPW와 같은 점 추정 방식은 \\(e(x) \\approx 0\\) 또는 \\(1\\)인 경우(Overlap이 부족한 경우) 가중치가 무한대로 발산하여 추정량이 매우 불안정해집니다.\n하지만 컨포멀 추론은 이 상황에서 매우 직관적이고 안전하게 반응합니다. 가중치가 무한대로 가면 구간의 길이도 무한대로 늘어납니다 (\\(\\hat{C}(x) = (-\\infty, \\infty)\\)). * 의미: “이 영역에는 데이터가 없어 정보를 알 수 없으므로, 구간을 무한히 넓게 잡겠다.” * 결과: 정보는 없지만, 여전히 정답을 포함할 확률(\\(1-\\alpha\\))은 수학적으로 지켜집니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#관찰-연구에서의-이중-강건성-double-robustness",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#관찰-연구에서의-이중-강건성-double-robustness",
    "title": "이론에서 현실로: 시뮬레이션을 통한 성능 검증",
    "section": "10 관찰 연구에서의 이중 강건성 (Double Robustness)",
    "text": "10 관찰 연구에서의 이중 강건성 (Double Robustness)\n관찰 연구(Observational Study)에서는 성향 점수 \\(e(x)\\)를 모르기 때문에 데이터로부터 추정해야 합니다(\\(\\hat{e}(x)\\)). 이때 발생하는 불확실성을 가중 컨포멀 추론은 어떻게 처리할까요?\n이 방법론은 이중 강건성(Doubly Robust Property)을 가집니다. 즉, 다음 두 가지 조건 중 하나만 만족해도 근사적으로(Approximately) 올바른 커버리지를 보장합니다.\n\n성향 점수 모델이 정확할 때 (\\(\\hat{e}(x) \\approx e(x)\\))\n결과 모델(Quantile)이 정확할 때 (\\(\\hat{q}(x) \\approx q(x)\\))\n\n\n10.1 직관적 증명 (Intuitive Justification)\nCase 1: 성향 점수 모델이 정확함 (\\(\\hat{e} \\approx e\\)) 이 경우, 우리가 계산한 가중치가 참(Oracle) 가중치와 거의 같아집니다. 따라서 결과 모델 \\(\\hat{q}(x)\\)가 아무리 부정확하더라도, 가중 컨포멀 추론의 기본 원리에 의해 커버리지가 보장됩니다.\nCase 2: 결과 모델이 정확함 (\\(\\hat{q} \\approx q\\)) 이 부분이 흥미롭습니다. 성향 점수(가중치)가 틀렸더라도, 결과 모델이 정확하다면 어떻게 될까요? 참 조건부 분위수 \\(q_{\\beta}(x)\\)를 정확히 추정했다면, 비적합 점수(Non-conformity score) \\(V_i\\)의 분포가 다음과 같이 됩니다.\n\\[\n\\begin{align}\nV_i &\\approx \\max \\{ q_{\\alpha_{lo}}(X_i) - Y_i, \\ Y_i - q_{\\alpha_{hi}}(X_i) \\} \\\\\n\\mathbb{P}(V_i \\le 0 | X_i) &\\approx \\mathbb{P}(Y_i \\in [q_{\\alpha_{lo}}, q_{\\alpha_{hi}}]) = 1 - \\alpha\n\\end{align}\n\\]\n즉, \\(0\\)이라는 값이 점수 분포의 \\((1-\\alpha)\\) 분위수가 됩니다. 따라서 알고리즘이 계산하는 보정값 \\(\\eta(x)\\)는 \\(0\\)에 가까워지며, 최종 구간은 참 분위수 구간으로 수렴하게 되어 커버리지를 만족합니다.\n![Image: double_robustness_diagram.png] Figure 1: 이중 강건성의 개념도. x축은 성향 점수 모델의 오차, y축은 결과 모델의 오차를 나타낸다. 두 축 중 하나만 0에 가까우면(L자 형태), 전체 커버리지 에러는 낮게 유지된다.\n\n\n10.2 Theorem 1: 수학적 보장\n논문의 정리 1(Theorem 1)은 이를 공식화합니다. 샘플 사이즈 \\(N, n \\to \\infty\\) 일 때, 다음 조건 중 하나가 성립하면: 1. \\(\\hat{e}_N(X) \\to e(X)\\) (성향 점수 일치) 2. \\(\\hat{q}_{\\beta, N}(X) \\to q_{\\beta}(X)\\) (분위수 일치)\n다음과 같은 커버리지를 보장합니다.\n\\[\n\\lim_{N,n \\to \\infty} \\mathbb{P}(Y(1) \\in \\hat{C}_{N,n}(X)) \\ge 1 - \\alpha\n\\]\n또한, 조건 2(결과 모델 정확)가 만족될 경우에는 평균 커버리지뿐만 아니라 조건부 커버리지(Conditional Coverage)까지 근사적으로 보장됨을 보일 수 있습니다.\n\\[\n\\lim_{N,n \\to \\infty} \\mathbb{P}(\\text{Coverage Error} | X) = 0\n\\]"
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#요약-1",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#요약-1",
    "title": "이론에서 현실로: 시뮬레이션을 통한 성능 검증",
    "section": "11 요약",
    "text": "11 요약\n이번 섹션의 핵심은 “가중치(Weighting)”와 “강건성(Robustness)”입니다.\n\n가중 컨포멀 추론의 가중치는 IPW의 성향 점수 가중치와 본질적으로 같습니다.\n성향 점수를 아는 RCT에서는 유한 표본에서도 완벽한 커버리지를 제공합니다.\n성향 점수를 모르는 관찰 연구에서는 성향 점수 모델 혹은 결과 예측 모델 중 하나만 잘 맞으면 커버리지가 보장되는 이중 강건성을 가집니다.\n\n이는 점 추정(Point Estimation)에서의 이중 강건성(일치성 보장) 개념을 구간 추정(Interval Estimation, 커버리지 보장)으로 성공적으로 확장한 사례라 할 수 있습니다.\n\nReference: Lei, L., & Candès, E. J. (2021). Conformal inference of counterfactuals and individual treatment effects. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 83(5), 911-938."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#들어가며-2",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#들어가며-2",
    "title": "이론에서 현실로: 시뮬레이션을 통한 성능 검증",
    "section": "12 들어가며",
    "text": "12 들어가며\n지금까지 우리는 이론적으로 개별 처치 효과(ITE)의 구간을 추정하는 방법과 그에 따른 성질(이중 강건성 등)을 살펴보았습니다. 이번 포스트에서는 “그래서 실제로 잘 작동하는가?”라는 질문에 답하기 위해 수행된 수치 실험(Numerical Experiments) 결과를 상세히 뜯어보겠습니다.\n저자들은 Causal Forest, X-learner, BART 등 현존하는 강력한 방법론들과 자신들의 Weighted Split-CQR을 비교하며, 특히 데이터가 복잡할 때(고차원, 상관관계 존재, 이분산성) 어떤 차이가 발생하는지 집중 조명합니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#실험-설계-experimental-setup",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#실험-설계-experimental-setup",
    "title": "이론에서 현실로: 시뮬레이션을 통한 성능 검증",
    "section": "13 실험 설계 (Experimental Setup)",
    "text": "13 실험 설계 (Experimental Setup)\n실험은 Wager and Athey (2018)의 설정을 변형하여 진행되었습니다. 데이터 생성 과정(Data Generating Process)을 수학적으로 정의해 보겠습니다.\n\n13.1 데이터 생성 메커니즘\n\n공변량 (Covariates) \\(X\\): \\(d\\)차원의 벡터 \\(X = (X_1, \\dots, X_d)^T\\)는 다음과 같이 생성됩니다.\n\\[\nX_j = \\Phi(X'_j)\n\\]\n여기서 \\(\\Phi\\)는 표준 정규분포의 누적 분포 함수(CDF)이며, \\(X'\\)는 평균이 0이고 분산이 1인 다변량 가우시안 분포를 따릅니다. 공변량 간의 상관계수는 \\(\\text{Cov}(X'_j, X'_{j'}) = \\rho\\) 입니다.\n잠재적 결과 (Potential Outcomes): 문제의 단순화를 위해, 처치를 받지 않았을 때의 결과 \\(Y(0)\\)는 0으로 고정합니다.\n\\[\nY(0) \\equiv 0\n\\]\n처치를 받았을 때의 결과 \\(Y(1)\\)은 다음과 같이 구성됩니다.\n\\[\n\\mathbb{E}[Y(1)|X] = f(X_1)f(X_2), \\quad \\text{where } f(x) = \\frac{2}{1 + \\exp\\{-12(x-0.5)\\}}\n\\]\n\\[\nY(1) = \\mathbb{E}[Y(1)|X] + \\sigma(X)\\epsilon, \\quad \\epsilon \\sim N(0, 1)\n\\]\n성향 점수 (Propensity Score): 충분한 겹침(Overlap)을 보장하기 위해 다음과 같이 설정합니다.\n\\[\ne(x) = \\frac{1}{4} (1 + \\beta_{2,4}(X_1))\n\\]\n여기서 \\(\\beta_{2,4}\\)는 베타 분포(2, 4)의 CDF입니다. 이 설정은 \\(e(x) \\in [0.25, 0.5]\\) 범위를 보장합니다.\n\n\n\n13.2 8가지 시나리오 (Scenarios)\n데이터의 복잡성에 따른 성능 변화를 보기 위해 총 \\(2 \\times 2 \\times 2 = 8\\)가지 시나리오를 구성했습니다.\n\n차원 (Dimension): 저차원 (\\(d=10\\)) vs 고차원 (\\(d=100\\))\n상관관계 (Correlation): 독립 (\\(\\rho=0\\)) vs 상관 (\\(\\rho=0.9\\))\n오차 분산 (Errors): 등분산 (\\(\\sigma^2(x)=1\\)) vs 이분산 (\\(\\sigma^2(x) = -\\log X_1\\))\n\n특히 이분산(Heteroscedasticity) 설정이 중요합니다. \\(X_1\\)이 0에 가까울수록 분산이 무한대로 커지기 때문에, 불확실성 추정이 매우 까다로워집니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#비교-방법론-competitors",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#비교-방법론-competitors",
    "title": "이론에서 현실로: 시뮬레이션을 통한 성능 검증",
    "section": "14 비교 방법론 (Competitors)",
    "text": "14 비교 방법론 (Competitors)\n본 실험에서는 다음 방법론들의 95% 구간 추정 성능을 비교합니다.\n\nCausal Forest (CF): grf 패키지 사용. CATE의 분산을 추정하지만 ITE용은 아님.\nX-learner: causalToolbox 패키지 사용. 부트스트랩 기반 CATE 분산 추정. 역시 ITE용은 아님.\nBART (Bayesian Additive Regression Trees): bartMachine 패키지. 베이지안 신용 구간(Credible Interval) 및 예측 구간(Prediction Interval) 생성 가능. 가장 강력한 경쟁자.\nWeighted Split-CQR (제안 방법): 기본 학습기(Learner)로 다음 3가지를 각각 사용.\n\nQuantile Random Forest (CQR-RF)\nQuantile Gradient Boosting (CQR-Boosting)\nBART (CQR-BART)"
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#결과-분석-1-커버리지-성능-coverage-performance",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#결과-분석-1-커버리지-성능-coverage-performance",
    "title": "이론에서 현실로: 시뮬레이션을 통한 성능 검증",
    "section": "15 결과 분석 1: 커버리지 성능 (Coverage Performance)",
    "text": "15 결과 분석 1: 커버리지 성능 (Coverage Performance)\n가장 중요한 지표는 “생성된 구간이 실제 값을 95% 확률로 포함하는가?”입니다.\n\n15.1 이론적 보장과 실제 (Table 2)\n먼저 각 방법론이 이론적으로 무엇을 보장하는지 살펴봅시다.\n Table 2: 이론적(위) 및 시뮬레이션(아래)에서의 커버리지 보장 요약. CF와 X-learner는 애초에 ITE 커버리지를 보장하지 않으며, 오직 CQR만이 모든 상황에서 ITE 커버리지를 달성함.\n\n\n15.2 CATE 커버리지 (Figure 1)\nCATE(조건부 평균)에 대한 커버리지를 먼저 봅니다.\n Figure 1: CATE에 대한 95% 커버리지 결과. 빨간 수직선(1.00 근처)이 목표치. CF와 X-learner는 고차원/이분산 상황에서 성능이 크게 떨어짐. 반면 CQR은 다소 보수적(과도한 커버리지)이지만 목표치를 항상 상회함.\n\nCF, X-learner: 모든 시나리오에서 낮은 커버리지를 보이며, 고차원(\\(d=100\\))에서 더 악화됩니다.\nCQR: CATE를 직접 타겟팅하지 않음에도 불구하고(ITE를 타겟팅하므로 구간이 더 넓음), 모든 시나리오에서 안전한 커버리지를 보여줍니다.\n\n\n\n15.3 ITE 커버리지 (Figure 2) - 핵심 결과\n논문의 진짜 목표인 개별 처치 효과(ITE)에 대한 커버리지입니다.\n Figure 2: ITE에 대한 95% 커버리지 결과. 이것이 이 논문의 핵심이다. CQR 계열(상단 3개)만이 모든 시나리오(특히 맨 오른쪽의 이분산+상관관계)에서 95% 선을 지킨다.\n\nCF, X-learner: ITE를 커버하도록 설계되지 않았으므로 당연히 실패합니다. (CATE 구간을 ITE 구간으로 오해해서는 안 된다는 것을 보여줍니다.)\nBART: 등분산(Homoscedastic) 상황에서는 완벽합니다. 하지만 이분산 + 상관관계(Heteroscedastic + Corr.) 상황에서는 커버리지가 무너집니다.\nCQR: 어떤 기본 학습기를 쓰든, 차원/상관관계/분산 구조에 상관없이 거의 정확한 95% 커버리지를 달성합니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#결과-분석-2-구간의-길이-interval-length",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#결과-분석-2-구간의-길이-interval-length",
    "title": "이론에서 현실로: 시뮬레이션을 통한 성능 검증",
    "section": "16 결과 분석 2: 구간의 길이 (Interval Length)",
    "text": "16 결과 분석 2: 구간의 길이 (Interval Length)\n커버리지가 높다고 무조건 좋은 것은 아닙니다. 구간이 \\((-\\infty, \\infty)\\)라면 커버리지는 100%겠지만 쓸모가 없으니까요. 구간은 짧을수록 좋습니다.\n Figure 3: ITE 구간의 평균 길이. 파란 수직선은 Oracle(이상적인) 길이. CQR-BART가 BART와 거의 유사한 길이를 보이면서도 더 나은 커버리지를 제공함을 알 수 있다.\n\nCF, X-learner: 구간이 매우 짧습니다. 그래서 커버리지(Figure 2)가 망가진 것입니다.\nBART: 등분산 상황에서 가장 효율적(짧은) 구간을 만듭니다.\nCQR-BART: BART를 기본 학습기로 사용한 CQR은 순수 BART와 거의 비슷한 구간 길이를 가집니다. 즉, “정보의 손실 없이(길이 유지) 정확성(커버리지)만 보정했다”는 뜻입니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#결과-분석-3-조건부-커버리지-conditional-coverage",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#결과-분석-3-조건부-커버리지-conditional-coverage",
    "title": "이론에서 현실로: 시뮬레이션을 통한 성능 검증",
    "section": "17 결과 분석 3: 조건부 커버리지 (Conditional Coverage)",
    "text": "17 결과 분석 3: 조건부 커버리지 (Conditional Coverage)\n마지막으로, 데이터의 특성(여기서는 분산의 크기)에 따라 커버리지가 어떻게 변하는지 확인합니다. 이상적으로는 분산이 크든 작든 일정한 커버리지를 유지해야 합니다.\n Figure 4: 조건부 분산(x축)에 따른 ITE 커버리지(y축) 변화. x축의 오른쪽으로 갈수록 노이즈가 심한 데이터이다. BART(가운데)는 노이즈가 커지면 커버리지가 급격히 떨어지지만, CQR(오른쪽)은 이를 잘 방어하고 있다.\n\n상황: \\(d=10\\), 이분산 설정. \\(x_1\\) 값에 따라 분산이 변함.\nBART: 분산이 큰 영역(그래프의 오른쪽)으로 갈수록 커버리지가 급격히 하락합니다.\nCQR-RF/Boosting: 분산의 크기와 관계없이 95% 수준을 견고하게 유지합니다. 이것이 바로 Conformal Inference의 적응력(Adaptability)입니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#결론-및-요약",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/index.html#결론-및-요약",
    "title": "이론에서 현실로: 시뮬레이션을 통한 성능 검증",
    "section": "18 결론 및 요약",
    "text": "18 결론 및 요약\nSection 3.6의 실험 결과는 다음과 같이 요약할 수 있습니다.\n\nCATE 추정기 \\(\\neq\\) ITE 구간 추정기: Causal Forest나 X-learner 같은 CATE 전용 방법론을 ITE 불확실성 추정에 그대로 사용하면 위험합니다.\nBART의 한계: BART는 강력하지만, 데이터가 복잡하고(상관관계 존재) 노이즈가 불균일할 때(이분산) 신뢰성을 잃을 수 있습니다.\nWeighted Split-CQR의 승리:\n\n강건성 (Robustness): 어떤 시나리오에서도 목표 커버리지(95%)를 지켰습니다.\n효율성 (Efficiency): 구간의 길이를 불필요하게 늘리지 않으면서도 정확도를 확보했습니다.\n유연성 (Flexibility): RF, Boosting, BART 등 어떤 알고리즘 위에 얹어도 성능을 향상시킵니다.\n\n\n이로써 이 논문이 제안한 방법론이 이론적으로만 아름다운 것이 아니라, 실전 데이터 분석에서도 매우 강력한 도구가 될 수 있음이 증명되었습니다.\n\nReference: Lei, L., & Candès, E. J. (2021). Conformal inference of counterfactuals and individual treatment effects. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 83(5), 911-938."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/05-From potential outcomes to other causal frameworks/index.html",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/05-From potential outcomes to other causal frameworks/index.html",
    "title": "세계관의 확장: 다른 인과추론 프레임워크로의 연결",
    "section": "",
    "text": "지금까지 우리는 잠재적 결과(Potential Outcome) 프레임워크 (Rubin’s Causal Model) 하에서 개별 처치 효과(ITE)의 구간을 추정하는 방법을 논의했습니다. 핵심은 가중 컨포멀 추론(Weighted Conformal Inference)을 이용해, 관측 데이터(학습 분포)와 우리가 추론하고자 하는 반사실/타겟 데이터(타겟 분포) 사이의 공변량 변화(Covariate Shift)를 보정하는 것이었습니다.\n이 논문의 마지막 섹션(Section 5)에서는 매우 흥미로운 통찰을 제시합니다. 우리가 개발한 이 방법론이 단순히 잠재적 결과 프레임워크에만 국한되지 않는다는 것입니다.\n핵심 통찰 (Key Observation): &gt; “조건부 분포의 불변성(Invariance of Conditional Distribution)과 공변량 변화(Covariate Shift)라는 구조만 동일하다면, 어떤 인과추론 프레임워크에도 이 방법론을 적용할 수 있다.”\n이번 포스트에서는 이 통찰이 Judea Pearl의 인과 다이어그램과 Peters의 불변 예측 프레임워크로 어떻게 확장되는지 수학적으로 살펴보겠습니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/05-From potential outcomes to other causal frameworks/index.html#들어가며",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/05-From potential outcomes to other causal frameworks/index.html#들어가며",
    "title": "세계관의 확장: 다른 인과추론 프레임워크로의 연결",
    "section": "",
    "text": "지금까지 우리는 잠재적 결과(Potential Outcome) 프레임워크 (Rubin’s Causal Model) 하에서 개별 처치 효과(ITE)의 구간을 추정하는 방법을 논의했습니다. 핵심은 가중 컨포멀 추론(Weighted Conformal Inference)을 이용해, 관측 데이터(학습 분포)와 우리가 추론하고자 하는 반사실/타겟 데이터(타겟 분포) 사이의 공변량 변화(Covariate Shift)를 보정하는 것이었습니다.\n이 논문의 마지막 섹션(Section 5)에서는 매우 흥미로운 통찰을 제시합니다. 우리가 개발한 이 방법론이 단순히 잠재적 결과 프레임워크에만 국한되지 않는다는 것입니다.\n핵심 통찰 (Key Observation): &gt; “조건부 분포의 불변성(Invariance of Conditional Distribution)과 공변량 변화(Covariate Shift)라는 구조만 동일하다면, 어떤 인과추론 프레임워크에도 이 방법론을 적용할 수 있다.”\n이번 포스트에서는 이 통찰이 Judea Pearl의 인과 다이어그램과 Peters의 불변 예측 프레임워크로 어떻게 확장되는지 수학적으로 살펴보겠습니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/05-From potential outcomes to other causal frameworks/index.html#인과-다이어그램-프레임워크-causal-diagram-framework",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/05-From potential outcomes to other causal frameworks/index.html#인과-다이어그램-프레임워크-causal-diagram-framework",
    "title": "세계관의 확장: 다른 인과추론 프레임워크로의 연결",
    "section": "2 인과 다이어그램 프레임워크 (Causal Diagram Framework)",
    "text": "2 인과 다이어그램 프레임워크 (Causal Diagram Framework)\n\n2.1 Pearl의 do-연산자\nJudea Pearl(1995)이 정립한 인과 다이어그램 프레임워크는 ‘반사실(Counterfactuals)’ 개념 대신, do-연산자(\\(do(\\cdot)\\))를 통해 인과 효과를 정의합니다. \\(do(T=t)\\)는 시스템에 개입하여 변수 \\(T\\)를 강제로 값 \\(t\\)로 고정하고, \\(T\\)로 들어오는 모든 인과적 경로를 끊는 것을 의미합니다.\n\n\n2.2 가정: 백도어 기준 (Back-door Criterion)\n우리는 변수 집합 \\(X\\)가 백도어 기준을 만족한다고 가정합니다. * \\(X\\)는 모든 교란 변수(Confounders)를 포함합니다. * \\(X\\)는 처치 이후의 변수(Post-treatment variables)를 포함하지 않습니다.\n![Image: causal_diagram_backdoor.png] Figure 1: 백도어 기준을 만족하는 인과 다이어그램 예시. X는 T와 Y의 공통 원인(Confounder)을 차단하고 있다.\n\n\n2.3 수학적 구조의 일치성 증명\n우리가 추론하고자 하는 타겟 분포(Target Distribution)는 개입이 일어났을 때의 분포입니다. Pearl(1995)의 기초 정리에 따르면, 백도어 기준이 만족될 때 다음이 성립합니다.\n\\[\nP_{(X,Y)|do(T=t)} = P_X \\times P_{Y|X, T=t}\n\\]\n반면, 우리가 실제로 가지고 있는 관측 분포(Observed Distribution)는 다음과 같습니다.\n\\[\nP_{(X,Y)|T=t} = P_{X|T=t} \\times P_{Y|X, T=t}\n\\]\n[비교 분석] 두 식을 비교해 봅시다. 1. 조건부 분포 \\(P_{Y|X, T=t}\\): 두 식에서 동일합니다. 즉, \\(X\\)와 \\(T\\)가 정해졌을 때 \\(Y\\)가 결정되는 메커니즘은 변하지 않습니다 (Invariance). 2. 공변량 분포: 타겟은 \\(P_X\\) (전체 모집단)이고, 관측은 \\(P_{X|T=t}\\) (특정 처치군)입니다.\n이 구조는 우리가 앞서 다루었던 잠재적 결과 프레임워크에서의 구조와 수학적으로 완전히 동일합니다.\n\n\n2.4 결론: 가중치의 적용\n따라서, 별도의 수정 없이 Weighted Split-CQR 알고리즘을 그대로 적용할 수 있습니다. 이때 가중치(Likelihood Ratio)는 다음과 같이 계산됩니다.\n\\[\nw(x) = \\frac{d P_X(x)}{d P_{X|T=t}(x)} \\propto \\frac{1}{P(T=t|X=x)}\n\\]\n이는 성향 점수(Propensity Score)의 역수와 같습니다. 즉, Pearl의 프레임워크에서도 성향 점수를 이용한 가중 컨포멀 추론이 유효함을 증명한 것입니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/05-From potential outcomes to other causal frameworks/index.html#불변-예측-프레임워크-invariant-prediction-framework",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/05-From potential outcomes to other causal frameworks/index.html#불변-예측-프레임워크-invariant-prediction-framework",
    "title": "세계관의 확장: 다른 인과추론 프레임워크로의 연결",
    "section": "3 불변 예측 프레임워크 (Invariant Prediction Framework)",
    "text": "3 불변 예측 프레임워크 (Invariant Prediction Framework)\n\n3.1 문제 설정\nPeters et al.(2016)이 제안한 불변 예측 프레임워크는 서로 다른 환경(Environments, 예: 유전자 노크아웃 실험 등)에서 데이터가 수집될 때 강력한 힘을 발휘합니다.\n\n\\(Y\\): 결과 변수\n\\(X\\): 개입 또는 공변량\n\\(E\\): 환경 변수 (데이터 소스, \\(e_1, \\dots, e_J\\))\n\n핵심 가정 (Invariance Assumption): 환경 \\(E\\)가 변하더라도, \\(X\\)가 주어졌을 때 \\(Y\\)의 조건부 분포는 변하지 않습니다.\n\\[\nY \\perp E \\mid X \\quad \\iff \\quad P(Y|X, E) = P(Y|X)\n\\]\n하지만 \\(X\\)의 분포는 환경에 따라 달라질 수 있습니다 (\\(X|E \\sim P_X^E\\)). 우리의 목표는 새로운 타겟 환경 \\(e_0\\)에서의 결과를 예측하는 것입니다.\n![Image: invariant_prediction_dag.png] Figure 2: 불변 예측의 구조. 환경 E는 X에 영향을 주지만, Y는 오직 X에 의해서만 직접적인 영향을 받는다(Y에 대한 E의 직접 경로 없음).\n\n\n3.2 Case 1: 단일 소스 환경 (\\(J=1\\))\n데이터 소스가 하나(\\(e_1\\))이고, 타겟 환경이 \\(e_0\\)인 경우를 봅시다.\n\n관측 분포 (Source): \\(P_X^{e_1} \\times P_{Y|X}\\)\n타겟 분포 (Target): \\(P_X^{e_0} \\times P_{Y|X}\\)\n\n이 역시 잠재적 결과 프레임워크와 동일한 공변량 변화(Covariate Shift) 문제입니다. 따라서 다음 가중치를 사용하여 Weighted Split-CQR을 적용하면 됩니다.\n\\[\nw(x) = \\frac{d P_X^{e_0}(x)}{d P_X^{e_1}(x)}\n\\]\n\n\n3.3 Case 2: 다중 소스 환경 (\\(J &gt; 1\\))\n여러 환경 \\(e_1, \\dots, e_J\\)에서 데이터 \\((X_{ij}, Y_{ij})\\)가 수집된 경우는 조금 더 복잡합니다.\nTibshirani et al.(2019b)의 일반화된 가중치를 사용할 수도 있지만, 식이 매우 복잡해집니다. 논문은 대신 가중 모집단(Weighted Population)을 생성하는 대안을 제시합니다.\n여러 환경의 데이터를 적절한 비율 \\(q_j\\)로 섞어서, 타겟 환경 \\(e_0\\)의 분포와 유사하게 만드는 아이디어입니다.\n[수학적 유도] 관측된 혼합 분포를 다음과 같이 정의합니다.\n\\[\nP_{Obs} = \\left( \\sum_{j=1}^J q_j P_X^{e_j} \\right) \\times P_{Y|X}\n\\]\n우리가 원하는 타겟 분포는 \\(P_X^{e_0} \\times P_{Y|X}\\)입니다. 따라서 이 혼합 데이터셋에 대해 다음 가중치를 적용하면 됩니다.\n\\[\nw(x) = \\frac{1}{\\sum_{j=1}^J q_j \\frac{d P_X^{e_j}}{d P_X^{e_0}}(x)}\n\\]\n여기서 \\(q_j\\)는 공변량 분포의 균형을 맞추는 절차(Balancing procedures)를 통해 선택할 수 있습니다. 이를 통해 다중 환경 데이터를 통합하여 타겟 환경에 대한 이중 강건성(Doubly Robust)을 가진 구간 추정이 가능해집니다."
  },
  {
    "objectID": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/05-From potential outcomes to other causal frameworks/index.html#전체-요약-및-결론",
    "href": "posts/paper/Conformal inference of counterfactuals and individual treatment effects/05-From potential outcomes to other causal frameworks/index.html#전체-요약-및-결론",
    "title": "세계관의 확장: 다른 인과추론 프레임워크로의 연결",
    "section": "4 전체 요약 및 결론",
    "text": "4 전체 요약 및 결론\n이 논문은 “평균(ATE)에서 개인(ITE)으로”, 그리고 “점 추정에서 구간 추정으로” 인과추론의 패러다임을 확장했습니다.\n\n문제의 재정의: ITE 추정 문제를 반사실(Counterfactual)의 예측 구간 생성 문제로 치환했습니다.\n방법론: 가중 컨포멀 추론(Weighted Split-CQR)을 도입하여, 학습 분포와 타겟 분포가 다른 상황(Covariate Shift)에서도 신뢰할 수 있는 구간을 생성했습니다.\n이론적 보장:\n\n무작위 실험(RCT)에서는 유한 샘플에서도 완전한(Exact) 커버리지를 보장합니다.\n관찰 연구(Observational Study)에서는 성향 점수나 결과 모델 중 하나만 정확해도 되는 이중 강건성(Double Robustness)을 가집니다.\n\n확장성: 이 방법론은 Pearl의 인과 다이어그램이나 불변 예측 프레임워크 등, 조건부 불변성이 성립하는 모든 인과추론 문제에 범용적으로 적용될 수 있습니다.\n\n결국, 이 연구는 불확실성이 가득한 세상에서 인과관계를 기반으로 한 의사결정을 내릴 때, “얼마나 확신할 수 있는가?”라는 질문에 답할 수 있는 강력하고 유연한 도구를 제공했다고 평가할 수 있습니다.\n\nReference: Lei, L., & Candès, E. J. (2021). Conformal inference of counterfactuals and individual treatment effects. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 83(5), 911-938."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "shsha0110.github.io",
    "section": "",
    "text": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 1)\n\n\n1. Conformal Prediction\n\n\n\nPaper Review\n\n\n\n\n\n\n\n\n\nJan 15, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.1)\n\n\n2.1. Examples of Conformal Procedures\n\n\n\nPaper Review\n\n\n\n\n\n\n\n\n\nJan 16, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.2)\n\n\n2.2. Conformalized Quantile Regression\n\n\n\nPaper Review\n\n\n\n\n\n\n\n\n\nJan 16, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.3)\n\n\n2.3. Conformalizing Scalar Uncertainty Estimates\n\n\n\nPaper Review\n\n\n\n\n\n\n\n\n\nJan 16, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.4)\n\n\n2.4. Conformalizing Bayes\n\n\n\nPaper Review\n\n\n\n\n\n\n\n\n\nJan 16, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 3.1)\n\n\n3.1. Evaluating Adaptivity\n\n\n\nPaper Review\n\n\n\n\n\n\n\n\n\nJan 16, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 3.2)\n\n\n3.2. The Effect of the Size of the Calibration Set\n\n\n\nPaper Review\n\n\n\n\n\n\n\n\n\nJan 16, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 3.3)\n\n\n3.3. Checking for Correct Coverage\n\n\n\nPaper Review\n\n\n\n\n\n\n\n\n\nJan 16, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.1)\n\n\n4.1. Group-Balanced Conformal Prediction\n\n\n\nPaper Review\n\n\n\n\n\n\n\n\n\nJan 16, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.2)\n\n\n4.2. Class-Conditional Conformal Prediction\n\n\n\nPaper Review\n\n\n\n\n\n\n\n\n\nJan 16, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.3)\n\n\n4.3. Conformal Risk Control\n\n\n\nPaper Review\n\n\n\n\n\n\n\n\n\nJan 16, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.4)\n\n\n4.4. Outlier Detection\n\n\n\nPaper Review\n\n\n\n\n\n\n\n\n\nJan 16, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.5)\n\n\n4.5. Conformal Prediction Under Covariate Shift\n\n\n\nPaper Review\n\n\n\n\n\n\n\n\n\nJan 16, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.6)\n\n\n4.6. Conformal Prediction Under Distribution Shift\n\n\n\nPaper Review\n\n\n\n\n\n\n\n\n\nJan 16, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 5)\n\n\n5. Worked Examples\n\n\n\nPaper Review\n\n\n\n\n\n\n\n\n\nJan 16, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 6)\n\n\n6. Full Conformal Prediction\n\n\n\nPaper Review\n\n\n\n\n\n\n\n\n\nJan 16, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 01. Introduction\n\n\n\n\n\n\nCausal Inference\n\n\n\nIntroduction to Causal Inference\n\n\n\n\n\nJan 6, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 04. Confounding and Backdoor (Part 1)\n\n\n\n\n\n\nCausal Inference\n\n\n\nIndentifiable and Non-identifiable Effects\n\n\n\n\n\nJan 7, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 04. Confounding and Backdoor (Part 2)\n\n\n\n\n\n\nCausal Inference\n\n\n\nCounfounding Bias\n\n\n\n\n\nJan 7, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 04. Confounding and Backdoor (Part 3)\n\n\n\n\n\n\nCausal Inference\n\n\n\nBack-door Criterion\n\n\n\n\n\nJan 7, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 04. Confounding and Backdoor (Part 4)\n\n\n\n\n\n\nCausal Inference\n\n\n\nInverse Probability Weighting\n\n\n\n\n\nJan 7, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 04. Confounding and Backdoor (Part 5)\n\n\n\n\n\n\nCausal Inference\n\n\n\nSimpson’s Paradox Simulation Using DoWhy: Stratification & Refutation\n\n\n\n\n\nJan 8, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 08. Partial Identification (Part 1)\n\n\n\n\n\n\nCausal Inference\n\n\n\nPartial Identification Problem: Natural Bounds\n\n\n\n\n\nJan 11, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 08. Partial Identification (Part 2)\n\n\n\n\n\n\nCausal Inference\n\n\n\nPartial Identification Problem: Non-Compliance\n\n\n\n\n\nJan 12, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 08. Partial Identification (Part 3)\n\n\n\n\n\n\nCausal Inference\n\n\n\nBounds on Partially-observed Covariates\n\n\n\n\n\nJan 13, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 08. Partial Identification (Part 4)\n\n\n\n\n\n\nCausal Inference\n\n\n\nNon-Compliance Simulation\n\n\n\n\n\nJan 13, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 13. IV (Part 1)\n\n\n\n\n\n\nCausal Inference\n\n\n\nIV under Linear Assumption\n\n\n\n\n\nJan 15, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 13. IV (Part 2)\n\n\n\n\n\n\nCausal Inference\n\n\n\nRandom Experiment wiht Noncompliance\n\n\n\n\n\nJan 16, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 13. IV (Part 3)\n\n\n\n\n\n\nCausal Inference\n\n\n\nLinear 2SLS vs. Deep IV\n\n\n\n\n\nJan 18, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 15. DiD & SCM (Part 1)\n\n\n\n\n\n\nCausal Inference\n\n\n\nDifference in Differences\n\n\n\n\n\nJan 22, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 15. DiD & SCM (Part 2)\n\n\n\n\n\n\nCausal Inference\n\n\n\nNonlinear DiD\n\n\n\n\n\nJan 22, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 15. DiD & SCM (Part 3)\n\n\n\n\n\n\nCausal Inference\n\n\n\nSynthetic Control Method\n\n\n\n\n\nJan 22, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 16. Causal Discovery (Part 1)\n\n\n\n\n\n\nCausal Inference\n\n\n\nIntroduction\n\n\n\n\n\nJan 22, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 16. Causal Discovery (Part 2)\n\n\n\n\n\n\nCausal Inference\n\n\n\nConstraint-Based Learning & PC Algorithm\n\n\n\n\n\nJan 22, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 16. Causal Discovery (Part 3)\n\n\n\n\n\n\nCausal Inference\n\n\n\nExtensions of PC Algorithm & FCI\n\n\n\n\n\nJan 22, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 16. Causal Discovery (Part 4)\n\n\n\n\n\n\nCausal Inference\n\n\n\nScore-Based Learning & Continuous Optimization\n\n\n\n\n\nJan 22, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 16. Causal Discovery (Part 5)\n\n\n\n\n\n\nCausal Inference\n\n\n\nFunctional Causal Models\n\n\n\n\n\nJan 22, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n[Causal Inference] 16. Causal Discovery (Part 6)\n\n\n\n\n\n\nCausal Inference\n\n\n\nTime Series Causal Discovery\n\n\n\n\n\nJan 22, 2026\n\n\n유성현\n\n\n\n\n\n\n\n\n\n\n\n\n성향 점수의 역할과 이중 강건성(Double Robustness)\n\n\nPaper Review: Conformal inference of counterfactuals and individual treatment effects (Section 3.1 - 3.2)\n\n\n\nCausal Inference\n\nConformal Prediction\n\nMachine Learning\n\n\n\n\n\n\n\n\n\nJan 22, 2026\n\n\nReviewer\n\n\n\n\n\n\n\n\n\n\n\n\n세계관의 확장: 다른 인과추론 프레임워크로의 연결\n\n\nPaper Review: Conformal inference of counterfactuals and individual treatment effects (Section 5)\n\n\n\nCausal Inference\n\nPearl's Causal Diagram\n\nInvariant Prediction\n\n\n\n\n\n\n\n\n\nJan 22, 2026\n\n\nReviewer\n\n\n\n\n\n\n\n\n\n\n\n\n실전 검증: ACIC 2018 데이터와 NLSM 실제 사례 분석\n\n\nPaper Review: Conformal inference of counterfactuals and individual treatment effects (Section 4)\n\n\n\nCausal Inference\n\nNested Conformal Prediction\n\nITE\n\n\n\n\n\n\n\n\n\nJan 22, 2026\n\n\nReviewer\n\n\n\n\n\n\n\n\n\n\n\n\n점 추정을 넘어 구간 추정으로: 인과추론의 불확실성을 다루는 법\n\n\nPaper Review: Conformal inference of counterfactuals and individual treatment effects (Section 2)\n\n\n\nCausal Inference\n\nStatistics\n\nUncertainty Quantification\n\n\n\n\n\n\n\n\n\nJan 22, 2026\n\n\nReviewer\n\n\n\n\n\n\n\n\n\n\n\n\n평균을 넘어 개인으로: 인과추론의 새로운 패러다임과 Conformal Inference\n\n\nPaper Review: Conformal inference of counterfactuals and individual treatment effects (Section 1)\n\n\n\nCausal Inference\n\nStatistics\n\nMachine Learning\n\n\n\n\n\n\n\n\n\nJan 22, 2026\n\n\nReviewer\n\n\n\n\n\nNo matching items"
  }
]