<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="유성현">
<meta name="dcterms.date" content="2026-02-10">
<meta name="description" content="시변 처리와 교란요인 피드백 상황에서의 인과 효과 추정">

<title>[What If] Chapter 21. G-Methods For Time-Varying Treatments – shsha0110.github.io</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5b4ad623e5705c0698d39aec6f10cf02.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<meta name="google-site-verification" content="wnUhrJyUH9DivslRuyTASn9K6KXZlRrojFuwYY1q2hI">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../../index.html">
    <span class="navbar-title">shsha0110.github.io</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">[What If] Chapter 21. G-Methods For Time-Varying Treatments</h1>
                  <div>
        <div class="description">
          시변 처리와 교란요인 피드백 상황에서의 인과 효과 추정
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Paper Review</div>
                <div class="quarto-category">What If</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>유성현 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 10, 2026</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-g-formula-for-time-varying-treatments" id="toc-the-g-formula-for-time-varying-treatments" class="nav-link active" data-scroll-target="#the-g-formula-for-time-varying-treatments">21.1 The g-formula for time-varying treatments</a>
  <ul class="collapse">
  <li><a href="#introduction-the-challenge-of-time-varying-treatments" id="toc-introduction-the-challenge-of-time-varying-treatments" class="nav-link" data-scroll-target="#introduction-the-challenge-of-time-varying-treatments">1. Introduction: The Challenge of Time-Varying Treatments</a></li>
  <li><a href="#motivating-example-sequential-randomized-experiment" id="toc-motivating-example-sequential-randomized-experiment" class="nav-link" data-scroll-target="#motivating-example-sequential-randomized-experiment">2. Motivating Example: Sequential Randomized Experiment</a>
  <ul class="collapse">
  <li><a href="#the-data-structure" id="toc-the-data-structure" class="nav-link" data-scroll-target="#the-data-structure">2.1 The Data Structure</a></li>
  <li><a href="#the-problem-with-static-adjustment" id="toc-the-problem-with-static-adjustment" class="nav-link" data-scroll-target="#the-problem-with-static-adjustment">2.2 The Problem with Static Adjustment</a></li>
  </ul></li>
  <li><a href="#the-g-formula-for-time-varying-treatments-1" id="toc-the-g-formula-for-time-varying-treatments-1" class="nav-link" data-scroll-target="#the-g-formula-for-time-varying-treatments-1">3. The G-Formula for Time-Varying Treatments</a>
  <ul class="collapse">
  <li><a href="#intuition-standardization-by-history" id="toc-intuition-standardization-by-history" class="nav-link" data-scroll-target="#intuition-standardization-by-history">3.1 Intuition: Standardization by History</a></li>
  <li><a href="#mathematical-formulation" id="toc-mathematical-formulation" class="nav-link" data-scroll-target="#mathematical-formulation">3.2 Mathematical Formulation</a></li>
  <li><a href="#application-to-the-example" id="toc-application-to-the-example" class="nav-link" data-scroll-target="#application-to-the-example">3.3 Application to the Example</a></li>
  </ul></li>
  <li><a href="#g-formula-as-a-simulation" id="toc-g-formula-as-a-simulation" class="nav-link" data-scroll-target="#g-formula-as-a-simulation">4. G-Formula as a Simulation</a>
  <ul class="collapse">
  <li><a href="#constructing-the-counterfactual-tree" id="toc-constructing-the-counterfactual-tree" class="nav-link" data-scroll-target="#constructing-the-counterfactual-tree">4.1 Constructing the Counterfactual Tree</a></li>
  <li><a href="#why-history-matters-fine-point-21.1" id="toc-why-history-matters-fine-point-21.1" class="nav-link" data-scroll-target="#why-history-matters-fine-point-21.1">4.2 Why History Matters (Fine Point 21.1)</a></li>
  </ul></li>
  <li><a href="#generalization-high-dimensional-g-formula" id="toc-generalization-high-dimensional-g-formula" class="nav-link" data-scroll-target="#generalization-high-dimensional-g-formula">5. Generalization: High-Dimensional G-Formula</a>
  <ul class="collapse">
  <li><a href="#the-plug-in-g-formula" id="toc-the-plug-in-g-formula" class="nav-link" data-scroll-target="#the-plug-in-g-formula">5.1 The Plug-in G-Formula</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#ip-weighting-for-time-varying-treatments" id="toc-ip-weighting-for-time-varying-treatments" class="nav-link" data-scroll-target="#ip-weighting-for-time-varying-treatments">21.2 IP weighting for time-varying treatments</a>
  <ul class="collapse">
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">1. Introduction</a></li>
  <li><a href="#ip-weighting-for-time-varying-treatments-1" id="toc-ip-weighting-for-time-varying-treatments-1" class="nav-link" data-scroll-target="#ip-weighting-for-time-varying-treatments-1">2. IP Weighting for Time-Varying Treatments</a>
  <ul class="collapse">
  <li><a href="#motivation-why-generalize" id="toc-motivation-why-generalize" class="nav-link" data-scroll-target="#motivation-why-generalize">2.1. Motivation: Why Generalize?</a></li>
  <li><a href="#construction-of-weights" id="toc-construction-of-weights" class="nav-link" data-scroll-target="#construction-of-weights">2.2. Construction of Weights</a></li>
  <li><a href="#pseudo-population-interpretation" id="toc-pseudo-population-interpretation" class="nav-link" data-scroll-target="#pseudo-population-interpretation">2.3. Pseudo-population Interpretation</a></li>
  </ul></li>
  <li><a href="#illustration-a-worked-example" id="toc-illustration-a-worked-example" class="nav-link" data-scroll-target="#illustration-a-worked-example">3. Illustration: A Worked Example</a>
  <ul class="collapse">
  <li><a href="#setting" id="toc-setting" class="nav-link" data-scroll-target="#setting">Setting</a></li>
  <li><a href="#calculation" id="toc-calculation" class="nav-link" data-scroll-target="#calculation">Calculation</a></li>
  </ul></li>
  <li><a href="#marginal-structural-models-msms" id="toc-marginal-structural-models-msms" class="nav-link" data-scroll-target="#marginal-structural-models-msms">4. Marginal Structural Models (MSMs)</a>
  <ul class="collapse">
  <li><a href="#the-curse-of-dimensionality" id="toc-the-curse-of-dimensionality" class="nav-link" data-scroll-target="#the-curse-of-dimensionality">4.1. The Curse of Dimensionality</a></li>
  <li><a href="#model-specification" id="toc-model-specification" class="nav-link" data-scroll-target="#model-specification">4.2. Model Specification</a></li>
  <li><a href="#estimation-via-weighted-least-squares-wls" id="toc-estimation-via-weighted-least-squares-wls" class="nav-link" data-scroll-target="#estimation-via-weighted-least-squares-wls">4.3. Estimation via Weighted Least Squares (WLS)</a></li>
  <li><a href="#model-misspecification-diagnostics" id="toc-model-misspecification-diagnostics" class="nav-link" data-scroll-target="#model-misspecification-diagnostics">4.4. Model Misspecification &amp; Diagnostics</a></li>
  </ul></li>
  <li><a href="#practical-implementation-details" id="toc-practical-implementation-details" class="nav-link" data-scroll-target="#practical-implementation-details">5. Practical Implementation Details</a></li>
  <li><a href="#effect-modification-효과-변경" id="toc-effect-modification-효과-변경" class="nav-link" data-scroll-target="#effect-modification-효과-변경">6. Effect Modification (효과 변경)</a>
  <ul class="collapse">
  <li><a href="#definition-of-variable-v" id="toc-definition-of-variable-v" class="nav-link" data-scroll-target="#definition-of-variable-v">6.1 Definition of Variable <span class="math inline">\(V\)</span></a></li>
  <li><a href="#the-model-with-interaction" id="toc-the-model-with-interaction" class="nav-link" data-scroll-target="#the-model-with-interaction">6.2 The Model with Interaction</a></li>
  <li><a href="#estimation-with-modified-weights" id="toc-estimation-with-modified-weights" class="nav-link" data-scroll-target="#estimation-with-modified-weights">6.3 Estimation with Modified Weights</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#a-doubly-robust-estimator-for-time-varying-treatments" id="toc-a-doubly-robust-estimator-for-time-varying-treatments" class="nav-link" data-scroll-target="#a-doubly-robust-estimator-for-time-varying-treatments">21.3 A doubly robust estimator for time-varying treatments</a>
  <ul class="collapse">
  <li><a href="#introduction-왜-이중-강건인가" id="toc-introduction-왜-이중-강건인가" class="nav-link" data-scroll-target="#introduction-왜-이중-강건인가">1. Introduction: 왜 ’이중 강건’인가?</a></li>
  <li><a href="#warm-up-시점-고정time-fixed-처리에서의-dr" id="toc-warm-up-시점-고정time-fixed-처리에서의-dr" class="nav-link" data-scroll-target="#warm-up-시점-고정time-fixed-처리에서의-dr">2. Warm-up: 시점 고정(Time-fixed) 처리에서의 DR</a>
  <ul class="collapse">
  <li><a href="#알고리즘-개요" id="toc-알고리즘-개요" class="nav-link" data-scroll-target="#알고리즘-개요">알고리즘 개요</a></li>
  </ul></li>
  <li><a href="#time-varying-treatment로의-확장" id="toc-time-varying-treatment로의-확장" class="nav-link" data-scroll-target="#time-varying-treatment로의-확장">3. Time-Varying Treatment로의 확장</a>
  <ul class="collapse">
  <li><a href="#step-1-순차적-처리-모형-sequential-treatment-models" id="toc-step-1-순차적-처리-모형-sequential-treatment-models" class="nav-link" data-scroll-target="#step-1-순차적-처리-모형-sequential-treatment-models">Step 1: 순차적 처리 모형 (Sequential Treatment Models)</a></li>
  <li><a href="#step-2-순차적-결과-모형-sequential-outcome-models" id="toc-step-2-순차적-결과-모형-sequential-outcome-models" class="nav-link" data-scroll-target="#step-2-순차적-결과-모형-sequential-outcome-models">Step 2: 순차적 결과 모형 (Sequential Outcome Models)</a></li>
  <li><a href="#step-3-최종-추정-standardization" id="toc-step-3-최종-추정-standardization" class="nav-link" data-scroll-target="#step-3-최종-추정-standardization">Step 3: 최종 추정 (Standardization)</a></li>
  </ul></li>
  <li><a href="#왜-이것이-강건robust한가" id="toc-왜-이것이-강건robust한가" class="nav-link" data-scroll-target="#왜-이것이-강건robust한가">4. 왜 이것이 “강건(Robust)”한가?</a>
  <ul class="collapse">
  <li><a href="#k2-robustness의-의미" id="toc-k2-robustness의-의미" class="nav-link" data-scroll-target="#k2-robustness의-의미">K+2 Robustness의 의미</a></li>
  </ul></li>
  <li><a href="#technical-details-implementation-notes" id="toc-technical-details-implementation-notes" class="nav-link" data-scroll-target="#technical-details-implementation-notes">5. Technical Details &amp; Implementation Notes</a>
  <ul class="collapse">
  <li><a href="#boundedness-경계-조건" id="toc-boundedness-경계-조건" class="nav-link" data-scroll-target="#boundedness-경계-조건">Boundedness (경계 조건)</a></li>
  <li><a href="#tmle와의-관계" id="toc-tmle와의-관계" class="nav-link" data-scroll-target="#tmle와의-관계">TMLE와의 관계</a></li>
  <li><a href="#computational-considerations" id="toc-computational-considerations" class="nav-link" data-scroll-target="#computational-considerations">Computational Considerations</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#g-estimation-for-time-varying-treatments" id="toc-g-estimation-for-time-varying-treatments" class="nav-link" data-scroll-target="#g-estimation-for-time-varying-treatments">21.4 G-estimation for time-varying treatments</a>
  <ul class="collapse">
  <li><a href="#introduction-1" id="toc-introduction-1" class="nav-link" data-scroll-target="#introduction-1">1. Introduction</a></li>
  <li><a href="#structural-nested-mean-models-snmms" id="toc-structural-nested-mean-models-snmms" class="nav-link" data-scroll-target="#structural-nested-mean-models-snmms">2. Structural Nested Mean Models (SNMMs)</a>
  <ul class="collapse">
  <li><a href="#the-blip-function-효과의-정의" id="toc-the-blip-function-효과의-정의" class="nav-link" data-scroll-target="#the-blip-function-효과의-정의">2.1. The “Blip” Function: 효과의 정의</a></li>
  <li><a href="#왜-nested인가" id="toc-왜-nested인가" class="nav-link" data-scroll-target="#왜-nested인가">2.2. 왜 “Nested”인가?</a></li>
  </ul></li>
  <li><a href="#g-estimation-methodology" id="toc-g-estimation-methodology" class="nav-link" data-scroll-target="#g-estimation-methodology">3. G-estimation Methodology</a>
  <ul class="collapse">
  <li><a href="#preliminary-the-intuition-behind-g-estimation" id="toc-preliminary-the-intuition-behind-g-estimation" class="nav-link" data-scroll-target="#preliminary-the-intuition-behind-g-estimation">3.1. Preliminary: The Intuition behind G-estimation</a></li>
  <li><a href="#candidate-counterfactuals-h_k-and-grid-search" id="toc-candidate-counterfactuals-h_k-and-grid-search" class="nav-link" data-scroll-target="#candidate-counterfactuals-h_k-and-grid-search">3.2. Candidate Counterfactuals (<span class="math inline">\(H_k\)</span>) and Grid Search</a></li>
  </ul></li>
  <li><a href="#efficient-estimation-multidimensional-parameters" id="toc-efficient-estimation-multidimensional-parameters" class="nav-link" data-scroll-target="#efficient-estimation-multidimensional-parameters">4. Efficient Estimation: Multidimensional Parameters</a>
  <ul class="collapse">
  <li><a href="#the-curse-of-dimensionality-차원의-저주" id="toc-the-curse-of-dimensionality-차원의-저주" class="nav-link" data-scroll-target="#the-curse-of-dimensionality-차원의-저주">4.1. The Curse of Dimensionality (차원의 저주)</a></li>
  <li><a href="#estimating-equations-and-closed-form-derivation" id="toc-estimating-equations-and-closed-form-derivation" class="nav-link" data-scroll-target="#estimating-equations-and-closed-form-derivation">4.2. Estimating Equations and Closed-form Derivation</a></li>
  </ul></li>
  <li><a href="#from-parameters-to-counterfactual-means" id="toc-from-parameters-to-counterfactual-means" class="nav-link" data-scroll-target="#from-parameters-to-counterfactual-means">5. From Parameters to Counterfactual Means</a>
  <ul class="collapse">
  <li><a href="#reconstruction-formula-for-static-strategies" id="toc-reconstruction-formula-for-static-strategies" class="nav-link" data-scroll-target="#reconstruction-formula-for-static-strategies">5.1. Reconstruction Formula for Static Strategies</a></li>
  <li><a href="#dynamic-strategies-and-simulation" id="toc-dynamic-strategies-and-simulation" class="nav-link" data-scroll-target="#dynamic-strategies-and-simulation">5.2. Dynamic Strategies and Simulation</a></li>
  </ul></li>
  <li><a href="#snmm-vs.-marginal-structural-models-msm" id="toc-snmm-vs.-marginal-structural-models-msm" class="nav-link" data-scroll-target="#snmm-vs.-marginal-structural-models-msm">6. SNMM vs.&nbsp;Marginal Structural Models (MSM)</a>
  <ul class="collapse">
  <li><a href="#effect-modification-효과-변경-1" id="toc-effect-modification-효과-변경-1" class="nav-link" data-scroll-target="#effect-modification-효과-변경-1">6.1. Effect Modification (효과 변경)</a></li>
  <li><a href="#the-trade-off-robustness-vs.-efficiency" id="toc-the-trade-off-robustness-vs.-efficiency" class="nav-link" data-scroll-target="#the-trade-off-robustness-vs.-efficiency">6.2. The Trade-off: Robustness vs.&nbsp;Efficiency</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#censoring-is-a-time-varying-treatment" id="toc-censoring-is-a-time-varying-treatment" class="nav-link" data-scroll-target="#censoring-is-a-time-varying-treatment">21.5 Censoring is a time-varying treatment</a>
  <ul class="collapse">
  <li><a href="#introduction-the-reality-of-censoring" id="toc-introduction-the-reality-of-censoring" class="nav-link" data-scroll-target="#introduction-the-reality-of-censoring">1. Introduction: The Reality of Censoring</a></li>
  <li><a href="#conceptual-framework" id="toc-conceptual-framework" class="nav-link" data-scroll-target="#conceptual-framework">2. Conceptual Framework</a>
  <ul class="collapse">
  <li><a href="#time-varying-censoring-definition" id="toc-time-varying-censoring-definition" class="nav-link" data-scroll-target="#time-varying-censoring-definition">2.1. Time-Varying Censoring Definition</a></li>
  <li><a href="#the-joint-intervention-perspective" id="toc-the-joint-intervention-perspective" class="nav-link" data-scroll-target="#the-joint-intervention-perspective">2.2. The Joint Intervention Perspective</a></li>
  </ul></li>
  <li><a href="#method-1-the-g-formula" id="toc-method-1-the-g-formula" class="nav-link" data-scroll-target="#method-1-the-g-formula">3. Method 1: The G-Formula</a>
  <ul class="collapse">
  <li><a href="#수식-해석" id="toc-수식-해석" class="nav-link" data-scroll-target="#수식-해석">수식 해석</a></li>
  </ul></li>
  <li><a href="#method-2-ip-weighting-inverse-probability-weighting" id="toc-method-2-ip-weighting-inverse-probability-weighting" class="nav-link" data-scroll-target="#method-2-ip-weighting-inverse-probability-weighting">4. Method 2: IP Weighting (Inverse Probability Weighting)</a>
  <ul class="collapse">
  <li><a href="#non-stabilized-ip-weights-for-censoring" id="toc-non-stabilized-ip-weights-for-censoring" class="nav-link" data-scroll-target="#non-stabilized-ip-weights-for-censoring">4.1. Non-stabilized IP Weights for Censoring</a></li>
  <li><a href="#joint-weights-treatment-censoring" id="toc-joint-weights-treatment-censoring" class="nav-link" data-scroll-target="#joint-weights-treatment-censoring">4.2. Joint Weights (Treatment + Censoring)</a></li>
  <li><a href="#stabilized-weights-swbarc" id="toc-stabilized-weights-swbarc" class="nav-link" data-scroll-target="#stabilized-weights-swbarc">4.3. Stabilized Weights (<span class="math inline">\(SW^{\bar{C}}\)</span>)</a></li>
  </ul></li>
  <li><a href="#method-3-g-estimation" id="toc-method-3-g-estimation" class="nav-link" data-scroll-target="#method-3-g-estimation">5. Method 3: G-Estimation</a></li>
  <li><a href="#extension-survival-analysis-technical-point-21.10" id="toc-extension-survival-analysis-technical-point-21.10" class="nav-link" data-scroll-target="#extension-survival-analysis-technical-point-21.10">6. Extension: Survival Analysis (Technical Point 21.10)</a>
  <ul class="collapse">
  <li><a href="#the-goal-estimating-counterfactual-risk" id="toc-the-goal-estimating-counterfactual-risk" class="nav-link" data-scroll-target="#the-goal-estimating-counterfactual-risk">6.1. The Goal: Estimating Counterfactual Risk</a></li>
  <li><a href="#approach-1-the-g-formula" id="toc-approach-1-the-g-formula" class="nav-link" data-scroll-target="#approach-1-the-g-formula">6.2. Approach 1: The g-formula</a></li>
  <li><a href="#approach-2-ip-weighting-pooled-logistic-model" id="toc-approach-2-ip-weighting-pooled-logistic-model" class="nav-link" data-scroll-target="#approach-2-ip-weighting-pooled-logistic-model">6.3. Approach 2: IP Weighting (Pooled Logistic Model)</a></li>
  <li><a href="#causal-graph-dag-interpretation" id="toc-causal-graph-dag-interpretation" class="nav-link" data-scroll-target="#causal-graph-dag-interpretation">6.4. Causal Graph (DAG) Interpretation</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#the-big-g-formula" id="toc-the-big-g-formula" class="nav-link" data-scroll-target="#the-big-g-formula">21.6 The big g-formula</a>
  <ul class="collapse">
  <li><a href="#introduction-관측-데이터의-한계를-넘어서" id="toc-introduction-관측-데이터의-한계를-넘어서" class="nav-link" data-scroll-target="#introduction-관측-데이터의-한계를-넘어서">1. Introduction: 관측 데이터의 한계를 넘어서</a></li>
  <li><a href="#factuals-vs.-counterfactuals" id="toc-factuals-vs.-counterfactuals" class="nav-link" data-scroll-target="#factuals-vs.-counterfactuals">2. Factuals vs.&nbsp;Counterfactuals</a></li>
  <li><a href="#the-big-g-formula의-정의" id="toc-the-big-g-formula의-정의" class="nav-link" data-scroll-target="#the-big-g-formula의-정의">3. The Big G-Formula의 정의</a></li>
  <li><a href="#case-study-front-door-criterion" id="toc-case-study-front-door-criterion" class="nav-link" data-scroll-target="#case-study-front-door-criterion">4. Case Study: Front Door Criterion</a>
  <ul class="collapse">
  <li><a href="#시나리오-설정" id="toc-시나리오-설정" class="nav-link" data-scroll-target="#시나리오-설정">4.1. 시나리오 설정</a></li>
  <li><a href="#big-g-formula를-이용한-증명-derivation" id="toc-big-g-formula를-이용한-증명-derivation" class="nav-link" data-scroll-target="#big-g-formula를-이용한-증명-derivation">4.2. Big G-Formula를 이용한 증명 (Derivation)</a></li>
  </ul></li>
  <li><a href="#alternative-proof-swigs-single-world-intervention-graphs" id="toc-alternative-proof-swigs-single-world-intervention-graphs" class="nav-link" data-scroll-target="#alternative-proof-swigs-single-world-intervention-graphs">5. Alternative Proof: SWIGs (Single World Intervention Graphs)</a></li>
  <li><a href="#summary-implications" id="toc-summary-implications" class="nav-link" data-scroll-target="#summary-implications">6. Summary &amp; Implications</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="the-g-formula-for-time-varying-treatments" class="level1">
<h1>21.1 The g-formula for time-varying treatments</h1>
<section id="introduction-the-challenge-of-time-varying-treatments" class="level2">
<h2 class="anchored" data-anchor-id="introduction-the-challenge-of-time-varying-treatments">1. Introduction: The Challenge of Time-Varying Treatments</h2>
<ul>
<li><p>인과추론에서 가장 까다로운 시나리오 중 하나는 <strong>시변 처리(Time-varying treatment)</strong>가 존재하고, 동시에 <strong>처리-교란요인 피드백(Treatment-confounder feedback)</strong>이 발생하는 상황입니다.</p></li>
<li><p>이전 챕터(Chapter 20)에서 우리는 이러한 구조를 가진 데이터셋에서 전통적인 조정 방법(층화, 회귀분석 등)이 실패한다는 것을 확인했습니다. 설령 실제 인과 효과가 0(Null)이라 할지라도, 전통적인 방법은 편향된 추정치를 내놓습니다.</p></li>
<li><p>Chapter 21에서는 이러한 편향을 해결하기 위한 <strong>G-Methods</strong>의 첫 번째 주자, <strong>The G-Formula</strong>를 소개합니다. 이 글에서는 G-formula가 어떻게 시변 처리 상황에서 올바른 인과 효과를 식별(Identify)해내는지, 그 수리적 구조와 직관적인 시뮬레이션 관점을 자세히 살펴봅니다.</p></li>
</ul>
</section>
<section id="motivating-example-sequential-randomized-experiment" class="level2">
<h2 class="anchored" data-anchor-id="motivating-example-sequential-randomized-experiment">2. Motivating Example: Sequential Randomized Experiment</h2>
<ul>
<li>논의를 구체화하기 위해, Chapter 20에서 사용했던 순차적 무작위 실험(Sequentially Randomized Experiment) 데이터를 다시 가져옵니다.</li>
</ul>
<section id="the-data-structure" class="level3">
<h3 class="anchored" data-anchor-id="the-data-structure">2.1 The Data Structure</h3>
<ul>
<li>이 데이터는 2개의 시점(<span class="math inline">\(k=0, 1\)</span>)을 가집니다.
<ul>
<li><strong><span class="math inline">\(A_0, A_1\)</span></strong>: 처치 여부 (0 또는 1)</li>
<li><strong><span class="math inline">\(L_1\)</span></strong>: 시점 1에서 측정된 교란요인 (Confounder)</li>
<li><strong><span class="math inline">\(Y\)</span></strong>: 최종 결과 (Outcome)</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/table_21_1.png" class="img-fluid figure-img"></p>
<figcaption>Table 21.1: 데이터의 구조와 요약 통계량. <span class="math inline">\(A_0\)</span>에 따라 <span class="math inline">\(L_1\)</span>의 분포가 달라지고, <span class="math inline">\(L_1\)</span>에 따라 <span class="math inline">\(A_1\)</span>과 <span class="math inline">\(Y\)</span>의 평균이 달라지는 구조를 보여준다.</figcaption>
</figure>
</div>
<ul>
<li>위 표(Table 21.1)를 트리 구조로 시각화하면 데이터의 생성 과정을 더 명확히 이해할 수 있습니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/figure_21_1.png" class="img-fluid figure-img"></p>
<figcaption>Figure 21.1: 관찰된 데이터의 인과 트리. 각 가지(Branch)는 처리(<span class="math inline">\(A\)</span>)와 교란요인(<span class="math inline">\(L\)</span>)의 경로를 나타내며, 각 끝단에는 관찰된 개체 수(<span class="math inline">\(N\)</span>)와 평균 결과(<span class="math inline">\(E[Y]\)</span>)가 표시되어 있다.</figcaption>
</figure>
</div>
</section>
<section id="the-problem-with-static-adjustment" class="level3">
<h3 class="anchored" data-anchor-id="the-problem-with-static-adjustment">2.2 The Problem with Static Adjustment</h3>
<ul>
<li>만약 우리가 시점 1의 처치(<span class="math inline">\(A_1\)</span>)에만 관심이 있고, 이것이 고정된(Time-fixed) 처치라면, 우리는 단순히 <span class="math inline">\(L_1\)</span>에 대해 표준화(Standardization)를 수행하면 됩니다.</li>
</ul>
<p><span class="math display">\[E[Y^{a_1}] = \sum_{l_1} E[Y|A_1=a_1, L_1=l_1] f(l_1)\]</span></p>
<ul>
<li><p>여기서 <span class="math inline">\(f(l_1) = Pr[L_1=l_1]\)</span>은 전체 모집단에서의 교란요인 분포입니다. 이 가중 평균(Weighted Average)이 바로 고정된 처치에 대한 G-formula입니다.</p></li>
<li><p>하지만, <strong>시변 처리(<span class="math inline">\(\bar{A} = (A_0, A_1)\)</span>)</strong> 상황에서는 문제가 복잡해집니다.</p>
<ul>
<li><ol type="1">
<li><strong>Feedback:</strong> <span class="math inline">\(A_0\)</span>가 <span class="math inline">\(L_1\)</span>에 영향을 미칩니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Selection:</strong> <span class="math inline">\(L_1\)</span>이 다시 <span class="math inline">\(A_1\)</span>에 영향을 미칩니다.</li>
</ol></li>
</ul></li>
<li><p>이 경우, 단순한 <span class="math inline">\(L_1\)</span> 조정은 <span class="math inline">\(A_0\)</span>의 효과를 가리거나(Over-adjustment), <span class="math inline">\(L_1\)</span> 자체가 collider가 되어 편향을 유발할 수 있습니다. 따라서 우리는 G-formula를 일반화해야 합니다.</p></li>
</ul>
</section>
</section>
<section id="the-g-formula-for-time-varying-treatments-1" class="level2">
<h2 class="anchored" data-anchor-id="the-g-formula-for-time-varying-treatments-1">3. The G-Formula for Time-Varying Treatments</h2>
<section id="intuition-standardization-by-history" class="level3">
<h3 class="anchored" data-anchor-id="intuition-standardization-by-history">3.1 Intuition: Standardization by History</h3>
<ul>
<li><p>시변 처리에 대한 G-formula의 핵심 아이디어는 <strong>“과거의 역사(History)에 조건부로 가중치를 부여한다”</strong>는 것입니다.</p></li>
<li><p>식별 조건(Identifiability conditions: Sequential Exchangeability, Positivity, Consistency) 하에서, G-formula 추정량은 다음과 같이 정의됩니다:</p></li>
</ul>
<blockquote class="blockquote">
<p><strong>핵심 개념</strong>: G-formula는 연구 모집단의 교란요인 분포로 표준화된 평균 결과를 계산하되, 이 분포는 <strong>이전 시점의 처치 및 교란요인 역사에 조건부(Conditional)</strong>여야 합니다.</p>
</blockquote>
</section>
<section id="mathematical-formulation" class="level3">
<h3 class="anchored" data-anchor-id="mathematical-formulation">3.2 Mathematical Formulation</h3>
<section id="the-g-formula-for-2-time-points-k0-1" class="level4">
<h4 class="anchored" data-anchor-id="the-g-formula-for-2-time-points-k0-1"><strong>1. The G-Formula for 2 Time Points (<span class="math inline">\(k=0, 1\)</span>)</strong></h4>
<ul>
<li>시변 처치(Time-varying treatment) 상황에서 2시점 데이터에 대한 G-formula는 다음과 같습니다.</li>
</ul>
<p><span class="math display">\[E[Y^{a_0, a_1}] = \sum_{l_1} E[Y | A_0=a_0, A_1=a_1, L_1=l_1] \times f(l_1 | A_0=a_0)\]</span></p>
</section>
<section id="time-fixed-vs.-time-varying-comparison" class="level4">
<h4 class="anchored" data-anchor-id="time-fixed-vs.-time-varying-comparison"><strong>2. Time-fixed vs.&nbsp;Time-varying Comparison</strong></h4>
<ul>
<li>이 식의 확률 부분(<span class="math inline">\(f\)</span>)은 고정된 처치(Time-fixed) 연구와 결정적인 차이가 있습니다.
<ul>
<li><strong>Time-fixed (<span class="math inline">\(f(l)\)</span>):</strong> 교란요인 <span class="math inline">\(L\)</span>이 처치 <span class="math inline">\(A\)</span>보다 <strong>먼저</strong> 발생하므로, 처치가 <span class="math inline">\(L\)</span>의 분포에 영향을 주지 않습니다. 따라서 모집단 전체의 주변 분포(marginal distribution)를 사용합니다.</li>
<li><strong>Time-varying (<span class="math inline">\(f(l_1 | a_0)\)</span>):</strong> 교란요인 <span class="math inline">\(L_1\)</span>이 초기 처치 <span class="math inline">\(A_0\)</span> <strong>이후</strong>에 발생합니다. <span class="math inline">\(A_0\)</span>가 <span class="math inline">\(L_1\)</span>에 인과적 영향을 주기 때문에, 개입(<span class="math inline">\(A_0=a_0\)</span>)이 있었을 때의 조건부 확률 분포를 사용해야 합니다.</li>
</ul></li>
</ul>
</section>
<section id="derivation-why-fl_1-a_0" class="level4">
<h4 class="anchored" data-anchor-id="derivation-why-fl_1-a_0"><strong>3. Derivation: Why <span class="math inline">\(f(l_1 | a_0)\)</span>?</strong></h4>
<ul>
<li><p>이 식은 관찰된 데이터의 결합 분포(Joint Distribution)에서 처치 할당 확률을 제거하는 <strong>절단된 분해(Truncated Factorization)</strong> 과정을 통해 유도됩니다.</p></li>
<li><p><strong>Step 1: Chain Rule (관찰 데이터의 분해)</strong></p>
<ul>
<li>관찰된 변수들의 결합 확률은 다음과 같이 분해됩니다. <span class="math display">\[P(Y, A_1, L_1, A_0) = P(Y | A_1, L_1, A_0) \times P(A_1 | L_1, A_0) \times P(L_1 | A_0) \times P(A_0)\]</span></li>
</ul></li>
<li><p><strong>Step 2: Intervention (개입 및 확률 제거)</strong></p>
<ul>
<li>우리가 강제로 <span class="math inline">\(A_0=a_0, A_1=a_1\)</span>로 고정(Intervention)하면, 자연적인 처치 할당 확률인 <span class="math inline">\(P(A_0)\)</span>와 <span class="math inline">\(P(A_1 | L_1, A_0)\)</span>는 더 이상 유효하지 않으므로 식에서 <strong>제거</strong>됩니다. 남은 부분은 자연 법칙(교란요인 생성 및 결과 생성)을 따릅니다. <span class="math display">\[P(Y^{a_0, a_1}=y, L_1^{a_0}=l_1) = P(Y=y | a_1, l_1, a_0) \times P(L_1=l_1 | a_0)\]</span></li>
</ul></li>
<li><p><strong>Step 3: Marginalization (평균 계산)</strong></p>
<ul>
<li>위 식을 모든 가능한 <span class="math inline">\(l_1\)</span>에 대해 합산(또는 적분)하여 <span class="math inline">\(Y\)</span>의 기대값을 구하면 G-formula가 도출됩니다. <span class="math display">\[E[Y^{a_0, a_1}] = \sum_{l_1} \underbrace{E[Y | A_1=a_1, L_1=l_1, A_0=a_0]}_{\text{Outcome Model}} \times \underbrace{f(l_1 | A_0=a_0)}_{\text{Confounder Model}}\]</span></li>
</ul></li>
<li><p>결론적으로 <span class="math inline">\(f(l_1)\)</span>이 아닌 <span class="math inline">\(f(l_1 | a_0)\)</span>를 사용하는 것은, <strong>초기 처치 <span class="math inline">\(A_0\)</span>가 중간 교란요인 <span class="math inline">\(L_1\)</span>의 분포를 변화시키는 인과적 흐름을 반영</strong>하기 위함입니다.</p></li>
</ul>
</section>
</section>
<section id="application-to-the-example" class="level3">
<h3 class="anchored" data-anchor-id="application-to-the-example">3.3 Application to the Example</h3>
<ul>
<li>이제 위에서 본 데이터를 사용하여 실제 인과 효과를 계산해 봅시다. 우리는 “항상 처치(<span class="math inline">\(a_0=1, a_1=1\)</span>)” 전략과 “전혀 처치 안 함(<span class="math inline">\(a_0=0, a_1=0\)</span>)” 전략을 비교합니다.</li>
</ul>
<section id="step-1-전혀-처치-안-함-a_00-a_10" class="level4">
<h4 class="anchored" data-anchor-id="step-1-전혀-처치-안-함-a_00-a_10">Step 1: “전혀 처치 안 함” (<span class="math inline">\(a_0=0, a_1=0\)</span>)</h4>
<p><span class="math display">\[
\begin{aligned}
E[Y^{0,0}] &amp;= \sum_{l_1} E[Y|A_0=0, A_1=0, L_1=l_1] \times P(L_1=l_1|A_0=0) \\
&amp;= E[Y|0,0, L_1=0]P(L_1=0|A_0=0) + E[Y|0,0, L_1=1]P(L_1=1|A_0=0)
\end{aligned}
\]</span></p>
<ul>
<li>Figure 21.1(트리)의 데이터를 대입하면:
<ul>
<li><span class="math inline">\(P(L_1=0|A_0=0) = 0.25\)</span></li>
<li><span class="math inline">\(P(L_1=1|A_0=0) = 0.75\)</span></li>
<li><span class="math inline">\(E[Y|0,0,0] = 84\)</span></li>
<li><span class="math inline">\(E[Y|0,0,1] = 52\)</span></li>
</ul></li>
</ul>
<p><span class="math display">\[\text{Result} = 84 \times 0.25 + 52 \times 0.75 = 21 + 39 = 60\]</span></p>
</section>
<section id="step-2-항상-처치-a_01-a_11" class="level4">
<h4 class="anchored" data-anchor-id="step-2-항상-처치-a_01-a_11">Step 2: “항상 처치” (<span class="math inline">\(a_0=1, a_1=1\)</span>)</h4>
<p><span class="math display">\[
\begin{aligned}
E[Y^{1,1}] &amp;= \sum_{l_1} E[Y|A_0=1, A_1=1, L_1=l_1] \times P(L_1=l_1|A_0=1) \\
&amp;= E[Y|1,1,0]P(L_1=0|1) + E[Y|1,1,1]P(L_1=1|1)
\end{aligned}
\]</span></p>
<ul>
<li>데이터 대입:
<ul>
<li><span class="math inline">\(P(L_1=0|A_0=1) = 0.50\)</span></li>
<li><span class="math inline">\(P(L_1=1|A_0=1) = 0.50\)</span></li>
<li><span class="math inline">\(E[Y|1,1,0] = 76\)</span></li>
<li><span class="math inline">\(E[Y|1,1,1] = 44\)</span></li>
</ul></li>
</ul>
<p><span class="math display">\[\text{Result} = 76 \times 0.50 + 44 \times 0.50 = 38 + 22 = 60\]</span></p>
</section>
<section id="step-3-causal-effect" class="level4">
<h4 class="anchored" data-anchor-id="step-3-causal-effect">Step 3: Causal Effect</h4>
<p><span class="math display">\[\text{Effect} = E[Y^{1,1}] - E[Y^{0,0}] = 60 - 60 = 0\]</span></p>
<ul>
<li>전통적인 방법론이 실패했던 것과 달리, G-formula는 <strong>정확한 인과 효과인 0(Null)을 성공적으로 추정</strong>해냈습니다.</li>
</ul>
</section>
</section>
</section>
<section id="g-formula-as-a-simulation" class="level2">
<h2 class="anchored" data-anchor-id="g-formula-as-a-simulation">4. G-Formula as a Simulation</h2>
<ul>
<li><p>G-formula를 이해하는 또 다른 강력한 직관은 <strong>시뮬레이션(Simulation)</strong>입니다.</p></li>
<li><p>순차적 교환가능성(Sequential Exchangeability)이 성립한다면, G-formula는 연구 모집단의 모든 개체가 특정 전략 <span class="math inline">\(\bar{a}\)</span>를 따랐을 때 관찰되었을 반사실적(Counterfactual) 결과 <span class="math inline">\(Y^{\bar{a}}\)</span>와 공변량 역사 <span class="math inline">\(\bar{L}^{\bar{a}}\)</span>의 결합 분포를 시뮬레이션하는 과정으로 볼 수 있습니다.</p></li>
</ul>
<section id="constructing-the-counterfactual-tree" class="level3">
<h3 class="anchored" data-anchor-id="constructing-the-counterfactual-tree">4.1 Constructing the Counterfactual Tree</h3>
<ul>
<li>이 시뮬레이션은 원래의 트리(Figure 21.1)를 수정하여 새로운 <strong>반사실적 트리(Counterfactual Tree)</strong>를 만드는 것과 같습니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/figure_21_2.png" class="img-fluid figure-img"></p>
<figcaption>Figure 21.2: “항상 처치(<span class="math inline">\(a_0=1, a_1=1\)</span>)” 전략 하에서의 반사실적 트리. <span class="math inline">\(A_0\)</span>와 <span class="math inline">\(A_1\)</span>의 확률은 1로 고정되지만, <span class="math inline">\(L_1\)</span>의 조건부 확률(<span class="math inline">\(P(L_1|A_0)\)</span>)과 조건부 평균 결과(<span class="math inline">\(E[Y|\dots]\)</span>)는 원본 데이터에서 그대로 가져와 보존된다.</figcaption>
</figure>
</div>
<ul>
<li>위 그림(Figure 21.2)은 모든 개체가 <span class="math inline">\(A_0=1, A_1=1\)</span>을 따랐을 때의 세상을 보여줍니다.
<ul>
<li><ol type="1">
<li><strong>Treatment Assignment:</strong> <span class="math inline">\(k=0, 1\)</span> 시점의 처치 확률을 1로 할당합니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Covariate &amp; Outcome:</strong> 하지만 <span class="math inline">\(P(L_1=l_1|A_0=a_0)\)</span>와 <span class="math inline">\(E[Y|A_0=a_0, A_1=a_1, L_1=l_1]\)</span> 값은 <strong>원본 모집단의 값</strong>을 그대로 가져옵니다.</li>
</ol></li>
</ul></li>
<li>이것이 바로 G-formula가 수학적으로 수행하는 작업입니다.</li>
</ul>
</section>
<section id="why-history-matters-fine-point-21.1" class="level3">
<h3 class="anchored" data-anchor-id="why-history-matters-fine-point-21.1">4.2 Why History Matters (Fine Point 21.1)</h3>
<ul>
<li><p>G-formula에서 “역사(History)”에 조건부 확률을 구한다고 할 때, 이 역사는 반드시 시간적(Chronological) 순서만을 의미하는 것은 아닙니다.</p></li>
<li><p>인과적 구조상 <span class="math inline">\(A_k\)</span>의 교환가능성을 확보하기 위해 필요한 교란요인들의 집합을 의미합니다.</p></li>
<li><p>일반적으로는 시간적 과거가 맞지만, 이론적으로는 미래의 변수라도 교란요인이 될 수 있습니다.</p></li>
<li><p>하지만, 단순히 시간적 과거에 있다고 해서 모두 조정하면 안 됩니다. M-bias를 유발하는 변수(Colliders)는 제외해야 합니다.</p></li>
</ul>
</section>
</section>
<section id="generalization-high-dimensional-g-formula" class="level2">
<h2 class="anchored" data-anchor-id="generalization-high-dimensional-g-formula">5. Generalization: High-Dimensional G-Formula</h2>
<ul>
<li>현실 세계의 데이터는 훨씬 복잡합니다. 시점 <span class="math inline">\(K\)</span>까지 다수의 시변 교란요인 <span class="math inline">\(L_k\)</span>가 존재하는 경우, G-formula는 다음과 같이 일반화됩니다. <span class="math display">\[E[Y^{\bar{a}}] = \sum_{\bar{l}} E[Y|\bar{A}=\bar{a}, \bar{L}=\bar{l}] \prod_{k=0}^{K} f(l_k | \bar{a}_{k-1}, \bar{l}_{k-1})\]</span>
<ul>
<li><span class="math inline">\(\sum_{\bar{l}}\)</span>: 가능한 모든 공변량 역사(<span class="math inline">\(l_0, l_1, \dots, l_K\)</span>)에 대한 합입니다.</li>
<li><span class="math inline">\(\prod_{k=0}^{K}\)</span>: 각 시점 <span class="math inline">\(k\)</span>에서, 과거 역사(<span class="math inline">\(\bar{a}_{k-1}, \bar{l}_{k-1}\)</span>)가 주어졌을 때 현재 교란요인(<span class="math inline">\(l_k\)</span>)이 나타날 조건부 확률의 곱입니다.</li>
</ul></li>
</ul>
<section id="the-plug-in-g-formula" class="level3">
<h3 class="anchored" data-anchor-id="the-plug-in-g-formula">5.1 The Plug-in G-Formula</h3>
<ul>
<li>고차원 데이터에서는 모든 가능한 <span class="math inline">\(\bar{l}\)</span> 조합에 대해 빈도수를 세는 것이 불가능합니다. 따라서 우리는 모수적 모델(Parametric Models)을 사용해야 합니다.
<ul>
<li><ol type="1">
<li><strong>Outcome Model:</strong> <span class="math inline">\(E[Y|\bar{A}, \bar{L}]\)</span>을 추정하기 위한 회귀모형 (예: 선형 회귀).</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Covariate Models:</strong> 각 시점 <span class="math inline">\(k\)</span>별로 <span class="math inline">\(f(l_k|\bar{a}_{k-1}, \bar{l}_{k-1})\)</span>을 추정하기 위한 모델 (예: 로지스틱 회귀).</li>
</ol></li>
</ul></li>
<li>이렇게 추정된 값들을 위 공식에 대입(Plug-in)하여 계산하는 방식을 <strong>Parametric G-formula</strong>라고 부릅니다.</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="ip-weighting-for-time-varying-treatments" class="level1">
<h1>21.2 IP weighting for time-varying treatments</h1>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">1. Introduction</h2>
<ul>
<li><p>이전 장들에서 우리는 고정된 시점의 처치(Time-fixed treatment)에 대한 인과 효과를 추정하기 위해 <strong>IP Weighting (Inverse Probability Weighting)</strong>을 사용하는 방법을 다루었습니다. 하지만 현실의 데이터, 특히 사회과학이나 의료 데이터는 처치와 교란요인(Confounder)이 시간의 흐름에 따라 변하는 <strong>Time-varying</strong> 구조를 가집니다.</p></li>
<li><p>본 포스트에서는 Hernán &amp; Robins의 <em>What If</em> Chapter 21.2를 바탕으로, 이러한 시변(Time-varying) 환경에서 IP Weighting을 어떻게 일반화할 수 있는지, 그리고 이를 통해 <strong>Marginal Structural Model (MSM)</strong>을 어떻게 추정하는지 상세히 정리합니다.</p></li>
</ul>
</section>
<section id="ip-weighting-for-time-varying-treatments-1" class="level2">
<h2 class="anchored" data-anchor-id="ip-weighting-for-time-varying-treatments-1">2. IP Weighting for Time-Varying Treatments</h2>
<section id="motivation-why-generalize" class="level3">
<h3 class="anchored" data-anchor-id="motivation-why-generalize">2.1. Motivation: Why Generalize?</h3>
<ul>
<li><p>고정된 처치(Time-fixed treatment) <span class="math inline">\(A\)</span>에 대한 IP Weighting의 핵심 아이디어는 각 개인에게 <span class="math inline">\(1/f(A|L)\)</span>의 가중치를 부여하여, 교란요인 <span class="math inline">\(L\)</span>과 처치 <span class="math inline">\(A\)</span> 사이의 연결을 끊어버리는 <strong>가상 모집단(Pseudo-population)</strong>을 생성하는 것이었습니다.</p></li>
<li><p>처치가 시간 흐름에 따라 <span class="math inline">\(k=0, 1, \dots, K\)</span> 시점에 걸쳐 이루어지는 경우(<span class="math inline">\(\bar{A} = (A_0, A_1, \dots, A_K)\)</span>), 우리는 각 시점마다 교란요인 <span class="math inline">\(\bar{L}_k\)</span>에 의해 처치 확률이 달라지는 상황을 마주하게 됩니다. 따라서 가중치 또한 시간의 흐름에 따른 조건부 확률들의 곱으로 확장되어야 합니다.</p></li>
</ul>
</section>
<section id="construction-of-weights" class="level3">
<h3 class="anchored" data-anchor-id="construction-of-weights">2.2. Construction of Weights</h3>
<ul>
<li>Time-varying treatment <span class="math inline">\(\bar{A}\)</span>와 Time-varying covariates <span class="math inline">\(\bar{L}\)</span>이 존재할 때, 가중치는 다음과 같이 정의됩니다.</li>
</ul>
<section id="non-stabilized-weights-wbara" class="level4">
<h4 class="anchored" data-anchor-id="non-stabilized-weights-wbara">Non-stabilized Weights (<span class="math inline">\(W^{\bar{A}}\)</span>)</h4>
<ul>
<li>비안정화 가중치는 각 시점 <span class="math inline">\(k\)</span>에서 관측된 과거 이력(<span class="math inline">\(\bar{A}_{k-1}, \bar{L}_k\)</span>)이 주어졌을 때, 해당 개인이 실제로 받은 처치(<span class="math inline">\(A_k\)</span>)를 받을 확률의 역수를 누적하여 계산합니다. <span class="math display">\[
W^{\bar{A}} = \prod_{k=0}^{K} \frac{1}{f(A_k | \bar{A}_{k-1}, \bar{L}_k)}
\]</span>
<ul>
<li>여기서 <span class="math inline">\(f(\cdot)\)</span>는 조건부 확률 밀도 함수(또는 질량 함수)를 의미합니다.</li>
</ul></li>
</ul>
</section>
<section id="stabilized-weights-swbara" class="level4">
<h4 class="anchored" data-anchor-id="stabilized-weights-swbara">Stabilized Weights (<span class="math inline">\(SW^{\bar{A}}\)</span>)</h4>
<ul>
<li>비안정화 가중치는 분모의 확률이 매우 작을 경우 가중치가 극단적으로 커져 추정량의 분산(Variance)을 폭발시킬 위험이 있습니다. 이를 방지하기 위해 분자에 처치의 주변 확률(Marginal probability)을 포함한 안정화 가중치를 사용합니다. <span class="math display">\[
SW^{\bar{A}} = \prod_{k=0}^{K} \frac{f(A_k | \bar{A}_{k-1})}{f(A_k | \bar{A}_{k-1}, \bar{L}_k)}
\]</span>
<ul>
<li><strong>분모 (Denominator):</strong> 과거의 처치 및 <strong>교란요인 이력(<span class="math inline">\(\bar{L}_k\)</span>)</strong>을 모두 고려했을 때, 현재 처치를 받을 확률. 이는 인과적 연결을 끊는 역할을 합니다.</li>
<li><strong>분자 (Numerator):</strong> 과거의 <strong>처치 이력(<span class="math inline">\(\bar{A}_{k-1}\)</span>)</strong>만 고려했을 때, 현재 처치를 받을 확률. 이는 가중치의 변동성을 줄여줍니다.</li>
</ul></li>
</ul>
<blockquote class="blockquote">
<p><strong>Important:</strong> 안정화 가중치를 사용하더라도 가상 모집단에서의 평균 인과 효과(Average Causal Effect) 추정치는 비안정화 가중치를 사용했을 때와 동일합니다 (Identifiability 조건 하에서). 단, 추정의 효율성(Efficiency) 측면에서 안정화 가중치가 선호됩니다.</p>
</blockquote>
</section>
</section>
<section id="pseudo-population-interpretation" class="level3">
<h3 class="anchored" data-anchor-id="pseudo-population-interpretation">2.3. Pseudo-population Interpretation</h3>
<ul>
<li>이 가중치들을 적용하여 생성된 가상 모집단에서는 다음과 같은 특성이 성립합니다:
<ul>
<li><ol type="1">
<li><strong>Non-stabilized:</strong> 각 시점 <span class="math inline">\(k\)</span>에서의 처치 <span class="math inline">\(A_k\)</span>는 과거 이력과 무관하게 완전히 무작위 할당된 것처럼 동작합니다 (Randomization probability = constant).</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Stabilized:</strong> 각 시점 <span class="math inline">\(k\)</span>에서의 처치 <span class="math inline">\(A_k\)</span>는 오직 과거 처치 이력 <span class="math inline">\(\bar{A}_{k-1}\)</span>에만 의존하며, 교란요인 <span class="math inline">\(\bar{L}_k\)</span>와는 독립이 됩니다.</li>
</ol></li>
</ul></li>
<li>즉, <strong>Sequential Unconditional Exchangeability</strong>가 성립하게 되어, 연관성(Association)이 곧 인과성(Causation)이 되는 구조가 만들어집니다.</li>
</ul>
</section>
</section>
<section id="illustration-a-worked-example" class="level2">
<h2 class="anchored" data-anchor-id="illustration-a-worked-example">3. Illustration: A Worked Example</h2>
<ul>
<li>교재의 Figure 21.3에 제시된 예제를 통해 IP Weighting이 어떻게 작동하는지 구체적으로 살펴보겠습니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/figure_21_3.png" class="img-fluid figure-img"></p>
<figcaption>Figure 21.3: Tree graph representing the pseudo-population created by IP weighting. The graph explicitly shows the number of individuals (<span class="math inline">\(N_W\)</span>) in the pseudo-population for each treatment and covariate history, alongside the calculated weights (<span class="math inline">\(W^{\bar{A}}\)</span> and <span class="math inline">\(SW^{\bar{A}}\)</span>). This visualizes how the original population is re-weighted to remove confounding.</figcaption>
</figure>
</div>
<section id="setting" class="level3">
<h3 class="anchored" data-anchor-id="setting">Setting</h3>
<ul>
<li>총 인구: 32,000명</li>
<li>우리의 목표: <span class="math inline">\(E[Y^{a_0=1, a_1=1}]\)</span>과 <span class="math inline">\(E[Y^{a_0=0, a_1=0}]\)</span>의 차이, 즉 인과 효과를 추정하는 것입니다.</li>
<li>데이터 구조: <span class="math inline">\(L_0\)</span>는 없으며, 시점 <span class="math inline">\(k=0, 1\)</span>에 대한 처치와 <span class="math inline">\(L_1\)</span>이 존재합니다.</li>
</ul>
</section>
<section id="calculation" class="level3">
<h3 class="anchored" data-anchor-id="calculation">Calculation</h3>
<ul>
<li><p>비안정화 가중치를 적용한 가상 모집단에서의 평균 <span class="math inline">\(E_{ps}[Y | A_0=0, A_1=0]\)</span>을 계산해 봅시다.</p></li>
<li><ol type="1">
<li>트리 그래프(Figure 21.3)에서 <span class="math inline">\((A_0=0, A_1=0)\)</span> 경로를 따르는 모든 개체를 찾습니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li>해당 경로의 가중치 <span class="math inline">\(W\)</span>와 결과값 <span class="math inline">\(Y\)</span>를 사용하여 가중 평균을 구합니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li>계산 결과: <span class="math display">\[
  E_{ps}[Y | \bar{a}=\bar{0}] = 84 \times \frac{8000}{32000} + 52 \times \frac{24000}{32000} = 21 + 39 = 60
  \]</span></li>
</ol></li>
<li><p>동일한 방식으로 <span class="math inline">\(E_{ps}[Y | \bar{a}=\bar{1}]\)</span>을 계산하면 역시 60이 나옵니다. 따라서 추정된 인과 효과는 <span class="math inline">\(60 - 60 = 0\)</span>입니다. 이는 g-formula를 사용했을 때 얻은 결과와 정확히 일치합니다.</p></li>
</ul>
<blockquote class="blockquote">
<p><strong>Insight:</strong> g-formula와 IP Weighting은 Identifiability 조건이 성립하지 않더라도(즉, 인과적 해석이 불가능하더라도) 수치적으로는 동일한 값을 산출합니다. 이는 두 방법론이 동일한 통계적 구조를 공유함을 시사합니다.</p>
</blockquote>
</section>
</section>
<section id="marginal-structural-models-msms" class="level2">
<h2 class="anchored" data-anchor-id="marginal-structural-models-msms">4. Marginal Structural Models (MSMs)</h2>
<section id="the-curse-of-dimensionality" class="level3">
<h3 class="anchored" data-anchor-id="the-curse-of-dimensionality">4.1. The Curse of Dimensionality</h3>
<ul>
<li><p>시점이 <span class="math inline">\(K\)</span>개로 늘어나면 가능한 처치 전략 <span class="math inline">\(\bar{a}\)</span>의 수는 <span class="math inline">\(2^K\)</span>개로 기하급수적으로 증가합니다. 데이터가 아무리 많아도 모든 가능한 처치 이력에 대해 평균 <span class="math inline">\(E[Y^{\bar{a}}]\)</span>를 비모수적(Non-parametric)으로 추정하는 것은 불가능에 가깝습니다.</p></li>
<li><p>이를 해결하기 위해 우리는 처치 이력 <span class="math inline">\(\bar{a}\)</span>를 요약하는 파라메트릭 모델인 <strong>Marginal Structural Model (MSM)</strong>을 도입합니다.</p></li>
</ul>
</section>
<section id="model-specification" class="level3">
<h3 class="anchored" data-anchor-id="model-specification">4.2. Model Specification</h3>
<ul>
<li>가장 일반적인 형태는 <strong>누적 처치량(Cumulative treatment)</strong>, <span class="math inline">\(\text{cum}(\bar{a}) = \sum_{k=0}^K a_k\)</span>에 선형적으로 의존한다고 가정하는 것입니다. <span class="math display">\[
E[Y^{\bar{a}}] = \beta_0 + \beta_1 \text{cum}(\bar{a})
\]</span>
<ul>
<li><span class="math inline">\(\beta_1\)</span>: 누적 처치량이 1단위 증가할 때 평균 결과값의 변화량(인과 효과).</li>
<li>이 모델은 <span class="math inline">\(2^K\)</span>개의 미지수를 단 2개의 파라미터(<span class="math inline">\(\beta_0, \beta_1\)</span>)로 축소시킵니다.</li>
</ul></li>
</ul>
</section>
<section id="estimation-via-weighted-least-squares-wls" class="level3">
<h3 class="anchored" data-anchor-id="estimation-via-weighted-least-squares-wls">4.3. Estimation via Weighted Least Squares (WLS)</h3>
<ul>
<li>이 MSM의 파라미터는 관측된 데이터에 대해 <strong>IP 가중치(<span class="math inline">\(SW^{\bar{A}}\)</span>)를 적용한 가중 최소 자승법(Weighted Least Squares, WLS)</strong>으로 추정할 수 있습니다.</li>
</ul>
<p><span class="math display">\[
E[Y | \bar{A}] = \theta_0 + \theta_1 \text{cum}(\bar{A}) \quad \text{(Weighted by } SW^{\bar{A}} \text{)}
\]</span></p>
<ul>
<li>Identifiability 조건 하에서, WLS로 추정된 <span class="math inline">\(\hat{\theta}_1\)</span>은 인과 파라미터 <span class="math inline">\(\beta_1\)</span>에 대해 일치 추정량(Consistent estimator)이 됩니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Note on Variance:</strong> 추정량의 분산은 Non-parametric Bootstrap을 사용하거나, Robust Variance Estimator(Sandwich estimator)를 통해 구할 수 있습니다. 일반적으로 안정화 가중치(<span class="math inline">\(SW^{\bar{A}}\)</span>)를 사용하면 신뢰구간의 폭이 더 좁아져 효율적입니다.</p>
</blockquote>
</section>
<section id="model-misspecification-diagnostics" class="level3">
<h3 class="anchored" data-anchor-id="model-misspecification-diagnostics">4.4. Model Misspecification &amp; Diagnostics</h3>
<ul>
<li><p>만약 실제 인과 효과가 누적 처치량의 제곱에 비례하거나, 특정 시점의 처치에만 의존한다면 위 선형 모델은 <strong>Misspecified</strong> 된 것입니다.</p></li>
<li><p>이를 검증하기 위해 더 복잡한 항(예: <span class="math inline">\(cum(\bar{A})^2\)</span> 또는 최근 5개월간의 처치량 등)을 모델에 추가하고, 해당 계수들이 0인지 검정(Wald test)하여 모델의 적합성을 평가할 수 있습니다. 다행히 IP Weighting 기반의 MSM은 g-formula와 달리 <strong>“g-null paradox”</strong>의 영향을 받지 않습니다.</p></li>
</ul>
</section>
</section>
<section id="practical-implementation-details" class="level2">
<h2 class="anchored" data-anchor-id="practical-implementation-details">5. Practical Implementation Details</h2>
<ul>
<li><p>실제 연구(Observational Study)에서는 <span class="math inline">\(f(A_k | \dots)\)</span>를 알 수 없으므로 데이터를 통해 추정해야 합니다.</p></li>
<li><ol type="1">
<li><strong>Propensity Score Estimation:</strong> 각 시점 <span class="math inline">\(k\)</span>마다 로지스틱 회귀분석 등을 사용하여 <span class="math inline">\(Pr[A_k=1 | \bar{A}_{k-1}, \bar{L}_k]\)</span>를 추정합니다.</li>
</ol>
<ul>
<li>보통은 데이터를 ’Long format’으로 변환한 후, 시간 <span class="math inline">\(k\)</span>를 공변량으로 포함하여 하나의 통합된 모델(Pooled logistic regression)을 적합합니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Weight Calculation:</strong> 추정된 확률 <span class="math inline">\(\hat{f}\)</span>를 사용하여 <span class="math inline">\(W^{\bar{A}}\)</span> 또는 <span class="math inline">\(SW^{\bar{A}}\)</span>를 계산합니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>WLS:</strong> 계산된 가중치를 적용하여 MSM을 적합합니다.</li>
</ol></li>
</ul>
</section>
<section id="effect-modification-효과-변경" class="level2">
<h2 class="anchored" data-anchor-id="effect-modification-효과-변경">6. Effect Modification (효과 변경)</h2>
<ul>
<li>기본적인 MSM은 전체 인구의 평균적인 인과 효과를 추정하지만, 때로는 <strong>“처치의 효과가 특정 집단에서 더 강력하게 나타나는가?”</strong>를 확인해야 할 때가 있습니다. 이를 <strong>효과 변경(Effect Modification)</strong>이라고 합니다.</li>
</ul>
<section id="definition-of-variable-v" class="level3">
<h3 class="anchored" data-anchor-id="definition-of-variable-v">6.1 Definition of Variable <span class="math inline">\(V\)</span></h3>
<ul>
<li><strong>정의:</strong> <span class="math inline">\(V\)</span>는 기저 교란요인(Baseline Covariates, <span class="math inline">\(L_0\)</span>) 중 연구자가 특별히 관심을 갖는 <strong>일부 변수의 집합</strong>입니다 (예: 성별, 연령대, 유전자 변이 여부 등).</li>
<li><strong>조건:</strong> <span class="math inline">\(V\)</span>는 반드시 처치가 시작되기 전인 <strong>기저 시점(Time 0)</strong>에 측정된 변수여야 합니다. <span class="math inline">\(k&gt;0\)</span> 시점의 시변 변수를 <span class="math inline">\(V\)</span>로 사용할 경우, 처치의 결과일 수 있어 해석이 매우 복잡해지거나 불가능해집니다.</li>
</ul>
</section>
<section id="the-model-with-interaction" class="level3">
<h3 class="anchored" data-anchor-id="the-model-with-interaction">6.2 The Model with Interaction</h3>
<ul>
<li><span class="math inline">\(V\)</span>에 따른 효과 차이를 확인하기 위해, MSM에 교차항(Interaction term)을 추가하여 다음과 같이 모델링합니다.</li>
</ul>
<p><span class="math display">\[
E[Y^{\bar{a}} | V] = \beta_0 + \beta_1 \text{cum}(\bar{a}) + \beta_2 V + \beta_3 \text{cum}(\bar{a})V
\]</span></p>
<ul>
<li><strong>파라미터 해석:</strong>
<ul>
<li><span class="math inline">\(\beta_1\)</span>: <span class="math inline">\(V=0\)</span>인 집단에서의 처치 효과.</li>
<li><span class="math inline">\(\beta_3\)</span>: <strong>효과 변경의 크기</strong>. 즉, <span class="math inline">\(V=1\)</span> 집단과 <span class="math inline">\(V=0\)</span> 집단 간의 처치 효과 차이입니다. (<span class="math inline">\(\beta_3 \neq 0\)</span>이면 효과 변경이 존재함)</li>
<li><span class="math inline">\(\beta_1 + \beta_3\)</span>: <span class="math inline">\(V=1\)</span>인 집단에서의 처치 효과.</li>
</ul></li>
</ul>
</section>
<section id="estimation-with-modified-weights" class="level3">
<h3 class="anchored" data-anchor-id="estimation-with-modified-weights">6.3 Estimation with Modified Weights</h3>
<ul>
<li><p>이 모델을 추정할 때는 <span class="math inline">\(V\)</span>를 고려하여 수정된 <strong>안정화 가중치 <span class="math inline">\(SW^{\bar{A}}(V)\)</span></strong>를 사용해야 합니다.</p></li>
<li><p><strong>가중치의 변화:</strong></p>
<ul>
<li>기존 분자: <span class="math inline">\(P(A)\)</span> (전체 평균 확률)</li>
<li><strong>수정된 분자:</strong> <span class="math inline">\(P(A|V)\)</span> (변수 <span class="math inline">\(V\)</span>에 따라 조건부로 계산된 확률)</li>
</ul></li>
</ul>
<p><span class="math display">\[SW^{\bar{A}}(V) = \prod_{k=0}^{K} \frac{f(A_k | \bar{A}_{k-1}, V)}{f(A_k | \bar{A}_{k-1}, \bar{L}_k)}\]</span></p>
<ul>
<li><strong>이점:</strong> 모델 식 자체에 이미 <span class="math inline">\(V\)</span>가 포함되어 있으므로(<span class="math inline">\(\beta_2 V\)</span>), 가중치를 통해 <span class="math inline">\(V\)</span>의 교란 효과를 제거할 필요가 없습니다. 따라서 분자에서 <span class="math inline">\(V\)</span>를 조건부로 잡아줌으로써 가중치의 변동성을 줄이고, 결과적으로 <strong>추정의 효율성(Efficiency)을 높여 신뢰구간을 좁힐 수 있습니다</strong>.</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="a-doubly-robust-estimator-for-time-varying-treatments" class="level1">
<h1>21.3 A doubly robust estimator for time-varying treatments</h1>
<section id="introduction-왜-이중-강건인가" class="level2">
<h2 class="anchored" data-anchor-id="introduction-왜-이중-강건인가">1. Introduction: 왜 ’이중 강건’인가?</h2>
<ul>
<li><p>인과추론, 특히 시변(Time-varying) 처리가 존재하는 복잡한 관찰 연구에서 우리는 보통 두 가지 거대한 방법론의 줄기를 마주합니다.</p>
<ul>
<li><ol type="1">
<li><strong>IP Weighting (Inverse Probability Weighting):</strong> 처리(Treatment) 모형 <span class="math inline">\(P(A|L)\)</span>을 정확히 맞춰야 함.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>G-formula (Parametric G-formula):</strong> 결과(Outcome) 모형 <span class="math inline">\(E[Y|A, L]\)</span>을 정확히 맞춰야 함.</li>
</ol></li>
</ul></li>
<li><p>하지만 현실 데이터에서 모델을 완벽하게 명시(Specification)하는 것은 매우 어렵습니다. 만약 모델이 틀리면 어떻게 될까요? 특히 Parametric G-formula의 경우, “G-null Paradox”라고 불리는 현상이 발생할 수 있습니다. 이는 귀무가설(Null hypothesis)이 참임에도 불구하고, 모델의 오설정(misspecification)만으로 인해 귀무가설을 기각해버리는 편향(Bias)이 발생할 수 있다는 이론적 문제입니다.</p></li>
<li><p>여기서 <strong>이중 강건 추정량(Doubly Robust Estimator, DR)</strong>이 등장합니다. 이름에서 알 수 있듯이, 이 방법은 우리에게 <strong>“두 번의 기회(Two chances)”</strong>를 줍니다.</p></li>
</ul>
<blockquote class="blockquote">
<p><strong>핵심 아이디어:</strong> 처리 모형(Propensity score) <strong>또는</strong> 결과 모형(Outcome regression) 중 <strong>하나만이라도</strong> 맞으면, 추정값은 일치성(Consistency)을 가집니다.</p>
</blockquote>
<ul>
<li>이 글에서는 Hernán &amp; Robins의 <em>What If</em> Chapter 21.3을 바탕으로, 시점 고정(Time-fixed) 상황에서 시작하여 시변(Time-varying) 상황으로 확장되는 DR 추정량의 알고리즘을 상세히 다룹니다.</li>
</ul>
</section>
<section id="warm-up-시점-고정time-fixed-처리에서의-dr" class="level2">
<h2 class="anchored" data-anchor-id="warm-up-시점-고정time-fixed-처리에서의-dr">2. Warm-up: 시점 고정(Time-fixed) 처리에서의 DR</h2>
<ul>
<li>복잡한 시변 처리를 다루기 전에, 단일 시점 처리(<span class="math inline">\(A\)</span>)와 결과(<span class="math inline">\(Y\)</span>), 그리고 교란변수(<span class="math inline">\(L\)</span>)가 있는 상황을 먼저 살펴보겠습니다. Bang and Robins (2005)가 제안한 이 방법론은 이후 시변 처리로 확장되는 기초가 됩니다.</li>
</ul>
<section id="알고리즘-개요" class="level3">
<h3 class="anchored" data-anchor-id="알고리즘-개요">알고리즘 개요</h3>
<ul>
<li>우리의 목표는 <span class="math inline">\(E[Y^{a=1}]\)</span>과 <span class="math inline">\(E[Y^{a=0}]\)</span>을 추정하여 인과 효과를 구하는 것입니다.</li>
</ul>
<section id="step-1-처리-모형-추정-propensity-score" class="level4">
<h4 class="anchored" data-anchor-id="step-1-처리-모형-추정-propensity-score">Step 1: 처리 모형 추정 (Propensity Score)</h4>
<ul>
<li>먼저, 처리(<span class="math inline">\(A\)</span>)에 대한 확률 모형을 적합합니다. <span class="math display">\[
\hat{f}(a|L) \equiv \widehat{Pr}[A=a|L]
\]</span></li>
<li>여기서 예측된 확률의 역수를 <strong>가중치(Weight)</strong>로 사용합니다. 이를 <span class="math inline">\(\hat{W}^a = \frac{1}{\hat{f}(a|L)}\)</span>라고 정의합시다.</li>
</ul>
</section>
<section id="step-2-결과-모형-추정-clever-covariate" class="level4">
<h4 class="anchored" data-anchor-id="step-2-결과-모형-추정-clever-covariate">Step 2: 결과 모형 추정 (Clever Covariate)</h4>
<ul>
<li>이 단계가 핵심입니다. <span class="math inline">\(Y\)</span>에 대한 회귀 모형을 적합하되, <strong>Step 1에서 구한 가중치 <span class="math inline">\(\hat{W}^a\)</span>를 공변량(Covariate)으로 추가</strong>합니다. <span class="math display">\[
b(a, L; \theta) = \text{expit}(\theta_{a,0} + \theta_{a,1}L + \theta_{a,2}\hat{W}^a)
\]</span>
<ul>
<li>Note: <span class="math inline">\(\text{expit}(x) = \frac{e^x}{1+e^x}\)</span></li>
</ul></li>
<li>이 회귀식은 <span class="math inline">\(A=a\)</span>인 집단(실제 처리를 받은 집단)에 대해서만 적합(Fit)합니다.</li>
</ul>
</section>
<section id="step-3-표준화-standardization" class="level4">
<h4 class="anchored" data-anchor-id="step-3-표준화-standardization">Step 3: 표준화 (Standardization)</h4>
<ul>
<li>Step 2에서 구한 회귀 계수 <span class="math inline">\(\hat{\theta}\)</span>를 사용하여, <strong>전체 표본(Treated + Untreated)</strong>에 대해 예측값을 구하고 평균을 냅니다.</li>
</ul>
<p><span class="math display">\[
\hat{E}[Y^a] = \frac{1}{n} \sum_{i=1}^{n} b(a, L_i; \hat{\theta})
\]</span></p>
<ul>
<li>이렇게 구한 <span class="math inline">\(\hat{E}[Y^{a=1}] - \hat{E}[Y^{a=0}]\)</span>은 이중 강건 성질을 가집니다.</li>
</ul>
</section>
</section>
</section>
<section id="time-varying-treatment로의-확장" class="level2">
<h2 class="anchored" data-anchor-id="time-varying-treatment로의-확장">3. Time-Varying Treatment로의 확장</h2>
<ul>
<li><p>이제 시간이 <span class="math inline">\(k=0, 1, \dots, K\)</span>로 흐르는 동적 상황으로 확장해 봅시다. 우리는 특정 처치 전략 <span class="math inline">\(\overline{a}\)</span> (예: “항상 처치받음”) 하에서의 반사실적 평균 <span class="math inline">\(E[Y^{\overline{a}}]\)</span>를 추정하고 싶습니다.</p></li>
<li><p>설명의 편의를 위해 <strong>“모든 시점에서 처치받음 (<span class="math inline">\(\overline{a} = \overline{1}\)</span>)”</strong> 전략을 기준으로 설명합니다.</p></li>
</ul>
<section id="step-1-순차적-처리-모형-sequential-treatment-models" class="level3">
<h3 class="anchored" data-anchor-id="step-1-순차적-처리-모형-sequential-treatment-models">Step 1: 순차적 처리 모형 (Sequential Treatment Models)</h3>
<ul>
<li>모든 시점 <span class="math inline">\(k\)</span>에 대해 처리 확률 모형 <span class="math inline">\(\pi_k\)</span>를 적합합니다. <span class="math display">\[
\pi_k(\overline{L}_k; \alpha) = Pr[A_k=1 | \overline{A}_{k-1}=\overline{1}_{k-1}, \overline{L}_k]
\]</span></li>
<li>이때, <span class="math inline">\(k-1\)</span> 시점까지 계속 처치를 받은 사람들(<span class="math inline">\(\overline{A}_{k-1}=\overline{1}_{k-1}\)</span>)만을 대상으로 데이터를 풀링(pooling)하여 적합합니다.</li>
</ul>
<section id="시변-가중치-계산" class="level4">
<h4 class="anchored" data-anchor-id="시변-가중치-계산">시변 가중치 계산</h4>
<ul>
<li>각 시점 <span class="math inline">\(m\)</span>까지 처치받은 사람들을 위한 누적 가중치 <span class="math inline">\(W^{\overline{1}_m}\)</span>을 계산합니다. 이는 Time-fixed 때와 달리 매 시점마다 누적된 확률의 역수입니다.</li>
</ul>
<p><span class="math display">\[
\hat{W}^{\overline{1}_m} = \prod_{k=0}^{m} \frac{1}{\hat{\pi}_k(\overline{L}_k)}
\]</span></p>
</section>
</section>
<section id="step-2-순차적-결과-모형-sequential-outcome-models" class="level3">
<h3 class="anchored" data-anchor-id="step-2-순차적-결과-모형-sequential-outcome-models">Step 2: 순차적 결과 모형 (Sequential Outcome Models)</h3>
<ul>
<li><p>이 부분이 알고리즘적으로 가장 흥미로운 부분입니다. <strong>미래 시점(<span class="math inline">\(K\)</span>)에서 현재 시점(<span class="math inline">\(0\)</span>)으로 시간을 거슬러 올라가는(Backward) 방식</strong>을 사용합니다. 이를 흔히 <strong>Iterative Conditional Expectation (ICE)</strong> 방식이라고도 부릅니다.</p></li>
<li><p>각 시점 <span class="math inline">\(m\)</span> (<span class="math inline">\(K\)</span>부터 <span class="math inline">\(0\)</span>까지)에 대해 별도의 회귀 모형 <span class="math inline">\(b_m\)</span>을 적합합니다.</p></li>
</ul>
<section id="핵심-로직" class="level4">
<h4 class="anchored" data-anchor-id="핵심-로직">핵심 로직</h4>
<ul>
<li>각 시점 <span class="math inline">\(m\)</span>의 회귀 모형에는 다음 두 가지가 포함됩니다.
<ul>
<li><ol type="1">
<li><strong>공변량:</strong> 과거의 이력 <span class="math inline">\(\overline{L}_m\)</span></li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Clever Covariate:</strong> Step 1에서 구한 누적 가중치 <span class="math inline">\(\hat{W}^{\overline{1}_m}\)</span></li>
</ol></li>
</ul></li>
<li><strong>종속변수(Target)가 시점마다 달라집니다:</strong>
<ul>
<li>마지막 시점 (<span class="math inline">\(m=K\)</span>): 실제 결과값 <span class="math inline">\(Y\)</span>가 종속변수입니다.</li>
<li>중간 시점 (<span class="math inline">\(m &lt; K\)</span>): <strong>바로 다음 단계(<span class="math inline">\(m+1\)</span>)에서 예측된 결과값</strong> <span class="math inline">\(\hat{B}_{m+1}\)</span>이 종속변수가 됩니다.</li>
</ul></li>
</ul>
</section>
<section id="수식적-표현" class="level4">
<h4 class="anchored" data-anchor-id="수식적-표현">수식적 표현</h4>
<ul>
<li>시점 <span class="math inline">\(m\)</span>에서의 회귀 모형을 다음과 같이 정의할 수 있습니다 (Binary Outcome의 경우):</li>
</ul>
<p><span class="math display">\[
b_m(\overline{L}_m; \beta_m) = \text{expit}\left( \gamma_m X_m + \varsigma_m \hat{W}^{\overline{1}_m} \right)
\]</span></p>
<ul>
<li>여기서:
<ul>
<li><span class="math inline">\(X_m\)</span>: 공변량 <span class="math inline">\(\overline{L}_m\)</span>의 벡터 함수</li>
<li><span class="math inline">\(\hat{W}^{\overline{1}_m}\)</span>: 시점 <span class="math inline">\(m\)</span>까지의 누적 가중치 (Clever Covariate)</li>
</ul></li>
<li>이 회귀식은 시점 <span class="math inline">\(m\)</span>까지 처치를 지속한 사람들을 대상으로 적합하며, 이를 통해 예측값 <span class="math inline">\(\hat{B}_m\)</span>을 생성합니다. 이 <span class="math inline">\(\hat{B}_m\)</span>은 <span class="math inline">\(m-1\)</span> 시점 회귀 모형의 종속변수로 사용됩니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>참고:</strong> 예측값 <span class="math inline">\(\hat{B}_{m+1}\)</span>은 실수가 아니지만, [0, 1] 사이의 값을 가지므로 Logistic 회귀의 종속변수로 사용할 수 있습니다 (Quasi-binomial likelihood 사용).</p>
</blockquote>
</section>
</section>
<section id="step-3-최종-추정-standardization" class="level3">
<h3 class="anchored" data-anchor-id="step-3-최종-추정-standardization">Step 3: 최종 추정 (Standardization)</h3>
<ul>
<li><p>Step 2의 역순환 과정을 <span class="math inline">\(m=0\)</span>까지 완료하면, 우리는 시점 0에서의 예측값 <span class="math inline">\(\hat{B}_0\)</span>를 얻게 됩니다. <span class="math display">\[
\hat{B}_0 = b_0(L_0; \hat{\beta}_0)
\]</span></p></li>
<li><p>최종적으로, <strong>전체 표본(모든 개인)</strong>에 대해 <span class="math inline">\(\hat{B}_0\)</span>의 평균을 구합니다.</p></li>
</ul>
<p><span class="math display">\[
\hat{E}[Y^{\overline{a}=\overline{1}}] = \frac{1}{n} \sum_{i=1}^{n} \hat{B}_{0,i}
\]</span></p>
<ul>
<li>만약 대조군(예: “항상 처치받지 않음”, <span class="math inline">\(\overline{a}=\overline{0}\)</span>)의 효과도 보고 싶다면, 위 과정을 <span class="math inline">\(\overline{a}=\overline{0}\)</span>으로 설정하여 반복한 뒤 두 결과의 차이를 구하면 됩니다.</li>
</ul>
</section>
</section>
<section id="왜-이것이-강건robust한가" class="level2">
<h2 class="anchored" data-anchor-id="왜-이것이-강건robust한가">4. 왜 이것이 “강건(Robust)”한가?</h2>
<ul>
<li>이 추정량은 단순히 “이중(Doubly)” 강건한 것을 넘어, <strong>다중 강건(Multiply Robust)</strong> 또는 <strong><span class="math inline">\(K+2\)</span> Robustness</strong>라는 강력한 성질을 가집니다.</li>
</ul>
<section id="k2-robustness의-의미" class="level3">
<h3 class="anchored" data-anchor-id="k2-robustness의-의미">K+2 Robustness의 의미</h3>
<ul>
<li>추정량이 일치성(Unbiasedness)을 가지기 위한 조건이 매우 유연합니다. 다음의 조합 중 하나만 성립해도 됩니다:
<ul>
<li><ol type="1">
<li>모든 시점 <span class="math inline">\(m\)</span>에서 <strong>결과 모형</strong> <span class="math inline">\(b_m\)</span>이 정확하게 명시됨.</li>
</ol></li>
<li><ol start="2" type="1">
<li>모든 시점 <span class="math inline">\(m\)</span>에서 <strong>처리 모형</strong> <span class="math inline">\(\pi_k\)</span>가 정확하게 명시됨.</li>
</ol></li>
<li><ol start="3" type="1">
<li>(가장 강력한 조건) 어떤 시점 <span class="math inline">\(m\)</span>을 기준으로, <strong><span class="math inline">\(0 \sim m\)</span>까지는 처리 모형</strong>이 맞고, <strong><span class="math inline">\(m+1 \sim K\)</span>까지는 결과 모형</strong>이 맞아도 됨.</li>
</ol></li>
</ul></li>
<li>즉, 전체 기간 동안 모델을 완벽하게 맞추지 못하더라도, 구간별로 모델이 부분적으로 맞다면 여전히 올바른 인과 효과를 추정할 수 있다는 것입니다.</li>
</ul>
</section>
</section>
<section id="technical-details-implementation-notes" class="level2">
<h2 class="anchored" data-anchor-id="technical-details-implementation-notes">5. Technical Details &amp; Implementation Notes</h2>
<section id="boundedness-경계-조건" class="level3">
<h3 class="anchored" data-anchor-id="boundedness-경계-조건">Boundedness (경계 조건)</h3>
<ul>
<li>이 방식(Plug-in Estimator)의 큰 장점 중 하나는 추정값이 항상 <strong>[0, 1] 범위 내에 존재</strong>한다는 것입니다. 기존의 다른 이중 강건 추정량(예: <span class="math inline">\(\psi_{TR}\)</span>)은 가중치가 불안정할 경우 [0, 1] 범위를 벗어나는 문제가 있었습니다.</li>
</ul>
</section>
<section id="tmle와의-관계" class="level3">
<h3 class="anchored" data-anchor-id="tmle와의-관계">TMLE와의 관계</h3>
<ul>
<li>이 추정량은 <strong>Targeted Minimum Loss-based Estimator (TMLE)</strong>의 한 종류입니다. TMLE는 머신러닝 모델을 인과추론에 적용할 때 발생할 수 있는 편향을 수정하는 데 매우 효과적인 프레임워크로, 최근 딥러닝 기반 인과추론에서도 많이 언급됩니다.</li>
</ul>
</section>
<section id="computational-considerations" class="level3">
<h3 class="anchored" data-anchor-id="computational-considerations">Computational Considerations</h3>
<ul>
<li>과거에는 이러한 절차가 계산 비용이 높고 소프트웨어가 부족하여 구현이 어려웠으나, 최근에는 머신러닝과 Sample splitting을 결합하여 복잡한 생존 분석(Failure time outcomes) 등에 적용하는 것이 가능해지고 있습니다.</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="g-estimation-for-time-varying-treatments" class="level1">
<h1>21.4 G-estimation for time-varying treatments</h1>
<section id="introduction-1" class="level2">
<h2 class="anchored" data-anchor-id="introduction-1">1. Introduction</h2>
<ul>
<li><p>이전 포스트들에서 우리는 시간 가변적 교란요인(Time-varying confounders)이 존재하는 상황에서 인과 효과를 추정하기 위해 <strong>IP Weighting</strong>과 <strong>G-formula</strong>를 다루었습니다. 이번 포스트에서는 이 두 방법론의 대안이자, 특히 효과의 이질성(effect heterogeneity)을 모델링하는 데 강력한 <strong>G-estimation</strong>과 그 기초가 되는 <strong>Structural Nested Mean Models (SNMMs)</strong>에 대해 깊이 있게 다룹니다.</p></li>
<li><p>G-formula가 결합 밀도(joint density)를 모델링하고 IP Weighting이 처치 확률(treatment assignment)을 모델링한다면, G-estimation은 <strong>조건부 인과 효과(conditional causal effect)</strong> 자체를 직접 모델링하는 접근 방식입니다.</p></li>
</ul>
</section>
<section id="structural-nested-mean-models-snmms" class="level2">
<h2 class="anchored" data-anchor-id="structural-nested-mean-models-snmms">2. Structural Nested Mean Models (SNMMs)</h2>
<ul>
<li>G-estimation을 수행하기 위해서는 먼저 인과 효과를 구조화하는 모델이 필요합니다. 이를 <strong>Structural Nested Mean Model (SNMM)</strong>이라고 합니다.</li>
</ul>
<section id="the-blip-function-효과의-정의" class="level3">
<h3 class="anchored" data-anchor-id="the-blip-function-효과의-정의">2.1. The “Blip” Function: 효과의 정의</h3>
<ul>
<li><p>SNMM은 각 시점 <span class="math inline">\(k\)</span>에서의 처치 <span class="math inline">\(A_k\)</span>가 결과 <span class="math inline">\(Y\)</span>에 미치는 효과를 <strong>“Blip”</strong>이라는 개념으로 정의합니다. 이는 과거의 처치 이력(<span class="math inline">\(\bar{a}_{k-1}\)</span>)은 고정된 상태에서, 시점 <span class="math inline">\(k\)</span>에서 처치를 받았을 때(<span class="math inline">\(a_k\)</span>)와 받지 않았을 때(<span class="math inline">\(0\)</span>)의 잠재적 결과(Counterfactual Outcome) 차이를 의미합니다.</p></li>
<li><p>가장 일반적인 형태의 SNMM은 다음과 같이 정의됩니다:</p></li>
</ul>
<p><span class="math display">\[
E[Y^{\bar{a}_{k-1}, a_k, \underline{0}_{k+1}} - Y^{\bar{a}_{k-1}, \underline{0}_k} \mid \bar{L}_k, \bar{A}_{k-1}] = a_k \gamma_k(\bar{a}_{k-1}, \bar{l}_k, \beta)
\]</span></p>
<ul>
<li>여기서 각 항의 의미는 다음과 같습니다:
<ul>
<li><span class="math inline">\((\bar{a}_{k-1}, a_k, \underline{0}_{k+1})\)</span>: 시점 <span class="math inline">\(k-1\)</span>까지는 <span class="math inline">\(\bar{a}_{k-1}\)</span>, 시점 <span class="math inline">\(k\)</span>에는 <span class="math inline">\(a_k\)</span>, 그 이후(<span class="math inline">\(k+1 \dots K\)</span>)에는 처치를 전혀 받지 않는(0) 전략.</li>
<li><span class="math inline">\((\bar{a}_{k-1}, \underline{0}_k)\)</span>: 시점 <span class="math inline">\(k-1\)</span>까지는 <span class="math inline">\(\bar{a}_{k-1}\)</span>, 그리고 시점 <span class="math inline">\(k\)</span>부터 끝까지 처치를 받지 않는 전략.</li>
<li><span class="math inline">\(\gamma_k(\cdot)\)</span>: <strong>Blip function</strong>. 과거의 처치 및 공변량 이력 <span class="math inline">\((\bar{a}_{k-1}, \bar{l}_k)\)</span>에 따라 시점 <span class="math inline">\(k\)</span>의 처치 효과가 어떻게 달라지는지를 나타내는 함수입니다.</li>
</ul></li>
</ul>
</section>
<section id="왜-nested인가" class="level3">
<h3 class="anchored" data-anchor-id="왜-nested인가">2.2. 왜 “Nested”인가?</h3>
<ul>
<li>이 모델이 “Nested(중첩)”라고 불리는 이유는 효과를 추정하는 방식이 역순으로 중첩되어 있기 때문입니다.
<ul>
<li><ol type="1">
<li>마지막 시점 <span class="math inline">\(K\)</span>에서의 처치 효과를 먼저 고려하고,</li>
</ol></li>
<li><ol start="2" type="1">
<li>그 효과를 제거한 상태에서 <span class="math inline">\(K-1\)</span> 시점의 효과를 고려하는 식으로,</li>
</ol></li>
<li><ol start="3" type="1">
<li><span class="math inline">\(k=0\)</span>이 될 때까지 거슬러 올라갑니다.</li>
</ol></li>
</ul></li>
</ul>
</section>
</section>
<section id="g-estimation-methodology" class="level2">
<h2 class="anchored" data-anchor-id="g-estimation-methodology">3. G-estimation Methodology</h2>
<ul>
<li>G-estimation은 복잡한 수식 이전에 <strong>“처치의 효과를 데이터에서 덜어낸다(Subtractive)”</strong>는 매우 직관적인 아이디어에서 출발합니다. 이 섹션에서는 단일 파라미터에 대한 Grid Search 방법부터 다차원 파라미터 추정을 위한 일반화된 방정식까지 살펴봅니다.</li>
</ul>
<section id="preliminary-the-intuition-behind-g-estimation" class="level3">
<h3 class="anchored" data-anchor-id="preliminary-the-intuition-behind-g-estimation">3.1. Preliminary: The Intuition behind G-estimation</h3>
<ul>
<li>G-estimation을 이해하기 위해 가장 먼저 필요한 개념은 <strong>“반사실적 결과의 복원”</strong>입니다.</li>
<li><strong>기본 아이디어:</strong> 만약 우리가 어떤 처치제(<span class="math inline">\(A\)</span>)의 정확한 인과적 효과(<span class="math inline">\(\psi\)</span>)를 이미 알고 있다면, 관측된 결과(<span class="math inline">\(Y\)</span>)에서 그 처치 효과만큼을 <strong>빼버림(Subtract)</strong>으로써, 그 환자가 처치를 받지 않았을 때의 잠재적 상태(<span class="math inline">\(Y^{a=0}\)</span>)를 역으로 계산해낼 수 있습니다.</li>
<li><strong>인과적 추론의 연결:</strong>
<ul>
<li>무작위 배정이나 교환성(Exchangeability) 가정 하에서, <strong>처치 여부(<span class="math inline">\(A\)</span>)</strong>는 <strong>처치를 받지 않았을 때의 잠재적 결과(<span class="math inline">\(Y^{a=0}\)</span>)</strong>와 독립이어야 합니다.</li>
<li>G-estimation은 이 논리를 역이용합니다. 다양한 효과 크기 후보(<span class="math inline">\(\psi^\dagger\)</span>)를 대입해 보면서, 계산된 “처치 제거 후 결과(<span class="math inline">\(H\)</span>)”가 처치 변수(<span class="math inline">\(A\)</span>)와 <strong>통계적으로 독립이 되게 만드는</strong> <span class="math inline">\(\psi\)</span>를 찾아내는 과정입니다.</li>
</ul></li>
</ul>
</section>
<section id="candidate-counterfactuals-h_k-and-grid-search" class="level3">
<h3 class="anchored" data-anchor-id="candidate-counterfactuals-h_k-and-grid-search">3.2. Candidate Counterfactuals (<span class="math inline">\(H_k\)</span>) and Grid Search</h3>
<ul>
<li><strong>Step 1: 후보 반사실(Candidate Counterfactual) 계산</strong>
<ul>
<li>특정 파라미터 후보값 <span class="math inline">\(\psi^\dagger\)</span>가 주어졌을 때, 우리는 관측 데이터로부터 시점 <span class="math inline">\(k\)</span> 이후의 처치 효과가 제거된 잠재적 결과 <span class="math inline">\(H_k(\psi^\dagger)\)</span>를 계산할 수 있습니다. <span class="math display">\[
  H_{k}(\psi^{\dagger}) = Y - \sum_{j=k}^{K} A_{j} \gamma_{j}(\bar{A}_{j-1}, \bar{L}_{j}, \psi^{\dagger})
  \]</span></li>
<li>여기서 <span class="math inline">\(\gamma_{j}\)</span>는 처치의 효과(Blip function)입니다. 만약 <span class="math inline">\(\psi^\dagger\)</span>가 참값이라면, <span class="math inline">\(H_k\)</span>는 시점 <span class="math inline">\(k\)</span> 이전에 처치를 받고 그 이후로는 처치를 받지 않은 잠재적 결과(<span class="math inline">\(Y^{\bar{a}_{k-1}, \underline{0}_k}\)</span>)와 동일합니다.</li>
</ul></li>
<li><strong>Step 2: 로지스틱 회귀 모델 적합 (Pooling over time)</strong>
<ul>
<li>계산된 <span class="math inline">\(H_k(\psi^\dagger)\)</span>가 현재의 처치 <span class="math inline">\(A_k\)</span>와 독립인지 확인하기 위해, 다음의 로지스틱 회귀 모형을 적합합니다. <span class="math display">\[
  \text{logit } \Pr[A_k = 1 | H_k(\psi^\dagger), \bar{L}_k, \bar{A}_{k-1}] = \alpha_0 + \alpha_1 H_k(\psi^\dagger) + \alpha_2 W_k
  \]</span></li>
<li>여기서 <span class="math inline">\(W_k\)</span>는 교란 요인을 통제하기 위한 공변량 벡터입니다.</li>
</ul></li>
<li><strong>Step 3: 스코어 검정(Score Test)을 통한 추정</strong>
<ul>
<li>만약 <span class="math inline">\(\psi^\dagger\)</span>가 참값이라면, <span class="math inline">\(H_k\)</span>는 처치 <span class="math inline">\(A_k\)</span>에 영향을 주지 않아야 하므로 회귀계수 <span class="math inline">\(\alpha_1\)</span>은 <strong>0</strong>이어야 합니다.</li>
<li>따라서, 우리는 <span class="math inline">\(\alpha_1 = 0\)</span>이라는 귀무가설에 대한 <strong>P-value가 1에 가까운(또는 Z-score가 0인)</strong> <span class="math inline">\(\psi^\dagger\)</span> 값을 찾습니다. 이를 수식으로 표현하면 다음의 <strong>스코어 방정식(Score Equation)</strong>을 만족하는 해를 찾는 것입니다. <span class="math display">\[
  \sum_{i=1}^{N} \sum_{k=0}^{K} \{ A_{i,k} - \text{expit}(\hat{\alpha}_0 + \hat{\alpha}_2 W_{i,k}) \} H_{i,k}(\psi^\dagger) = 0
  \]</span></li>
<li><strong>Derivation Note (유도 과정):</strong>
<ol type="1">
<li><strong>로그-우도 함수 (<span class="math inline">\(LL\)</span>):</strong> 로지스틱 회귀의 <span class="math inline">\(LL\)</span>은 <span class="math inline">\(\sum [ A \ln(p) + (1-A) \ln(1-p) ]\)</span> 입니다.</li>
<li><strong>스코어 함수 (<span class="math inline">\(U\)</span>):</strong> 스코어는 <span class="math inline">\(LL\)</span>을 파라미터 <span class="math inline">\(\alpha_1\)</span>으로 미분한 기울기입니다. 연쇄 법칙(Chain Rule)에 의해 미분 결과는 다음과 같이 간단해집니다. <span class="math display">\[U(\alpha_1) = \frac{\partial LL}{\partial \alpha_1} = \sum (A - p) H\]</span></li>
<li><strong>귀무가설 적용:</strong> <span class="math inline">\(\alpha_1=0\)</span>이라는 가설 하에서, 확률 <span class="math inline">\(p\)</span>는 <span class="math inline">\(H\)</span>항이 사라진 <span class="math inline">\(\text{expit}(\alpha_0 + \alpha_2 W)\)</span>가 됩니다.</li>
<li><strong>결론:</strong> 따라서 최적점(기울기=0)을 찾는 식은 위와 같이 “잔차(<span class="math inline">\(A-p\)</span>)와 공변량(<span class="math inline">\(H\)</span>)의 곱의 합 = 0”이 됩니다.</li>
</ol></li>
</ul></li>
</ul>
</section>
</section>
<section id="efficient-estimation-multidimensional-parameters" class="level2">
<h2 class="anchored" data-anchor-id="efficient-estimation-multidimensional-parameters">4. Efficient Estimation: Multidimensional Parameters</h2>
<ul>
<li>앞서 설명한 Grid Search 방식은 파라미터가 하나일 때는 유용하지만, 모델이 복잡해지면 계산상 불가능해집니다.</li>
</ul>
<section id="the-curse-of-dimensionality-차원의-저주" class="level3">
<h3 class="anchored" data-anchor-id="the-curse-of-dimensionality-차원의-저주">4.1. The Curse of Dimensionality (차원의 저주)</h3>
<ul>
<li><p><strong>Simple vs.&nbsp;Complex:</strong> 단순한 모델(<span class="math inline">\(\beta_1\)</span> 하나)에서는 1차원 그리드만 탐색하면 되지만, 현실적인 모델은 훨씬 복잡합니다.</p></li>
<li><p><strong>Introducing Notation <span class="math inline">\(R\)</span>:</strong> 예를 들어, 처치 효과가 시간(<span class="math inline">\(k\)</span>)이 지남에 따라 변하고, 과거 처치 이력(<span class="math inline">\(a_{k-1}\)</span>)이나 현재 환자 상태(<span class="math inline">\(l_k\)</span>)에 따라 달라지는 정교한 모형을 고려해 봅시다. 파라미터가 5개인 경우, 효과 함수 <span class="math inline">\(\gamma_k\)</span>는 다음과 같이 표현됩니다.</p>
<p><span class="math display">\[
  \begin{aligned}
  \gamma_k(\bar{\alpha}_{k-1}, \bar{l}_{k}, \beta) &amp;= \beta_0 \cdot 1 + \beta_1 \cdot k + \beta_2 \cdot a_{k-1} + \beta_3 \cdot l_k + \beta_4 \cdot (l_k a_{k-1}) \\
  &amp;= \beta^T R_k
  \end{aligned}
  \]</span></p></li>
<li><p><strong>Definition of <span class="math inline">\(R_k\)</span>:</strong> 위 식에서 보듯이, 복잡한 수식은 <strong>파라미터 벡터 <span class="math inline">\(\beta\)</span></strong>와 <strong>공변량 벡터 <span class="math inline">\(R_k\)</span></strong>의 내적(Inner Product)으로 깔끔하게 정리됩니다.</p>
<ul>
<li><span class="math inline">\(\beta = [\beta_0, \beta_1, \beta_2, \beta_3, \beta_4]^T\)</span>: 우리가 추정해야 할 <strong>계수(가중치)</strong>들입니다.</li>
<li><span class="math inline">\(R_k = [1, k, a_{k-1}, l_k, l_k a_{k-1}]^T\)</span>: 처치 효과를 결정하거나 조절하는(Modify) <strong>데이터상의 변수 조합</strong>들입니다.</li>
</ul></li>
<li><p><strong>The Computational Cost:</strong> 이 벡터 표기는 간결하지만, 실제 추정 과정에서는 큰 문제를 야기합니다. 5개의 파라미터(<span class="math inline">\(\beta_0 \sim \beta_4\)</span>)를 찾기 위해 5차원 공간을 탐색해야 하기 때문입니다. 각 차원마다 20개의 후보값만 테스트한다고 해도, <span class="math inline">\(20^5 = 3,200,000\)</span>번의 검정이 필요합니다. 이것이 바로 그리드 탐색의 한계인 <strong>차원의 저주</strong>입니다.</p></li>
</ul>
</section>
<section id="estimating-equations-and-closed-form-derivation" class="level3">
<h3 class="anchored" data-anchor-id="estimating-equations-and-closed-form-derivation">4.2. Estimating Equations and Closed-form Derivation</h3>
<ul>
<li>닫힌 해를 유도하기 위해, 먼저 우리가 풀고자 하는 <strong>원래의 추정 방정식(Original Estimating Equation)</strong>을 명확히 정의하고 시작합시다. 우리의 목표는 다음 등식을 만족하는 <span class="math inline">\(\beta\)</span>를 찾는 것입니다.</li>
</ul>
<p><span class="math display">\[
\sum_{i=1}^{N} \sum_{k=0}^{K} \underbrace{\{ A_{i,k} - \text{expit}(\hat{\alpha}^T W_{i,k}) \}}_{X_{i,k} (\text{처치 잔차})} H_{i,k}(\beta) \underbrace{Q_{i,k}}_{\text{가중치/검정 벡터}} = 0
\]</span></p>
<ul>
<li><strong>주요 항 설명:</strong>
<ul>
<li><strong><span class="math inline">\(X_{i,k}\)</span> (처치 잔차):</strong> 처치 여부(<span class="math inline">\(A\)</span>)에서 예측된 확률을 뺀 값입니다. 이 잔차는 설명되지 않은(Random) 변동을 의미합니다.</li>
<li><strong><span class="math inline">\(H_{i,k}(\beta)\)</span> (후보 반사실):</strong> 파라미터 <span class="math inline">\(\beta\)</span>를 가정했을 때 복원된 “처치받지 않았을 때의 잠재적 결과”입니다. 이 안에 미지수 <span class="math inline">\(\beta\)</span>가 숨어 있습니다.</li>
<li><strong><span class="math inline">\(Q_{i,k}\)</span> (가중치/검정 벡터):</strong> 이 벡터는 <strong>연립방정식을 생성하는 핵심 역할</strong>을 합니다.
<ul>
<li><strong>필요성:</strong> 우리가 구해야 할 <span class="math inline">\(\beta\)</span>가 5개의 파라미터를 가진 벡터라면, 미지수가 5개이므로 식도 5개가 필요합니다.</li>
<li><strong>구조:</strong> <span class="math inline">\(Q_{i,k}\)</span>는 보통 <span class="math inline">\(\beta\)</span>에 대응하는 공변량들로 구성됩니다 (예: <span class="math inline">\(Q_{i,k} = [1, k, L_k, \dots]^T\)</span>).</li>
<li><strong>의미:</strong> 이 벡터를 곱함으로써, 단순히 전체 평균에서뿐만 아니라 <strong>“<span class="math inline">\(Q\)</span>에 포함된 각 변수의 관점(예: 시간 <span class="math inline">\(k\)</span>, 특정 집단 <span class="math inline">\(L\)</span>)에서도 잔차와 반사실의 독립성이 성립하는지”</strong>를 깐깐하게 검증하게 됩니다.</li>
</ul></li>
</ul></li>
<li>이제 이 식을 전개하여 숨어 있는 <span class="math inline">\(\beta\)</span>를 끄집어내고 해를 구해보겠습니다.</li>
</ul>
<section id="step-1-hbeta의-선형-분해-unpacking-h" class="level4">
<h4 class="anchored" data-anchor-id="step-1-hbeta의-선형-분해-unpacking-h"><strong>Step 1: <span class="math inline">\(H(\beta)\)</span>의 선형 분해 (Unpacking H)</strong></h4>
<ul>
<li>선형 SNMM에서, 시점 <span class="math inline">\(k\)</span>에서의 후보 반사실 <span class="math inline">\(H_{i,k}(\beta)\)</span>는 관측된 결과 <span class="math inline">\(Y_i\)</span>에서 <strong>“추정된 처치 효과의 합”</strong>을 뺀 것입니다. <span class="math display">\[
H_{i,k}(\beta) = Y_i - \underbrace{\sum_{j=k}^{K} (\beta^T R_{i,j}) A_{i,j}}_{\text{Removed Effect}} = Y_i - \beta^T \underbrace{\left( \sum_{j=k}^{K} A_{i,j} R_{i,j} \right)}_{S_{i,k}}
\]</span>
<ul>
<li>여기서 <span class="math inline">\(S_{i,k}\)</span>는 처치(<span class="math inline">\(A\)</span>)와 공변량(<span class="math inline">\(R\)</span>)이 결합된 누적 이력 벡터입니다.</li>
<li>이제 <span class="math inline">\(H_{i,k}(\beta)\)</span>를 <strong><span class="math inline">\(Y_i - \beta^T S_{i,k}\)</span></strong> 로 바꿔 쓸 수 있습니다.</li>
</ul></li>
</ul>
</section>
<section id="step-2-방정식에-대입-substitution" class="level4">
<h4 class="anchored" data-anchor-id="step-2-방정식에-대입-substitution"><strong>Step 2: 방정식에 대입 (Substitution)</strong></h4>
<ul>
<li>이제 Step 1에서 정리한 <span class="math inline">\(H(\beta)\)</span>를 맨 처음 제시한 <strong>원래의 추정 방정식</strong>에 대입합니다.</li>
</ul>
<p><span class="math display">\[
\sum_{i,k} \underbrace{X_{i,k}}_{\text{Residual}} \times \underbrace{(Y_i - \beta^T S_{i,k})}_{H(\beta)} \times Q_{i,k} = 0
\]</span></p>
</section>
<section id="step-3-전개-및-이항-expansion-rearrangement" class="level4">
<h4 class="anchored" data-anchor-id="step-3-전개-및-이항-expansion-rearrangement"><strong>Step 3: 전개 및 이항 (Expansion &amp; Rearrangement)</strong></h4>
<ul>
<li>덧셈을 기준으로 식을 두 덩어리로 쪼갭니다.</li>
</ul>
<p><span class="math display">\[
\sum_{i,k} X_{i,k} Y_i Q_{i,k} - \sum_{i,k} X_{i,k} (\beta^T S_{i,k}) Q_{i,k} = 0
\]</span></p>
<ul>
<li><span class="math inline">\(\beta\)</span>가 포함된 항을 우변으로 넘깁니다. (<span class="math inline">\(\beta\)</span>는 상수 벡터이므로 시그마 밖으로 나올 수 있습니다.)</li>
</ul>
<p><span class="math display">\[
\sum_{i,k} X_{i,k} Y_i Q_{i,k} = \beta^T \left( \sum_{i,k} X_{i,k} S_{i,k} Q_{i,k}^T \right)
\]</span></p>
</section>
<section id="step-4-닫힌-해-도출-closed-form-solution" class="level4">
<h4 class="anchored" data-anchor-id="step-4-닫힌-해-도출-closed-form-solution"><strong>Step 4: 닫힌 해 도출 (Closed-form Solution)</strong></h4>
<ul>
<li>이제 <span class="math inline">\(\beta\)</span>를 구하기 위해 양변에 역행렬을 곱하면(나눗셈), 반복 탐색(Grid Search) 없이 한 번에 답을 구할 수 있습니다.</li>
</ul>
<p><span class="math display">\[
\hat{\beta} = \left[ \sum_{i=1}^{N} \sum_{k=0}^{K} X_{i,k} Q_{i,k} S_{i,k}^T \right]^{-1} \times \left[ \sum_{i=1}^{N} \sum_{k=0}^{K} X_{i,k} Y_i Q_{i,k} \right]
\]</span></p>
<ul>
<li><strong>직관적 해석:</strong> 이 식은 본질적으로 통계학의 <strong><span class="math inline">\(\hat{\beta} = (X^T X)^{-1} X^T Y\)</span></strong> (최소자승법 공식)와 동일한 형태입니다.
<ul>
<li><strong>분모(역행렬 부분):</strong> 처치 변동(<span class="math inline">\(X\)</span>)과 공변량 이력(<span class="math inline">\(S\)</span>)의 공분산 행렬.</li>
<li><strong>분자:</strong> 처치 변동(<span class="math inline">\(X\)</span>)과 결과(<span class="math inline">\(Y\)</span>)의 공분산.</li>
<li>즉, <strong>“설명되지 않은 처치 변동(<span class="math inline">\(X\)</span>)이 결과(<span class="math inline">\(Y\)</span>)를 얼마나 변화시키는가?”</strong>를 계산하는 과정입니다.</li>
</ul></li>
</ul>
</section>
</section>
</section>
<section id="from-parameters-to-counterfactual-means" class="level2">
<h2 class="anchored" data-anchor-id="from-parameters-to-counterfactual-means">5. From Parameters to Counterfactual Means</h2>
<ul>
<li>G-estimation을 통해 인과 파라미터 <span class="math inline">\(\hat{\beta}\)</span>를 구했다면, 이제 우리의 최종 목표인 <strong>“특정 처치 전략 하에서의 평균 결과값”</strong>을 복원해야 합니다.</li>
</ul>
<section id="reconstruction-formula-for-static-strategies" class="level3">
<h3 class="anchored" data-anchor-id="reconstruction-formula-for-static-strategies">5.1. Reconstruction Formula for Static Strategies</h3>
<ul>
<li>우리가 관심 있는 것이 정적 처치 전략(Static Strategy, 예: 항상 처치받음 <span class="math inline">\(\bar{a}\)</span>)인 경우, 평균 잠재적 결과 <span class="math inline">\(E[Y^{\bar{a}}]\)</span>는 다음과 같이 추정됩니다.</li>
</ul>
<p><span class="math display">\[
\hat{E}[Y^{\bar{a}}] = \hat{E}[Y^{\bar{0}}] + \sum_{k=0}^{K} a_k \gamma_k(\bar{a}_{k-1}, \bar{l}_k, \hat{\beta})
\]</span></p>
<ul>
<li><strong>1단계 (<span class="math inline">\(H_0\)</span> 추정):</strong> 먼저 모든 처치 효과를 제거한 상태, 즉 ‘처치를 전혀 받지 않았을 때의 잠재적 결과’(<span class="math inline">\(Y^{\bar{0}}\)</span>)를 추정합니다. 이는 앞서 구한 <span class="math inline">\(\hat{\beta}\)</span>를 이용해 계산한 <span class="math inline">\(H_0(\hat{\beta})\)</span>들의 표본 평균입니다. (<span class="math inline">\(\hat{E}[Y^{\bar{0}}] = \frac{1}{n}\sum H_{0,i}(\hat{\beta})\)</span>)</li>
<li><strong>2단계 (효과 더하기):</strong> 1단계에서 구한 베이스라인 평균에, 우리가 관심 있는 전략 <span class="math inline">\(\bar{a}\)</span>에 해당하는 처치 효과들의 합을 더해줍니다.</li>
</ul>
</section>
<section id="dynamic-strategies-and-simulation" class="level3">
<h3 class="anchored" data-anchor-id="dynamic-strategies-and-simulation">5.2. Dynamic Strategies and Simulation</h3>
<ul>
<li><p>만약 관심 있는 전략 <span class="math inline">\(g\)</span>가 동적(Dynamic, 예: “혈압이 오르면 약을 먹는다”)이거나, 모델이 시간 의존적 공변량 <span class="math inline">\(L_k\)</span>에 의존한다면 계산은 더 복잡해집니다. 이 경우 <strong>몬테카를로 시뮬레이션(Monte Carlo Simulation)</strong>을 이용한 알고리즘이 필요합니다.</p></li>
<li><p>구조적 중첩 평균 모형(SNMM) <span class="math inline">\(\gamma_k(\bar{a}_{k-1}, \bar{l}_k, \beta)\)</span>에 대해 이중 강건(doubly robust) g-추정량 <span class="math inline">\(\tilde{\beta}\)</span>를 얻었다고 가정할 때, 동적 전략 <span class="math inline">\(g\)</span> 하에서의 평균 결과 <span class="math inline">\(E[Y^g]\)</span>를 추정하는 단계는 다음과 같습니다.</p></li>
<li><ol type="1">
<li><strong>Baseline 평균 결과 추정 (처치가 전혀 없었을 때):</strong></li>
</ol>
<ul>
<li>먼저 모든 시점에서 처치를 받지 않았을 경우(had treatment always been withheld, <span class="math inline">\(\bar{0}_K\)</span>)의 평균 반응 <span class="math inline">\(E[Y^{\bar{0}_K}]\)</span>를 추정합니다. 이는 <span class="math inline">\(N\)</span>명의 연구 대상자에 대해 <span class="math inline">\(H_0(\tilde{\beta})\)</span>의 표본 평균으로 계산합니다. <span class="math display">\[\hat{E}[Y^{\bar{0}_K}] = \frac{1}{N} \sum_{i=1}^{N} H_{0,i}(\tilde{\beta})\]</span></li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>공변량 모델 적합 (Covariate Modeling):</strong></li>
</ol>
<ul>
<li>데이터를 사람과 시점에 대해 풀링(pooling)하여, 과거 이력이 주어졌을 때 현재 공변량의 분포 <span class="math inline">\(f(l_k | \bar{a}_{k-1}, \bar{l}_{k-1})\)</span>에 대한 파라메트릭 모델을 적합시킵니다. 이 모델에 의한 추정치를 <span class="math inline">\(\hat{f}(l_k | \bar{a}_{k-1}, \bar{l}_{k-1})\)</span>라고 합니다.</li>
</ul></li>
<li><ol start="3" type="1">
<li><strong>몬테카를로 시뮬레이션 (Monte Carlo Simulation):</strong></li>
</ol>
<ul>
<li>가상의 환자 <span class="math inline">\(v = 1, \dots, V\)</span>에 대하여 다음 과정을 반복합니다.
<ul>
<li><strong>(a) 초기값 생성:</strong> <span class="math inline">\(\hat{f}(l_0)\)</span>로부터 <span class="math inline">\(l_{v,0}\)</span>를 추출합니다.</li>
<li><strong>(b) 재귀적 생성 (Recursive Generation):</strong> <span class="math inline">\(k=1, \dots, K\)</span>에 대해, 전략 <span class="math inline">\(g\)</span>에 따른 처치 이력 <span class="math inline">\(\bar{a}_{v, k-1} = \bar{g}_{k-1}(\bar{l}_{v, k-1})\)</span>을 설정하고, 이를 바탕으로 <span class="math inline">\(\hat{f}(l_k | \bar{a}_{v, k-1}, \bar{l}_{v, k-1})\)</span>에서 <span class="math inline">\(l_{v,k}\)</span>를 추출합니다.</li>
<li><strong>(c) 개별 효과 계산:</strong> 해당 가상 환자 <span class="math inline">\(v\)</span>에 대해, 전략 <span class="math inline">\(g\)</span>와 비처치군(<span class="math inline">\(\bar{0}_K\)</span>) 간의 잠재적 결과 차이(contrast)를 계산합니다. 여기서 <span class="math inline">\(a_{v,j} = g_j(\bar{l}_{v, j-1})\)</span>입니다. <span class="math display">\[\hat{\Delta}_{g,v} = \sum_{j=0}^{K} a_{v,j} \gamma_j (\bar{a}_{v, j-1}, \bar{l}_{v,j}, \tilde{\beta})\]</span> 이 값은 <span class="math inline">\(v\)</span>번째 몬테카를로 추정치인 <span class="math inline">\(Y^g - Y^{\bar{0}_K}\)</span>에 해당합니다.</li>
</ul></li>
</ul></li>
<li><ol start="4" type="1">
<li><strong>최종 추정 (Final Estimation):</strong></li>
</ol>
<ul>
<li>위에서 구한 Baseline 추정치와 시뮬레이션된 효과들의 평균을 합하여 <span class="math inline">\(E[Y^g]\)</span>를 추정합니다. <span class="math display">\[\hat{E}[Y^g] = \hat{E}[Y^{\bar{0}_K}] + \frac{1}{V} \sum_{v=1}^{V} \hat{\Delta}_{g,v}\]</span></li>
</ul></li>
<li><p><strong>참고 (Consistency):</strong></p>
<ul>
<li>이 추정량 <span class="math inline">\(\hat{E}[Y^g]\)</span>는 공변량 모델 <span class="math inline">\(f\)</span>가 정확하고, SNMM <span class="math inline">\(\gamma_k\)</span>가 정확하며, <strong>[처치 모델 <span class="math inline">\(\Pr(A_k=1|\dots)\)</span> 또는 결과 모델 <span class="math inline">\(E[Y^{\bar{0}_K}|\dots]\)</span> 중 하나]</strong>가 정확하게 명시되었다면 일치 추정량(consistent estimator)이 됩니다. 신뢰구간은 비모수적 부트스트랩(nonparametric bootstrap)을 통해 얻을 수 있습니다.</li>
</ul></li>
</ul>
</section>
</section>
<section id="snmm-vs.-marginal-structural-models-msm" class="level2">
<h2 class="anchored" data-anchor-id="snmm-vs.-marginal-structural-models-msm">6. SNMM vs.&nbsp;Marginal Structural Models (MSM)</h2>
<ul>
<li>시변 처치 분석을 위해 <strong>MSM(IP Weighting)</strong>과 <strong>SNMM(G-estimation)</strong> 중 무엇을 선택해야 할까요?</li>
</ul>
<section id="effect-modification-효과-변경-1" class="level3">
<h3 class="anchored" data-anchor-id="effect-modification-효과-변경-1">6.1. Effect Modification (효과 변경)</h3>
<ul>
<li><strong>MSM:</strong> 과거 공변량(<span class="math inline">\(L\)</span>)에 의한 효과 변경(Effect Modification) 여부에 대해 <strong>불가지론적(Agnostic)</strong>입니다. 즉, 효과 변경 구조를 몰라도 전체 평균 효과(<span class="math inline">\(E[Y^{\bar{a}}]\)</span>)를 정확히 추정할 수 있습니다.</li>
<li><strong>SNMM:</strong> 효과 변경 여부를 모델 식(<span class="math inline">\(\gamma_k\)</span>)에 <strong>명시적으로</strong> 포함해야 합니다. 만약 중요한 효과 변경 변수를 누락하면 추정치에 편향(Bias)이 발생합니다.</li>
</ul>
</section>
<section id="the-trade-off-robustness-vs.-efficiency" class="level3">
<h3 class="anchored" data-anchor-id="the-trade-off-robustness-vs.-efficiency">6.2. The Trade-off: Robustness vs.&nbsp;Efficiency</h3>
<ul>
<li><strong>MSM (Robustness):</strong> 모델 설정 오류(Misspecification)에 상대적으로 안전합니다.</li>
<li><strong>SNMM (Efficiency):</strong> 모델을 정확하게 설정한다면, MSM보다 더 좁은 신뢰구간을 제공하여 <strong>통계적 효율성(Efficiency)</strong>이 높습니다. 또한, <span class="math inline">\(P(A|L)\)</span>이 0이나 1에 가까워 IPW 가중치가 불안정해지는 상황(Positivity 위반)에서도 SNMM은 상대적으로 안정적인 결과를 제공합니다.</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="censoring-is-a-time-varying-treatment" class="level1">
<h1>21.5 Censoring is a time-varying treatment</h1>
<section id="introduction-the-reality-of-censoring" class="level2">
<h2 class="anchored" data-anchor-id="introduction-the-reality-of-censoring">1. Introduction: The Reality of Censoring</h2>
<ul>
<li><p>인과추론 연구, 특히 장기간의 추적 관찰이 필요한 연구에서 <strong>중도절단(Censoring)</strong>은 피할 수 없는 문제입니다. 이상적인 상황에서는 모든 연구 대상자의 결과(Outcome)를 관찰할 수 있지만, 실제 데이터에서는 추적 소실(loss to follow-up) 등으로 인해 일부 대상자의 결과가 누락됩니다.</p></li>
<li><p>앞선 챕터들(Part II)에서는 중도절단을 시점 고정 변수(time-fixed variable) <span class="math inline">\(C\)</span>로 단순화하여 다루었습니다. 하지만 현실적으로 중도절단은 연구 기간 중 <strong>언제든지 발생할 수 있는 사건</strong>입니다. 따라서 Hernán &amp; Robins(2020)은 중도절단을 <strong>시변 변수(time-varying variable)</strong> <span class="math inline">\(C_1, C_2, \dots, C_{K+1}\)</span>로 확장하여 모델링할 것을 제안합니다.</p></li>
<li><p>이 포스트에서는 중도절단을 마치 <strong>또 하나의 처치(treatment)</strong>처럼 취급하여, <em>“아무도 중도절단되지 않았을 때(had nobody been censored)”</em>의 인과 효과를 추정하는 방법론을 다룹니다.</p></li>
</ul>
</section>
<section id="conceptual-framework" class="level2">
<h2 class="anchored" data-anchor-id="conceptual-framework">2. Conceptual Framework</h2>
<section id="time-varying-censoring-definition" class="level3">
<h3 class="anchored" data-anchor-id="time-varying-censoring-definition">2.1. Time-Varying Censoring Definition</h3>
<ul>
<li>각 시점 <span class="math inline">\(m\)</span>에서의 중도절단 지시자(indicator) <span class="math inline">\(C_m\)</span>을 다음과 같이 정의합니다:</li>
</ul>
<p><span class="math display">\[
C_m = \begin{cases}
0 &amp; \text{if the individual remains uncensored at time } m \\
1 &amp; \text{otherwise (censored)}
\end{cases}
\]</span></p>
<ul>
<li><p>중도절단은 <strong>단조적(monotonic)</strong> 특성을 가진 결측 데이터입니다. 즉, 특정 시점에서 중도절단이 발생하면(<span class="math inline">\(C_m=1\)</span>), 그 이후의 모든 시점에서도 중도절단 상태가 유지됩니다.</p></li>
<li><p>또한, 연구 시작 시점에는 모든 대상자가 관찰 가능해야 하므로, 정의상 <span class="math inline">\(C_0=0\)</span>입니다.</p></li>
</ul>
</section>
<section id="the-joint-intervention-perspective" class="level3">
<h3 class="anchored" data-anchor-id="the-joint-intervention-perspective">2.2. The Joint Intervention Perspective</h3>
<ul>
<li><p>우리가 추정하고자 하는 인과 효과는 <strong>“특정 처치 전략 <span class="math inline">\(\bar{a}\)</span>를 따르고, 동시에 아무도 중도절단되지 않았을 때(<span class="math inline">\(\bar{c}=\bar{0}\)</span>)”</strong>의 결과입니다.</p></li>
<li><p>이는 인과추론의 관점에서 볼 때, 처치 변수 <span class="math inline">\(A\)</span>와 중도절단 변수 <span class="math inline">\(C\)</span>에 대한 <strong>결합 개입(Joint Intervention)</strong> <span class="math inline">\((\bar{a}, \bar{c}=\bar{0})\)</span>의 효과를 추정하는 것과 동일합니다.</p></li>
</ul>
<p><span class="math display">\[
E[Y^{\bar{a}, \bar{c}=\bar{0}}]
\]</span></p>
<ul>
<li>이 값이 식별(identified)되려면, 처치 <span class="math inline">\(A\)</span>뿐만 아니라 중도절단 <span class="math inline">\(C\)</span>에 대해서도 교환가능성(exchangeability), 일치성(consistency), 양수성(positivity) 가정이 성립해야 합니다.</li>
</ul>
</section>
</section>
<section id="method-1-the-g-formula" class="level2">
<h2 class="anchored" data-anchor-id="method-1-the-g-formula">3. Method 1: The G-Formula</h2>
<ul>
<li><p>기존의 G-formula는 중도절단이 없는 이상적인 상황을 가정했습니다. 시변 중도절단이 존재하는 상황에서 Counterfactual Mean <span class="math inline">\(E[Y^{\bar{a}}]\)</span>를 추정하기 위해서는, 분석 대상을 <strong>중도절단되지 않은(uncensored) 사람-시점</strong>으로 제한해야 합니다.</p></li>
<li><p>수정된 G-formula는 다음과 같습니다:</p></li>
</ul>
<p><span class="math display">\[
E[Y^{\bar{a}, \bar{c}=\bar{0}}] = \sum_{\bar{l}} E[Y|\bar{C}=\bar{0}, \bar{A}=\bar{a}, \bar{L}=\bar{l}] \prod_{k=0}^{K} f(l_k | c_k=0, \bar{a}_{k-1}, \bar{l}_{k-1})
\]</span></p>
<section id="수식-해석" class="level3">
<h3 class="anchored" data-anchor-id="수식-해석">수식 해석</h3>
<ul>
<li><ol type="1">
<li><strong>조건부 기대값 <span class="math inline">\(E[Y|\dots]\)</span></strong>: 모든 시점에서 중도절단이 발생하지 않았고(<span class="math inline">\(\bar{C}=\bar{0}\)</span>), 처치 <span class="math inline">\(\bar{a}\)</span>를 받았으며, 공변량 이력이 <span class="math inline">\(\bar{l}\)</span>인 집단에서의 결과값입니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>확률 밀도 곱 <span class="math inline">\(\prod f(\dots)\)</span></strong>: 각 시점 <span class="math inline">\(k\)</span>에서 이전까지 중도절단되지 않은(<span class="math inline">\(c_k=0\)</span>) 생존자들 내에서 공변량 <span class="math inline">\(L_k\)</span>가 나타날 확률을 누적합니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>합 <span class="math inline">\(\sum_{\bar{l}}\)</span></strong>: 모든 가능한 공변량 경로에 대해 가중 평균을 구합니다.</li>
</ol></li>
<li>이 식은 “모든 개인이 처치 전략 <span class="math inline">\(\bar{a}\)</span>를 받고 중도절단되지 않았을 때 관찰되었을 평균 결과”를 나타냅니다.</li>
</ul>
</section>
</section>
<section id="method-2-ip-weighting-inverse-probability-weighting" class="level2">
<h2 class="anchored" data-anchor-id="method-2-ip-weighting-inverse-probability-weighting">4. Method 2: IP Weighting (Inverse Probability Weighting)</h2>
<ul>
<li>IP Weighting은 중도절단으로 인한 선택 편향(selection bias)을 보정하기 위해 <strong>가상의 모집단(Pseudo-population)</strong>을 생성하는 방식입니다. 이 가상 모집단에서는 중도절단이 제거되거나(unstabilized), 무작위로 발생(stabilized)합니다.</li>
</ul>
<section id="non-stabilized-ip-weights-for-censoring" class="level3">
<h3 class="anchored" data-anchor-id="non-stabilized-ip-weights-for-censoring">4.1. Non-stabilized IP Weights for Censoring</h3>
<ul>
<li>중도절단을 보정하기 위한 가중치 <span class="math inline">\(W^{\bar{C}}\)</span>는 다음과 같이 정의됩니다.</li>
</ul>
<p><span class="math display">\[
W^{\bar{C}} = \prod_{k=1}^{K+1} \frac{1}{Pr(C_k=0 | C_{k-1}=0, \bar{A}_{k-1}, \bar{L}_{k-1})}
\]</span></p>
<ul>
<li><strong>분모</strong>: 과거의 처치 및 공변량 이력이 주어졌을 때, 현재 시점에서 중도절단되지 않을 확률입니다. 로지스틱 회귀 등을 통해 추정합니다.</li>
<li><strong>해석</strong>: 중도절단될 확률이 높은 특성을 가진 사람에게 더 큰 가중치를 부여하여, 중도절단으로 사라진 사람들을 “복제”해 채워 넣는 개념입니다. 결과적으로 가상 모집단에서는 중도절단이 존재하지 않게 됩니다.</li>
</ul>
</section>
<section id="joint-weights-treatment-censoring" class="level3">
<h3 class="anchored" data-anchor-id="joint-weights-treatment-censoring">4.2. Joint Weights (Treatment + Censoring)</h3>
<ul>
<li>처치 <span class="math inline">\(A\)</span>와 중도절단 <span class="math inline">\(C\)</span>를 동시에 보정하기 위해, 두 가중치를 곱하여 사용합니다.</li>
</ul>
<p><span class="math display">\[
W_{joint} = W^{\bar{A}} \times W^{\bar{C}}
\]</span></p>
<ul>
<li>이 가중치를 사용하여 결과 변수 <span class="math inline">\(Y\)</span>에 대한 회귀분석(예: <span class="math inline">\(E[Y|\bar{A}, \bar{C}=\bar{0}] = \theta_0 + \theta_1 \text{cum}(\bar{A})\)</span>)을 수행하면 인과 효과를 추정할 수 있습니다.</li>
</ul>
</section>
<section id="stabilized-weights-swbarc" class="level3">
<h3 class="anchored" data-anchor-id="stabilized-weights-swbarc">4.3. Stabilized Weights (<span class="math inline">\(SW^{\bar{C}}\)</span>)</h3>
<ul>
<li>비안정화 가중치는 가상 모집단의 크기를 팽창시킬 수 있습니다. 이를 방지하기 위해 분자에 주변 확률(marginal probability)을 추가한 안정화 가중치를 사용합니다.</li>
</ul>
<p><span class="math display">\[
SW^{\bar{C}} = \prod_{k=1}^{K+1} \frac{Pr(C_k=0 | C_{k-1}=0, \bar{A}_{k-1})}{Pr(C_k=0 | C_{k-1}=0, \bar{A}_{k-1}, \bar{L}_{k-1})}
\]</span></p>
<ul>
<li><strong>분자</strong>: 공변량 <span class="math inline">\(L\)</span>을 조건부로 하지 않은, 처치 이력 <span class="math inline">\(\bar{A}\)</span>에 따른 중도절단 확률입니다.</li>
<li><strong>효과</strong>: 안정화 가중치를 사용한 가상 모집단은 원래 연구 모집단 중 중도절단되지 않은 사람들의 크기와 동일하게 유지됩니다. 여기서 중도절단은 완전히 사라지는 것이 아니라, 공변량 <span class="math inline">\(L\)</span>과 무관하게(at random) 발생하게 됩니다.</li>
</ul>
</section>
</section>
<section id="method-3-g-estimation" class="level2">
<h2 class="anchored" data-anchor-id="method-3-g-estimation">5. Method 3: G-Estimation</h2>
<ul>
<li><p>구조적 중첩 평균 모델(Structural Nested Mean Models)을 이용한 G-estimation을 수행할 때도 중도절단 보정은 필수적입니다.</p></li>
<li><ol type="1">
<li><strong>Step 1 (IPW for Censoring):</strong> 먼저 중도절단에 대한 비안정화 가중치 <span class="math inline">\(W^{\bar{C}}\)</span>를 추정합니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Step 2 (Pseudo-population):</strong> <span class="math inline">\(W^{\bar{C}}\)</span>를 이용해 “아무도 중도절단되지 않은” 가상 모집단을 생성합니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Step 3 (G-estimation):</strong> 이 가상 모집단 데이터에 대해 처치 <span class="math inline">\(A\)</span>에 대한 G-estimation을 적용합니다.</li>
</ol></li>
<li><p>이는 G-estimation 자체가 처치의 효과를 추정하는 데 특화되어 있기 때문에, 데이터 누락(censoring) 문제는 IP Weighting으로 먼저 해결하고 들어가는 전략입니다.</p></li>
</ul>
</section>
<section id="extension-survival-analysis-technical-point-21.10" class="level2">
<h2 class="anchored" data-anchor-id="extension-survival-analysis-technical-point-21.10">6. Extension: Survival Analysis (Technical Point 21.10)</h2>
<ul>
<li><p>기존의 분석이 ’특정 시점에 사건이 발생했는가(<span class="math inline">\(Y\)</span>)’를 다루었다면, <strong>생존 분석(Survival Analysis)</strong>은 ’사건이 발생하기까지 <strong>시간이 얼마나 걸리는가(Failure time)</strong>’를 다룹니다.</p></li>
<li><p>이 섹션에서는 시간이 지남에 따라 처치(<span class="math inline">\(A\)</span>)가 변하고, 중도절단(Censoring, <span class="math inline">\(C\)</span>)이 발생할 수 있는 복잡한 상황에서 인과효과를 추정하는 방법을 설명합니다.</p></li>
</ul>
<section id="the-goal-estimating-counterfactual-risk" class="level3">
<h3 class="anchored" data-anchor-id="the-goal-estimating-counterfactual-risk">6.1. The Goal: Estimating Counterfactual Risk</h3>
<ul>
<li>우리의 목표는 특정 처치 전략 <span class="math inline">\(\bar{a}\)</span>를 따르고, 중도절단이 전혀 발생하지 않았을 때(<span class="math inline">\(\bar{c}=\bar{0}\)</span>)의 <strong>반사실적 위험(Counterfactual Risk)</strong>을 추정하는 것입니다. <span class="math display">\[
\text{Risk} = \Pr [D_{k+1}^{\bar{a}, \bar{c}=\bar{0}} = 1]
\]</span>
<ul>
<li>여기서 <span class="math inline">\(D_k\)</span>는 시점 <span class="math inline">\(k\)</span>에서의 사건 발생 여부(1=사망/발생, 0=생존)를 의미합니다. 즉, <span class="math inline">\(k+1\)</span> 시점까지 사건이 발생할 확률을 구하는 것입니다.</li>
</ul></li>
</ul>
</section>
<section id="approach-1-the-g-formula" class="level3">
<h3 class="anchored" data-anchor-id="approach-1-the-g-formula">6.2. Approach 1: The g-formula</h3>
<ul>
<li>첫 번째 방법은 <strong>g-formula</strong>를 직접 사용하는 것입니다. 이는 <span class="math inline">\(k+1\)</span> 시점까지 생존할 확률(<span class="math inline">\(D_{k+1}=0\)</span>)을 계산한 뒤, 전체 1에서 빼는 방식으로 위험을 구합니다.</li>
</ul>
<p><span class="math display">\[
\text{Risk} = 1 - \sum_{\bar{l}_k} \Pr [D_{k+1} = 0 | \bar{A}_k = \bar{a}_k, \bar{L}_k = \bar{l}_k, D_k = C_{k+1} = 0] \times
\]</span> <span class="math display">\[
\prod_{m=0}^{k} f(l_m|\bar{a}_{m-1}, \bar{l}_{m-1}, D_m=C_m=0) \Pr [D_m=0|\bar{A}_{m-1}=\bar{a}_{m-1}, \bar{L}_{m-1}=\bar{l}_{m-1}, D_{m-1}=C_m=0]
\]</span></p>
<ul>
<li><strong>의미:</strong> 이 수식은 복잡해 보이지만, 핵심은 <strong>“시뮬레이션”</strong>입니다.
<ul>
<li>매 시점(<span class="math inline">\(m\)</span>)마다 공변량(<span class="math inline">\(L\)</span>)이 어떻게 변하고, 그에 따라 생존(<span class="math inline">\(D=0\)</span>)할 확률이 얼마인지 차근차근 계산하여 곱해나갑니다(Product <span class="math inline">\(\prod\)</span>).</li>
<li>마지막으로 가능한 모든 공변량의 역사(<span class="math inline">\(\bar{l}_k\)</span>)에 대해 합산(Sum <span class="math inline">\(\sum\)</span>)하여 전체 평균 위험을 도출합니다.</li>
</ul></li>
</ul>
</section>
<section id="approach-2-ip-weighting-pooled-logistic-model" class="level3">
<h3 class="anchored" data-anchor-id="approach-2-ip-weighting-pooled-logistic-model">6.3. Approach 2: IP Weighting (Pooled Logistic Model)</h3>
<ul>
<li><p>두 번째 방법은 <strong>역확률 가중치(IP Weighting)</strong>를 사용하는 것입니다. 생존 분석 데이터는 사람마다 관찰 기간이 다르므로, 모든 시점의 데이터를 세로로 길게 쌓은(Stacked) <strong>Pooled Logistic Model</strong>을 주로 사용합니다.</p></li>
<li><p>이때, <strong>시간 가변 가중치(Time-varying weights)</strong>를 각 개인의 각 시점 데이터에 적용해야 합니다. 가중치는 처치에 대한 가중치(<span class="math inline">\(W^A\)</span>)와 중도절단에 대한 가중치(<span class="math inline">\(W^C\)</span>)의 곱으로 이루어집니다.</p></li>
<li><p><strong>1) 처치 가중치 (<span class="math inline">\(W_k^A\)</span>)</strong></p>
<ul>
<li>시간 <span class="math inline">\(k\)</span>까지 내가 받은 처치(<span class="math inline">\(A\)</span>)를 받을 확률의 역수입니다. <span class="math display">\[
W_k^{A} = \prod_{m=0}^{k} \frac{1}{f(A_m | \bar{A}_{m-1}, D_m = C_m = 0, \bar{L}_m)}
\]</span></li>
</ul></li>
<li><p><strong>2) 중도절단 가중치 (<span class="math inline">\(W_k^C\)</span>)</strong></p>
<ul>
<li>시간 <span class="math inline">\(k\)</span>까지 중도절단 되지 않고 계속 관찰될(<span class="math inline">\(C=0\)</span>) 확률의 역수입니다. <span class="math display">\[
W_k^{C} = \prod_{m=1}^{k} \frac{1}{\Pr(C_m=0 | \bar{A}_{m-1}, D_{m-1}=C_{m-1}=0, \bar{L}_{m-1})}
\]</span></li>
</ul></li>
<li><p><strong>조건 설명:</strong> 수식의 분모에 있는 <span class="math inline">\(D_{m-1}=0\)</span>과 <span class="math inline">\(C_{m-1}=0\)</span> 조건은 “이전 시점까지 살아있었고, 중도절단되지 않은 사람”들만을 대상으로 확률을 계산한다는 뜻입니다. 이미 사망하거나 사라진 사람은 위험을 계산할 수 없기 때문입니다.</p></li>
</ul>
</section>
<section id="causal-graph-dag-interpretation" class="level3">
<h3 class="anchored" data-anchor-id="causal-graph-dag-interpretation">6.4. Causal Graph (DAG) Interpretation</h3>
<ul>
<li>생존 분석의 인과 구조를 이해하기 위해 아래의 인과 다이어그램(DAG)을 살펴봅니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/figure_21_4.png" class="img-fluid figure-img"></p>
<figcaption>Figure 21.4: Causal diagram for time-varying treatment and failure time outcome. 화살표는 시간의 흐름에 따른 인과 관계를 나타냅니다. <span class="math inline">\(L_k\)</span>는 공변량, <span class="math inline">\(A_k\)</span>는 처치, <span class="math inline">\(D_k\)</span>는 사건 발생을 의미합니다.</figcaption>
</figure>
</div>
<ul>
<li><strong>변수 설명:</strong>
<ul>
<li><span class="math inline">\(L_k\)</span>: 시점 <span class="math inline">\(k\)</span>에서의 공변량 (건강 상태 등)</li>
<li><span class="math inline">\(A_k\)</span>: 시점 <span class="math inline">\(k\)</span>에서의 처치 (약물 복용 여부 등)</li>
<li><span class="math inline">\(D_k\)</span>: 시점 <span class="math inline">\(k\)</span>에서의 사건 발생 여부 (1=사망, 0=생존)</li>
<li><span class="math inline">\(U_k\)</span>: 측정되지 않은 교란 요인 (Unmeasured Confounders)</li>
</ul></li>
<li><strong>구조적 특징:</strong>
<ol type="1">
<li><strong>시간의 흐름:</strong> <span class="math inline">\(L_0 \rightarrow A_0 \rightarrow D_1 \rightarrow L_1 \rightarrow A_1 \dots\)</span> 순서로 서로 영향을 주고받습니다.</li>
<li><strong>피드백 고리:</strong> 과거의 처치(<span class="math inline">\(A_0\)</span>)가 미래의 건강(<span class="math inline">\(L_1\)</span>)에 영향을 주고, 그 건강 상태(<span class="math inline">\(L_1\)</span>)가 다시 다음 처치(<span class="math inline">\(A_1\)</span>)에 영향을 줍니다.</li>
<li><strong>교란(Confounding):</strong> <span class="math inline">\(U_k\)</span>가 <span class="math inline">\(L_k\)</span>와 <span class="math inline">\(D_{k+1}\)</span>에 동시에 영향을 주어 인과 추론을 어렵게 만듭니다. IP Weighting이나 g-formula는 이러한 복잡한 시간 가변적 교란 요인을 통제하기 위해 설계되었습니다.</li>
</ol></li>
</ul>
<hr>
</section>
</section>
</section>
<section id="the-big-g-formula" class="level1">
<h1>21.6 The big g-formula</h1>
<section id="introduction-관측-데이터의-한계를-넘어서" class="level2">
<h2 class="anchored" data-anchor-id="introduction-관측-데이터의-한계를-넘어서">1. Introduction: 관측 데이터의 한계를 넘어서</h2>
<ul>
<li><p>우리는 지금까지 인과효과를 식별(Identification)하기 위해 주로 <strong>Sequential Exchangeability (순차적 교환가능성)</strong> 가정을 사용했습니다. 이는 우리가 측정한 공변량(covariates) <span class="math inline">\(\overline{L}\)</span>이 교란요인(confounder)을 충분히 통제한다고 가정할 때 유효합니다. 이 경우, 표준적인 <strong>g-formula</strong>를 통해 관측 데이터의 분포만으로 인과효과를 계산할 수 있었습니다.</p></li>
<li><p>하지만 현실은 복잡합니다. <strong>측정되지 않은 교란요인(Unmeasured Confounders, <span class="math inline">\(\overline{U}\)</span>)</strong>이 존재하여 <span class="math inline">\(\overline{L}\)</span>만으로는 교환가능성이 성립하지 않는다면 어떻게 해야 할까요?</p></li>
<li><p>이 포스트에서는 Hernán &amp; Robins의 <em>What If</em> Chapter 21.6에서 소개하는 <strong>The Big G-Formula</strong>를 다룹니다. 이는 측정 여부와 관계없이 <em>모든</em> 변수를 포함하는 이론적 공식으로, 인과추론의 난제(Front Door Criterion 등)를 해결하는 강력한 수학적 도구로 작동합니다.</p></li>
</ul>
</section>
<section id="factuals-vs.-counterfactuals" class="level2">
<h2 class="anchored" data-anchor-id="factuals-vs.-counterfactuals">2. Factuals vs.&nbsp;Counterfactuals</h2>
<ul>
<li><p>본격적인 수식에 앞서, 논문(책)에서 정의하는 변수의 범주를 명확히 할 필요가 있습니다.</p></li>
<li><p><strong>Observed Variables (관측 변수):</strong> <span class="math inline">\((\overline{A}, \overline{L}, Y)\)</span> - 우리가 데이터셋에서 실제로 볼 수 있는 값들입니다.</p></li>
<li><p><strong>Factuals (실제 변수):</strong> <span class="math inline">\((\overline{A}, \overline{L}, Y, \overline{U})\)</span> - 관측 여부와 상관없이, 실제 세계(Actual World)에 존재하는 모든 변수입니다. 여기서 <span class="math inline">\(\overline{U}\)</span>는 데이터 분석에는 사용할 수 없지만 실존하는 변수입니다.</p></li>
<li><p><strong>Counterfactuals (반사실적 변수):</strong> <span class="math inline">\(Y^{\overline{a}}\)</span> - 특정 처치 전략 <span class="math inline">\(g\)</span> 혹은 <span class="math inline">\(\overline{a}\)</span>를 따랐을 때 발생했을 잠재적 결과입니다.</p></li>
<li><p>저자들은 <strong>Factuals</strong>를 Counterfactuals와 구별하며, Big G-formula는 바로 이 Factuals의 결합 분포에 기반한다고 강조합니다.</p></li>
</ul>
</section>
<section id="the-big-g-formula의-정의" class="level2">
<h2 class="anchored" data-anchor-id="the-big-g-formula의-정의">3. The Big G-Formula의 정의</h2>
<ul>
<li><p>만약 우리가 신(God)의 관점에서 측정되지 않은 변수 <span class="math inline">\(\overline{U}\)</span>를 포함한 모든 변수 <span class="math inline">\(\overline{X} = (\overline{L}, \overline{U})\)</span>를 관측할 수 있다고 가정해 봅시다.</p></li>
<li><p>인과적 DAG(Directed Acyclic Graph)의 성질에 따라, 어떤 처치 변수 <span class="math inline">\(A\)</span>의 부모(Parents) 변수는 반드시 <span class="math inline">\(\overline{A}\)</span> (과거 처치) 혹은 <span class="math inline">\(\overline{X}\)</span> (모든 공변량) 안에 포함됩니다. 따라서, <span class="math inline">\(\overline{X}\)</span>를 조건부로 하면 <strong>항상(Always)</strong> 순차적 교환가능성이 성립합니다.</p></li>
<li><p>이를 수식으로 표현한 것이 바로 <strong>The Big G-Formula</strong>입니다.</p></li>
</ul>
<p><span class="math display">\[
f(y^g) = \int \prod_{k=0}^{K} f(x_k | \overline{x}_{k-1}, \overline{a}_{k-1}) dy d\overline{x}
\]</span></p>
<ul>
<li>하지만 이 식은 실용적이지 않습니다. 왜냐하면 식 안에 <strong>관측 불가능한 <span class="math inline">\(\overline{U}\)</span></strong>가 포함되어 있기 때문입니다. 그렇다면 이 식은 왜 중요할까요?</li>
</ul>
<blockquote class="blockquote">
<p><strong>핵심 질문 (The Mathematical Question):</strong></p>
<p>“관측되지 않은 변수 <span class="math inline">\(\overline{U}\)</span>를 포함하는 Big G-Formula를, DAG의 조건부 독립성(d-separation)만을 이용하여 <strong>오직 관측된 변수 <span class="math inline">\((\overline{A}, \overline{L}, Y)\)</span>만의 함수</strong>로 환원(Reduce)할 수 있는가?”</p>
</blockquote>
<ul>
<li>이 질문에 대한 답이 ’Yes’라면, 우리는 <span class="math inline">\(\overline{U}\)</span>를 측정하지 못해도 인과효과를 식별할 수 있습니다. 이것이 바로 Pearl의 <strong>ID Algorithm</strong>이나 <strong>Front Door Criterion</strong>이 작동하는 원리입니다.</li>
</ul>
</section>
<section id="case-study-front-door-criterion" class="level2">
<h2 class="anchored" data-anchor-id="case-study-front-door-criterion">4. Case Study: Front Door Criterion</h2>
<ul>
<li>Big G-Formula가 어떻게 관측 데이터 공식으로 변환되는지 가장 잘 보여주는 예시가 바로 <strong>Front Door Criterion</strong>입니다.</li>
</ul>
<section id="시나리오-설정" class="level3">
<h3 class="anchored" data-anchor-id="시나리오-설정">4.1. 시나리오 설정</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/figure_07_14.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Front Door Criterion DAG. A는 처치, Y는 결과, M은 매개변수, U는 A와 Y에 모두 영향을 주는 측정되지 않은 교란요인이다. A에서 Y로 가는 직접 경로는 없고 오직 M을 통해서만 흐른다.</figcaption>
</figure>
</div>
<ul>
<li>위 그림과 같은 상황을 가정해 봅시다.
<ul>
<li><span class="math inline">\(A \rightarrow Y\)</span>: 직접적인 화살표가 없음 (모든 효과는 <span class="math inline">\(M\)</span>을 통함)</li>
<li><span class="math inline">\(U \rightarrow A, U \rightarrow Y\)</span>: 측정되지 않은 교란요인 <span class="math inline">\(U\)</span>가 존재 (<span class="math inline">\(A\)</span>와 <span class="math inline">\(Y\)</span> 사이의 Back-door path가 열려 있음)</li>
<li><span class="math inline">\(A \rightarrow M \rightarrow Y\)</span>: <span class="math inline">\(A\)</span>의 효과는 <span class="math inline">\(M\)</span>을 통해서만 전달됨</li>
</ul></li>
<li>이 경우 <span class="math inline">\(U\)</span> 때문에 표준적인 G-formula는 사용할 수 없습니다. 하지만 Big G-Formula를 이용해 식별 식을 유도해낼 수 있습니다.</li>
</ul>
</section>
<section id="big-g-formula를-이용한-증명-derivation" class="level3">
<h3 class="anchored" data-anchor-id="big-g-formula를-이용한-증명-derivation">4.2. Big G-Formula를 이용한 증명 (Derivation)</h3>
<ul>
<li><p>Hernán &amp; Robins는 Technical Point 21.11에서 반사실적 변수(<span class="math inline">\(Y^m\)</span>)의 존재를 가정하지 않고, 오직 Factuals의 결합 분포와 d-separation만을 이용하여 <strong>Front Door Formula</strong>를 유도합니다.</p></li>
<li><p><strong>목표:</strong> <span class="math inline">\(P(Y^a = y)\)</span>를 관측 데이터 <span class="math inline">\((A, M, Y)\)</span>로 표현하기.</p></li>
<li><p><strong>Step 1: Big G-Formula 작성</strong></p>
<ul>
<li>모든 변수 <span class="math inline">\((A, M, Y, U)\)</span>를 포함한 G-formula는 다음과 같습니다. <span class="math display">\[
P(Y^a = y) = \sum_{m} \sum_{u} P(Y=y | M=m, A=a, U=u) P(M=m | A=a, U=u) P(U=u)
\]</span></li>
</ul></li>
<li><p><strong>Step 2: DAG 구조를 이용한 단순화</strong></p>
<ul>
<li>DAG(<span class="math inline">\(A \rightarrow M \rightarrow Y\)</span>, <span class="math inline">\(U \rightarrow A, U \rightarrow Y\)</span>)를 보면 다음 조건부 독립성이 성립합니다.
<ul>
<li><ol type="1">
<li><strong><span class="math inline">\(M \perp U | A\)</span></strong>: <span class="math inline">\(M\)</span>은 <span class="math inline">\(A\)</span>에 의해서만 결정되므로 (<span class="math inline">\(U \rightarrow A \rightarrow M\)</span>), <span class="math inline">\(A\)</span>가 주어지면 <span class="math inline">\(U\)</span>와 독립입니다. 따라서 <span class="math inline">\(P(M|A, U) = P(M|A)\)</span>.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong><span class="math inline">\(Y \perp A | M, U\)</span></strong>: <span class="math inline">\(A\)</span>가 <span class="math inline">\(Y\)</span>에 미치는 영향은 <span class="math inline">\(M\)</span>에 의해 차단(blocked)되므로, <span class="math inline">\(M\)</span>과 <span class="math inline">\(U\)</span>를 알면 <span class="math inline">\(Y\)</span>는 <span class="math inline">\(A\)</span>와 무관합니다. 따라서 <span class="math inline">\(P(Y|M, A, U) = P(Y|M, U)\)</span>.</li>
</ol></li>
</ul></li>
</ul></li>
<li><p>이 식을 Step 1에 대입합니다.</p></li>
</ul>
<p><span class="math display">\[
= \sum_{m} P(M=m|A=a) \sum_{u} P(Y=y | M=m, U=u) P(U=u)
\]</span></p>
<ul>
<li><strong>Step 3: U를 제거하기 위한 “Marginalization Trick”</strong>
<ul>
<li>여기서 천재적인 조작이 들어갑니다. <span class="math inline">\(P(U=u)\)</span>를 <span class="math inline">\(A\)</span>에 대해 주변화(marginalize)된 형태로 다시 씁니다. <span class="math display">\[
P(U=u) = \sum_{a'} P(U=u | A=a') P(A=a')
\]</span></li>
</ul></li>
<li>이를 위 식에 대입합니다.</li>
</ul>
<p><span class="math display">\[
= \sum_{m} P(M=m|A=a) \sum_{u} P(Y=y | M=m, U=u) \left\{ \sum_{a'} P(U=u | A=a') P(A=a') \right\}
\]</span></p>
<ul>
<li><strong>Step 4: 식 정리 및 Front Door Formula 도출</strong>
<ul>
<li>합(Summation)의 순서를 바꿉니다.</li>
</ul></li>
</ul>
<p><span class="math display">\[
= \sum_{m} P(M=m|A=a) \sum_{a'} P(A=a') \underbrace{\left\{ \sum_{u} P(Y=y | M=m, U=u) P(U=u | A=a') \right\}}_{(*)}
\]</span></p>
<ul>
<li>여기서 <span class="math inline">\((*)\)</span> 부분을 자세히 봅시다. <span class="math inline">\(M \perp U | A\)</span> (Step 2에서 확인)이므로, <span class="math inline">\(P(U=u|A=a') = P(U=u|M=m, A=a')\)</span>로 쓸 수 있습니다. 그렇다면 <span class="math inline">\((*)\)</span> 부분은 <span class="math inline">\(M, A\)</span>가 주어졌을 때 <span class="math inline">\(Y\)</span>의 주변 확률이 됩니다.</li>
</ul>
<p><span class="math display">\[
(*) = \sum_{u} P(Y=y | M=m, A=a', U=u) P(U=u | M=m, A=a') = P(Y=y | M=m, A=a')
\]</span></p>
<ul>
<li><p><strong>최종 결과:</strong> <span class="math display">\[
P(Y^a = y) = \sum_{m} P(M=m|A=a) \sum_{a'} P(Y=y | M=m, A=a') P(A=a')
\]</span></p></li>
<li><p>이것이 바로 우리가 아는 <strong>Front Door Formula</strong>입니다! 놀랍게도 식 안에 <span class="math inline">\(U\)</span>는 사라지고 모두 관측 가능한 <span class="math inline">\((A, M, Y)\)</span>만 남았습니다.</p></li>
</ul>
</section>
</section>
<section id="alternative-proof-swigs-single-world-intervention-graphs" class="level2">
<h2 class="anchored" data-anchor-id="alternative-proof-swigs-single-world-intervention-graphs">5. Alternative Proof: SWIGs (Single World Intervention Graphs)</h2>
<ul>
<li>Technical Point 21.12에서는 <strong>SWIGs</strong>를 이용한 또 다른 증명 방법을 제시합니다. 이 방법은 반사실적 변수들 간의 독립성을 시각적으로 파악하기 용이합니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>SWIG Property:</strong> <span class="math inline">\(G^a\)</span> (SWIG) 상에서, 고정된 노드(fixed node) <span class="math inline">\(a\)</span>가 공변량 <span class="math inline">\(C^a\)</span>를 조건부로 결과 <span class="math inline">\(B^a\)</span>와 d-separated 되어 있다면: <span class="math display">\[P(B^a=b | C^a=c) \text{ does not depend on } a\]</span> 즉, <span class="math inline">\(E[Y^a | M^a, A] = E[Y^{a'} | M^{a'}, A]\)</span> 가 성립합니다.</p>
</blockquote>
<ul>
<li>Front Door Graph의 SWIG에서 <span class="math inline">\(a\)</span>에서 <span class="math inline">\(Y^a\)</span>로 가는 길은 <span class="math inline">\(M^a\)</span>에 의해 막혀있습니다. 따라서 다음 등식이 성립합니다.</li>
</ul>
<p><span class="math display">\[
E[Y^a | M^a] = \sum_{a'} E[Y^a | M^a, A=a'] P(A=a' | M^a)
\]</span></p>
<ul>
<li><p>여기서 <span class="math inline">\(M^a \perp A\)</span> (M은 A의 하류 변수이므로 개입 시 독립) 이므로 <span class="math inline">\(P(A=a'|M^a) = P(A=a')\)</span>가 됩니다.</p></li>
<li><p>또한 SWIG property에 의해 <span class="math inline">\(E[Y^a | M^a, A=a'] = E[Y | M, A=a']\)</span> (Consistency)가 됩니다.</p></li>
<li><p>결국: <span class="math display">\[
E[Y^a] = \sum_m E[Y^a | M^a=m] P(M^a=m)
\]</span> <span class="math display">\[
= \sum_m \left( \sum_{a'} E[Y | M=m, A=a'] P(A=a') \right) P(M=m | A=a)
\]</span></p></li>
<li><p>이 방식은 수식 전개보다 그래프 상의 독립성을 직관적으로 활용한다는 장점이 있습니다.</p></li>
</ul>
</section>
<section id="summary-implications" class="level2">
<h2 class="anchored" data-anchor-id="summary-implications">6. Summary &amp; Implications</h2>
<ul>
<li>이 챕터가 시사하는 바는 다음과 같습니다.
<ul>
<li><ol type="1">
<li><strong>일반화된 도구:</strong> Big G-Formula는 관측되지 않은 변수가 있는 상황에서도 인과효과(Counterfactual mean)를 정의하는 가장 일반적인 수학적 틀(Mathematical framework)입니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>연결 고리:</strong> Tian &amp; Pearl (2002), Shpitser &amp; Pearl (2006) 등이 정립한 그래프 기반 식별 알고리즘(ID algorithm)이 결국 Big G-Formula를 관측 데이터 분포로 환원하는 과정임을 보여줍니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>인과성 vs 수학:</strong> Big G-Formula가 관측 데이터 공식으로 환원될 수 있는지는 <strong>순수하게 수학적인(d-separation) 문제</strong>입니다. 하지만 그 결과가 “인과효과”로 해석되려면, 우리가 그린 <strong>DAG가 실제 인과 관계를 정확히 반영(Causal DAG)</strong>한다는 전제가 필요합니다.</li>
</ol></li>
</ul></li>
</ul>



</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/shsha0110\.github\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>