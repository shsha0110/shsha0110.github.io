<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>shsha0110.github.io</title>
<link>https://shsha0110.github.io/</link>
<atom:link href="https://shsha0110.github.io/index.xml" rel="self" type="application/rss+xml"/>
<description>A blog built with Quarto</description>
<generator>quarto-1.8.26</generator>
<lastBuildDate>Wed, 21 Jan 2026 15:00:00 GMT</lastBuildDate>
<item>
  <title>[Causal Inference] 15. DiD &amp; SCM (Part 1)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L15/causal-inference-15-part-01/</link>
  <description><![CDATA[ 





<section id="overview" class="level1">
<h1>Overview</h1>
<ul>
<li>이번 포스트에서는 인과추론의 가장 강력하고 널리 쓰이는 도구 중 하나인 <strong>이중차분법(Differences in Differences, DiD)</strong>에 대해 다룹니다.</li>
<li>특히 잠재적 결과(Potential Outcomes) 프레임워크를 기반으로 DiD 추정량이 도출되는 과정을 수학적으로 엄밀하게 살펴보겠습니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>참고 자료</strong>: 본 포스트는 이상학 교수님의 “Differences in Differences &amp; Synthetic Control Method” 강의 자료를 바탕으로 재구성되었습니다.</p>
</blockquote>
<hr>
</section>
<section id="identification-problem" class="level1">
<h1>1. Identification Problem</h1>
<ul>
<li>인과추론의 근본적인 문제는 <strong>반사실(Counterfactual)</strong>을 관찰할 수 없다는 데 있습니다.</li>
</ul>
<section id="basic-setup" class="level2">
<h2 class="anchored" data-anchor-id="basic-setup">1.1 Basic Setup</h2>
<ul>
<li><p>두 개의 그룹과 두 개의 시점이 있다고 가정해 봅시다.</p></li>
<li><p><strong>집단 (Groups):</strong></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?G_i%20=%201">: 처치 집단 (Treated Group, 예: 최저임금이 인상된 뉴저지주)</li>
<li><img src="https://latex.codecogs.com/png.latex?G_i%20=%200">: 통제 집단 (Control Group, 예: 최저임금이 동결된 펜실베이니아주)</li>
</ul></li>
<li><p><strong>시점 (Time Periods):</strong></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?t%20=%200">: 개입 이전 (Pre-period)</li>
<li><img src="https://latex.codecogs.com/png.latex?t%20=%201">: 개입 이후 (Post-period)</li>
</ul></li>
</ul>
</section>
<section id="potential-outcomes" class="level2">
<h2 class="anchored" data-anchor-id="potential-outcomes">1.2 Potential Outcomes</h2>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Y_%7Bit%7D(x)">를 시점 <img src="https://latex.codecogs.com/png.latex?t">에서 처치 상태가 <img src="https://latex.codecogs.com/png.latex?x">일 때 개인 <img src="https://latex.codecogs.com/png.latex?i">의 잠재적 결과라고 정의합니다.</li>
<li>우리가 실제로 관찰하는 결과 <img src="https://latex.codecogs.com/png.latex?Y_%7Bit%7D">는 일치성(Consistency) 가정에 의해 다음과 같이 표현됩니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AY_%7Bit%7D%20=%20G_%7Bit%7DY_%7Bit%7D(1)%20+%20(1-G_%7Bit%7D)Y_%7Bit%7D(0)%0A"></p>
<ul>
<li>아래 테이블은 DiD 디자인에서 관측되는 잠재적 결과(Potential Outcomes)의 기댓값을 나타냅니다.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;"><strong>Pre-period (<img src="https://latex.codecogs.com/png.latex?t=0">)</strong></th>
<th style="text-align: center;"><strong>Post-period (<img src="https://latex.codecogs.com/png.latex?t=1">)</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>Treated group (<img src="https://latex.codecogs.com/png.latex?G_i=1">)</strong></td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?%5Ccolor%7Bpurple%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi0%7D(0)%20%5Cmid%20G_i=1%5D%7D"></td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?%5Ccolor%7Bgreen%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi1%7D(1)%20%5Cmid%20G_i=1%5D%7D"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>Control group (<img src="https://latex.codecogs.com/png.latex?G_i=0">)</strong></td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?%5Ccolor%7Borange%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi0%7D(0)%20%5Cmid%20G_i=0%5D%7D"></td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?%5Ccolor%7Bblue%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi1%7D(0)%20%5Cmid%20G_i=0%5D%7D"></td>
</tr>
</tbody>
</table>
</section>
<section id="att" class="level2">
<h2 class="anchored" data-anchor-id="att">1.3 ATT</h2>
<ul>
<li>우리의 목표는 <strong>처치 집단에 대한 평균 처치 효과(ATT: Average Treatment Effect on the Treated)</strong>를 구하는 것입니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctau_%7BATT%7D%20=%20%5Cmathbb%7BE%7D%5B%7B%5Ccolor%7Bgreen%7D%7BY_%7Bi1%7D(1)%7D%7D%20-%20%7B%5Ccolor%7Bred%7D%7BY_%7Bi1%7D(0)%7D%7D%20%7C%20G_i=1%5D%0A"></p>
<ul>
<li>이 식을 풀면 다음과 같습니다. <img src="https://latex.codecogs.com/png.latex?%0A%5Ctau_%7BATT%7D%20=%20%5Cunderbrace%7B%5Ccolor%7Bgreen%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi0%7D(0)%20%5Cmid%20G_i=1%5D%7D%7D_%7B%5Ctext%7B(a)%20%EA%B4%80%EC%B0%B0%20%EA%B0%80%EB%8A%A5%7D%7D%20-%20%5Cunderbrace%7B%5Ccolor%7Bred%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi1%7D(0)%20%7C%20G_i=1%5D%7D%7D_%7B%5Ctext%7B(b)%20%EB%B0%98%EC%82%AC%EC%8B%A4%20(%EA%B4%80%EC%B0%B0%20%EB%B6%88%EA%B0%80)%7D%7D%0A">
<ul>
<li><strong>(a)</strong>: 처치를 받은 집단의 처치 후 결과이므로 데이터에서 관찰할 수 있습니다.</li>
<li><strong>(b)</strong>:
<ul>
<li><strong>문제의 핵심</strong>입니다.</li>
<li>처치를 받은 집단이 만약 처치를 받지 <em>않았더라면</em> 겪었을 결과입니다.</li>
<li>이는 현실에 존재하지 않으므로, 적절한 대조군을 통해 추정해야 합니다.</li>
</ul></li>
</ul></li>
</ul>
<hr>
</section>
<section id="three-control-strategies" class="level2">
<h2 class="anchored" data-anchor-id="three-control-strategies">2. Three Control Strategies</h2>
<ul>
<li>반사실 <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BE%7D%5BY_%7Bi1%7D(0)%20%7C%20G_i=1%5D">을 대체하기 위해 우리는 어떤 전략을 취할 수 있을까요?</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L15/causal-inference-15-part-01/images/variation-to-exploit.png" class="img-fluid figure-img"></p>
<figcaption>Figure: <img src="https://latex.codecogs.com/png.latex?x">축은 시간(Time), <img src="https://latex.codecogs.com/png.latex?y">축은 평균 결과(Average Outcome)를 나타내며, 처치 집단과 통제 집단의 변화 추이를 시각화한 그래프입니다.</figcaption>
</figure>
</div>
<section id="전략-1-전후-비교-before-and-after-design" class="level3">
<h3 class="anchored" data-anchor-id="전략-1-전후-비교-before-and-after-design">전략 1: 전후 비교 (Before-and-After Design)</h3>
<ul>
<li>처치 집단의 개입 이전 시점(<img src="https://latex.codecogs.com/png.latex?t=0">) 결과를 반사실로 사용하는 방법입니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7B%5Ccolor%7Bred%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi1%7D(0)%20%7C%20G_i=1%5D%7D%7D%20%5Capprox%20%7B%5Ccolor%7Bpurple%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi0%7D(0)%20%7C%20G_i=1%5D%7D%7D%0A"></p>
<ul>
<li><strong>가정:</strong> 시간이 지나도 결과에 자연적인 변화(Trend)가 없어야 합니다.</li>
<li><strong>한계:</strong> 경기 변동이나 계절적 요인 등 시간의 흐름에 따른 변화를 무시합니다.</li>
</ul>
</section>
<section id="전략-2-횡단면-비교-cross-sectional-design" class="level3">
<h3 class="anchored" data-anchor-id="전략-2-횡단면-비교-cross-sectional-design">전략 2: 횡단면 비교 (Cross-sectional Design)</h3>
<ul>
<li>가장 단순한 접근은 처치 후 시점(<img src="https://latex.codecogs.com/png.latex?t=1">)에서 통제 집단의 결과를 반사실로 사용하는 것입니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7B%5Ccolor%7Bred%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi1%7D(0)%20%7C%20G_i=1%5D%7D%7D%20%5Capprox%20%7B%5Ccolor%7Bblue%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi1%7D(0)%20%7C%20G_i=0%5D%7D%7D%0A"></p>
<ul>
<li><strong>가정:</strong> 처치 여부가 결과와 독립적이어야 합니다 (Selection Bias가 없어야 함).</li>
<li><strong>한계:</strong> 두 집단은 처치 여부 외에도 원래부터 다른 특성을 가질 수 있습니다. 예를 들어, 뉴저지와 펜실베이니아는 경제 상황이 다를 수 있습니다.</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="이중차분법-difference-in-differences" class="level1">
<h1>3. 이중차분법 (Difference-in-Differences)</h1>
<ul>
<li>DiD는 위 두 전략의 한계를 극복하기 위해 <strong>“집단 간 차이”</strong>와 <strong>“시점 간 차이”</strong>를 결합합니다.</li>
</ul>
<section id="평행-추세-가정-parallel-trends-assumption" class="level2">
<h2 class="anchored" data-anchor-id="평행-추세-가정-parallel-trends-assumption">3.1 평행 추세 가정 (Parallel Trends Assumption)</h2>
<ul>
<li><p>DiD의 핵심 가정입니다.</p></li>
<li><p><strong>“처치가 없었더라면, 처치 집단의 평균 결과 변화량은 통제 집단의 변화량과 같았을 것”</strong>이라는 가정입니다.</p></li>
<li><p>수식으로는 다음과 같습니다: <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BE%7D%5B%7B%5Ccolor%7Bred%7D%7BY_%7Bi1%7D(0)%7D%7D%20-%20%7B%5Ccolor%7Bpurple%7D%7BY_%7Bi0%7D(0)%7D%7D%20%7C%20G_i=1%5D%20=%20%5Cmathbb%7BE%7D%5B%7B%5Ccolor%7Bblue%7D%7BY_%7Bi1%7D(0)%7D%7D%20-%20%20%7B%5Ccolor%7Borange%7D%7BY_%7Bi0%7D(0)%7D%7D%20%7C%20G_i=0%5D%0A"></p></li>
<li><p>이 가정을 이용해 우리가 모르는 반사실을 유도해 봅시다.</p></li>
<li><p>위 식을 이항하면 반사실 <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BE%7D%5BY_%7Bi1%7D(0)%20%7C%20G_i=1%5D">은 다음과 같이 표현됩니다.</p></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cunderbrace%7B%7B%5Ccolor%7Bred%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi1%7D(0)%20%7C%20G_i=1%5D%7D%7D%7D_%7B%5Ctext%7B%EB%B0%98%EC%82%AC%EC%8B%A4%7D%7D%20=%20%5Cunderbrace%7B%7B%5Ccolor%7Bpurple%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi0%7D(0)%20%7C%20G_i=1%5D%7D%7D%7D_%7B%5Ctext%7B%EC%B2%98%EC%B9%98%EC%A7%91%EB%8B%A8%20%EC%B4%88%EA%B8%B0%EA%B0%92%7D%7D%20+%20%5Cunderbrace%7B(%7B%5Ccolor%7Bblue%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi1%7D(0)%20%7C%20G_i=0%5D%7D%7D%20-%20%7B%5Ccolor%7Borange%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi0%7D(0)%20%7C%20G_i=0%5D%7D%7D)%7D_%7B%5Ctext%7B%ED%86%B5%EC%A0%9C%EC%A7%91%EB%8B%A8%EC%9D%98%20%EC%8B%9C%EA%B0%84%20%EC%B6%94%EC%84%B8%7D%7D%0A"></p>
<ul>
<li>즉, 처치 집단의 초기값에 통제 집단에서 관찰된 ’시간에 따른 변화분(Trend)’을 더해주면, 처치 집단이 처치를 받지 않았을 때의 결과를 추정할 수 있습니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L15/causal-inference-15-part-01/images/single-figure.png" class="img-fluid figure-img"></p>
<figcaption>Figure: 점선으로 표시된 부분은 평행 추세 가정에 기반하여 생성된 Counterfactual 지점입니다. 처치 집단(빨간색)의 실제 결과와 점선(Counterfactual)의 차이가 바로 인과 효과입니다.</figcaption>
</figure>
</div>
</section>
<section id="did-identification-result" class="level2">
<h2 class="anchored" data-anchor-id="did-identification-result">3.2 DiD Identification Result</h2>
<ul>
<li>이제 ATT 식에 위에서 구한 반사실을 대입해 보겠습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Ctau_%7BATT%7D%20&amp;=%20%7B%5Ccolor%7Bgreen%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi1%7D%20%7C%20G_i=1%5D%7D%7D%20-%20%7B%5Ccolor%7Bred%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi1%7D(0)%20%7C%20G_i=1%5D%7D%7D%20%5C%5C%0A&amp;=%20%7B%5Ccolor%7Bgreen%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi1%7D%20%7C%20G_i=1%5D%7D%7D%20-%20%5Cleft(%7B%5Ccolor%7Bpurple%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi0%7D%20%7C%20G_i=1%5D%7D%7D%20+%20(%7B%5Ccolor%7Bblue%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi1%7D%20%7C%20G_i=0%5D%7D%7D%20-%20%7B%5Ccolor%7Borange%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi0%7D%20%7C%20G_i=0%5D%7D%7D)%20%5Cright)%20%5C%5C%0A&amp;=%20%5Cleft(%20%7B%5Ccolor%7Bgreen%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi1%7D%20%7C%20G_i=1%5D%7D%7D%20-%20%7B%5Ccolor%7Bpurple%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi0%7D%20%7C%20G_i=1%5D%7D%7D%20%5Cright)%20-%20%5Cleft(%20%7B%5Ccolor%7Bblue%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi1%7D%20%7C%20G_i=0%5D%7D%7D%20-%20%7B%5Ccolor%7Borange%7D%7B%5Cmathbb%7BE%7D%5BY_%7Bi0%7D%20%7C%20G_i=0%5D%7D%7D%20%5Cright)%0A%5Cend%7Baligned%7D%0A"></p>
<ul>
<li>이 수식이 의미하는 바는 명확합니다:
<ul>
<li><ol type="1">
<li><strong>First Difference:</strong> 처치 집단의 전후 차이를 구합니다 (시간 효과 + 처치 효과).</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Second Difference:</strong> 통제 집단의 전후 차이를 구합니다 (순수 시간 효과).</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Difference-in-Differences:</strong> 1번에서 2번을 빼면 순수한 <strong>처치 효과(Treatment Effect)</strong>만 남습니다.</li>
</ol></li>
</ul></li>
</ul>
<hr>
</section>
</section>
<section id="estimation" class="level1">
<h1>4. Estimation</h1>
<ul>
<li>실제 데이터 분석에서는 회귀분석을 통해 표준오차(Standard Error)와 함께 추정량을 계산합니다.</li>
</ul>
<section id="이원-고정-효과-모형-two-way-fixed-effects-model" class="level2">
<h2 class="anchored" data-anchor-id="이원-고정-효과-모형-two-way-fixed-effects-model">4.1 이원 고정 효과 모형 (Two-way Fixed Effects Model)</h2>
<ul>
<li>단순한 평균의 차감 계산이 아니라, 회귀분석을 이용하면 표준오차(Standard Error)를 계산하고 다른 공변량을 통제하기 용이합니다.</li>
</ul>
<section id="회귀식의-정의" class="level3">
<h3 class="anchored" data-anchor-id="회귀식의-정의">4.1.1 회귀식의 정의</h3>
<ul>
<li>패널 데이터(혹은 반복 횡단면 데이터)에 대해 다음과 같은 선형 회귀식을 설정합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AY_%7Bit%7D%20=%20%5Calpha%20+%20%5Cgamma%20G_i%20+%20%5Cbeta%20t%20+%20%5Ctau%20X_%7Bit%7D%20+%20%5Cepsilon_%7Bit%7D%0A"></p>
<ul>
<li>여기서 변수들의 정의는 다음과 같습니다.
<ul>
<li><img src="https://latex.codecogs.com/png.latex?G_i">: <strong>집단 더미 (Group Dummy)</strong>. 처치 집단이면 1, 통제 집단이면 0.</li>
<li><img src="https://latex.codecogs.com/png.latex?t">: <strong>시점 더미 (Time Dummy)</strong>. 개입 이후(Post)면 1, 이전(Pre)이면 0.</li>
<li><img src="https://latex.codecogs.com/png.latex?X_%7Bit%7D">: <strong>상호작용항 (Interaction Term)</strong>. <img src="https://latex.codecogs.com/png.latex?G_i%20%5Ctimes%20t">와 동일하며, <strong>‘처치 집단이면서 동시에 개입 이후인 경우’</strong>에만 1을 갖습니다.</li>
</ul></li>
</ul>
</section>
<section id="계수의-유도-과정-derivation" class="level3">
<h3 class="anchored" data-anchor-id="계수의-유도-과정-derivation">4.1.2 계수의 유도 과정 (Derivation)</h3>
<ul>
<li>이 식을 이용해 4가지 경우의 수(처치/통제 <img src="https://latex.codecogs.com/png.latex?%5Ctimes"> 전/후)에 대한 기댓값 <img src="https://latex.codecogs.com/png.latex?E%5BY_%7Bit%7D%5D">를 계산해보면 각 계수의 의미가 명확해집니다.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">구분</th>
<th style="text-align: center;">시점 (<img src="https://latex.codecogs.com/png.latex?t">)</th>
<th style="text-align: center;">집단 (<img src="https://latex.codecogs.com/png.latex?G_i">)</th>
<th style="text-align: center;">상호작용 (<img src="https://latex.codecogs.com/png.latex?X_%7Bit%7D">)</th>
<th style="text-align: left;">기댓값 <img src="https://latex.codecogs.com/png.latex?E%5BY_%7Bit%7D%5D"></th>
<th style="text-align: left;">의미</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>통제 집단 / 전</strong></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?%5Calpha"></td>
<td style="text-align: left;"><strong>베이스라인</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>통제 집단 / 후</strong></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?%5Calpha%20+%20%5Cbeta"></td>
<td style="text-align: left;">시간의 흐름에 따른 자연적 변화 (<img src="https://latex.codecogs.com/png.latex?%5Cbeta">) 반영</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>처치 집단 / 전</strong></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?%5Calpha%20+%20%5Cgamma"></td>
<td style="text-align: left;">집단 간의 고유한 차이 (<img src="https://latex.codecogs.com/png.latex?%5Cgamma">) 반영</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>처치 집단 / 후</strong></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?%5Calpha%20+%20%5Cgamma%20+%20%5Cbeta%20+%20%5Ctau"></td>
<td style="text-align: left;">시간(<img src="https://latex.codecogs.com/png.latex?%5Cbeta">) + 집단(<img src="https://latex.codecogs.com/png.latex?%5Cgamma">) + <strong>정책효과(<img src="https://latex.codecogs.com/png.latex?%5Ctau">)</strong></td>
</tr>
</tbody>
</table>
</section>
<section id="이중차분-difference-in-differences-계산" class="level3">
<h3 class="anchored" data-anchor-id="이중차분-difference-in-differences-계산">4.1.3 이중차분 (Difference-in-Differences) 계산</h3>
<ul>
<li>위의 표를 바탕으로 DiD 연산을 수행해 봅시다.</li>
<li><ol type="1">
<li><strong>시간 전후 차이 (After - Before):</strong></li>
</ol>
<ul>
<li>통제 집단의 변화: <img src="https://latex.codecogs.com/png.latex?(%5Calpha%20+%20%5Cbeta)%20-%20%5Calpha%20=%20%5Cmathbf%7B%5Cbeta%7D"> (순수 시간 효과)</li>
<li>처치 집단의 변화: <img src="https://latex.codecogs.com/png.latex?(%5Calpha%20+%20%5Cgamma%20+%20%5Cbeta%20+%20%5Ctau)%20-%20(%5Calpha%20+%20%5Cgamma)%20=%20%5Cmathbf%7B%5Cbeta%20+%20%5Ctau%7D"> (시간 효과 + 처치 효과)</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>집단 간 차이 (Treated - Control):</strong></li>
</ol>
<ul>
<li>변화량의 차이: <img src="https://latex.codecogs.com/png.latex?(%5Cbeta%20+%20%5Ctau)%20-%20%5Cbeta%20=%20%5Cmathbf%7B%5Ctau%7D"></li>
</ul></li>
<li><strong>결론적으로 회귀계수 <img src="https://latex.codecogs.com/png.latex?%5Ctau">는 우리가 구하고자 하는 이중차분 추정량(ATT)과 정확히 일치합니다.</strong></li>
</ul>
</section>
</section>
<section id="실제-사례-card-krueger-1994" class="level2">
<h2 class="anchored" data-anchor-id="실제-사례-card-krueger-1994">4.2 실제 사례: Card &amp; Krueger (1994)</h2>
<ul>
<li>최저임금 인상이 고용에 미치는 영향을 분석한 고전적인 연구입니다.</li>
<li><strong>Question:</strong> 최저임금을 올리면 고용이 감소하는가?</li>
<li><strong>Setting:</strong> 1992년 뉴저지(NJ)는 최저임금을 $4.25에서 $5.05로 인상(처치 집단), 펜실베이니아(PA)는 동결(통제 집단).</li>
<li><strong>Result:</strong> 두 주(State)의 패스트푸드점 고용 변화를 DiD로 분석한 결과, 통념과 달리 고용 감소 효과가 뚜렷하지 않음을 보였습니다.</li>
</ul>
<hr>
</section>
</section>
<section id="threat-to-identification-and-falsification-test" class="level1">
<h1>5. Threat to Identification and Falsification Test</h1>
<ul>
<li>DiD가 강력한 도구이긴 하지만, <strong>평행 추세 가정</strong>이 위배되면 결과는 편향됩니다.</li>
</ul>
<section id="ashenfelters-dip" class="level2">
<h2 class="anchored" data-anchor-id="ashenfelters-dip">5.1 Ashenfelter’s Dip</h2>
<ul>
<li>직업 훈련 프로그램 등의 효과를 분석할 때 자주 나타나는 현상입니다.</li>
<li>처치를 받기 직전에 소득이 일시적으로 급락하는 현상을 말합니다.</li>
<li>이 경우 처치 이전의 추세가 평행하지 않을 수 있으므로 주의해야 합니다.</li>
</ul>
</section>
<section id="위조-검증-falsification-test" class="level2">
<h2 class="anchored" data-anchor-id="위조-검증-falsification-test">5.2 위조 검증 (Falsification Test)</h2>
<ul>
<li>평행 추세 가정을 간접적으로 검증하기 위해 <strong>개입 이전 시점(Pre-treatment period)</strong>들의 데이터를 사용합니다.</li>
<li>개입이 없었던 과거 기간 동안에도 두 집단의 추세가 평행했는지 확인하는 것입니다. 만약 과거에도 추세가 달랐다면, 미래에도 달랐을 가능성이 높습니다.</li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L15/causal-inference-15-part-01/</guid>
  <pubDate>Wed, 21 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 15. DiD &amp; SCM (Part 2)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L15/causal-inference-15-part-02/</link>
  <description><![CDATA[ 





<section id="overview-선형-did의-한계" class="level1">
<h1>Overview: 선형 DiD의 한계</h1>
<ul>
<li>지난 포스트에서 다룬 표준 이중차분법(Standard DiD)은 강력하지만, 중요한 가정을 전제로 합니다.</li>
<li>바로 <strong>“평행 추세(Parallel Trends)”</strong> 가정입니다.</li>
<li>하지만 이 가정은 결과 변수(<img src="https://latex.codecogs.com/png.latex?Y">)의 <strong>선형성(Linearity)</strong>에 의존적이라는 한계가 있습니다.</li>
<li>예를 들어, 소득(<img src="https://latex.codecogs.com/png.latex?Y">)에 대해서는 평행 추세가 성립하더라도, 로그 소득(<img src="https://latex.codecogs.com/png.latex?%5Clog%20Y">)에 대해서는 성립하지 않을 수 있습니다(Not invariant to nonlinear transformations).</li>
<li>만약 정책 효과가 소득 구간별로 다르게 나타난다면(예: 저소득층에게 더 큰 효과), 평균값의 변화만 보는 선형 DiD는 이러한 분포의 변화를 놓치게 됩니다.</li>
<li>이번 포스트에서는 이러한 선형성 가정을 완화하고, 분포 전체의 변화를 추정할 수 있는 <strong>비선형 이중차분법(Nonlinear DiD)</strong>, 일명 <strong>Changes-in-Changes (CiC)</strong> 모델에 대해 알아봅니다.</li>
</ul>
<hr>
</section>
<section id="직관적-이해-분위수-매핑-quantile-mapping" class="level1">
<h1>1. 직관적 이해: 분위수 매핑 (Quantile Mapping)</h1>
<ul>
<li>비선형 DiD의 핵심 아이디어는 “평균의 변화”가 아니라 <strong>“분위수(Quantile)의 변화”</strong>를 비교하는 것입니다.</li>
</ul>
<section id="시각적-설명" class="level2">
<h2 class="anchored" data-anchor-id="시각적-설명">시각적 설명</h2>
<ul>
<li>아래 그림은 통제 집단(Control)과 처치 집단(Treated)의 누적 분포 함수(CDF)가 시간이 지남에 따라 어떻게 변하는지를 보여줍니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L15/causal-inference-15-part-02/images/nonlinear_did_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure: <img src="https://latex.codecogs.com/png.latex?x">축은 결과값, <img src="https://latex.codecogs.com/png.latex?y">축은 확률(0~1)을 나타냅니다. <img src="https://latex.codecogs.com/png.latex?r_0(q)">와 <img src="https://latex.codecogs.com/png.latex?r_1(q)">는 각각 통제 집단과 처치 집단에서 특정 분위수 <img src="https://latex.codecogs.com/png.latex?q">에 해당하는 값의 시간적 변화(매핑)를 의미합니다.</figcaption>
</figure>
</div>
<ul>
<li><strong>통제 집단의 변화 (<img src="https://latex.codecogs.com/png.latex?r_0(q)">):</strong> <img src="https://latex.codecogs.com/png.latex?t=0"> 시점의 <img src="https://latex.codecogs.com/png.latex?q"> 분위수 값이 <img src="https://latex.codecogs.com/png.latex?t=1"> 시점에 어떻게 변했는지 보여줍니다.</li>
<li><strong>가정:</strong> 처치 집단이 처치를 받지 않았더라면, <strong>“시간에 따른 분위수의 변화 양상”</strong>이 통제 집단과 동일했을 것이라고 가정합니다.</li>
<li>즉, 통제 집단에서의 매핑(화살표)을 처치 집단에 그대로 적용하여 반사실(Counterfactual)을 구성합니다.</li>
</ul>
<hr>
</section>
</section>
<section id="수식적-정의-formalization" class="level1">
<h1>2. 수식적 정의 (Formalization)</h1>
<ul>
<li>이제 이를 수학적으로 엄밀하게 정의해 봅시다.</li>
</ul>
<section id="분포-함수-distribution-functions" class="level2">
<h2 class="anchored" data-anchor-id="분포-함수-distribution-functions">2.1 분포 함수 (Distribution Functions)</h2>
<ul>
<li>우선, 각 집단(<img src="https://latex.codecogs.com/png.latex?G_i=g">)과 시점(<img src="https://latex.codecogs.com/png.latex?t">)에서의 잠재적 결과(Potential Outcome) <img src="https://latex.codecogs.com/png.latex?Y(0)">(처치받지 않음)의 누적 분포 함수를 정의합니다. <img src="https://latex.codecogs.com/png.latex?%0AF_%7Bgt%7D(y)%20=%20P(Y_%7Bit%7D(0)%20%5Cle%20y%20%7C%20G_i%20=%20g)%0A">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?g%20%5Cin%20%5C%7B0,%201%5C%7D%5Ctextit%7B(0:%20%ED%86%B5%EC%A0%9C,%201:%20%EC%B2%98%EC%B9%98)%7D"></li>
<li><img src="https://latex.codecogs.com/png.latex?t%20%5Cin%20%5C%7B0,%201%5C%7D%5Ctextit%7B(0:%20%EC%A0%84,%201:%20%ED%9B%84)%7D"></li>
</ul></li>
<li>우리가 관찰할 수 있는 분포들은 <img src="https://latex.codecogs.com/png.latex?F_%7B00%7D,%20F_%7B01%7D,%20F_%7B10%7D">입니다.</li>
<li>처치 집단의 사후 결과인 <img src="https://latex.codecogs.com/png.latex?F_%7B11%7D">은 처치(<img src="https://latex.codecogs.com/png.latex?Y(1)">)를 받은 상태이므로, 처치를 받지 않았을 상태(<img src="https://latex.codecogs.com/png.latex?Y(0)">)인 <img src="https://latex.codecogs.com/png.latex?F_%7B11%7D">은 <strong>반사실(Counterfactual)</strong>로서 식별해야 할 대상입니다.</li>
</ul>
</section>
<section id="분위수-처치-효과-quantile-treatment-effect-qte" class="level2">
<h2 class="anchored" data-anchor-id="분위수-처치-효과-quantile-treatment-effect-qte">2.2 분위수 처치 효과 (Quantile Treatment Effect, QTE)</h2>
<ul>
<li>우리의 목표는 특정 분위수 <img src="https://latex.codecogs.com/png.latex?q">에서의 처치 효과 <img src="https://latex.codecogs.com/png.latex?%5Ctau(q)">를 구하는 것입니다. <img src="https://latex.codecogs.com/png.latex?%0A%5Ctau(q)%20=%20%5Cunderbrace%7B%5Ctilde%7BF%7D_%7B11%7D%5E%7B-1%7D(q)%7D_%7B%5Ctext%7B%EA%B4%80%EC%B8%A1%EA%B0%92%7D%7D%20-%20%5Cunderbrace%7BF_%7B11%7D%5E%7B-1%7D(q)%7D_%7B%5Ctext%7B%EB%B0%98%EC%82%AC%EC%8B%A4(%EC%B6%94%EC%A0%95%EA%B0%92)%7D%7D%0A">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctilde%7BF%7D_%7B11%7D(y)%20=%20P(Y_%7Bi1%7D(1)%20%5Cle%20y%20%7C%20G_i%20=%201)">:
<ul>
<li>실제로 관측된 처치 집단의 사후 결과 분포 (<img src="https://latex.codecogs.com/png.latex?Y(1)">).</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?F_%7B11%7D(y)">:
<ul>
<li>우리가 추정해야 할 처치 집단의 반사실적 사후 결과 분포 (<img src="https://latex.codecogs.com/png.latex?Y(0)">).</li>
</ul></li>
</ul></li>
</ul>
<hr>
</section>
</section>
<section id="식별-가정-및-유도-identification" class="level1">
<h1>3. 식별 가정 및 유도 (Identification)</h1>
<ul>
<li>비선형 DiD의 핵심 가정은 <strong>“분위수 변화의 불변성”</strong>입니다.</li>
<li>Athey &amp; Imbens (2006)의 Changes-in-Changes 모델로도 알려져 있습니다.</li>
</ul>
<section id="식별-가정-identification-assumption" class="level2">
<h2 class="anchored" data-anchor-id="식별-가정-identification-assumption">3.1 식별 가정 (Identification Assumption)</h2>
<ul>
<li>모든 분위수 <img src="https://latex.codecogs.com/png.latex?q%20%5Cin%20%5B0,%201%5D">에 대하여 다음이 성립한다고 가정합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AF_%7B01%7D(F_%7B00%7D%5E%7B-1%7D(q))%20=%20F_%7B11%7D(F_%7B10%7D%5E%7B-1%7D(q))%0A"></p>
<ul>
<li>이 수식의 의미를 단계별로 풀어보겠습니다.
<ul>
<li><ol type="1">
<li><strong>좌변 (<img src="https://latex.codecogs.com/png.latex?F_%7B01%7D(F_%7B00%7D%5E%7B-1%7D(q))">):</strong></li>
</ol>
<ul>
<li>통제 집단에서 시점 0에 <img src="https://latex.codecogs.com/png.latex?q"> 분위수에 해당하는 값(<img src="https://latex.codecogs.com/png.latex?F_%7B00%7D%5E%7B-1%7D(q)">)을 찾습니다.</li>
<li>그 값이 시점 1의 분포(<img src="https://latex.codecogs.com/png.latex?F_%7B01%7D">)에서 차지하는 위치(확률)를 봅니다.</li>
<li>즉, <strong>통제 집단에서 시간이 흐름에 따라 순위(Rank)가 어떻게 변했는지</strong>를 나타냅니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>우변 (<img src="https://latex.codecogs.com/png.latex?F_%7B11%7D(F_%7B10%7D%5E%7B-1%7D(q))">):</strong></li>
</ol>
<ul>
<li>처치 집단에서도 동일하게, 시점 0에 <img src="https://latex.codecogs.com/png.latex?q"> 분위수에 해당하는 값(<img src="https://latex.codecogs.com/png.latex?F_%7B10%7D%5E%7B-1%7D(q)">)을 찾습니다.</li>
<li>그 값이 시점 1의 반사실 분포(<img src="https://latex.codecogs.com/png.latex?F_%7B11%7D">)에서 갖게 될 위치를 나타냅니다.</li>
</ul></li>
<li><ol start="3" type="1">
<li><strong>결론:</strong> “시간에 따른 상대적 위치(Rank)의 변화 함수”는 두 집단 간에 동일하다는 것입니다.</li>
</ol></li>
</ul></li>
</ul>
</section>
<section id="반사실-분포-f_11y의-유도-과정" class="level2">
<h2 class="anchored" data-anchor-id="반사실-분포-f_11y의-유도-과정">3.2 반사실 분포 <img src="https://latex.codecogs.com/png.latex?F_%7B11%7D(y)">의 유도 과정</h2>
<ul>
<li><p>우리는 <img src="https://latex.codecogs.com/png.latex?F_%7B11%7D(y)">를 구하고 싶습니다. 위 식별 가정을 이용하여 이를 <img src="https://latex.codecogs.com/png.latex?y">에 대한 함수로 정리해 봅시다.</p></li>
<li><p><strong>단계 1: 목표 변수 설정</strong></p>
<ul>
<li>우변의 <img src="https://latex.codecogs.com/png.latex?F_%7B11%7D(%5Ccdot)"> 안에 있는 <img src="https://latex.codecogs.com/png.latex?F_%7B10%7D%5E%7B-1%7D(q)">를 <img src="https://latex.codecogs.com/png.latex?y">라고 둡니다.</li>
<li>즉, 어떤 결과값 <img src="https://latex.codecogs.com/png.latex?y">가 처치 집단의 사전 시점(<img src="https://latex.codecogs.com/png.latex?t=0">)에서 갖는 누적 확률(분위수)을 <img src="https://latex.codecogs.com/png.latex?q'">라고 합시다.</li>
</ul></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0Ay%20=%20F_%7B10%7D%5E%7B-1%7D(q')%20%5Ciff%20q'%20=%20F_%7B10%7D(y)%0A"></p>
<ul>
<li><strong>단계 2: 가정식에 대입</strong>
<ul>
<li>식별 가정 식의 <img src="https://latex.codecogs.com/png.latex?q"> 자리에 <img src="https://latex.codecogs.com/png.latex?q'%20=%20F_%7B10%7D(y)">를 대입합니다. <img src="https://latex.codecogs.com/png.latex?%0AF_%7B01%7D(F_%7B00%7D%5E%7B-1%7D(q'))%20=%20F_%7B11%7D(F_%7B10%7D%5E%7B-1%7D(q'))%0A"></li>
<li>여기에 <img src="https://latex.codecogs.com/png.latex?q'">와 <img src="https://latex.codecogs.com/png.latex?y">의 관계를 적용하면: <img src="https://latex.codecogs.com/png.latex?%0AF_%7B01%7D(F_%7B00%7D%5E%7B-1%7D(F_%7B10%7D(y)))%20=%20F_%7B11%7D(y)%0A"></li>
</ul></li>
<li><strong>단계 3: 결과 도출</strong></li>
<li>따라서, 처치 집단이 처치를 받지 않았을 때(<img src="https://latex.codecogs.com/png.latex?t=1">)의 잠재적 분포 <img src="https://latex.codecogs.com/png.latex?F_%7B11%7D(y)">는 관찰 가능한 데이터(<img src="https://latex.codecogs.com/png.latex?F_%7B01%7D,%20F_%7B00%7D,%20F_%7B10%7D">)만으로 다음과 같이 식별됩니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AF_%7B11%7D(y)%20=%20F_%7B01%7D%5Cleft%5B%20F_%7B00%7D%5E%7B-1%7D%20%5C%7B%20F_%7B10%7D(y)%20%5C%7D%20%5Cright%5D%0A"></p>
</section>
<section id="해석" class="level2">
<h2 class="anchored" data-anchor-id="해석">3.3 해석</h2>
<ul>
<li>이 최종 수식은 다음과 같은 알고리즘으로 이해할 수 있습니다.
<ul>
<li><ol type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?F_%7B10%7D(y)">:</strong> 처치 집단의 <img src="https://latex.codecogs.com/png.latex?t=0"> 시점에서 결과값 <img src="https://latex.codecogs.com/png.latex?y">의 분위수(Rank)를 찾습니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?F_%7B00%7D%5E%7B-1%7D(%5Ccdot)">:</strong> 통제 집단의 <img src="https://latex.codecogs.com/png.latex?t=0"> 시점에서 <strong>동일한 분위수</strong>를 가진 결과값을 찾습니다. (집단 간 비교 기준점 확보)</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?F_%7B01%7D(%5Ccdot)">:</strong> 그 결과값이 통제 집단의 <img src="https://latex.codecogs.com/png.latex?t=1"> 시점에서 갖는 새로운 분위수를 확인합니다. (시간 효과 반영)</li>
</ol></li>
<li><ol start="4" type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?F_%7B11%7D(y)">:</strong> 이 “변환된 분위수”가 바로 처치 집단(<img src="https://latex.codecogs.com/png.latex?t=1">)에서 <img src="https://latex.codecogs.com/png.latex?y">가 가질 누적 확률입니다.</li>
</ol></li>
</ul></li>
</ul>
<hr>
</section>
<section id="요약-및-시사점" class="level2">
<h2 class="anchored" data-anchor-id="요약-및-시사점">4. 요약 및 시사점</h2>
<ul>
<li><p>비선형 DiD(CiC)는 평균값 비교에 그치는 기존 DiD의 한계를 넘어, 정책이 <strong>전체 소득 분포나 특정 분위수(예: 하위 10%)</strong>에 미치는 영향을 정밀하게 분석할 수 있게 해줍니다.</p></li>
<li><p><strong>장점:</strong></p>
<ul>
<li>로그 변환 등 결과 변수의 비선형 변환에 영향을 받지 않습니다(Invariant).</li>
<li>평균뿐만 아니라 분포 전체의 처치 효과(QTE)를 추정할 수 있습니다.</li>
</ul></li>
<li><p><strong>조건:</strong></p>
<ul>
<li>연속적인 결과 변수에 적합하며, 역함수(<img src="https://latex.codecogs.com/png.latex?F%5E%7B-1%7D">)가 존재해야 하므로 분포 함수가 강단조증가(strictly increasing)해야 한다는 조건이 필요할 수 있습니다.</li>
</ul></li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L15/causal-inference-15-part-02/</guid>
  <pubDate>Wed, 21 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 15. DiD &amp; SCM (Part 3)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L15/causal-inference-15-part-03/</link>
  <description><![CDATA[ 





<section id="overview" class="level1">
<h1>Overview</h1>
<ul>
<li>지난 포스트들에서 우리는 이중차분법(DiD)을 통해 인과효과를 추정하는 방법을 배웠습니다.</li>
<li>하지만 DiD를 적용하기 어려운 상황이 종종 발생합니다. 바로 <strong>“적절한 통제 집단(Control Group)을 찾기 어려울 때”</strong>입니다.</li>
<li>예를 들어, 캘리포니아 주가 담배 규제 정책(Proposition 99)을 시행했을 때, 나머지 49개 주 전체를 평균 내어 비교하는 것이 공정할까요?</li>
<li>캘리포니아와 인구 구조, 경제 규모, 흡연 문화가 비슷한 단일한 주는 존재하지 않을지도 모릅니다.</li>
<li>이번 포스트에서는 이러한 문제를 해결하기 위해, 여러 통제 집단을 적절히 섞어 <strong>“가상의 도플갱어(Synthetic Control)”</strong>를 만들어내는 <strong>통제집단합성법(Synthetic Control Method, SCM)</strong>에 대해 알아봅니다.</li>
</ul>
<hr>
</section>
<section id="사례-연구-캘리포니아-담배-규제-proposition-99" class="level1">
<h1>1. 사례 연구: 캘리포니아 담배 규제 (Proposition 99)</h1>
<ul>
<li>1988년 캘리포니아 주는 담배 소비를 줄이기 위해 담배세를 인상하는 ’Proposition 99’를 통과시켰습니다. 이 정책의 효과를 어떻게 측정할 수 있을까요?</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L15/causal-inference-15-part-03/images/scm_control.png" class="img-fluid figure-img"></p>
<figcaption>Figure: 점선(Rest of the U.S.)은 캘리포니아(실선)와 정책 시행 이전(1988년 이전)부터 추세가 다릅니다. 이는 평행 추세 가정을 위배하며, 좋은 비교 대상이 아님을 보여줍니다(좌). 합성 캘리포니아(점선)는 정책 시행 이전까지 실제 캘리포니아(실선)와 거의 일치합니다. 따라서 1988년 이후 벌어지는 격차(Gap)를 순수한 정책 효과로 해석할 수 있습니다(우).</figcaption>
</figure>
</div>
<section id="단순-비교의-함정" class="level2">
<h2 class="anchored" data-anchor-id="단순-비교의-함정">1.1 단순 비교의 함정</h2>
<ul>
<li>가장 단순한 방법은 “캘리포니아”와 “나머지 미국 전체(Rest of the U.S.)”의 담배 판매량을 비교하는 것입니다.</li>
</ul>
</section>
<section id="합성-캘리포니아-synthetic-california의-등장" class="level2">
<h2 class="anchored" data-anchor-id="합성-캘리포니아-synthetic-california의-등장">1.2 합성 캘리포니아 (Synthetic California)의 등장</h2>
<ul>
<li>SCM은 다른 주들의 데이터를 가중 평균(Weighted Average)하여, 1988년 이전의 캘리포니아와 <strong>거의 완벽하게 겹치는</strong> 가상의 캘리포니아를 만들어냅니다.</li>
</ul>
<hr>
</section>
<section id="mathematical-framework" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-framework">2. Mathematical Framework</h2>
<ul>
<li>SCM을 수식으로 엄밀하게 정의해 봅시다.</li>
</ul>
</section>
<section id="setup" class="level2">
<h2 class="anchored" data-anchor-id="setup">2.1 Setup</h2>
<ul>
<li><p><strong>단일 처치 집단:</strong> <img src="https://latex.codecogs.com/png.latex?i=1"> (캘리포니아)</p></li>
<li><p><strong>통제 집단 풀(Donor Pool):</strong> <img src="https://latex.codecogs.com/png.latex?i=2,%20%5Cdots,%20J+1"> (나머지 주들)</p></li>
<li><p><strong>시간:</strong> <img src="https://latex.codecogs.com/png.latex?T_0"> (개입 이전 기간), <img src="https://latex.codecogs.com/png.latex?T"> (전체 기간)</p></li>
<li><p><strong>목표:</strong> 개입 이후(<img src="https://latex.codecogs.com/png.latex?t%20%3E%20T_0">)의 처치 효과 <img src="https://latex.codecogs.com/png.latex?%5Ctau_%7B1t%7D"> 추정 <img src="https://latex.codecogs.com/png.latex?%5Ctau_%7B1t%7D%20=%20Y_%7B1t%7D(1)%20-%20Y_%7B1t%7D(0)"></p></li>
<li><p>여기서 <img src="https://latex.codecogs.com/png.latex?Y_%7B1t%7D(1)">은 관찰되지만, 정책이 없었을 때의 결과인 <img src="https://latex.codecogs.com/png.latex?Y_%7B1t%7D(0)">은 <strong>결측된 반사실(Missing Counterfactual)</strong>입니다.</p></li>
</ul>
</section>
<section id="합성-통제-집단-구성-weights-construction" class="level2">
<h2 class="anchored" data-anchor-id="합성-통제-집단-구성-weights-construction">2.2 합성 통제 집단 구성 (Weights Construction)</h2>
<ul>
<li>SCM의 핵심은 통제 집단 유닛들에 부여할 <strong>가중치 벡터 <img src="https://latex.codecogs.com/png.latex?W%20=%20(w_2,%20%5Cdots,%20w_%7BJ+1%7D)'"></strong>를 찾는 것입니다.</li>
<li>이 가중치는 다음 두 가지 제약 조건을 만족해야 합니다.
<ul>
<li><ol type="1">
<li><strong>비음수 조건 (Non-negative):</strong> <img src="https://latex.codecogs.com/png.latex?w_j%20%5Cge%200"></li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>합의 조건 (Sum to one):</strong> <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bj=2%7D%5E%7BJ+1%7D%20w_j%20=%201"></li>
</ol></li>
</ul></li>
<li>이 제약 조건들은 합성 통제 집단이 데이터들의 <strong>볼록 껍질(Convex Hull)</strong> 내부에 존재하게 하여, <strong>내삽(Interpolation)</strong>을 수행하도록 강제합니다.</li>
<li>즉, 데이터의 범위를 벗어나는 과도한 <strong>외삽(Extrapolation)</strong>을 방지합니다.</li>
</ul>
</section>
<section id="최적화-문제-optimization" class="level2">
<h2 class="anchored" data-anchor-id="최적화-문제-optimization">2.3 최적화 문제 (Optimization)</h2>
<ul>
<li>SCM의 핵심은 “어떤 주(State)를 얼마나 섞을 것인가?”를 결정하는 <strong>최적의 가중치 벡터 <img src="https://latex.codecogs.com/png.latex?W%5E*"></strong>를 찾는 것입니다.</li>
</ul>
<section id="목적-함수-objective-function" class="level3">
<h3 class="anchored" data-anchor-id="목적-함수-objective-function">2.3.1 목적 함수 (Objective Function)</h3>
<ul>
<li>우리는 개입 이전 기간(<img src="https://latex.codecogs.com/png.latex?t%20%5Cle%20T_0">) 동안, 처치 집단과 합성 통제 집단 사이의 <strong>차이(Distance)</strong>를 최소화하고자 합니다.</li>
<li>이를 위한 목적 함수는 다음과 같이 구성됩니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AW%5E*%20=%20%5Cunderset%7BW%7D%7B%5Cmathrm%7Bargmin%7D%7D%20%5Csqrt%7B%20%5Cunderbrace%7B%5Csum_%7Bm=1%7D%5E%7Bk%7D%20v_m%20%5Cleft(%20X_%7B1m%7D%20-%20%5Csum_%7Bj=2%7D%5E%7BJ+1%7D%20w_j%20X_%7Bjm%7D%20%5Cright)%5E2%7D_%7B%5Ctext%7B%EC%98%88%EC%B8%A1%20%EB%B3%80%EC%88%98%EB%93%A4%EC%9D%98%20%EA%B0%80%EC%A4%91%20%EA%B1%B0%EB%A6%AC%20%ED%95%A9%7D%7D%20%7D%0A"></p>
<ul>
<li><p>여기서 <img src="https://latex.codecogs.com/png.latex?X_%7B1m%7D">과 <img src="https://latex.codecogs.com/png.latex?X_%7Bjm%7D">은 각각 처치 집단과 통제 집단의 예측 변수(Pre-treatment outcomes 및 Covariates)를 의미하며, 수식의 의미는 다음과 같습니다.</p></li>
<li><ol type="1">
<li><strong>결과 변수 추세 매칭 (Outcome Matching):</strong></li>
</ol>
<ul>
<li>개입 이전의 결과 변수(예: 연도별 담배 판매량) 추세가 처치 집단과 최대한 겹치도록 만듭니다.</li>
<li>과거의 궤적을 잘 모사해야 미래의 반사실(Counterfactual)도 신뢰할 수 있습니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>공변량 매칭 (Covariate Matching):</strong></li>
</ol>
<ul>
<li>단순히 결과값의 패턴만 맞추는 것이 아니라, 결과에 영향을 미치는 근본적인 특성(예: GDP, 인구 비중, 소득 수준 등)까지 유사하게 맞춥니다.</li>
<li>이는 모델이 우연히 시계열 패턴만 맞추는 <strong>과적합(Overfitting)</strong>을 방지하고, 구조적인 유사성을 보장합니다.</li>
</ul></li>
</ul>
</section>
<section id="제약-조건-constraints" class="level3">
<h3 class="anchored" data-anchor-id="제약-조건-constraints">2.3.2 제약 조건 (Constraints)</h3>
<ul>
<li>찾아낸 가중치 <img src="https://latex.codecogs.com/png.latex?W%20=%20(w_2,%20%5Cdots,%20w_%7BJ+1%7D)'">는 반드시 다음 두 가지 조건을 만족해야 합니다.</li>
<li><strong>비음수 조건 (<img src="https://latex.codecogs.com/png.latex?w_j%20%5Cge%200">):</strong> 회귀분석과 달리 음의 가중치를 허용하지 않습니다. <img src="https://latex.codecogs.com/png.latex?%0Aw_j%20%5Cge%200%0A"></li>
<li><strong>합의 조건 (<img src="https://latex.codecogs.com/png.latex?%5Csum%20w_j%20=%201">):</strong> 모든 가중치의 합은 1이어야 합니다. <img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bj=2%7D%5E%7BJ+1%7D%20w_j%20=%201%0A"></li>
<li><strong>의미:</strong>
<ul>
<li>이 제약 조건들로 인해 합성 대조군은 데이터의 <strong>볼록 껍질(Convex Hull)</strong> 내에서 생성됩니다.</li>
<li>즉, 합성 대조군은 통제 집단들의 <strong>‘엄밀한 내삽(Interpolation)’</strong> 결과물이 되며, 데이터 범위를 벗어나는 외삽(Extrapolation)의 위험을 차단합니다.</li>
</ul></li>
</ul>
</section>
<section id="변수-중요도-행렬-v-matrix" class="level3">
<h3 class="anchored" data-anchor-id="변수-중요도-행렬-v-matrix">2.3.3 변수 중요도 행렬 (<img src="https://latex.codecogs.com/png.latex?V"> Matrix)</h3>
<ul>
<li><p>위 수식의 <img src="https://latex.codecogs.com/png.latex?v_m">은 각 변수 <img src="https://latex.codecogs.com/png.latex?m">이 합성에 얼마나 기여해야 하는지를 결정하는 <strong>중요도 가중치</strong>입니다.</p></li>
<li><p>모든 변수가 예측에 동일하게 중요하지 않습니다. 예를 들어, 흡연량을 예측할 때 ’지난해 흡연량’이 ’GDP’보다 더 중요할 수 있습니다.</p></li>
<li><p>실제 분석에서는 <strong>이중 최적화(Nested Optimization)</strong> 과정을 거칩니다.</p>
<ul>
<li><strong>Inner Step:</strong> <img src="https://latex.codecogs.com/png.latex?V">가 주어졌을 때, 차이를 최소화하는 <img src="https://latex.codecogs.com/png.latex?W">를 찾습니다.</li>
<li><strong>Outer Step:</strong> 개입 이전 기간의 예측 오차(MSPE)를 가장 낮추는 최적의 변수 중요도 <img src="https://latex.codecogs.com/png.latex?V">를 찾아냅니다.</li>
</ul></li>
</ul>
<hr>
</section>
</section>
</section>
<section id="이론적-정당성-theoretical-justification" class="level1">
<h1>3. 이론적 정당성 (Theoretical Justification)</h1>
<section id="model-based-justification" class="level2">
<h2 class="anchored" data-anchor-id="model-based-justification">3.1. Model-based Justification</h2>
<ul>
<li>SCM이 단순히 “비슷해 보이는” 대상을 섞는 것이 아니라, 수학적으로 타당한 인과추론 도구인 이유는 무엇일까요?</li>
<li>Abadie et al.&nbsp;(2010)은 두 가지 모형을 통해 SCM의 강력함을 증명했습니다.</li>
</ul>
<section id="모형-1-상호작용-요인-모형-interacted-factor-model" class="level3">
<h3 class="anchored" data-anchor-id="모형-1-상호작용-요인-모형-interacted-factor-model">모형 1: 상호작용 요인 모형 (Interacted Factor Model)</h3>
<ul>
<li>가장 널리 인용되는 SCM의 기반 모형입니다.</li>
<li>결과 변수 <img src="https://latex.codecogs.com/png.latex?Y_%7Bit%7D(0)">가 관찰 가능한 요인뿐만 아니라, 관찰되지 않는 <strong>‘시간에 따라 변하는 요인’</strong>에 의해 결정된다고 가정합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AY_%7Bit%7D(0)%20=%20%5Cunderbrace%7B%5Cdelta_t%7D_%7B%5Ctext%7BTime%20FE%7D%7D%20+%20%5Cunderbrace%7B%5Cboldsymbol%7BZ%7D_i'%20%5Cboldsymbol%7B%5Cbeta%7D_t%7D_%7B%5Ctext%7BCovariates%7D%7D%20+%20%5Cunderbrace%7B%5Calpha_i%7D_%7B%5Ctext%7BUnit%20FE%7D%7D%20+%20%5Cunderbrace%7B%5Cboldsymbol%7B%5Clambda%7D_t%20%5Cboldsymbol%7B%5Cmu%7D_i%7D_%7B%5Ctext%7BLatent%20Factors%7D%7D%20+%20%5Cepsilon_%7Bit%7D%0A"></p>
<ul>
<li>이 수식의 각 항은 다음을 의미합니다.
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cdelta_t">: 모든 유닛에 공통적으로 영향을 미치는 시간 충격 (예: 글로벌 경제 위기).</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BZ%7D_i'%20%5Cboldsymbol%7B%5Cbeta%7D_t">: 관찰 가능한 공변량(<img src="https://latex.codecogs.com/png.latex?Z">)이 시간에 따라 미치는 영향(<img src="https://latex.codecogs.com/png.latex?%5Cbeta_t">)이 변할 수 있음을 허용.</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Calpha_i">: 유닛 고유의 고정 효과 (기존 DiD가 통제하는 부분).</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Clambda%7D_t%20%5Cboldsymbol%7B%5Cmu%7D_i"> (핵심):</strong> 관찰되지 않는 공통 요인(<img src="https://latex.codecogs.com/png.latex?%5Clambda_t">)과 각 유닛의 요인 적재값(<img src="https://latex.codecogs.com/png.latex?%5Cmu_i">)의 곱입니다.
<ul>
<li>이는 <strong>시간 가변적 교란 요인(Time-varying Confounding)</strong>을 구조적으로 모형화한 것입니다.</li>
<li>예를 들어, <img src="https://latex.codecogs.com/png.latex?%5Clambda_t">가 ’기술 발전 속도’라면 <img src="https://latex.codecogs.com/png.latex?%5Cmu_i">는 해당 주(State)의 ’기술 수용성’이 될 수 있으며, 이 효과는 시간에 따라 달라집니다.</li>
</ul></li>
</ul></li>
<li>기존의 이중차분법(DiD)은 <img src="https://latex.codecogs.com/png.latex?%5Calpha_i">(시간 불변 요인)만 제거할 수 있습니다.</li>
<li>하지만 SCM은 적절한 가중치(<img src="https://latex.codecogs.com/png.latex?W">)를 통해 <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Clambda%7D_t%20%5Cboldsymbol%7B%5Cmu%7D_i"> 항까지 상쇄시킬 수 있어, 평행 추세 가정이 위배되는 상황에서도 편향 없는 추정이 가능합니다.</li>
</ul>
</section>
<section id="모형-2-자기회귀-모형-autoregressive-model" class="level3">
<h3 class="anchored" data-anchor-id="모형-2-자기회귀-모형-autoregressive-model">모형 2: 자기회귀 모형 (Autoregressive Model)</h3>
<ul>
<li>두 번째 정당화 논리는 데이터가 자기회귀(AR) 과정을 따른다는 가정에서 출발합니다.</li>
<li>즉, 현재의 결과가 과거의 결과에 의존하는 경우입니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AY_%7Bi,%20t+1%7D(0)%20=%20%5Calpha_t%20Y_%7Bit%7D(0)%20+%20%5Cbeta_%7Bt+1%7D%20%5Cboldsymbol%7BZ%7D_%7Bi,%20t+1%7D%20+%20u_%7Bi,%20t+1%7D%0A"> <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BZ%7D_%7Bi,%20t+1%7D%20=%20%5Cgamma_t%20Y_%7Bit%7D(0)%20+%20%5CPi_t%20%5Cboldsymbol%7BZ%7D_%7Bit%7D%20+%20%5Cboldsymbol%7Bv%7D_%7Bi,%20t+1%7D%0A"></p>
<ul>
<li>이 모형은 고정 효과(Fixed Effects) 없이도, 과거의 결과값(<img src="https://latex.codecogs.com/png.latex?Y_%7Bit%7D">)과 공변량(<img src="https://latex.codecogs.com/png.latex?Z">)을 완벽하게 매칭하면 미래의 경로도 예측할 수 있음을 시사합니다.</li>
</ul>
</section>
</section>
<section id="scm의-추정-성질-scm-properties" class="level2">
<h2 class="anchored" data-anchor-id="scm의-추정-성질-scm-properties">3.2 SCM의 추정 성질 (SCM Properties)</h2>
<ul>
<li>위의 모형들 하에서, 만약 우리가 개입 이전 기간의 결과(<img src="https://latex.codecogs.com/png.latex?Y">)와 공변량(<img src="https://latex.codecogs.com/png.latex?Z">)을 완벽하게 균형 맞추는 가중치 <img src="https://latex.codecogs.com/png.latex?w%5E*">를 찾을 수 있다면 다음과 같은 성질이 성립합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bj=2%7D%5E%7BJ+1%7D%20w_j%5E*%20Y_%7Bjt%7D%20=%20Y_%7B1t%7D%20%5Cquad%20%5Ctext%7Band%7D%20%5Cquad%20%5Csum_%7Bj=2%7D%5E%7BJ+1%7D%20w_j%5E*%20%5Cboldsymbol%7BZ%7D_j%20=%20%5Cboldsymbol%7BZ%7D_1%0A"></p>
<ul>
<li>이 조건이 충족될 때, 개입 이후 시점(<img src="https://latex.codecogs.com/png.latex?t%20%3E%20T_0">)에 대한 반사실 추정량 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BY%7D_%7B1t%7D(0)">은 다음과 같은 특징을 가집니다.</li>
</ul>
<ol type="1">
<li><strong>Under Model 1 (점근적 일치성):</strong>
<ul>
<li>개입 이전 기간(<img src="https://latex.codecogs.com/png.latex?T_0">)이 길어질수록(<img src="https://latex.codecogs.com/png.latex?T_0%20%5Cto%20%5Cinfty">), 편향(Bias)이 0으로 수렴합니다.</li>
<li>즉, <img src="https://latex.codecogs.com/png.latex?%5Chat%7BY%7D_%7B1t%7D(0)%20%5Cto%20Y_%7B1t%7D(0)">이 되어, 과거 데이터를 길게 확보할수록 추정이 정확해집니다.</li>
</ul></li>
<li><strong>Under Model 2 (비편향성):</strong>
<ul>
<li>자기회귀 모형 하에서는 단기간의 개입 이전 데이터만으로도 비편향 추정량(<img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BE%7D%5B%5Chat%7BY%7D_%7B1t%7D(0)%5D%20=%20%5Cmathbb%7BE%7D%5BY_%7B1t%7D(0)%5D">)을 얻을 수 있습니다.</li>
</ul></li>
</ol>
<ul>
<li>결론적으로 SCM은 <strong>“과거의 궤적(Trajectory)을 오랫동안, 그리고 정확하게 흉내 낼 수 있다면 미래의 궤적 또한 신뢰할 수 있다”</strong>는 수학적 보장을 가지고 있습니다.</li>
</ul>
</section>
<section id="볼록성convexity의-기하학적-의미" class="level2">
<h2 class="anchored" data-anchor-id="볼록성convexity의-기하학적-의미">3.3 볼록성(Convexity)의 기하학적 의미</h2>
<ul>
<li>SCM은 데이터를 ‘섞어서’ 만드는 것이므로 기하학적으로는 다면체 내부의 한 점을 찾는 것과 같습니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L15/causal-inference-15-part-03/images/convex_hull_triangle.png" class="img-fluid figure-img"></p>
<figcaption>Figure: <img src="https://latex.codecogs.com/png.latex?X_1">(검은 점)을 <img src="https://latex.codecogs.com/png.latex?X_0">(빨간 점들)의 조합으로 표현할 때, <img src="https://latex.codecogs.com/png.latex?X_1">이 빨간 점들이 이루는 다면체(Triangle) 내부에 있어야 안전한 추론(Interpolation)이 가능합니다. 외부에 있다면 SCM 적용에 주의가 필요합니다.</figcaption>
</figure>
</div>
<hr>
</section>
</section>
<section id="practical-concerns-augmented-scm" class="level1">
<h1>4. Practical Concerns: Augmented SCM</h1>
<section id="편향-보정-bias-correction" class="level2">
<h2 class="anchored" data-anchor-id="편향-보정-bias-correction">4.1 편향 보정 (Bias Correction)</h2>
<ul>
<li>현실에서는 개입 이전 기간(<img src="https://latex.codecogs.com/png.latex?T_0">)에도 처치 집단과 합성 대조군이 완벽하게 일치하지 않을 수 있습니다(Imperfect Pre-treatment Fit).</li>
<li>이 경우 추정치에 편향이 발생합니다.</li>
<li>이를 해결하기 위해 <strong>Augmented SCM (ASCM)</strong>이 제안되었습니다.</li>
</ul>
</section>
<section id="ascm-공식" class="level2">
<h2 class="anchored" data-anchor-id="ascm-공식">4.2 ASCM 공식</h2>
<ul>
<li>ASCM은 기존 SCM 추정치에 <strong>회귀분석을 이용한 보정항</strong>을 추가합니다. <img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7BY%7D_%7B1t%7D%5E%7Baug%7D(0)%20=%20%5Cunderbrace%7B%5Csum_%7Bj=2%7D%5E%7BJ+1%7D%20w_j%20Y_%7Bjt%7D%7D_%7B%5Ctext%7BOriginal%20SCM%7D%7D%20+%20%5Cunderbrace%7B%5Cleft(%20%5Chat%7Bm%7D_%7B1t%7D%20-%20%5Csum_%7Bj=2%7D%5E%7BJ+1%7D%20w_j%20%5Chat%7Bm%7D_%7Bjt%7D%20%5Cright)%7D_%7B%5Ctext%7BBias%20Correction%7D%7D%0A">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Chat%7Bm%7D_%7Bit%7D">: 공변량 등을 이용해 예측한 결과값 (Ridge Regression 등을 사용)</li>
<li>이 보정항은 합성 대조군이 설명하지 못하는 잔여 차이를 회귀 모델로 메꿔주는 역할을 합니다.</li>
</ul></li>
</ul>
<hr>
</section>
</section>
<section id="마치며-투명하고-강력한-인과추론" class="level1">
<h1>마치며: 투명하고 강력한 인과추론</h1>
<ul>
<li>통제집단합성법은 다음과 같은 이유로 현대 사회과학 연구에서 가장 사랑받는 방법론 중 하나가 되었습니다.
<ul>
<li><ol type="1">
<li><strong>투명성 (Transparency):</strong> 어떤 통제 유닛이 몇 퍼센트의 비중으로 사용되었는지 명확히 알 수 있습니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>데이터 기반 (Data-driven):</strong> 연구자의 자의적인 대조군 선정을 방지합니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>유연성:</strong> 시간에 따라 변하는 교란 요인을 통제할 수 있습니다.</li>
</ol></li>
</ul></li>
<li>데이터가 충분히 쌓인 시계열 환경에서 정책 효과를 분석해야 한다면, SCM은 가장 먼저 고려해야 할 도구입니다.</li>
</ul>



</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L15/causal-inference-15-part-03/</guid>
  <pubDate>Wed, 21 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>이론에서 현실로: 시뮬레이션을 통한 성능 검증</title>
  <dc:creator>Reviewer </dc:creator>
  <link>https://shsha0110.github.io/posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/</link>
  <description><![CDATA[ 





<section id="들어가며" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="들어가며"><span class="header-section-number">1</span> 들어가며</h2>
<p>이전 포스트에서는 개별 처치 효과(ITE)의 불확실성을 정량화하기 위해 <strong>예측 구간(Prediction Interval)</strong>을 생성해야 함을 역설했습니다. 하지만 여기에는 현실적인 장벽이 존재합니다. 우리가 가진 데이터는 ’처치를 받은 사람(<img src="https://latex.codecogs.com/png.latex?T=1">)’의 결과뿐인데, 우리가 예측하고 싶은 대상은 ’전체 인구’이거나 ’처치를 받지 않은 사람’일 수 있기 때문입니다.</p>
<p>이번 포스트에서는 이러한 <strong>분포의 불일치(Covariate Shift)</strong> 문제를 정의하고, 이를 <strong>가중 컨포멀 추론(Weighted Conformal Inference)</strong>을 통해 수학적으로 어떻게 보정하는지 단계별로 살펴보겠습니다.</p>
<hr>
</section>
<section id="관측-데이터와-반사실-간의-괴리-counterfactuals-and-covariate-shift" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="관측-데이터와-반사실-간의-괴리-counterfactuals-and-covariate-shift"><span class="header-section-number">2</span> 관측 데이터와 반사실 간의 괴리 (Counterfactuals and Covariate Shift)</h2>
<section id="문제의-본질-훈련-데이터와-타겟-데이터의-불일치" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="문제의-본질-훈련-데이터와-타겟-데이터의-불일치"><span class="header-section-number">2.1</span> 문제의 본질: 훈련 데이터와 타겟 데이터의 불일치</h3>
<p>우리의 목표는 잠재적 결과 <img src="https://latex.codecogs.com/png.latex?Y(1)">과 <img src="https://latex.codecogs.com/png.latex?Y(0)">에 대한 예측 구간을 만드는 것입니다. [cite_start]이때 우리는 <strong>강한 무시 가능성(Strong Ignorability)</strong> 가정을 바탕으로 오직 관측된 데이터 <img src="https://latex.codecogs.com/png.latex?(Y%5E%7Bobs%7D,%20T,%20X)">만을 사용합니다[cite: 226].</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Y(1)">의 구간을 추정하기 위해: 처치군 (<img src="https://latex.codecogs.com/png.latex?T=1">) 데이터만 사용 가능.</li>
<li><img src="https://latex.codecogs.com/png.latex?Y(0)">의 구간을 추정하기 위해: 대조군 (<img src="https://latex.codecogs.com/png.latex?T=0">) 데이터만 사용 가능.</li>
</ul>
<p>하지만 여기서 문제가 발생합니다. <strong>데이터를 학습하는 분포</strong>와 <strong>예측을 적용하려는 타겟 분포</strong>가 서로 다릅니다. 이를 수식으로 표현해 보겠습니다.</p>
</section>
<section id="수학적-정의-covariate-shift" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="수학적-정의-covariate-shift"><span class="header-section-number">2.2</span> 수학적 정의: Covariate Shift</h3>
<p>[cite_start]우리가 <img src="https://latex.codecogs.com/png.latex?Y(1)">을 학습할 때 사용하는 처치군 데이터의 결합 분포는 다음과 같습니다[cite: 234].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP_%7BTrain%7D%20=%20P_%7BX%7CT=1%7D%20%5Ctimes%20P_%7BY(1)%7CX%7D%0A"></p>
<p>[cite_start]하지만 우리가 결과를 일반화하여 적용하고 싶은 타겟 분포(예: 전체 인구)는 다음과 같습니다[cite: 236].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP_%7BTarget%7D%20=%20Q_X%20%5Ctimes%20P_%7BY(1)%7CX%7D%0A"></p>
<p>여기서 주목할 점은 <strong>조건부 결과 분포 <img src="https://latex.codecogs.com/png.latex?P_%7BY(1)%7CX%7D">는 동일하다</strong>는 것입니다. 즉, <img src="https://latex.codecogs.com/png.latex?X">가 주어졌을 때 결과가 나오는 메커니즘(생물학적 반응 등)은 변하지 않습니다. 유일한 차이는 <strong>공변량 <img src="https://latex.codecogs.com/png.latex?X">의 분포(<img src="https://latex.codecogs.com/png.latex?P_%7BX%7CT=1%7D"> vs <img src="https://latex.codecogs.com/png.latex?Q_X">)</strong>에 있습니다.</p>
<p>[cite_start]이러한 현상을 머신러닝에서는 <strong>공변량 변화(Covariate Shift)</strong>라고 부릅니다[cite: 237].</p>
<p>![Image: covariate_shift_diagram.png] <em>Figure 1: Covariate Shift의 개념도. 학습 데이터(Treated)는 특정 영역(예: 고연령층)에 치우쳐 있을 수 있지만, 타겟(Target)은 전체 인구를 포함한다. 회귀 곡선(조건부 평균)은 같더라도 데이터 밀도가 달라 예측 구간 보정이 필요하다.</em></p>
<p>일반적인 머신러닝 방법론들은 훈련 데이터와 테스트 데이터의 분포가 같다고 가정(<img src="https://latex.codecogs.com/png.latex?P_%7BTrain%7D%20=%20P_%7BTarget%7D">)하기 때문에, 이 상황에서 그대로 적용하면 잘못된 커버리지(Coverage)를 산출하게 됩니다.</p>
<hr>
</section>
</section>
<section id="해결책-가중-컨포멀-추론-weighted-conformal-inference" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="해결책-가중-컨포멀-추론-weighted-conformal-inference"><span class="header-section-number">3</span> 해결책: 가중 컨포멀 추론 (Weighted Conformal Inference)</h2>
<p>[cite_start]이 문제를 해결하기 위해 논문은 Tibshirani et al.(2019b)이 제안한 <strong>가중 컨포멀 추론</strong>을 도입합니다[cite: 238].</p>
<section id="표준-컨포멀-추론의-한계" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="표준-컨포멀-추론의-한계"><span class="header-section-number">3.1</span> 표준 컨포멀 추론의 한계</h3>
<p>[cite_start]표준적인 컨포멀 추론(Standard Conformal Inference)은 데이터가 i.i.d.일 때, 임의의 예측 모델(예: Quantile Regression)의 잔차(Residual)를 보정하여 다음을 만족하는 구간 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D(X)">를 생성합니다[cite: 243].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D_%7B(X,Y)%20%5Csim%20P_X%20%5Ctimes%20P_%7BY%7CX%7D%7D(Y%20%5Cin%20%5Chat%7BC%7D(X))%20%5Cge%201%20-%20%5Calpha%0A"></p>
<p>[cite_start]보통 <strong>Conformal Quantile Regression (CQR)</strong>을 사용하여 다음과 같은 형태의 구간을 만듭니다[cite: 247].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7BC%7D(x)%20=%20%5B%5Chat%7Bq%7D_%7B%5Calpha_%7Blo%7D%7D(x)%20-%20%5Ceta,%20%5Chat%7Bq%7D_%7B%5Calpha_%7Bhi%7D%7D(x)%20+%20%5Ceta%5D%0A"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?%5Ceta">는 보정 상수입니다. 하지만 분포가 다를 경우(<img src="https://latex.codecogs.com/png.latex?P_%7BTrain%7D%20%5Cneq%20P_%7BTarget%7D">), 이 단순한 보정은 실패합니다.</p>
</section>
<section id="가중치likelihood-ratio의-도입" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="가중치likelihood-ratio의-도입"><span class="header-section-number">3.2</span> 가중치(Likelihood Ratio)의 도입</h3>
<p>[cite_start]우리는 타겟 분포 <img src="https://latex.codecogs.com/png.latex?Q_X"> 하에서의 커버리지를 보장해야 합니다[cite: 252]. [cite_start]이를 위해 두 분포 사이의 비율인 <strong>우도비(Likelihood Ratio)</strong>를 가중치로 사용합니다[cite: 255].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Aw(x)%20=%20%5Cfrac%7BdQ_X(x)%7D%7BdP_%7BX%7CT=1%7D(x)%7D%0A"></p>
<p>이 가중치 <img src="https://latex.codecogs.com/png.latex?w(x)">는 “타겟 분포에서 <img src="https://latex.codecogs.com/png.latex?x">가 관측될 확률이 학습 분포에 비해 얼마나 높은가”를 나타냅니다.</p>
<hr>
</section>
</section>
<section id="알고리즘-상세-weighted-split-cqr" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="알고리즘-상세-weighted-split-cqr"><span class="header-section-number">4</span> 알고리즘 상세: Weighted Split-CQR</h2>
<p>[cite_start]논문에서 제안하는 <strong>Algorithm 1 (Weighted split-CQR)</strong>의 작동 원리를 단계별로 분석해 보겠습니다[cite: 262].</p>
<section id="step-1-데이터-분할-data-splitting" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="step-1-데이터-분할-data-splitting"><span class="header-section-number">4.1</span> Step 1: 데이터 분할 (Data Splitting)</h3>
<p>전체 데이터를 훈련 집합(Training fold, <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BZ%7D_%7Btr%7D">)과 캘리브레이션 집합(Calibration fold, <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BZ%7D_%7Bca%7D">)으로 나눕니다. * <strong>훈련 집합:</strong> 분위수 회귀 모델 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D(%5Ccdot)">와 가중치 함수 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bw%7D(%5Ccdot)">를 학습하는 데 사용합니다. * <strong>캘리브레이션 집합:</strong> 모델의 예측 오차를 측정하여 구간을 보정하는 데 사용합니다.</p>
</section>
<section id="step-2-비적합-점수-계산-non-conformity-scores" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="step-2-비적합-점수-계산-non-conformity-scores"><span class="header-section-number">4.2</span> Step 2: 비적합 점수 계산 (Non-conformity Scores)</h3>
<p>캘리브레이션 데이터 <img src="https://latex.codecogs.com/png.latex?i%20%5Cin%20%5Cmathcal%7BI%7D_%7Bca%7D">에 대해, 실제 값 <img src="https://latex.codecogs.com/png.latex?Y_i">가 예측된 구간 <img src="https://latex.codecogs.com/png.latex?%5B%5Chat%7Bq%7D_%7B%5Calpha_%7Blo%7D%7D,%20%5Chat%7Bq%7D_%7B%5Calpha_%7Bhi%7D%7D%5D"> 밖으로 얼마나 벗어났는지 점수(<img src="https://latex.codecogs.com/png.latex?V_i">)를 계산합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AV_i%20=%20%5Cmax%20%5C%7B%20%5Chat%7Bq%7D_%7B%5Calpha_%7Blo%7D%7D(X_i)%20-%20Y_i,%20%5Cquad%20Y_i%20-%20%5Chat%7Bq%7D_%7B%5Calpha_%7Bhi%7D%7D(X_i)%20%5C%7D%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?V_i%20%3E%200">: 실제 값이 예측 구간 밖에 있음 (오차 발생).</li>
<li><img src="https://latex.codecogs.com/png.latex?V_i%20%5Cle%200">: 실제 값이 예측 구간 안에 있음.</li>
</ul>
</section>
<section id="step-3-가중치-계산-weight-computation" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="step-3-가중치-계산-weight-computation"><span class="header-section-number">4.3</span> Step 3: 가중치 계산 (Weight Computation)</h3>
<p>캘리브레이션 데이터 각각에 대해 가중치를 계산합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AW_i%20=%20%5Chat%7Bw%7D(X_i)%0A"></p>
</section>
<section id="step-4-정규화된-확률-계산-normalized-probabilities-핵심" class="level3" data-number="4.4">
<h3 data-number="4.4" class="anchored" data-anchor-id="step-4-정규화된-확률-계산-normalized-probabilities-핵심"><span class="header-section-number">4.4</span> Step 4: 정규화된 확률 계산 (Normalized Probabilities) <strong>[핵심]</strong></h3>
<p>새로운 데이터 포인트(Test point) <img src="https://latex.codecogs.com/png.latex?x">가 주어졌을 때, 이 점에서의 예측 구간을 구하기 위해 가중치를 정규화합니다. 이때 테스트 포인트의 가중치 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bw%7D(x)">도 함께 고려합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7Bp%7D_i(x)%20=%20%5Cfrac%7BW_i%7D%7B%5Csum_%7Bj%20%5Cin%20%5Cmathcal%7BI%7D_%7Bca%7D%7D%20W_j%20+%20%5Chat%7Bw%7D(x)%7D,%20%5Cquad%20%5Cforall%20i%20%5Cin%20%5Cmathcal%7BI%7D_%7Bca%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7Bp%7D_%7B%5Cinfty%7D(x)%20=%20%5Cfrac%7B%5Chat%7Bw%7D(x)%7D%7B%5Csum_%7Bj%20%5Cin%20%5Cmathcal%7BI%7D_%7Bca%7D%7D%20W_j%20+%20%5Chat%7Bw%7D(x)%7D%0A"></p>
<ul>
<li><strong>의미:</strong> 만약 테스트 포인트 <img src="https://latex.codecogs.com/png.latex?x">가 타겟 분포에서 아주 희귀한 값이라면(<img src="https://latex.codecogs.com/png.latex?%5Chat%7Bw%7D(x)%20%5Capprox%200">), <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bp%7D_%5Cinfty(x)">는 작아지고 기존 캘리브레이션 데이터들의 영향력이 커집니다. 반대라면 테스트 포인트 자체의 불확실성이 크게 반영됩니다.</li>
</ul>
</section>
<section id="step-5-가중-분위수-계산-weighted-quantile" class="level3" data-number="4.5">
<h3 data-number="4.5" class="anchored" data-anchor-id="step-5-가중-분위수-계산-weighted-quantile"><span class="header-section-number">4.5</span> Step 5: 가중 분위수 계산 (Weighted Quantile)</h3>
<p>다음과 같은 이산 분포(Discrete Distribution)를 구성하고, 이 분포의 <img src="https://latex.codecogs.com/png.latex?(1-%5Calpha)"> 분위수를 찾아 보정값 <img src="https://latex.codecogs.com/png.latex?%5Ceta(x)">로 설정합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi%20%5Cin%20%5Cmathcal%7BI%7D_%7Bca%7D%7D%20%5Chat%7Bp%7D_i(x)%20%5Cdelta_%7BV_i%7D%20+%20%5Chat%7Bp%7D_%7B%5Cinfty%7D(x)%20%5Cdelta_%7B%5Cinfty%7D%0A"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?%5Cdelta">는 디랙 델타 함수입니다. 즉, 가중치 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bp%7D_i(x)">를 반영하여 에러 점수 <img src="https://latex.codecogs.com/png.latex?V_i">들을 줄 세운 뒤, 상위 <img src="https://latex.codecogs.com/png.latex?(1-%5Calpha)"> 지점에 해당하는 에러 값을 찾는 과정입니다.</p>
</section>
<section id="최종-출력" class="level3" data-number="4.6">
<h3 data-number="4.6" class="anchored" data-anchor-id="최종-출력"><span class="header-section-number">4.6</span> 최종 출력</h3>
<p>구해진 <img src="https://latex.codecogs.com/png.latex?%5Ceta(x)">를 이용하여 최종 예측 구간을 생성합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7BC%7D(x)%20=%20%5B%5Chat%7Bq%7D_%7B%5Calpha_%7Blo%7D%7D(x)%20-%20%5Ceta(x),%20%5Cquad%20%5Chat%7Bq%7D_%7B%5Calpha_%7Bhi%7D%7D(x)%20+%20%5Ceta(x)%5D%0A"></p>
<p>![Image: weighted_cqr_process.png] <em>Figure 2: Weighted Split-CQR 프로세스. 캘리브레이션 데이터의 에러(Score)들에 가중치를 부여하여 히스토그램을 그리고, 타겟 커버리지(1-alpha)를 만족하는 지점(Quantile)을 동적으로 결정한다.</em></p>
<hr>
</section>
</section>
<section id="이론적-보장-theoretical-guarantee" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="이론적-보장-theoretical-guarantee"><span class="header-section-number">5</span> 이론적 보장 (Theoretical Guarantee)</h2>
<p>[cite_start]이 알고리즘은 강력한 이론적 성질을 가집니다 (Proposition 1)[cite: 268].</p>
<ol type="1">
<li><p><strong>가중치를 정확히 아는 경우 (<img src="https://latex.codecogs.com/png.latex?%5Chat%7Bw%7D%20=%20w">):</strong> 데이터 분포에 대한 어떠한 가정 없이도, 유한한 샘플에서 타겟 분포에 대한 커버리지(Equation 10)를 <strong>완벽하게 보장</strong>합니다. <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BP%7D_%7B(X,Y)%20%5Csim%20Q_X%20%5Ctimes%20P_%7BY%7CX%7D%7D(Y%20%5Cin%20%5Chat%7BC%7D(X))%20%5Cge%201%20-%20%5Calpha"></p></li>
<li><p><strong>가중치를 추정해야 하는 경우 (<img src="https://latex.codecogs.com/png.latex?%5Chat%7Bw%7D%20%5Cneq%20w">):</strong> [cite_start]가중치 추정에 오차가 있더라도, 그 오차(<img src="https://latex.codecogs.com/png.latex?%5CDelta_w">)만큼만 커버리지가 벗어납니다[cite: 274]. <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BCoverage%7D%20%5Cge%201%20-%20%5Calpha%20-%20%5CDelta_w"> 이는 이 방법론이 가중치 추정의 정확도에 의존하지만, 어느 정도의 오차는 허용하는 강건함(Robustness)을 가짐을 의미합니다.</p></li>
</ol>
</section>
<section id="요약" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="요약"><span class="header-section-number">6</span> 요약</h2>
<p>이번 섹션에서는 인과추론에서 피할 수 없는 <strong>공변량 변화(Covariate Shift)</strong> 문제를 해결하기 위해 <strong>가중 컨포멀 추론</strong>을 사용하는 방법을 다루었습니다.</p>
<ul>
<li>우리는 <img src="https://latex.codecogs.com/png.latex?P_%7BTrain%7D">에서 학습하지만 <img src="https://latex.codecogs.com/png.latex?P_%7BTarget%7D">을 예측해야 합니다.</li>
<li>두 분포의 비율(<img src="https://latex.codecogs.com/png.latex?w(x)">)을 이용하여 캘리브레이션 데이터의 에러 분포를 재조정(Reweighting)합니다.</li>
<li>이 방식은 모델이 완벽하지 않아도, 수학적으로 타겟 분포에 대한 유효한 예측 구간을 보장해 줍니다.</li>
</ul>
<p>다음 단계에서는 이 가중치 <img src="https://latex.codecogs.com/png.latex?w(x)">가 인과추론의 <strong>성향 점수(Propensity Score)</strong>와 어떻게 연결되는지 구체적으로 살펴보게 될 것입니다.</p>
<hr>
<p><strong>Reference:</strong> Lei, L., &amp; Candès, E. J. (2021). Conformal inference of counterfactuals and individual treatment effects. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 83(5), 911-938.</p>
</section>
<section id="들어가며-1" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="들어가며-1"><span class="header-section-number">7</span> 들어가며</h2>
<p>이전 포스트에서는 공변량 변화(Covariate Shift)를 해결하기 위해 <strong>가중 컨포멀 추론(Weighted Conformal Inference)</strong>을 도입했습니다. 핵심은 학습 분포와 타겟 분포의 비율인 가중치 <img src="https://latex.codecogs.com/png.latex?w(x)">를 어떻게 설정하느냐였습니다.</p>
<p>이번 포스트에서는 인과추론의 꽃이라 불리는 <strong>성향 점수(Propensity Score)</strong>가 이 가중치와 어떻게 수학적으로 연결되는지 살펴보고, 이 방법론이 가진 두 가지 강력한 성질인 <strong>완전성(Exactness)</strong>과 <strong>이중 강건성(Double Robustness)</strong>에 대해 알아보겠습니다.</p>
<hr>
</section>
<section id="성향-점수propensity-score의-역할" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="성향-점수propensity-score의-역할"><span class="header-section-number">8</span> 성향 점수(Propensity Score)의 역할</h2>
<section id="성향-점수와-ipw의-관계" class="level3" data-number="8.1">
<h3 data-number="8.1" class="anchored" data-anchor-id="성향-점수와-ipw의-관계"><span class="header-section-number">8.1</span> 성향 점수와 IPW의 관계</h3>
<p>Rosenbaum &amp; Rubin(1983)이 제안한 성향 점수 <img src="https://latex.codecogs.com/png.latex?e(x)">는 공변량이 주어졌을 때 처치를 받을 확률로 정의됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ae(x)%20=%20%5Cmathbb%7BP%7D(T=1%20%7C%20X=x)%0A"></p>
<p>전통적인 인과추론에서 평균 처치 효과(ATE)를 추정할 때 사용하는 <strong>역성향 점수 가중법(IPW, Inverse Propensity Weighting)</strong>은 다음과 같은 가중치를 사용합니다.</p>
<ul>
<li>처치군 (<img src="https://latex.codecogs.com/png.latex?T=1">): <img src="https://latex.codecogs.com/png.latex?w_1(x)%20=%20%5Cfrac%7B1%7D%7Be(x)%7D"></li>
<li>대조군 (<img src="https://latex.codecogs.com/png.latex?T=0">): <img src="https://latex.codecogs.com/png.latex?w_0(x)%20=%20%5Cfrac%7B1%7D%7B1-e(x)%7D"></li>
</ul>
</section>
<section id="가중-컨포멀-추론에서의-유도-과정" class="level3" data-number="8.2">
<h3 data-number="8.2" class="anchored" data-anchor-id="가중-컨포멀-추론에서의-유도-과정"><span class="header-section-number">8.2</span> 가중 컨포멀 추론에서의 유도 과정</h3>
<p>놀랍게도, 가중 컨포멀 추론에서 필요한 공변량 변화 비율(Likelihood Ratio)은 IPW 가중치와 정확히 일치합니다. 이를 수학적으로 유도해 보겠습니다.</p>
<p>우리가 <img src="https://latex.codecogs.com/png.latex?Y(1)">에 대한 ATE 타입의 구간을 구한다고 가정합시다. * <strong>Target Distribution:</strong> 전체 모집단 (<img src="https://latex.codecogs.com/png.latex?P_X">) * <strong>Sampling Distribution:</strong> 처치군 (<img src="https://latex.codecogs.com/png.latex?P_%7BX%7CT=1%7D">)</p>
<p>베이즈 정리(Bayes’ Formula)를 적용하면 가중치 <img src="https://latex.codecogs.com/png.latex?w_1(x)">는 다음과 같습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign%7D%0Aw_1(x)%20&amp;=%20%5Cfrac%7BdP_X(x)%7D%7BdP_%7BX%7CT=1%7D(x)%7D%20%5C%5C%0A%20%20%20%20%20%20%20&amp;=%20%5Cfrac%7BdP_X(x)%7D%7B%5Cfrac%7BP(T=1%7CX=x)dP_X(x)%7D%7BP(T=1)%7D%7D%20%5C%5C%0A%20%20%20%20%20%20%20&amp;=%20%5Cfrac%7BP(T=1)%7D%7Be(x)%7D%0A%5Cend%7Balign%7D%0A"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?P(T=1)">은 상수입니다. 가중 컨포멀 추론 알고리즘은 가중치의 <strong>상수배(Rescaling)에 불변(Invariant)</strong>하므로, 분자를 무시하면 다음과 같이 귀결됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Aw_1(x)%20%5Cpropto%20%5Cfrac%7B1%7D%7Be(x)%7D%0A"></p>
<p>즉, <strong>가중 컨포멀 추론은 본질적으로 IPW 추정 방식과 동일한 가중치 체계를 공유</strong>합니다.</p>
</section>
<section id="다양한-추론-목표에-따른-가중치-요약" class="level3" data-number="8.3">
<h3 data-number="8.3" class="anchored" data-anchor-id="다양한-추론-목표에-따른-가중치-요약"><span class="header-section-number">8.3</span> 다양한 추론 목표에 따른 가중치 요약</h3>
<p>논문에서는 ATE뿐만 아니라 ATT(처치군 대상 효과), ATC(대조군 대상 효과), 그리고 일반화(Generalizability) 상황까지 아우르는 가중치 표를 제시합니다.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">추론 목표 (Inferential Target)</th>
<th style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?w_1(x)"> (for <img src="https://latex.codecogs.com/png.latex?Y(1)">)</th>
<th style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?w_0(x)"> (for <img src="https://latex.codecogs.com/png.latex?Y(0)">)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>ATE</strong> (전체 평균)</td>
<td style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?1/e(x)"></td>
<td style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?1/(1-e(x))"></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>ATT</strong> (처치군 평균)</td>
<td style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?1"> (가중치 불필요)</td>
<td style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?e(x)/(1-e(x))"></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>ATC</strong> (대조군 평균)</td>
<td style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?(1-e(x))/e(x)"></td>
<td style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?1"></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>General</strong> (외부 타겟 <img src="https://latex.codecogs.com/png.latex?Q">)</td>
<td style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7BdQ%7D%7BdP%7D(x)%20%5Ccdot%20%5Cfrac%7B1%7D%7Be(x)%7D"></td>
<td style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7BdQ%7D%7BdP%7D(x)%20%5Ccdot%20%5Cfrac%7B1%7D%7B1-e(x)%7D"></td>
</tr>
</tbody>
</table>
<p><em>Table 1: 다양한 인과추론 목표에 따른 가중치 함수 요약. IPW 추정량에서 쓰이는 가중치와 정확히 일치한다.</em></p>
<hr>
</section>
</section>
<section id="무작위-대조군-연구rct에서의-완전성-exactness" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="무작위-대조군-연구rct에서의-완전성-exactness"><span class="header-section-number">9</span> 무작위 대조군 연구(RCT)에서의 완전성 (Exactness)</h2>
<section id="완전한-성향-점수-완전한-커버리지" class="level3" data-number="9.1">
<h3 data-number="9.1" class="anchored" data-anchor-id="완전한-성향-점수-완전한-커버리지"><span class="header-section-number">9.1</span> 완전한 성향 점수, 완전한 커버리지</h3>
<p><strong>무작위 대조군 연구(Randomized Controlled Trials, RCT)</strong>에서는 연구자가 처치 확률을 설계하므로 성향 점수 <img src="https://latex.codecogs.com/png.latex?e(x)">를 정확히 알고 있습니다.</p>
<ul>
<li><strong>완전 무작위 배정(Completely Randomized):</strong> <img src="https://latex.codecogs.com/png.latex?e(x)%20=%200.5"> (상수). 가중치가 일정하므로 일반적인(Unweighted) 컨포멀 추론을 사용해도 됩니다.</li>
<li><strong>층화 무작위 배정(Stratified Randomized):</strong> <img src="https://latex.codecogs.com/png.latex?e(x)">가 공변량(예: 연령, 성별)에 따라 다르지만, 그 값은 정확히 알고 있습니다.</li>
</ul>
<p>이 경우, 가중 컨포멀 추론은 유한한 샘플(Finite Samples)에서도 <strong>정확한(Exact) 커버리지</strong>를 보장합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D(Y(1)%20%5Cin%20%5Chat%7BC%7D(X))%20%5Cge%201%20-%20%5Calpha%0A"></p>
<p>이 보장은 결과 모델(Conditional Quantile Model)을 얼마나 엉터리로 만들었는지와 상관없이 성립합니다.</p>
</section>
<section id="겹침-조건overlap-condition-위반에-대한-강건성" class="level3" data-number="9.2">
<h3 data-number="9.2" class="anchored" data-anchor-id="겹침-조건overlap-condition-위반에-대한-강건성"><span class="header-section-number">9.2</span> 겹침 조건(Overlap Condition) 위반에 대한 강건성</h3>
<p>IPW와 같은 점 추정 방식은 <img src="https://latex.codecogs.com/png.latex?e(x)%20%5Capprox%200"> 또는 <img src="https://latex.codecogs.com/png.latex?1">인 경우(Overlap이 부족한 경우) 가중치가 무한대로 발산하여 추정량이 매우 불안정해집니다.</p>
<p>하지만 컨포멀 추론은 이 상황에서 매우 직관적이고 안전하게 반응합니다. 가중치가 무한대로 가면 구간의 길이도 무한대로 늘어납니다 (<img src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D(x)%20=%20(-%5Cinfty,%20%5Cinfty)">). * <strong>의미:</strong> “이 영역에는 데이터가 없어 정보를 알 수 없으므로, 구간을 무한히 넓게 잡겠다.” * <strong>결과:</strong> 정보는 없지만, 여전히 정답을 포함할 확률(<img src="https://latex.codecogs.com/png.latex?1-%5Calpha">)은 수학적으로 지켜집니다.</p>
<hr>
</section>
</section>
<section id="관찰-연구에서의-이중-강건성-double-robustness" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="관찰-연구에서의-이중-강건성-double-robustness"><span class="header-section-number">10</span> 관찰 연구에서의 이중 강건성 (Double Robustness)</h2>
<p>관찰 연구(Observational Study)에서는 성향 점수 <img src="https://latex.codecogs.com/png.latex?e(x)">를 모르기 때문에 데이터로부터 추정해야 합니다(<img src="https://latex.codecogs.com/png.latex?%5Chat%7Be%7D(x)">). 이때 발생하는 불확실성을 가중 컨포멀 추론은 어떻게 처리할까요?</p>
<p>이 방법론은 <strong>이중 강건성(Doubly Robust Property)</strong>을 가집니다. 즉, 다음 두 가지 조건 중 <strong>하나만</strong> 만족해도 근사적으로(Approximately) 올바른 커버리지를 보장합니다.</p>
<ol type="1">
<li><strong>성향 점수 모델이 정확할 때 (<img src="https://latex.codecogs.com/png.latex?%5Chat%7Be%7D(x)%20%5Capprox%20e(x)">)</strong></li>
<li><strong>결과 모델(Quantile)이 정확할 때 (<img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D(x)%20%5Capprox%20q(x)">)</strong></li>
</ol>
<section id="직관적-증명-intuitive-justification" class="level3" data-number="10.1">
<h3 data-number="10.1" class="anchored" data-anchor-id="직관적-증명-intuitive-justification"><span class="header-section-number">10.1</span> 직관적 증명 (Intuitive Justification)</h3>
<p><strong>Case 1: 성향 점수 모델이 정확함 (<img src="https://latex.codecogs.com/png.latex?%5Chat%7Be%7D%20%5Capprox%20e">)</strong> 이 경우, 우리가 계산한 가중치가 참(Oracle) 가중치와 거의 같아집니다. 따라서 결과 모델 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D(x)">가 아무리 부정확하더라도, 가중 컨포멀 추론의 기본 원리에 의해 커버리지가 보장됩니다.</p>
<p><strong>Case 2: 결과 모델이 정확함 (<img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D%20%5Capprox%20q">)</strong> 이 부분이 흥미롭습니다. 성향 점수(가중치)가 틀렸더라도, 결과 모델이 정확하다면 어떻게 될까요? 참 조건부 분위수 <img src="https://latex.codecogs.com/png.latex?q_%7B%5Cbeta%7D(x)">를 정확히 추정했다면, 비적합 점수(Non-conformity score) <img src="https://latex.codecogs.com/png.latex?V_i">의 분포가 다음과 같이 됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign%7D%0AV_i%20&amp;%5Capprox%20%5Cmax%20%5C%7B%20q_%7B%5Calpha_%7Blo%7D%7D(X_i)%20-%20Y_i,%20%5C%20Y_i%20-%20q_%7B%5Calpha_%7Bhi%7D%7D(X_i)%20%5C%7D%20%5C%5C%0A%5Cmathbb%7BP%7D(V_i%20%5Cle%200%20%7C%20X_i)%20&amp;%5Capprox%20%5Cmathbb%7BP%7D(Y_i%20%5Cin%20%5Bq_%7B%5Calpha_%7Blo%7D%7D,%20q_%7B%5Calpha_%7Bhi%7D%7D%5D)%20=%201%20-%20%5Calpha%0A%5Cend%7Balign%7D%0A"></p>
<p>즉, <img src="https://latex.codecogs.com/png.latex?0">이라는 값이 점수 분포의 <img src="https://latex.codecogs.com/png.latex?(1-%5Calpha)"> 분위수가 됩니다. 따라서 알고리즘이 계산하는 보정값 <img src="https://latex.codecogs.com/png.latex?%5Ceta(x)">는 <img src="https://latex.codecogs.com/png.latex?0">에 가까워지며, 최종 구간은 참 분위수 구간으로 수렴하게 되어 커버리지를 만족합니다.</p>
<p>![Image: double_robustness_diagram.png] <em>Figure 1: 이중 강건성의 개념도. x축은 성향 점수 모델의 오차, y축은 결과 모델의 오차를 나타낸다. 두 축 중 하나만 0에 가까우면(L자 형태), 전체 커버리지 에러는 낮게 유지된다.</em></p>
</section>
<section id="theorem-1-수학적-보장" class="level3" data-number="10.2">
<h3 data-number="10.2" class="anchored" data-anchor-id="theorem-1-수학적-보장"><span class="header-section-number">10.2</span> Theorem 1: 수학적 보장</h3>
<p>논문의 정리 1(Theorem 1)은 이를 공식화합니다. 샘플 사이즈 <img src="https://latex.codecogs.com/png.latex?N,%20n%20%5Cto%20%5Cinfty"> 일 때, 다음 조건 중 하나가 성립하면: 1. <img src="https://latex.codecogs.com/png.latex?%5Chat%7Be%7D_N(X)%20%5Cto%20e(X)"> (성향 점수 일치) 2. <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D_%7B%5Cbeta,%20N%7D(X)%20%5Cto%20q_%7B%5Cbeta%7D(X)"> (분위수 일치)</p>
<p>다음과 같은 커버리지를 보장합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clim_%7BN,n%20%5Cto%20%5Cinfty%7D%20%5Cmathbb%7BP%7D(Y(1)%20%5Cin%20%5Chat%7BC%7D_%7BN,n%7D(X))%20%5Cge%201%20-%20%5Calpha%0A"></p>
<p>또한, 조건 2(결과 모델 정확)가 만족될 경우에는 평균 커버리지뿐만 아니라 <strong>조건부 커버리지(Conditional Coverage)</strong>까지 근사적으로 보장됨을 보일 수 있습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clim_%7BN,n%20%5Cto%20%5Cinfty%7D%20%5Cmathbb%7BP%7D(%5Ctext%7BCoverage%20Error%7D%20%7C%20X)%20=%200%0A"></p>
</section>
</section>
<section id="요약-1" class="level2" data-number="11">
<h2 data-number="11" class="anchored" data-anchor-id="요약-1"><span class="header-section-number">11</span> 요약</h2>
<p>이번 섹션의 핵심은 <strong>“가중치(Weighting)”</strong>와 <strong>“강건성(Robustness)”</strong>입니다.</p>
<ol type="1">
<li>가중 컨포멀 추론의 가중치는 <strong>IPW의 성향 점수 가중치</strong>와 본질적으로 같습니다.</li>
<li>성향 점수를 아는 RCT에서는 <strong>유한 표본에서도 완벽한 커버리지</strong>를 제공합니다.</li>
<li>성향 점수를 모르는 관찰 연구에서는 <strong>성향 점수 모델</strong> 혹은 <strong>결과 예측 모델</strong> 중 하나만 잘 맞으면 커버리지가 보장되는 <strong>이중 강건성</strong>을 가집니다.</li>
</ol>
<p>이는 점 추정(Point Estimation)에서의 이중 강건성(일치성 보장) 개념을 구간 추정(Interval Estimation, 커버리지 보장)으로 성공적으로 확장한 사례라 할 수 있습니다.</p>
<hr>
<p><strong>Reference:</strong> Lei, L., &amp; Candès, E. J. (2021). Conformal inference of counterfactuals and individual treatment effects. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 83(5), 911-938.</p>
</section>
<section id="들어가며-2" class="level2" data-number="12">
<h2 data-number="12" class="anchored" data-anchor-id="들어가며-2"><span class="header-section-number">12</span> 들어가며</h2>
<p>지금까지 우리는 이론적으로 개별 처치 효과(ITE)의 구간을 추정하는 방법과 그에 따른 성질(이중 강건성 등)을 살펴보았습니다. 이번 포스트에서는 <strong>“그래서 실제로 잘 작동하는가?”</strong>라는 질문에 답하기 위해 수행된 수치 실험(Numerical Experiments) 결과를 상세히 뜯어보겠습니다.</p>
<p>저자들은 <strong>Causal Forest</strong>, <strong>X-learner</strong>, <strong>BART</strong> 등 현존하는 강력한 방법론들과 자신들의 <strong>Weighted Split-CQR</strong>을 비교하며, 특히 데이터가 복잡할 때(고차원, 상관관계 존재, 이분산성) 어떤 차이가 발생하는지 집중 조명합니다.</p>
<hr>
</section>
<section id="실험-설계-experimental-setup" class="level2" data-number="13">
<h2 data-number="13" class="anchored" data-anchor-id="실험-설계-experimental-setup"><span class="header-section-number">13</span> 실험 설계 (Experimental Setup)</h2>
<p>실험은 Wager and Athey (2018)의 설정을 변형하여 진행되었습니다. 데이터 생성 과정(Data Generating Process)을 수학적으로 정의해 보겠습니다.</p>
<section id="데이터-생성-메커니즘" class="level3" data-number="13.1">
<h3 data-number="13.1" class="anchored" data-anchor-id="데이터-생성-메커니즘"><span class="header-section-number">13.1</span> 데이터 생성 메커니즘</h3>
<ol type="1">
<li><p><strong>공변량 (Covariates) <img src="https://latex.codecogs.com/png.latex?X"></strong>: <img src="https://latex.codecogs.com/png.latex?d">차원의 벡터 <img src="https://latex.codecogs.com/png.latex?X%20=%20(X_1,%20%5Cdots,%20X_d)%5ET">는 다음과 같이 생성됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AX_j%20=%20%5CPhi(X'_j)%0A"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?%5CPhi">는 표준 정규분포의 누적 분포 함수(CDF)이며, <img src="https://latex.codecogs.com/png.latex?X'">는 평균이 0이고 분산이 1인 다변량 가우시안 분포를 따릅니다. 공변량 간의 상관계수는 <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BCov%7D(X'_j,%20X'_%7Bj'%7D)%20=%20%5Crho"> 입니다.</p></li>
<li><p><strong>잠재적 결과 (Potential Outcomes)</strong>: 문제의 단순화를 위해, 처치를 받지 않았을 때의 결과 <img src="https://latex.codecogs.com/png.latex?Y(0)">는 0으로 고정합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AY(0)%20%5Cequiv%200%0A"></p>
<p>처치를 받았을 때의 결과 <img src="https://latex.codecogs.com/png.latex?Y(1)">은 다음과 같이 구성됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BE%7D%5BY(1)%7CX%5D%20=%20f(X_1)f(X_2),%20%5Cquad%20%5Ctext%7Bwhere%20%7D%20f(x)%20=%20%5Cfrac%7B2%7D%7B1%20+%20%5Cexp%5C%7B-12(x-0.5)%5C%7D%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0AY(1)%20=%20%5Cmathbb%7BE%7D%5BY(1)%7CX%5D%20+%20%5Csigma(X)%5Cepsilon,%20%5Cquad%20%5Cepsilon%20%5Csim%20N(0,%201)%0A"></p></li>
<li><p><strong>성향 점수 (Propensity Score)</strong>: 충분한 겹침(Overlap)을 보장하기 위해 다음과 같이 설정합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ae(x)%20=%20%5Cfrac%7B1%7D%7B4%7D%20(1%20+%20%5Cbeta_%7B2,4%7D(X_1))%0A"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?%5Cbeta_%7B2,4%7D">는 베타 분포(2, 4)의 CDF입니다. 이 설정은 <img src="https://latex.codecogs.com/png.latex?e(x)%20%5Cin%20%5B0.25,%200.5%5D"> 범위를 보장합니다.</p></li>
</ol>
</section>
<section id="가지-시나리오-scenarios" class="level3" data-number="13.2">
<h3 data-number="13.2" class="anchored" data-anchor-id="가지-시나리오-scenarios"><span class="header-section-number">13.2</span> 8가지 시나리오 (Scenarios)</h3>
<p>데이터의 복잡성에 따른 성능 변화를 보기 위해 총 <img src="https://latex.codecogs.com/png.latex?2%20%5Ctimes%202%20%5Ctimes%202%20=%208">가지 시나리오를 구성했습니다.</p>
<ul>
<li><strong>차원 (Dimension):</strong> 저차원 (<img src="https://latex.codecogs.com/png.latex?d=10">) vs 고차원 (<img src="https://latex.codecogs.com/png.latex?d=100">)</li>
<li><strong>상관관계 (Correlation):</strong> 독립 (<img src="https://latex.codecogs.com/png.latex?%5Crho=0">) vs 상관 (<img src="https://latex.codecogs.com/png.latex?%5Crho=0.9">)</li>
<li><strong>오차 분산 (Errors):</strong> 등분산 (<img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2(x)=1">) vs 이분산 (<img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2(x)%20=%20-%5Clog%20X_1">)</li>
</ul>
<p>특히 <strong>이분산(Heteroscedasticity)</strong> 설정이 중요합니다. <img src="https://latex.codecogs.com/png.latex?X_1">이 0에 가까울수록 분산이 무한대로 커지기 때문에, 불확실성 추정이 매우 까다로워집니다.</p>
<hr>
</section>
</section>
<section id="비교-방법론-competitors" class="level2" data-number="14">
<h2 data-number="14" class="anchored" data-anchor-id="비교-방법론-competitors"><span class="header-section-number">14</span> 비교 방법론 (Competitors)</h2>
<p>본 실험에서는 다음 방법론들의 95% 구간 추정 성능을 비교합니다.</p>
<ol type="1">
<li><strong>Causal Forest (CF):</strong> <code>grf</code> 패키지 사용. CATE의 분산을 추정하지만 ITE용은 아님.</li>
<li><strong>X-learner:</strong> <code>causalToolbox</code> 패키지 사용. 부트스트랩 기반 CATE 분산 추정. 역시 ITE용은 아님.</li>
<li><strong>BART (Bayesian Additive Regression Trees):</strong> <code>bartMachine</code> 패키지. 베이지안 신용 구간(Credible Interval) 및 예측 구간(Prediction Interval) 생성 가능. 가장 강력한 경쟁자.</li>
<li><strong>Weighted Split-CQR (제안 방법):</strong> 기본 학습기(Learner)로 다음 3가지를 각각 사용.
<ul>
<li>Quantile Random Forest (CQR-RF)</li>
<li>Quantile Gradient Boosting (CQR-Boosting)</li>
<li>BART (CQR-BART)</li>
</ul></li>
</ol>
<hr>
</section>
<section id="결과-분석-1-커버리지-성능-coverage-performance" class="level2" data-number="15">
<h2 data-number="15" class="anchored" data-anchor-id="결과-분석-1-커버리지-성능-coverage-performance"><span class="header-section-number">15</span> 결과 분석 1: 커버리지 성능 (Coverage Performance)</h2>
<p>가장 중요한 지표는 <strong>“생성된 구간이 실제 값을 95% 확률로 포함하는가?”</strong>입니다.</p>
<section id="이론적-보장과-실제-table-2" class="level3" data-number="15.1">
<h3 data-number="15.1" class="anchored" data-anchor-id="이론적-보장과-실제-table-2"><span class="header-section-number">15.1</span> 이론적 보장과 실제 (Table 2)</h3>
<p>먼저 각 방법론이 이론적으로 무엇을 보장하는지 살펴봅시다.</p>
<p><img src="https://shsha0110.github.io/posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/Table_2_Summary_of_coverage_guarantees_in_theory_and_simulation.png" class="img-fluid" alt="Table 2: Summary of coverage guarantees"> <em>Table 2: 이론적(위) 및 시뮬레이션(아래)에서의 커버리지 보장 요약. CF와 X-learner는 애초에 ITE 커버리지를 보장하지 않으며, 오직 CQR만이 모든 상황에서 ITE 커버리지를 달성함.</em></p>
</section>
<section id="cate-커버리지-figure-1" class="level3" data-number="15.2">
<h3 data-number="15.2" class="anchored" data-anchor-id="cate-커버리지-figure-1"><span class="header-section-number">15.2</span> CATE 커버리지 (Figure 1)</h3>
<p>CATE(조건부 평균)에 대한 커버리지를 먼저 봅니다.</p>
<p><img src="https://shsha0110.github.io/posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/Figure_1_Empirical_95_percent_coverage_of_CATE.png" class="img-fluid" alt="Figure 1: Empirical 95% coverage of CATE"> <em>Figure 1: CATE에 대한 95% 커버리지 결과. 빨간 수직선(1.00 근처)이 목표치. CF와 X-learner는 고차원/이분산 상황에서 성능이 크게 떨어짐. 반면 CQR은 다소 보수적(과도한 커버리지)이지만 목표치를 항상 상회함.</em></p>
<ul>
<li><strong>CF, X-learner:</strong> 모든 시나리오에서 낮은 커버리지를 보이며, 고차원(<img src="https://latex.codecogs.com/png.latex?d=100">)에서 더 악화됩니다.</li>
<li><strong>CQR:</strong> CATE를 직접 타겟팅하지 않음에도 불구하고(ITE를 타겟팅하므로 구간이 더 넓음), 모든 시나리오에서 안전한 커버리지를 보여줍니다.</li>
</ul>
</section>
<section id="ite-커버리지-figure-2---핵심-결과" class="level3" data-number="15.3">
<h3 data-number="15.3" class="anchored" data-anchor-id="ite-커버리지-figure-2---핵심-결과"><span class="header-section-number">15.3</span> ITE 커버리지 (Figure 2) - 핵심 결과</h3>
<p>논문의 진짜 목표인 <strong>개별 처치 효과(ITE)</strong>에 대한 커버리지입니다.</p>
<p><img src="https://shsha0110.github.io/posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/Figure_2_Empirical_95_percent_coverage_of_ITE.png" class="img-fluid" alt="Figure 2: Empirical 95% coverage of ITE"> <em>Figure 2: ITE에 대한 95% 커버리지 결과. 이것이 이 논문의 핵심이다. CQR 계열(상단 3개)만이 모든 시나리오(특히 맨 오른쪽의 이분산+상관관계)에서 95% 선을 지킨다.</em></p>
<ul>
<li><strong>CF, X-learner:</strong> ITE를 커버하도록 설계되지 않았으므로 당연히 실패합니다. (CATE 구간을 ITE 구간으로 오해해서는 안 된다는 것을 보여줍니다.)</li>
<li><strong>BART:</strong> 등분산(Homoscedastic) 상황에서는 완벽합니다. 하지만 <strong>이분산 + 상관관계(Heteroscedastic + Corr.)</strong> 상황에서는 커버리지가 무너집니다.</li>
<li><strong>CQR:</strong> 어떤 기본 학습기를 쓰든, 차원/상관관계/분산 구조에 상관없이 <strong>거의 정확한 95% 커버리지</strong>를 달성합니다.</li>
</ul>
<hr>
</section>
</section>
<section id="결과-분석-2-구간의-길이-interval-length" class="level2" data-number="16">
<h2 data-number="16" class="anchored" data-anchor-id="결과-분석-2-구간의-길이-interval-length"><span class="header-section-number">16</span> 결과 분석 2: 구간의 길이 (Interval Length)</h2>
<p>커버리지가 높다고 무조건 좋은 것은 아닙니다. 구간이 <img src="https://latex.codecogs.com/png.latex?(-%5Cinfty,%20%5Cinfty)">라면 커버리지는 100%겠지만 쓸모가 없으니까요. 구간은 <strong>짧을수록 좋습니다.</strong></p>
<p><img src="https://shsha0110.github.io/posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/Figure_3_Lengths_of_interval_estimates_for_ITE.png" class="img-fluid" alt="Figure 3: Lengths of interval estimates for ITE"> <em>Figure 3: ITE 구간의 평균 길이. 파란 수직선은 Oracle(이상적인) 길이. CQR-BART가 BART와 거의 유사한 길이를 보이면서도 더 나은 커버리지를 제공함을 알 수 있다.</em></p>
<ul>
<li><strong>CF, X-learner:</strong> 구간이 매우 짧습니다. 그래서 커버리지(Figure 2)가 망가진 것입니다.</li>
<li><strong>BART:</strong> 등분산 상황에서 가장 효율적(짧은) 구간을 만듭니다.</li>
<li><strong>CQR-BART:</strong> BART를 기본 학습기로 사용한 CQR은 순수 BART와 <strong>거의 비슷한 구간 길이</strong>를 가집니다. 즉, <strong>“정보의 손실 없이(길이 유지) 정확성(커버리지)만 보정했다”</strong>는 뜻입니다.</li>
</ul>
<hr>
</section>
<section id="결과-분석-3-조건부-커버리지-conditional-coverage" class="level2" data-number="17">
<h2 data-number="17" class="anchored" data-anchor-id="결과-분석-3-조건부-커버리지-conditional-coverage"><span class="header-section-number">17</span> 결과 분석 3: 조건부 커버리지 (Conditional Coverage)</h2>
<p>마지막으로, 데이터의 특성(여기서는 분산의 크기)에 따라 커버리지가 어떻게 변하는지 확인합니다. 이상적으로는 분산이 크든 작든 일정한 커버리지를 유지해야 합니다.</p>
<p><img src="https://shsha0110.github.io/posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/Figure_4_Estimated_conditional_coverage_of_ITE.png" class="img-fluid" alt="Figure 4: Estimated conditional coverage of ITE"> <em>Figure 4: 조건부 분산(x축)에 따른 ITE 커버리지(y축) 변화. x축의 오른쪽으로 갈수록 노이즈가 심한 데이터이다. BART(가운데)는 노이즈가 커지면 커버리지가 급격히 떨어지지만, CQR(오른쪽)은 이를 잘 방어하고 있다.</em></p>
<ul>
<li><strong>상황:</strong> <img src="https://latex.codecogs.com/png.latex?d=10">, 이분산 설정. <img src="https://latex.codecogs.com/png.latex?x_1"> 값에 따라 분산이 변함.</li>
<li><strong>BART:</strong> 분산이 큰 영역(그래프의 오른쪽)으로 갈수록 커버리지가 급격히 하락합니다.</li>
<li><strong>CQR-RF/Boosting:</strong> 분산의 크기와 관계없이 95% 수준을 견고하게 유지합니다. 이것이 바로 <strong>Conformal Inference의 적응력(Adaptability)</strong>입니다.</li>
</ul>
<hr>
</section>
<section id="결론-및-요약" class="level2" data-number="18">
<h2 data-number="18" class="anchored" data-anchor-id="결론-및-요약"><span class="header-section-number">18</span> 결론 및 요약</h2>
<p>Section 3.6의 실험 결과는 다음과 같이 요약할 수 있습니다.</p>
<ol type="1">
<li><strong>CATE 추정기 <img src="https://latex.codecogs.com/png.latex?%5Cneq"> ITE 구간 추정기:</strong> Causal Forest나 X-learner 같은 CATE 전용 방법론을 ITE 불확실성 추정에 그대로 사용하면 위험합니다.</li>
<li><strong>BART의 한계:</strong> BART는 강력하지만, 데이터가 복잡하고(상관관계 존재) 노이즈가 불균일할 때(이분산) 신뢰성을 잃을 수 있습니다.</li>
<li><strong>Weighted Split-CQR의 승리:</strong>
<ul>
<li><strong>강건성 (Robustness):</strong> 어떤 시나리오에서도 목표 커버리지(95%)를 지켰습니다.</li>
<li><strong>효율성 (Efficiency):</strong> 구간의 길이를 불필요하게 늘리지 않으면서도 정확도를 확보했습니다.</li>
<li><strong>유연성 (Flexibility):</strong> RF, Boosting, BART 등 어떤 알고리즘 위에 얹어도 성능을 향상시킵니다.</li>
</ul></li>
</ol>
<p>이로써 이 논문이 제안한 방법론이 이론적으로만 아름다운 것이 아니라, 실전 데이터 분석에서도 매우 강력한 도구가 될 수 있음이 증명되었습니다.</p>
<hr>
<p><strong>Reference:</strong> Lei, L., &amp; Candès, E. J. (2021). Conformal inference of counterfactuals and individual treatment effects. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 83(5), 911-938.</p>



</section>

 ]]></description>
  <category>Causal Inference</category>
  <category>Conformal Prediction</category>
  <category>Machine Learning</category>
  <guid>https://shsha0110.github.io/posts/paper/Conformal inference of counterfactuals and individual treatment effects/03-From observables to counterfactuals/</guid>
  <pubDate>Wed, 21 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>세계관의 확장: 다른 인과추론 프레임워크로의 연결</title>
  <dc:creator>Reviewer </dc:creator>
  <link>https://shsha0110.github.io/posts/paper/Conformal inference of counterfactuals and individual treatment effects/05-From potential outcomes to other causal frameworks/</link>
  <description><![CDATA[ 





<section id="들어가며" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="들어가며"><span class="header-section-number">1</span> 들어가며</h2>
<p>지금까지 우리는 <strong>잠재적 결과(Potential Outcome) 프레임워크</strong> (Rubin’s Causal Model) 하에서 개별 처치 효과(ITE)의 구간을 추정하는 방법을 논의했습니다. 핵심은 <strong>가중 컨포멀 추론(Weighted Conformal Inference)</strong>을 이용해, 관측 데이터(학습 분포)와 우리가 추론하고자 하는 반사실/타겟 데이터(타겟 분포) 사이의 <strong>공변량 변화(Covariate Shift)</strong>를 보정하는 것이었습니다.</p>
<p>이 논문의 마지막 섹션(Section 5)에서는 매우 흥미로운 통찰을 제시합니다. 우리가 개발한 이 방법론이 단순히 잠재적 결과 프레임워크에만 국한되지 않는다는 것입니다.</p>
<p><strong>핵심 통찰 (Key Observation):</strong> &gt; “조건부 분포의 불변성(Invariance of Conditional Distribution)과 공변량 변화(Covariate Shift)라는 구조만 동일하다면, 어떤 인과추론 프레임워크에도 이 방법론을 적용할 수 있다.”</p>
<p>이번 포스트에서는 이 통찰이 <strong>Judea Pearl의 인과 다이어그램</strong>과 <strong>Peters의 불변 예측</strong> 프레임워크로 어떻게 확장되는지 수학적으로 살펴보겠습니다.</p>
<hr>
</section>
<section id="인과-다이어그램-프레임워크-causal-diagram-framework" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="인과-다이어그램-프레임워크-causal-diagram-framework"><span class="header-section-number">2</span> 인과 다이어그램 프레임워크 (Causal Diagram Framework)</h2>
<section id="pearl의-do-연산자" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="pearl의-do-연산자"><span class="header-section-number">2.1</span> Pearl의 do-연산자</h3>
<p>Judea Pearl(1995)이 정립한 인과 다이어그램 프레임워크는 ‘반사실(Counterfactuals)’ 개념 대신, <strong>do-연산자(<img src="https://latex.codecogs.com/png.latex?do(%5Ccdot)">)</strong>를 통해 인과 효과를 정의합니다. <img src="https://latex.codecogs.com/png.latex?do(T=t)">는 시스템에 개입하여 변수 <img src="https://latex.codecogs.com/png.latex?T">를 강제로 값 <img src="https://latex.codecogs.com/png.latex?t">로 고정하고, <img src="https://latex.codecogs.com/png.latex?T">로 들어오는 모든 인과적 경로를 끊는 것을 의미합니다.</p>
</section>
<section id="가정-백도어-기준-back-door-criterion" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="가정-백도어-기준-back-door-criterion"><span class="header-section-number">2.2</span> 가정: 백도어 기준 (Back-door Criterion)</h3>
<p>우리는 변수 집합 <img src="https://latex.codecogs.com/png.latex?X">가 <strong>백도어 기준</strong>을 만족한다고 가정합니다. * <img src="https://latex.codecogs.com/png.latex?X">는 모든 교란 변수(Confounders)를 포함합니다. * <img src="https://latex.codecogs.com/png.latex?X">는 처치 이후의 변수(Post-treatment variables)를 포함하지 않습니다.</p>
<p>![Image: causal_diagram_backdoor.png] <em>Figure 1: 백도어 기준을 만족하는 인과 다이어그램 예시. X는 T와 Y의 공통 원인(Confounder)을 차단하고 있다.</em></p>
</section>
<section id="수학적-구조의-일치성-증명" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="수학적-구조의-일치성-증명"><span class="header-section-number">2.3</span> 수학적 구조의 일치성 증명</h3>
<p>우리가 추론하고자 하는 <strong>타겟 분포(Target Distribution)</strong>는 개입이 일어났을 때의 분포입니다. Pearl(1995)의 기초 정리에 따르면, 백도어 기준이 만족될 때 다음이 성립합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP_%7B(X,Y)%7Cdo(T=t)%7D%20=%20P_X%20%5Ctimes%20P_%7BY%7CX,%20T=t%7D%0A"></p>
<p>반면, 우리가 실제로 가지고 있는 <strong>관측 분포(Observed Distribution)</strong>는 다음과 같습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP_%7B(X,Y)%7CT=t%7D%20=%20P_%7BX%7CT=t%7D%20%5Ctimes%20P_%7BY%7CX,%20T=t%7D%0A"></p>
<p><strong>[비교 분석]</strong> 두 식을 비교해 봅시다. 1. <strong>조건부 분포 <img src="https://latex.codecogs.com/png.latex?P_%7BY%7CX,%20T=t%7D">:</strong> 두 식에서 <strong>동일</strong>합니다. 즉, <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?T">가 정해졌을 때 <img src="https://latex.codecogs.com/png.latex?Y">가 결정되는 메커니즘은 변하지 않습니다 (Invariance). 2. <strong>공변량 분포:</strong> 타겟은 <img src="https://latex.codecogs.com/png.latex?P_X"> (전체 모집단)이고, 관측은 <img src="https://latex.codecogs.com/png.latex?P_%7BX%7CT=t%7D"> (특정 처치군)입니다.</p>
<p>이 구조는 우리가 앞서 다루었던 잠재적 결과 프레임워크에서의 구조와 <strong>수학적으로 완전히 동일</strong>합니다.</p>
</section>
<section id="결론-가중치의-적용" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="결론-가중치의-적용"><span class="header-section-number">2.4</span> 결론: 가중치의 적용</h3>
<p>따라서, 별도의 수정 없이 <strong>Weighted Split-CQR</strong> 알고리즘을 그대로 적용할 수 있습니다. 이때 가중치(Likelihood Ratio)는 다음과 같이 계산됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Aw(x)%20=%20%5Cfrac%7Bd%20P_X(x)%7D%7Bd%20P_%7BX%7CT=t%7D(x)%7D%20%5Cpropto%20%5Cfrac%7B1%7D%7BP(T=t%7CX=x)%7D%0A"></p>
<p>이는 성향 점수(Propensity Score)의 역수와 같습니다. 즉, <strong>Pearl의 프레임워크에서도 성향 점수를 이용한 가중 컨포멀 추론이 유효함</strong>을 증명한 것입니다.</p>
<hr>
</section>
</section>
<section id="불변-예측-프레임워크-invariant-prediction-framework" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="불변-예측-프레임워크-invariant-prediction-framework"><span class="header-section-number">3</span> 불변 예측 프레임워크 (Invariant Prediction Framework)</h2>
<section id="문제-설정" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="문제-설정"><span class="header-section-number">3.1</span> 문제 설정</h3>
<p>Peters et al.(2016)이 제안한 불변 예측 프레임워크는 서로 다른 환경(Environments, 예: 유전자 노크아웃 실험 등)에서 데이터가 수집될 때 강력한 힘을 발휘합니다.</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Y">: 결과 변수</li>
<li><img src="https://latex.codecogs.com/png.latex?X">: 개입 또는 공변량</li>
<li><img src="https://latex.codecogs.com/png.latex?E">: 환경 변수 (데이터 소스, <img src="https://latex.codecogs.com/png.latex?e_1,%20%5Cdots,%20e_J">)</li>
</ul>
<p><strong>핵심 가정 (Invariance Assumption):</strong> 환경 <img src="https://latex.codecogs.com/png.latex?E">가 변하더라도, <img src="https://latex.codecogs.com/png.latex?X">가 주어졌을 때 <img src="https://latex.codecogs.com/png.latex?Y">의 조건부 분포는 변하지 않습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AY%20%5Cperp%20E%20%5Cmid%20X%20%5Cquad%20%5Ciff%20%5Cquad%20P(Y%7CX,%20E)%20=%20P(Y%7CX)%0A"></p>
<p>하지만 <img src="https://latex.codecogs.com/png.latex?X">의 분포는 환경에 따라 달라질 수 있습니다 (<img src="https://latex.codecogs.com/png.latex?X%7CE%20%5Csim%20P_X%5EE">). 우리의 목표는 새로운 타겟 환경 <img src="https://latex.codecogs.com/png.latex?e_0">에서의 결과를 예측하는 것입니다.</p>
<p>![Image: invariant_prediction_dag.png] <em>Figure 2: 불변 예측의 구조. 환경 E는 X에 영향을 주지만, Y는 오직 X에 의해서만 직접적인 영향을 받는다(Y에 대한 E의 직접 경로 없음).</em></p>
</section>
<section id="case-1-단일-소스-환경-j1" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="case-1-단일-소스-환경-j1"><span class="header-section-number">3.2</span> Case 1: 단일 소스 환경 (<img src="https://latex.codecogs.com/png.latex?J=1">)</h3>
<p>데이터 소스가 하나(<img src="https://latex.codecogs.com/png.latex?e_1">)이고, 타겟 환경이 <img src="https://latex.codecogs.com/png.latex?e_0">인 경우를 봅시다.</p>
<ul>
<li><strong>관측 분포 (Source):</strong> <img src="https://latex.codecogs.com/png.latex?P_X%5E%7Be_1%7D%20%5Ctimes%20P_%7BY%7CX%7D"></li>
<li><strong>타겟 분포 (Target):</strong> <img src="https://latex.codecogs.com/png.latex?P_X%5E%7Be_0%7D%20%5Ctimes%20P_%7BY%7CX%7D"></li>
</ul>
<p>이 역시 잠재적 결과 프레임워크와 동일한 <strong>공변량 변화(Covariate Shift)</strong> 문제입니다. 따라서 다음 가중치를 사용하여 Weighted Split-CQR을 적용하면 됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Aw(x)%20=%20%5Cfrac%7Bd%20P_X%5E%7Be_0%7D(x)%7D%7Bd%20P_X%5E%7Be_1%7D(x)%7D%0A"></p>
</section>
<section id="case-2-다중-소스-환경-j-1" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="case-2-다중-소스-환경-j-1"><span class="header-section-number">3.3</span> Case 2: 다중 소스 환경 (<img src="https://latex.codecogs.com/png.latex?J%20%3E%201">)</h3>
<p>여러 환경 <img src="https://latex.codecogs.com/png.latex?e_1,%20%5Cdots,%20e_J">에서 데이터 <img src="https://latex.codecogs.com/png.latex?(X_%7Bij%7D,%20Y_%7Bij%7D)">가 수집된 경우는 조금 더 복잡합니다.</p>
<p>Tibshirani et al.(2019b)의 일반화된 가중치를 사용할 수도 있지만, 식이 매우 복잡해집니다. 논문은 대신 <strong>가중 모집단(Weighted Population)</strong>을 생성하는 대안을 제시합니다.</p>
<p>여러 환경의 데이터를 적절한 비율 <img src="https://latex.codecogs.com/png.latex?q_j">로 섞어서, 타겟 환경 <img src="https://latex.codecogs.com/png.latex?e_0">의 분포와 유사하게 만드는 아이디어입니다.</p>
<p><strong>[수학적 유도]</strong> 관측된 혼합 분포를 다음과 같이 정의합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP_%7BObs%7D%20=%20%5Cleft(%20%5Csum_%7Bj=1%7D%5EJ%20q_j%20P_X%5E%7Be_j%7D%20%5Cright)%20%5Ctimes%20P_%7BY%7CX%7D%0A"></p>
<p>우리가 원하는 타겟 분포는 <img src="https://latex.codecogs.com/png.latex?P_X%5E%7Be_0%7D%20%5Ctimes%20P_%7BY%7CX%7D">입니다. 따라서 이 혼합 데이터셋에 대해 다음 가중치를 적용하면 됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Aw(x)%20=%20%5Cfrac%7B1%7D%7B%5Csum_%7Bj=1%7D%5EJ%20q_j%20%5Cfrac%7Bd%20P_X%5E%7Be_j%7D%7D%7Bd%20P_X%5E%7Be_0%7D%7D(x)%7D%0A"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?q_j">는 공변량 분포의 균형을 맞추는 절차(Balancing procedures)를 통해 선택할 수 있습니다. 이를 통해 다중 환경 데이터를 통합하여 타겟 환경에 대한 이중 강건성(Doubly Robust)을 가진 구간 추정이 가능해집니다.</p>
<hr>
</section>
</section>
<section id="전체-요약-및-결론" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="전체-요약-및-결론"><span class="header-section-number">4</span> 전체 요약 및 결론</h2>
<p>이 논문은 <strong>“평균(ATE)에서 개인(ITE)으로”</strong>, 그리고 <strong>“점 추정에서 구간 추정으로”</strong> 인과추론의 패러다임을 확장했습니다.</p>
<ol type="1">
<li><strong>문제의 재정의:</strong> ITE 추정 문제를 <strong>반사실(Counterfactual)의 예측 구간 생성</strong> 문제로 치환했습니다.</li>
<li><strong>방법론:</strong> <strong>가중 컨포멀 추론(Weighted Split-CQR)</strong>을 도입하여, 학습 분포와 타겟 분포가 다른 상황(Covariate Shift)에서도 신뢰할 수 있는 구간을 생성했습니다.</li>
<li><strong>이론적 보장:</strong>
<ul>
<li>무작위 실험(RCT)에서는 유한 샘플에서도 <strong>완전한(Exact) 커버리지</strong>를 보장합니다.</li>
<li>관찰 연구(Observational Study)에서는 성향 점수나 결과 모델 중 하나만 정확해도 되는 <strong>이중 강건성(Double Robustness)</strong>을 가집니다.</li>
</ul></li>
<li><strong>확장성:</strong> 이 방법론은 Pearl의 인과 다이어그램이나 불변 예측 프레임워크 등, <strong>조건부 불변성</strong>이 성립하는 모든 인과추론 문제에 범용적으로 적용될 수 있습니다.</li>
</ol>
<p>결국, 이 연구는 불확실성이 가득한 세상에서 인과관계를 기반으로 한 의사결정을 내릴 때, <strong>“얼마나 확신할 수 있는가?”</strong>라는 질문에 답할 수 있는 강력하고 유연한 도구를 제공했다고 평가할 수 있습니다.</p>
<hr>
<p><strong>Reference:</strong> Lei, L., &amp; Candès, E. J. (2021). Conformal inference of counterfactuals and individual treatment effects. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 83(5), 911-938.</p>



</section>

 ]]></description>
  <category>Causal Inference</category>
  <category>Pearl&#39;s Causal Diagram</category>
  <category>Invariant Prediction</category>
  <guid>https://shsha0110.github.io/posts/paper/Conformal inference of counterfactuals and individual treatment effects/05-From potential outcomes to other causal frameworks/</guid>
  <pubDate>Wed, 21 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>실전 검증: ACIC 2018 데이터와 NLSM 실제 사례 분석</title>
  <dc:creator>Reviewer </dc:creator>
  <link>https://shsha0110.github.io/posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/</link>
  <description><![CDATA[ 





<section id="들어가며" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="들어가며"><span class="header-section-number">1</span> 들어가며</h2>
<p>이전 포스트(Section 3)까지 우리는 데이터셋에 이미 존재하는 대상(In-sample)에 대해, 관측되지 않은 반사실(Counterfactual)을 추론하여 ITE 구간을 구하는 법을 배웠습니다.</p>
<p>하지만 현실의 문제는 더 어렵습니다. 병원에 <strong>새로운 환자</strong>가 찾아왔습니다. 이 환자는 아직 처치를 받지도(Treat), 받지 않지도(Control) 않았습니다. 즉, <img src="https://latex.codecogs.com/png.latex?Y(1)">과 <img src="https://latex.codecogs.com/png.latex?Y(0)">가 <strong>모두 미지수(Missing)</strong>입니다.</p>
<p>이번 포스트에서는 Section 4에서 제안하는, <strong>두 잠재적 결과가 모두 없는 새로운 대상</strong>에 대해 ITE 신뢰 구간을 구축하는 세 가지 접근법(Naive, Nested-Inexact, Nested-Exact)을 살펴보겠습니다.</p>
<hr>
</section>
<section id="나이브-접근법-a-naive-approach" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="나이브-접근법-a-naive-approach"><span class="header-section-number">2</span> 나이브 접근법 (A Naive Approach)</h2>
<p>가장 직관적이고 단순한 방법은 앞서 배운 반사실 추론 도구를 각각 적용하는 것입니다.</p>
<section id="논리적-구조" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="논리적-구조"><span class="header-section-number">2.1</span> 논리적 구조</h3>
<ol type="1">
<li>새로운 환자 <img src="https://latex.codecogs.com/png.latex?X">에 대해 <img src="https://latex.codecogs.com/png.latex?Y(1)">의 예측 구간 <img src="https://latex.codecogs.com/png.latex?%5B%5Chat%7BY%7D%5EL(1),%20%5Chat%7BY%7D%5ER(1)%5D">을 구합니다.</li>
<li>동일한 환자 <img src="https://latex.codecogs.com/png.latex?X">에 대해 <img src="https://latex.codecogs.com/png.latex?Y(0)">의 예측 구간 <img src="https://latex.codecogs.com/png.latex?%5B%5Chat%7BY%7D%5EL(0),%20%5Chat%7BY%7D%5ER(0)%5D">을 구합니다.</li>
<li>두 구간의 차(Difference)를 이용하여 ITE 구간을 구성합니다.</li>
</ol>
</section>
<section id="수학적-정의" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="수학적-정의"><span class="header-section-number">2.2</span> 수학적 정의</h3>
<p>ITE 구간 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D_%7BITE%7D(x)">는 다음과 같이 정의됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7BC%7D_%7BITE%7D(x)%20=%20%5B%5Chat%7BY%7D%5EL(1;x)%20-%20%5Chat%7BY%7D%5ER(0;x),%20%5Cquad%20%5Chat%7BY%7D%5ER(1;x)%20-%20%5Chat%7BY%7D%5EL(0;x)%5D%0A"></p>
<ul>
<li><strong>하한(Lower Bound):</strong> <img src="https://latex.codecogs.com/png.latex?Y(1)">의 최소값 - <img src="https://latex.codecogs.com/png.latex?Y(0)">의 최대값 (최악의 경우)</li>
<li><strong>상한(Upper Bound):</strong> <img src="https://latex.codecogs.com/png.latex?Y(1)">의 최대값 - <img src="https://latex.codecogs.com/png.latex?Y(0)">의 최소값 (최상의 경우)</li>
</ul>
</section>
<section id="한계점" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="한계점"><span class="header-section-number">2.3</span> 한계점</h3>
<p>만약 각 반사실 구간이 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha/2"> 수준의 커버리지를 가진다면, 이 나이브 구간은 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha"> 수준의 ITE 커버리지를 보장합니다.</p>
<p>하지만 이 방식은 <strong>구간이 지나치게 넓어지는(Conservative)</strong> 경향이 있습니다. <img src="https://latex.codecogs.com/png.latex?Y(1)">과 <img src="https://latex.codecogs.com/png.latex?Y(0)"> 사이의 상관관계를 고려하지 않고, 가장 극단적인 경우를 가정하여 구간을 빼버리기 때문입니다.</p>
<p>![Image: naive_approach_diagram.png] <em>Figure 1: 나이브 접근법의 도식화. 두 개의 독립적인 구간을 단순히 빼서 ITE 구간을 만들면, 불확실성이 과도하게 합쳐져 구간이 매우 넓어진다.</em></p>
<hr>
</section>
</section>
<section id="중첩-접근법-a-nested-approach" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="중첩-접근법-a-nested-approach"><span class="header-section-number">3</span> 중첩 접근법 (A Nested Approach)</h2>
<p>저자들은 나이브 방식의 한계를 극복하기 위해 <strong>중첩(Nested) 접근법</strong>을 제안합니다. 이 방법은 데이터를 두 번 활용하여, ITE에 대한 <strong>“대리 구간(Surrogate Interval)”</strong>을 먼저 만들고 이를 학습하는 방식입니다.</p>
<section id="데이터-분할-전략-data-splitting" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="데이터-분할-전략-data-splitting"><span class="header-section-number">3.1</span> 데이터 분할 전략 (Data Splitting)</h3>
<p>전체 데이터를 두 개의 폴드(Fold 1, Fold 2)로 나눕니다.</p>
<ol type="1">
<li><strong>Fold 1 (Training):</strong> 반사실 구간 모델(<img src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D_1(x),%20%5Chat%7BC%7D_0(x)">)을 학습하는 데 사용합니다 (Section 3의 방법론 적용).</li>
<li><strong>Fold 2 (Inference):</strong> 학습된 모델을 적용하여 각 개체의 ITE 구간을 추론하고, 이를 다시 학습 데이터로 활용합니다.</li>
</ol>
</section>
<section id="대리-구간surrogate-interval-생성" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="대리-구간surrogate-interval-생성"><span class="header-section-number">3.2</span> 대리 구간(Surrogate Interval) 생성</h3>
<p>Fold 2에 있는 개체 <img src="https://latex.codecogs.com/png.latex?i">는 <img src="https://latex.codecogs.com/png.latex?T_i">와 <img src="https://latex.codecogs.com/png.latex?Y_i%5E%7Bobs%7D">를 알고 있습니다. 이를 이용해 개인별 ITE 구간 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D_i">를 다음과 같이 계산합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7BC%7D_%7BITE%7D(X_i;%20T_i,%20Y_i%5E%7Bobs%7D)%20=%0A%5Cbegin%7Bcases%7D%0AY_i%5E%7Bobs%7D%20-%20%5Chat%7BC%7D_0(X_i)%20&amp;%20%5Ctext%7Bif%20%7D%20T_i%20=%201%20%5C%5C%0A%5Chat%7BC%7D_1(X_i)%20-%20Y_i%5E%7Bobs%7D%20&amp;%20%5Ctext%7Bif%20%7D%20T_i%20=%200%0A%5Cend%7Bcases%7D%0A"></p>
<ul>
<li><strong>설명:</strong>
<ul>
<li>처치군(<img src="https://latex.codecogs.com/png.latex?T=1">)은 <img src="https://latex.codecogs.com/png.latex?Y(1)">을 이미 알고 있습니다. 따라서 <img src="https://latex.codecogs.com/png.latex?Y(0)">에 대한 예측 구간만 구해서 관측값에서 빼줍니다.</li>
<li>대조군(<img src="https://latex.codecogs.com/png.latex?T=0">)은 <img src="https://latex.codecogs.com/png.latex?Y(0)">를 이미 알고 있습니다. 따라서 <img src="https://latex.codecogs.com/png.latex?Y(1)">에 대한 예측 구간을 구해서 관측값을 빼줍니다.</li>
</ul></li>
</ul>
<p>![Image: nested_approach_table.png] <em>Figure 2: 중첩 접근법의 데이터 흐름 (Table 3 참조). Fold 1에서 모델을 만들고, Fold 2에서 실제 관측값과 결합하여 ITE 구간을 완성한다.</em></p>
</section>
<section id="커버리지-보장-증명" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="커버리지-보장-증명"><span class="header-section-number">3.3</span> 커버리지 보장 증명</h3>
<p>이렇게 만든 대리 구간 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D_i">가 실제 ITE를 포함할 확률은 얼마나 될까요?</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign%7D%0A%5Cmathbb%7BP%7D(Y_i(1)%20-%20Y_i(0)%20%5Cin%20%5Chat%7BC%7D_i)%20&amp;=%20%5Cmathbb%7BP%7D(T_i=1)%5Cmathbb%7BP%7D(Y_i(0)%20%5Cin%20%5Chat%7BC%7D_0(X_i)%20%7C%20T_i=1)%20%5C%5C%0A&amp;+%20%5Cmathbb%7BP%7D(T_i=0)%5Cmathbb%7BP%7D(Y_i(1)%20%5Cin%20%5Chat%7BC%7D_1(X_i)%20%7C%20T_i=0)%0A%5Cend%7Balign%7D%0A"></p>
<p>만약 우리가 Fold 1에서 만든 구간들이 각각 조건부 커버리지 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha">를 만족한다면(식 14), 위 식에 의해 <strong>대리 구간 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D_i"> 역시 ITE를 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha"> 확률로 포함</strong>하게 됩니다(식 15).</p>
<hr>
</section>
</section>
<section id="중첩-프레임워크-하에서의-두-가지-방법론" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="중첩-프레임워크-하에서의-두-가지-방법론"><span class="header-section-number">4</span> 중첩 프레임워크 하에서의 두 가지 방법론</h2>
<p>이제 우리는 Fold 2 데이터셋을 통해 입력 <img src="https://latex.codecogs.com/png.latex?X_i">와 출력 구간 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D_i">의 쌍 <img src="https://latex.codecogs.com/png.latex?(X_i,%20%5Chat%7BC%7D_i)">를 확보했습니다. 이제 새로운 데이터 <img src="https://latex.codecogs.com/png.latex?X">가 들어왔을 때 어떤 구간을 내놓을지 결정해야 합니다.</p>
<section id="부정확한-방법-the-inexact-method" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="부정확한-방법-the-inexact-method"><span class="header-section-number">4.1</span> 1. 부정확한 방법 (The Inexact Method)</h3>
<p>가장 실용적인 방법은 머신러닝을 이용해 구간의 경계를 직접 예측하는 것입니다.</p>
<ul>
<li><strong>방법:</strong> <img src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D_i">의 왼쪽 끝점(<img src="https://latex.codecogs.com/png.latex?L">)과 오른쪽 끝점(<img src="https://latex.codecogs.com/png.latex?R">)을 타겟 변수로 삼아, <img src="https://latex.codecogs.com/png.latex?X_i">에 대해 회귀 모델을 학습합니다.</li>
<li><strong>예시:</strong> 왼쪽 끝점의 40% 분위수, 오른쪽 끝점의 60% 분위수를 예측하는 모델 등.</li>
<li><strong>특징:</strong>
<ul>
<li><strong>장점:</strong> 나이브 접근법보다 훨씬 짧고 효율적인 구간을 생성합니다.</li>
<li><strong>단점:</strong> “부정확(Inexact)”하다고 명명된 이유는, 최종 예측 결과에 대한 엄밀한 유한 샘플 커버리지 보장(Finite-sample guarantee)이 없기 때문입니다.</li>
</ul></li>
</ul>
</section>
<section id="정확한-방법-the-exact-method" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="정확한-방법-the-exact-method"><span class="header-section-number">4.2</span> 2. 정확한 방법 (The Exact Method)</h3>
<p>엄격한 안전성이 요구되는 의료/금융 분야를 위해, 저자들은 <strong>2차 컨포멀 추론(Secondary Conformal Inference)</strong>을 제안합니다.</p>
<ul>
<li><strong>목표:</strong> 새로운 입력 <img src="https://latex.codecogs.com/png.latex?X">에 대해, 앞서 구한 대리 구간 <img src="https://latex.codecogs.com/png.latex?C">를 포함할 확률이 <img src="https://latex.codecogs.com/png.latex?1-%5Cgamma">인 <strong>구간의 구간(Interval expansion)</strong> <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmathcal%7BC%7D%7D(X)">를 찾는 것입니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D(C%20%5Csubset%20%5Chat%7B%5Cmathcal%7BC%7D%7D(X))%20%5Cge%201%20-%20%5Cgamma%0A"></p>
<p>이를 만족하면 최종적으로 ITE를 놓칠 확률은 <img src="https://latex.codecogs.com/png.latex?%5Calpha%20+%20%5Cgamma"> 이하로 통제됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D(%5Ctext%7BITE%20Error%7D)%20%5Cle%20%5Calpha%20(%5Ctext%7BStep%201%20Error%7D)%20+%20%5Cgamma%20(%5Ctext%7BStep%202%20Error%7D)%0A"></p>
<section id="algorithm-2-구간-결과를-위한-컨포멀-추론" class="level4" data-number="4.2.1">
<h4 data-number="4.2.1" class="anchored" data-anchor-id="algorithm-2-구간-결과를-위한-컨포멀-추론"><span class="header-section-number">4.2.1</span> Algorithm 2: 구간 결과를 위한 컨포멀 추론</h4>
<p>저자들은 단순한 보정(Bonferroni) 대신, 구간의 왼쪽(<img src="https://latex.codecogs.com/png.latex?C%5EL">)과 오른쪽(<img src="https://latex.codecogs.com/png.latex?C%5ER">)을 동시에 보정하는 알고리즘을 제시합니다.</p>
<ol type="1">
<li><strong>점수 계산 (Score <img src="https://latex.codecogs.com/png.latex?V_i">):</strong> 예측된 구간 <img src="https://latex.codecogs.com/png.latex?%5B%5Chat%7Bm%7D%5EL,%20%5Chat%7Bm%7D%5ER%5D">이 실제 대리 구간 <img src="https://latex.codecogs.com/png.latex?%5BC%5EL,%20C%5ER%5D">을 얼마나 벗어났는지 계산합니다. <img src="https://latex.codecogs.com/png.latex?V_i%20=%20%5Cmax%20%5C%7B%20%5Chat%7Bm%7D%5EL(X_i)%20-%20C_i%5EL,%20%5Cquad%20C_i%5ER%20-%20%5Chat%7Bm%7D%5ER(X_i)%20%5C%7D"></li>
<li><strong>보정값 (<img src="https://latex.codecogs.com/png.latex?%5Ceta">) 산출:</strong> <img src="https://latex.codecogs.com/png.latex?V_i">들의 분포에서 <img src="https://latex.codecogs.com/png.latex?(1-%5Cgamma)"> 분위수를 찾아 보정합니다.</li>
<li><strong>최종 구간:</strong> <img src="https://latex.codecogs.com/png.latex?%5B%5Chat%7Bm%7D%5EL(x)%20-%20%5Ceta,%20%5Chat%7Bm%7D%5ER(x)%20+%20%5Ceta%5D"></li>
</ol>
<p>이 “정확한 방법”을 사용하면, 새로운 환자에 대해서도 수학적으로 증명된 커버리지를 가진 ITE 구간을 제공할 수 있습니다.</p>
<hr>
</section>
</section>
</section>
<section id="요약" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="요약"><span class="header-section-number">5</span> 요약</h2>
<p>Section 4는 인과추론의 가장 어려운 단계인 <strong>완전한 미지수(Out-of-sample ITE)</strong>를 다룹니다.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">접근법</th>
<th style="text-align: left;">설명</th>
<th style="text-align: left;">장점</th>
<th style="text-align: left;">단점</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Naive</strong></td>
<td style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?Y(1)"> 구간 - <img src="https://latex.codecogs.com/png.latex?Y(0)"> 구간</td>
<td style="text-align: left;">구현이 쉬움</td>
<td style="text-align: left;">구간이 너무 넓어 쓸모가 적음</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Nested (Inexact)</strong></td>
<td style="text-align: left;">ITE 대리 구간(<img src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D_i">)을 ML로 학습</td>
<td style="text-align: left;">구간이 짧고 효율적임</td>
<td style="text-align: left;">수학적 보장이 완벽하지 않음</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Nested (Exact)</strong></td>
<td style="text-align: left;">대리 구간에 대해 다시 Conformal 적용</td>
<td style="text-align: left;"><strong>이중 보장(<img src="https://latex.codecogs.com/png.latex?%5Calpha+%5Cgamma">)</strong> 가능</td>
<td style="text-align: left;">Inexact보다 구간이 다소 넓을 수 있음</td>
</tr>
</tbody>
</table>
<p>실제 적용 시에는 데이터의 양과 리스크 허용 범위에 따라 <strong>Nested-Inexact</strong> (실용성 중시) 혹은 <strong>Nested-Exact</strong> (안전성 중시)를 선택하여 사용할 수 있습니다.</p>
<hr>
<p><strong>Reference:</strong> Lei, L., &amp; Candès, E. J. (2021). Conformal inference of counterfactuals and individual treatment effects. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 83(5), 911-938.</p>
</section>
<section id="들어가며-1" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="들어가며-1"><span class="header-section-number">6</span> 들어가며</h2>
<p>이론적으로 완벽해 보이는 방법론도 실제 데이터 앞에서는 무력할 수 있습니다. 특히, 인과추론의 가장 큰 난제인 <strong>“두 잠재적 결과가 모두 결측된 새로운 대상(Out-of-sample)”</strong>에 대한 ITE 구간 추정은 검증이 더욱 까다롭습니다.</p>
<p>저자들은 이를 검증하기 위해 두 가지 단계의 실험을 설계했습니다. 1. <strong>정답(Ground Truth)을 아는 상황:</strong> ACIC 2018 워크숍 데이터를 기반으로 한 합성 데이터 실험. 2. <strong>정답을 모르는 상황:</strong> 실제 NLSM(National Study of Learning Mindsets) 데이터 분석.</p>
<hr>
</section>
<section id="acic-2018-데이터를-활용한-성능-평가-empirical-performance" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="acic-2018-데이터를-활용한-성능-평가-empirical-performance"><span class="header-section-number">7</span> ACIC 2018 데이터를 활용한 성능 평가 (Empirical Performance)</h2>
<section id="데이터-생성-메커니즘-data-generating-process" class="level3" data-number="7.1">
<h3 data-number="7.1" class="anchored" data-anchor-id="데이터-생성-메커니즘-data-generating-process"><span class="header-section-number">7.1</span> 데이터 생성 메커니즘 (Data Generating Process)</h3>
<p>저자들은 2018 Atlantic Causal Inference Conference (ACIC) 워크숍에서 사용된 데이터를 기반으로 실험을 설계했습니다. 이 데이터는 실제 대규모 교육 실험인 NLSM의 특성을 모방하여 만들어졌습니다.</p>
<p>커버리지(Coverage)를 정확히 평가하려면 실제값(<img src="https://latex.codecogs.com/png.latex?Y(1),%20Y(0)">)을 알아야 하므로, 저자들은 다음과 같은 과정을 통해 합성 데이터를 생성했습니다.</p>
<p><strong>Step 1: 기저 함수 학습</strong> 전체 데이터를 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BZ%7D_1"> (20%)과 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BZ%7D_2"> (80%)로 나눕니다. <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BZ%7D_1">을 이용해 <img src="https://latex.codecogs.com/png.latex?Y(0)">의 평균 함수 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bm%7D_0(x)">를 Random Forest로 학습합니다.</p>
<p><strong>Step 2: 이분산성(Heteroscedasticity) 모델링</strong> 데이터의 현실성을 높이기 위해 오차의 분산이 공변량에 따라 달라지게 설정합니다. Quantile Random Forest를 이용해 조건부 사분위수 범위(Interquartile Range) <img src="https://latex.codecogs.com/png.latex?%5Chat%7Br%7D_0(x)">와 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Br%7D_1(x)">를 추정합니다.</p>
<p><strong>Step 3: 잠재적 결과 생성 (수학적 정의)</strong> 새로운 공변량 <img src="https://latex.codecogs.com/png.latex?X_i">에 대해, 잠재적 결과는 다음과 같이 생성됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign%7D%0AY_i(0)%20&amp;=%20%5Chat%7Bm%7D_0(X_i)%20+%200.5%20%5Chat%7Br%7D_0(X_i)%20%5Cepsilon_%7Bi0%7D%20%5C%5C%0AY_i(1)%20&amp;=%20%5Chat%7Bm%7D_0(X_i)%20+%20%5Ctau(X_i)%20+%200.5%20%5Chat%7Br%7D_1(X_i)%20%5Cepsilon_%7Bi1%7D%0A%5Cend%7Balign%7D%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctau(x)">: 사전에 정의된 참 CATE 함수.</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cepsilon_%7Bi0%7D,%20%5Cepsilon_%7Bi1%7D%20%5Csim%20N(0,%201)">: 독립적인 표준 정규분포 노이즈.</li>
<li>이 식은 평균 효과뿐만 아니라 분산의 구조까지 반영된 정교한 생성 방식입니다.</li>
</ul>
<p><strong>Step 4: 성향 점수 및 관측 데이터 생성</strong> 성향 점수 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Be%7D(x)">를 추정하고, 이를 0.1과 0.9 사이로 잘라낸(Truncate) 뒤, 베르누이 시행을 통해 처치 여부 <img src="https://latex.codecogs.com/png.latex?T_i">를 결정합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AT_i%20%5Csim%20%5Ctext%7BBernoulli%7D(%5Chat%7Be%7D(X_i))%0A"></p>
</section>
<section id="비교-방법론-및-실험-설정" class="level3" data-number="7.2">
<h3 data-number="7.2" class="anchored" data-anchor-id="비교-방법론-및-실험-설정"><span class="header-section-number">7.2</span> 비교 방법론 및 실험 설정</h3>
<ul>
<li><strong>Training:</strong> <img src="https://latex.codecogs.com/png.latex?n=1000">개의 샘플로 학습.</li>
<li><strong>Testing:</strong> 5000개의 새로운 샘플에 대해 ITE 구간 추정 (오직 <img src="https://latex.codecogs.com/png.latex?X">만 제공됨).</li>
<li><strong>비교 대상:</strong>
<ul>
<li><strong>CQR 계열:</strong> Naive, Exact Nested, Inexact Nested (제안 방법).</li>
<li><strong>BART 계열:</strong> Naive, Inexact Nested.</li>
<li><strong>벤치마크:</strong> Causal Forest, X-learner (ITE용이 아님을 감안).</li>
</ul></li>
</ul>
</section>
<section id="실험-결과-1-커버리지와-구간-길이" class="level3" data-number="7.3">
<h3 data-number="7.3" class="anchored" data-anchor-id="실험-결과-1-커버리지와-구간-길이"><span class="header-section-number">7.3</span> 실험 결과 1: 커버리지와 구간 길이</h3>
<p><img src="https://shsha0110.github.io/posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/Figure_5_Coverage_and_average_length.png" class="img-fluid" alt="Figure 5: Coverage and average length of intervals for ITE"> <em>Figure 5: (왼쪽) ITE 구간의 커버리지. 빨간 선은 목표인 95%. (오른쪽) 구간의 평균 길이. 파란 선은 Oracle 길이.</em></p>
<p><strong>핵심 결과 분석:</strong> 1. <strong>Naive 방법들의 보수성:</strong> CQR(Naive)와 BART(Naive)는 100%에 가까운 커버리지를 보이지만, 구간의 길이가 매우 깁니다(오른쪽 패널). 이는 두 구간을 단순히 뺐기 때문에 불확실성이 과대평가되었음을 의미합니다. 2. <strong>Inexact Nested CQR의 우수성:</strong> 제안된 <strong>Inexact Nested CQR</strong>은 목표치인 95% 커버리지를 정확히 달성하면서도, 구간의 길이가 Naive 방식이나 Exact 방식보다 훨씬 짧고 효율적입니다. 3. <strong>경쟁자들의 실패:</strong> * <strong>BART(Inexact):</strong> 목표 커버리지(95%)에 도달하지 못했습니다. * <strong>Causal Forest / X-learner:</strong> ITE가 아닌 CATE를 추정하도록 설계되었기에, ITE의 불확실성을 담기에는 구간이 턱없이 좁고 커버리지가 매우 낮습니다.</p>
</section>
<section id="실험-결과-2-조건부-커버리지의-안정성" class="level3" data-number="7.4">
<h3 data-number="7.4" class="anchored" data-anchor-id="실험-결과-2-조건부-커버리지의-안정성"><span class="header-section-number">7.4</span> 실험 결과 2: 조건부 커버리지의 안정성</h3>
<p>데이터의 분산(Variance)이나 효과의 크기(CATE)가 달라질 때 커버리지가 유지되는지 확인합니다.</p>
<p><img src="https://shsha0110.github.io/posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/Figure_6_Estimated_conditional_coverage_of_ITE.png" class="img-fluid" alt="Figure 6: Estimated conditional coverage of ITE"> <em>Figure 6: 조건부 분산(위쪽 행)과 CATE 크기(아래쪽 행)에 따른 조건부 커버리지 변화.</em></p>
<ul>
<li><strong>Inexact CQR (맨 오른쪽):</strong> 분산이 커지거나(x축 오른쪽), CATE가 변해도 커버리지가 비교적 안정적으로 유지됩니다.</li>
<li><strong>Inexact BART (두 번째 열):</strong> 조건부 분산이 커질수록 커버리지가 급격히 떨어지는 약점을 보입니다. 이는 Section 3.6의 결과와 일치하며, BART가 이분산성(Heteroscedasticity) 데이터에서 불확실성 추정에 취약함을 재확인시켜 줍니다.</li>
</ul>
<hr>
</section>
</section>
<section id="실제-데이터-재분석-nlsm-re-analysing-nlsm-data" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="실제-데이터-재분석-nlsm-re-analysing-nlsm-data"><span class="header-section-number">8</span> 실제 데이터 재분석: NLSM (Re-analysing NLSM data)</h2>
<section id="분석-개요" class="level3" data-number="8.1">
<h3 data-number="8.1" class="anchored" data-anchor-id="분석-개요"><span class="header-section-number">8.1</span> 분석 개요</h3>
<p>NLSM(National Study of Learning Mindsets)은 학생들의 학습 태도에 대한 개입 효과를 연구한 대규모 실험입니다. 실제 데이터이므로 개별 학생의 참 ITE(<img src="https://latex.codecogs.com/png.latex?Y_i(1)-Y_i(0)">)는 알 수 없습니다(Ground Truth 부재).</p>
<p>하지만 저자들은 제안한 <strong>Inexact CQR (w/ BART learner)</strong> 방법을 적용하여 탐색적 분석(Exploratory Analysis)을 수행했습니다. 이는 실제 환경에서 이 방법론이 어떻게 의사결정을 도울 수 있는지 보여줍니다.</p>
</section>
<section id="분석-방법-교차-예측-cross-prediction" class="level3" data-number="8.2">
<h3 data-number="8.2" class="anchored" data-anchor-id="분석-방법-교차-예측-cross-prediction"><span class="header-section-number">8.2</span> 분석 방법: 교차 예측 (Cross-Prediction)</h3>
<p>데이터를 두 폴드 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BZ%7D_1,%20%5Cmathcal%7BZ%7D_2">로 나눈 뒤, 서로가 서로의 테스트 셋이 되도록 교차하여 ITE 구간을 생성했습니다. 이를 100회 반복하여 변동성을 반영했습니다.</p>
</section>
<section id="분석-결과-및-해석" class="level3" data-number="8.3">
<h3 data-number="8.3" class="anchored" data-anchor-id="분석-결과-및-해석"><span class="header-section-number">8.3</span> 분석 결과 및 해석</h3>
<p><img src="https://shsha0110.github.io/posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/Figure_7_Re_analysis_of_NLSM_data.png" class="img-fluid" alt="Figure 7: Re-analysis of NLSM data"> <em>Figure 7: NLSM 데이터 분석 결과. (a) 유의수준 alpha에 따른 구간 길이. (b) 구간의 하한이 양수인 비율(긍정적 효과). (c) 구간의 상한이 음수인 비율(부정적 효과).</em></p>
<ol type="1">
<li><strong>구간의 길이 (패널 a):</strong> 허용 오차 수준(<img src="https://latex.codecogs.com/png.latex?%5Calpha">)이 커질수록(즉, 신뢰 수준이 낮아질수록) 구간의 길이는 줄어듭니다. 이는 통계적으로 자연스러운 현상입니다.</li>
<li><strong>긍정적 효과의 발견 (패널 b):</strong> <img src="https://latex.codecogs.com/png.latex?%5Calpha%20%3E%200.25"> (신뢰수준 75% 미만)일 때부터 구간의 하한이 0보다 큰(Positive Lower Bound) 케이스들이 나타나기 시작합니다.
<ul>
<li><strong>의미:</strong> “이 학생에게 개입을 하면 학습 태도가 개선될 것이다”라고 어느 정도 확신을 가지고 말할 수 있는 학생들의 비율입니다.</li>
</ul></li>
<li><strong>부정적 효과의 부재 (패널 c):</strong> <img src="https://latex.codecogs.com/png.latex?%5Calpha">를 0.5까지 높여도 구간의 상한이 0보다 작은(Negative Upper Bound) 케이스는 거의 없습니다.
<ul>
<li><strong>의미:</strong> 이 개입(Intervention)이 학생에게 악영향을 끼친다는 증거는 발견되지 않았습니다.</li>
</ul></li>
</ol>
</section>
<section id="실무적-시사점" class="level3" data-number="8.4">
<h3 data-number="8.4" class="anchored" data-anchor-id="실무적-시사점"><span class="header-section-number">8.4</span> 실무적 시사점</h3>
<p>이 분석은 정책 결정자에게 매우 유용한 가이드를 제공합니다. * <strong>안전한 개입:</strong> 부정적 효과가 관측되지 않으므로, 부작용 걱정 없이 프로그램을 시행할 수 있는 근거가 됩니다. * <strong>타겟팅:</strong> 긍정적 효과가 확실시되는 하위 그룹을 식별하여 자원을 집중할 수 있습니다. * 이 모든 판단은 점 추정(Point Estimate)이 아닌, <strong>신뢰할 수 있는 구간(Interval Estimate)</strong>에 기반하므로 훨씬 더 안전합니다.</p>
<hr>
</section>
</section>
<section id="결론-conclusion" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="결론-conclusion"><span class="header-section-number">9</span> 결론 (Conclusion)</h2>
<p>이 논문은 인과추론의 영역을 <strong>‘평균의 점 추정’</strong>에서 <strong>‘개인의 구간 추정’</strong>으로 확장했습니다.</p>
<ol type="1">
<li><strong>방법론의 확장:</strong> 가중 컨포멀 추론(Weighted Conformal Inference)을 통해 관측 데이터의 공변량 변화(Covariate Shift)를 보정했습니다.</li>
<li><strong>이중 강건성:</strong> 성향 점수 혹은 결과 모델 중 하나만 정확해도 커버리지가 보장됨을 입증했습니다.</li>
<li><strong>현실적 적용:</strong> 데이터가 완전히 없는 새로운 대상에 대해서도 중첩(Nested) 접근법을 통해 효율적인 ITE 구간을 생성할 수 있음을 보였습니다.</li>
<li><strong>성능 입증:</strong> 합성 데이터와 실제 데이터 분석을 통해, 기존의 Causal Forest나 BART보다 불확실성 정량화 측면에서 우월함을 증명했습니다.</li>
</ol>
<p>결국 이 연구는 <strong>“불확실성을 고려한 안전하고 정밀한 의사결정”</strong>이라는 인과추론의 궁극적 목표에 한 걸음 더 다가가게 해 줍니다.</p>
<hr>
<p><strong>Reference:</strong> Lei, L., &amp; Candès, E. J. (2021). Conformal inference of counterfactuals and individual treatment effects. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 83(5), 911-938.</p>



</section>

 ]]></description>
  <category>Causal Inference</category>
  <category>Nested Conformal Prediction</category>
  <category>ITE</category>
  <guid>https://shsha0110.github.io/posts/paper/Conformal inference of counterfactuals and individual treatment effects/04-From counterfactuals to treatment effects/</guid>
  <pubDate>Wed, 21 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>점 추정을 넘어 구간 추정으로: 인과추론의 불확실성을 다루는 법</title>
  <dc:creator>Reviewer </dc:creator>
  <link>https://shsha0110.github.io/posts/paper/Conformal inference of counterfactuals and individual treatment effects/02-From point estimates to interval estimates/</link>
  <description><![CDATA[ 





<section id="들어가며" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="들어가며"><span class="header-section-number">1</span> 들어가며</h2>
<p>이전 포스트에서는 왜 우리가 ’평균’을 넘어 ’개인’에 집중해야 하는지 살펴보았습니다. 이번 포스트(Section 2)에서는 이를 수학적으로 정식화(Formalization)하고, 기존의 <strong>점 추정(Point Estimate)</strong> 방식이 왜 불확실성을 담아내기에 부족한지, 그리고 우리가 목표로 하는 <strong>구간 추정(Interval Estimate)</strong>의 정의가 무엇인지 구체적으로 파고들어 보겠습니다.</p>
<hr>
</section>
<section id="문제-설정-problem-setup" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="문제-설정-problem-setup"><span class="header-section-number">2</span> 문제 설정 (Problem Setup)</h2>
<section id="잠재적-결과-프레임워크-potential-outcome-framework" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="잠재적-결과-프레임워크-potential-outcome-framework"><span class="header-section-number">2.1</span> 잠재적 결과 프레임워크 (Potential Outcome Framework)</h3>
<p>논문은 Neyman(1923)과 Rubin(1974)이 정립한 <strong>잠재적 결과 프레임워크</strong>를 따릅니다. <img src="https://latex.codecogs.com/png.latex?n">명의 대상에 대해 다음과 같은 변수들을 정의합니다.</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?T_i%20%5Cin%20%5C%7B0,%201%5C%7D">: 이진 처치 변수 (Treatment Indicator). (예: 1=약 복용, 0=미복용)</li>
<li><img src="https://latex.codecogs.com/png.latex?(Y_i(1),%20Y_i(0))">: 잠재적 결과 쌍.
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Y_i(1)">: 처치를 받았을 때의 결과.</li>
<li><img src="https://latex.codecogs.com/png.latex?Y_i(0)">: 처치를 받지 않았을 때의 결과.</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?X_i">: 공변량 벡터 (Covariates, 예: 나이, 성별, 혈압 등).</li>
</ul>
<p>우리는 데이터가 <strong>I.I.D. (Independent and Identically Distributed)</strong> 가정하에 생성된다고 봅니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A(Y_i(1),%20Y_i(0),%20T_i,%20X_i)%20%5Cstackrel%7Bi.i.d%7D%7B%5Csim%7D%20(Y(1),%20Y(0),%20T,%20X)%0A"></p>
</section>
<section id="관측된-데이터와-ite의-정의" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="관측된-데이터와-ite의-정의"><span class="header-section-number">2.2</span> 관측된 데이터와 ITE의 정의</h3>
<p>현실에서는 <strong>SUTVA(Stable Unit Treatment Value Assumption)</strong> 가정하에, 각 개인에 대해 오직 하나의 결과만 관측됩니다. 이를 <strong>관측된 결과(Observed Outcome, <img src="https://latex.codecogs.com/png.latex?Y_i%5E%7Bobs%7D">)</strong>라고 합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AY_i%5E%7Bobs%7D%20=%20%5Cbegin%7Bcases%7D%0AY_i(1)%20&amp;%20%5Ctext%7Bif%20%7D%20T_i%20=%201%20%5C%5C%0AY_i(0)%20&amp;%20%5Ctext%7Bif%20%7D%20T_i%20=%200%0A%5Cend%7Bcases%7D%0A"></p>
<p>우리가 알고 싶은 <strong>개별 처치 효과(ITE, Individual Treatment Effect)</strong> <img src="https://latex.codecogs.com/png.latex?%5Ctau_i">는 다음과 같이 정의됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctau_i%20%5Ctriangleq%20Y_i(1)%20-%20Y_i(0)%0A"></p>
<p><strong>핵심 문제:</strong> 정의상, 우리는 <img src="https://latex.codecogs.com/png.latex?Y_i(1)">과 <img src="https://latex.codecogs.com/png.latex?Y_i(0)"> 중 하나만 관측할 수 있습니다. 나머지 하나는 결측(Missing)됩니다. 따라서 ITE는 관측 불가능하며(Unobserved), 오직 추론만 가능합니다.</p>
</section>
<section id="강력한-무시-가능성-strong-ignorability" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="강력한-무시-가능성-strong-ignorability"><span class="header-section-number">2.3</span> 강력한 무시 가능성 (Strong Ignorability)</h3>
<p>이 논문은 분석을 위해 <strong>강력한 무시 가능성(Strong Ignorability)</strong> 가정을 사용합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A(Y(1),%20Y(0))%20%5Cperp%20T%20%5Cmid%20X%0A"></p>
<p>이는 공변량 <img src="https://latex.codecogs.com/png.latex?X">가 주어졌을 때, 처치 할당(<img src="https://latex.codecogs.com/png.latex?T">)이 잠재적 결과와 독립적이라는 뜻입니다. 즉, 측정되지 않은 교란 변수(Unmeasured Confounders)가 없음을 의미합니다.</p>
<p>![Image: strong_ignorability_dag.png] <em>Figure 1: 강력한 무시 가능성을 나타내는 인과 다이어그램(DAG). X가 주어졌을 때 T와 Y(t) 사이에는 직접적인 연결(Confounder)이 없다.</em></p>
<hr>
</section>
</section>
<section id="기존의-추론-목표-cate와-그-한계" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="기존의-추론-목표-cate와-그-한계"><span class="header-section-number">3</span> 기존의 추론 목표: CATE와 그 한계</h2>
<section id="cate의-정의-및-유도" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="cate의-정의-및-유도"><span class="header-section-number">3.1</span> CATE의 정의 및 유도</h3>
<p>기존 연구들은 대부분 <strong>조건부 평균 처치 효과(CATE)</strong> <img src="https://latex.codecogs.com/png.latex?%5Ctau(x)">를 추정하는 데 집중했습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctau(x)%20%5Ctriangleq%20%5Cmathbb%7BE%7D%5BY(1)%20-%20Y(0)%20%5Cmid%20X%20=%20x%5D%0A"></p>
<p>이를 분해하면 두 조건부 평균 함수 <img src="https://latex.codecogs.com/png.latex?m_1(x)">와 <img src="https://latex.codecogs.com/png.latex?m_0(x)">의 차이로 표현할 수 있습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign%7D%0A%5Ctau(x)%20&amp;=%20%5Cmathbb%7BE%7D%5BY(1)%20%5Cmid%20X=x%5D%20-%20%5Cmathbb%7BE%7D%5BY(0)%20%5Cmid%20X=x%5D%20%5C%5C%0A%20%20%20%20%20%20%20%20&amp;=%20m_1(x)%20-%20m_0(x)%0A%5Cend%7Balign%7D%0A"></p>
<p><strong>[수학적 유도: 관측 데이터로의 연결]</strong> 강력한 무시 가능성 가정(<img src="https://latex.codecogs.com/png.latex?(Y(1),%20Y(0))%20%5Cperp%20T%20%5Cmid%20X">) 덕분에, 우리는 잠재적 결과의 평균을 관측된 데이터의 평균으로 대체할 수 있습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign%7D%0Am_1(x)%20&amp;=%20%5Cmathbb%7BE%7D%5BY(1)%20%5Cmid%20X=x%5D%20%5C%5C%0A%20%20%20%20%20%20%20&amp;=%20%5Cmathbb%7BE%7D%5BY(1)%20%5Cmid%20X=x,%20T=1%5D%20%5Cquad%20(%5Cbecause%20%5Ctext%7BIgnorability%7D)%20%5C%5C%0A%20%20%20%20%20%20%20&amp;=%20%5Cmathbb%7BE%7D%5BY%5E%7Bobs%7D%20%5Cmid%20X=x,%20T=1%5D%0A%5Cend%7Balign%7D%0A"></p>
<p>마찬가지로 <img src="https://latex.codecogs.com/png.latex?m_0(x)%20=%20%5Cmathbb%7BE%7D%5BY%5E%7Bobs%7D%20%5Cmid%20X=x,%20T=0%5D"> 입니다. 이로써 인과 추론 문제는 통계적 회귀(Regression) 문제가 됩니다.</p>
</section>
<section id="cate의-한계" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="cate의-한계"><span class="header-section-number">3.2</span> CATE의 한계</h3>
<ol type="1">
<li><strong>불확실성 과소평가:</strong> 고차원 회귀 함수(<img src="https://latex.codecogs.com/png.latex?m(x)">) 주변의 신뢰대(Confidence Band)를 만드는 것은 매우 까다롭습니다. 일반적인 근사법이나 리샘플링 기법은 변동성을 과소평가하는 경향이 있습니다.</li>
<li><strong>분위수(Quantile)의 혼동:</strong> 평균 대신 분위수를 사용하는 <strong>CQTE(Conditional Quantile Treatment Effect)</strong>를 고려할 수도 있습니다. 하지만 주의해야 할 점은 <strong>“차이의 분위수(Quantile of Difference)”</strong>와 <strong>“분위수의 차이(Difference of Quantiles)”</strong>는 전혀 다르다는 것입니다.
<ul>
<li>우리가 알고 싶은 것: Quantile of <img src="https://latex.codecogs.com/png.latex?(Y(1)%20-%20Y(0))"></li>
<li>CQTE: Quantile<img src="https://latex.codecogs.com/png.latex?(Y(1))"> - Quantile<img src="https://latex.codecogs.com/png.latex?(Y(0))"></li>
<li>전자는 <img src="https://latex.codecogs.com/png.latex?Y(1)">과 <img src="https://latex.codecogs.com/png.latex?Y(0)">의 결합 분포(Joint Distribution)를 알아야만 식별 가능한데, 이는 관측이 불가능합니다.</li>
</ul></li>
</ol>
<hr>
</section>
</section>
<section id="새로운-목표-구간-추정-interval-estimates" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="새로운-목표-구간-추정-interval-estimates"><span class="header-section-number">4</span> 새로운 목표: 구간 추정 (Interval Estimates)</h2>
<section id="커버리지coverage-기준" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="커버리지coverage-기준"><span class="header-section-number">4.1</span> 커버리지(Coverage) 기준</h3>
<p>이 연구의 목표는 단순히 점 값을 맞추는 것이 아니라, 실제 값(ITE 혹은 잠재적 결과)을 포함할 확률이 보장되는 <strong>예측 구간(Prediction Interval)</strong>을 만드는 것입니다.</p>
<p>예를 들어, <img src="https://latex.codecogs.com/png.latex?Y(1)">에 대한 예측 구간 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D_1(X)">는 다음을 만족해야 합니다. (사전에 지정된 레벨 <img src="https://latex.codecogs.com/png.latex?%5Calpha">에 대해)</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D(Y(1)%20%5Cin%20%5Chat%7BC%7D_1(X))%20%5Cge%201%20-%20%5Calpha%0A"></p>
<p>마찬가지로, ITE인 <img src="https://latex.codecogs.com/png.latex?Y(1)-Y(0)">에 대한 구간 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D_%7BITE%7D(X)">는 다음을 만족해야 합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D(Y(1)%20-%20Y(0)%20%5Cin%20%5Chat%7BC%7D_%7BITE%7D(X))%20%5Cge%201%20-%20%5Calpha%0A"></p>
<p>![Image: prediction_interval_concept.png] <em>Figure 2: 점 추정(Point Estimate) vs 구간 추정(Interval Estimate). 점 추정은 하나의 선으로 나타나지만, 구간 추정은 데이터가 포함될 범위를 띠(Band) 형태로 제공하여 불확실성을 시각화한다.</em></p>
</section>
<section id="오라클oracle-구간과-현실" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="오라클oracle-구간과-현실"><span class="header-section-number">4.2</span> 오라클(Oracle) 구간과 현실</h3>
<p>만약 우리가 <img src="https://latex.codecogs.com/png.latex?Y(1)">의 조건부 분포를 완벽하게 안다면, 참 분위수(True Quantiles) <img src="https://latex.codecogs.com/png.latex?q_%7B%5Cbeta%7D(x)">를 이용해 최적의 구간을 만들 수 있습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AC_1(x)%20=%20%5Bq_%7B%5Calpha/2%7D(x),%20q_%7B1-%5Calpha/2%7D(x)%5D%0A"></p>
<p>하지만 현실에서는 제한된 샘플 크기와 모델 불확실성 때문에 참 분위수를 알 수 없습니다. 이를 추정치로 대체하면 커버리지를 보장하기 어렵습니다. 저자들은 Conformal Inference를 통해 이 문제를 해결하고자 합니다.</p>
<hr>
</section>
</section>
<section id="일반화된-커버리지-기준-general-coverage-criteria" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="일반화된-커버리지-기준-general-coverage-criteria"><span class="header-section-number">5</span> 일반화된 커버리지 기준 (General Coverage Criteria)</h2>
<section id="ate-vs-att" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="ate-vs-att"><span class="header-section-number">5.1</span> ATE vs ATT</h3>
<p>전통적인 인과추론에서는 전체 평균(ATE)보다 <strong>처치군 평균 처치 효과(ATT, Average Treatment Effect on the Treated)</strong>를 선호하는 경우가 많습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BATT%7D%20=%20%5Cmathbb%7BE%7D%5BY(1)%20-%20Y(0)%20%5Cmid%20T=1%5D%0A"></p>
<p>이에 맞춰 커버리지 기준도 조건부 확률로 수정할 수 있습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D(Y(t)%20%5Cin%20%5Chat%7BC%7D_t(X)%20%5Cmid%20T=1)%20%5Cge%201%20-%20%5Calpha%0A"></p>
<p>이는 <img src="https://latex.codecogs.com/png.latex?X">의 분포를 모집단 전체가 아닌, 처치를 받은 집단(<img src="https://latex.codecogs.com/png.latex?T=1">)의 분포로 한정하여 평가하겠다는 의미입니다.</p>
</section>
<section id="일반화-transportability" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="일반화-transportability"><span class="header-section-number">5.2</span> 일반화 (Transportability)</h3>
<p>더 나아가, 연구 대상 집단(Study Population)과 우리가 결과를 적용하고자 하는 타겟 집단(Target Population)이 다를 수 있습니다 (Covariate Shift). 이를 위해 저자들은 타겟 분포 <img src="https://latex.codecogs.com/png.latex?Q_X">를 도입한 일반화된 커버리지 기준을 제안합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D_%7B(X,%20Y(t))%20%5Csim%20Q_X%20%5Ctimes%20P_%7BY(t)%7CX%7D%7D%20(Y(t)%20%5Cin%20%5Chat%7BC%7D_t(X))%20%5Cge%201%20-%20%5Calpha%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Q_X">: 타겟 집단의 공변량 분포.</li>
<li>이 식은 <img src="https://latex.codecogs.com/png.latex?Q_X">를 어떻게 설정하느냐에 따라 전체 인구(ATE 관점), 처치군(ATT 관점), 혹은 완전히 새로운 외부 집단(Generalizability/External Validity)에 대한 구간 추정을 모두 포괄합니다.</li>
</ul>
<hr>
</section>
</section>
<section id="요약" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="요약"><span class="header-section-number">6</span> 요약</h2>
<p>Section 2에서는 CATE와 같은 점 추정치가 가진 불확실성 표현의 한계를 지적하고, 이를 극복하기 위해 <strong>ITE에 대한 유효한 예측 구간</strong>을 생성하는 것을 목표로 설정했습니다.</p>
<ul>
<li><strong>기존:</strong> <img src="https://latex.codecogs.com/png.latex?E%5BY(1)-Y(0)%7CX%5D"> (평균) 추정에 집중 -&gt; 불확실성 정보 부족.</li>
<li><strong>제안:</strong> <img src="https://latex.codecogs.com/png.latex?P(Y(1)-Y(0)%20%5Cin%20C(X))%20%5Cge%201-%5Calpha"> (구간) 생성에 집중 -&gt; 리스크 관리 가능.</li>
</ul>
<p>다음 섹션(Section 3)부터는 실제로 관측된 데이터(Observables)를 이용해 어떻게 관측되지 않은 반사실적 결과(Counterfactuals)의 구간을 만들어낼지 구체적인 방법론을 다루게 됩니다.</p>
<hr>
<p><strong>Reference:</strong> Lei, L., &amp; Candès, E. J. (2021). Conformal inference of counterfactuals and individual treatment effects. [cite_start]<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 83(5), 911-938. [cite: 107, 108]</p>



</section>

 ]]></description>
  <category>Causal Inference</category>
  <category>Statistics</category>
  <category>Uncertainty Quantification</category>
  <guid>https://shsha0110.github.io/posts/paper/Conformal inference of counterfactuals and individual treatment effects/02-From point estimates to interval estimates/</guid>
  <pubDate>Wed, 21 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>평균을 넘어 개인으로: 인과추론의 새로운 패러다임과 Conformal Inference</title>
  <dc:creator>Reviewer </dc:creator>
  <link>https://shsha0110.github.io/posts/paper/Conformal inference of counterfactuals and individual treatment effects/01-From average effects to individual effects/</link>
  <description><![CDATA[ 





<section id="들어가며-평균의-함정" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="들어가며-평균의-함정"><span class="header-section-number">1</span> 들어가며: 평균의 함정</h2>
<p>인과추론(Causal Inference) 분야에서 지난 수십 년간 가장 지배적인 목표는 <strong>평균 처치 효과(ATE, Average Treatment Effect)</strong>를 추정하는 것이었습니다. 하지만 ATE는 집단 전체에 대한 거친 요약(coarse summary)일 뿐, 개별 환자나 대상에게 적용할 때는 치명적인 한계를 드러낼 수 있습니다.</p>
<p>논문에서는 아주 직관적인 예시를 듭니다. 어떤 신약이 있다고 가정해 봅시다.</p>
<blockquote class="blockquote">
<p><strong>시나리오:</strong> * 환자의 <strong>70%</strong>: 완치됨 (긍정적 효과) * 환자의 <strong>30%</strong>: 증상이 훨씬 악화됨 (부정적 효과)</p>
</blockquote>
<p>이 경우, 단순 평균을 내면 “효과가 있다”는 긍정적인 ATE가 도출될 수 있습니다. 하지만 이 약을 승인해야 할까요? [cite_start]30%의 환자에게는 독이 될 수 있는 약을 획일적으로 처방하는 것은 위험합니다[cite: 36, 37].</p>
<p>[cite_start]이처럼 <strong>“One-size-fits-all(만능)”</strong> 접근법은 불충분하며, 임상적 특성과 개인의 선호에 맞춘 <strong>개별 처치 효과(ITE, Individual Treatment Effect)</strong>의 추정이 필수적입니다[cite: 42].</p>
<hr>
</section>
<section id="cate의-등장과-그-한계" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="cate의-등장과-그-한계"><span class="header-section-number">2</span> CATE의 등장과 그 한계</h2>
<section id="cate란-무엇인가" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="cate란-무엇인가"><span class="header-section-number">2.1</span> CATE란 무엇인가?</h3>
<p>ITE의 중요성이 대두되면서, 연구자들은 <strong>조건부 평균 처치 효과(CATE, Conditional Average Treatment Effect)</strong>에 주목하기 시작했습니다. CATE는 특정 공변량(covariate, <img src="https://latex.codecogs.com/png.latex?X">)을 가진 하위 그룹의 평균적인 효과를 의미합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctau(x)%20=%20%5Cmathbb%7BE%7D%5BY(1)%20-%20Y(0)%20%7C%20X%20=%20x%5D%0A"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?Y(1)">은 처치를 받았을 때의 잠재적 결과, <img src="https://latex.codecogs.com/png.latex?Y(0)">는 받지 않았을 때의 결과입니다. [cite_start]머신러닝 알고리즘을 활용해 이 CATE를 유연하게 추정하려는 시도가 많았습니다[cite: 16].</p>
<p>!(placeholder_image_1.png) <em>Figure 1: 평균 처치 효과(ATE)와 조건부 평균 처치 효과(CATE)의 차이. ATE는 전체의 평균을 보지만, CATE는 변수 X에 따른 효과의 분포를 추정한다.</em></p>
</section>
<section id="점-추정point-estimate의-위험성" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="점-추정point-estimate의-위험성"><span class="header-section-number">2.2</span> 점 추정(Point Estimate)의 위험성</h3>
<p>하지만 본 논문의 저자들은 CATE 역시 충분하지 않다고 지적합니다. CATE는 여전히 <strong>‘조건부 평균(Expectation)’</strong>에 불과하기 때문입니다. 의사결정, 특히 의료나 공공 정책과 같이 민감한 분야에서는 “평균적으로 어떠한가”보다 <strong>“불확실성이 어느 정도인가”</strong>가 훨씬 중요합니다.</p>
<p>[cite_start]저자들은 CATE 추정만으로는 놓치게 되는 두 가지 핵심적인 변동성(Variability)을 강조합니다[cite: 48].</p>
<ol type="1">
<li><strong>반응 변수의 내재적 변동성 (Aleatoric Uncertainty):</strong> 회귀 함수(regression function) 주변에 데이터가 얼마나 퍼져 있는가? 공변량 <img src="https://latex.codecogs.com/png.latex?X">가 ITE의 변동을 완벽하게 설명하지 못한다면 여전히 큰 불확실성이 남습니다.</li>
<li><strong>추정량의 변동성 (Epistemic Uncertainty):</strong> 유한한 표본(finite samples)으로 인해 발생하는 CATE 추정값 자체의 오차입니다.</li>
</ol>
<p>이 두 가지를 모두 통제하려면, (1) 공변량이 ITE의 변동을 거의 완벽하게 설명해야 하고, (2) 모든 <img src="https://latex.codecogs.com/png.latex?X"> 값에 대해 CATE를 완벽하게 추정할 수 있어야 합니다. [cite_start]현실적으로 이는 불가능에 가깝습니다[cite: 49, 50].</p>
<hr>
</section>
</section>
<section id="불확실성-정량화-신뢰구간의-필요성" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="불확실성-정량화-신뢰구간의-필요성"><span class="header-section-number">3</span> 불확실성 정량화: 신뢰구간의 필요성</h2>
<p>[cite_start]미국 FDA는 약물 승인을 위해 단순한 점 추정치가 아닌, 충분한 증거를 보장하는 <strong>신뢰구간(Confidence Interval)</strong> 또는 p-value를 요구합니다[cite: 57]. 하지만 기존의 머신러닝 기반 CATE 추정 방법들은 이러한 불확실성 정량화(Uncertainty Quantification)에서 꽤 저조한 성능을 보입니다.</p>
<p>[cite_start]심지어 베이지안 방법론을 포함한 최신 기법들도 간단하고 매끄러운 모형(smooth models)에서조차 목표하는 커버리지(coverage)를 달성하지 못하는 경우가 많습니다[cite: 61].</p>
<section id="제안하는-해결책-conformal-inference" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="제안하는-해결책-conformal-inference"><span class="header-section-number">3.1</span> 제안하는 해결책: Conformal Inference</h3>
<p>[cite_start]이 논문은 <strong>Conformal Inference(컨포멀 추론)</strong> 아이디어를 차용하여, 잠재적 결과(Potential Outcome) 프레임워크 하에서 신뢰할 수 있는 ITE 예측 구간(Prediction Interval)을 생성하는 방법을 제안합니다[cite: 19, 62].</p>
<p>!(placeholder_image_2.png) <em>Figure 2: Conformal Inference의 기본 개념. 데이터 분포에 대한 가정 없이, 유한한 샘플에서 실제 값이 포함될 확률(예: 90%)을 보장하는 구간을 생성한다.</em></p>
<hr>
</section>
</section>
<section id="해결해야-할-두-가지-도전-과제" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="해결해야-할-두-가지-도전-과제"><span class="header-section-number">4</span> 해결해야 할 두 가지 도전 과제</h2>
<p>[cite_start]ITE에 대한 신뢰 구간을 만들기 위해 논문은 문제를 두 가지 단계로 나눕니다[cite: 63, 64, 65].</p>
<section id="challenge-1-연구-대상자in-sample를-위한-구간-추정" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="challenge-1-연구-대상자in-sample를-위한-구간-추정"><span class="header-section-number">4.1</span> Challenge 1: 연구 대상자(In-sample)를 위한 구간 추정</h3>
<p>데이터셋에 존재하는 대상(<img src="https://latex.codecogs.com/png.latex?i">)에 대해 ITE 구간을 만드는 것입니다. * <strong>문제:</strong> 각 대상에 대해 <img src="https://latex.codecogs.com/png.latex?Y_i(1)"> 혹은 <img src="https://latex.codecogs.com/png.latex?Y_i(0)"> 중 하나만 관측됩니다(Fundamental Problem of Causal Inference). * <strong>접근법:</strong> 관측되지 않은 잠재적 결과(Counterfactual)를 추론하는 문제로 귀결됩니다.</p>
</section>
<section id="challenge-2-새로운-대상out-of-sample을-위한-구간-추정" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="challenge-2-새로운-대상out-of-sample을-위한-구간-추정"><span class="header-section-number">4.2</span> Challenge 2: 새로운 대상(Out-of-sample)을 위한 구간 추정</h3>
<p>연구에 참여하지 않은 완전히 새로운 대상에 대해 ITE 구간을 만드는 것입니다. * <strong>문제:</strong> 이들은 <img src="https://latex.codecogs.com/png.latex?Y(1)">과 <img src="https://latex.codecogs.com/png.latex?Y(0)">가 둘 다 관측되지 않습니다. * <strong>접근법:</strong> 두 잠재적 결과를 동시에 모델링할 수 없으므로 훨씬 더 어려운 문제입니다.</p>
<hr>
</section>
</section>
<section id="핵심-아이디어의-논리적-전개-step-by-step" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="핵심-아이디어의-논리적-전개-step-by-step"><span class="header-section-number">5</span> 핵심 아이디어의 논리적 전개 (Step-by-Step)</h2>
<p>논문의 Section 1은 구체적인 수식보다는 방법론의 <strong>논리적 구조</strong>를 설명하는 데 집중합니다. [cite_start]저자들이 제안하는 방법이 어떻게 첫 번째 Challenge(반사실적 추론)를 해결하여 ITE 구간으로 연결되는지 단계별로 정리해 보겠습니다[cite: 70, 71].</p>
<section id="step-1-반사실적counterfactual-결과의-추론" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="step-1-반사실적counterfactual-결과의-추론"><span class="header-section-number">5.1</span> Step 1: 반사실적(Counterfactual) 결과의 추론</h3>
<p>어떤 환자 <img src="https://latex.codecogs.com/png.latex?i">가 처치(<img src="https://latex.codecogs.com/png.latex?T_i=1">)를 받았고 결과 <img src="https://latex.codecogs.com/png.latex?Y_i(1)">이 관측되었다고 가정해 봅시다. 우리가 알고 싶은 ITE는 다음과 같습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctau_i%20=%20Y_i(1)%20-%20Y_i(0)%0A"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?Y_i(1)">은 이미 알고 있는 상수(observed)입니다. 따라서 <img src="https://latex.codecogs.com/png.latex?%5Ctau_i">를 아는 것은 오직 미지의 값인 <strong><img src="https://latex.codecogs.com/png.latex?Y_i(0)">(Counterfactual)</strong>를 추론하는 것에 달려 있습니다.</p>
</section>
<section id="step-2-예측-구간-생성" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="step-2-예측-구간-생성"><span class="header-section-number">5.2</span> Step 2: 예측 구간 생성</h3>
<p>Conformal Inference를 사용하여, 미지의 <img src="https://latex.codecogs.com/png.latex?Y_i(0)">가 포함될 확률이 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha">인 예측 구간 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D_0(X_i)">를 생성합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D(Y_i(0)%20%5Cin%20%5Chat%7BC%7D_0(X_i))%20%5Cge%201%20-%20%5Calpha%0A"></p>
</section>
<section id="step-3-구간의-이동shifting을-통한-ite-구간-도출" class="level3" data-number="5.3">
<h3 data-number="5.3" class="anchored" data-anchor-id="step-3-구간의-이동shifting을-통한-ite-구간-도출"><span class="header-section-number">5.3</span> Step 3: 구간의 이동(Shifting)을 통한 ITE 구간 도출</h3>
<p>이제 관측된 <img src="https://latex.codecogs.com/png.latex?Y_i(1)">을 이용하여 위에서 구한 구간을 이동(shift)시킵니다. 부등식을 재배열하면 자연스럽게 ITE(<img src="https://latex.codecogs.com/png.latex?%5Ctau_i">)에 대한 구간이 도출됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AY_i(0)%20%5Cin%20%5Chat%7BC%7D_0(X_i)%20%5Ciff%20Y_i(1)%20-%20%5Ctau_i%20%5Cin%20%5Chat%7BC%7D_0(X_i)%0A"></p>
<p>이를 <img src="https://latex.codecogs.com/png.latex?%5Ctau_i">에 대해 정리하면:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctau_i%20%5Cin%20Y_i(1)%20-%20%5Chat%7BC%7D_0(X_i)%0A"></p>
<p>즉, <strong>“관측되지 않은 잠재적 결과에 대한 신뢰 구간을 구하면, 이를 관측된 결과와 대조하여 ITE의 신뢰 구간으로 변환할 수 있다”</strong>는 것이 핵심 논리입니다.</p>
<hr>
</section>
</section>
<section id="결론-및-요약" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="결론-및-요약"><span class="header-section-number">6</span> 결론 및 요약</h2>
<p>이 논문의 Section 1은 단순히 평균 효과(ATE)나 조건부 평균(CATE)을 추정하는 것을 넘어, <strong>개별 효과(ITE)의 불확실성을 정량화</strong>하는 것이 왜 필수적인지 역설합니다.</p>
<p>특히 저자들은 자신들의 방법론이 <strong>이중 강건성(Doubly Robust Property)</strong>을 가짐을 강조합니다. [cite_start]이는 (1) 성향 점수(Propensity Score) 모델이 정확하거나, (2) 조건부 분위수(Conditional Quantiles) 모델이 정확하다면, 둘 중 하나만 만족해도 평균 커버리지(Average Coverage)가 보장된다는 강력한 성질입니다[cite: 21].</p>
<p>다음 포스트에서는 이 개념들이 구체적인 수식과 알고리즘(Section 2 이후)으로 어떻게 구현되는지 살펴보겠습니다.</p>
<hr>
<p><strong>Reference:</strong> Lei, L., &amp; Candès, E. J. (2021). Conformal inference of counterfactuals and individual treatment effects. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 83(5), 911-938.</p>


</section>

 ]]></description>
  <category>Causal Inference</category>
  <category>Statistics</category>
  <category>Machine Learning</category>
  <guid>https://shsha0110.github.io/posts/paper/Conformal inference of counterfactuals and individual treatment effects/01-From average effects to individual effects/</guid>
  <pubDate>Wed, 21 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 13. IV (Part 3)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L13/causal-inference-13-part-03/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>Introduction</h1>
<ul>
<li><p>데이터를 다루다 보면 선형(Linear) 모델로는 설명하기 힘든 복잡한 인과관계를 마주하게 됩니다.</p></li>
<li><p>전통적인 <strong>2단계 최소제곱법(2SLS)</strong>은 강력한 도구이지만, 다음과 같은 한계가 있습니다.</p>
<ul>
<li><ol type="1">
<li>처치(Treatment)와 결과(Outcome)의 관계를 <strong>선형</strong>으로 가정합니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li>공변량(Covariate)과 처치 변수 간의 복잡한 <strong>상호작용</strong>을 포착하기 어렵습니다.</li>
</ol></li>
</ul></li>
<li><p>이번 포스트에서는 Hartford et al.(2017)이 제안한 <strong>Deep IV</strong> 방법론을 소개하고, 가격(<img src="https://latex.codecogs.com/png.latex?P">)과 판매량(<img src="https://latex.codecogs.com/png.latex?Y">)의 비선형적 관계를 시뮬레이션 데이터를 통해 추정해보겠습니다.</p></li>
</ul>
<section id="the-problem-formulation" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-formulation">The Problem Formulation</h2>
<ul>
<li>우리가 해결하고자 하는 인과추론 문제는 다음과 같은 구조적 방정식(Structural Equation)으로 정의됩니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?Y%20=%20g(P,%20X)%20+%20%5Cepsilon"></p>
<ul>
<li>이 수식이 실제 현실에서 어떤 의미를 갖는지, 논문에서 제시한 <strong>항공권 가격 결정 시나리오</strong>를 통해 살펴보겠습니다.</li>
</ul>
</section>
<section id="motivating-example-airline-ticket-pricing" class="level2">
<h2 class="anchored" data-anchor-id="motivating-example-airline-ticket-pricing">Motivating Example: Airline Ticket Pricing</h2>
<ul>
<li><p>항공사가 티켓 가격(<img src="https://latex.codecogs.com/png.latex?P">)을 책정하고 그에 따른 판매량(<img src="https://latex.codecogs.com/png.latex?Y">)을 분석한다고 가정해 봅시다.</p></li>
<li><p>우리의 목표는 “가격을 올렸을 때 판매량이 실제로 얼마나 줄어드는가?”(인과 효과)를 알아내는 것입니다.</p></li>
<li><p>하지만 단순히 데이터를 관찰하면 <strong>내생성(Endogeneity)</strong> 문제로 인해 잘못된 결론에 도달하게 됩니다.</p></li>
<li><p><strong>교란 변수 (<img src="https://latex.codecogs.com/png.latex?E">, Confounder):</strong></p>
<ul>
<li>예를 들어 ‘비즈니스 컨퍼런스’나 ’휴가철’ 같은 수요 급증 요인이 있다고 합시다.</li>
<li>이 요인은 <strong>가격(<img src="https://latex.codecogs.com/png.latex?P">)</strong>을 높이게 만들고(항공사가 가격을 올림), 동시에 <strong>판매량(<img src="https://latex.codecogs.com/png.latex?Y">)</strong>도 높입니다(사람들이 비싸도 삼).</li>
<li>그 결과, 데이터상으로는 <strong>“가격이 비싼데도 판매량이 높네?”</strong>라는 양의 상관관계가 나타나, 가격의 부정적 효과를 과소평가하게 됩니다.</li>
</ul></li>
<li><p>이 고리를 끊기 위해 우리는 <strong>도구 변수 (<img src="https://latex.codecogs.com/png.latex?Z">, Instrument)</strong>를 도입합니다.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L13/causal-inference-13-part-03/images/dag.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Causal Graph (DAG) 인과 관계를 도식화하면 다음과 같습니다.</figcaption>
</figure>
</div>
<hr>
</section>
</section>
<section id="import-libarary" class="level1">
<h1>1. Import Libarary</h1>
<ul>
<li>실습에 필요한 라이브러리를 불러옵니다.</li>
</ul>
<div id="libarary-import" class="cell" data-execution_count="1">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.nn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> nn</span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.optim <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> optim</span>
<span id="cb1-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.distributions <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> D</span>
<span id="cb1-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.nn.functional <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> F</span>
<span id="cb1-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LinearRegression</span>
<span id="cb1-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StandardScaler</span></code></pre></div></div>
</details>
</div>
<hr>
</section>
<section id="data-generation" class="level1">
<h1>2. Data Generation</h1>
<ul>
<li>먼저 내생성과 비선형성이 존재하는 가상의 데이터를 생성합니다.</li>
<li>상황은 다음과 같습니다.
<ul>
<li><strong>가격(<img src="https://latex.codecogs.com/png.latex?P">)</strong>이 오르면 <strong>판매량(<img src="https://latex.codecogs.com/png.latex?Y">)</strong>은 줄어듭니다.</li>
<li>하지만 <strong>성수기(<img src="https://latex.codecogs.com/png.latex?X">)</strong>에는 가격도 비싸고 판매량도 많아, 단순 회귀 시 양의 상관관계(편향)가 관찰됩니다.</li>
<li>실제 인과 효과는 특정 가격 이상에서 급격히 판매량이 떨어지는 <strong>S자 곡선(Sigmoid)</strong> 형태입니다.</li>
</ul></li>
</ul>
<div id="data-generation-function" class="cell" data-execution_count="2">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> generate_data(n, seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>):</span>
<span id="cb2-2">    np.random.seed(seed)</span>
<span id="cb2-3">    </span>
<span id="cb2-4">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. 외생 변수 생성</span></span>
<span id="cb2-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># X: 공변량 (성수기 여부)</span></span>
<span id="cb2-6">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.uniform(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, n) </span>
<span id="cb2-7">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Z: 도구변수 (연료비)</span></span>
<span id="cb2-8">    z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.uniform(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, n) </span>
<span id="cb2-9">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># E: 교란 변수</span></span>
<span id="cb2-10">    e <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.normal(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, n)   </span>
<span id="cb2-11"></span>
<span id="cb2-12">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. 처치 변수 (P) 생성</span></span>
<span id="cb2-13">    p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> z) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> e) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> np.random.normal(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, n)</span>
<span id="cb2-14"></span>
<span id="cb2-15">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. 결과 변수 (Y) 생성</span></span>
<span id="cb2-16">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># True Structural Function: g(p, x)</span></span>
<span id="cb2-17">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> true_structural_function(p_val, x_val):</span>
<span id="cb2-18">        threshold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">35</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x_val) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># X에 따라 임계값이 변함 (Heterogeneity)</span></span>
<span id="cb2-19">        base_effect <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">150</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> np.exp(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (p_val <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> threshold)))</span>
<span id="cb2-20">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> base_effect <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x_val)</span>
<span id="cb2-21">        </span>
<span id="cb2-22">    y_structural <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> true_structural_function(p, x)</span>
<span id="cb2-23">    y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_structural <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> e) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> np.random.normal(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, n)</span>
<span id="cb2-24"></span>
<span id="cb2-25">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> (z.reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), x.reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), p.reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), y.reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), true_structural_function)</span></code></pre></div></div>
</details>
</div>
<div id="data-generation" class="cell" data-execution_count="3">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. 데이터 생성</span></span>
<span id="cb3-2">Z_data, X_data, P_data, Y_data, true_func <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> generate_data(n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. Scaler 선언</span></span>
<span id="cb3-5">scaler_z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb3-6">scaler_x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb3-7">scaler_p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb3-8">scaler_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb3-9"></span>
<span id="cb3-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. Fitting &amp; Transform</span></span>
<span id="cb3-11">Z_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler_z.fit_transform(Z_data)</span>
<span id="cb3-12">X_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler_x.fit_transform(X_data)</span>
<span id="cb3-13">P_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler_p.fit_transform(P_data)</span>
<span id="cb3-14">Y_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler_y.fit_transform(Y_data)</span>
<span id="cb3-15"></span>
<span id="cb3-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 4. 텐서 변환</span></span>
<span id="cb3-17">Z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(Z_scaled, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float32)</span>
<span id="cb3-18">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(X_scaled, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float32)</span>
<span id="cb3-19">P <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(P_scaled, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float32)</span>
<span id="cb3-20">Y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(Y_scaled, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float32)</span></code></pre></div></div>
</details>
</div>
<div id="cell-data-visualization" class="cell" data-execution_count="4">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 스타일 설정</span></span>
<span id="cb4-2">sns.set_style(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"whitegrid"</span>)</span>
<span id="cb4-3">plt.rcParams[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'figure.figsize'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">18</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb4-4">plt.rcParams[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'font.size'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span></span>
<span id="cb4-5"></span>
<span id="cb4-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 데이터 1차원 변환</span></span>
<span id="cb4-7">z_flat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Z_data.flatten()</span>
<span id="cb4-8">x_flat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_data.flatten()</span>
<span id="cb4-9">p_flat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> P_data.flatten()</span>
<span id="cb4-10">y_flat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Y_data.flatten()</span>
<span id="cb4-11"></span>
<span id="cb4-12">fig, axes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb4-13">fig.suptitle(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'DeepIV Simulation: Non-linear Causal Inference'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">22</span>, weight<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bold'</span>)</span>
<span id="cb4-14"></span>
<span id="cb4-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ---------------------------------------------------------</span></span>
<span id="cb4-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (A) First Stage Strength: 도구 변수(Z) -&gt; 처치(P)</span></span>
<span id="cb4-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ---------------------------------------------------------</span></span>
<span id="cb4-18">sns.regplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>z_flat, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>p_flat, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], </span>
<span id="cb4-19">            scatter_kws<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'alpha'</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'color'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'navy'</span>}, line_kws<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'color'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>})</span>
<span id="cb4-20">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'(A) First Stage Relevance: Instrument(Z) -&gt; Treatment(P)'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>, weight<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bold'</span>)</span>
<span id="cb4-21">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Instrument Z (Fuel Cost)'</span>)</span>
<span id="cb4-22">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Treatment P (Price)'</span>)</span>
<span id="cb4-23">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Corr(Z, P): </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>np<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>corrcoef(z_flat, p_flat)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">Strong Relevance"</span>, </span>
<span id="cb4-24">                transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].transAxes, bbox<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>(facecolor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'white'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>))</span>
<span id="cb4-25"></span>
<span id="cb4-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ---------------------------------------------------------</span></span>
<span id="cb4-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (B) Confounding Bias: 가격(P) vs 판매량(Y) (관측 데이터)</span></span>
<span id="cb4-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ---------------------------------------------------------</span></span>
<span id="cb4-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># X(성수기 여부)가 P와 Y 모두를 증가시키는 교란(Confounding) 현상 시각화</span></span>
<span id="cb4-30">scatter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].scatter(p_flat, y_flat, c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>x_flat, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>)</span>
<span id="cb4-31">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'(B) Confounding Bias: Observed P vs Y'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>, weight<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bold'</span>)</span>
<span id="cb4-32">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Price P'</span>)</span>
<span id="cb4-33">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Sales Y'</span>)</span>
<span id="cb4-34">cbar <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.colorbar(scatter, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb4-35">cbar.set_label(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Confounder X (Seasonality)'</span>, rotation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">270</span>, labelpad<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>)</span>
<span id="cb4-36">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Endogeneity Present:</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">High X causes High P &amp; High Y"</span>, </span>
<span id="cb4-37">                transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].transAxes, bbox<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>(facecolor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'white'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>))</span>
<span id="cb4-38"></span>
<span id="cb4-39"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ---------------------------------------------------------</span></span>
<span id="cb4-40"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (C) Covariate Distribution: 공변량(X) -&gt; 가격(P)</span></span>
<span id="cb4-41"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ---------------------------------------------------------</span></span>
<span id="cb4-42">sns.kdeplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>p_flat, hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(x_flat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>), fill<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb4-43">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'(C) P Distribution by Seasonality (X)'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>, weight<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bold'</span>)</span>
<span id="cb4-44">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Treatment P (Price)'</span>)</span>
<span id="cb4-45">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].legend([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'High Season (X&gt;0.5)'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Low Season (X&lt;=0.5)'</span>])</span>
<span id="cb4-46"></span>
<span id="cb4-47"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ---------------------------------------------------------</span></span>
<span id="cb4-48"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (D) The "True" Causal Curve (Ground Truth)</span></span>
<span id="cb4-49"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ---------------------------------------------------------</span></span>
<span id="cb4-50"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> get_true_effect_consistent(p_input, x_val):</span>
<span id="cb4-51">    threshold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">35</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x_val)</span>
<span id="cb4-52">    base_effect <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">150</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> np.exp(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (p_input <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> threshold)))</span>
<span id="cb4-53">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> base_effect <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x_val)</span>
<span id="cb4-54"></span>
<span id="cb4-55">p_range <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(p_flat.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(), p_flat.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>)</span>
<span id="cb4-56"></span>
<span id="cb4-57">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].scatter(p_flat, y_flat, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gray'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Observed Samples'</span>)</span>
<span id="cb4-58"></span>
<span id="cb4-59"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 시나리오별 True Curve 그리기</span></span>
<span id="cb4-60"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># X=0.1 (비수기), X=0.5 (평균), X=0.9 (성수기)</span></span>
<span id="cb4-61">lines_x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>]</span>
<span id="cb4-62">colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>]</span>
<span id="cb4-63">labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Low Season (X=0.1)'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Avg Season (X=0.5)'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'High Season (X=0.9)'</span>]</span>
<span id="cb4-64"></span>
<span id="cb4-65"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> lx, c, lbl <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">zip</span>(lines_x, colors, labels):</span>
<span id="cb4-66">    y_true <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_true_effect_consistent(p_range, lx)</span>
<span id="cb4-67">    axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].plot(p_range, y_true, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>c, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>, linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'True: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>lbl<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb4-68"></span>
<span id="cb4-69">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'(D) Ground Truth: Heterogeneous S-Curves'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>, weight<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bold'</span>)</span>
<span id="cb4-70">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Treatment P (Price)'</span>)</span>
<span id="cb4-71">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Outcome Y (Sales)'</span>)</span>
<span id="cb4-72">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].legend(loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'upper right'</span>, frameon<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, framealpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>)</span>
<span id="cb4-73"></span>
<span id="cb4-74">plt.tight_layout()</span>
<span id="cb4-75">plt.show()</span></code></pre></div></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L13/causal-inference-13-part-03/index_files/figure-html/data-visualization-output-1.png" id="data-visualization" width="1712" height="1130" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<hr>
</section>
<section id="benchmark-linear-2sls" class="level1">
<h1>3. Benchmark: Linear 2SLS</h1>
<ul>
<li>비교를 위해 전통적인 Linear 2SLS를 먼저 수행합니다.</li>
<li><code>scikit-learn</code>을 사용하여 2단계 회귀분석을 진행합니다.
<ul>
<li><ol type="1">
<li>Stage 1: Predict <img src="https://latex.codecogs.com/png.latex?P"> using <img src="https://latex.codecogs.com/png.latex?Z,%20X"></li>
</ol></li>
<li><ol start="2" type="1">
<li>Stage 2: Regress Y on <img src="https://latex.codecogs.com/png.latex?%5Chat%7BP%7D,%20X"></li>
</ol></li>
</ul></li>
</ul>
<div id="linear-2sls" class="cell" data-execution_count="5">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [Stage 1] P ~ Z + X</span></span>
<span id="cb5-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 도구변수(Z)와 공변량(X)를 사용하여 내생변수(P)를 예측.</span></span>
<span id="cb5-3">ZX_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.concatenate((Z_data, X_data), axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb5-4">stage1_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LinearRegression()</span>
<span id="cb5-5">stage1_model.fit(ZX_data, P_data)</span>
<span id="cb5-6"></span>
<span id="cb5-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># P_hat (Hat P): 내생성이 제거된 P의 부분</span></span>
<span id="cb5-8">P_hat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> stage1_model.predict(ZX_data)</span>
<span id="cb5-9"></span>
<span id="cb5-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [Stage 2] Y ~ P_hat + X</span></span>
<span id="cb5-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 예측된 처치(P_hat)와 공변량(X)를 사용하여 결과(Y)를 예측.</span></span>
<span id="cb5-12">PX_hat_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.concatenate((P_hat, X_data), axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb5-13">stage2_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LinearRegression()</span>
<span id="cb5-14">stage2_model.fit(PX_hat_data, Y_data)</span>
<span id="cb5-15"></span>
<span id="cb5-16"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Linear 2SLS Training Complete."</span>)</span>
<span id="cb5-17"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Estimated Causal Effect (Coefficient of P): </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>stage2_model<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>coef_[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Linear 2SLS Training Complete.
Estimated Causal Effect (Coefficient of P): -3.1744</code></pre>
</div>
</div>
<hr>
</section>
<section id="deep-iv-implementation" class="level1">
<h1>4. Deep IV Implementation</h1>
<ul>
<li>구현에 들어가기에 앞서, <strong>“왜 굳이 두 개의 신경망이 필요한가?”</strong>를 수학적으로 짚고 넘어갑시다.</li>
</ul>
<section id="mathematical-intuition-why-two-stages" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-intuition-why-two-stages">Mathematical Intuition: Why Two Stages?</h2>
<ul>
<li><p>우리의 목표는 인과 함수 <img src="https://latex.codecogs.com/png.latex?g(P,%20X)">를 찾는 것입니다.</p></li>
<li><p>하지만 앞서 보았듯 <img src="https://latex.codecogs.com/png.latex?Y%20=%20g(P,%20X)%20+%20%5Cepsilon"> 식에서 바로 회귀분석을 할 수 없습니다.</p></li>
<li><p>오차항 <img src="https://latex.codecogs.com/png.latex?%5Cepsilon">이 <img src="https://latex.codecogs.com/png.latex?P">와 상관관계가 있기 때문입니다.</p></li>
<li><p>이 문제를 해결하기 위해, 우리는 식의 양변에 <strong>도구 변수 <img src="https://latex.codecogs.com/png.latex?Z">와 공변량 <img src="https://latex.codecogs.com/png.latex?X">에 대한 조건부 기댓값(Conditional Expectation)</strong>을 취합니다.</p></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?E%5BY%20%7C%20X,%20Z%5D%20=%20E%5Bg(P,%20X)%20+%20%5Cepsilon%20%7C%20X,%20Z%5D"></p>
<ul>
<li>기댓값의 선형성(Linearity)에 의해 우변을 분리할 수 있습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?E%5BY%20%7C%20X,%20Z%5D%20=%20E%5Bg(P,%20X)%20%7C%20X,%20Z%5D%20+%20%5Cunderbrace%7BE%5B%5Cepsilon%20%7C%20X,%20Z%5D%7D_%7B=%200%7D"></p>
<ul>
<li><p><strong>도구 변수의 정의(외생성)</strong>에 의해, 도구 변수는 오차항과 공변량이 주어진 경우 독립입니다.</p></li>
<li><p>따라서 <img src="https://latex.codecogs.com/png.latex?z%20%5Cperp%20%5Cepsilon%20%7C%20x%20%5CLongrightarrow%20E%5B%5Cepsilon%20%7C%20X,%20Z%5D%20=%200">이 되어 오차항이 사라집니다.</p></li>
<li><p>이제 남은 식을 적분 형태로 풀어서 쓰면 다음과 같습니다.</p></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?E%5BY%20%7C%20X,%20Z%5D%20=%20%5Cint%20g(p,%20x)%20dF(p%20%7C%20x,%20z)"></p>
<ul>
<li>이 식은 Deep IV 모델의 청사진이 됩니다.
<ul>
<li><ol type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?F(p%20%7C%20x,%20z)">:</strong> 우변의 적분을 계산하려면, <img src="https://latex.codecogs.com/png.latex?Z">와 <img src="https://latex.codecogs.com/png.latex?X">가 주어졌을 때 <img src="https://latex.codecogs.com/png.latex?P">가 어떻게 분포하는지 알아야 합니다. <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> <strong>Stage 1 (Treatment Network)</strong></li>
</ol></li>
<li><ol start="2" type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?g(p,%20x)">:</strong> 위 등식을 만족시키는 미지의 함수 <img src="https://latex.codecogs.com/png.latex?g">를 찾아야 합니다. <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> <strong>Stage 2 (Outcome Network)</strong></li>
</ol></li>
</ul></li>
<li>결국 Deep IV는 <strong>“1단계에서 추정한 분포(<img src="https://latex.codecogs.com/png.latex?F">)를 이용해 2단계 함수(<img src="https://latex.codecogs.com/png.latex?g">)를 적분했을 때, 그 결과가 실제 관측된 <img src="https://latex.codecogs.com/png.latex?Y">의 평균과 일치하도록”</strong> 학습하는 과정입니다.</li>
</ul>
<hr>
</section>
<section id="stage-1-mixture-density-network-mdn" class="level2">
<h2 class="anchored" data-anchor-id="stage-1-mixture-density-network-mdn">Stage 1: Mixture Density Network (MDN)</h2>
<ul>
<li>Deep IV의 첫 번째 단계는 ’Treatment Network’를 구축하는 것입니다.</li>
<li>이 단계의 핵심은 전통적인 방식과의 차이점을 이해하는 데 있습니다.</li>
</ul>
<section id="why-density-estimation-point-vs.-distribution" class="level3">
<h3 class="anchored" data-anchor-id="why-density-estimation-point-vs.-distribution">1.1. Why Density Estimation? (Point vs.&nbsp;Distribution)</h3>
<ul>
<li><p>전통적인 <strong>Linear 2SLS</strong> 1단계에서는 도구변수(<img src="https://latex.codecogs.com/png.latex?Z">)와 공변량(<img src="https://latex.codecogs.com/png.latex?X">)을 사용하여 처치 변수의 <strong>평균(Mean)</strong>을 예측합니다. <img src="https://latex.codecogs.com/png.latex?%5Chat%7BP%7D_%7B2SLS%7D%20=%20E%5BP%20%7C%20Z,%20X%5D%20%5Capprox%20%5Calpha%20Z%20+%20%5Cbeta%20X"></p></li>
<li><p>이는 <img src="https://latex.codecogs.com/png.latex?P">와 <img src="https://latex.codecogs.com/png.latex?Z">의 관계가 선형적이고, 오차가 등분산(Homoscedastic)을 가진다는 강력한 가정을 전제로 합니다.</p></li>
<li><p>하지만 논문(Hartford et al., 2017)에서는 현실 데이터가 이보다 훨씬 복잡하다고 지적합니다.</p></li>
<li><p>가격(<img src="https://latex.codecogs.com/png.latex?P">) 결정 과정은 다봉형(Multimodal)일 수도 있고, 시기(<img src="https://latex.codecogs.com/png.latex?X">)에 따라 변동성(Variance)이 달라질 수도 있습니다.</p></li>
<li><p>따라서 단순한 평균값 하나로는 정보 손실이 발생합니다.</p></li>
<li><p><strong>Deep IV의 1단계 목표</strong>는 <img src="https://latex.codecogs.com/png.latex?P">의 값을 하나로 예측하는 것이 아니라, <img src="https://latex.codecogs.com/png.latex?Z">와 <img src="https://latex.codecogs.com/png.latex?X">가 주어졌을 때 <img src="https://latex.codecogs.com/png.latex?P">가 가질 수 있는 <strong>조건부 확률 분포(Conditional Probability Distribution)</strong> 전체를 추정하는 것입니다.</p></li>
</ul>
</section>
<section id="the-mixture-density-network-mdn" class="level3">
<h3 class="anchored" data-anchor-id="the-mixture-density-network-mdn">1.2. The Mixture Density Network (MDN)</h3>
<ul>
<li>복잡한 분포를 유연하게 추정하기 위해, Deep IV는 <strong>MDN(Mixture Density Network)</strong> 구조를 사용합니다.</li>
<li>이는 신경망의 출력을 이용해 <strong>가우시안 혼합 모델(Gaussian Mixture Model, GMM)</strong>의 파라미터를 구성하는 방식입니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%5Chat%7BF%7D(p%7Cz,x)%20=%20%5Csum_%7Bk=1%7D%5E%7BK%7D%20%5Cpi_k(z,x)%20%5Cmathcal%7BN%7D(p%20;%20%5Cmu_k(z,x),%20%5Csigma_k%5E2(z,x))"></p>
<ul>
<li><p>이 수식의 의미는 다음과 같습니다.</p></li>
<li><p><strong><img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BN%7D"> (Normal Distribution):</strong> <img src="https://latex.codecogs.com/png.latex?K">개의 정규분포를 섞어서 복잡한 분포를 표현합니다.</p></li>
<li><p><strong>신경망의 역할:</strong> 입력(<img src="https://latex.codecogs.com/png.latex?Z,%20X">)을 받아 각 정규분포의 파라미터 3가지를 출력합니다.</p>
<ol type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?%5Cpi_k"> (Mixing Coefficient):</strong> <img src="https://latex.codecogs.com/png.latex?k">번째 정규분포가 선택될 확률 (가중치, <img src="https://latex.codecogs.com/png.latex?%5Csum%20%5Cpi_k%20=%201">)</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?%5Cmu_k"> (Mean):</strong> <img src="https://latex.codecogs.com/png.latex?k">번째 정규분포의 중심 (평균)</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?%5Csigma_k"> (Standard Deviation):</strong> <img src="https://latex.codecogs.com/png.latex?k">번째 정규분포의 퍼짐 정도 (분산)</li>
</ol></li>
</ul>
</section>
<section id="deep-iv-architecture-treatment-network" class="level3">
<h3 class="anchored" data-anchor-id="deep-iv-architecture-treatment-network">1.3. Deep IV Architecture: Treatment Network</h3>
<ul>
<li>논문에서 제시하는 네트워크 구조를 도식화하면 다음과 같습니다.
<ul>
<li><ol type="1">
<li><strong>Input:</strong> 도구변수(<img src="https://latex.codecogs.com/png.latex?Z">)와 공변량(<img src="https://latex.codecogs.com/png.latex?X">)이 신경망에 들어갑니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Hidden Layers:</strong> 데이터의 비선형적인 패턴을 학습합니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Output Heads:</strong> 마지막 층은 세 갈래로 나뉩니다.</li>
</ol>
<ul>
<li><code>Softmax</code> <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> <img src="https://latex.codecogs.com/png.latex?%5Cpi"> (가중치)</li>
<li><code>Linear</code> <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> <img src="https://latex.codecogs.com/png.latex?%5Cmu"> (평균)</li>
<li><code>Softplus</code> <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> <img src="https://latex.codecogs.com/png.latex?%5Csigma"> (표준편차, 양수 제약)</li>
</ul></li>
</ul></li>
</ul>
<div id="deep-iv-stage1-model" class="cell" data-execution_count="6">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> FirstStageMDN(nn.Module):</span>
<span id="cb7-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, input_dim, num_gaussians<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>):</span>
<span id="cb7-3">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>().<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb7-4">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.shared_layer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Sequential(</span>
<span id="cb7-5">            nn.Linear(input_dim, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>),</span>
<span id="cb7-6">            nn.ReLU(),</span>
<span id="cb7-7">            nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>),</span>
<span id="cb7-8">            nn.ReLU()</span>
<span id="cb7-9">        )</span>
<span id="cb7-10">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.pi_head <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>, num_gaussians)     <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 혼합 계수</span></span>
<span id="cb7-11">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.mu_head <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>, num_gaussians)     <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 평균</span></span>
<span id="cb7-12">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.sigma_head <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>, num_gaussians)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 표준편차</span></span>
<span id="cb7-13"></span>
<span id="cb7-14">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x, z):</span>
<span id="cb7-15">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. 입력 결합</span></span>
<span id="cb7-16">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shape: (Batch, x_dim) + (Batch, z_dim) -&gt; (Batch, input_dim)</span></span>
<span id="cb7-17">        inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([x, z], dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb7-18">        </span>
<span id="cb7-19">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. 특징 추출</span></span>
<span id="cb7-20">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shape: (Batch, input_dim) -&gt; (Batch, 64)</span></span>
<span id="cb7-21">        features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.shared_layer(inputs)</span>
<span id="cb7-22">        </span>
<span id="cb7-23">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. 파라미터 추정 (K=num_gaussians)</span></span>
<span id="cb7-24">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pi: (Batch, K)</span></span>
<span id="cb7-25">        pi <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> F.softmax(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.pi_head(features), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb7-26">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Mu: (Batch, K)</span></span>
<span id="cb7-27">        mu <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.mu_head(features)</span>
<span id="cb7-28">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Sigma: (Batch, K)</span></span>
<span id="cb7-29">        sigma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> F.softplus(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.sigma_head(features)) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-5</span></span>
<span id="cb7-30">        </span>
<span id="cb7-31">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> pi, mu, sigma</span>
<span id="cb7-32"></span>
<span id="cb7-33">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> sample(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, pi, mu, sigma, n_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>):</span>
<span id="cb7-34">        mix <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> D.Categorical(probs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pi)</span>
<span id="cb7-35">        comp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> D.Normal(loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>mu, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sigma)</span>
<span id="cb7-36">        gmm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> D.MixtureSameFamily(mix, comp)</span>
<span id="cb7-37">        </span>
<span id="cb7-38">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 샘플링 수행</span></span>
<span id="cb7-39">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> n_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:</span>
<span id="cb7-40">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shape: (Batch) -&gt; (Batch, 1)</span></span>
<span id="cb7-41">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> gmm.sample().unsqueeze(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb7-42">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb7-43">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shape: (n_samples, Batch) -&gt; (Batch, n_samples)</span></span>
<span id="cb7-44">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> gmm.sample((n_samples,)).permute(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span></code></pre></div></div>
</details>
</div>
</section>
<section id="optimization-objective-negative-log-likelihood" class="level3">
<h3 class="anchored" data-anchor-id="optimization-objective-negative-log-likelihood">1.4. Optimization Objective (Negative Log-Likelihood)</h3>
<ul>
<li>이 신경망을 학습시키기 위해 사용하는 손실 함수는 <strong>음의 로그 우도(Negative Log-Likelihood, NLL)</strong>입니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D_1(%5Cphi)%20=%20-%20%5Csum_%7Bi=1%7D%5E%7BN%7D%20%5Clog%20%5Cleft(%20%5Csum_%7Bk=1%7D%5E%7BK%7D%20%5Cpi_k(z_i,%20x_i)%20%5Ccdot%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%5Csigma_k(z_i,%20x_i)%7D%20%5Cexp%20%5Cleft(%20-%5Cfrac%7B(p_i%20-%20%5Cmu_k(z_i,%20x_i))%5E2%7D%7B2%5Csigma_k%5E2(z_i,%20x_i)%7D%20%5Cright)%20%5Cright)"></p>
<ul>
<li>쉽게 말해, <strong>“실제 관측된 가격 데이터(<img src="https://latex.codecogs.com/png.latex?p_i">)가 우리 모델의 확률 분포에서 등장할 확률을 최대화하라”</strong>는 뜻입니다.</li>
<li>이를 통해 신경망은 데이터가 뭉쳐 있는 곳(Mode)과 퍼져 있는 정도(Variance)를 정확하게 학습하게 됩니다.</li>
</ul>
<div id="deep-iv-stage1-loss-function" class="cell" data-execution_count="7">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> first_stage_loss_fn(pi, mu, sigma, p):</span>
<span id="cb8-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. 로그 확률 밀도 계산 (Log Probability)</span></span>
<span id="cb8-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shape: (Batch, K)</span></span>
<span id="cb8-4">    m <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> D.Normal(loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>mu, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sigma)</span>
<span id="cb8-5">    log_probs_component <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m.log_prob(p)</span>
<span id="cb8-6">    </span>
<span id="cb8-7">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. 가중치 반영 및 Log-Sum-Exp</span></span>
<span id="cb8-8">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shape: (Batch, K) -&gt; (Batch,)</span></span>
<span id="cb8-9">    weighted_log_probs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.log(pi <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-8</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> log_probs_component</span>
<span id="cb8-10">    log_likelihood <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.logsumexp(weighted_log_probs, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb8-11">    </span>
<span id="cb8-12">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. NLL 평균 (Scalar)</span></span>
<span id="cb8-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>torch.mean(log_likelihood)</span></code></pre></div></div>
</details>
</div>
<hr>
</section>
</section>
<section id="stage-2-outcome-network" class="level2">
<h2 class="anchored" data-anchor-id="stage-2-outcome-network">Stage 2: Outcome Network</h2>
<ul>
<li>1단계에서 우리는 가격(<img src="https://latex.codecogs.com/png.latex?P">)이 형성되는 확률 분포 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BF%7D(P%7CZ,X)">를 얻었습니다.</li>
<li>이제 두 번째 단계에서는 이를 바탕으로 <strong>진짜 인과 함수(Causal Function)</strong> <img src="https://latex.codecogs.com/png.latex?g(P,%20X)">를 찾아낼 차례입니다.</li>
</ul>
<section id="the-structural-equation" class="level3">
<h3 class="anchored" data-anchor-id="the-structural-equation">2.1. The Structural Equation</h3>
<ul>
<li>우리의 목표는 다음 식을 만족하는 함수 <img src="https://latex.codecogs.com/png.latex?g">를 찾는 것입니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?E%5BY%20%7C%20Z,%20X%5D%20=%20%5Cint%20g(p,%20x)%20dF(p%20%7C%20z,%20x)"></p>
<ul>
<li><p>이 식은 <strong>“도구변수(<img src="https://latex.codecogs.com/png.latex?Z">)와 공변량(<img src="https://latex.codecogs.com/png.latex?X">)이 주어졌을 때, 예상되는 판매량(<img src="https://latex.codecogs.com/png.latex?Y">)의 평균은, 가능한 모든 가격(<img src="https://latex.codecogs.com/png.latex?p">)에 대해 해당 가격일 확률과 그 때의 판매량을 곱해서 더한(적분한) 것과 같다”</strong>는 의미입니다.</p></li>
<li><p>여기서 중요한 점은 우리가 1단계 모델(MDN)을 통해 분포 <img src="https://latex.codecogs.com/png.latex?F">를 이미 알고 있다는 것입니다.</p></li>
<li><p>따라서 남은 미지수인 함수 <img src="https://latex.codecogs.com/png.latex?g">를 신경망으로 근사할 수 있습니다.</p></li>
</ul>
</section>
<section id="the-loss-function-inverse-problem" class="level3">
<h3 class="anchored" data-anchor-id="the-loss-function-inverse-problem">2.2. The Loss Function (Inverse Problem)</h3>
<ul>
<li>2단계 신경망(Outcome Network)을 학습시키기 위한 손실 함수는 다음과 같이 정의됩니다. <img src="https://latex.codecogs.com/png.latex?L(%5Ctheta)%20=%20%5Cfrac%7B1%7D%7BN%7D%20%5Csum_%7Bi=1%7D%5E%7BN%7D%20%5Cleft(%20y_i%20-%20%5Cint%20g_%7B%5Ctheta%7D(p,%20x_i)%20d%5Chat%7BF%7D_%7B%5Cphi%7D(p%20%7C%20z_i,%20x_i)%20%5Cright)%5E2">
<ul>
<li><strong><img src="https://latex.codecogs.com/png.latex?y_i">:</strong> 실제 관측된 결과 (Target)</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?%5Cint%20g_%7B%5Ctheta%7D%20d%5Chat%7BF%7D_%7B%5Cphi%7D">:</strong> 1단계 모델의 분포를 반영한 예측값 (Prediction)</li>
</ul></li>
<li>이 손실 함수의 핵심 아이디어는 <strong>“내생성이 있는 개별 <img src="https://latex.codecogs.com/png.latex?P">값 하나를 믿는 대신, 1단계 모델이 예측한 <img src="https://latex.codecogs.com/png.latex?P">의 ’분포 전체’를 믿겠다”</strong>는 것입니다.</li>
<li>분포를 적분하여 얻은 기댓값이 실제 <img src="https://latex.codecogs.com/png.latex?Y">와 일치하도록 강제함으로써, 오차항(<img src="https://latex.codecogs.com/png.latex?%5Cepsilon">)의 영향을 상쇄시킵니다.</li>
</ul>
</section>
<section id="deep-iv-architecture-outcome-network" class="level3">
<h3 class="anchored" data-anchor-id="deep-iv-architecture-outcome-network">2.3. Deep IV Architecture: Outcome Network</h3>
<ul>
<li>2단계 네트워크의 작동 방식은 다음과 같습니다.
<ul>
<li><ol type="1">
<li><strong>Input:</strong> 1단계 분포에서 샘플링된 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BP%7D">와 공변량 <img src="https://latex.codecogs.com/png.latex?X">를 입력받습니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Hidden Layers:</strong> 인과 함수 <img src="https://latex.codecogs.com/png.latex?g(P,X)">의 형태(예: 비선형 S자 곡선)를 학습합니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Output:</strong> 예측된 <img src="https://latex.codecogs.com/png.latex?Y">값을 출력합니다.</li>
</ol></li>
</ul></li>
</ul>
<div id="deep-iv-stage2-model" class="cell" data-execution_count="8">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> SecondStageH(nn.Module):</span>
<span id="cb9-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x_dim, p_dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, output_dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>):</span>
<span id="cb9-3">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>().<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb9-4">        input_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> p_dim</span>
<span id="cb9-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.net <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Sequential(</span>
<span id="cb9-6">            nn.Linear(input_dim, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>),</span>
<span id="cb9-7">            nn.ReLU(),</span>
<span id="cb9-8">            nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>),</span>
<span id="cb9-9">            nn.ReLU(),</span>
<span id="cb9-10">            nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>),</span>
<span id="cb9-11">            nn.ReLU(),</span>
<span id="cb9-12">            nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>, output_dim)</span>
<span id="cb9-13">        )</span>
<span id="cb9-14">        </span>
<span id="cb9-15">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, p, x):</span>
<span id="cb9-16">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 입력 결합</span></span>
<span id="cb9-17">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shape: (Batch, S, p_dim) + (Batch, S, x_dim) -&gt; (Batch, S, input_dim)</span></span>
<span id="cb9-18">        inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([p, x], dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) </span>
<span id="cb9-19">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.net(inputs)</span></code></pre></div></div>
</details>
</div>
</section>
<section id="monte-carlo-approximation" class="level3">
<h3 class="anchored" data-anchor-id="monte-carlo-approximation">2.4. Monte Carlo Approximation</h3>
<ul>
<li>현실적으로 딥러닝 학습 중에 복잡한 적분(<img src="https://latex.codecogs.com/png.latex?%5Cint">)을 매번 계산하는 것은 불가능에 가깝습니다.</li>
<li>따라서 Deep IV는 <strong>몬테카를로 샘플링(Monte Carlo Sampling)</strong>을 사용하여 적분을 근사합니다. <img src="https://latex.codecogs.com/png.latex?%5Cint%20g_%7B%5Ctheta%7D(p,%20x_i)%20d%5Chat%7BF%7D_%7B%5Cphi%7D(p%20%7C%20z_i,%20x_i)%20%5Capprox%20%5Cfrac%7B1%7D%7BS%7D%20%5Csum_%7Bs=1%7D%5E%7BS%7D%20g_%7B%5Ctheta%7D(%5Chat%7Bp%7D%5E%7B(s)%7D,%20x_i)">
<ul>
<li>여기서 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bp%7D%5E%7B(s)%7D">는 1단계 MDN 모델에서 샘플링한 값들입니다 (<img src="https://latex.codecogs.com/png.latex?%5Chat%7Bp%7D%5E%7B(s)%7D%20%5Csim%20%5Chat%7BF%7D_%7B%5Cphi%7D">).</li>
<li><img src="https://latex.codecogs.com/png.latex?S">는 샘플 개수입니다 (보통 10~30개 사용).</li>
</ul></li>
<li>즉, <strong>“1단계 모델이 시뮬레이션한 가상의 가격들(<img src="https://latex.codecogs.com/png.latex?%5Chat%7Bp%7D">)을 2단계 모델에 넣어보고, 그 평균값이 실제 판매량(<img src="https://latex.codecogs.com/png.latex?y">)과 비슷해지도록”</strong> 학습하는 것입니다.</li>
</ul>
<div id="deep-iv-stage2-loss-function" class="cell" data-execution_count="9">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> second_stage_loss_fn(treatment_net, outcome_net, pi, mu, sigma, x, y, num_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>):</span>
<span id="cb10-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. 몬테카를로 샘플링</span></span>
<span id="cb10-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shape: (Batch, S) -&gt; (Batch, S, 1)</span></span>
<span id="cb10-4">    p_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> treatment_net.sample(pi, mu, sigma, n_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>num_samples).unsqueeze(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).detach()</span>
<span id="cb10-5">    </span>
<span id="cb10-6">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. 공변량 차원 확장</span></span>
<span id="cb10-7">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shape: (Batch, x_dim) -&gt; (Batch, S, x_dim)</span></span>
<span id="cb10-8">    batch_size, x_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.shape</span>
<span id="cb10-9">    x_expanded <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).expand(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, num_samples, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb10-10">    </span>
<span id="cb10-11">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. 결과 예측 (Outcome Network Forward)</span></span>
<span id="cb10-12">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shape: (Batch, S, 1) + (Batch, S, x_dim) -&gt; (Batch, S, 1)</span></span>
<span id="cb10-13">    y_pred_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> outcome_net(p_samples, x_expanded)</span>
<span id="cb10-14">    </span>
<span id="cb10-15">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 4. 기댓값 근사 (Sample Mean)</span></span>
<span id="cb10-16">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shape: (Batch, S, 1) -&gt; (Batch, 1)</span></span>
<span id="cb10-17">    y_pred_expectation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_pred_samples.mean(dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb10-18">    </span>
<span id="cb10-19">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 5. 손실 계산 (MSE)</span></span>
<span id="cb10-20">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shape: (Batch, 1) vs (Batch, 1) -&gt; Scalar</span></span>
<span id="cb10-21">    loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> F.mse_loss(y_pred_expectation, y.view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb10-22">    </span>
<span id="cb10-23">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> loss</span></code></pre></div></div>
</details>
</div>
</section>
</section>
<section id="training-procedure" class="level2">
<h2 class="anchored" data-anchor-id="training-procedure">Training Procedure</h2>
<ul>
<li>Deep IV의 학습은 일반적인 지도 학습(Supervised Learning)과는 다르게, <strong>순차적인 두 단계(Sequential Two-Stage Process)</strong>로 진행됩니다.</li>
</ul>
<section id="phase-1-distribution-learning-treatment-network" class="level4">
<h4 class="anchored" data-anchor-id="phase-1-distribution-learning-treatment-network">Phase 1: Distribution Learning (Treatment Network)</h4>
<ul>
<li>첫 번째 단계에서는 <strong>Treatment Network</strong>만을 학습시킵니다.
<ul>
<li><strong>목표:</strong> 도구변수(<img src="https://latex.codecogs.com/png.latex?Z">)와 공변량(<img src="https://latex.codecogs.com/png.latex?X">)을 보고, 처치변수(<img src="https://latex.codecogs.com/png.latex?P">)가 어떻게 분포하는지 완벽하게 모사하는 것입니다.</li>
<li><strong>학습 방법:</strong> <code>NLL Loss</code>를 최소화하여 실제 데이터 <img src="https://latex.codecogs.com/png.latex?P">가 모델의 확률 분포 안에 위치할 확률을 높입니다.</li>
<li><strong>주의점:</strong> 이때 결과변수 <img src="https://latex.codecogs.com/png.latex?Y">는 전혀 사용하지 않습니다.</li>
</ul></li>
</ul>
</section>
<section id="transition-the-freeze" class="level4">
<h4 class="anchored" data-anchor-id="transition-the-freeze">Transition: The Freeze</h4>
<ul>
<li>1단계 학습이 끝나면 Treatment Network의 파라미터(<img src="https://latex.codecogs.com/png.latex?%5Cphi">)를 <strong>동결(Freeze)</strong>합니다.</li>
<li>이제 1단계 모델은 더 이상 학습 대상이 아니라, 내생성이 제거된 가상의 처치값 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BP%7D">를 생성해내는 <strong>시뮬레이터(Generator)</strong> 역할을 수행합니다.</li>
</ul>
</section>
<section id="phase-2-causal-learning-outcome-network" class="level4">
<h4 class="anchored" data-anchor-id="phase-2-causal-learning-outcome-network">Phase 2: Causal Learning (Outcome Network)</h4>
<ul>
<li>두 번째 단계에서는 <strong>Outcome Network</strong>를 학습시킵니다.
<ul>
<li><strong>입력:</strong> 실제 관측된 <img src="https://latex.codecogs.com/png.latex?P">를 사용하는 것이 아니라, <strong>동결된 1단계 모델에서 샘플링한 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BP%7D"></strong>를 사용합니다.</li>
<li><strong>목표:</strong> <img src="https://latex.codecogs.com/png.latex?%5Chat%7BP%7D">를 입력받았을 때의 예측값 평균이 실제 <img src="https://latex.codecogs.com/png.latex?Y">와 가까워지도록 합니다.</li>
<li><strong>학습 방법:</strong> <code>MSE Loss</code>를 최소화하여 인과 함수 <img src="https://latex.codecogs.com/png.latex?g(P,%20X)">를 근사합니다.</li>
</ul></li>
</ul>
<div id="training" class="cell" data-execution_count="10">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -----------------------------------------------------</span></span>
<span id="cb11-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [Stage 1] Treatment Network Training (Z + X -&gt; P distribution)</span></span>
<span id="cb11-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -----------------------------------------------------</span></span>
<span id="cb11-4">treatment_net <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> FirstStageMDN(</span>
<span id="cb11-5">    input_dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>X.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> Z.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], </span>
<span id="cb11-6">    num_gaussians<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span></span>
<span id="cb11-7">)</span>
<span id="cb11-8"></span>
<span id="cb11-9">opt1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> optim.Adam(treatment_net.parameters(), lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-4</span>)</span>
<span id="cb11-10">epochs_stage1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span></span>
<span id="cb11-11"></span>
<span id="cb11-12"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Starting Stage 1 Training (Epochs: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>epochs_stage1<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">)..."</span>)</span>
<span id="cb11-13"></span>
<span id="cb11-14">treatment_net.train()</span>
<span id="cb11-15"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> epoch <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(epochs_stage1):</span>
<span id="cb11-16">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. Forward Pass</span></span>
<span id="cb11-17">    pi, mu, sigma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> treatment_net(X, Z)</span>
<span id="cb11-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. Loss Calculation (Negative Log Likelihood)</span></span>
<span id="cb11-19">    loss1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> first_stage_loss_fn(pi, mu, sigma, P)</span>
<span id="cb11-20">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. Optimization</span></span>
<span id="cb11-21">    opt1.zero_grad()</span>
<span id="cb11-22">    loss1.backward()</span>
<span id="cb11-23">    opt1.step()</span>
<span id="cb11-24">    </span>
<span id="cb11-25">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (epoch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb11-26">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"[Stage 1] Epoch [</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>epoch<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>epochs_stage1<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">] | Loss: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>loss1<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> | Avg Sigma: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>sigma<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>mean()<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>item()<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb11-27"></span>
<span id="cb11-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -----------------------------------------------------</span></span>
<span id="cb11-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [Transition] Freeze Stage 1</span></span>
<span id="cb11-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -----------------------------------------------------</span></span>
<span id="cb11-31">treatment_net.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span>
<span id="cb11-32"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> param <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> treatment_net.parameters():</span>
<span id="cb11-33">    param.requires_grad <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb11-34"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Stage 1 Freezed."</span>)</span>
<span id="cb11-35"></span>
<span id="cb11-36"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -----------------------------------------------------</span></span>
<span id="cb11-37"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [Stage 2] Outcome Network Training (Resampled P + X -&gt; Y)</span></span>
<span id="cb11-38"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -----------------------------------------------------</span></span>
<span id="cb11-39">outcome_net <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SecondStageH(</span>
<span id="cb11-40">    x_dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>X.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], </span>
<span id="cb11-41">    p_dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, </span>
<span id="cb11-42">    output_dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb11-43">)</span>
<span id="cb11-44"></span>
<span id="cb11-45">opt2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> optim.Adam(outcome_net.parameters(), lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-4</span>)</span>
<span id="cb11-46">epochs_stage2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span></span>
<span id="cb11-47"></span>
<span id="cb11-48"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">Starting Stage 2 Training (Epochs: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>epochs_stage2<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">)..."</span>)</span>
<span id="cb11-49"></span>
<span id="cb11-50">outcome_net.train()</span>
<span id="cb11-51"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> epoch <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(epochs_stage2):</span>
<span id="cb11-52">    total_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb11-53"></span>
<span id="cb11-54">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb11-55">        pi, mu, sigma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> treatment_net(X, Z)</span>
<span id="cb11-56">    </span>
<span id="cb11-57">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2단계 Loss 계산</span></span>
<span id="cb11-58">    loss2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> second_stage_loss_fn(</span>
<span id="cb11-59">        treatment_net<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>treatment_net,</span>
<span id="cb11-60">        outcome_net<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>outcome_net, </span>
<span id="cb11-61">        pi<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pi, </span>
<span id="cb11-62">        mu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>mu, </span>
<span id="cb11-63">        sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sigma, </span>
<span id="cb11-64">        x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>X, </span>
<span id="cb11-65">        y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Y, </span>
<span id="cb11-66">        num_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span> </span>
<span id="cb11-67">    )</span>
<span id="cb11-68">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Optimization</span></span>
<span id="cb11-69">    opt2.zero_grad()</span>
<span id="cb11-70">    loss2.backward()</span>
<span id="cb11-71">    opt2.step()</span>
<span id="cb11-72"></span>
<span id="cb11-73">    </span>
<span id="cb11-74">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (epoch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb11-75">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"[Stage 2] Epoch [</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>epoch<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>epochs_stage2<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">] | Loss: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>loss2<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb11-76">   </span>
<span id="cb11-77"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Deep IV Training Complete."</span>)</span></code></pre></div></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Starting Stage 1 Training (Epochs: 1000)...
[Stage 1] Epoch [100/1000] | Loss: 1.2246 | Avg Sigma: 0.7426
[Stage 1] Epoch [200/1000] | Loss: 0.8651 | Avg Sigma: 0.6943
[Stage 1] Epoch [300/1000] | Loss: 0.4267 | Avg Sigma: 0.5430
[Stage 1] Epoch [400/1000] | Loss: 0.0645 | Avg Sigma: 0.3683
[Stage 1] Epoch [500/1000] | Loss: -0.1064 | Avg Sigma: 0.2715
[Stage 1] Epoch [600/1000] | Loss: -0.4534 | Avg Sigma: 0.1886
[Stage 1] Epoch [700/1000] | Loss: -0.7542 | Avg Sigma: 0.1364
[Stage 1] Epoch [800/1000] | Loss: -0.9869 | Avg Sigma: 0.1000
[Stage 1] Epoch [900/1000] | Loss: -1.2780 | Avg Sigma: 0.0781
[Stage 1] Epoch [1000/1000] | Loss: -1.1258 | Avg Sigma: 0.0643
Stage 1 Freezed.

Starting Stage 2 Training (Epochs: 1000)...
[Stage 2] Epoch [100/1000] | Loss: 0.1575
[Stage 2] Epoch [200/1000] | Loss: 0.0995
[Stage 2] Epoch [300/1000] | Loss: 0.0867
[Stage 2] Epoch [400/1000] | Loss: 0.0775
[Stage 2] Epoch [500/1000] | Loss: 0.0773
[Stage 2] Epoch [600/1000] | Loss: 0.0631
[Stage 2] Epoch [700/1000] | Loss: 0.0811
[Stage 2] Epoch [800/1000] | Loss: 0.0609
[Stage 2] Epoch [900/1000] | Loss: 0.0585
[Stage 2] Epoch [1000/1000] | Loss: 0.0580
Deep IV Training Complete.</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="result-visualization" class="level2">
<h2 class="anchored" data-anchor-id="result-visualization">Result Visualization</h2>
<ul>
<li>학습된 모델이 실제 인과 효과 곡선(Ground Truth)을 얼마나 잘 복원했는지 확인합니다.</li>
<li>테스트는 <strong>성수기와 비성수기의 중간(<img src="https://latex.codecogs.com/png.latex?X=0.5">)</strong> 조건을 가정합니다.</li>
</ul>
<div id="cell-visualization" class="cell" data-execution_count="11">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ===========================================================</span></span>
<span id="cb13-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. 테스트 데이터 생성</span></span>
<span id="cb13-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ===========================================================</span></span>
<span id="cb13-4">p_min, p_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> P_data.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(), P_data.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>()</span>
<span id="cb13-5">p_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(p_min, p_max, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>).reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb13-6"></span>
<span id="cb13-7">fixed_x_val <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span></span>
<span id="cb13-8">x_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.full_like(p_test, fixed_x_val)</span>
<span id="cb13-9"></span>
<span id="cb13-10"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> true_structural_function(p_val, x_val):</span>
<span id="cb13-11">    threshold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">35</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x_val)</span>
<span id="cb13-12">    base_effect <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">150</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> np.exp(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (p_val <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> threshold)))</span>
<span id="cb13-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> base_effect <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x_val)</span>
<span id="cb13-14">        </span>
<span id="cb13-15">true_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> true_structural_function(p_test, x_test)</span>
<span id="cb13-16"></span>
<span id="cb13-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ===========================================================</span></span>
<span id="cb13-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. Linear 2SLS 예측</span></span>
<span id="cb13-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ===========================================================</span></span>
<span id="cb13-20">px_test_linear <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.concatenate((p_test, x_test), axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb13-21">linear_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> stage2_model.predict(px_test_linear)</span>
<span id="cb13-22"></span>
<span id="cb13-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ===========================================================</span></span>
<span id="cb13-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. DeepIV 예측</span></span>
<span id="cb13-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ===========================================================</span></span>
<span id="cb13-26">outcome_net.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span>
<span id="cb13-27"></span>
<span id="cb13-28">p_test_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler_p.transform(p_test)</span>
<span id="cb13-29">x_test_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler_x.transform(x_test)</span>
<span id="cb13-30">p_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(p_test_scaled, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float32)</span>
<span id="cb13-31">x_tensor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(x_test_scaled, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float32)</span>
<span id="cb13-32"></span>
<span id="cb13-33"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb13-34">    y_pred_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> outcome_net(p_tensor, x_tensor)    </span>
<span id="cb13-35">    deep_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler_y.inverse_transform(y_pred_scaled.numpy())</span>
<span id="cb13-36"></span>
<span id="cb13-37"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ===========================================================</span></span>
<span id="cb13-38"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 4. 최종 시각화</span></span>
<span id="cb13-39"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ===========================================================</span></span>
<span id="cb13-40">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>))</span>
<span id="cb13-41"></span>
<span id="cb13-42"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 배경: 관측 데이터</span></span>
<span id="cb13-43">plt.scatter(P_data, Y_data, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gray'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Observed Data'</span>)</span>
<span id="cb13-44"></span>
<span id="cb13-45"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. Ground Truth (검은 실선)</span></span>
<span id="cb13-46">plt.plot(p_test, true_y, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k-'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Ground Truth'</span>)</span>
<span id="cb13-47"></span>
<span id="cb13-48"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. Linear 2SLS (빨간 점선)</span></span>
<span id="cb13-49">plt.plot(p_test, linear_pred, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r--'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Linear 2SLS'</span>)</span>
<span id="cb13-50"></span>
<span id="cb13-51"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. Deep IV (파란 실선)</span></span>
<span id="cb13-52">plt.plot(p_test, deep_pred, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'b-'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Deep IV'</span>)</span>
<span id="cb13-53"></span>
<span id="cb13-54">plt.title(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Causal Effect Estimation: Non-linear Pricing (at Seasonality X=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>fixed_x_val<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">)"</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>, weight<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bold'</span>)</span>
<span id="cb13-55">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Treatment: Ticket Price (P)"</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">13</span>)</span>
<span id="cb13-56">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Outcome: Sales (Y)"</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">13</span>)</span>
<span id="cb13-57">plt.legend(fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'upper right'</span>, framealpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>)</span>
<span id="cb13-58">plt.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>)</span>
<span id="cb13-59">plt.tight_layout()</span>
<span id="cb13-60">plt.show()</span></code></pre></div></div>
</details>
<div class="cell-output cell-output-display">
<div id="visualization" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L13/causal-inference-13-part-03/index_files/figure-html/visualization-output-1.png" width="1138" height="755" class="figure-img"></p>
<figcaption>Comparison of Causal Effect Estimation</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<ul>
<li>결과 그래프에서 볼 수 있듯이:
<ul>
<li><ol type="1">
<li><strong>Linear 2SLS</strong>는 데이터의 비선형성을 무시하고 단순한 직선으로 효과를 추정하여, 가격 임계값 근처에서의 급격한 수요 변화를 포착하지 못합니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Deep IV</strong>는 실제 인과 곡선(Ground Truth)인 S자 형태를 매우 정확하게 복원해냈습니다.</li>
</ol></li>
</ul></li>
<li>이는 비선형성이 강하게 의심될 때, 딥러닝 기반의 인과추론 방법론이 강력한 대안이 될 수 있음을 시사합니다.</li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L13/causal-inference-13-part-03/</guid>
  <pubDate>Sat, 17 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.1)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-01-Classification-wiht-Adaptive-Prediction-Sets/</link>
  <description><![CDATA[ 





<section id="introduction-why-adaptive" class="level1">
<h1>Introduction: Why Adaptive?</h1>
<ul>
<li><p>이전 포스트(Section 1)에서 다룬 기본적인 Conformal Prediction 방법은 단순하고 강력하지만 한 가지 단점이 있습니다.</p></li>
<li><p>기존 방식(Naive method)은 단순히 <img src="https://latex.codecogs.com/png.latex?1%20-%20%5Chat%7Bf%7D(x)_y">를 점수로 사용하기 때문에, 모든 클래스에 대해 고정된 임계값(Threshold)을 적용하는 경향이 있습니다.</p></li>
<li><p>이로 인해 다음과 같은 문제가 발생합니다:</p>
<ul>
<li><ol type="1">
<li><strong>Hard Inputs (어려운 이미지)</strong>: 모델이 헷갈려하는 경우에도 예측 집합이 충분히 커지지 않아 정답을 놓칠 수 있습니다 (Under-coverage).</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Easy Inputs (쉬운 이미지)</strong>: 모델이 확신하는 경우에도 예측 집합이 불필요하게 클 수 있습니다 (Over-coverage).</li>
</ol></li>
</ul></li>
<li><p>우리는 입력 이미지의 난이도에 따라 <strong>어려우면 집합을 크게, 쉬우면 집합을 작게</strong> 만드는 <strong>Adaptive Prediction Sets (APS)</strong> 기법을 도입하여 이 문제를 해결할 것입니다.</p></li>
</ul>
</section>
<section id="the-intuition-water-filling-approach" class="level1">
<h1>The Intuition: “Water-filling” Approach</h1>
<ul>
<li>APS의 핵심 아이디어는 직관적입니다.</li>
<li>만약 모델의 예측 확률 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bf%7D(x)">가 완벽하다면, 우리는 확률이 높은 클래스부터 순서대로 골라 담으면서 그 <strong>확률의 합(Cumulative Sum)이 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha"> (예: 90%)를 넘기는 순간</strong> 멈추면 됩니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bj=1%7D%5E%7Bk%7D%20%5Chat%7Bf%7D(x)_%7B%5Cpi_j(x)%7D%20%5Cge%201%20-%20%5Calpha%0A"></p>
<ul>
<li><p>여기서 <img src="https://latex.codecogs.com/png.latex?%5Cpi(x)">는 확률이 높은 순서대로 정렬된 클래스의 순열(Permutation)입니다.</p></li>
<li><p>이 방식은 “컵에 물(확률)을 <img src="https://latex.codecogs.com/png.latex?90%5C%25">가 찰 때까지 붓는 것”과 유사합니다.</p></li>
<li><p><strong>쉬운 문제</strong>: 확률 분포가 뾰족(Peaked)하므로, 1~2개만 담아도 금방 <img src="https://latex.codecogs.com/png.latex?90%5C%25">가 찹니다. <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> <strong>Small Set</strong></p></li>
<li><p><strong>어려운 문제</strong>: 확률 분포가 평평(Flat)하므로, 여러 개를 담아야 <img src="https://latex.codecogs.com/png.latex?90%5C%25">가 찹니다. <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> <strong>Large Set</strong></p></li>
<li><p>하지만 실제 모델의 확률 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bf%7D(x)">는 완벽하지 않으므로(Overconfident/Underconfident), 단순히 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha">에서 끊으면 커버리지를 보장할 수 없습니다.</p></li>
<li><p>따라서 <strong>Conformal Prediction을 사용하여 이 “멈추는 지점(Threshold)”을 보정</strong>해야 합니다.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-01-Classification-wiht-Adaptive-Prediction-Sets/images/figure4_aps_visualization.png" class="img-fluid figure-img"></p>
<figcaption>Figure 4: Adaptive Prediction Sets (APS) 알고리즘의 시각화. 확률이 높은 클래스(Fox squirrel, Gray fox…)부터 순서대로 누적 합을 구하고, 그 합이 보정된 분위수(Quantile)를 넘을 때까지 클래스를 포함시킨다.</figcaption>
</figure>
</div>
</section>
<section id="mathematical-formulation" class="level1">
<h1>Mathematical Formulation</h1>
<ul>
<li>이제 이를 수학적으로 엄밀하게 정의해보겠습니다.</li>
</ul>
<section id="defining-the-score-function" class="level2">
<h2 class="anchored" data-anchor-id="defining-the-score-function">1. Defining the Score Function</h2>
<ul>
<li><p>APS를 위한 Score Function <img src="https://latex.codecogs.com/png.latex?s(x,%20y)">는 <strong>“정답 클래스 <img src="https://latex.codecogs.com/png.latex?y">를 포함시키기 위해, 확률 상위 몇 번째 클래스까지 내려가야 하는가?”</strong>를 누적 확률로 나타냅니다.</p></li>
<li><p>먼저, 입력 <img src="https://latex.codecogs.com/png.latex?x">에 대해 모델이 예측한 확률을 내림차순으로 정렬하는 순열 함수 <img src="https://latex.codecogs.com/png.latex?%5Cpi(x)">를 정의합니다. <img src="https://latex.codecogs.com/png.latex?%20%5Chat%7Bf%7D(x)_%7B%5Cpi_1(x)%7D%20%5Cge%20%5Chat%7Bf%7D(x)_%7B%5Cpi_2(x)%7D%20%5Cge%20%5Cdots%20%5Cge%20%5Chat%7Bf%7D(x)_%7B%5Cpi_K(x)%7D%20"></p></li>
<li><p>이때, 정답 클래스 <img src="https://latex.codecogs.com/png.latex?y">가 정렬된 순서상 <img src="https://latex.codecogs.com/png.latex?k">번째에 위치한다고 가정합시다 (<img src="https://latex.codecogs.com/png.latex?y%20=%20%5Cpi_k(x)">).</p></li>
<li><p>Score <img src="https://latex.codecogs.com/png.latex?s(x,%20y)">는 <img src="https://latex.codecogs.com/png.latex?y">까지의 누적 확률 질량(Cumulative Probability Mass)으로 정의됩니다:</p></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0As(x,y)%20=%20%5Csum_%7Bj=1%7D%5E%7Bk%7D%20%5Chat%7Bf%7D(x)_%7B%5Cpi_j(x)%7D%0A"></p>
<ul>
<li><strong>의미</strong>: “모델이 가장 가능성 높다고 생각하는 것부터 정답 <img src="https://latex.codecogs.com/png.latex?y">가 나올 때까지 확률을 다 더한 값”입니다.
<ul>
<li>만약 모델이 정답을 1순위로 예측했다면, <img src="https://latex.codecogs.com/png.latex?s(x,y)">는 작을 것입니다.</li>
<li>만약 모델이 정답을 하위권으로 예측했다면, <img src="https://latex.codecogs.com/png.latex?s(x,y)">는 1에 가까워질 것입니다.</li>
</ul></li>
</ul>
</section>
<section id="calibration-finding-hatq" class="level2">
<h2 class="anchored" data-anchor-id="calibration-finding-hatq">2. Calibration (Finding <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">)</h2>
<ul>
<li>이제 Calibration 데이터셋 <img src="https://latex.codecogs.com/png.latex?(X_1,%20Y_1),%20%5Cdots,%20(X_n,%20Y_n)">에 대해 위 점수들을 계산합니다.</li>
<li>그리고 다음 식을 만족하는 분위수(Quantile) <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">를 찾습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7Bq%7D%20=%20%5Ctext%7BQuantile%7D%5Cleft(%20%5Cfrac%7B%5Clceil%20(n+1)(1-%5Calpha)%20%5Crceil%7D%7Bn%7D%20;%20%5C%7Bs_1,%20%5Cdots,%20s_n%5C%7D%20%5Cright)%0A"></p>
<ul>
<li>이 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">는 “정답을 포함하기 위해 누적 확률을 어디까지 허용해야 하는가?”에 대한 통계적 임계값입니다.</li>
</ul>
</section>
<section id="constructing-the-prediction-set" class="level2">
<h2 class="anchored" data-anchor-id="constructing-the-prediction-set">3. Constructing the Prediction Set</h2>
<ul>
<li>새로운 테스트 데이터 <img src="https://latex.codecogs.com/png.latex?X_%7Btest%7D">에 대해 예측 집합 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BC%7D(X_%7Btest%7D)">는 누적 확률이 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">를 넘어서는 지점까지의 모든 클래스를 포함하여 구성됩니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BC%7D(x)%20=%20%5C%7B%20%5Cpi_1(x),%20%5Cdots,%20%5Cpi_k(x)%20%5C%7D%0A"></p>
<ul>
<li>여기서 <img src="https://latex.codecogs.com/png.latex?k">는 다음을 만족하는 가장 작은 정수입니다: <img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bsup%7D%20%5Cleft%5C%7B%20k'%20:%20%5Csum_%7Bj=1%7D%5E%7Bk'%7D%20%5Chat%7Bf%7D(x)_%7B%5Cpi_j(x)%7D%20%3C%20%5Chat%7Bq%7D%20%5Cright%5C%7D%20+%201%0A"></li>
<li>즉, 누적 합이 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">를 초과하는 순간까지 포함합니다.</li>
</ul>
</section>
</section>
<section id="implementation-steps" class="level1">
<h1>Implementation Steps</h1>
<ul>
<li>Python 코드로 구현할 때의 핵심 로직은 다음과 같습니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-01-Classification-wiht-Adaptive-Prediction-Sets/images/figure5_aps_python_code.png" class="img-fluid figure-img"></p>
<figcaption>Figure 5: Adaptive Prediction Sets 구현을 위한 Python 코드 예시. <code>argsort</code>를 통해 정렬하고 <code>cumsum</code>을 통해 누적 확률을 계산하는 과정이 포함되어 있다.</figcaption>
</figure>
</div>
<ol type="1">
<li><strong>Softmax &amp; Sort</strong>: 모델 출력값(Softmax)을 구하고 <code>argsort</code>를 이용해 내림차순 정렬합니다.</li>
<li><strong>Cumulative Sum</strong>: 정렬된 확률값들의 누적 합(<code>cumsum</code>)을 계산합니다.</li>
<li><strong>Calculate Scores (Calibration)</strong>: 정답 라벨 위치에서의 누적 합을 가져와 <img src="https://latex.codecogs.com/png.latex?s_i">를 구하고, Quantile <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">를 계산합니다.</li>
<li><strong>Prediction (Test)</strong>: 테스트 데이터의 누적 합이 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">보다 작거나 같은 클래스들을 선택합니다. (엄밀하게는 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">를 넘는 첫 번째 클래스까지 포함해야 함)</li>
</ol>
</section>
<section id="summary" class="level1">
<h1>Summary</h1>
<ul>
<li><strong>Adaptive Prediction Sets (APS)</strong>는 불확실성을 더 지능적으로 다루는 방법입니다.</li>
<li>단순히 모델의 Softmax 값 하나만 보는 것이 아니라, <strong>전체 확률 분포의 형상(Shape)</strong>을 고려합니다.</li>
<li>그 결과, <strong>쉬운 샘플에는 작은 집합</strong>을, <strong>어려운 샘플에는 큰 집합</strong>을 할당하여 사용자가 모델의 신뢰도를 직관적으로 파악할 수 있게 해줍니다.</li>
<li>이 모든 과정에서도 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha">라는 통계적 커버리지는 엄격하게 보장됩니다.</li>
</ul>
<hr>
<p><strong>Next Step</strong>: 다음 포스트에서는 연속적인 값을 예측하는 회귀(Regression) 문제에서 불확실성 구간을 구하는 <strong>Conformalized Quantile Regression</strong>에 대해 알아보겠습니다.</p>


</section>

 ]]></description>
  <category>Paper Review</category>
  <guid>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-01-Classification-wiht-Adaptive-Prediction-Sets/</guid>
  <pubDate>Thu, 15 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.2)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-02-Conformalized-Quantile-Regression/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>Introduction</h1>
<ul>
<li><p>이전 포스트에서는 분류(Classification) 문제에 대한 Conformal Prediction을 다루었습니다.</p></li>
<li><p>이번에는 <strong>연속적인 값(Continuous Output)을 예측하는 회귀(Regression)</strong> 문제로 넘어가 보겠습니다.</p></li>
<li><p>회귀 문제에서 우리의 목표는 입력 <img src="https://latex.codecogs.com/png.latex?x">에 대해 단순히 하나의 예측값 <img src="https://latex.codecogs.com/png.latex?%5Chat%7By%7D">를 내놓는 것이 아니라, 정답 <img src="https://latex.codecogs.com/png.latex?y">가 포함될 확률이 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha"> (예: 90%)인 <strong>예측 구간(Prediction Interval)</strong>을 생성하는 것입니다.</p></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BC%7D(x)%20=%20%5B%5Ctext%7BLower%20Bound%7D,%20%5Ctext%7BUpper%20Bound%7D%5D%0A"></p>
<ul>
<li>이를 위해 가장 효과적인 베이스 모델 중 하나인 <strong>Quantile Regression</strong>을 사용하고, CP를 통해 이를 보정하는 <strong>Conformalized Quantile Regression (CQR)</strong> 기법을 알아보겠습니다.</li>
</ul>
</section>
<section id="base-model-quantile-regression" class="level1">
<h1>Base Model: Quantile Regression</h1>
<section id="concept" class="level2">
<h2 class="anchored" data-anchor-id="concept">Concept</h2>
<ul>
<li><p>일반적인 회귀 모델은 평균(Mean)을 예측(MSE Loss 사용)하지만, <strong>Quantile Regression</strong>은 조건부 분포의 특정 분위수(Quantile)를 예측합니다.</p></li>
<li><p>90%의 커버리지를 목표로 한다면, 우리는 양쪽 꼬리에서 5%씩을 제외한 구간을 알고 싶을 것입니다. 즉, 다음 두 가지 분위수를 학습합니다:</p>
<ul>
<li><strong>Lower Quantile</strong>: <img src="https://latex.codecogs.com/png.latex?%5Calpha/2%20=%200.05"> (5% 지점)</li>
<li><strong>Upper Quantile</strong>: <img src="https://latex.codecogs.com/png.latex?1%20-%20%5Calpha/2%20=%200.95"> (95% 지점)</li>
</ul></li>
<li><p>모델이 완벽하다면, 정답 <img src="https://latex.codecogs.com/png.latex?y">는 90%의 확률로 이 구간 <img src="https://latex.codecogs.com/png.latex?%5B%5Chat%7Bt%7D_%7B%5Calpha/2%7D(x),%20%5Chat%7Bt%7D_%7B1-%5Calpha/2%7D(x)%5D"> 사이에 존재해야 합니다.</p></li>
</ul>
</section>
<section id="quantile-loss-pinball-loss" class="level2">
<h2 class="anchored" data-anchor-id="quantile-loss-pinball-loss">Quantile Loss (Pinball Loss)</h2>
<ul>
<li>이러한 분위수를 학습하기 위해 <strong>Quantile Loss (Pinball Loss)</strong>를 사용합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AL_%7B%5Cgamma%7D(%5Chat%7Bt%7D_%7B%5Cgamma%7D,%20y)%20=%20(y%20-%20%5Chat%7Bt%7D_%7B%5Cgamma%7D)%5Cgamma%20%5Cmathbb%7B1%7D%5C%7By%20%3E%20%5Chat%7Bt%7D_%7B%5Cgamma%7D%5C%7D%20+%20(%5Chat%7Bt%7D_%7B%5Cgamma%7D%20-%20y)(1-%5Cgamma)%5Cmathbb%7B1%7D%5C%7By%20%5Cle%20%5Chat%7Bt%7D_%7B%5Cgamma%7D%5C%7D%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cgamma">: 타겟 분위수 (예: 0.05 또는 0.95)</li>
<li>이 손실 함수를 사용하여 뉴럴 네트워크 등 어떤 모델이든 특정 분위수를 예측하도록 학습시킬 수 있습니다.</li>
</ul>
</section>
</section>
<section id="the-problem-why-conformalize" class="level1">
<h1>The Problem: Why Conformalize?</h1>
<ul>
<li><p>Quantile Regression으로 구한 구간 <img src="https://latex.codecogs.com/png.latex?%5B%5Chat%7Bt%7D_%7B0.05%7D(x),%20%5Chat%7Bt%7D_%7B0.95%7D(x)%5D">는 꽤 훌륭한 불확실성 추정치입니다.</p></li>
<li><p>하지만 문제는 <strong>“Finite Sample”에서 90% 커버리지를 보장하지 못한다</strong>는 점입니다.</p></li>
<li><p>모델이 과적합(Overfitting)되거나 학습이 덜 되면, 실제 정답이 이 구간을 벗어나는 비율이 10%보다 훨씬 클 수도, 작을 수도 있습니다.</p></li>
<li><p>따라서 우리는 Conformal Prediction을 사용하여 이 구간을 <strong>보정(Calibrate)</strong>해야 합니다.</p></li>
</ul>
</section>
<section id="conformalized-quantile-regression-algorithm" class="level1">
<h1>Conformalized Quantile Regression Algorithm</h1>
<ul>
<li>CQR의 핵심 아이디어는 학습된 분위수 구간을 <strong><img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">만큼 늘리거나 줄여서</strong> 엄밀한 커버리지를 맞추는 것입니다.</li>
</ul>
<section id="step-1-define-score-function" class="level2">
<h2 class="anchored" data-anchor-id="step-1-define-score-function">Step 1: Define Score Function</h2>
<ul>
<li>Calibration 데이터 <img src="https://latex.codecogs.com/png.latex?(X_i,%20Y_i)">에 대해, 정답 <img src="https://latex.codecogs.com/png.latex?Y_i">가 학습된 구간 <img src="https://latex.codecogs.com/png.latex?%5B%5Chat%7Bt%7D_%7B%5Calpha/2%7D(X_i),%20%5Chat%7Bt%7D_%7B1-%5Calpha/2%7D(X_i)%5D"> 밖으로 얼마나 나갔는지를 측정하는 Score를 정의합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0As(x,%20y)%20=%20%5Cmax%20%5C%7B%20%5Chat%7Bt%7D_%7B%5Calpha/2%7D(x)%20-%20y,%20%5Cquad%20y%20-%20%5Chat%7Bt%7D_%7B1-%5Calpha/2%7D(x)%20%5C%7D%0A"></p>
<ul>
<li>이 식의 의미를 직관적으로 살펴봅시다:
<ul>
<li><strong>Case 1: <img src="https://latex.codecogs.com/png.latex?y">가 구간 안에 있을 때</strong>:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Chat%7Bt%7D_%7B%5Ctext%7Blower%7D%7D%20%3C%20y%20%3C%20%5Chat%7Bt%7D_%7B%5Ctext%7Bupper%7D%7D"> 이므로, 두 항 모두 음수가 됩니다.</li>
<li><img src="https://latex.codecogs.com/png.latex?s(x,%20y)%20%3C%200"> (즉, 안전함)</li>
</ul></li>
<li><strong>Case 2: <img src="https://latex.codecogs.com/png.latex?y">가 구간 밖(위쪽)에 있을 때</strong>:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?y%20%3E%20%5Chat%7Bt%7D_%7B%5Ctext%7Bupper%7D%7D"> 이므로 <img src="https://latex.codecogs.com/png.latex?y%20-%20%5Chat%7Bt%7D_%7B%5Ctext%7Bupper%7D%7D"> 가 양수가 됩니다.</li>
<li><img src="https://latex.codecogs.com/png.latex?s(x,%20y)%20%3E%200"> (즉, 위험함/에러)</li>
</ul></li>
</ul></li>
<li>즉, 점수 <img src="https://latex.codecogs.com/png.latex?s">가 클수록 정답이 예측 구간을 크게 벗어났음을 의미합니다.</li>
</ul>
</section>
<section id="step-2-calibration-get-hatq" class="level2">
<h2 class="anchored" data-anchor-id="step-2-calibration-get-hatq">Step 2: Calibration (Get <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">)</h2>
<ul>
<li>계산된 점수들 <img src="https://latex.codecogs.com/png.latex?s_1,%20%5Cdots,%20s_n">의 분포에서 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha"> 분위수 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">를 찾습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7Bq%7D%20=%20%5Ctext%7BQuantile%7D%5Cleft(%20%5Cfrac%7B%5Clceil%20(n+1)(1-%5Calpha)%20%5Crceil%7D%7Bn%7D%20;%20%5C%7Bs_1,%20%5Cdots,%20s_n%5C%7D%20%5Cright)%0A"></p>
<ul>
<li>만약 모델이 불확실성을 과소평가했다면(구간이 너무 좁으면), 많은 <img src="https://latex.codecogs.com/png.latex?y">가 구간 밖에 있을 것이고 <img src="https://latex.codecogs.com/png.latex?s">값들이 커져서 <strong>양수의 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D"></strong>가 나옵니다.</li>
<li>만약 모델이 불확실성을 과대평가했다면(구간이 너무 넓으면), <img src="https://latex.codecogs.com/png.latex?s">값들이 대부분 음수일 것이고 <strong>음수의 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D"></strong>가 나옵니다.</li>
</ul>
</section>
<section id="step-3-construct-prediction-interval" class="level2">
<h2 class="anchored" data-anchor-id="step-3-construct-prediction-interval">Step 3: Construct Prediction Interval</h2>
<ul>
<li>최종적으로 새로운 입력 <img src="https://latex.codecogs.com/png.latex?X_%7Btest%7D">에 대한 예측 구간을 생성할 때, 원래 구간을 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">만큼 조정합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BC%7D(X_%7Btest%7D)%20=%20%5B%5Chat%7Bt%7D_%7B%5Calpha/2%7D(X_%7Btest%7D)%20-%20%5Chat%7Bq%7D,%20%5Cquad%20%5Chat%7Bt%7D_%7B1-%5Calpha/2%7D(X_%7Btest%7D)%20+%20%5Chat%7Bq%7D%5D%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D%20%3E%200">: 원래 구간이 너무 좁았으므로, 양쪽으로 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">만큼 <strong>넓힙니다</strong>.</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D%20%3C%200">: 원래 구간이 너무 넓었으므로, 양쪽으로 <img src="https://latex.codecogs.com/png.latex?%7C%5Chat%7Bq%7D%7C">만큼 <strong>좁힙니다</strong>.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-02-Conformalized-Quantile-Regression/images/figure6_cqr_visualization.png" class="img-fluid figure-img"></p>
<figcaption>Figure 6: CQR 알고리즘의 시각화. 원래의 Quantile Regression 구간(파란색 영역)을 Calibration을 통해 얻은 상수 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">만큼 확장하거나 축소하여 최종 Prediction Set을 생성한다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="implementation" class="level1">
<h1>Implementation</h1>
<p>Python으로 CQR을 구현하는 것은 매우 간단합니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-02-Conformalized-Quantile-Regression/images/figure7_cqr_python_code.png" class="img-fluid figure-img"></p>
<figcaption>Figure 7: Conformalized Quantile Regression 구현을 위한 Python 코드. Score를 계산하고 Quantile을 구하여 최종 구간을 조정하는 과정이 몇 줄의 코드로 구현된다.</figcaption>
</figure>
</div>
<ul>
<li><ol type="1">
<li><strong>Get Scores</strong>: Calibration 데이터에 대해 <code>max(lower - y, y - upper)</code>를 계산합니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Get Quantile</strong>: 위 점수들의 <img src="https://latex.codecogs.com/png.latex?(1-%5Calpha)"> 분위수 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">를 계산합니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Deploy</strong>: 새로운 데이터의 Lower/Upper 예측값에 각각 <img src="https://latex.codecogs.com/png.latex?-%5Chat%7Bq%7D,%20+%5Chat%7Bq%7D">를 더해줍니다.</li>
</ol></li>
</ul>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<ul>
<li><p><strong>Conformalized Quantile Regression (CQR)</strong>은 회귀 문제에서 가장 널리 사용되는 최신 기법 중 하나입니다.</p></li>
<li><p><strong>Adaptivity</strong>: 입력값 <img src="https://latex.codecogs.com/png.latex?x">에 따라 구간의 길이(불확실성 크기)가 달라지는 Quantile Regression의 장점을 그대로 가집니다. (어려운 입력은 구간이 넓고, 쉬운 입력은 구간이 좁음)</p></li>
<li><p><strong>Validity</strong>: Conformal Prediction을 통해 통계적 커버리지를 엄밀하게 보장합니다.</p></li>
<li><p>이 방법은 단순한 MSE 기반 회귀보다 훨씬 풍부한 정보를 제공하며, 의료나 금융과 같이 리스크 관리가 중요한 분야에서 필수적인 도구입니다.</p></li>
</ul>
<hr>
<p><strong>Next Step</strong>: 다음 포스트에서는 회귀 문제에서 Quantile Regression을 사용하기 어려운 경우(예: 단순히 평균과 분산만 예측하는 경우)에 사용할 수 있는 <strong>Conformalizing Scalar Uncertainty Estimates</strong>에 대해 알아보겠습니다.</p>


</section>

 ]]></description>
  <category>Paper Review</category>
  <guid>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-02-Conformalized-Quantile-Regression/</guid>
  <pubDate>Thu, 15 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.3)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-03-Conformalizing-Scalar-Uncertainty-Estimates/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>Introduction</h1>
<ul>
<li><p>이전 포스트에서 다룬 <strong>Conformalized Quantile Regression (CQR)</strong>은 매우 강력하지만, 두 개의 Quantile을 학습시켜야 한다는 조건이 있습니다.</p></li>
<li><p>하지만 실무에서는 종종 <strong>평균(<img src="https://latex.codecogs.com/png.latex?%5Cmu">)과 분산(<img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2">)</strong>만을 예측하는 더 단순한 모델을 사용하거나, 혹은 모델 앙상블의 분산 등을 불확실성 지표로 삼기도 합니다.</p></li>
<li><p>이번 포스트에서는 이러한 <strong>단일 스칼라 불확실성 지표(Scalar Uncertainty Estimate)</strong>를 활용하여 통계적으로 유효한 예측 구간을 생성하는 방법을 알아봅니다.</p></li>
</ul>
</section>
<section id="heuristic-uncertainty-the-estimated-standard-deviation" class="level1">
<h1>Heuristic Uncertainty: The Estimated Standard Deviation</h1>
<p>가장 흔한 시나리오는 데이터가 정규분포(Gaussian)를 따른다고 가정하고 모델을 학습시키는 것입니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20Y%20%7C%20X%20=%20x%20%5Csim%20%5Cmathcal%7BN%7D(%5Cmu(x),%20%5Csigma(x))%20"></p>
<ul>
<li><p>딥러닝 프레임워크(PyTorch 등)에서는 <code>GaussianNLLLoss</code>와 같은 손실 함수를 제공하여, 모델이 평균 예측값 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bf%7D(x)">와 불확실성 예측값 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Csigma%7D(x)">를 동시에 학습하도록 돕습니다.</p></li>
<li><p>하지만 실제 데이터는 <strong>정규분포를 따르지 않는 경우가 대부분</strong>입니다.</p></li>
<li><p>따라서 모델이 예측한 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Csigma%7D(x)">를 그대로 사용하여 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bf%7D(x)%20%5Cpm%201.96%5Chat%7B%5Csigma%7D(x)">와 같은 구간을 만들면, 실제로는 95% 커버리지를 보장할 수 없습니다.</p></li>
<li><p>우리는 Conformal Prediction을 사용하여 이 부정확한(Heuristic) <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Csigma%7D(x)">를 <strong>보정(Calibrate)</strong>할 것입니다.</p></li>
</ul>
</section>
<section id="generalizing-uncertainty-scalars" class="level1">
<h1>Generalizing Uncertainty Scalars</h1>
<ul>
<li><p>이 방법은 비단 표준편차뿐만 아니라, <strong>“값이 클수록 불확실하다”</strong>는 의미를 가진 어떤 함수 <img src="https://latex.codecogs.com/png.latex?u(x)">에도 적용 가능합니다.</p></li>
<li><p>논문에서는 <img src="https://latex.codecogs.com/png.latex?u(x)">로 사용할 수 있는 다양한 예시를 제시합니다:</p>
<ul>
<li><ol type="1">
<li><strong>Residual Prediction</strong>: <img src="https://latex.codecogs.com/png.latex?%7Cy%20-%20%5Chat%7Bf%7D(x)%7C">를 예측하는 별도의 모델 학습.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Ensemble Variance</strong>: 여러 모델 예측값들의 분산 측정.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Dropout Variance</strong>: 추론 시 Dropout을 켜고 여러 번 예측했을 때의 분산.</li>
</ol></li>
<li><ol start="4" type="1">
<li><strong>Input Perturbation</strong>: 입력에 작은 노이즈를 주었을 때 출력의 변화량.</li>
</ol></li>
</ul></li>
<li><p>우리는 이 <img src="https://latex.codecogs.com/png.latex?u(x)">를 “불확실성의 크기(Magnitude)”로 간주하고, 이를 스케일링하는 방식(Multiplicative Correction)을 사용합니다.</p></li>
</ul>
</section>
<section id="the-algorithm" class="level1">
<h1>The Algorithm</h1>
<ul>
<li>알고리즘의 핵심은 <strong>“실제 에러가 불확실성 지표 <img src="https://latex.codecogs.com/png.latex?u(x)"> 대비 몇 배나 큰가?”</strong>를 측정하는 것입니다.</li>
</ul>
<section id="step-1-define-score-function" class="level2">
<h2 class="anchored" data-anchor-id="step-1-define-score-function">Step 1: Define Score Function</h2>
<ul>
<li>Calibration 데이터 <img src="https://latex.codecogs.com/png.latex?(X_i,%20Y_i)">에 대해 다음과 같은 Score를 정의합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0As(x,%20y)%20=%20%5Cfrac%7B%7Cy%20-%20%5Chat%7Bf%7D(x)%7C%7D%7Bu(x)%7D%0A"></p>
<ul>
<li><strong>분자 <img src="https://latex.codecogs.com/png.latex?%7Cy%20-%20%5Chat%7Bf%7D(x)%7C"></strong>: 실제 모델의 예측 오차(절대값)입니다.</li>
<li><strong>분모 <img src="https://latex.codecogs.com/png.latex?u(x)"></strong>: 모델이 스스로 추정한 불확실성입니다.</li>
<li><strong>의미</strong>: “모델이 예상한 불확실성 대비 실제 오차의 비율”입니다.
<ul>
<li>만약 모델이 불확실하다고 판단(<img src="https://latex.codecogs.com/png.latex?u(x)"> 큼)했는데 오차도 크다면, <img src="https://latex.codecogs.com/png.latex?s">는 적절한 값을 가집니다.</li>
<li>만약 모델이 확실하다고 판단(<img src="https://latex.codecogs.com/png.latex?u(x)"> 작음)했는데 오차가 크다면, <img src="https://latex.codecogs.com/png.latex?s">는 매우 커집니다 (Penalty).</li>
</ul></li>
</ul>
</section>
<section id="step-2-calibration-get-hatq" class="level2">
<h2 class="anchored" data-anchor-id="step-2-calibration-get-hatq">Step 2: Calibration (Get <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">)</h2>
<ul>
<li>계산된 점수들 <img src="https://latex.codecogs.com/png.latex?s_1,%20%5Cdots,%20s_n">에 대해 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha"> 분위수(Quantile) <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">를 구합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7Bq%7D%20=%20%5Ctext%7BQuantile%7D%5Cleft(%20%5Cfrac%7B%5Clceil%20(n+1)(1-%5Calpha)%20%5Crceil%7D%7Bn%7D%20;%20%5C%7Bs_1,%20%5Cdots,%20s_n%5C%7D%20%5Cright)%0A"></p>
<ul>
<li>여기서 구해진 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">는 <strong>“불확실성 지표 <img src="https://latex.codecogs.com/png.latex?u(x)">에 곱해야 할 보정 계수(Multiplier)”</strong> 역할을 합니다.</li>
</ul>
</section>
<section id="step-3-construct-prediction-interval" class="level2">
<h2 class="anchored" data-anchor-id="step-3-construct-prediction-interval">Step 3: Construct Prediction Interval</h2>
<ul>
<li>새로운 입력 <img src="https://latex.codecogs.com/png.latex?X_%7Btest%7D">에 대한 예측 구간은 중심 예측값 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bf%7D(x)">에서 불확실성 지표 <img src="https://latex.codecogs.com/png.latex?u(x)">의 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">배만큼 벌려준 구간이 됩니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BC%7D(x)%20=%20%5B%5Chat%7Bf%7D(x)%20-%20%5Chat%7Bq%7Du(x),%20%5Cquad%20%5Chat%7Bf%7D(x)%20+%20%5Chat%7Bq%7Du(x)%5D%0A"></p>
<section id="유도-과정-derivation-of-validity" class="level3">
<h3 class="anchored" data-anchor-id="유도-과정-derivation-of-validity">유도 과정 (Derivation of Validity)</h3>
<ul>
<li>이 구간이 왜 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha"> 커버리지를 보장하는지 살펴보겠습니다.</li>
</ul>
<ol type="1">
<li>Calibration 단계에서 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">를 구했으므로, 새로운 데이터에 대해 다음 확률이 성립합니다. <img src="https://latex.codecogs.com/png.latex?%20%5Cmathbb%7BP%7D%5Bs(X_%7Btest%7D,%20Y_%7Btest%7D)%20%5Cle%20%5Chat%7Bq%7D%5D%20%5Cge%201%20-%20%5Calpha%20"></li>
<li>Score <img src="https://latex.codecogs.com/png.latex?s">의 정의를 대입합니다. <img src="https://latex.codecogs.com/png.latex?%20%5Cmathbb%7BP%7D%5Cleft%5B%20%5Cfrac%7B%7CY_%7Btest%7D%20-%20%5Chat%7Bf%7D(X_%7Btest%7D)%7C%7D%7Bu(X_%7Btest%7D)%7D%20%5Cle%20%5Chat%7Bq%7D%20%5Cright%5D%20%5Cge%201%20-%20%5Calpha%20"></li>
<li>양변에 <img src="https://latex.codecogs.com/png.latex?u(X_%7Btest%7D)">를 곱합니다 (불확실성은 항상 양수이므로 부등호 유지). <img src="https://latex.codecogs.com/png.latex?%20%5Cmathbb%7BP%7D%5Cleft%5B%20%7CY_%7Btest%7D%20-%20%5Chat%7Bf%7D(X_%7Btest%7D)%7C%20%5Cle%20%5Chat%7Bq%7Du(X_%7Btest%7D)%20%5Cright%5D%20%5Cge%201%20-%20%5Calpha%20"></li>
<li>절대값을 풉니다. <img src="https://latex.codecogs.com/png.latex?%20%5Cmathbb%7BP%7D%5Cleft%5B%20-%5Chat%7Bq%7Du(X_%7Btest%7D)%20%5Cle%20Y_%7Btest%7D%20-%20%5Chat%7Bf%7D(X_%7Btest%7D)%20%5Cle%20%5Chat%7Bq%7Du(X_%7Btest%7D)%20%5Cright%5D%20%5Cge%201%20-%20%5Calpha%20"></li>
<li><img src="https://latex.codecogs.com/png.latex?Y_%7Btest%7D">에 대해 정리하면 최종 구간이 도출됩니다. <img src="https://latex.codecogs.com/png.latex?%20%5Cmathbb%7BP%7D%5Cleft%5B%20%5Chat%7Bf%7D(X_%7Btest%7D)%20-%20%5Chat%7Bq%7Du(X_%7Btest%7D)%20%5Cle%20Y_%7Btest%7D%20%5Cle%20%5Chat%7Bf%7D(X_%7Btest%7D)%20+%20%5Chat%7Bq%7Du(X_%7Btest%7D)%20%5Cright%5D%20%5Cge%201%20-%20%5Calpha%20"></li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-03-Conformalizing-Scalar-Uncertainty-Estimates/images/figure8_scalar_visualization.png" class="img-fluid figure-img"></p>
<figcaption>Figure 8: Uncertainty Scalar를 이용한 예측 구간 시각화. 중심 예측값 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bf%7D(x)">를 기준으로, 위아래로 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7Du(x)">만큼 벌어진 대칭적인 구간을 형성한다.</figcaption>
</figure>
</div>
</section>
</section>
</section>
<section id="implementation" class="level1">
<h1>Implementation</h1>
<ul>
<li>이 방법은 구현이 매우 간단하며, PyTorch 등의 라이브러리와 쉽게 결합됩니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-03-Conformalizing-Scalar-Uncertainty-Estimates/images/figure9_scalar_python_code.png" class="img-fluid figure-img"></p>
<figcaption>Figure 9: Conformalized Uncertainty Scalars 구현을 위한 Python 코드. Score를 계산할 때 예측된 표준편차(model output의 두 번째 컬럼)로 나누어주는 것이 핵심이다.</figcaption>
</figure>
</div>
<ol type="1">
<li><strong>Get Scores</strong>: 에러의 절대값을 예측된 표준편차(또는 불확실성 지표)로 나눕니다.</li>
<li><strong>Get Quantile</strong>: 점수들의 분위수 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">를 계산합니다.</li>
<li><strong>Deploy</strong>: 예측값 <img src="https://latex.codecogs.com/png.latex?%5Cpm%20(%5Ctext%7B%EB%B6%88%ED%99%95%EC%8B%A4%EC%84%B1%7D%20%5Ctimes%20%5Chat%7Bq%7D)">를 통해 구간을 생성합니다.</li>
</ol>
</section>
<section id="discussion" class="level1">
<h1>Discussion</h1>
<ul>
<li>이 방법은 <strong>Symmetric(대칭적)</strong>인 구간을 생성한다는 특징이 있습니다.
<ul>
<li><strong>장점</strong>: 구현이 쉽고 직관적입니다. 이미 학습된 모델(Gaussian Output 등)을 그대로 재활용하기 좋습니다.</li>
<li><strong>단점</strong>: CQR과 달리 구간이 항상 예측값을 중심으로 대칭입니다. 실제 데이터 분포가 비대칭(Skewed)이라면 효율적이지 않을 수 있습니다. 또한, <img src="https://latex.codecogs.com/png.latex?u(x)">가 실제 분위수와 비례하지 않는다면 CQR보다 성능(구간의 평균 길이 등)이 떨어질 수 있습니다.</li>
</ul></li>
<li>따라서 가능하다면 <strong>Quantile Regression (CQR)</strong>을 사용하는 것이 더 좋지만, 상황이 여의치 않거나 빠른 배포가 필요할 때 이 방법은 훌륭한 대안이 됩니다.</li>
</ul>
<hr>
<p><strong>Next Step</strong>: 지금까지는 Black-box 모델의 불확실성을 다루었습니다. 다음 포스트에서는 이 기법들이 실제 복잡한 문제(Computer Vision 등)에서 어떻게 확장되는지 살펴보겠습니다.</p>


</section>

 ]]></description>
  <category>Paper Review</category>
  <guid>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-03-Conformalizing-Scalar-Uncertainty-Estimates/</guid>
  <pubDate>Thu, 15 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.4)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-04-Conformalizing-Bayes/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>Introduction</h1>
<ul>
<li><p>Bayesian Neural Network와 같은 베이지안 모델들은 불확실성 정량화(Uncertainty Quantification) 분야에서 매우 매력적인 도구입니다.</p></li>
<li><p>이들은 사전 지식(Prior)을 반영할 수 있고, 예측의 결과물로 단일 값이 아닌 분포(Posterior Predictive Density)를 제공하기 때문입니다.</p></li>
<li><p>하지만 베이지안 모델에는 치명적인 약점이 있습니다.</p></li>
<li><p><strong>“모델의 가정(Prior, Likelihood function 등)이 완벽하게 맞아야만”</strong> 예측된 불확실성이 정확하다는 점입니다.</p></li>
<li><p>현실의 복잡한 데이터에서 이러한 가정이 완벽히 들어맞기는 어렵습니다.</p></li>
<li><p><strong>Conformalizing Bayes</strong>는 베이지안 모델의 정보량을 그대로 활용하되, <strong>Conformal Prediction을 통해 “가정이 틀렸더라도” 통계적 커버리지를 보장</strong>하는 강력한 방법론입니다.</p></li>
</ul>
</section>
<section id="the-bayesian-ideal-vs.-reality" class="level1">
<h1>The Bayesian Ideal vs.&nbsp;Reality</h1>
<section id="ideal-scenario" class="level2">
<h2 class="anchored" data-anchor-id="ideal-scenario">Ideal Scenario</h2>
<ul>
<li>만약 우리가 만든 베이지안 모델 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bf%7D(y%7Cx)"> (입력 <img src="https://latex.codecogs.com/png.latex?x">가 주어졌을 때 <img src="https://latex.codecogs.com/png.latex?y">의 사후 확률 밀도)가 완벽하다면, 최적의 예측 집합 <img src="https://latex.codecogs.com/png.latex?S(x)">는 단순히 밀도 함수(Density)가 높은 영역을 잘라내어 만들 수 있습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AS(x)%20=%20%5C%7B%20y%20:%20%5Chat%7Bf%7D(y%7Cx)%20%3E%20t%20%5C%7D%0A"></p>
<ul>
<li>여기서 임계값 <img src="https://latex.codecogs.com/png.latex?t">는 해당 영역의 적분값이 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha">가 되도록 설정합니다. <img src="https://latex.codecogs.com/png.latex?%5Cint_%7By%20%5Cin%20S(x)%7D%20%5Chat%7Bf%7D(y%7Cx)%20dy%20=%201-%5Calpha"></li>
<li>이를 <strong>Highest Posterior Density (HPD) Region</strong>이라고도 합니다.</li>
</ul>
</section>
<section id="reality" class="level2">
<h2 class="anchored" data-anchor-id="reality">Reality</h2>
<ul>
<li><p>하지만 우리는 모델 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bf%7D">가 완벽하다고 보장할 수 없습니다.</p></li>
<li><p>따라서 위 방식으로 구한 집합은 실제로는 90%를 커버하지 못할 수도(Under-coverage), 너무 넓을 수도(Over-coverage) 있습니다.</p></li>
<li><p>우리는 베이지안 모델의 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bf%7D(y%7Cx)">를 <strong>“진짜 확률”이 아니라 “유용한 불확실성 점수(Heuristic Score)”로 간주</strong>하고, CP를 적용하여 올바른 임계값(Threshold)을 찾을 것입니다.</p></li>
</ul>
</section>
</section>
<section id="the-algorithm" class="level1">
<h1>The Algorithm</h1>
<ul>
<li>Conformalizing Bayes의 절차는 우리가 익숙한 CP의 흐름을 그대로 따릅니다.</li>
</ul>
<section id="step-1-define-score-function" class="level2">
<h2 class="anchored" data-anchor-id="step-1-define-score-function">Step 1: Define Score Function</h2>
<ul>
<li>우리는 모델이 예측한 <strong>사후 확률 밀도(Posterior Predictive Density)</strong>가 높을수록 에러가 작다(확실하다)고 봅니다.</li>
<li>Conformal Score는 “불확실한 정도”를 나타내야 하므로, 밀도 함수의 <strong>음수(Negative)</strong>를 취합니다. <img src="https://latex.codecogs.com/png.latex?%0As(x,%20y)%20=%20-%20%5Chat%7Bf%7D(y%7Cx)%0A">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Chat%7Bf%7D(y%7Cx)">가 높음 (모델이 정답을 확신함) <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> Score <img src="https://latex.codecogs.com/png.latex?s">는 매우 작은 음수.</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Chat%7Bf%7D(y%7Cx)">가 낮음 (모델이 정답을 예측 못함) <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> Score <img src="https://latex.codecogs.com/png.latex?s">는 큰 값(0에 가까운 값 혹은 양수).</li>
</ul></li>
</ul>
</section>
<section id="step-2-calibration-finding-hatq" class="level2">
<h2 class="anchored" data-anchor-id="step-2-calibration-finding-hatq">Step 2: Calibration (Finding <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">)</h2>
<ul>
<li>Calibration 데이터 <img src="https://latex.codecogs.com/png.latex?(X_1,%20Y_1),%20%5Cdots,%20(X_n,%20Y_n)">에 대해 점수들을 계산하고, <img src="https://latex.codecogs.com/png.latex?1-%5Calpha"> 분위수 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">를 찾습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7Bq%7D%20=%20%5Ctext%7BQuantile%7D%5Cleft(%20%5Cfrac%7B%5Clceil%20(n+1)(1-%5Calpha)%20%5Crceil%7D%7Bn%7D%20;%20%5C%7Bs_1,%20%5Cdots,%20s_n%5C%7D%20%5Cright)%0A"></p>
<ul>
<li>여기서 구한 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">는 <strong>“밀도 함수를 어디서 잘라야(Thresholding) 하는가?”</strong>에 대한 보정된 기준선이 됩니다.</li>
</ul>
</section>
<section id="step-3-construct-prediction-set" class="level2">
<h2 class="anchored" data-anchor-id="step-3-construct-prediction-set">Step 3: Construct Prediction Set</h2>
<ul>
<li>새로운 입력 <img src="https://latex.codecogs.com/png.latex?X_%7Btest%7D">에 대해, Score가 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D"> 이하인(즉, 밀도가 <img src="https://latex.codecogs.com/png.latex?-%5Chat%7Bq%7D"> 이상인) 모든 <img src="https://latex.codecogs.com/png.latex?y">를 포함합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BC%7D(x)%20=%20%5C%7B%20y%20:%20s(x,%20y)%20%5Cle%20%5Chat%7Bq%7D%20%5C%7D%20=%20%5C%7B%20y%20:%20-%5Chat%7Bf%7D(y%7Cx)%20%5Cle%20%5Chat%7Bq%7D%20%5C%7D%0A"></p>
<ul>
<li>이를 정리하면 최종 예측 집합은 다음과 같습니다:</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BC%7D(x)%20=%20%5C%7B%20y%20:%20%5Chat%7Bf%7D(y%7Cx)%20%5Cge%20-%5Chat%7Bq%7D%20%5C%7D%0A"></p>
<ul>
<li>즉, <strong>보정된 임계값 <img src="https://latex.codecogs.com/png.latex?-%5Chat%7Bq%7D">보다 확률 밀도가 높은 모든 <img src="https://latex.codecogs.com/png.latex?y">의 집합(Superlevel Set)</strong>을 구성합니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-04-Conformalizing-Bayes/images/bayes_visualization.png" class="img-fluid figure-img"></p>
<figcaption>Figure 10: Conformalized Bayes 알고리즘 시각화. 사후 확률 밀도 함수(Posterior Predictive Density) <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bf%7D(y%7Cx)">를 Conformal Prediction으로 구한 임계값 <img src="https://latex.codecogs.com/png.latex?-%5Chat%7Bq%7D">에서 잘라(Slicing), 그 위의 영역을 예측 집합으로 삼는다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="mathematical-derivation-validity" class="level1">
<h1>Mathematical Derivation &amp; Validity</h1>
<ul>
<li><p>이 집합이 왜 유효한지(Valid) 수학적으로 살펴보겠습니다.</p></li>
<li><ol type="1">
<li><strong>Calibration Guarantee</strong>:</li>
</ol>
<ul>
<li>Calibration 단계에서 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">를 구했으므로, 새로운 i.i.d. 샘플에 대해 다음이 성립합니다. <img src="https://latex.codecogs.com/png.latex?%20%5Cmathbb%7BP%7D%5Bs(X_%7Btest%7D,%20Y_%7Btest%7D)%20%5Cle%20%5Chat%7Bq%7D%5D%20%5Cge%201%20-%20%5Calpha%20"></li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Substitution</strong>:</li>
</ol>
<ul>
<li>Score의 정의 <img src="https://latex.codecogs.com/png.latex?s(x,y)%20=%20-%5Chat%7Bf%7D(y%7Cx)">를 대입합니다. <img src="https://latex.codecogs.com/png.latex?%20%5Cmathbb%7BP%7D%5B-%5Chat%7Bf%7D(Y_%7Btest%7D%20%7C%20X_%7Btest%7D)%20%5Cle%20%5Chat%7Bq%7D%5D%20%5Cge%201%20-%20%5Calpha%20"></li>
</ul></li>
<li><ol start="3" type="1">
<li><strong>Inequality Rearrangement</strong>:</li>
</ol>
<ul>
<li>부등식의 양변에 -1을 곱하여 부등호 방향을 바꿉니다. <img src="https://latex.codecogs.com/png.latex?%20%5Cmathbb%7BP%7D%5B%5Chat%7Bf%7D(Y_%7Btest%7D%20%7C%20X_%7Btest%7D)%20%5Cge%20-%5Chat%7Bq%7D%5D%20%5Cge%201%20-%20%5Calpha%20"></li>
</ul></li>
</ul>
<p><em>4. <strong>Conclusion</strong>: </em> 따라서, 예측 집합 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BC%7D(X_%7Btest%7D)%20=%20%5C%7B%20y%20:%20%5Chat%7Bf%7D(y%7CX_%7Btest%7D)%20%5Cge%20-%5Chat%7Bq%7D%20%5C%7D">는 정답 <img src="https://latex.codecogs.com/png.latex?Y_%7Btest%7D">를 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha"> 확률로 포함합니다.</p>
</section>
<section id="why-is-this-useful-bayes-optimality" class="level1">
<h1>Why is this useful? (Bayes Optimality)</h1>
<ul>
<li><p>이 방법은 단순히 유효할(Valid) 뿐만 아니라, 특정 조건 하에서 <strong>효율적(Efficient)</strong>입니다.</p></li>
<li><p>논문에 따르면, 만약 원래의 베이지안 모델이 (비록 틀렸을지라도) 어느 정도 합리적이라면, 이 방법으로 생성된 예측 집합은 <strong><img src="https://latex.codecogs.com/png.latex?1-%5Calpha"> 커버리지를 만족하는 모든 예측 집합 중에서 평균 크기(Average Size)가 가장 작습니다 (Bayes Optimal).</strong></p></li>
<li><p>이는 Neyman-Pearson Lemma와 유사한 논리로, “가장 확률 밀도가 높은 곳부터 담는 것”이 주어진 확률 질량을 채우면서 집합의 크기(Volume)를 최소화하는 전략이기 때문입니다.</p></li>
</ul>
</section>
<section id="summary" class="level1">
<h1>Summary</h1>
<ul>
<li><strong>Conformalizing Bayes</strong>는 베이지안 모델의 확률 밀도 함수를 Score로 사용하여 CP를 적용하는 기법입니다.</li>
<li>결과적으로 <strong>“Superlevel Set of Density”</strong> 형태의 예측 집합을 얻게 됩니다.</li>
<li>이 방법은 베이지안 모델의 가정이 틀려도 <strong>Coverage를 보장</strong>하며, 동시에 베이지안 모델의 정보량을 활용하여 <strong>집합의 크기를 최적화</strong>할 수 있습니다.</li>
</ul>
<hr>
<p><strong>Next Step</strong>: 지금까지 Section 2를 통해 Classification, Regression, Bayesian Model 등 다양한 환경에서의 CP 적용법을 배웠습니다. 다음 포스트에서는 이러한 CP 알고리즘들이 제대로 작동하는지 검증하는 <strong>Section 3. Evaluating Conformal Prediction</strong>에 대해 다루겠습니다.</p>


</section>

 ]]></description>
  <category>Paper Review</category>
  <guid>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-02-Examples-of-Conformal-Procedures/Part-02-04-Conformalizing-Bayes/</guid>
  <pubDate>Thu, 15 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 3.1)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-01-Evaluating-Adaptivity/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>Introduction</h1>
<ul>
<li><p>지금까지 우리는 Conformal Prediction(CP)을 통해 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha">의 커버리지를 보장하는 예측 집합을 만드는 법을 배웠습니다.</p></li>
<li><p>하지만 <strong>“평균적으로 90% 정답을 포함한다(Marginal Coverage)”</strong>는 사실만으로는 충분하지 않습니다.</p></li>
<li><p>예를 들어, 어떤 의사가 쉬운 환자에게는 100% 정확한 진단을 내리지만, 어려운 희귀병 환자에게는 0%의 정확도를 보인다면 어떨까요?</p></li>
<li><p>전체 평균으로는 90% 정확도일지 몰라도, 이는 좋은 시스템이라 할 수 없습니다.</p></li>
<li><p>좋은 CP 알고리즘은 <strong>쉬운 입력에는 작은 집합(Small Sets)</strong>을, <strong>어려운 입력에는 큰 집합(Large Sets)</strong>을 출력해야 합니다. 이를 <strong>Adaptivity(적응성)</strong>라고 합니다.</p></li>
<li><p>이번 포스트에서는 내 모델이 얼마나 “적응적(Adaptive)”인지 평가하는 구체적인 지표들을 알아봅니다.</p></li>
</ul>
</section>
<section id="metric-1-set-size-distribution" class="level1">
<h1>Metric 1: Set Size Distribution</h1>
<ul>
<li>가장 먼저 확인해야 할 지표는 예측 집합 크기(Set Size)의 분포입니다.</li>
<li>단순히 평균 크기만 보는 것이 아니라, <strong>히스토그램</strong>을 그려봐야 합니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-01-Evaluating-Adaptivity/images/set_size_histogram.png" class="img-fluid figure-img"></p>
<figcaption>Placeholder: Histogram of Set Sizes. X축은 집합의 크기, Y축은 빈도수를 나타낸다. 분포가 넓게 퍼져 있을수록 다양한 난이도의 입력을 잘 구별하고 있다는 의미이다.</figcaption>
</figure>
</div>
<ul>
<li><ol type="1">
<li><strong>Average Set Size</strong>:</li>
</ol>
<ul>
<li>작을수록 좋습니다. (단, <img src="https://latex.codecogs.com/png.latex?1-%5Calpha"> 커버리지를 만족하는 전제하에)</li>
<li>평균이 너무 크다면? <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> 모델 성능이 나쁘거나, Score Function이 효율적이지 않음을 의미합니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Spread of Set Sizes</strong>:</li>
</ol>
<ul>
<li>분포가 넓을수록(Dynamic Range가 클수록) 좋습니다.</li>
<li>분포가 넓다는 것은 모델이 “확실한 것(크기 1)”과 “불확실한 것(크기 5 이상)”을 잘 구분하고 있다는 뜻입니다.</li>
</ul></li>
</ul>
</section>
<section id="metric-2-conditional-coverage" class="level1">
<h1>Metric 2: Conditional Coverage</h1>
<ul>
<li>우리가 궁극적으로 원하는 것은 모든 개별 입력 <img src="https://latex.codecogs.com/png.latex?X">에 대해 커버리지를 보장하는 <strong>Conditional Coverage</strong>입니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D%5BY_%7Btest%7D%20%5Cin%20%5Cmathcal%7BC%7D(X_%7Btest%7D)%20%7C%20X_%7Btest%7D%5D%20%5Cge%201%20-%20%5Calpha%0A"></p>
<ul>
<li>하지만 현실적으로 모든 <img src="https://latex.codecogs.com/png.latex?X">값 하나하나에 대해 이를 검증하는 것은 불가능합니다(Impossible in general case).</li>
<li>대신 우리는 데이터를 의미 있는 <strong>그룹(Group)</strong>으로 나누어, 각 그룹별로 커버리지가 잘 지켜지는지 확인해야 합니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-01-Evaluating-Adaptivity/images/conditional_coverage.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Marginal Coverage vs Conditional Coverage 비교. (좌측) 커버리지가 지켜지지 않음. (중앙) Marginal Coverage는 만족하지만 특정 그룹(Group 2)에서 에러가 집중됨. (우측) Conditional Coverage는 모든 그룹에서 고르게 에러가 분산됨.</figcaption>
</figure>
</div>
<ul>
<li>위 그림의 중앙(Marginal) 케이스를 봅시다.
<ul>
<li><strong>Group 1 (Easy)</strong>: 100% 커버리지 (과잉)</li>
<li><strong>Group 2 (Hard)</strong>: 80% 커버리지 (부족)</li>
<li><strong>전체 평균</strong>: 90% 커버리지 (만족)</li>
</ul></li>
<li>이런 경우 “Marginal Coverage는 만족하지만, Conditional Coverage는 실패했다”고 합니다.</li>
<li>이를 잡아내기 위해 다음 두 가지 지표를 사용합니다.</li>
</ul>
<section id="feature-stratified-coverage-fsc" class="level2">
<h2 class="anchored" data-anchor-id="feature-stratified-coverage-fsc">2.1 Feature-stratified Coverage (FSC)</h2>
<ul>
<li><p>데이터의 특성(Feature)에 따라 그룹을 나누어 커버리지를 측정하는 방법입니다.</p></li>
<li><p>예를 들어 인종(Race), 나이대(Age), 혹은 이미지의 밝기 등으로 데이터를 그룹화(<img src="https://latex.codecogs.com/png.latex?g=1,%20%5Cdots,%20G">)합니다.</p></li>
<li><p>각 그룹 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BI%7D_g">에 속한 데이터들의 커버리지를 계산하고, <strong>가장 성능이 안 좋은 그룹(Minimum Coverage)</strong>을 찾습니다.</p></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BFSC%20metric%7D%20=%20%5Cmin_%7Bg%20%5Cin%20%5C%7B1,%20%5Cdots,%20G%5C%7D%7D%20%5Cfrac%7B1%7D%7B%7C%5Cmathcal%7BI%7D_g%7C%7D%20%5Csum_%7Bi%20%5Cin%20%5Cmathcal%7BI%7D_g%7D%20%5Cmathbb%7BI%7D%5C%7B%20Y_i%20%5Cin%20%5Cmathcal%7BC%7D(X_i)%20%5C%7D%0A"></p>
<ul>
<li>만약 완벽한 Conditional Coverage라면, 이 값은 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha">에 근접해야 합니다.</li>
<li>이 값이 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha">보다 현저히 낮다면, 특정 그룹(예: 야간 주행 이미지)에서 모델이 실패하고 있음을 의미합니다.</li>
</ul>
</section>
<section id="size-stratified-coverage-ssc" class="level2">
<h2 class="anchored" data-anchor-id="size-stratified-coverage-ssc">2.2 Size-stratified Coverage (SSC)</h2>
<ul>
<li>하지만 어떤 Feature가 중요한지 모를 때는 어떻게 할까요?</li>
<li>이때 사용할 수 있는 아주 일반적이고 강력한 방법이 <strong>“예측 집합의 크기”</strong>로 그룹을 나누는 것입니다.
<ul>
<li>그룹 1: 집합 크기가 1인 데이터들 (<img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BC%7D(x)%7C%20=%201">)</li>
<li>그룹 2: 집합 크기가 2인 데이터들</li>
<li>…</li>
</ul></li>
<li>모델이 “이건 정말 어려워서 후보를 10개나 뽑았어”라고 말한 경우(집합 크기 10), 실제로도 그 안에 정답이 90% 확률로 들어 있어야 합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BSSC%20metric%7D%20=%20%5Cmin_%7Bg%20%5Cin%20%5C%7B%20%5Ctext%7Bset%20sizes%7D%20%5C%7D%7D%20%5Cfrac%7B1%7D%7B%7C%5Cmathcal%7BI%7D_g%7C%7D%20%5Csum_%7Bi%20%5Cin%20%5Cmathcal%7BI%7D_g%7D%20%5Cmathbb%7BI%7D%5C%7B%20Y_i%20%5Cin%20%5Cmathcal%7BC%7D(X_i)%20%5C%7D%0A"></p>
<ul>
<li>이 지표는 사용자가 사전에 그룹을 정의할 필요가 없으므로(Feature-agnostic), 어떤 상황에서도 바로 적용해볼 수 있는 훌륭한 진단 도구입니다.</li>
</ul>
</section>
</section>
<section id="summary" class="level1">
<h1>Summary</h1>
<ul>
<li>Conformal Prediction을 평가할 때는 단순히 전체 커버리지만 보지 말고, 다음을 꼭 확인해야합니다:
<ul>
<li><ol type="1">
<li><strong>Histogram of Set Sizes</strong>: 쉬운 건 작게, 어려운 건 크게 잘 구분하고 있는가?</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Stratified Coverage (FSC / SSC)</strong>: 특정 그룹(인종, 나이, 혹은 모델이 불확실해하는 그룹)에서만 커버리지가 깨지고 있지는 않은가?</li>
</ol></li>
</ul></li>
<li>이러한 <strong>Adaptivity</strong> 체크는 실험실 환경을 넘어 실제 서비스(Production)에 CP를 적용할 때 “Non-negotiable(타협할 수 없는)” 필수 검증 단계입니다.</li>
</ul>
<hr>
<p><strong>Next Step</strong>: 다음 포스트에서는 이러한 평가 지표들을 실제로 계산할 때 필요한 데이터셋 크기(Calibration Set Size)와 통계적 검증 방법에 대해 알아보겠습니다.</p>


</section>

 ]]></description>
  <category>Paper Review</category>
  <guid>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-01-Evaluating-Adaptivity/</guid>
  <pubDate>Thu, 15 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 3.2)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-02-The-Effect-of-the-Size-of-the-Calibration-Set/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>Introduction</h1>
<ul>
<li>Conformal Prediction(CP)을 실제 서비스에 배포할 때, 엔지니어가 가장 먼저 마주하는 실무적인 질문은 이것입니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>“Calibration Set(<img src="https://latex.codecogs.com/png.latex?n">)의 크기는 얼마나 커야 할까요? 100개면 충분한가요, 아니면 1,000개가 필요한가요?”</strong></p>
</blockquote>
<ul>
<li><p>이론적으로 CP의 커버리지 보장(<img src="https://latex.codecogs.com/png.latex?1-%5Calpha">)은 <img src="https://latex.codecogs.com/png.latex?n">의 크기와 상관없이 성립합니다(Finite-sample guarantee).</p></li>
<li><p>하지만 직관적으로 생각했을 때, 데이터가 많을수록 더 안정적일 것이라 예상할 수 있습니다.</p></li>
<li><p>이번 포스트에서는 <strong>Calibration Set의 크기 <img src="https://latex.codecogs.com/png.latex?n">이 예측 구간의 안정성(Stability)에 미치는 영향</strong>을 수학적으로 분석하고, 실무적인 가이드라인(<img src="https://latex.codecogs.com/png.latex?n%20%5Capprox%201000">)을 제시합니다.</p></li>
</ul>
</section>
<section id="validity-vs.-stability" class="level1">
<h1>Validity vs.&nbsp;Stability</h1>
<section id="the-theoretical-guarantee-validity" class="level2">
<h2 class="anchored" data-anchor-id="the-theoretical-guarantee-validity">The Theoretical Guarantee (Validity)</h2>
<ul>
<li>놀랍게도, CP의 커버리지 보장 정리(Theorem 1)는 <strong>모든 <img src="https://latex.codecogs.com/png.latex?n">에 대해 성립</strong>합니다.</li>
<li>Calibration 데이터가 단 10개뿐이라도, 새로운 데이터에 대한 평균 커버리지는 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha">를 만족합니다.</li>
</ul>
</section>
<section id="the-catch-stability" class="level2">
<h2 class="anchored" data-anchor-id="the-catch-stability">The Catch (Stability)</h2>
<ul>
<li><p>하지만 여기에는 중요한 디테일이 숨어 있습니다.</p></li>
<li><p>우리가 보장하는 것은 <strong>“Calibration Set을 무한히 새로 뽑았을 때의 평균”</strong>입니다.</p></li>
<li><p>하지만 현실에서 우리는 <strong>단 하나의 고정된 Calibration Set</strong>을 사용합니다.</p></li>
<li><p>만약 우리가 운이 나빠서 이상한(Bias된) 데이터가 섞인 Calibration Set을 뽑았다면 어떨까요?</p></li>
<li><p>이 고정된 데이터셋으로 학습된 CP 모델을 무한한 테스트 데이터에 적용했을 때의 실제 커버리지는 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha">와 정확히 일치하지 않을 수 있습니다.</p></li>
<li><p>즉, <strong>Calibration Set 자체의 무작위성(Randomness)</strong> 때문에 실제 커버리지는 <strong>확률 변수(Random Quantity)</strong>가 됩니다.</p></li>
</ul>
</section>
</section>
<section id="mathematical-derivation-beta-distribution" class="level1">
<h1>Mathematical Derivation: Beta Distribution</h1>
<ul>
<li>Vladimir Vovk는 고정된 Calibration Set이 주어졌을 때, 무한한 검증 데이터에 대한 커버리지 확률 분포가 <strong>베타 분포(Beta Distribution)</strong>를 따른다는 것을 증명했습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D(Y_%7Btest%7D%20%5Cin%20%5Cmathcal%7BC%7D(X_%7Btest%7D)%20%5Cmid%20%5C%7B(X_i,%20Y_i)%5C%7D_%7Bi=1%7D%5En)%20%5Csim%20%5Ctext%7BBeta%7D(n+1-l,%20l)%0A"></p>
<ul>
<li>여기서 파라미터 <img src="https://latex.codecogs.com/png.latex?l">은 다음과 같이 정의됩니다: <img src="https://latex.codecogs.com/png.latex?%0Al%20=%20%5Clfloor%20(n+1)%5Calpha%20%5Crfloor%0A">
<ul>
<li><strong>의미</strong>: 이 식은 <img src="https://latex.codecogs.com/png.latex?n">이 커질수록 커버리지 확률 분포가 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha">를 중심으로 얼마나 뾰족하게(Sharp) 모이는지를 설명합니다.</li>
<li><strong>평균</strong>: 베타 분포의 성질에 의해 이 분포의 기댓값은 정확히 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha">가 됩니다 (Validity).</li>
<li><strong>분산</strong>: <img src="https://latex.codecogs.com/png.latex?n">이 작을수록 분산이 커져서, 실제 커버리지가 목표치 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha">에서 크게 벗어날 확률이 높아집니다.</li>
</ul></li>
</ul>
</section>
<section id="visualizing-the-effect-of-n" class="level1">
<h1>Visualizing the Effect of <img src="https://latex.codecogs.com/png.latex?n"></h1>
<ul>
<li>이 현상을 시각적으로 확인해보겠습니다.</li>
<li>아래 그래프는 Calibration Set의 크기 <img src="https://latex.codecogs.com/png.latex?n">에 따른 커버리지 확률의 밀도 함수를 보여줍니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-02-The-Effect-of-the-Size-of-the-Calibration-Set/images/coverage_distribution.png" class="img-fluid figure-img"></p>
<figcaption>Figure: 무한한 Validation Set에 대한 커버리지 분포. <img src="https://latex.codecogs.com/png.latex?n">이 100일 때는 분포가 넓게 퍼져 있지만, <img src="https://latex.codecogs.com/png.latex?n">이 10,000일 때는 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha(0.9)"> 근처에 매우 좁게 집중된다. 분포는 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BO%7D(n%5E%7B-1/2%7D)">의 속도로 수렴한다.</figcaption>
</figure>
</div>
<ul>
<li><strong><img src="https://latex.codecogs.com/png.latex?n=100"> (파란색)</strong>: 그래프가 넓게 퍼져 있습니다. 운이 나쁘면 실제 커버리지가 85%나 95%가 될 수도 있습니다.</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?n=1,000"> (주황색)</strong>: 그래프가 훨씬 좁아졌습니다. 대부분의 경우 커버리지가 <strong>88% ~ 92%</strong> 사이로 유지됩니다.</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?n=10,000"> (초록색)</strong>: 매우 뾰족합니다. 거의 정확하게 90%를 맞춥니다.</li>
</ul>
</section>
<section id="practical-guideline-the-n1000-rule" class="level1">
<h1>Practical Guideline: The “n=1000” Rule</h1>
<ul>
<li>그렇다면 실무에서는 몇 개를 써야 할까요?</li>
<li>논문에서는 <strong><img src="https://latex.codecogs.com/png.latex?n=1000"> 정도면 대부분의 목적에 충분하다</strong>고 제안합니다.
<ul>
<li><ol type="1">
<li><strong>안정성 확보</strong>: 위 그래프에서 보듯이, <img src="https://latex.codecogs.com/png.latex?n=1000">일 때 커버리지는 목표치(<img src="https://latex.codecogs.com/png.latex?1-%5Calpha">)에서 <img src="https://latex.codecogs.com/png.latex?%5Cpm%202%5C%25"> 내외의 오차 범위를 가집니다. 이는 대부분의 머신러닝 애플리케이션에서 허용 가능한 수준입니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>비용 효율성</strong>: 데이터를 10,000개까지 늘려도 얻을 수 있는 이득(오차 감소)은 크지 않습니다. (수렴 속도가 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BO%7D(n%5E%7B-1/2%7D)">로 느려지기 때문)</li>
</ol></li>
</ul></li>
</ul>
<section id="required-sample-size-calculation" class="level2">
<h2 class="anchored" data-anchor-id="required-sample-size-calculation">Required Sample Size Calculation</h2>
<ul>
<li>만약 더 엄격한 기준(예: 99% 확률로 오차 1% 이내)이 필요하다면, 다음 표를 참고하여 필요한 <img src="https://latex.codecogs.com/png.latex?n">을 역산할 수 있습니다.</li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">허용 오차 (<img src="https://latex.codecogs.com/png.latex?%5Cepsilon">)</th>
<th style="text-align: left;">필요한 <img src="https://latex.codecogs.com/png.latex?n"> (신뢰도 90%)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0.1 (10%)</td>
<td style="text-align: left;">22</td>
</tr>
<tr class="even">
<td style="text-align: left;">0.05 (5%)</td>
<td style="text-align: left;">102</td>
</tr>
<tr class="odd">
<td style="text-align: left;">0.01 (1%)</td>
<td style="text-align: left;">2,491</td>
</tr>
<tr class="even">
<td style="text-align: left;">0.005 (0.5%)</td>
<td style="text-align: left;">9,812</td>
</tr>
</tbody>
</table>
<ul>
<li>일반적인 기준인 90% 신뢰도(<img src="https://latex.codecogs.com/png.latex?%5Cdelta=0.1">)에서 목표 커버리지와의 오차를 1%(<img src="https://latex.codecogs.com/png.latex?%5Cepsilon=0.01">) 이내로 줄이려면 약 <strong>2,500개</strong>의 데이터가 필요합니다.</li>
<li>하지만 5% 오차(<img src="https://latex.codecogs.com/png.latex?%5Cepsilon=0.05">)를 허용한다면 <strong>102개</strong>로도 충분합니다.</li>
</ul>
</section>
</section>
<section id="summary" class="level1">
<h1>Summary</h1>
<ul>
<li>Conformal Prediction은 <img src="https://latex.codecogs.com/png.latex?n">이 작아도 평균적으로는 커버리지를 보장합니다.</li>
<li>하지만 <strong>개별 Calibration Set에 대한 신뢰도(Stability)</strong>를 높이기 위해서는 충분한 <img src="https://latex.codecogs.com/png.latex?n">이 필요합니다.</li>
<li><strong>Rule of Thumb</strong>: 약 <strong>1,000개</strong>의 Calibration 데이터를 사용하면, 실제 커버리지가 목표치에서 크게 벗어나지 않음(약 <img src="https://latex.codecogs.com/png.latex?%5Cpm%202%5C%25">)을 확신할 수 있습니다.</li>
</ul>
<hr>
<p><strong>Next Step</strong>: 이제 적절한 Calibration 데이터 크기도 알았으니, 실제로 우리가 구현한 CP 알고리즘이 올바른지 검증하는 구체적인 절차인 <strong>Section 3.3 Checking for Correct Coverage</strong>에 대해 알아보겠습니다.</p>


</section>

 ]]></description>
  <category>Paper Review</category>
  <guid>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-02-The-Effect-of-the-Size-of-the-Calibration-Set/</guid>
  <pubDate>Thu, 15 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 3.3)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-03-Checking-for-Correct-Coverage/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>Introduction</h1>
<ul>
<li><p>Conformal Prediction(CP)을 구현했다면, 가장 먼저 해야 할 일은 <strong>“이게 정말 작동하는가?”</strong>를 확인하는 것입니다.</p></li>
<li><p>즉, 우리가 설정한 목표 커버리지(예: 90%)가 실제 테스트 데이터에서도 지켜지는지 검증해야 합니다.</p></li>
<li><p>하지만 단순히 한 번의 테스트 셋 결과만 보고 “90.1%니까 성공!”이라고 단정 짓기는 어렵습니다.</p></li>
<li><p>데이터의 무작위성 때문에 우연히 잘 나왔을 수도, 우연히 못 나왔을 수도 있기 때문입니다.</p></li>
<li><p>따라서 우리는 <strong>여러 번의 실험(Trials)</strong>을 통해 커버리지 분포를 확인해야 합니다.</p></li>
</ul>
</section>
<section id="methodology-repeated-experiments" class="level1">
<h1>Methodology: Repeated Experiments</h1>
<ul>
<li>가장 확실한 검증 방법은 <img src="https://latex.codecogs.com/png.latex?R">번의 독립적인 실험을 수행하는 것입니다.</li>
<li>각 실험 <img src="https://latex.codecogs.com/png.latex?j=1,%20%5Cdots,%20R">마다 새로운 Calibration Set과 Validation Set을 준비하고, 다음 과정을 반복합니다:
<ul>
<li><ol type="1">
<li>Calibration 수행 <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D_j"> 계산</li>
</ol></li>
<li><ol start="2" type="1">
<li>Validation Set에 대해 예측 집합 구성 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BC%7D_j"></li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>경험적 커버리지(Empirical Coverage)</strong> <img src="https://latex.codecogs.com/png.latex?C_j"> 계산:</li>
</ol></li>
</ul></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AC_j%20=%20%5Cfrac%7B1%7D%7Bn_%7Bval%7D%7D%20%5Csum_%7Bi=1%7D%5E%7Bn_%7Bval%7D%7D%20%5Cmathbb%7BI%7D%20%5C%7B%20Y_%7Bi,j%7D%5E%7B(val)%7D%20%5Cin%20%5Cmathcal%7BC%7D_j(X_%7Bi,j%7D%5E%7B(val)%7D)%20%5C%7D%0A"></p>
<ul>
<li>이렇게 얻은 <img src="https://latex.codecogs.com/png.latex?R">개의 커버리지 값들 <img src="https://latex.codecogs.com/png.latex?C_1,%20%5Cdots,%20C_R">의 평균 <img src="https://latex.codecogs.com/png.latex?%5Coverline%7BC%7D">는 이론적으로 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha">에 매우 근접해야 합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Coverline%7BC%7D%20=%20%5Cfrac%7B1%7D%7BR%7D%20%5Csum_%7Bj=1%7D%5E%7BR%7D%20C_j%20%5Capprox%201%20-%20%5Calpha%0A"></p>
<ul>
<li>또한, <img src="https://latex.codecogs.com/png.latex?C_j">들의 히스토그램을 그렸을 때 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha">를 중심으로 종 모양(Bell-curve) 분포를 보여야 합니다.</li>
</ul>
</section>
<section id="the-practical-challenge-limited-data" class="level1">
<h1>The Practical Challenge: Limited Data</h1>
<ul>
<li><p>현실적인 문제는 <strong>“매번 새로운 데이터를 어디서 구하는가?”</strong>입니다.</p></li>
<li><p>우리가 가진 데이터는 유한(총 <img src="https://latex.codecogs.com/png.latex?n_%7Btotal%7D%20=%20n%20+%20n_%7Bval%7D">)하므로, <img src="https://latex.codecogs.com/png.latex?R">번이나 새로운 데이터를 수집할 수는 없습니다.</p></li>
<li><p>따라서 우리는 <strong>Resampling (Random Split)</strong> 방식을 사용합니다.</p></li>
<li><p>전체 데이터를 무작위로 섞어서 Calibration/Validation 셋으로 나누는 과정을 <img src="https://latex.codecogs.com/png.latex?R">번 반복하는 것입니다.</p></li>
</ul>
<section id="efficiency-trick-score-caching" class="level2">
<h2 class="anchored" data-anchor-id="efficiency-trick-score-caching">Efficiency Trick: Score Caching</h2>
<ul>
<li><p>하지만 <img src="https://latex.codecogs.com/png.latex?R">번(예: 100번)이나 모델을 다시 학습시키거나 추론(Inference)을 돌리는 것은 계산 비용이 매우 큽니다.</p></li>
<li><p>여기서 중요한 팁은 <strong>Conformal Score를 미리 계산해두는 것(Caching)</strong>입니다.</p></li>
<li><p>CP 알고리즘은 <strong>Score값(<img src="https://latex.codecogs.com/png.latex?s_i">)들의 순위</strong>에만 의존합니다.</p></li>
<li><p>데이터가 어느 셋(Calibration vs Validation)에 속하느냐에 따라 역할만 달라질 뿐, 각 데이터 포인트의 Score 값 자체는 변하지 않습니다.</p></li>
<li><p>따라서 다음과 같이 효율적으로 검증할 수 있습니다:</p>
<ul>
<li><ol type="1">
<li><strong>Pre-computation</strong>: 전체 데이터에 대해 Score를 미리 한 번만 계산합니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Shuffle &amp; Split</strong>: 계산된 Score 배열만 무작위로 섞어서 나눕니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Evaluate</strong>: 나누어진 Score들로 Quantile을 구하고 커버리지를 계산합니다.</li>
</ol></li>
</ul></li>
<li><p>이 방식을 사용하면 딥러닝 모델을 매번 돌릴 필요가 없어 검증 속도가 수백 배 빨라집니다.</p></li>
</ul>
</section>
</section>
<section id="implementation" class="level1">
<h1>Implementation</h1>
<ul>
<li>Python 코드로 이를 구현하면 다음과 같습니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-03-Checking-for-Correct-Coverage/images/coverage_check_code.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Score Caching을 이용한 효율적인 커버리지 검증 코드. 전체 Score를 미리 계산해두고(<code>get_scores</code>), 반복문 안에서는 단순히 배열을 섞고(<code>shuffle</code>) 자르는 연산만 수행한다.</figcaption>
</figure>
</div>
<section id="code-explanation" class="level2">
<h2 class="anchored" data-anchor-id="code-explanation">Code Explanation</h2>
<ul>
<li><ol type="1">
<li><strong>Load/Compute Scores</strong>: <code>get_scores(X, Y)</code>를 통해 모든 데이터의 Score를 계산하고 저장합니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Loop <img src="https://latex.codecogs.com/png.latex?R"> times</strong>:</li>
</ol>
<ul>
<li><code>np.random.shuffle(scores)</code>: Score들을 섞습니다.</li>
<li><code>calib, val = scores[:n], scores[n:]</code>: <img src="https://latex.codecogs.com/png.latex?n">개는 Calibration용, 나머지는 검증용으로 나눕니다.</li>
<li><code>qhat</code>: Calibration Score들로 Quantile을 계산합니다.</li>
<li><code>mean()</code>: Validation Score들이 <code>qhat</code>보다 작은 비율(Coverage)을 계산합니다.</li>
</ul></li>
<li><ol start="3" type="1">
<li><strong>Check</strong>: <code>coverages.mean()</code>이 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha">와 비슷한지 확인하고, 히스토그램을 그립니다.</li>
</ol></li>
</ul>
</section>
</section>
<section id="interpretation-of-results" class="level1">
<h1>Interpretation of Results</h1>
<ul>
<li><p>검증 결과 커버리지가 정확히 90.00%가 나오지 않더라도 당황할 필요는 없습니다.</p></li>
<li><p><img src="https://latex.codecogs.com/png.latex?n"> (Calibration 크기), <img src="https://latex.codecogs.com/png.latex?n_%7Bval%7D"> (Validation 크기), <img src="https://latex.codecogs.com/png.latex?R"> (반복 횟수)이 모두 유한하기 때문에 <strong>약간의 변동(Benign Fluctuations)</strong>은 자연스러운 현상입니다.</p></li>
<li><p><strong>정상</strong>: 평균이 0.89 ~ 0.91 사이이며 히스토그램이 0.9 근처에 모여 있음.</p></li>
<li><p><strong>비정상</strong>: 평균이 0.80처럼 현저히 낮거나, 히스토그램이 한쪽으로 크게 치우침 <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> 구현 오류(버그) 혹은 데이터 분포의 문제(i.i.d. 위반 등)를 의심해야 합니다.</p></li>
<li><p>이 진단 과정을 통과했다면, 여러분의 Conformal Predictor는 통계적으로 신뢰할 수 있는 상태입니다.</p></li>
</ul>
<hr>
<p><strong>Next Step</strong>: 지금까지는 표준적인 환경에서의 CP를 다루었습니다. 다음 포스트부터는 <strong>Section 4. Extensions of Conformal Prediction</strong>으로 넘어가서, 데이터 불균형, 시계열, 분포 변화 등 더 복잡하고 현실적인 문제들을 해결하는 방법을 알아보겠습니다. 첫 번째로 <strong>Group-Balanced Conformal Prediction</strong>을 다룹니다.</p>


</section>

 ]]></description>
  <category>Paper Review</category>
  <guid>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-03-Evaluating-Conformal-Prediction/Part-03-03-Checking-for-Correct-Coverage/</guid>
  <pubDate>Thu, 15 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.1)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-01-Group-Balanced-Conformal-Prediction/</link>
  <description><![CDATA[ 





<section id="introduction-the-fairness-problem" class="level1">
<h1>Introduction: The Fairness Problem</h1>
<ul>
<li><p>지금까지 우리는 전체 데이터셋에 대해 평균적으로 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha">의 커버리지를 보장하는 방법(Marginal Coverage)을 배웠습니다.</p></li>
<li><p>하지만 현실 세계, 특히 의료나 금융 같은 민감한 분야에서는 “평균적인 성공”만으로는 충분하지 않습니다.</p></li>
<li><p>예를 들어, 어떤 질병 진단 AI가 백인 환자에게는 99%의 정확도를 보이지만, 유색 인종 환자에게는 80%의 정확도밖에 보이지 않는다고 가정해봅시다.</p></li>
<li><p>이 경우 백인 환자가 다수라면 전체 평균 정확도는 90%를 넘길 수 있겠지만, 이는 <strong>공정하지 못한(Unfair)</strong> 시스템입니다.</p></li>
<li><p><strong>Group-Balanced Conformal Prediction</strong>은 이러한 문제를 해결하기 위해, 데이터 내의 특정 그룹(인종, 성별, 연령대 등) 각각에 대해 독립적으로 커버리지를 보장하는 기법입니다.</p></li>
</ul>
</section>
<section id="problem-formulation" class="level1">
<h1>Problem Formulation</h1>
<ul>
<li><p>우리의 입력 데이터 <img src="https://latex.codecogs.com/png.latex?X">의 첫 번째 특성(Feature) <img src="https://latex.codecogs.com/png.latex?X_%7Bi,1%7D">이 그룹을 나타내는 범주형 변수라고 가정해봅시다.</p></li>
<li><p>이 그룹은 <img src="https://latex.codecogs.com/png.latex?%5C%7B1,%20%5Cdots,%20G%5C%7D"> 중 하나의 값을 가집니다.</p></li>
<li><p>기존의 CP는 다음을 보장했습니다: <img src="https://latex.codecogs.com/png.latex?%20%5Cmathbb%7BP%7D(Y_%7Btest%7D%20%5Cin%20%5Cmathcal%7BC%7D(X_%7Btest%7D))%20%5Cge%201-%5Calpha%20"></p></li>
<li><p>하지만 우리가 원하는 것은 <strong>모든 그룹 <img src="https://latex.codecogs.com/png.latex?g">에 대해</strong> 다음이 성립하는 것입니다:</p></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D(Y_%7Btest%7D%20%5Cin%20%5Cmathcal%7BC%7D(X_%7Btest%7D)%20%5Cmid%20X_%7Btest,1%7D%20=%20g)%20%5Cge%201-%5Calpha,%20%5Cquad%20%5Cforall%20g%20%5Cin%20%5C%7B1,%20%5Cdots,%20G%5C%7D%0A"></p>
<ul>
<li>즉, 어떤 그룹에 속한 데이터가 들어오더라도 똑같이 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha"> 이상의 확률로 정답을 포함해야 합니다.</li>
</ul>
</section>
<section id="the-algorithm" class="level1">
<h1>The Algorithm</h1>
<ul>
<li>이 문제를 해결하는 방법은 직관적입니다. <strong>“그룹별로 따로따로 Conformal Prediction을 수행”</strong>하는 것입니다.</li>
</ul>
<section id="step-1-stratify-calibration-data" class="level2">
<h2 class="anchored" data-anchor-id="step-1-stratify-calibration-data">Step 1: Stratify Calibration Data</h2>
<ul>
<li>Calibration 데이터셋을 그룹별로 나눕니다.</li>
<li>그룹 <img src="https://latex.codecogs.com/png.latex?g">에 속하는 데이터들만 모아서 부분집합을 만듭니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AS%5E%7B(g)%7D%20=%20%5C%7B%20(X_j,%20Y_j)%20:%20X_%7Bj,1%7D%20=%20g%20%5C%7D%0A"></p>
</section>
<section id="step-2-calibrate-per-group" class="level2">
<h2 class="anchored" data-anchor-id="step-2-calibrate-per-group">Step 2: Calibrate per Group</h2>
<ul>
<li>각 그룹 <img src="https://latex.codecogs.com/png.latex?g">에 대해 독립적으로 Quantile <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D%5E%7B(g)%7D">를 계산합니다.</li>
<li><ol type="1">
<li>그룹 <img src="https://latex.codecogs.com/png.latex?g"> 데이터에 대한 Conformal Score들을 계산합니다: <img src="https://latex.codecogs.com/png.latex?s%5E%7B(g)%7D_1,%20%5Cdots,%20s%5E%7B(g)%7D_%7Bn%5E%7B(g)%7D%7D"></li>
</ol></li>
<li><ol start="2" type="1">
<li>해당 그룹의 데이터 개수 <img src="https://latex.codecogs.com/png.latex?n%5E%7B(g)%7D">를 기준으로 보정된 분위수를 구합니다: <img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7Bq%7D%5E%7B(g)%7D%20=%20%5Ctext%7BQuantile%7D%5Cleft(%20%5Cfrac%7B%5Clceil%20(n%5E%7B(g)%7D+1)(1-%5Calpha)%20%5Crceil%7D%7Bn%5E%7B(g)%7D%7D%20;%20%5C%7Bs%5E%7B(g)%7D_1,%20%5Cdots,%20s%5E%7B(g)%7D_%7Bn%5E%7B(g)%7D%7D%5C%7D%20%5Cright)%0A"></li>
</ol></li>
<li>결과적으로 우리는 그룹의 개수만큼 서로 다른 임계값(Threshold) <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D%5E%7B(1)%7D,%20%5Cdots,%20%5Chat%7Bq%7D%5E%7B(G)%7D">를 얻게 됩니다.
<ul>
<li>모델이 잘 맞추는 쉬운 그룹은 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">가 작을 것이고 (작은 예측 집합),</li>
<li>모델이 어려워하는 그룹은 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">가 클 것입니다 (큰 예측 집합).</li>
</ul></li>
</ul>
</section>
<section id="step-3-inference" class="level2">
<h2 class="anchored" data-anchor-id="step-3-inference">Step 3: Inference</h2>
<ul>
<li>새로운 테스트 데이터 <img src="https://latex.codecogs.com/png.latex?X_%7Btest%7D">가 들어오면, 먼저 이 데이터가 어느 그룹에 속하는지(<img src="https://latex.codecogs.com/png.latex?X_%7Btest,1%7D">) 확인합니다.</li>
<li>그리고 해당 그룹에 맞는 임계값 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D%5E%7B(X_%7Btest,1%7D)%7D">을 사용하여 예측 집합을 구성합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BC%7D(x)%20=%20%5C%7B%20y%20:%20s(x,%20y)%20%5Cle%20%5Chat%7Bq%7D%5E%7B(x_1)%7D%20%5C%7D%0A"></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-01-Group-Balanced-Conformal-Prediction/images/group_balanced_cp_visualization.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Group-Balanced Conformal Prediction의 개념도. 전체 데이터를 파란색 그룹과 초록색 그룹으로 나누고, 각각의 분포(Histogram)에서 별도의 Quantile <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D%5E%7B(1)%7D,%20%5Chat%7Bq%7D%5E%7B(2)%7D">를 계산하여 적용한다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="theoretical-guarantee" class="level1">
<h1>Theoretical Guarantee</h1>
<ul>
<li>이 방법은 Vovk에 의해 처음 제안되었으며, 다음의 명제에 의해 수학적으로 정당화됩니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Proposition 1 (Error control guarantee for group-balanced conformal prediction)</strong></p>
<p>데이터가 i.i.d. 가정하에 추출되었다면, 위 알고리즘을 통해 생성된 예측 집합 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BC%7D">는 모든 그룹 <img src="https://latex.codecogs.com/png.latex?g">에 대해 다음을 만족한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cmathbb%7BP%7D(Y_%7Btest%7D%20%5Cin%20%5Cmathcal%7BC%7D(X_%7Btest%7D)%20%5Cmid%20X_%7Btest,1%7D%20=%20g)%20%5Cge%201-%5Calpha%20"></p>
</blockquote>
<ul>
<li>이로써 우리는 인종, 성별 등 민감한 속성에 관계없이 모든 사용자에게 <strong>동등한 수준의 안전장치(Equal Coverage)</strong>를 제공할 수 있게 됩니다.</li>
</ul>
</section>
<section id="practical-note" class="level1">
<h1>Practical Note</h1>
<ul>
<li><strong>Explicit Groups</strong>: 인종, 성별처럼 데이터에 명시적으로 존재하는 카테고리를 사용할 수 있습니다.</li>
<li><strong>Constructed Groups (Binning)</strong>: 나이(Age)와 같은 연속형 변수라도, ‘20대’, ‘30대’ 등으로 구간화(Binning)하여 그룹을 만든 뒤 이 방법을 적용할 수 있습니다. 이를 통해 연속적인 특성에 대한 Conditional Coverage를 근사할 수 있습니다.</li>
</ul>
<hr>
<p><strong>Next Step</strong>: 그룹 정보가 입력(Input Feature)으로 주어지는 경우에는 위 방법을 쓰면 됩니다. 하지만, <strong>“실제 정답 클래스(Class)”별로 커버리지를 보장하고 싶다면</strong> 어떻게 해야 할까요? (예: 암 환자를 암이라고 맞출 확률과 정상인을 정상이라고 맞출 확률을 동시에 보장). 다음 포스트에서는 <strong>Section 4.2 Class-Conditional Conformal Prediction</strong>을 다루겠습니다.</p>


</section>

 ]]></description>
  <category>Paper Review</category>
  <guid>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-01-Group-Balanced-Conformal-Prediction/</guid>
  <pubDate>Thu, 15 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.2)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-02-Class-Conditional-Conformal-Prediction/</link>
  <description><![CDATA[ 





<section id="introduction-the-problem-with-imbalanced-classes" class="level1">
<h1>Introduction: The Problem with Imbalanced Classes</h1>
<ul>
<li><p>머신러닝 분류 문제, 특히 의료 진단과 같은 분야에서는 <strong>클래스 불균형(Class Imbalance)</strong>이 흔하게 발생합니다.</p></li>
<li><p>예를 들어, 암 진단 모델을 개발한다고 가정해봅시다.</p>
<ul>
<li><strong>정상(Normal)</strong>: 데이터의 95%</li>
<li><strong>암(Cancer)</strong>: 데이터의 5%</li>
</ul></li>
<li><p>우리가 일반적인 Conformal Prediction을 사용하여 95% 커버리지를 달성했다고 칩시다.</p></li>
<li><p>가장 쉬운 달성 방법은 무엇일까요?</p></li>
<li><p><strong>“그냥 모든 환자를 ’정상’이라고 예측하고, 암 환자는 다 틀리는 것”</strong>입니다.</p></li>
<li><p>이렇게 해도 (정상 95% + 암 0%) / 100% <img src="https://latex.codecogs.com/png.latex?%5Capprox"> 95% 커버리지는 달성됩니다.</p></li>
<li><p>하지만 이는 재앙입니다.</p></li>
<li><p>우리는 암 환자에 대해서도 똑같이 95%의 정확도로 정답을 포함시키기를 원합니다.</p></li>
<li><p><strong>Class-Conditional Conformal Prediction</strong>은 바로 이 문제, 즉 <strong>모든 정답 클래스(Ground Truth Class)</strong>에 대해 균등한 커버리지를 보장하기 위한 방법입니다.</p></li>
</ul>
</section>
<section id="problem-formulation" class="level1">
<h1>Problem Formulation</h1>
<ul>
<li>우리의 목표는 단순한 전체 평균(<img src="https://latex.codecogs.com/png.latex?1-%5Calpha">)이 아니라, <strong>각 클래스 <img src="https://latex.codecogs.com/png.latex?y%20%5Cin%20%5C%7B1,%20%5Cdots,%20K%5C%7D"> 별로</strong> 조건부 커버리지를 만족하는 것입니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D(Y_%7Btest%7D%20%5Cin%20%5Cmathcal%7BC%7D(X_%7Btest%7D)%20%5Cmid%20Y_%7Btest%7D%20=%20y)%20%5Cge%201-%5Calpha,%20%5Cquad%20%5Cforall%20y%20%5Cin%20%5C%7B1,%20%5Cdots,%20K%5C%7D%0A"></p>
<ul>
<li>이것이 보장된다면, “암 환자” 그룹 내에서도 정답이 예측 집합에 포함될 확률이 95% 이상이 되고, “정상인” 그룹 내에서도 마찬가지가 됩니다.</li>
</ul>
</section>
<section id="the-algorithm" class="level1">
<h1>The Algorithm</h1>
<ul>
<li>알고리즘은 Group-Balanced CP와 유사하게 <strong>“따로따로(Separately)”</strong> 전략을 취하지만, 추론(Inference) 단계에서 중요한 차이가 있습니다.</li>
</ul>
<section id="step-1-stratify-calibration-data-by-class" class="level2">
<h2 class="anchored" data-anchor-id="step-1-stratify-calibration-data-by-class">Step 1: Stratify Calibration Data by Class</h2>
<ul>
<li>Calibration 데이터셋을 실제 정답 클래스(Ground Truth Class)별로 나눕니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AS%5E%7B(k)%7D%20=%20%5C%7B%20(X_j,%20Y_j)%20:%20Y_j%20=%20k%20%5C%7D%0A"></p>
</section>
<section id="step-2-calibrate-per-class" class="level2">
<h2 class="anchored" data-anchor-id="step-2-calibrate-per-class">Step 2: Calibrate per Class</h2>
<ul>
<li>각 클래스 <img src="https://latex.codecogs.com/png.latex?k">에 대해 독립적으로 Quantile <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D%5E%7B(k)%7D">를 계산합니다.
<ul>
<li><ol type="1">
<li>클래스 <img src="https://latex.codecogs.com/png.latex?k">에 속하는 데이터들의 Score <img src="https://latex.codecogs.com/png.latex?s%5E%7B(k)%7D_1,%20%5Cdots,%20s%5E%7B(k)%7D_%7Bn%5E%7B(k)%7D%7D">를 모읍니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li>해당 클래스의 데이터 수 <img src="https://latex.codecogs.com/png.latex?n%5E%7B(k)%7D">를 기준으로 보정된 분위수를 구합니다: <img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7Bq%7D%5E%7B(k)%7D%20=%20%5Ctext%7BQuantile%7D%5Cleft(%20%5Cfrac%7B%5Clceil%20(n%5E%7B(k)%7D+1)(1-%5Calpha)%20%5Crceil%7D%7Bn%5E%7B(k)%7D%7D%20;%20%5C%7Bs%5E%7B(k)%7D_1,%20%5Cdots,%20s%5E%7B(k)%7D_%7Bn%5E%7B(k)%7D%7D%5C%7D%20%5Cright)%0A"></li>
</ol></li>
</ul></li>
<li>결과적으로 우리는 클래스 개수만큼의 임계값 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D%5E%7B(1)%7D,%20%5Cdots,%20%5Chat%7Bq%7D%5E%7B(K)%7D">를 얻습니다.
<ul>
<li>샘플이 적거나 모델이 어려워하는 클래스(예: 암)는 임계값이 높게(보수적으로) 설정될 것입니다.</li>
</ul></li>
</ul>
</section>
<section id="step-3-inference-iterative-check" class="level2">
<h2 class="anchored" data-anchor-id="step-3-inference-iterative-check">Step 3: Inference (Iterative Check)</h2>
<ul>
<li><p>이 부분이 4.1절(Group-Balanced)과 가장 다릅니다.</p></li>
<li><p>테스트 시점에는 입력 <img src="https://latex.codecogs.com/png.latex?X_%7Btest%7D">의 <strong>진짜 클래스(True Class)가 무엇인지 모릅니다.</strong></p></li>
<li><p>따라서 “해당 그룹의 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">를 가져다 쓰는” 방식은 불가능합니다.</p></li>
<li><p>대신, 우리는 <strong>“만약 정답이 클래스 <img src="https://latex.codecogs.com/png.latex?y">라면?”</strong>이라는 가정을 모든 후보 클래스에 대해 수행합니다.</p></li>
<li><p>예측 집합 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BC%7D(x)">는 다음 조건을 만족하는 모든 클래스 <img src="https://latex.codecogs.com/png.latex?y">를 포함합니다: <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BC%7D(x)%20=%20%5C%7B%20y%20:%20s(x,%20y)%20%5Cle%20%5Chat%7Bq%7D%5E%7B(y)%7D%20%5C%7D%0A"></p>
<ul>
<li>후보 클래스 <img src="https://latex.codecogs.com/png.latex?y">가 ‘암’이라면? <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> <img src="https://latex.codecogs.com/png.latex?s(x,%20%5Ctext%7B%EC%95%94%7D)">을 계산하고, 이를 ’암’ 클래스의 임계값 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D%5E%7B(%5Ctext%7B%EC%95%94%7D)%7D">과 비교합니다.</li>
<li>후보 클래스 <img src="https://latex.codecogs.com/png.latex?y">가 ‘정상’이라면? <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> <img src="https://latex.codecogs.com/png.latex?s(x,%20%5Ctext%7B%EC%A0%95%EC%83%81%7D)">을 계산하고, 이를 ’정상’ 클래스의 임계값 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D%5E%7B(%5Ctext%7B%EC%A0%95%EC%83%81%7D)%7D">과 비교합니다.</li>
</ul></li>
<li><p>각 클래스마다 <strong>자신만의 기준(Threshold)</strong>을 통과해야 집합에 들어갈 수 있는 것입니다.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-02-Class-Conditional-Conformal-Prediction/images/class_conditional_cp_visualization.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Class-Conditional Conformal Prediction의 개념도. Calibration 데이터를 색깔(클래스)별로 나누어 각각의 분포 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D%5E%7B(1)%7D,%20%5Chat%7Bq%7D%5E%7B(2)%7D">를 구한다. 추론 시에는 각 후보 클래스 <img src="https://latex.codecogs.com/png.latex?y">가 자신의 기준 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D%5E%7B(y)%7D">를 만족하는지 확인한다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="comparison-group-balanced-vs.-class-conditional" class="level1">
<h1>Comparison: Group-Balanced vs.&nbsp;Class-Conditional</h1>
<ul>
<li>이 두 가지 확장의 차이를 명확히 구분하는 것이 중요합니다.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">특징</th>
<th style="text-align: left;">Group-Balanced (4.1)</th>
<th style="text-align: left;">Class-Conditional (4.2)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>기준 (Condition)</strong></td>
<td style="text-align: left;">입력 특성 (Input Feature <img src="https://latex.codecogs.com/png.latex?X_%7B:,1%7D">)</td>
<td style="text-align: left;">출력 라벨 (Output Label <img src="https://latex.codecogs.com/png.latex?Y">)</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>정보 가용성</strong></td>
<td style="text-align: left;">테스트 시점에 <img src="https://latex.codecogs.com/png.latex?X">를 통해 그룹을 <strong>알 수 있음</strong></td>
<td style="text-align: left;">테스트 시점에 <img src="https://latex.codecogs.com/png.latex?Y">를 <strong>알 수 없음</strong></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>적용 방식</strong></td>
<td style="text-align: left;">그룹을 확인하고 <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> 해당 그룹의 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D"> 적용</td>
<td style="text-align: left;">모든 <img src="https://latex.codecogs.com/png.latex?y">에 대해 순회하며 <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> 각자의 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D%5E%7B(y)%7D"> 적용</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>주요 사용처</strong></td>
<td style="text-align: left;">공정성 (인종, 성별 간 평등)</td>
<td style="text-align: left;">불균형 데이터 (희귀 클래스 탐지)</td>
</tr>
</tbody>
</table>
</section>
<section id="theoretical-guarantee" class="level1">
<h1>Theoretical Guarantee</h1>
<ul>
<li>Vovk의 증명에 따르면, 이 방법 또한 수학적으로 엄밀한 커버리지를 보장합니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Proposition 2 (Error control guarantee for class-balanced conformal prediction)</strong></p>
<p>데이터가 i.i.d.라면, 위 알고리즘으로 생성된 집합 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BC%7D">는 모든 클래스 <img src="https://latex.codecogs.com/png.latex?y">에 대해 다음을 만족한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cmathbb%7BP%7D(Y_%7Btest%7D%20%5Cin%20%5Cmathcal%7BC%7D(X_%7Btest%7D)%20%5Cmid%20Y_%7Btest%7D%20=%20y)%20%5Cge%201-%5Calpha%20"></p>
</blockquote>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<ul>
<li>Class-Conditional CP는 불균형한 데이터셋에서 <strong>소수 클래스(Minority Class)의 성능을 희생하지 않기 위한 필수적인 기법</strong>입니다.</li>
<li>비록 소수 클래스의 데이터가 적어서 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">가 커지고(불확실성이 커지고), 결과적으로 예측 집합의 크기가 커질 수는 있습니다.</li>
<li>하지만 이는 “틀리는 것”보다는 훨씬 낫습니다. 우리는 적어도 그 안에 정답이 있다는 확신(Safety)을 가질 수 있기 때문입니다.</li>
</ul>
<hr>
<p><strong>Next Step</strong>: 지금까지는 “정답을 포함할 확률(Coverage)”을 제어하는 것에 집중했습니다. 하지만 어떤 문제에서는 “포함 확률”보다 <strong>“틀렸을 때의 손실(Risk/Loss)”</strong>을 제어하는 것이 더 중요할 수 있습니다. 다음 포스트에서는 이를 일반화한 <strong>Section 4.3 Conformal Risk Control</strong>에 대해 다루겠습니다.</p>


</section>

 ]]></description>
  <category>Paper Review</category>
  <guid>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-02-Class-Conditional-Conformal-Prediction/</guid>
  <pubDate>Thu, 15 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.3)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-03-Conformal-Risk-Control/</link>
  <description><![CDATA[ 





<section id="introduction-beyond-coverage" class="level1">
<h1>Introduction: Beyond Coverage</h1>
<ul>
<li>지금까지 우리가 다룬 Conformal Prediction의 핵심 보장은 다음과 같은 형태였습니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cmathbb%7BP%7D(Y_%7Btest%7D%20%5Cnotin%20%5Cmathcal%7BC%7D(X_%7Btest%7D))%20%5Cle%20%5Calpha%20"></p>
<ul>
<li>즉, “정답을 놓칠 확률(Miscoverage rate)”을 <img src="https://latex.codecogs.com/png.latex?%5Calpha"> 이하로 묶는 것이었습니다.</li>
<li>하지만 현실의 많은 머신러닝 문제에서는 단순히 “맞았다/틀렸다”의 이진(Binary) 에러보다 더 복잡한 <strong>손실(Loss)</strong>을 제어해야 할 때가 많습니다.
<ul>
<li><strong>의료 영상 분할(Tumor Segmentation)</strong>: 암 영역을 조금이라도 놓치면(False Negative) 치명적입니다. 픽셀 단위의 재현율(Recall)을 보장해야 할 수 있습니다.</li>
<li><strong>다중 라벨 분류(Multilabel Classification)</strong>: 여러 개의 태그 중 90% 이상을 맞추기를 원할 수 있습니다 (F1-score 등).</li>
</ul></li>
<li><strong>Conformal Risk Control (CRC)</strong>은 이러한 요구를 반영하여, 임의의 유계 손실 함수(Bounded Loss Function)의 기댓값을 제어하는 기법입니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BE%7D%5Bl(%5Cmathcal%7BC%7D(X_%7Btest%7D),%20Y_%7Btest%7D)%5D%20%5Cle%20%5Calpha%0A"></p>
</section>
<section id="problem-formulation" class="level1">
<h1>Problem Formulation</h1>
<ul>
<li>우리의 목표는 모델의 출력 집합 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BC%7D(X)">가 커질수록 <strong>손실(Loss)이 줄어드는</strong> 상황에서, 기대 손실(Expected Risk)이 사용자 지정 허용치 <img src="https://latex.codecogs.com/png.latex?%5Calpha"> 이하가 되도록 하는 파라미터를 찾는 것입니다.</li>
</ul>
<section id="key-components" class="level2">
<h2 class="anchored" data-anchor-id="key-components">Key Components</h2>
<ul>
<li><ol type="1">
<li><strong>Nested Sets (<img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BC%7D_%5Clambda">)</strong>:</li>
</ol>
<ul>
<li>우리는 파라미터 <img src="https://latex.codecogs.com/png.latex?%5Clambda">를 조절하여 예측 집합의 크기(보수적인 정도)를 조절합니다.</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Clambda">가 커질수록 예측 집합 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BC%7D_%5Clambda(x)">는 더 커지고(더 많은 후보를 포함), 따라서 더 안전해집니다(Conservative).</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Monotone Loss Function (<img src="https://latex.codecogs.com/png.latex?l">)</strong>:</li>
</ol>
<ul>
<li>손실 함수 <img src="https://latex.codecogs.com/png.latex?l(%5Cmathcal%7BC%7D,%20Y)">는 집합 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BC%7D">가 커질수록 감소하거나 같아야 합니다 (Non-increasing).</li>
<li>또한, 손실값은 어떤 상한선 <img src="https://latex.codecogs.com/png.latex?B">를 넘지 않아야 합니다 (<img src="https://latex.codecogs.com/png.latex?l%20%5Cin%20(-%5Cinfty,%20B%5D">).</li>
</ul>
<img src="https://latex.codecogs.com/png.latex?%20%5Clambda_1%20%5Cle%20%5Clambda_2%20%5Cimplies%20l(%5Cmathcal%7BC%7D_%7B%5Clambda_1%7D(x),%20y)%20%5Cge%20l(%5Cmathcal%7BC%7D_%7B%5Clambda_2%7D(x),%20y)%20"></li>
</ul>
</section>
</section>
<section id="the-algorithm" class="level1">
<h1>The Algorithm</h1>
<ul>
<li>CRC의 알고리즘은 기존 CP와 매우 유사하지만, Quantile 대신 <strong>경험적 리스크(Empirical Risk)</strong>를 사용한다는 점이 다릅니다.</li>
</ul>
<section id="step-1-calculate-empirical-risk" class="level2">
<h2 class="anchored" data-anchor-id="step-1-calculate-empirical-risk">Step 1: Calculate Empirical Risk</h2>
<ul>
<li>Calibration 데이터셋 <img src="https://latex.codecogs.com/png.latex?(X_1,%20Y_1),%20%5Cdots,%20(X_n,%20Y_n)">에 대해, 특정 파라미터 <img src="https://latex.codecogs.com/png.latex?%5Clambda">를 썼을 때의 평균 손실(Empirical Risk)을 계산하는 함수 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BR%7D(%5Clambda)">를 정의합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7BR%7D(%5Clambda)%20=%20%5Cfrac%7B1%7D%7Bn%7D%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20l(%5Cmathcal%7BC%7D_%7B%5Clambda%7D(X_i),%20Y_i)%0A"></p>
<ul>
<li>이 함수는 <img src="https://latex.codecogs.com/png.latex?%5Clambda">가 증가함에 따라 손실이 감소하는 우하향 곡선을 그립니다.</li>
</ul>
</section>
<section id="step-2-find-optimal-lambda" class="level2">
<h2 class="anchored" data-anchor-id="step-2-find-optimal-lambda">Step 2: Find Optimal <img src="https://latex.codecogs.com/png.latex?%5Clambda"></h2>
<ul>
<li><p>우리는 기대 손실이 <img src="https://latex.codecogs.com/png.latex?%5Calpha"> 이하가 되기를 원합니다.</p></li>
<li><p>하지만 유한한 데이터(<img src="https://latex.codecogs.com/png.latex?n">)로 인한 불확실성을 고려해야 하므로, 단순히 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BR%7D(%5Clambda)%20%5Cle%20%5Calpha">가 되는 지점을 찾으면 안 됩니다.</p></li>
<li><p>대신, 다음과 같이 <strong>보정된 기준(Conservative Target)</strong>을 사용합니다.</p></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7B%5Clambda%7D%20=%20%5Cinf%20%5Cleft%5C%7B%20%5Clambda%20:%20%5Chat%7BR%7D(%5Clambda)%20%5Cle%20%5Calpha%20-%20%5Cfrac%7BB%20-%20%5Calpha%7D%7Bn%7D%20%5Cright%5C%7D%0A"></p>
<ul>
<li><strong><img src="https://latex.codecogs.com/png.latex?B"></strong>: 손실 함수의 최댓값 (Upper Bound)</li>
<li><strong>Correction Term (<img src="https://latex.codecogs.com/png.latex?%5Cfrac%7BB-%5Calpha%7D%7Bn%7D">)</strong>: 데이터 개수 <img src="https://latex.codecogs.com/png.latex?n">이 적을 때 더 보수적으로 <img src="https://latex.codecogs.com/png.latex?%5Clambda">를 선택하게 만드는 항입니다. <img src="https://latex.codecogs.com/png.latex?n">이 무한대로 가면 이 항은 0이 되어 <img src="https://latex.codecogs.com/png.latex?%5Calpha">에 수렴합니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-03-Conformal-Risk-Control/images/risk_control_visualization.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Conformal Risk Control의 개념도. 파란색 실선은 <img src="https://latex.codecogs.com/png.latex?%5Clambda">에 따른 경험적 리스크 <img src="https://latex.codecogs.com/png.latex?%5Chat%7BR%7D(%5Clambda)">를 나타낸다. 목표 리스크 <img src="https://latex.codecogs.com/png.latex?%5Calpha">에서 보정항 <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7BB-%5Calpha%7D%7Bn%7D">만큼을 뺀 점선과 만나는 지점에서 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Clambda%7D">를 결정한다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="example-multilabel-classification" class="level1">
<h1>Example: Multilabel Classification</h1>
<ul>
<li><p>다중 라벨 분류 문제를 예로 들어보겠습니다.</p></li>
<li><p>하나의 이미지가 ‘사람’, ‘차’, ‘신호등’ 등 여러 클래스(<img src="https://latex.codecogs.com/png.latex?Y_i%20%5Csubseteq%20%5C%7B1,%20%5Cdots,%20K%5C%7D">)를 가질 수 있습니다.</p></li>
<li><ol type="1">
<li><strong>Prediction Set</strong>:</li>
</ol>
<ul>
<li>모델이 각 클래스에 대해 예측한 점수 <img src="https://latex.codecogs.com/png.latex?f(X)_k">가 임계값 <img src="https://latex.codecogs.com/png.latex?1-%5Clambda"> 이상인 클래스들을 담습니다. <img src="https://latex.codecogs.com/png.latex?%20%5Cmathcal%7BC%7D_%5Clambda(x)%20=%20%5C%7B%20k%20:%20f(x)_k%20%5Cge%201-%5Clambda%20%5C%7D%20">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Clambda">가 클수록 임계값이 낮아져 더 많은 클래스가 선택됨</li>
</ul></li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Loss Function</strong>:</li>
</ol>
<ul>
<li>“전체 정답 태그 중 놓친 태그의 비율”을 손실로 정의합니다. <img src="https://latex.codecogs.com/png.latex?%20l(%5Cmathcal%7BC%7D,%20Y)%20=%201%20-%20%5Cfrac%7B%7CY%20%5Ccap%20%5Cmathcal%7BC%7D%7C%7D%7B%7CY%7C%7D%20"></li>
<li>이 값은 0(모두 맞춤)과 1(하나도 못 맞춤) 사이이므로 <img src="https://latex.codecogs.com/png.latex?B=1">입니다.</li>
</ul></li>
<li><ol start="3" type="1">
<li><strong>Applying CRC</strong>:</li>
</ol>
<ul>
<li>사용자가 <img src="https://latex.codecogs.com/png.latex?%5Calpha=0.1">로 설정했다면, 위 알고리즘을 통해 구한 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Clambda%7D">를 사용했을 때 <strong>“평균적으로 정답 태그의 90% 이상을 포함”</strong>하는 예측 집합을 얻게 됩니다.</li>
</ul></li>
</ul>
</section>
<section id="theoretical-guarantee" class="level1">
<h1>Theoretical Guarantee</h1>
<ul>
<li>이 알고리즘은 다음 정리에 의해 수학적으로 보장됩니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Theorem 2 (Conformal Risk Control)</strong></p>
<p>데이터가 i.i.d.이고 손실 함수가 단조 감소(Monotone)한다면, 위 알고리즘으로 선택된 <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Clambda%7D">에 대해 다음이 성립한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cmathbb%7BE%7D%5Bl(%5Cmathcal%7BC%7D_%7B%5Chat%7B%5Clambda%7D%7D(X_%7Btest%7D),%20Y_%7Btest%7D)%5D%20%5Cle%20%5Calpha%20"></p>
</blockquote>
<ul>
<li>이 정리는 CP가 단순히 “에러율 제어”를 넘어, FNR, False Discovery Rate 등 <strong>비즈니스에 중요한 다양한 KPI를 직접 제어</strong>할 수 있는 도구로 확장됨을 의미합니다.</li>
</ul>
<hr>
<p><strong>Next Step</strong>: 지금까지 지도 학습(Supervised Learning) 환경에서의 CP를 다루었습니다. 다음 포스트에서는 정답 라벨이 없는 비지도 학습 환경, 특히 <strong>Section 4.4 Outlier Detection</strong>에 CP를 어떻게 적용하는지 알아보겠습니다.</p>


</section>

 ]]></description>
  <category>Paper Review</category>
  <guid>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-03-Conformal-Risk-Control/</guid>
  <pubDate>Thu, 15 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 4.4)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-04-Outlier-Detection/</link>
  <description><![CDATA[ 





<section id="introduction-unsupervised-setting" class="level1">
<h1>Introduction: Unsupervised Setting</h1>
<ul>
<li>이전까지 우리는 입력 <img src="https://latex.codecogs.com/png.latex?X">와 정답 <img src="https://latex.codecogs.com/png.latex?Y">가 있는 지도 학습 환경을 다루었습니다.</li>
<li>하지만 <img src="https://latex.codecogs.com/png.latex?Y"> 라벨이 없는 경우, 특히 <strong>“정상 데이터 분포에서 벗어난 이상치(Outlier)”</strong>를 탐지해야 하는 상황은 어떻게 해야 할까요?
<ul>
<li>공장 설비의 이상 진동 감지</li>
<li>네트워크 침입 탐지</li>
<li>불량품 검출</li>
</ul></li>
<li>이러한 <strong>Outlier Detection (Anomaly Detection)</strong> 문제에서도 Conformal Prediction을 활용하면, <strong>“정상 데이터를 이상치라고 오판할 확률(False Positive Rate)”</strong>을 통계적으로 제어할 수 있습니다.</li>
</ul>
</section>
<section id="problem-formulation" class="level1">
<h1>Problem Formulation</h1>
<ul>
<li><p>우리는 오염되지 않은 <strong>깨끗한 데이터(Clean Dataset)</strong> <img src="https://latex.codecogs.com/png.latex?X_1,%20%5Cdots,%20X_n">을 가지고 있습니다.</p></li>
<li><p>이들은 모두 정상(Inlier) 분포에서 나왔다고 가정합니다.</p></li>
<li><p>우리의 목표는 새로운 데이터 <img src="https://latex.codecogs.com/png.latex?X_%7Btest%7D">가 들어왔을 때, 이것이 정상 분포에서 온 것인지 아니면 이상치인지 판단하는 함수 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BC%7D">를 만드는 것입니다.</p></li>
<li><p>이때, <strong>실제로는 정상인데 이상치라고 잘못 판단할 확률(Type I Error)</strong>을 <img src="https://latex.codecogs.com/png.latex?%5Calpha"> 이하로 억제해야 합니다. <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D(%5Cmathcal%7BC%7D(X_%7Btest%7D)%20=%20%5Ctext%7Boutlier%7D)%20%5Cle%20%5Calpha%0A"></p>
<ul>
<li>여기서 확률은 <img src="https://latex.codecogs.com/png.latex?X_%7Btest%7D">가 정상 데이터 분포에서 왔을 때의 확률입니다.</li>
</ul></li>
</ul>
</section>
<section id="the-algorithm" class="level1">
<h1>The Algorithm</h1>
<ul>
<li>알고리즘은 기존의 Conformal Prediction과 매우 유사하지만, <img src="https://latex.codecogs.com/png.latex?Y">가 없기 때문에 <strong>입력 <img src="https://latex.codecogs.com/png.latex?X">만으로 계산되는 Score</strong>를 사용합니다.</li>
</ul>
<section id="step-1-define-heuristic-score-function" class="level2">
<h2 class="anchored" data-anchor-id="step-1-define-heuristic-score-function">Step 1: Define Heuristic Score Function</h2>
<ul>
<li>비지도 학습 모델(예: One-class SVM, Isolation Forest, Autoencoder의 Reconstruction Error 등)을 사용하여, 데이터 포인트가 이상치일수록 커지는 점수 함수 <img src="https://latex.codecogs.com/png.latex?s(x)">를 정의합니다. <img src="https://latex.codecogs.com/png.latex?%20s(x):%20%5Cmathcal%7BX%7D%20%5Crightarrow%20%5Cmathbb%7BR%7D%20">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?s(x)">가 큼 <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> 이상치(Outlier)일 가능성 높음</li>
<li><img src="https://latex.codecogs.com/png.latex?s(x)">가 작음 <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> 정상(Inlier)일 가능성 높음</li>
</ul></li>
</ul>
</section>
<section id="step-2-calibration" class="level2">
<h2 class="anchored" data-anchor-id="step-2-calibration">Step 2: Calibration</h2>
<ul>
<li>깨끗한 데이터셋 <img src="https://latex.codecogs.com/png.latex?X_1,%20%5Cdots,%20X_n">에 대해 점수들을 계산합니다. <img src="https://latex.codecogs.com/png.latex?%20s_i%20=%20s(X_i),%20%5Cquad%20i=1,%20%5Cdots,%20n%20"></li>
<li>그리고 이 점수들의 분포에서 <img src="https://latex.codecogs.com/png.latex?1-%5Calpha"> 분위수(Quantile)에 해당하는 임계값 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">를 계산합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7Bq%7D%20=%20%5Ctext%7BQuantile%7D%5Cleft(%20%5C%7Bs_1,%20%5Cdots,%20s_n%5C%7D%20;%20%5Cfrac%7B%5Clceil%20(n+1)(1-%5Calpha)%20%5Crceil%7D%7Bn%7D%20%5Cright)%0A"></p>
</section>
<section id="step-3-detection-inference" class="level2">
<h2 class="anchored" data-anchor-id="step-3-detection-inference">Step 3: Detection (Inference)</h2>
<ul>
<li>새로운 테스트 데이터 <img src="https://latex.codecogs.com/png.latex?X_%7Btest%7D">가 들어오면 점수 <img src="https://latex.codecogs.com/png.latex?s(X_%7Btest%7D)">를 계산하고, 임계값 <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">와 비교하여 판정합니다.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BC%7D(x)%20=%20%5Cbegin%7Bcases%7D%20%5Ctext%7Binlier%7D%20&amp;%20%5Ctext%7Bif%20%7D%20s(x)%20%5Cle%20%5Chat%7Bq%7D%20%5C%5C%20%5Ctext%7Boutlier%7D%20&amp;%20%5Ctext%7Bif%20%7D%20s(x)%20%3E%20%5Chat%7Bq%7D%20%5Cend%7Bcases%7D%0A"></p>
</section>
</section>
<section id="theoretical-guarantee-interpretation" class="level1">
<h1>Theoretical Guarantee &amp; Interpretation</h1>
<ul>
<li>이 간단한 절차는 다음 명제에 의해 False Positive Rate를 <img src="https://latex.codecogs.com/png.latex?%5Calpha"> 이하로 보장합니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Proposition 3 (Error control guarantee for outlier detection)</strong></p>
<p><img src="https://latex.codecogs.com/png.latex?X_1,%20%5Cdots,%20X_n">과 <img src="https://latex.codecogs.com/png.latex?X_%7Btest%7D">가 동일한 분포(i.i.d.)에서 추출되었다면, 위 알고리즘은 다음을 만족한다. <img src="https://latex.codecogs.com/png.latex?%20%5Cmathbb%7BP%7D(%5Cmathcal%7BC%7D(X_%7Btest%7D)%20=%20%5Ctext%7Boutlier%7D)%20%5Cle%20%5Calpha%20"></p>
</blockquote>
<section id="statistical-interpretation" class="level3">
<h3 class="anchored" data-anchor-id="statistical-interpretation">Statistical Interpretation</h3>
<ul>
<li>이 과정은 통계적 <strong>가설 검정(Hypothesis Testing)</strong>과도 연결됩니다.
<ul>
<li><strong>귀무가설(<img src="https://latex.codecogs.com/png.latex?H_0">)</strong>: <img src="https://latex.codecogs.com/png.latex?X_%7Btest%7D">는 정상 데이터 분포(Calibration Data)와 교환 가능하다(Exchangeable).</li>
<li><strong>기각</strong>: 만약 <img src="https://latex.codecogs.com/png.latex?s(X_%7Btest%7D)">가 상위 <img src="https://latex.codecogs.com/png.latex?%5Calpha"> 범위에 들어간다면(즉, p-value &lt; <img src="https://latex.codecogs.com/png.latex?%5Calpha">), 우리는 귀무가설을 기각하고 해당 데이터를 이상치로 판단합니다.</li>
</ul></li>
</ul>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<ul>
<li>Conformal Outlier Detection은 복잡한 이상탐지 모델의 출력값을 <strong>“신뢰할 수 있는 통계적 판정”</strong>으로 변환해줍니다.</li>
<li>사용자는 “이 데이터는 점수가 0.8입니다”라는 모호한 말 대신, <strong>“이 데이터는 95% 신뢰수준에서 정상 범위를 벗어났습니다”</strong>라는 명확한 근거를 가지고 의사결정을 내릴 수 있습니다.</li>
</ul>
<hr>
<p><strong>Next Step</strong>: 지금까지는 학습 데이터와 테스트 데이터의 분포가 같다는 가정(i.i.d.) 하에 진행했습니다. 하지만 현실에서는 시간이 지나며 분포가 변하기도 합니다. 다음 포스트에서는 이러한 <strong>Covariate Shift</strong> 환경에서 CP를 적용하는 <strong>Section 4.5 Conformal Prediction Under Covariate Shift</strong>에 대해 알아보겠습니다.</p>


</section>

 ]]></description>
  <category>Paper Review</category>
  <guid>https://shsha0110.github.io/posts/paper/A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification/Part-04-Extensions-of-Conformal-Prediction/Part-04-04-Outlier-Detection/</guid>
  <pubDate>Thu, 15 Jan 2026 15:00:00 GMT</pubDate>
</item>
</channel>
</rss>
