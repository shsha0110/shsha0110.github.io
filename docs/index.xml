<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>shsha0110.github.io</title>
<link>https://shsha0110.github.io/</link>
<atom:link href="https://shsha0110.github.io/index.xml" rel="self" type="application/rss+xml"/>
<description>A blog built with Quarto</description>
<generator>quarto-1.8.26</generator>
<lastBuildDate>Sat, 24 Jan 2026 15:00:00 GMT</lastBuildDate>
<item>
  <title>[Causal Inference] Causal Data Science: Dimensions and Tasks</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L17/part-01/</link>
  <description><![CDATA[ 





<section id="introduction-all-data-is-not-created-equal" class="level1">
<h1>1. Introduction: All Data is Not Created Equal</h1>
<p>현대의 데이터 과학(Data Science)은 수많은 데이터를 다루지만, 이 데이터들이 모두 동일한 가치를 지니거나 같은 방식으로 생성된 것은 아닙니다. [cite_start]<strong>“All data is not created equal”</strong>이라는 명제는 Causal Data Science의 가장 핵심적인 출발점입니다[cite: 12].</p>
<p>[cite_start]우리가 현실에서 마주하는 데이터는 거의 예외 없이 다음과 같은 문제점들을 안고 있습니다 [cite: 13-18, 30-35]:</p>
<ol type="1">
<li><strong>상이한 실험 조건 (Different Experimental Conditions):</strong> 관찰 데이터(Observational)인가, 실험 데이터(Experimental)인가?</li>
<li><strong>상이한 모집단 (Different Underlying Populations):</strong> 데이터가 수집된 집단이 우리가 알고자 하는 대상과 같은가?</li>
<li><strong>비무작위 표본 추출 (Non-random Sampling):</strong> 샘플링 과정에서 편향(Bias)이 발생했는가?</li>
<li><strong>비무작위 처치 할당 (Non-random Treatment Assignment):</strong> 처치(Treatment)가 무작위로 배정되었는가, 아니면 선택 편향이 있는가?</li>
<li><strong>측정되지 않은 변수 (Unmeasured Variables):</strong> 인과 관계를 파악하는 데 필요한 변수가 누락되었는가?</li>
</ol>
<p>[cite_start]이러한 문제들로 인해 수집된 데이터는 “지저분(messy)”하며, 우리가 추론하고자 하는 <strong>Target</strong>과 완벽하게 일치하는 경우는 매우 드뭅니다[cite: 27, 36]. [cite_start]<strong>Causal Data Science</strong>의 목표는 이러한 이질적인(Heterogeneous) 데이터셋들을 결합하여 과학적이고 원칙적인(principled) 방법으로 인과 추론을 수행하는 것입니다 [cite: 77-79].</p>
<hr>
</section>
<section id="motivation-why-causal-data-science" class="level1">
<h1>2. Motivation: Why Causal Data Science?</h1>
<p>왜 우리는 단순히 “빅데이터”를 모으는 것을 넘어, 데이터의 생성 과정을 고민해야 할까요? [cite_start]강의 자료에서는 세 가지 주요 사례를 들어 그 동기를 설명합니다 [cite: 6-10].</p>
<section id="genetics-transportability" class="level3">
<h3 class="anchored" data-anchor-id="genetics-transportability">2.1. Genetics (Transportability)</h3>
<p>쥐(Rats)를 대상으로 한 실험 연구에서 특정 물질이 발암성(Carcinogenic)이라는 결과가 나왔다고 가정해 봅시다. 우리의 질문은 다음과 같습니다. [cite_start]<strong>“이 결과가 인간에게도 그대로 적용될 것인가?”</strong> [cite: 6-7] 이는 동물 모델에서 얻은 지식을 인간이라는 다른 모집단으로 옮길 수 있는지(Transportability)의 문제입니다.</p>
</section>
<section id="advertisement-transfer-learning" class="level3">
<h3 class="anchored" data-anchor-id="advertisement-transfer-learning">2.2. Advertisement (Transfer Learning)</h3>
<p>어떤 회사에서 ’제품 A’의 판매량을 높이기 위해 다양한 광고 전략의 효과를 분석했습니다. 이제 새로운 ’제품 B’를 출시하려고 합니다. [cite_start]<strong>“제품 A에서 얻은 데이터를 제품 B의 광고 전략 수립에 활용할 수 있는가?”</strong> [cite: 8] 이는 기존 도메인의 지식을 새로운 도메인으로 전이(Transfer)하는 문제입니다.</p>
</section>
<section id="robotics-domain-adaptation" class="level3">
<h3 class="anchored" data-anchor-id="robotics-domain-adaptation">2.3. Robotics (Domain Adaptation)</h3>
<p>캘리포니아 사막에서 암석을 채굴하도록 훈련된 화성 탐사 로봇(Rover)이 있습니다. [cite_start]<strong>“지구에서 학습한 내용을 바탕으로, 화성에서의 비용 소모적인 탐색을 최소화할 수 있는가?”</strong> [cite: 9-10] 환경이 급격히 변화했을 때, 에이전트가 어떻게 적응해야 하는지에 대한 문제입니다.</p>
<hr>
</section>
</section>
<section id="heterogeneous-datasets-formalizing-the-messiness" class="level1">
<h1>3. Heterogeneous Datasets: Formalizing the Messiness</h1>
<p>데이터가 지저분하다는 것은 직관적이지만, 이를 수학적으로 다루기 위해서는 형식이 필요합니다. 우리는 데이터를 다음과 같은 속성들의 집합으로 분류할 수 있습니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-01/images/heterogeneous_datasets_table.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: 이질적인 데이터셋들의 구조화. Target은 우리가 알고자 하는 인과 효과 <img src="https://latex.codecogs.com/png.latex?Q=P%5E*(y%7Cdo(x))">이다. 반면 우리가 가진 데이터들(<img src="https://latex.codecogs.com/png.latex?d_1,%20d_2,%20%5Cdots">)은 서로 다른 지역(Population), 수집 방식(Obs/Exp), 표본 추출 방식(Sampling), 측정 변수(Measured)를 가진다.</figcaption>
</figure>
</div>
<p>[cite_start]위 그림(Figure 1)은 다양한 데이터셋(<img src="https://latex.codecogs.com/png.latex?d_1,%20d_2,%20%5Cdots">)이 어떻게 다른지를 보여줍니다 [cite: 48-74]. * <strong>Target (<img src="https://latex.codecogs.com/png.latex?Q">):</strong> 우리의 목표는 <img src="https://latex.codecogs.com/png.latex?P%5E*(y%7Cdo(x))">를 알아내는 것입니다. * <strong>Source Data:</strong> * <strong>Population:</strong> LA, NY, Seoul, Boston 등 모집단이 다를 수 있습니다. * <strong>Regime:</strong> 관찰(Observational) 데이터일 수도, 무작위 대조군 실험(RCT) 데이터일 수도 있습니다. * <strong>Sampling:</strong> 나이(Age)나 사회경제적 지위(SES)에 따라 선택적으로 추출되었을 수 있습니다. * <strong>Measurement:</strong> 어떤 데이터셋은 변수 <img src="https://latex.codecogs.com/png.latex?W">를 포함하지만, 다른 데이터셋은 포함하지 않을 수 있습니다.</p>
<hr>
</section>
<section id="the-big-picture-in-causal-inference" class="level1">
<h1>4. The “Big Picture” in Causal Inference</h1>
<p>전통적인 인과 추론(Classic Causal Inference)과 Causal Data Science가 바라보는 관점의 차이를 이해해야 합니다.</p>
<section id="classic-causal-inference-engine" class="level3">
<h3 class="anchored" data-anchor-id="classic-causal-inference-engine">4.1. Classic Causal Inference Engine</h3>
<p>[cite_start]전통적인 접근법(예: Pearl의 프레임워크)은 단일 모집단 내에서의 식별(Identifiability) 문제에 집중했습니다 [cite: 87-102].</p>
<ol type="1">
<li><strong>Query:</strong> <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))"></li>
<li><strong>Causal Diagram (Knowledge):</strong> 변수들 간의 인과 구조 (DAG).</li>
<li><strong>Data:</strong> 관찰된 데이터 분포 <img src="https://latex.codecogs.com/png.latex?P(V)">.</li>
<li><strong>Engine:</strong> 주어진 다이어그램에서 데이터만으로 쿼리를 계산할 수 있는지 판별(Yes/No)하고, 가능하다면 추정 식(Estimand)을 도출.</li>
</ol>
</section>
<section id="causal-data-science-framework" class="level3">
<h3 class="anchored" data-anchor-id="causal-data-science-framework">4.2. Causal Data Science Framework</h3>
<p>하지만 현실은 더 복잡합니다. [cite_start]우리가 목표로 하는 <strong>Target Population (<img src="https://latex.codecogs.com/png.latex?%5CPi%5E*">)</strong>과 데이터가 수집되는 <strong>Source Populations (a, b, c, …)</strong>이 다르기 때문입니다 [cite: 104-135].</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-01/images/big_picture_graphs.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: Causal Data Science의 전체 그림. 중앙의 Target Population(US)에 대한 인과 효과를 추정하고 싶지만, 가용 데이터는 구조적으로 상이한 여러 지역(NY, LA, Boston, Texas 등)에서 수집되었다. 각 지역은 Causal Graph 상에서 화살표가 추가되거나(Selection Bias), 노드가 회색으로 처리되는(Missingness) 등의 구조적 차이를 보인다.</figcaption>
</figure>
</div>
<p>[cite_start]위 그림(Figure 2)에서 볼 수 있듯이, 각 소스 데이터는 구조적 차이를 가집니다 [cite: 136-183]. * <strong>Target (US):</strong> <img src="https://latex.codecogs.com/png.latex?X%20%5Crightarrow%20W%20%5Crightarrow%20Y">와 같은 기본 구조. * <strong>NY:</strong> <img src="https://latex.codecogs.com/png.latex?W">가 측정되지 않음 (Grey Node). * <strong>LA:</strong> <img src="https://latex.codecogs.com/png.latex?Z">가 선택 편향의 원인이 됨 (Selection Node <img src="https://latex.codecogs.com/png.latex?S">의 개입). * <strong>Utah:</strong> <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?X">에 영향을 주지 않는 실험적 환경(Randomized).</p>
<p>[cite_start]Causal Data Science의 목표는 이러한 <strong>Multiple, Heterogeneous Datasets</strong>를 융합(Fusion)하여 <strong>Automated Scientist</strong>처럼 타겟 질의에 답하는 것입니다 [cite: 82-85].</p>
<hr>
</section>
</section>
<section id="dimensions-and-tasks-of-causal-data-science" class="level1">
<h1>5. Dimensions and Tasks of Causal Data Science</h1>
<p>[cite_start]이질적인 데이터셋을 통합적으로 다루기 위해, Bareinboim과 Lee 교수는 데이터 수집 조건을 4가지 차원(Dimensions)의 튜플(Tuple)로 정의합니다[cite: 220, 241].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BData%20Collection%20Tuple:%20%7D%20(d_1,%20d_2,%20d_3,%20d_4)%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?d_1">: Population (모집단)</li>
<li><img src="https://latex.codecogs.com/png.latex?d_2">: Regime (관찰 vs 실험)</li>
<li><img src="https://latex.codecogs.com/png.latex?d_3">: Sampling (표본 추출 기전)</li>
<li><img src="https://latex.codecogs.com/png.latex?d_4">: Measurement (측정된 변수 집합)</li>
</ul>
<p>[cite_start]이 튜플의 변화는 우리가 해결해야 할 <strong>데이터 과학의 핵심 과제</strong>들과 1:1로 대응됩니다 [cite: 239-248, 263-271].</p>
<section id="task-1-causal-inference-from-observational-studies" class="level3">
<h3 class="anchored" data-anchor-id="task-1-causal-inference-from-observational-studies">Task 1: Causal Inference (from Observational Studies)</h3>
<ul>
<li><strong>Transition:</strong> <img src="https://latex.codecogs.com/png.latex?(d_1,%20%5Ctext%7BObs%7D,%20d_3,%20d_4)%20%5Clongrightarrow%20(d_1,%20do(x),%20d_3,%20d_4)"></li>
<li><strong>Description:</strong> 가장 고전적인 인과 추론의 영역입니다. 관찰 데이터(<img src="https://latex.codecogs.com/png.latex?P(y%7Cx)">)로부터 실험적 결론(<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">)을 도출합니다. 교란 요인(Confounding Bias)을 통제하는 것이 핵심입니다.</li>
</ul>
</section>
<section id="task-2-experimental-inference-generalized-ivs" class="level3">
<h3 class="anchored" data-anchor-id="task-2-experimental-inference-generalized-ivs">Task 2: Experimental Inference (Generalized IVs)</h3>
<ul>
<li><strong>Transition:</strong> <img src="https://latex.codecogs.com/png.latex?(d_1,%20do(z),%20d_3,%20d_4)%20%5Clongrightarrow%20(d_1,%20do(x),%20d_3,%20d_4)"></li>
<li><strong>Description:</strong> 우리가 원하는 것은 <img src="https://latex.codecogs.com/png.latex?X">에 대한 개입(<img src="https://latex.codecogs.com/png.latex?do(x)">)의 효과인데, 실제 데이터는 도구 변수(Instrumental Variable, <img src="https://latex.codecogs.com/png.latex?Z">)에 대한 개입(<img src="https://latex.codecogs.com/png.latex?do(z)">)만 있는 경우입니다. 불완전한 순응(Imperfect Compliance) 문제를 다룹니다.</li>
</ul>
</section>
<section id="task-3-sampling-selection-bias" class="level3">
<h3 class="anchored" data-anchor-id="task-3-sampling-selection-bias">Task 3: Sampling Selection Bias</h3>
<ul>
<li><strong>Transition:</strong> <img src="https://latex.codecogs.com/png.latex?(d_1,%20d_2,%20%5Ctext%7BSelect%7D(Age),%20d_4)%20%5Clongrightarrow%20(d_1,%20d_2,%20%5C%7B%5C%7D,%20d_4)"></li>
<li><strong>Description:</strong> 데이터가 특정 조건(예: 나이, 소득)에 따라 편향되게 수집되었을 때, 이를 전체 모집단(Random Sample)의 분포로 복원하는 문제입니다.</li>
</ul>
</section>
<section id="task-4-transportability-external-validity" class="level3">
<h3 class="anchored" data-anchor-id="task-4-transportability-external-validity">Task 4: Transportability (External Validity)</h3>
<ul>
<li><strong>Transition:</strong> <img src="https://latex.codecogs.com/png.latex?(%5Ctext%7BBonobos%7D,%20d_2,%20d_3,%20d_4)%20%5Clongrightarrow%20(%5Ctext%7BHumans%7D,%20d_2,%20d_3,%20d_4)"></li>
<li><strong>Description:</strong> 소스 모집단(예: 보노보 원숭이, LA)에서 얻은 지식을 타겟 모집단(예: 인간, US 전체)으로 이송(Transport)하는 문제입니다. 환경적 조건의 차이를 극복해야 합니다.</li>
</ul>
</section>
<section id="summary-of-dimensions" class="level3">
<h3 class="anchored" data-anchor-id="summary-of-dimensions">Summary of Dimensions</h3>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Dimension</th>
<th style="text-align: left;">Problem Domain</th>
<th style="text-align: left;">Key Challenge</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>1. Experimental Cond.</strong></td>
<td style="text-align: left;">Causal Identification</td>
<td style="text-align: left;">Confounding Bias</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>2. Environmental Cond.</strong></td>
<td style="text-align: left;">Transportability</td>
<td style="text-align: left;">External Validity</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>3. Sampling Cond.</strong></td>
<td style="text-align: left;">Selection Bias</td>
<td style="text-align: left;">Sample Selection</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>4. Responding Cond.</strong></td>
<td style="text-align: left;">Missing Data</td>
<td style="text-align: left;">Recovering from Missingness</td>
</tr>
</tbody>
</table>
<p>[cite_start]과거의 문헌들은 이 문제들을 각각 고립된 상태에서 특수한 모수적(parametric) 가정하에 다루었습니다 [cite: 251-252]. [cite_start]하지만 <strong>Causal Data Science</strong>는 이 4가지 차원이 현실에서 복합적으로 나타난다는 점을 인식하고, 이를 통합적으로 해결하기 위한 일반화된 알고리즘과 조건을 연구합니다 [cite: 254-259].</p>
<hr>
</section>
</section>
<section id="conclusion" class="level1">
<h1>6. Conclusion</h1>
<p>이번 포스트에서는 “Causal Data Science”가 무엇이며, 왜 필요한지에 대한 서론을 다루었습니다. 핵심은 <strong>데이터가 수집되는 과정(Data Generating Process)의 이질성을 4가지 차원(실험, 환경, 샘플링, 응답)으로 구조화</strong>하고, 이를 통해 서로 다른 소스의 데이터를 타겟 쿼리에 맞게 융합하는 것입니다.</p>
<p>다음 포스트에서는 각 차원별로 구체적인 식별 조건(Identification Condition)과 알고리즘이 어떻게 작동하는지 자세히 살펴보겠습니다.</p>
<hr>
<section id="appendix-verification-checklist" class="level3">
<h3 class="anchored" data-anchor-id="appendix-verification-checklist"><strong>Appendix: Verification Checklist</strong></h3>
<ul>
<li><strong>포함된 내용:</strong>
<ul class="task-list">
<li><label><input type="checkbox" checked="">“All data is not created equal” 모티베이션 (Genetics, Ads, Robotics)</label></li>
<li><label><input type="checkbox" checked="">Heterogeneous Datasets의 정의 및 예시</label></li>
<li><label><input type="checkbox" checked="">Classic Causal Inference vs.&nbsp;Big Picture 비교</label></li>
<li><label><input type="checkbox" checked="">Target Population과 Source Populations의 관계</label></li>
<li><label><input type="checkbox" checked="">데이터 수집 튜플 <img src="https://latex.codecogs.com/png.latex?(d_1,%20d_2,%20d_3,%20d_4)">의 정의</label></li>
<li><label><input type="checkbox" checked="">Causal Data Science의 4가지 차원 및 대응하는 Task (Causal Inference, Exp Inference, Selection Bias, Transportability)</label></li>
<li><label><input type="checkbox" checked="">모든 수식에 대한 LaTeX 적용</label></li>
<li><label><input type="checkbox" checked="">주요 도표에 대한 Placeholder 및 상세 캡션</label></li>
</ul></li>
<li><strong>생략된 내용:</strong>
<ul>
<li>강의 자료(PDF)는 12페이지(슬라이드 번호 261, 272)에서 종료되었으므로, 그 이후의 구체적인 알고리즘(예: do-calculus의 확장, transportability formula 등)은 포함되지 않았음. (제공된 범위 내 완결)</li>
</ul></li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <category>Data Science</category>
  <category>Methodology</category>
  <guid>https://shsha0110.github.io/posts/lecture/L17/part-01/</guid>
  <pubDate>Sat, 24 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] Experimental Identifiability &amp; g-ID</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L17/part-02/</link>
  <description><![CDATA[ 





<section id="overview-the-challenge-of-experimental-conditions" class="level1">
<h1>1. Overview: The Challenge of Experimental Conditions</h1>
<p>이전 포스트에서는 Causal Data Science가 다루는 4가지 차원(Dimensions)에 대해 개괄적으로 살펴보았습니다. [cite_start]이번 포스트에서는 그 첫 번째이자 가장 기초가 되는 문제인 <strong>Experimental Conditions</strong>와 <strong>General Identifiability (g-ID)</strong>에 대해 깊이 있게 다룹니다[cite: 274].</p>
<p>우리가 <img src="https://latex.codecogs.com/png.latex?do(x)">에 대한 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 알고 싶을 때, 이상적인 상황은 <img src="https://latex.codecogs.com/png.latex?X">에 대한 무작위 대조군 실험(RCT) 데이터가 있는 것입니다. 하지만 현실에서는 다음과 같은 제약이 따릅니다:</p>
<ol type="1">
<li><strong>윤리적/비용적 문제:</strong> <img src="https://latex.codecogs.com/png.latex?X">(예: 흡연, 유해 물질 노출)를 직접 실험할 수 없음.</li>
<li><strong>대리 실험(Surrogate Experiments):</strong> <img src="https://latex.codecogs.com/png.latex?X"> 대신 <img src="https://latex.codecogs.com/png.latex?Z">(예: 식이요법, 보조 약물)에 대한 실험 데이터만 존재함.</li>
<li><strong>이질적 데이터의 결합:</strong> 여러 개의 서로 다른 실험 결과(<img src="https://latex.codecogs.com/png.latex?do(x_1),%20do(x_2)">)를 결합하여 새로운 개입(<img src="https://latex.codecogs.com/png.latex?do(x_1,%20x_2)">)의 효과를 추정해야 함.</li>
</ol>
<p>이 문제는 <strong>“우리가 가진 다양한 실험 및 관찰 데이터(<img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BP%7D">)를 활용하여, 타겟 질의(<img src="https://latex.codecogs.com/png.latex?Q">)를 식별할 수 있는가?”</strong>라는 <strong>General Identifiability</strong> 문제로 귀결됩니다.</p>
<hr>
</section>
<section id="z-id-experimental-identifiability" class="level1">
<h1>2. z-ID: Experimental Identifiability</h1>
<section id="motivation-diet-cholesterol-and-heart-attack" class="level2">
<h2 class="anchored" data-anchor-id="motivation-diet-cholesterol-and-heart-attack">2.1. Motivation: Diet, Cholesterol, and Heart Attack</h2>
<p>가장 단순한 형태의 대리 실험 문제를 살펴보겠습니다. [cite_start]우리의 목표는 콜레스테롤 수치(<img src="https://latex.codecogs.com/png.latex?X">)가 심장마비(<img src="https://latex.codecogs.com/png.latex?Y">)에 미치는 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 알아내는 것입니다 [cite: 283-294].</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-02/images/zid_motivation_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: z-ID의 기본 모티베이션 그래프. Z(식이요법)는 X(콜레스테롤)에 영향을 주고, X는 Y(심장마비)에 영향을 준다. 점선 화살표는 측정되지 않은 교란 변수(Confounder)를 의미한다. Z와 Y 사이의 직접적인 화살표가 없다는 점(Exclusion Restriction)이 중요하다.</figcaption>
</figure>
</div>
<ul>
<li><strong>Query:</strong> <img src="https://latex.codecogs.com/png.latex?Q%20=%20P(y%7Cdo(x))"></li>
<li><strong>Problem:</strong> <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이에 관측되지 않은 교란 요인(Confounder)이 존재하여(위 그림의 <img src="https://latex.codecogs.com/png.latex?X%20%5Cleftrightarrow%20Y"> 점선), 관찰 데이터 <img src="https://latex.codecogs.com/png.latex?P(x,y,z)">만으로는 <img src="https://latex.codecogs.com/png.latex?Q">를 식별할 수 없습니다.</li>
<li><strong>Available Data:</strong>
<ul>
<li>Observational: <img src="https://latex.codecogs.com/png.latex?P(x,y,z)"></li>
<li>Experimental (Surrogate): <img src="https://latex.codecogs.com/png.latex?P(x,y%7Cdo(z))"> — 식이요법(<img src="https://latex.codecogs.com/png.latex?Z">)은 실험 가능함.</li>
</ul></li>
</ul>
<p>이 경우, <img src="https://latex.codecogs.com/png.latex?Z">에 대한 실험 데이터를 사용하여 <img src="https://latex.codecogs.com/png.latex?X">의 효과를 식별할 수 있을까요? 이를 <strong>z-ID</strong> 문제라고 합니다.</p>
</section>
<section id="instrumental-variable-formula-derived-from-experiments" class="level2">
<h2 class="anchored" data-anchor-id="instrumental-variable-formula-derived-from-experiments">2.2. Instrumental Variable Formula derived from Experiments</h2>
<p>[cite_start]만약 <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?X">를 통해서만 <img src="https://latex.codecogs.com/png.latex?Y">에 영향을 미친다면(즉, <img src="https://latex.codecogs.com/png.latex?Z%20%5Cto%20Y"> 직접 경로가 없고, <img src="https://latex.codecogs.com/png.latex?Z">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 교란이 없다면), 우리는 다음 식을 유도할 수 있습니다[cite: 309].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Cfrac%7BP(x,y%7Cdo(z))%7D%7BP(x%7Cdo(z))%7D%20=%20P(y%7Cx,%20do(z))%0A"></p>
<p>이는 도구 변수(Instrumental Variable) 논리와 유사하지만, 여기서는 <img src="https://latex.codecogs.com/png.latex?do(z)">라는 명시적인 실험 분포를 활용한다는 점이 다릅니다. 이 식은 <img src="https://latex.codecogs.com/png.latex?Z">를 개입했을 때 나타나는 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">의 관계를 통해, <img src="https://latex.codecogs.com/png.latex?X">가 변했을 때 <img src="https://latex.codecogs.com/png.latex?Y">가 어떻게 변하는지(<img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Y"> 메커니즘)를 추출해 내는 것입니다.</p>
</section>
<section id="subtleties-of-z-id" class="level2">
<h2 class="anchored" data-anchor-id="subtleties-of-z-id">2.3. Subtleties of z-ID</h2>
<p>모든 경우에 대리 실험이 유효한 것은 아닙니다. [cite_start]그래프 구조에 따라 식별 가능 여부가 달라집니다 [cite: 311-393].</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-02/images/zid_vs_nonzid.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: z-ID 가능 그래프와 불가능 그래프의 비교. 상단 그래프들은 Z에 대한 실험으로 X의 효과를 식별할 수 있는 경우(z-ID)이고, 하단 그래프들은 식별 불가능한 경우(non-z-ID)이다. 핵심은 Z의 개입이 X와 Y 사이의 교란 요인을 통제하거나 우회할 수 있는지 여부이다.</figcaption>
</figure>
</div>
<p>위 그림에서 <strong>z-ID</strong>가 가능한 경우와 그렇지 않은 경우(non-z-ID)를 구분하는 것은, <img src="https://latex.codecogs.com/png.latex?Z">에 대한 개입이 <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Y"> 관계를 교란하는 뒷문 경로(Back-door path)를 차단하거나, <img src="https://latex.codecogs.com/png.latex?X">의 변동을 충분히 설명할 수 있는지와 관련이 있습니다.</p>
<hr>
</section>
</section>
<section id="advanced-derivation-combining-causal-mechanisms" class="level1">
<h1>3. Advanced Derivation: Combining Causal Mechanisms</h1>
<p>[cite_start]조금 더 복잡한 그래프를 통해, 식별 불가능해 보이는 효과를 도출해 내는 과정을 수식으로 살펴보겠습니다 [cite: 394-405].</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-02/images/complex_zid_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3: 4개의 노드(Z, X, W, Y)를 가진 복잡한 인과 그래프. Z에서 X, X에서 W, W에서 Y로 이어지는 경로 외에 다양한 교란 경로(점선)가 존재한다. 이 그래프에서 P(y|do(x))를 구하는 것이 목표다.</figcaption>
</figure>
</div>
<section id="goal" class="level3">
<h3 class="anchored" data-anchor-id="goal">Goal</h3>
<p>Target: <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))"></p>
<p>이 그래프에서 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이에는 직접적인 교란이 존재하므로, 표준적인 Back-door criterion을 사용할 수 없습니다. 하지만, <img src="https://latex.codecogs.com/png.latex?Z">에 대한 실험 데이터 <img src="https://latex.codecogs.com/png.latex?P(v%7Cdo(z))">가 있다면 가능합니다.</p>
</section>
<section id="derivation-step-by-step" class="level3">
<h3 class="anchored" data-anchor-id="derivation-step-by-step">Derivation Step-by-Step</h3>
<p>Do-calculus와 확률의 법칙(Law of Total Probability)을 사용하여 식을 분해해 봅시다. [cite_start]매개변수 <img src="https://latex.codecogs.com/png.latex?W">를 도입하여 conditioning을 수행합니다[cite: 395].</p>
<ol type="1">
<li><p><strong>Conditioning on W:</strong> <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))%20=%20%5Csum_%7Bw%7D%20P(y%7Cdo(x),%20w)%20P(w%7Cdo(x))"></p></li>
<li><p><strong>Simplification using Causal Graph (Rule 2/3):</strong> 그래프 구조상, <img src="https://latex.codecogs.com/png.latex?X">에 개입하고 <img src="https://latex.codecogs.com/png.latex?W">가 주어졌을 때 <img src="https://latex.codecogs.com/png.latex?Y">의 분포는 <img src="https://latex.codecogs.com/png.latex?W">에만 개입했을 때의 분포와 같습니다(X의 영향은 W를 통해서만 전달됨). <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x),%20w)%20=%20P(y%7Cdo(w))"></p></li>
<li><p><strong>Substitution:</strong> <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))%20=%20%5Csum_%7Bw%7D%20P(y%7Cdo(w))%20P(w%7Cdo(x))"></p></li>
</ol>
<p>이제 우변의 두 항(<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(w))">, <img src="https://latex.codecogs.com/png.latex?P(w%7Cdo(x))">)을 각각 구해야 합니다. [cite_start]놀랍게도 이 두 항은 모두 <img src="https://latex.codecogs.com/png.latex?P(v%7Cdo(z))">로부터 식별 가능합니다 [cite: 405-408].</p>
<ul>
<li><strong>Identifying <img src="https://latex.codecogs.com/png.latex?Q%5BY%5D%20=%20P(y%7Cdo(w))">:</strong> <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(w))%20=%20P(y%7Cdo(w,z))%20=%20%5Csum_x%20P(y%7Cdo(z),%20w,%20x)%20P(x%7Cdo(z))"></li>
<li><strong>Identifying <img src="https://latex.codecogs.com/png.latex?Q%5BW%5D%20=%20P(w%7Cdo(x))">:</strong> <img src="https://latex.codecogs.com/png.latex?P(w%7Cdo(x))%20=%20P(w%7Cdo(x,z))%20=%20P(w%7Cdo(z),%20x)"></li>
</ul>
<p>따라서, <img src="https://latex.codecogs.com/png.latex?Z">에 대한 실험 데이터만으로 <img src="https://latex.codecogs.com/png.latex?X">에 대한 개입 효과를 완전히 계산할 수 있게 됩니다.</p>
<hr>
</section>
</section>
<section id="example-drug-drug-interactions-combining-experiments" class="level1">
<h1>4. Example: Drug-Drug Interactions (Combining Experiments)</h1>
<p>이 이론의 가장 강력한 응용 사례는 <strong>약물 상호작용(Drug-Drug Interaction)</strong> 분석입니다. [cite_start]개별 약물 실험 데이터만 있을 때, 두 약물을 동시에 처방했을 때의 효과를 예측할 수 있을까요? [cite: 415-460]</p>
<section id="problem-setup" class="level3">
<h3 class="anchored" data-anchor-id="problem-setup">4.1. Problem Setup</h3>
<ul>
<li><strong>Variables:</strong>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?X_1">: 고혈압 치료제 (Anti-hypertensive drug)</li>
<li><img src="https://latex.codecogs.com/png.latex?X_2">: 당뇨 치료제 (Anti-diabetic drug)</li>
<li><img src="https://latex.codecogs.com/png.latex?B">: 혈압 (Blood pressure)</li>
<li><img src="https://latex.codecogs.com/png.latex?Y">: 심혈관 질환 (CVD)</li>
</ul></li>
<li><strong>Data Sources:</strong>
<ul>
<li>Study 1: <img src="https://latex.codecogs.com/png.latex?X_1">에 대한 RCT <img src="https://latex.codecogs.com/png.latex?%5Crightarrow%20P(v%7Cdo(x_1))"></li>
<li>Study 2: <img src="https://latex.codecogs.com/png.latex?X_2">에 대한 RCT <img src="https://latex.codecogs.com/png.latex?%5Crightarrow%20P(v%7Cdo(x_2))"></li>
</ul></li>
<li><strong>Target Query:</strong>
<ul>
<li>Joint Intervention: <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x_1,%20x_2))"></li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-02/images/drug_interaction_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 4: 약물 상호작용 인과 그래프. X1은 B에 영향을 주고, B는 Y에 영향을 준다. X2는 Y에 직접 영향을 준다. X1과 B, X2와 Y, B와 Y 사이에는 교란 요인(점선)이 존재한다. 목표는 X1과 X2를 동시에 개입했을 때 Y의 분포를 구하는 것이다.</figcaption>
</figure>
</div>
</section>
<section id="derivation" class="level3">
<h3 class="anchored" data-anchor-id="derivation">4.2. Derivation</h3>
<p>우리는 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x_1,%20x_2))">를 구해야 합니다. [cite_start]혈압 <img src="https://latex.codecogs.com/png.latex?B">가 <img src="https://latex.codecogs.com/png.latex?X_1">과 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 매개체 역할을 한다는 점에 착안하여 식을 전개합니다 [cite: 570-577].</p>
<ol type="1">
<li><p><strong>Total Probability Theorem over B:</strong> <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x_1,%20x_2))%20=%20%5Csum_%7Bb%7D%20P(y%7Cdo(x_1,%20x_2),%20b)%20P(b%7Cdo(x_1,%20x_2))"></p></li>
<li><p><strong>Factor 1: <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x_1,%20x_2),%20b)"></strong> 그래프에서 <img src="https://latex.codecogs.com/png.latex?X_1">은 <img src="https://latex.codecogs.com/png.latex?B">로 가는 화살표를 제외하면 <img src="https://latex.codecogs.com/png.latex?Y">에 직접 영향을 주지 않습니다(Block). 따라서 <img src="https://latex.codecogs.com/png.latex?X_1">을 조건부에서 제거할 수 있습니다. <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x_1,%20x_2),%20b)%20=%20P(y%7Cdo(x_2),%20b)"> 이 항은 <strong>Study 2 (<img src="https://latex.codecogs.com/png.latex?do(x_2)">)</strong> 데이터에서 <img src="https://latex.codecogs.com/png.latex?B">를 관측함으로써 얻을 수 있습니다 (<img src="https://latex.codecogs.com/png.latex?P_%7Bx_2%7D(y%7Cb)">).</p></li>
<li><p><strong>Factor 2: <img src="https://latex.codecogs.com/png.latex?P(b%7Cdo(x_1,%20x_2))"></strong> 그래프에서 <img src="https://latex.codecogs.com/png.latex?X_2">는 <img src="https://latex.codecogs.com/png.latex?B">에 영향을 주지 않습니다 (<img src="https://latex.codecogs.com/png.latex?Y">에만 영향). 따라서 <img src="https://latex.codecogs.com/png.latex?X_2">를 제거할 수 있습니다. <img src="https://latex.codecogs.com/png.latex?P(b%7Cdo(x_1,%20x_2))%20=%20P(b%7Cdo(x_1))"> 이 항은 <strong>Study 1 (<img src="https://latex.codecogs.com/png.latex?do(x_1)">)</strong> 데이터에서 바로 얻을 수 있습니다 (<img src="https://latex.codecogs.com/png.latex?P_%7Bx_1%7D(b)">).</p></li>
</ol>
</section>
<section id="final-formula" class="level3">
<h3 class="anchored" data-anchor-id="final-formula">4.3. Final Formula</h3>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x_1,%20x_2))%20=%20%5Csum_%7Bb%7D%20P_%7Bx_1%7D(b)%20P_%7Bx_2%7D(y%7Cb)%0A"></p>
<p>이 결과는 매우 강력합니다. <strong>두 약물을 동시에 사용하는 실험을 한 번도 수행하지 않았음에도</strong>, 개별 약물 실험 데이터를 수학적으로 결합하여 그 효과를 정확히 예측할 수 있기 때문입니다.</p>
<hr>
</section>
</section>
<section id="algorithm-for-general-identifiability-g-id" class="level1">
<h1>5. Algorithm for General Identifiability (g-ID)</h1>
<p>[cite_start]위의 사례들을 일반화하면 <strong>General Identifiability (g-ID)</strong> 알고리즘을 만들 수 있습니다 [cite: 488-511].</p>
<section id="the-g-id-algorithm-flow" class="level3">
<h3 class="anchored" data-anchor-id="the-g-id-algorithm-flow">The g-ID Algorithm Flow</h3>
<ol type="1">
<li><p><strong>Decomposition (분해):</strong> 주어진 쿼리 <img src="https://latex.codecogs.com/png.latex?Q%20=%20P_x(y)">를 Causal Graph의 구조(C-components)를 이용하여 더 작은 <strong>Factors (요인들)</strong>의 곱과 합(<img src="https://latex.codecogs.com/png.latex?%5Csum%20%5Cprod">)으로 분해합니다. <img src="https://latex.codecogs.com/png.latex?Q%20=%20%5Csum%20%5Cprod%20P_%7B%5Cbullet%7D(%5Cbullet)"></p></li>
<li><p><strong>Identification (식별):</strong> 분해된 각 Factor가 가용한 데이터 소스 집합 <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BP%7D%20=%20%5C%7B%20P(obs),%20P(do(z_1)),%20P(do(z_2)),%20%5Cdots%20%5C%7D"> 중 하나로부터 식별 가능한지 확인합니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-02/images/gid_algorithm_flow.png" class="img-fluid figure-img"></p>
<figcaption>Figure 5: g-ID 알고리즘의 도식화. 쿼리(좌측)가 여러 Factor로 분해되고, 각 Factor가 우측의 가용 데이터 소스(P_z1, P_zm…) 중 하나와 매칭되어 식별되는 과정을 보여준다.</figcaption>
</figure>
</div></li>
<li><p><strong>Conclusion:</strong></p>
<ul>
<li>만약 모든 Factor가 데이터 소스로부터 식별 가능하다면 <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> <strong>Identifiable</strong>.</li>
<li>하나라도 식별 불가능한 Factor가 남는다면 <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> <strong>Fail</strong>.</li>
</ul></li>
</ol>
</section>
<section id="significance" class="level3">
<h3 class="anchored" data-anchor-id="significance">Significance</h3>
<p>이 알고리즘과 Do-calculus는 Experimental Identifiability 문제에 대해 <strong>Completeness(완전성)</strong>를 가집니다. [cite_start]즉, 이 알고리즘으로 식별할 수 없다면, 그 인과 효과는 주어진 데이터와 그래프 가정하에서는 이론적으로 식별이 불가능한 것입니다[cite: 586].</p>
<hr>
</section>
</section>
<section id="conclusion" class="level1">
<h1>6. Conclusion</h1>
<p>이번 포스트에서는 Causal Data Science의 첫 번째 차원인 <strong>Experimental Conditions</strong>를 다루었습니다.</p>
<ul>
<li><strong>z-ID:</strong> 직접 실험할 수 없는 변수의 효과를 대리 실험(<img src="https://latex.codecogs.com/png.latex?Z">)을 통해 식별하는 방법.</li>
<li><strong>Data Fusion:</strong> 서로 다른 실험 데이터(<img src="https://latex.codecogs.com/png.latex?do(x_1),%20do(x_2)">)를 결합하여 새로운 인과 효과를 추론하는 메커니즘.</li>
<li><strong>g-ID Algorithm:</strong> 이를 일반화하여 복잡한 쿼리를 분해하고 가용 데이터와 매핑하는 체계적인 방법론.</li>
</ul>
<p>다음 포스트에서는 두 번째 차원인 <strong>Environmental Conditions (Transportability)</strong>, 즉 한 집단(예: 쥐, LA)에서 얻은 결과를 다른 집단(예: 인간, NY)으로 일반화하는 방법에 대해 다루겠습니다.</p>
<hr>
<section id="appendix-verification-checklist" class="level3">
<h3 class="anchored" data-anchor-id="appendix-verification-checklist"><strong>Appendix: Verification Checklist</strong></h3>
<ul>
<li><strong>포함된 내용:</strong>
<ul class="task-list">
<li><label><input type="checkbox" checked="">Experimental Conditions (General Identifiability)의 정의 및 필요성</label></li>
<li><label><input type="checkbox" checked="">Diet-Cholesterol-Heart Attack 예시를 통한 z-ID 모티베이션</label></li>
<li><label><input type="checkbox" checked="">z-ID 식별 공식 및 유도 (<img src="https://latex.codecogs.com/png.latex?P(y%7Cx,%20do(z))">)</label></li>
<li><label><input type="checkbox" checked="">복잡한 그래프에서의 수식 유도 (Subtleties, c-component factorization 논리)</label></li>
<li><label><input type="checkbox" checked="">Drug-Drug Interaction 예시와 단계별 수식 유도 (Joint intervention)</label></li>
<li><label><input type="checkbox" checked="">g-ID 알고리즘의 2단계 구조 (Decomposition -&gt; Identification)</label></li>
<li><label><input type="checkbox" checked="">Do-calculus의 Completeness 언급</label></li>
<li><label><input type="checkbox" checked="">모든 주요 수식의 LaTeX 구현 및 Figure Placeholder</label></li>
</ul></li>
<li><strong>생략된 내용:</strong>
<ul>
<li>“Missing Data” 및 “Selection Bias”에 대한 상세 내용은 PDF의 Overview(Slide 1)와 결론부(Slide 21 이후)에만 짧게 언급되어 있고, 본문 슬라이드(Slide 2-20)는 Experimental Identifiability에 집중되어 있어, 이번 포스트도 g-ID에 집중하여 작성함.</li>
</ul></li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <category>Data Science</category>
  <category>Methodology</category>
  <guid>https://shsha0110.github.io/posts/lecture/L17/part-02/</guid>
  <pubDate>Sat, 24 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] General Identifiability with Partial Observation (GID-PO)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L17/part-06/</link>
  <description><![CDATA[ 





<section id="introduction-데이터-융합data-fusion의-필요성" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction-데이터-융합data-fusion의-필요성"><span class="header-section-number">1</span> 1. Introduction: 데이터 융합(Data Fusion)의 필요성</h2>
<p>현대 데이터 과학, 특히 사회과학과 공학이 교차하는 지점에서는 <strong>“모든 변수가 완벽하게 측정된 단 하나의 데이터셋”</strong>을 확보하는 것이 거의 불가능합니다. 현실에서는 다음과 같은 상황이 빈번하게 발생합니다.</p>
<ul>
<li><strong>실험 연구(Experimental Study):</strong> 핵심적인 처치(Treatment)와 주요 결과 변수만 측정하며, 비용 문제로 많은 공변량을 측정하지 못함.</li>
<li><strong>관찰 연구(Observational Study):</strong> 방대한 공변량과 결과 변수가 존재하지만, 처치 변수가 없거나 무작위 배정(Randomization)이 되어 있지 않음.</li>
</ul>
<p>이러한 상황에서, 서로 다른 변수 집합(<img src="https://latex.codecogs.com/png.latex?V_i%20%5Csubseteq%20V">)을 포함하는 이질적인 데이터셋들을 결합하여, 전체 시스템의 인과 효과(Causal Effect)를 추정할 수 있을까요? 이번 포스트에서는 <strong>General Identifiability with Partial Observation (GID-PO)</strong> 개념을 통해 이 문제를 해결하는 과정을 다룹니다.</p>
</section>
<section id="problem-setup-gid-po" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="problem-setup-gid-po"><span class="header-section-number">2</span> 2. Problem Setup: GID-PO</h2>
<p>우리가 관심을 가지는 전체 변수 집합을 <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BV%7D">라고 합시다. 하지만 우리는 <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BV%7D"> 전체를 관측한 데이터가 없습니다. 대신, <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BV%7D">의 부분집합인 <img src="https://latex.codecogs.com/png.latex?V_i">만을 관측한 여러 개의 데이터셋(실험 또는 관찰) 모음 <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BP%7D=%5C%7BP_%7BZ_%7Bi%7D%7D(V_%7Bi%7D)%5C%7D_%7Bi%7D">를 가지고 있습니다.</p>
<p>이때 우리의 목표는 타겟 인과 효과 <img src="https://latex.codecogs.com/png.latex?P_x(y)"> (처치 <img src="https://latex.codecogs.com/png.latex?X">가 결과 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 효과)를 식별(Identify)하는 것입니다.</p>
<section id="예시-시나리오-운동이-뇌졸중에-미치는-영향" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="예시-시나리오-운동이-뇌졸중에-미치는-영향"><span class="header-section-number">2.1</span> 2.1 예시 시나리오: 운동이 뇌졸중에 미치는 영향</h3>
<p>강의 자료에서 제시된 구체적인 예시를 통해 문제를 정의해 봅시다. 우리는 <strong>운동(Exercise, <img src="https://latex.codecogs.com/png.latex?X">)</strong>이 <strong>뇌졸중(Stroke, <img src="https://latex.codecogs.com/png.latex?Y">)</strong>에 미치는 인과적 효과를 알고 싶습니다.</p>
<p>관련된 변수들은 다음과 같습니다: * <img src="https://latex.codecogs.com/png.latex?A">: 나이 (Age) * <img src="https://latex.codecogs.com/png.latex?X">: 운동 (Exercise) - <strong>처치 변수</strong> * <img src="https://latex.codecogs.com/png.latex?B">: BMI * <img src="https://latex.codecogs.com/png.latex?C">: 혈압 (Blood Pressure) * <img src="https://latex.codecogs.com/png.latex?Y">: 뇌졸중 (Stroke) - <strong>결과 변수</strong></p>
<p>이 변수들의 인과 관계는 아래의 Causal Graph(DAG)로 표현됩니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-06/images/causal_graph_stroke_exercise.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: Exercise &amp; Stroke Causal Graph. A(Age)는 X(Exercise)와 B(BMI)에 영향을 줌. X는 B에 영향을 줌. B는 C(Blood Pressure)에 영향을 줌. C는 Y(Stroke)에 영향을 줌. 점선(Dashed Line)은 X와 Y 사이에 관측되지 않은 교란 요인(Unobserved Confounder)이 존재함을 암시함.</figcaption>
</figure>
</div>
</section>
<section id="주어진-데이터의-한계" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="주어진-데이터의-한계"><span class="header-section-number">2.2</span> 2.2 주어진 데이터의 한계</h3>
<p>우리는 <img src="https://latex.codecogs.com/png.latex?P(A,%20X,%20B,%20C,%20Y)"> 전체를 포함하는 데이터가 없습니다. 대신 두 가지의 불완전한 연구 결과만 가지고 있다고 가정해 봅시다.</p>
<ol type="1">
<li><strong>연구 1 (Experimental Study):</strong>
<ul>
<li>운동(<img src="https://latex.codecogs.com/png.latex?X">)에 대해 무작위 배정(Intervention)을 수행했습니다.</li>
<li>측정 변수: 나이(<img src="https://latex.codecogs.com/png.latex?A">), 혈압(<img src="https://latex.codecogs.com/png.latex?C">). (BMI와 뇌졸중은 측정하지 않음)</li>
<li>확보된 분포: <img src="https://latex.codecogs.com/png.latex?P_X(A,%20C)"></li>
</ul></li>
<li><strong>연구 2 (Observational Study):</strong>
<ul>
<li>단순 관찰 연구입니다.</li>
<li>측정 변수: BMI(<img src="https://latex.codecogs.com/png.latex?B">), 혈압(<img src="https://latex.codecogs.com/png.latex?C">), 뇌졸중(<img src="https://latex.codecogs.com/png.latex?Y">). (나이와 운동 여부는 데이터에 없음)</li>
<li>확보된 분포: <img src="https://latex.codecogs.com/png.latex?P(B,%20C,%20Y)"></li>
</ul></li>
</ol>
<p><strong>Task:</strong> 이 두 가지 부분적인 분포 <img src="https://latex.codecogs.com/png.latex?P_X(A,%20C)">와 <img src="https://latex.codecogs.com/png.latex?P(B,%20C,%20Y)">만을 사용하여, 타겟 인과 효과 <strong><img src="https://latex.codecogs.com/png.latex?P_X(Y)"></strong>를 계산할 수 있는가?</p>
</section>
</section>
<section id="mathematical-derivations" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="mathematical-derivations"><span class="header-section-number">3</span> 3. Mathematical Derivations</h2>
<p>이 문제는 단순히 데이터를 합치는(Merge) 것으로는 해결되지 않습니다. 공통 변수가 <img src="https://latex.codecogs.com/png.latex?C">밖에 없으며, 연구 1은 실험 데이터, 연구 2는 관찰 데이터라는 성격의 차이가 있기 때문입니다. 우리는 확률 분포의 분해(Factorization) 법칙과 인과 그래프의 구조를 이용해야 합니다.</p>
<section id="step-1-target-distribution의-정의" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="step-1-target-distribution의-정의"><span class="header-section-number">3.1</span> 3.1 Step 1: Target Distribution의 정의</h3>
<p>우리가 구하고자 하는 것은 <img src="https://latex.codecogs.com/png.latex?X">에 개입했을 때 <img src="https://latex.codecogs.com/png.latex?Y">의 주변 확률 분포(Marginal Distribution)입니다. <img src="https://latex.codecogs.com/png.latex?P_x(y)%20=%20%5Csum_%7Ba,b,c%7D%20P_x(a,%20b,%20c,%20y)"></p>
</section>
<section id="step-2-c-component-factorization" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="step-2-c-component-factorization"><span class="header-section-number">3.2</span> 3.2 Step 2: C-Component Factorization</h3>
<p>인과 그래프(Figure 1)의 구조에 따라 결합 확률 분포(Joint Distribution)를 분해해 봅시다. 특히 <img src="https://latex.codecogs.com/png.latex?do(X)"> 연산이 적용된 개입 분포(Interventional Distribution) <img src="https://latex.codecogs.com/png.latex?P_x(%5Ccdot)">를 고려합니다.</p>
<p>일반적인 베이지안 네트워크 분해 법칙과 <img src="https://latex.codecogs.com/png.latex?do">-calculus의 원리에 따라, <img src="https://latex.codecogs.com/png.latex?X">로 들어오는 화살표를 제거한 그래프에서의 분해를 생각할 수 있습니다. 강의 자료의 유도 과정(Slide 8-10)에 따르면, 이 시스템은 다음과 같은 형태로 분해(Factorization)될 수 있습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?P_x(a,%20b,%20c,%20y)%20=%20P(a)%20%5Ccdot%20P_%7Ba,x%7D(b)%20%5Ccdot%20P_b(c)%20%5Ccdot%20P_c(y)"></p>
<p>이 식의 각 항이 의미하는 바는 다음과 같습니다: * <img src="https://latex.codecogs.com/png.latex?P(a)">: 나이의 분포 (외생 변수). * <img src="https://latex.codecogs.com/png.latex?P_%7Ba,x%7D(b)">: <img src="https://latex.codecogs.com/png.latex?A">와 <img src="https://latex.codecogs.com/png.latex?X">가 주어졌을 때(또는 개입했을 때) <img src="https://latex.codecogs.com/png.latex?B">의 분포. * <img src="https://latex.codecogs.com/png.latex?P_b(c)">: <img src="https://latex.codecogs.com/png.latex?B">가 주어졌을 때 <img src="https://latex.codecogs.com/png.latex?C">의 분포. * <img src="https://latex.codecogs.com/png.latex?P_c(y)">: <img src="https://latex.codecogs.com/png.latex?C">가 주어졌을 때 <img src="https://latex.codecogs.com/png.latex?Y">의 분포.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Why this factorization?</strong> 이 분해는 그래프의 <strong>c-component</strong> 구조에 기반합니다. <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이에는 직접적인(또는 confounding에 의한) 경로가 존재하지만, <img src="https://latex.codecogs.com/png.latex?A%20%5Cto%20B%20%5Cto%20C%20%5Cto%20Y">와 같은 매개 경로들이 존재합니다. 이 식은 전체 효과를 각 메커니즘의 결합으로 쪼갠 것입니다.</p>
</div>
</div>
</section>
<section id="step-3-수식의-재구성-regrouping" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="step-3-수식의-재구성-regrouping"><span class="header-section-number">3.3</span> 3.3 Step 3: 수식의 재구성 (Regrouping)</h3>
<p>이제 위에서 얻은 식을 우리가 가진 데이터 <img src="https://latex.codecogs.com/png.latex?P_X(A,%20C)">와 <img src="https://latex.codecogs.com/png.latex?P(B,%20C,%20Y)">와 연결하기 위해 <img src="https://latex.codecogs.com/png.latex?%5Csum">의 순서를 조정하여 재구성합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0AP_x(y)%20&amp;=%20%5Csum_%7Ba,b,c%7D%20P(a)%20P_%7Ba,x%7D(b)%20P_b(c)%20P_c(y)%20%5C%5C%0A&amp;=%20%5Csum_%7Ba,c%7D%20P(a)%20%5Cleft(%20%5Csum_%7Bb%7D%20P_%7Ba,x%7D(b)%20P_b(c)%20%5Cright)%20P_c(y)%0A%5Cend%7Baligned%7D%0A"></p>
<p>여기서 괄호 안의 부분 <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bb%7D%20P_%7Ba,x%7D(b)%20P_b(c)">를 살펴봅시다. 이는 <img src="https://latex.codecogs.com/png.latex?A">와 <img src="https://latex.codecogs.com/png.latex?X">가 결정되었을 때, <img src="https://latex.codecogs.com/png.latex?B">를 거쳐 <img src="https://latex.codecogs.com/png.latex?C">가 결정되는 과정의 확률, 즉 <img src="https://latex.codecogs.com/png.latex?P_%7Ba,x%7D(c)">로 해석할 수 있습니다 (Chain Rule of Intervention).</p>
<p>따라서 식은 다음과 같이 간소화됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?P_x(y)%20=%20%5Csum_%7Ba,c%7D%20P(a)%20P_%7Ba,x%7D(c)%20P_c(y)"></p>
<p>이 식은 매우 중요한 의미를 가집니다. <strong>서로 다른 출처의 정보를 결합할 수 있는 연결고리</strong>가 되기 때문입니다.</p>
</section>
</section>
<section id="mapping-to-data-sources-the-puzzle" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="mapping-to-data-sources-the-puzzle"><span class="header-section-number">4</span> 4. Mapping to Data Sources (The Puzzle)</h2>
<p>이제 최종 유도된 식의 각 구성 요소가 우리가 가진 두 개의 데이터셋 중 어디에서 올 수 있는지 확인해 봅시다.</p>
<p><img src="https://latex.codecogs.com/png.latex?P_x(y)%20=%20%5Csum_%7Ba,c%7D%20%5Cunderbrace%7BP(a)%20P_%7Ba,x%7D(c)%7D_%7B%5Ctext%7BSource%201%7D%7D%20%5Ccdot%20%5Cunderbrace%7BP_c(y)%7D_%7B%5Ctext%7BSource%202%7D%7D"></p>
<section id="source-1-experimental-study-p_xa-c" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="source-1-experimental-study-p_xa-c"><span class="header-section-number">4.1</span> 4.1 Source 1: Experimental Study (<img src="https://latex.codecogs.com/png.latex?P_X(A,%20C)">)</h3>
<p>첫 번째 데이터셋은 운동(<img src="https://latex.codecogs.com/png.latex?X">)에 개입한 실험 데이터이며 <img src="https://latex.codecogs.com/png.latex?A">와 <img src="https://latex.codecogs.com/png.latex?C">를 관측합니다. 즉, <img src="https://latex.codecogs.com/png.latex?P_X(A,%20C)"> 분포를 온전히 가지고 있습니다.</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?P(a)">: <img src="https://latex.codecogs.com/png.latex?X">는 무작위 배정되었으므로 <img src="https://latex.codecogs.com/png.latex?A">와 독립입니다. 따라서 <img src="https://latex.codecogs.com/png.latex?P_x(a)%20=%20P(a)">. 실험군 내의 나이 분포에서 얻을 수 있습니다.</li>
<li><img src="https://latex.codecogs.com/png.latex?P_%7Ba,x%7D(c)">: <img src="https://latex.codecogs.com/png.latex?A">와 <img src="https://latex.codecogs.com/png.latex?X">가 주어졌을 때 <img src="https://latex.codecogs.com/png.latex?C">의 분포입니다. 실험 데이터 <img src="https://latex.codecogs.com/png.latex?P_X(A,%20C)">에서 조건부 확률 등을 통해 도출할 수 있습니다. (엄밀히는 <img src="https://latex.codecogs.com/png.latex?P_x(c%7Ca)"> 형태)</li>
</ul>
<p>따라서 식의 앞부분 <img src="https://latex.codecogs.com/png.latex?P(a)P_%7Ba,x%7D(c)">는 <strong>연구 1</strong>에서 식별 가능합니다.</p>
</section>
<section id="source-2-observational-study-pb-c-y" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="source-2-observational-study-pb-c-y"><span class="header-section-number">4.2</span> 4.2 Source 2: Observational Study (<img src="https://latex.codecogs.com/png.latex?P(B,%20C,%20Y)">)</h3>
<p>두 번째 데이터셋은 <img src="https://latex.codecogs.com/png.latex?B,%20C,%20Y">를 관측합니다. 우리가 필요한 마지막 조각은 <img src="https://latex.codecogs.com/png.latex?P_c(y)">입니다.</p>
<ul>
<li>그래프 구조상 <img src="https://latex.codecogs.com/png.latex?C">에서 <img src="https://latex.codecogs.com/png.latex?Y">로 가는 길목에 <img src="https://latex.codecogs.com/png.latex?B">가 교란 요인으로 작용하지 않고(앞단의 변수임), <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 Confounding path는 존재하지만, <img src="https://latex.codecogs.com/png.latex?C"> 자체에 대한 개입(<img src="https://latex.codecogs.com/png.latex?P_c(y)">)을 고려할 때 <img src="https://latex.codecogs.com/png.latex?P(B,%20C,%20Y)"> 데이터 내에서 이를 추정할 수 있는 구조적 조건이 성립합니다.</li>
<li>즉, <img src="https://latex.codecogs.com/png.latex?P_c(y)">는 <strong>연구 2</strong>의 관찰 데이터로부터 복원해낼 수 있습니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-06/images/data_fusion_puzzle.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: The Puzzle of Data Fusion. 보라색 퍼즐 조각(<img src="https://latex.codecogs.com/png.latex?P_c(y)">, <img src="https://latex.codecogs.com/png.latex?P_%7Ba,x%7D(b)"> 등)과 초록색 퍼즐 조각(<img src="https://latex.codecogs.com/png.latex?P(a)">, <img src="https://latex.codecogs.com/png.latex?P_b(c)">)이 서로 다른 데이터셋에서 추출되어 하나의 완성된 그림(<img src="https://latex.codecogs.com/png.latex?P_x(y)">)을 맞추는 과정을 시각화함.</figcaption>
</figure>
</div>
</section>
<section id="final-formula" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="final-formula"><span class="header-section-number">4.3</span> 4.3 Final Formula</h3>
<p>결과적으로 우리는 타겟 효과를 다음과 같이 계산할 수 있습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?P_x(y)%20=%20%5Csum_%7Ba,c%7D%20P_x(a,%20c)%20%5Ctimes%20P_c(y)"></p>
<p>(참고: 위 식은 직관적인 매핑을 보여주며, 실제 계산 시에는 <img src="https://latex.codecogs.com/png.latex?P_c(y)">를 <img src="https://latex.codecogs.com/png.latex?P(B,C,Y)">에서 도출하기 위한 추가적인 adjustment formula가 적용될 수 있습니다. 강의 자료 Slide 10 하단에는 다음과 같은 GID 공식이 제시되어 있습니다.)</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BGID%7D%20=%20%5Csum_%7Ba,c%7D%20P_%7Bx'%7D(a)%20P_x(c%7Ca)%20%5Cleft(%20%5Csum_b%20P(y%7Cb,c)P(b)%20%5Cright)"></p>
<p>이 공식은 각 데이터 소스에서 얻을 수 있는 확률값들의 곱과 합으로 타겟 인과 효과를 완벽하게 재구성합니다.</p>
</section>
</section>
<section id="conclusions" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="conclusions"><span class="header-section-number">5</span> 5. Conclusions</h2>
<p>이번 GID-PO 프레임워크가 시사하는 바는 단순히 수식을 푸는 것 이상입니다.</p>
<ol type="1">
<li><strong>Data Fusion의 이론적 토대:</strong> 서로 다른 변수를 측정하는 이질적인 데이터셋들도, 그 기저에 있는 <strong>인과 메커니즘(Causal Mechanism)</strong>을 공유한다면 논리적으로 결합될 수 있습니다.</li>
<li><strong>데이터 과학의 새로운 패러다임:</strong> 빅데이터 시대에는 “모든 것을 측정한 스몰 데이터”보다 “부분적으로 측정한 빅 데이터”가 더 흔합니다. GID-PO는 이러한 환경에서 선택 편향(Selection Bias), 교란 편향(Confounding Bias), 그리고 데이터 결측(Missing Data) 문제를 통합적으로 해결할 수 있는 충분조건과 알고리즘을 제공합니다.</li>
<li><strong>Parsimonious Representation:</strong> 인과 그래프는 현상을 설명하는 가장 간결하고(coarse and parsimonious) 효율적인 표현 방식이며, 이를 통해 데이터 통합의 복잡성을 관리할 수 있습니다.</li>
</ol>
<hr>
<section id="appendix-checklist" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="appendix-checklist"><span class="header-section-number">5.1</span> <strong>Appendix: Checklist</strong></h3>
<p>본 포스트 작성을 위해 검토한 강의 자료 체크리스트입니다.</p>
<ul class="task-list">
<li><label><input type="checkbox" checked=""><strong>GID-PO 개념 정의</strong>: 부분 관측(Partial Observation) 하에서의 식별 가능성 문제 정의 완료.</label></li>
<li><label><input type="checkbox" checked=""><strong>Causal Graph &amp; Variables</strong>: Exercise-Stroke 예시의 변수(<img src="https://latex.codecogs.com/png.latex?A,%20X,%20B,%20C,%20Y">) 및 그래프 구조 반영 완료.</label></li>
<li><label><input type="checkbox" checked=""><strong>Data Sources</strong>: 실험 연구(<img src="https://latex.codecogs.com/png.latex?P_X(A,C)">)와 관찰 연구(<img src="https://latex.codecogs.com/png.latex?P(B,C,Y)">)의 차이 명시 완료.</label></li>
<li><label><input type="checkbox" checked=""><strong>Mathematical Derivation</strong>: <img src="https://latex.codecogs.com/png.latex?P_x(y)">의 분해 과정(Factorization) 및 단계별 유도(<img src="https://latex.codecogs.com/png.latex?%5Csum"> regrouping) 포함 완료.</label></li>
<li><label><input type="checkbox" checked=""><strong>Data Mapping</strong>: 유도된 수식의 각 항이 어느 데이터셋에서 식별 가능한지 설명 완료.</label></li>
<li><label><input type="checkbox" checked=""><strong>Visuals</strong>: 인과 그래프 및 퍼즐 비유 이미지에 대한 설명(Alt text) 포함 완료.</label></li>
<li><label><input type="checkbox" checked=""><strong>Conclusion</strong>: 인과 데이터 과학(Causal Data Science) 관점에서의 의의 서술 완료.</label></li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <category>Data Science</category>
  <category>Econometrics</category>
  <guid>https://shsha0110.github.io/posts/lecture/L17/part-06/</guid>
  <pubDate>Sat, 24 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] Missing Data &amp; Graphical Models: m-graphs</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L17/part-05/</link>
  <description><![CDATA[ 





<section id="introduction-missingness-is-a-causal-concept" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction-missingness-is-a-causal-concept"><span class="header-section-number">1</span> 1. Introduction: Missingness is a Causal Concept</h2>
<p>데이터 분석, 특히 사회과학이나 의료 데이터를 다룰 때 결측치(Missing Data)는 피할 수 없는 현실입니다. [cite_start]설문조사에서 응답자가 특정 문항을 건너뛰거나, 센서가 오작동하거나, 환자가 과거 기록을 기억하지 못하는 등 다양한 이유로 발생합니다[cite: 13, 14, 15].</p>
<p>통계학 문헌, 특히 Rubin의 선구적인 연구 이후 대부분의 결측치 처리 방식은 <strong>MAR(Missing At Random)</strong> 가정을 기반으로 합니다. [cite_start]이는 Maximum Likelihood나 Multiple Imputation의 수렴성을 보장하기 위한 필수적인 가정이지만, 실제 데이터에서 이 가정이 성립하는지 검증하는 것은 매우 어렵습니다[cite: 19, 20, 21, 23].</p>
<p>Mohan과 Pearl(2021)은 결측치 문제를 <strong>통계적 문제(Statistical Problem)가 아닌 인과적 문제(Causal Problem)</strong>로 재정의합니다. 데이터가 왜 비었는지에 대한 “이유(Reason)”는 데이터 생성 과정(Data Generating Process)의 일부이기 때문입니다. [cite_start]본 포스트에서는 그래프 모형(Graphical Models), 특히 <strong>m-graphs</strong>를 통해 결측 메커니즘을 시각화하고, 데이터의 복원 가능성(Recoverability)을 판단하는 방법을 정리합니다[cite: 31, 32].</p>
<hr>
</section>
<section id="formalism-the-m-graph" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="formalism-the-m-graph"><span class="header-section-number">2</span> 2. Formalism: The m-graph</h2>
<p>결측 데이터 문제를 그래프로 표현하기 위해, 우리는 변수를 관측 여부와 역할에 따라 분류하고 <strong>Proxy Variable</strong>이라는 개념을 도입합니다.</p>
<section id="variables-classification" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="variables-classification"><span class="header-section-number">2.1</span> 2.1. Variables Classification</h3>
<p>[cite_start]Causal DAG <img src="https://latex.codecogs.com/png.latex?G">의 노드들은 다음 다섯 가지 카테고리로 분류됩니다[cite: 115, 116]:</p>
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?U">: <strong>Latent Variables</strong> (관측되지 않는 잠재 변수)</li>
<li><img src="https://latex.codecogs.com/png.latex?V_o">: <strong>Fully Observed Variables</strong> (모든 레코드에서 관측된 변수)</li>
<li><img src="https://latex.codecogs.com/png.latex?V_m">: <strong>Missing Variables</strong> (적어도 하나의 레코드에서 결측이 발생한 변수)</li>
<li><img src="https://latex.codecogs.com/png.latex?R">: <strong>Missingness Mechanisms</strong> (결측을 유발하는 인과적 메커니즘을 나타내는 변수)</li>
<li><img src="https://latex.codecogs.com/png.latex?V%5E*">: <strong>Proxy Variables</strong> (실제로 관측된 변수)</li>
</ol>
</section>
<section id="the-proxy-variable-mechanism" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="the-proxy-variable-mechanism"><span class="header-section-number">2.2</span> 2.2. The Proxy Variable Mechanism</h3>
<p>[cite_start]변수 <img src="https://latex.codecogs.com/png.latex?X">가 결측될 수 있다면, 우리는 실제 값 <img src="https://latex.codecogs.com/png.latex?X">와 결측 여부를 결정하는 스위치 <img src="https://latex.codecogs.com/png.latex?R_X">를 통해 관측된 값 <img src="https://latex.codecogs.com/png.latex?X%5E*">를 다음과 같이 정의합니다[cite: 49, 50].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AX%5E*%20=%20f(R_X,%20X)%20=%20%5Cbegin%7Bcases%7D%0AX%20&amp;%20%5Ctext%7Bif%20%7D%20R_X%20=%200%20%5Cquad%20(%5Ctext%7BObserved%7D)%20%5C%5C%0Am%20&amp;%20%5Ctext%7Bif%20%7D%20R_X%20=%201%20%5Cquad%20(%5Ctext%7BMissing%7D)%0A%5Cend%7Bcases%7D%0A"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?m">은 결측(missing value)을 나타내는 기호입니다. [cite_start]<img src="https://latex.codecogs.com/png.latex?R_X=1">이면 변수의 값은 가려지고(masked), <img src="https://latex.codecogs.com/png.latex?R_X=0">이면 드러납니다(revealed)[cite: 54, 55].</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-05/images/basic_proxy_structure.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: 비만도(Obesity) 예시를 통한 m-graph의 기본 구조. G(성별), A(나이)는 완전히 관측되지만, O(비만도)는 결측 메커니즘 <img src="https://latex.codecogs.com/png.latex?R_O">에 의해 <img src="https://latex.codecogs.com/png.latex?O%5E*">로 관측된다.</figcaption>
</figure>
</div>
<blockquote class="blockquote">
<p><strong>Figure 1 설명</strong>: 위 그림은 학교 데이터 예시를 보여줍니다. <img src="https://latex.codecogs.com/png.latex?G">(Gender)와 <img src="https://latex.codecogs.com/png.latex?A">(Age)는 학교 기록부에 있어 완전히 관측되지만(<img src="https://latex.codecogs.com/png.latex?V_o">), <img src="https://latex.codecogs.com/png.latex?O">(Obesity)는 학생이 응답을 거부할 수 있어 결측이 발생합니다(<img src="https://latex.codecogs.com/png.latex?V_m">). [cite_start]<img src="https://latex.codecogs.com/png.latex?R_O">는 <img src="https://latex.codecogs.com/png.latex?O">가 결측될지 여부를 결정하는 변수이며, 실제로 우리가 데이터셋에서 보는 것은 <img src="https://latex.codecogs.com/png.latex?O%5E*">(<img src="https://latex.codecogs.com/png.latex?V%5E*">)입니다[cite: 39, 44, 45, 49].</p>
</blockquote>
<hr>
</section>
</section>
<section id="categories-of-missingness-in-graphs" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="categories-of-missingness-in-graphs"><span class="header-section-number">3</span> 3. Categories of Missingness in Graphs</h2>
<p>Rubin의 분류법인 MCAR, MAR, MNAR을 m-graph 상에서의 조건부 독립성(Conditional Independence)으로 명확히 정의할 수 있습니다. [cite_start]그래프 구조를 통해 데이터가 어떤 결측 유형에 속하는지 시각적으로 판별(Inspection)이 가능해집니다[cite: 34].</p>
<section id="mcar-missing-completely-at-random" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="mcar-missing-completely-at-random"><span class="header-section-number">3.1</span> 3.1. MCAR (Missing Completely At Random)</h3>
<p>결측이 완전히 무작위로 발생하는 경우입니다. [cite_start]설문지를 잃어버리는 등의 상황이 이에 해당합니다[cite: 69].</p>
<ul>
<li><strong>정의</strong>: 결측 메커니즘 <img src="https://latex.codecogs.com/png.latex?R">이 데이터의 모든 변수(<img src="https://latex.codecogs.com/png.latex?V_m,%20V_o,%20U">)와 독립입니다.</li>
<li>[cite_start]<strong>그래프 조건</strong>: <img src="https://latex.codecogs.com/png.latex?R"> 변수들과 <img src="https://latex.codecogs.com/png.latex?V_o%20%5Ccup%20V_m"> 사이에 엣지가 없습니다[cite: 138, 143].</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AV_m,%20V_o,%20U%20%5Cperp%20%5Cmathbb%7BR%7D%0A"></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-05/images/mcar_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: MCAR의 그래프 구조. <img src="https://latex.codecogs.com/png.latex?R_O">로 들어오는 화살표가 없다. 즉, 나이(A)나 성별(G), 실제 비만도(O)가 결측 여부(<img src="https://latex.codecogs.com/png.latex?R_O">)에 영향을 주지 않는다.</figcaption>
</figure>
</div>
</section>
<section id="mar-missing-at-random" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="mar-missing-at-random"><span class="header-section-number">3.2</span> 3.2. MAR (Missing At Random)</h3>
<p>결측이 <strong>완전히 관측된 변수(<img src="https://latex.codecogs.com/png.latex?V_o">)</strong>에만 의존하여 발생하는 경우입니다. [cite_start]예를 들어, 10대(<img src="https://latex.codecogs.com/png.latex?A">)들이 반항심에 몸무게를 보고하지 않는 경우 등입니다[cite: 77].</p>
<ul>
<li>[cite_start]<strong>정의</strong>: 관측된 변수 <img src="https://latex.codecogs.com/png.latex?V_o">가 주어졌을 때, 결측 메커니즘 <img src="https://latex.codecogs.com/png.latex?R">은 나머지 변수들과 독립입니다[cite: 146].</li>
<li>[cite_start]<strong>그래프 조건</strong>: (i) <img src="https://latex.codecogs.com/png.latex?R">과 부분적으로 관측된 변수(<img src="https://latex.codecogs.com/png.latex?V_m">) 사이에 엣지가 없고, (ii) <img src="https://latex.codecogs.com/png.latex?R">과 <img src="https://latex.codecogs.com/png.latex?V_o"> 사이에 양방향 엣지(bidirected edge, Latent confounder)가 없어야 합니다[cite: 147].</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AV_m,%20U%20%5Cperp%20%5Cmathbb%7BR%7D%20%5Cmid%20V_o%0A"></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-05/images/mar_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3: MAR의 그래프 구조. 나이(A)가 결측 메커니즘(<img src="https://latex.codecogs.com/png.latex?R_O">)에 영향을 준다(<img src="https://latex.codecogs.com/png.latex?A%20%5Crightarrow%20R_O">). 즉, 결측 여부는 관측된 나이에 따라 달라진다.</figcaption>
</figure>
</div>
</section>
<section id="mnar-missing-not-at-random" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="mnar-missing-not-at-random"><span class="header-section-number">3.3</span> 3.3. MNAR (Missing Not At Random)</h3>
<p>데이터가 MCAR나 MAR이 아닌 모든 경우입니다. 특히, 결측된 변수 그 자체가 결측 원인이 되는 경우가 포함됩니다. [cite_start]예를 들어, 비만인 학생(<img src="https://latex.codecogs.com/png.latex?O">)이 부끄러워서 몸무게를 숨기는 경우입니다[cite: 87, 112].</p>
<ul>
<li><strong>특징</strong>: <img src="https://latex.codecogs.com/png.latex?R"> 변수로 들어오는 화살표가 결측 변수(<img src="https://latex.codecogs.com/png.latex?V_m">)나 잠재 변수(<img src="https://latex.codecogs.com/png.latex?U">)에서 시작됩니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-05/images/mnar_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 4: MNAR의 그래프 구조. 실제 비만도(O)가 결측 여부(<img src="https://latex.codecogs.com/png.latex?R_O">)에 직접 영향을 준다(<img src="https://latex.codecogs.com/png.latex?O%20%5Crightarrow%20R_O">). 비만일수록 응답하지 않을 확률이 높아지는 메커니즘이다.</figcaption>
</figure>
</div>
<hr>
</section>
</section>
<section id="recoverability-can-we-restore-the-truth" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="recoverability-can-we-restore-the-truth"><span class="header-section-number">4</span> 4. Recoverability: Can We Restore the Truth?</h2>
<p>[cite_start]<strong>Recoverability(복원 가능성)</strong>란, 결측이 포함된 관측 데이터(<img src="https://latex.codecogs.com/png.latex?V%5E*,%20V_o,%20R">)의 분포로부터 우리가 알고 싶은 원래 분포(Target Distribution, <img src="https://latex.codecogs.com/png.latex?P(V_o,%20V_m)">)를 일관되게(consistently) 추정할 수 있는지에 대한 문제입니다[cite: 35].</p>
<section id="recoverability-of-mcar" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="recoverability-of-mcar"><span class="header-section-number">4.1</span> 4.1. Recoverability of MCAR</h3>
<p>MCAR의 경우, <img src="https://latex.codecogs.com/png.latex?R_O">는 모든 변수와 독립이므로, 데이터를 삭제(List-wise deletion)하고 남은 데이터만 써도 편향(Bias)이 없습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(G,%20O,%20A)%20=%20P(G,%20O,%20A%20%5Cmid%20R_O%20=%200)%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?R_O%20=%200">인 조건 하에서는 <img src="https://latex.codecogs.com/png.latex?O%20=%20O%5E*">이므로,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A=%20P(G,%20O%5E*,%20A%20%5Cmid%20R_O%20=%200)%0A"></p>
<p>[cite_start]즉, 관측된 데이터만으로 원래 분포를 완벽히 복원할 수 있습니다[cite: 187, 189].</p>
</section>
<section id="recoverability-of-mar" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="recoverability-of-mar"><span class="header-section-number">4.2</span> 4.2. Recoverability of MAR</h3>
<p>MAR의 경우, 단순 삭제는 편향을 낳지만, 조건부 확률을 이용해 복원할 수 있습니다. 예를 들어 <img src="https://latex.codecogs.com/png.latex?A%20%5Crightarrow%20R_O">인 상황(Figure 3)을 봅시다.</p>
<p>[cite_start]우리는 결합 확률 <img src="https://latex.codecogs.com/png.latex?P(G,%20O,%20A)">를 다음과 같이 분해(Factorization)할 수 있습니다[cite: 198]: <img src="https://latex.codecogs.com/png.latex?%0AP(G,%20O,%20A)%20=%20P(G,%20O%20%5Cmid%20A)P(A)%0A"></p>
<p>그래프에서 <img src="https://latex.codecogs.com/png.latex?A">는 <img src="https://latex.codecogs.com/png.latex?R_O">와 <img src="https://latex.codecogs.com/png.latex?%5C%7BG,%20O%5C%7D"> 사이를 <strong>d-separation</strong> 합니다. [cite_start]따라서 <img src="https://latex.codecogs.com/png.latex?R_O">에 조건을 걸어도 확률은 변하지 않습니다[cite: 199]. <img src="https://latex.codecogs.com/png.latex?%0AP(G,%20O%20%5Cmid%20A)%20=%20P(G,%20O%20%5Cmid%20A,%20R_O%20=%200)%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?R_O=0">일 때 <img src="https://latex.codecogs.com/png.latex?O=O%5E*">이므로, 최종적으로 관측 가능한 변수들로 표현됩니다: <img src="https://latex.codecogs.com/png.latex?%0AP(G,%20O,%20A)%20=%20P(G,%20O%5E*%20%5Cmid%20A,%20R_O%20=%200)P(A)%0A"></p>
<p>[cite_start]이것이 MAR 상황에서 데이터를 복원하는 핵심 논리입니다[cite: 202].</p>
</section>
<section id="the-challenge-of-mnar" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="the-challenge-of-mnar"><span class="header-section-number">4.3</span> 4.3. The Challenge of MNAR</h3>
<p>MNAR, 예를 들어 <img src="https://latex.codecogs.com/png.latex?O%20%5Crightarrow%20R_O">인 경우(Figure 4), 위와 같은 분해나 d-separation을 사용할 수 없습니다. [cite_start]<img src="https://latex.codecogs.com/png.latex?O">를 관측하지 못했는데 <img src="https://latex.codecogs.com/png.latex?O">가 결측 원인이 되므로, 일반적으로 복원이 불가능(Non-recoverable)합니다[cite: 218, 224].</p>
<p>하지만 <strong>모든 MNAR이 복원 불가능한 것은 아닙니다.</strong> m-graph 구조에 따라 MNAR임에도 복원 가능한 특수한 케이스들이 존재합니다.</p>
<hr>
</section>
</section>
<section id="advanced-recoverability-theorems" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="advanced-recoverability-theorems"><span class="header-section-number">5</span> 5. Advanced Recoverability Theorems</h2>
<p>MNAR 상황에서도 복원 가능한 조건을 다루는 두 가지 중요한 정리가 있습니다.</p>
<section id="sequential-factorization-순차적-분해" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="sequential-factorization-순차적-분해"><span class="header-section-number">5.1</span> 5.1. Sequential Factorization (순차적 분해)</h3>
<p>[cite_start]타겟 분포 <img src="https://latex.codecogs.com/png.latex?Q">를 인수분해했을 때, 각 인수가 <img src="https://latex.codecogs.com/png.latex?P(Y_i%20%7C%20X_i)"> 꼴을 띠고, 각각의 <img src="https://latex.codecogs.com/png.latex?Y_i">가 <img src="https://latex.codecogs.com/png.latex?X_i">가 주어졌을 때 자신의 결측 메커니즘 <img src="https://latex.codecogs.com/png.latex?R_%7BY_i%7D">과 독립이라면 복원 가능합니다[cite: 247].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(Y_i%20%5Cmid%20X_i)%20=%20P(Y_i%5E*%20%5Cmid%20X_i%5E*,%20R_%7BY_i%7D=0,%20R_%7BX_i%7D=0)%0A"></p>
</section>
<section id="r-factorization-theorem" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="r-factorization-theorem"><span class="header-section-number">5.2</span> 5.2. R-Factorization Theorem</h3>
<p>전체 결합 분포 <img src="https://latex.codecogs.com/png.latex?P(V)">의 복원 가능성에 대한 필요충분조건입니다. [cite_start]<img src="https://latex.codecogs.com/png.latex?R"> 변수들 간에 엣지가 없다고 가정할 때, 다음 두 조건에 해당하는 변수 <img src="https://latex.codecogs.com/png.latex?X%20%5Cin%20V_m">이 <strong>없다면</strong> 복원 가능합니다[cite: 254, 255, 256].</p>
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?R_X">가 이웃(neighbor)함.</li>
<li><img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?R_X">가 <img src="https://latex.codecogs.com/png.latex?V_m%20%5Ccup%20V_o"> 내의 collider들로만 이루어진 경로로 연결됨.</li>
</ol>
<p>[cite_start]복원 가능하다면, 분포는 다음과 같이 주어집니다[cite: 258]:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(V)%20=%20%5Cfrac%7BP(R=0,%20V%5E*)%7D%7B%5Cprod_i%20P(R_i=0%20%5Cmid%20Mb_%7BR_i%7D%5Eo,%20Mb_%7BR_i%7D%5Em,%20R_%7BMb_%7BR_i%7D%5Em%7D=0)%7D%0A"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?Mb_%7BR_i%7D">는 <img src="https://latex.codecogs.com/png.latex?R_i">의 Markov Blanket을 의미합니다.</p>
<hr>
</section>
</section>
<section id="case-study-recovering-causal-effect-pydoz" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="case-study-recovering-causal-effect-pydoz"><span class="header-section-number">6</span> 6. Case Study: Recovering Causal Effect (<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(z))">)</h2>
<p>[cite_start]마지막으로, 결측 데이터가 있는 상황에서 인과 효과(Causal Effect)를 추정하는 예제를 살펴보겠습니다[cite: 261].</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-05/images/causal_effect_recovery_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 5: Causal Effect 복원 예시 그래프. <img src="https://latex.codecogs.com/png.latex?W%20%5Crightarrow%20Z%20%5Crightarrow%20Y">의 인과 경로가 있고, <img src="https://latex.codecogs.com/png.latex?W">가 <img src="https://latex.codecogs.com/png.latex?Y">의 결측(<img src="https://latex.codecogs.com/png.latex?R_Y">)에 영향을 주며, <img src="https://latex.codecogs.com/png.latex?W">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이에 잠재적 교란 요인(dashed bidirectional edge)이 존재하는 복잡한 MNAR 상황이다.</figcaption>
</figure>
</div>
<blockquote class="blockquote">
<p><strong>Figure 5 설명</strong>: 이 그래프에서 우리는 <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(z))">를 알고 싶습니다. 하지만 <img src="https://latex.codecogs.com/png.latex?Y">에는 결측이 있고, 결측 메커니즘 <img src="https://latex.codecogs.com/png.latex?R_Y">는 <img src="https://latex.codecogs.com/png.latex?W">에 의존합니다(<img src="https://latex.codecogs.com/png.latex?W%20%5Crightarrow%20R_Y">). 또한 <img src="https://latex.codecogs.com/png.latex?W">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이에는 Confounder가 있습니다.</p>
</blockquote>
<p><strong>유도 과정:</strong></p>
<ol type="1">
<li><p><strong>Backdoor Adjustment</strong>: <img src="https://latex.codecogs.com/png.latex?W">가 <img src="https://latex.codecogs.com/png.latex?Z%20%5Crightarrow%20Y"> 관계의 confounder 역할을 하므로, <img src="https://latex.codecogs.com/png.latex?W">에 대해 조정(adjustment)을 수행합니다. <img src="https://latex.codecogs.com/png.latex?P(y%20%5Cmid%20do(z))%20=%20%5Csum_w%20P(y%20%5Cmid%20w,%20z)%20P(w)"> [cite_start]<em>(주의: 슬라이드 수식 [cite: 269]에서는 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(z))">를 바로 전개하지만, 여기서는 이해를 돕기 위해 Backdoor 기준을 적용한 형태를 풀어서 설명합니다. 슬라이드의 전개는 do-calculus와 결측 매커니즘 분해를 결합한 것입니다.)</em></p>
<p>슬라이드의 유도 과정을 따라가면: <img src="https://latex.codecogs.com/png.latex?P(y%20%5Cmid%20do(z))%20=%20P(y%20%5Cmid%20do(z),%20r_y)%20%5Cquad%20%5Ctext%7B($R_y$%EB%8A%94%20%EA%B0%9C%EC%9E%85%20%EC%9D%B4%ED%9B%84%20%EB%B3%80%EC%88%98%EA%B0%80%20%EC%95%84%EB%8B%98)%7D"></p>
<p><img src="https://latex.codecogs.com/png.latex?R_y">가 조건부에 포함되면, 우리는 <img src="https://latex.codecogs.com/png.latex?Y"> 대신 <img src="https://latex.codecogs.com/png.latex?Y%5E*">를 사용할 수 있습니다 (<img src="https://latex.codecogs.com/png.latex?Y%20=%20Y%5E*"> when <img src="https://latex.codecogs.com/png.latex?R_Y=0"> or implicit context). <img src="https://latex.codecogs.com/png.latex?=%20P(y%5E*%20%5Cmid%20do(z),%20r_y)"></p>
<p>이 확률을 <img src="https://latex.codecogs.com/png.latex?W">를 통해 분해합니다: <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_w%20P(y%5E*%20%5Cmid%20w,%20do(z),%20r_y)%20P(w%20%5Cmid%20do(z),%20r_y)"></p>
<p>그래프 상의 독립성을 활용합니다. <img src="https://latex.codecogs.com/png.latex?Z">에 개입(<img src="https://latex.codecogs.com/png.latex?do(z)">)하면 <img src="https://latex.codecogs.com/png.latex?W">에서 오는 화살표는 무시되거나, <img src="https://latex.codecogs.com/png.latex?W">가 <img src="https://latex.codecogs.com/png.latex?Z">의 부모이므로 <img src="https://latex.codecogs.com/png.latex?do(z)">와 독립일 수 있습니다. 중요한 점은 <img src="https://latex.codecogs.com/png.latex?Y%5E*">가 관측 가능해진다는 것입니다.</p>
<p>[cite_start]최종적으로 슬라이드는 다음과 같은 형태의 복원식을 제시합니다[cite: 269]: <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_w%20P(y%5E*%20%5Cmid%20w,%20z,%20r_y)%20P(w%20%5Cmid%20r_y)"></p>
<p>이 식의 의미는, <strong>결측이 있는 상태(<img src="https://latex.codecogs.com/png.latex?Y%5E*">)에서도, 결측 메커니즘(<img src="https://latex.codecogs.com/png.latex?R_Y">)과 관련된 변수(<img src="https://latex.codecogs.com/png.latex?W">)들을 적절히 통제하면 원래의 인과 효과를 계산해낼 수 있다</strong>는 것입니다.</p></li>
</ol>
<hr>
</section>
<section id="conclusion" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">7</span> 7. Conclusion</h2>
<p>이번 포스트에서는 결측 데이터 문제를 인과적 관점에서 바라보는 <strong>m-graph</strong> 프레임워크를 다뤘습니다.</p>
<ol type="1">
<li>[cite_start]<strong>Transparency</strong>: 그래프 모델은 결측의 원인(Missingness Mechanism)을 명시적으로 표현하여, MAR/MCAR 가정을 시각적으로 검증(Testability)할 수 있게 해줍니다[cite: 32, 36].</li>
<li><strong>Recoverability</strong>: 단순히 데이터를 삭제하거나 평균을 채워 넣는 것이 아니라, 그래프 구조에 기반하여 이론적으로 타당한 복원 공식을 유도할 수 있습니다.</li>
<li>[cite_start]<strong>Beyond MAR</strong>: 기존 통계학에서 다루기 어려웠던 MNAR 상황에서도, 구조적 특성을 이용해(Sequential Factorization 등) 편향 없는 추정이 가능함을 확인했습니다[cite: 24, 253].</li>
</ol>
<p>[cite_start]통계학자와 데이터 과학자는 결측치를 단순한 “전처리 대상”이 아니라, <strong>데이터 생성 과정의 일부</strong>로 보고 모델링해야 합니다[cite: 272].</p>
<hr>
<section id="누락-방지-검증-체크리스트" class="level3" data-number="7.1">
<h3 data-number="7.1" class="anchored" data-anchor-id="누락-방지-검증-체크리스트"><span class="header-section-number">7.1</span> 누락 방지 검증 체크리스트</h3>
<ul>
<li><strong>포함된 내용</strong>:
<ul class="task-list">
<li><label><input type="checkbox" checked="">결측 데이터의 동기 및 기존 방법론(Rubin)의 한계</label></li>
<li><label><input type="checkbox" checked="">m-graph의 정의 및 구성 요소 (<img src="https://latex.codecogs.com/png.latex?V%5E*,%20R"> 등)</label></li>
<li><label><input type="checkbox" checked="">MCAR, MAR, MNAR의 그래프적 정의 및 예시</label></li>
<li><label><input type="checkbox" checked="">MCAR, MAR, MNAR 상황별 복원 가능성(Recoverability) 유도 과정</label></li>
<li><label><input type="checkbox" checked="">고급 정리: Sequential Factorization, R-Factorization Theorem 수식</label></li>
<li><label><input type="checkbox" checked="">Causal Effect (<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(z))">) 복원 예제</label></li>
</ul></li>
<li><strong>생략된 내용</strong>:
<ul>
<li>슬라이드 24의 복잡한 MNAR 예제 (<img src="https://latex.codecogs.com/png.latex?Z_1,%20Z_2,%20X,%20Y">)에 대한 세부 유도 과정은 R-Factorization Theorem의 일반론으로 갈음하고, 대신 Causal Effect 예제를 상세히 다루었습니다. (흐름상 핵심 정리를 보여주는 것이 더 중요하다고 판단)</li>
<li>JASA 논문 원문의 증명(Proof) 등은 슬라이드 범위를 벗어나므로 제외했습니다.</li>
</ul></li>
</ul>
<hr>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <category>Missing Data</category>
  <category>Graphical Models</category>
  <guid>https://shsha0110.github.io/posts/lecture/L17/part-05/</guid>
  <pubDate>Sat, 24 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] Selection Bias &amp; Generalized Adjustment</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L17/part-04/</link>
  <description><![CDATA[ 





<section id="introduction-the-man-made-bias" class="level1">
<h1>1. Introduction: The “Man-Made” Bias</h1>
<p>데이터 과학에서 우리는 종종 <strong>“데이터가 스스로 말하게 하라(Let the data speak)”</strong>는 격언을 듣습니다. 하지만 데이터가 수집되는 과정에서 이미 입이 막혀 있거나, 왜곡된 목소리만 내고 있다면 어떨까요? 이것이 바로 <strong>선택 편향(Selection Bias)</strong>의 문제입니다.</p>
<p>[cite_start]선택 편향은 데이터 샘플링 과정에서 특정 개체가 우선적으로 포함되거나 배제됨으로써 발생합니다[cite: 2228]. 이는 단순한 통계적 오차를 넘어, 인과 추론의 타당성을 근본적으로 위협하는 주요 장애물입니다.</p>
<section id="confounding-vs.-selection-bias" class="level3">
<h3 class="anchored" data-anchor-id="confounding-vs.-selection-bias">Confounding vs.&nbsp;Selection Bias</h3>
<p>우리는 앞서 교란(Confounding)에 대해 다뤘습니다. [cite_start]두 편향은 근본적으로 다릅니다 [cite: 2287-2295]. * <strong>Confounding:</strong> 자연(Nature)적으로 발생하는 Treatment와 Outcome 사이의 정보 흐름(Common Cause)입니다. “치료를 받은 사람이 더 건강해서 결과가 좋은가?”의 문제입니다. * <strong>Selection Bias:</strong> 인간(Man-made)에 의해, 혹은 측정 장비에 의해 발생하는 데이터 수집 과정의 편향입니다. “특정 조건을 만족하는 사람만 설문에 응답했는가?”의 문제입니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-04/images/confounding_vs_selection.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: Confounding vs Selection Bias. 왼쪽은 Z가 X와 Y에 영향을 주는 교란(Confounding) 구조이고, 오른쪽은 X와 Y가 S(선택 여부)에 영향을 주는 선택 편향(Selection Bias) 구조이다. S=1인 샘플만 관측됨으로써 X와 Y 사이에 허위 상관관계(Spurious Correlation)가 발생한다.</figcaption>
</figure>
</div>
<p>이 포스트에서는 선택 편향이 있는 데이터(<img src="https://latex.codecogs.com/png.latex?S=1">)만 관측 가능한 상황에서, 어떻게 전체 모집단의 분포(<img src="https://latex.codecogs.com/png.latex?P(y%7Cx)">)나 인과 효과(<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">)를 복원(Recover)할 수 있는지 다룹니다.</p>
<hr>
</section>
</section>
<section id="modeling-selection-bias-with-causal-graphs" class="level1">
<h1>2. Modeling Selection Bias with Causal Graphs</h1>
<p>[cite_start]선택 편향을 수학적으로 다루기 위해 우리는 <strong>선택 노드(Selection Node) <img src="https://latex.codecogs.com/png.latex?S"></strong>를 인과 그래프에 도입합니다 [cite: 2263-2286].</p>
<ul>
<li><strong>Definition:</strong> <img src="https://latex.codecogs.com/png.latex?S">는 이진 변수로, <img src="https://latex.codecogs.com/png.latex?S=1">인 샘플만 데이터셋에 포함됩니다.</li>
<li><strong>Problem:</strong> 우리의 목표는 <img src="https://latex.codecogs.com/png.latex?S=1"> 조건부 분포 <img src="https://latex.codecogs.com/png.latex?P(v%7CS=1)">로부터, 모집단 분포 <img src="https://latex.codecogs.com/png.latex?P(v)"> 혹은 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 추정하는 것입니다.</li>
</ul>
<section id="the-origin-of-selection-bias-collider-bias" class="level3">
<h3 class="anchored" data-anchor-id="the-origin-of-selection-bias-collider-bias">The Origin of Selection Bias (Collider Bias)</h3>
<p>선택 편향은 그래프상에서 <strong>Collider</strong> 구조로 설명될 수 있습니다. 예를 들어, 두 개의 독립적인 변수 <img src="https://latex.codecogs.com/png.latex?X">(재능)와 <img src="https://latex.codecogs.com/png.latex?Y">(미모)가 있고, 이 두 가지를 모두 갖춘 사람만이 연예인이 되어 TV에 나온다(<img src="https://latex.codecogs.com/png.latex?S=1">)고 가정해 봅시다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AX%20%5Crightarrow%20S%20%5Cleftarrow%20Y%0A"></p>
<p>전체 모집단에서 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">는 독립(<img src="https://latex.codecogs.com/png.latex?X%20%5Cperp%20Y">)이지만, 우리가 관측하는 TV 속 세상(<img src="https://latex.codecogs.com/png.latex?S=1">)에서는 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이에 강한 음의 상관관계가 생깁니다(Berkson’s Paradox). 즉, 재능이 없으면 미모라도 뛰어나야 하기 때문입니다.</p>
<hr>
</section>
</section>
<section id="recoverability-without-external-information" class="level1">
<h1>3. Recoverability without External Information</h1>
<p>[cite_start]가장 먼저 던져야 할 질문은 <strong>“편향된 데이터만 가지고 편향을 제거할 수 있는가?”</strong>입니다 [cite: 2329-2345].</p>
<section id="theorem-recoverability-of-conditional-probability" class="level3">
<h3 class="anchored" data-anchor-id="theorem-recoverability-of-conditional-probability">Theorem: Recoverability of Conditional Probability</h3>
<p>우리가 구하고 싶은 분포가 <img src="https://latex.codecogs.com/png.latex?Q%20=%20P(y%7Cx)">이고, 가진 데이터가 <img src="https://latex.codecogs.com/png.latex?P(y%7Cx,%20S=1)">일 때, 복원 가능 조건은 다음과 같습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cx)%20%5Ctext%7B%20is%20recoverable%7D%20%5Ciff%20Y%20%5Cperp%20S%20%5Cmid%20X%0A"></p>
<p>즉, 그래프상에서 <img src="https://latex.codecogs.com/png.latex?X">가 주어졌을 때 <img src="https://latex.codecogs.com/png.latex?Y">와 <img src="https://latex.codecogs.com/png.latex?S">가 <strong>d-separation</strong> 되어야 합니다.</p>
<ul>
<li><strong>직관:</strong> <img src="https://latex.codecogs.com/png.latex?X">라는 조건(예: 나이)을 알면, 데이터에 선택되었는지 여부(<img src="https://latex.codecogs.com/png.latex?S">)가 결과(<img src="https://latex.codecogs.com/png.latex?Y">)에 대한 추가적인 정보를 주지 않아야 합니다. 이 경우 <img src="https://latex.codecogs.com/png.latex?P(y%7Cx)%20=%20P(y%7Cx,%20S=1)">이 성립하여, 편향된 데이터를 그대로 사용할 수 있습니다.</li>
</ul>
<hr>
</section>
</section>
<section id="recoverability-with-external-information" class="level1">
<h1>4. Recoverability with External Information</h1>
<p>만약 <img src="https://latex.codecogs.com/png.latex?Y%20%5Cperp%20S%20%5Cmid%20X"> 조건이 성립하지 않는다면 어떻게 해야 할까요? [cite_start]이때는 편향되지 않은 <strong>외부 데이터(External Data)</strong>의 도움이 필요합니다 [cite: 2346-2373].</p>
<ul>
<li><strong>Biased Data:</strong> <img src="https://latex.codecogs.com/png.latex?P(y,%20x,%20c%20%7C%20S=1)"> (풍부하지만 편향됨)</li>
<li><strong>Unbiased External Data:</strong> <img src="https://latex.codecogs.com/png.latex?P(c,%20x)"> (일부 변수에 대한 모집단 통계, 예: 인구센서스)</li>
</ul>
<section id="theorem-sufficiency-for-recoverability" class="level3">
<h3 class="anchored" data-anchor-id="theorem-sufficiency-for-recoverability">Theorem: Sufficiency for Recoverability</h3>
<p>다음 조건을 만족하는 변수 집합 <img src="https://latex.codecogs.com/png.latex?C">가 존재하면 <img src="https://latex.codecogs.com/png.latex?P(y%7Cx)">를 복원할 수 있습니다.</p>
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?Y%20%5Cperp%20S%20%5Cmid%20%5C%7BC,%20X%5C%7D"> in Graph <img src="https://latex.codecogs.com/png.latex?G"></li>
<li><img src="https://latex.codecogs.com/png.latex?P(C,%20X)"> is estimable (외부 데이터 존재)</li>
</ol>
<p>[cite_start]이때 복원 공식은 다음과 같습니다[cite: 2361]:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cx)%20=%20%5Csum_%7Bc%7D%20P(y%7Cx,%20c,%20S=1)%20P(c%7Cx)%0A"></p>
<ul>
<li><strong>해석:</strong> <img src="https://latex.codecogs.com/png.latex?C">라는 변수(예: 지역, 소득)를 통해 선택 편향의 고리를 끊을 수 있다면, 편향된 데이터에서 <img src="https://latex.codecogs.com/png.latex?C">별 <img src="https://latex.codecogs.com/png.latex?Y">의 분포를 구하고(<img src="https://latex.codecogs.com/png.latex?P(y%7Cx,c,S=1)">), 이를 외부 데이터의 <img src="https://latex.codecogs.com/png.latex?C"> 분포(<img src="https://latex.codecogs.com/png.latex?P(c%7Cx)">)로 가중 평균(Re-weighting)하여 모집단 분포를 재구성합니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-04/images/recoverability_external_c.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: 외부 정보를 이용한 복원 가능성 판단 예시. C={W1, W2}를 조건부로 했을 때 S와 Y가 독립이 된다면(d-separation), 외부의 P(W1, W2) 데이터를 이용하여 편향을 제거할 수 있다. 반면 C가 S와 Y 사이의 경로를 차단하지 못하면 복원 불가능하다.</figcaption>
</figure>
</div>
<hr>
</section>
</section>
<section id="generalized-adjustment-criterion" class="level1">
<h1>5. Generalized Adjustment Criterion</h1>
<p>이제 가장 일반적이고 강력한 시나리오를 다룹니다. 현실의 데이터는 <strong>교란(Confounding)과 선택 편향(Selection Bias)이 동시에 존재</strong>합니다. [cite_start]우리는 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 구하기 위해 이 두 마리 토끼를 동시에 잡아야 합니다 [cite: 2428-2462].</p>
<section id="definition-generalized-adjustment-set" class="level3">
<h3 class="anchored" data-anchor-id="definition-generalized-adjustment-set">Definition: Generalized Adjustment Set</h3>
<p>[cite_start]변수 집합 <img src="https://latex.codecogs.com/png.latex?(Z,%20Z%5ET)">가 다음 세 가지 조건을 만족하면, 이를 통해 인과 효과를 식별할 수 있습니다 [cite: 2456-2461]. 여기서 <img src="https://latex.codecogs.com/png.latex?Z%5ET%20%5Csubseteq%20Z">는 편향 없이 측정 가능한 외부 데이터가 있는 부분집합입니다.</p>
<ol type="1">
<li><strong>Causal Path protection:</strong> <img src="https://latex.codecogs.com/png.latex?Z">는 <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Y">로 가는 어떠한 적절한 인과 경로(Proper Causal Path)도 차단해서는 안 됩니다. (과도한 통제 방지)</li>
<li><strong>Back-door Blocking:</strong> <img src="https://latex.codecogs.com/png.latex?Z%20%5Ccup%20%5C%7BS%5C%7D">는 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 모든 <strong>비인과적 경로(Non-causal paths)</strong>를 차단해야 합니다. (교란 제거)</li>
<li><strong>Selection Blocking:</strong> <img src="https://latex.codecogs.com/png.latex?Z%5ET">는 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 인과 경로가 끊어진 그래프에서, <img src="https://latex.codecogs.com/png.latex?Y">와 <img src="https://latex.codecogs.com/png.latex?S">를 d-separation 시켜야 합니다. (선택 편향 제거)</li>
</ol>
</section>
<section id="the-generalized-adjustment-formula" class="level3">
<h3 class="anchored" data-anchor-id="the-generalized-adjustment-formula">The Generalized Adjustment Formula</h3>
<p>[cite_start]위 조건이 만족될 때, 인과 효과는 다음과 같이 계산됩니다[cite: 2472]:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(y%7Cx,%20z,%20S=1)%20P(z%20%5Csetminus%20z%5ET%20%7C%20z%5ET,%20S=1)%20P(z%5ET)%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?P(y%7Cx,%20z,%20S=1)">: 편향된 데이터에서 추정한 모형.</li>
<li><img src="https://latex.codecogs.com/png.latex?P(z%20%5Csetminus%20z%5ET%20%7C%20z%5ET,%20S=1)">: 편향된 데이터에서 <img src="https://latex.codecogs.com/png.latex?Z"> 내부 변수 간의 관계.</li>
<li><img src="https://latex.codecogs.com/png.latex?P(z%5ET)">: 외부에서 가져온 편향 없는 모집단 데이터.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-04/images/generalized_adjustment_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3: Generalized Adjustment 예시. 교란 요인과 선택 편향 메커니즘이 복잡하게 얽힌 그래프에서, 적절한 Z 집합(일부는 biased, 일부는 external)을 찾아내어 인과 효과를 계산하는 과정을 보여준다.</figcaption>
</figure>
</div>
<p>이 공식은 기존의 Back-door Adjustment Formula (<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))%20=%20%5Csum_z%20P(y%7Cx,z)P(z)">)를 선택 편향이 있는 상황으로 확장한 것입니다. <img src="https://latex.codecogs.com/png.latex?S=1"> 조건이 붙은 항들과 외부 데이터 <img src="https://latex.codecogs.com/png.latex?P(z%5ET)">가 결합되는 형태를 주목하세요.</p>
<hr>
</section>
</section>
<section id="summary-the-power-of-causal-data-science" class="level1">
<h1>6. Summary: The Power of Causal Data Science</h1>
<p>이번 포스트를 통해 우리는 데이터 과학의 난제인 <strong>선택 편향</strong>을 인과 그래프를 통해 체계적으로 해결하는 방법을 배웠습니다.</p>
<ol type="1">
<li><strong>Problem Identification:</strong> 선택 편향은 데이터 수집 과정의 인과 구조(<img src="https://latex.codecogs.com/png.latex?S"> 노드)로 모델링됩니다.</li>
<li><strong>Pure Recoverability:</strong> 외부 데이터 없이도 <img src="https://latex.codecogs.com/png.latex?Y%20%5Cperp%20S%20%7C%20X"> 조건이 만족되면 복원 가능합니다.</li>
<li><strong>External Data Fusion:</strong> 외부 데이터(<img src="https://latex.codecogs.com/png.latex?P(c)">)가 있다면, 이를 연결고리(Re-weighting bridge)로 사용하여 복원할 수 있습니다.</li>
<li><strong>Generalized Adjustment:</strong> 교란과 선택 편향이 섞여 있어도, <strong>Generalized Adjustment Criterion</strong>을 통해 올바른 통제 변수 집합(<img src="https://latex.codecogs.com/png.latex?Z">)과 외부 데이터(<img src="https://latex.codecogs.com/png.latex?Z%5ET">)를 찾아내어 인과 효과를 편향 없이 추정할 수 있습니다.</li>
</ol>
<p>[cite_start]Bareinboim과 Tian 등의 연구에 따르면, 이 알고리즘들은 <strong>완전(Complete)</strong>합니다[cite: 2477]. 즉, 이 방법으로 복원할 수 없다면, 주어진 가정하에서는 그 어떤 방법으로도 편향을 제거하는 것이 불가능하다는 뜻입니다.</p>
<hr>
<section id="appendix-verification-checklist" class="level3">
<h3 class="anchored" data-anchor-id="appendix-verification-checklist"><strong>Appendix: Verification Checklist</strong></h3>
<ul>
<li><strong>포함된 내용:</strong>
<ul class="task-list">
<li><label><input type="checkbox" checked="">선택 편향의 정의 (Preferential inclusion) 및 Confounding과의 차이점 비교</label></li>
<li><label><input type="checkbox" checked="">선택 노드(S)를 포함한 인과 그래프 모델링</label></li>
<li><label><input type="checkbox" checked="">외부 정보 없는 복원 가능성 조건 (<img src="https://latex.codecogs.com/png.latex?Y%20%5Cperp%20S%20%7C%20X">) 및 정리(Theorem)</label></li>
<li><label><input type="checkbox" checked="">외부 정보(<img src="https://latex.codecogs.com/png.latex?P(c,x)">)를 이용한 복원 가능성(Sufficiency) 및 복원 공식 유도</label></li>
<li><label><input type="checkbox" checked="">Confounding과 Selection Bias가 동시에 존재하는 상황 (Generalized Adjustment)</label></li>
<li><label><input type="checkbox" checked="">Generalized Adjustment Criterion의 3가지 조건 상세 서술</label></li>
<li><label><input type="checkbox" checked="">Generalized Adjustment Formula (<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">)의 LaTeX 수식 정확한 재현</label></li>
<li><label><input type="checkbox" checked="">주요 도표(Origin of Bias, Recoverability examples)에 대한 Placeholder 및 캡션</label></li>
</ul></li>
<li><strong>생략된 내용:</strong>
<ul>
<li>강의 자료 마지막 부분의 Odds Ratio 관련 내용은 Selection Bias의 통계적 변형(Statistical Variant)으로 소개되었으나, 인과 추론(Causal Inference)의 핵심 흐름인 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))"> 복원에 집중하기 위해 본문에서는 간략히 언급하거나 생략하고 Recoverability Theorem에 집중함.</li>
</ul></li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <category>Data Science</category>
  <category>Methodology</category>
  <guid>https://shsha0110.github.io/posts/lecture/L17/part-04/</guid>
  <pubDate>Sat, 24 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] Transportability &amp; External Validity</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L17/part-03/</link>
  <description><![CDATA[ 





<section id="introduction-moving-from-lab-to-real-world" class="level1">
<h1>1. Introduction: Moving from Lab to Real-World</h1>
<p>[cite_start]데이터 과학과 인과 추론에서 가장 빈번하면서도 어려운 질문 중 하나는 <strong>“어떤 환경(Source)에서 얻은 지식을 다른 환경(Target)에 적용할 수 있는가?”</strong>입니다[cite: 1512].</p>
<p>예를 들어: * [cite_start]미국의 교육 정책 효과를 한국에 그대로 적용할 수 있는가? [cite: 1513] * [cite_start]LA에서 수행된 임상 시험 결과를 NYC의 환자들에게 적용할 수 있는가? [cite: 1594] * [cite_start]통제된 실험실 환경(Lab)의 로봇 학습 데이터를 실제 도로(Real-World)에 쓸 수 있는가? [cite: 1524]</p>
<p>[cite_start]이 문제는 사회과학에서는 <strong>외부 타당성(External Validity)</strong>, 통계학에서는 <strong>일반화(Generalizability)</strong>, 머신러닝에서는 <strong>도메인 적응(Domain Adaptation)</strong> 등으로 불려왔습니다 [cite: 1517-1521].</p>
<p><strong>Causal Data Science</strong>는 이 문제를 <strong>Transportability(이송 가능성)</strong>라는 수학적 프레임워크로 정의하고, <strong>Selection Diagram</strong>이라는 도구를 통해 데이터가 언제, 어떻게 이송 가능한지를 공식화합니다.</p>
<hr>
</section>
<section id="the-transportability-problem" class="level1">
<h1>2. The Transportability Problem</h1>
<p>우리의 목표는 Source Domain(<img src="https://latex.codecogs.com/png.latex?%5CPi">)에서 수집된 관찰(<img src="https://latex.codecogs.com/png.latex?P">) 및 실험(<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">) 데이터를 사용하여, Target Domain(<img src="https://latex.codecogs.com/png.latex?%5CPi%5E*">)에서의 인과 효과 <img src="https://latex.codecogs.com/png.latex?Q%20=%20P%5E*(y%7Cdo(x))">를 계산하는 것입니다.</p>
<section id="trivial-vs.-non-trivial-cases" class="level3">
<h3 class="anchored" data-anchor-id="trivial-vs.-non-trivial-cases">2.1. Trivial vs.&nbsp;Non-Trivial Cases</h3>
<p>가장 단순한 가정(<img src="https://latex.codecogs.com/png.latex?H_0">)은 Source와 Target의 모든 조건이 동일하다는 것입니다. [cite_start]이 경우 결과는 자명하게 이송 가능합니다(Trivially Transportable) [cite: 1543-1544].</p>
<p>하지만 현실(<img src="https://latex.codecogs.com/png.latex?H_a">)에서는 두 도메인 간에 차이가 존재합니다. * <strong>분포의 차이:</strong> <img src="https://latex.codecogs.com/png.latex?f_z%20%5Cneq%20f%5E*_z"> (예: LA와 NYC의 연령 분포가 다름) * <strong>메커니즘의 차이:</strong> <img src="https://latex.codecogs.com/png.latex?f_y%20%5Cneq%20f%5E*_y"> (예: 동일한 치료제라도 인종적 특성에 따라 반응률이 다름)</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-03/images/transportability_spectrum.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: Source Domain과 Target Domain의 차이. 모든 구조적 방정식(Structural Equations) f가 동일하다면(H0) 문제는 간단하지만, 현실(Ha)에서는 변수들의 분포나 메커니즘이 다르다. 이를 ’Spectrum’으로 표현할 수 있다.</figcaption>
</figure>
</div>
<p>[cite_start]위 그림(Figure 1)은 Source와 Target 사이에 구조적 불일치가 존재할 때, 단순한 데이터 결합이 불가능함을 보여줍니다 [cite: 1570-1592].</p>
<hr>
</section>
</section>
<section id="selection-diagrams-encoding-differences" class="level1">
<h1>3. Selection Diagrams: Encoding Differences</h1>
<p>[cite_start]도메인 간의 차이를 체계적으로 표현하기 위해 Pearl과 Bareinboim은 <strong>Selection Diagram</strong>을 도입했습니다 [cite: 1671-1689].</p>
<section id="definition" class="level3">
<h3 class="anchored" data-anchor-id="definition">Definition</h3>
<p>Selection Diagram은 기존의 Causal Graph <img src="https://latex.codecogs.com/png.latex?G">에 <strong>Selection Node (<img src="https://latex.codecogs.com/png.latex?S">)</strong>를 추가한 확장된 그래프입니다. * <strong>Selection Node (ㅁ, Yellow Square):</strong> 특정 변수의 메커니즘이 도메인 간에 차이가 있음을 나타냅니다. * 만약 변수 <img src="https://latex.codecogs.com/png.latex?V">에 대해 <img src="https://latex.codecogs.com/png.latex?f_V%20%5Cneq%20f%5E*_V">라면, <img src="https://latex.codecogs.com/png.latex?S%20%5Cto%20V"> 화살표를 추가합니다. * 반대로, <img src="https://latex.codecogs.com/png.latex?S">가 가리키지 않는 변수는 도메인 간에 메커니즘이 동일(Invariant)하다고 가정합니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-03/images/selection_diagram_definition.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: Selection Diagram의 예시. 상단 그래프(G)는 일반적인 인과 그래프이고, 하단 우측 그래프(D)는 Selection Diagram이다. Z와 Y에 노란색 사각형(Selection Node)이 화살표를 보내고 있다. 이는 Z의 분포와 Y를 결정하는 메커니즘이 도메인 간에 다르다는 것을 의미한다. 반면 X와 W는 Selection Node가 없으므로 두 도메인에서 동일한 메커니즘을 가진다.</figcaption>
</figure>
</div>
<hr>
</section>
</section>
<section id="deriving-transport-formulas" class="level1">
<h1>4. Deriving Transport Formulas</h1>
<p>Selection Diagram을 사용하면, 타겟 도메인의 데이터를 사용하지 않고도(혹은 일부만 사용하여) 타겟의 인과 효과를 계산하는 <strong>Transport Formula</strong>를 유도할 수 있습니다. [cite_start]그래프 구조(Causal Story)에 따라 공식이 달라지는 세 가지 사례를 살펴보겠습니다 [cite: 1623-1670].</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-03/images/three_transportability_cases.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3: 세 가지 다른 인과 구조에 따른 Transportability. (a) Z가 교란 변수(Confounder)인 경우, (b) Z가 결과의 결과(Outcome’s outcome)인 경우, (c) Z가 매개 변수(Mediator)인 경우. 각 경우마다 Selection Node(노란색 사각형)의 위치가 다르며, 이에 따라 유도되는 공식도 다르다.</figcaption>
</figure>
</div>
<section id="case-a-z-represents-age-confounder" class="level3">
<h3 class="anchored" data-anchor-id="case-a-z-represents-age-confounder">Case (a): Z represents Age (Confounder)</h3>
<ul>
<li><strong>Scenario:</strong> <img src="https://latex.codecogs.com/png.latex?Z">(나이)는 <img src="https://latex.codecogs.com/png.latex?X">(치료)와 <img src="https://latex.codecogs.com/png.latex?Y">(결과) 모두에 영향을 미치는 교란 요인입니다. 나이 분포(<img src="https://latex.codecogs.com/png.latex?P(z)">)는 도메인마다 다릅니다(<img src="https://latex.codecogs.com/png.latex?S%20%5Cto%20Z">).</li>
<li><strong>Formula:</strong> <img src="https://latex.codecogs.com/png.latex?P%5E*(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(y%7Cdo(x),%20z)%20P%5E*(z)"></li>
<li><strong>Interpretation:</strong> Source에서 <img src="https://latex.codecogs.com/png.latex?Z">별 인과 효과(<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x),z)">)를 구한 뒤, 이를 Target의 나이 분포(<img src="https://latex.codecogs.com/png.latex?P%5E*(z)">)에 맞춰 가중 평균(Re-weighting)합니다. 이것이 표준적인 <strong>Adjustment Formula</strong>입니다.</li>
</ul>
</section>
<section id="case-b-z-represents-language-skill-proxy" class="level3">
<h3 class="anchored" data-anchor-id="case-b-z-represents-language-skill-proxy">Case (b): Z represents Language Skill (Proxy)</h3>
<ul>
<li><strong>Scenario:</strong> <img src="https://latex.codecogs.com/png.latex?Z">(언어 능력)는 <img src="https://latex.codecogs.com/png.latex?Y">의 결과물일 뿐, <img src="https://latex.codecogs.com/png.latex?X">나 <img src="https://latex.codecogs.com/png.latex?Y">의 원인이 아닙니다. <img src="https://latex.codecogs.com/png.latex?Z">의 메커니즘이 도메인마다 다릅니다.</li>
<li><strong>Formula:</strong> <img src="https://latex.codecogs.com/png.latex?P%5E*(y%7Cdo(x))%20=%20P(y%7Cdo(x))"></li>
<li><strong>Interpretation:</strong> <img src="https://latex.codecogs.com/png.latex?Z">는 인과 경로에 개입하지 않으므로, <img src="https://latex.codecogs.com/png.latex?Z">의 차이는 <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Y"> 효과에 영향을 주지 않습니다. 즉, Source의 결과를 그대로 Target에 적용할 수 있습니다.</li>
</ul>
</section>
<section id="case-c-z-represents-bio-marker-mediator" class="level3">
<h3 class="anchored" data-anchor-id="case-c-z-represents-bio-marker-mediator">Case (c): Z represents Bio-marker (Mediator)</h3>
<ul>
<li><strong>Scenario:</strong> <img src="https://latex.codecogs.com/png.latex?Z">는 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 매개 변수입니다. <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Z">에 미치는 영향은 동일하지만, <img src="https://latex.codecogs.com/png.latex?Z">의 기저 분포나 측정 방식이 다를 수 있습니다(<img src="https://latex.codecogs.com/png.latex?S%20%5Cto%20Z">).</li>
<li><strong>Formula:</strong> <img src="https://latex.codecogs.com/png.latex?P%5E*(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(y%7Cdo(x),%20z)%20P%5E*(z%7Cx)"></li>
<li><strong>Interpretation:</strong> <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Z"> 메커니즘이 다르다면, Target 도메인에서의 조건부 확률 <img src="https://latex.codecogs.com/png.latex?P%5E*(z%7Cx)"> 정보를 사용하여 보정해야 합니다.</li>
</ul>
<hr>
</section>
</section>
<section id="general-transportability-data-fusion-from-multiple-domains" class="level1">
<h1>5. General Transportability: Data Fusion from Multiple Domains</h1>
<p>[cite_start]더 복잡한 시나리오는 여러 Source Domain(<img src="https://latex.codecogs.com/png.latex?%5CPi%5Ea,%20%5CPi%5Eb,%20%5Cdots">)에서 부분적인 실험 데이터만 존재할 때, 이를 결합(Data Fusion)하여 Target(<img src="https://latex.codecogs.com/png.latex?%5CPi%5E*">)을 추론하는 것입니다 [cite: 1734-1774].</p>
<section id="motivation-the-la-nyc-example" class="level3">
<h3 class="anchored" data-anchor-id="motivation-the-la-nyc-example">Motivation: The LA &amp; NYC Example</h3>
<ul>
<li><strong>Target:</strong> <img src="https://latex.codecogs.com/png.latex?Q%20=%20P%5E*(y%7Cdo(x))"></li>
<li><strong>Source A (LA):</strong> <img src="https://latex.codecogs.com/png.latex?X">에 대한 실험 가능. 하지만 <img src="https://latex.codecogs.com/png.latex?Z%20%5Cto%20Y"> 메커니즘이 Target과 다름.</li>
<li><strong>Source B (NYC):</strong> <img src="https://latex.codecogs.com/png.latex?Z">에 대한 실험 가능. 하지만 <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Z"> 메커니즘이 Target과 다름.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-03/images/multi_domain_fusion.png" class="img-fluid figure-img"></p>
<figcaption>Figure 4: 다중 도메인 데이터 융합(Data Fusion). 좌측 그래프는 Source A(LA)로 Z-&gt;Y 메커니즘에 차이가 있고(Selection Node on Y), 우측 그래프는 Source B(NYC)로 X-&gt;Z 메커니즘에 차이가 있다(Selection Node on Z). 목표는 이 두 불완전한 소스를 결합하여 Target의 효과를 추정하는 것이다.</figcaption>
</figure>
</div>
</section>
<section id="derivation-steps" class="level3">
<h3 class="anchored" data-anchor-id="derivation-steps">Derivation Steps</h3>
<p>우리는 <strong>do-calculus</strong>를 사용하여 Target Query를 Source들의 조합으로 변환합니다.</p>
<ol type="1">
<li><p><strong>Definition &amp; c-component Decomposition:</strong> <img src="https://latex.codecogs.com/png.latex?P%5E*(y%7Cdo(x))%20=%20%5Csum_z%20P%5E*(y%7Cdo(x),%20z)%20P%5E*(z%7Cdo(x))"> 그래프 구조상 <img src="https://latex.codecogs.com/png.latex?P%5E*(y%7Cdo(x),%20z)%20=%20P%5E*(y%7Cdo(z))"> (Rule 2), <img src="https://latex.codecogs.com/png.latex?P%5E*(z%7Cdo(x))%20=%20P%5E*(z%7Cx)"> (Rule 2) 등을 적용합니다.</p></li>
<li><p><strong>Mapping to Sources:</strong></p>
<ul>
<li>Target의 <img src="https://latex.codecogs.com/png.latex?Z%20%5Cto%20Y"> 관계(<img src="https://latex.codecogs.com/png.latex?P%5E*(y%7Cdo(z))">)는 Source B(NYC)와 공유됩니다(Source A는 <img src="https://latex.codecogs.com/png.latex?Y">에 Selection Node가 있어 불가). <img src="https://latex.codecogs.com/png.latex?%5Crightarrow%20P%5E%7B(b)%7D(y%7Cdo(z))"></li>
<li>Target의 <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Z"> 관계(<img src="https://latex.codecogs.com/png.latex?P%5E*(z%7Cdo(x))">)는 Source A(LA)와 공유됩니다(Source B는 <img src="https://latex.codecogs.com/png.latex?Z">에 Selection Node가 있어 불가). <img src="https://latex.codecogs.com/png.latex?%5Crightarrow%20P%5E%7B(a)%7D(z%7Cdo(x))"></li>
</ul></li>
<li><p><strong>Final Transport Formula:</strong> <img src="https://latex.codecogs.com/png.latex?P%5E*(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P%5E%7B(b)%7D(y%7Cdo(z))%20P%5E%7B(a)%7D(z%7Cdo(x))"></p></li>
</ol>
<p>이 공식은 <strong>LA에서 얻은 <img src="https://latex.codecogs.com/png.latex?X">의 효과</strong>와 <strong>NYC에서 얻은 <img src="https://latex.codecogs.com/png.latex?Z">의 효과</strong>를 수학적으로 결합하여, <strong>두 도시 어디에서도 직접 실험하지 않은 전체 인과 효과</strong>를 계산해 낸 것입니다.</p>
<hr>
</section>
</section>
<section id="conclusion-is-the-gold-standard-golden" class="level1">
<h1>6. Conclusion: Is the Gold Standard Golden?</h1>
<p>무작위 대조군 실험(RCT)은 인과 추론의 “Gold Standard”로 여겨집니다. [cite_start]하지만 Transportability 이론은 RCT조차 완벽하지 않음을 시사합니다 [cite: 1775-1802].</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L17/part-03/images/rct_limitations.png" class="img-fluid figure-img"></p>
<figcaption>Figure 5: RCT의 한계. 랜덤화(Randomization)는 X로 들어오는 화살표를 제거(우측 그래프)하여 교란을 없애주지만, 환경적 차이를 나타내는 Selection Node(상단 노란 사각형)는 제거하지 못한다. 즉, RCT는 내부 타당성(Internal Validity)만 보장할 뿐, 외부 타당성(External Validity)은 별도의 문제이다.</figcaption>
</figure>
</div>
<ul>
<li>[cite_start]<strong>Lesson:</strong> 완벽한 RCT 데이터가 있더라도, 모집단 간의 차이(Selection Node)가 존재한다면 반드시 <strong>Transportability Exercise</strong>를 거쳐야 합니다 [cite: 1800-1801].</li>
<li><strong>Completeness:</strong> 다행히도, Selection Diagram과 do-calculus를 이용한 이송 알고리즘은 <strong>완전(Complete)</strong>합니다. [cite_start]즉, 이 방법으로 이송 공식을 유도할 수 없다면, 해당 데이터만으로는 이론적으로 타겟 효과를 식별할 수 없음이 증명된 것입니다[cite: 1806].</li>
</ul>
<hr>
<section id="appendix-verification-checklist" class="level3">
<h3 class="anchored" data-anchor-id="appendix-verification-checklist"><strong>Appendix: Verification Checklist</strong></h3>
<ul>
<li><strong>포함된 내용:</strong>
<ul class="task-list">
<li><label><input type="checkbox" checked="">Transportability의 정의 및 필요성 (Shadish et al., Manski 인용)</label></li>
<li><label><input type="checkbox" checked="">Source vs Target Domain의 차이 (<img src="https://latex.codecogs.com/png.latex?H_0"> vs <img src="https://latex.codecogs.com/png.latex?H_a">)</label></li>
<li><label><input type="checkbox" checked="">Selection Diagram의 정의 및 Selection Node (<img src="https://latex.codecogs.com/png.latex?%5Csquare%20%5Cto%20V">) 설명</label></li>
<li><label><input type="checkbox" checked="">3가지 케이스(Age, Language, Bio-marker)에 따른 Transport Formula 유도 및 해석</label></li>
<li><label><input type="checkbox" checked="">다중 도메인(LA, NYC)에서의 Data Fusion 예시 및 수식 유도</label></li>
<li><label><input type="checkbox" checked="">RCT의 한계(“Is the Gold Standard Golden?”)와 Transportability의 필요성</label></li>
<li><label><input type="checkbox" checked="">Transportability 알고리즘의 Completeness 언급</label></li>
<li><label><input type="checkbox" checked="">주요 수식 LaTeX 처리 및 Figure Placeholder 삽입</label></li>
</ul></li>
<li><strong>생략된 내용:</strong>
<ul>
<li>Slide 28의 복잡한 알고리즘 의사코드(Pseudocode)는 텍스트로 설명하기보다 핵심 원리(Factorization &amp; Mapping) 위주로 서술함.</li>
<li>Meta-Analysis의 구체적인 통계적 기법은 다루지 않고, Transportability가 그 이론적 배경이 된다는 점만 언급함(Slide 33 참조).</li>
</ul></li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <category>Data Science</category>
  <category>Methodology</category>
  <guid>https://shsha0110.github.io/posts/lecture/L17/part-03/</guid>
  <pubDate>Sat, 24 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 02. Causal Models and Graphs (Part 2)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L02/part-02/</link>
  <description><![CDATA[ 





<section id="introduction-why-causal-models" class="level1">
<h1>1. Introduction: Why Causal Models?</h1>
<p>기존의 통계학이나 머신러닝의 추론(Inference)은 주로 <strong>결합 확률 분포(Joint Distribution)</strong> <img src="https://latex.codecogs.com/png.latex?P(v)">를 파악하는 데 집중합니다. [cite_start]“고객이 A를 샀을 때 B도 살 확률은?”(<img src="https://latex.codecogs.com/png.latex?P(B%7CA)">)과 같은 질문은 데이터의 상관관계(Association)만으로도 충분히 답할 수 있습니다. [cite: 2412-2419]</p>
<p>하지만 “가격을 두 배로 올리면 판매량은 어떻게 변할까?”와 같은 <strong>개입(Intervention)</strong>이나 반사실적(Counterfactual) 질문에 답하기 위해서는 데이터 그 자체(<img src="https://latex.codecogs.com/png.latex?P">)를 넘어, 데이터가 생성되는 <strong>현실의 메커니즘(Reality)</strong>을 이해해야 합니다. [cite_start]이를 위해 우리는 <strong>구조적 인과 모델(Structural Causal Model, SCM)</strong>이라는 새로운 언어를 배웁니다. [cite: 2421-2449]</p>
<section id="motivation-simpsons-paradox-example" class="level2">
<h2 class="anchored" data-anchor-id="motivation-simpsons-paradox-example">1.1 Motivation: Simpson’s Paradox Example</h2>
<p>[cite_start]강의에서는 의사결정의 어려움을 보여주기 위해 가상의 전염병과 치료제 시나리오를 제시합니다. [cite: 2236-2246]</p>
<ul>
<li><strong>상황</strong>: 특정 도시에 전염병이 돌고 있고, 치료제(Drug)가 있습니다.</li>
<li><strong>숨겨진 진실(Reality - Unknown to physicians)</strong>:
<ol type="1">
<li><strong>부유층(Rich)</strong>: 생활 환경이 좋아 약물 복용 여부와 상관없이 생존합니다.</li>
<li><strong>빈곤층(Poor)</strong>:
<ul>
<li>유전 인자(Gene)가 없는 경우: 자연 치유력이 없어 사망합니다.</li>
<li>유전 인자가 있는 경우: 약을 먹으면 알레르기 반응으로 사망하고, 안 먹으면 생존합니다.</li>
</ul></li>
<li><strong>현재 처방 관행</strong>: 약값이 비싸서 의사들은 부유층에게만 약을 처방합니다.</li>
</ol></li>
</ul>
<p>이 상황에서 데이터만 관측하면(<img src="https://latex.codecogs.com/png.latex?P(r,%20d,%20a)">), 약을 먹은 사람(주로 부유층)은 생존율이 높고, 안 먹은 사람(주로 빈곤층)은 생존율이 낮게 나옵니다. 머신러닝 모델은 “약을 먹는 것이 생존에 유리하다”고 잘못된 결론을 내릴 수 있습니다. [cite_start]하지만 실제 메커니즘(SCM)을 안다면, <strong>“누구에게도 약을 주지 말아야 한다(빈곤층에게는 치명적, 부유층에게는 무의미)”</strong>는 정반대의 결론에 도달합니다. [cite: 2340-2402]</p>
<p>즉, 데이터(<img src="https://latex.codecogs.com/png.latex?P">)는 현실(<img src="https://latex.codecogs.com/png.latex?M">)의 그림자일 뿐이며, 올바른 인과 추론을 위해서는 <img src="https://latex.codecogs.com/png.latex?M">을 모델링해야 합니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-02/images/inference_paradigm.png" class="img-fluid figure-img"></p>
<figcaption>Figure: 기존 통계적 추론과 인과 추론의 패러다임 비교. 통계적 추론은 데이터 P 내에서의 성질 Q(P)를 찾지만, 인과 추론은 데이터 생성 모델 M을 통해 현실을 이해하고 P’를 추정한다.</figcaption>
</figure>
</div>
<hr>
</section>
</section>
<section id="structural-causal-model-scm" class="level1">
<h1>2. Structural Causal Model (SCM)</h1>
<p>인과 관계를 수학적으로 정의하기 위해 SCM을 도입합니다. SCM은 현실의 메커니즘을 <strong>결정론적 함수</strong>와 <strong>확률적 노이즈</strong>의 결합으로 표현합니다.</p>
<section id="definition" class="level2">
<h2 class="anchored" data-anchor-id="definition">2.1 Definition</h2>
<p>[cite_start]SCM <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BM%7D">은 4개의 요소 <img src="https://latex.codecogs.com/png.latex?%5Clangle%20V,%20U,%20F,%20P(U)%20%5Crangle">로 구성된 튜플입니다. [cite: 2548-2554]</p>
<ol type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?V%20=%20%5C%7BV_1,%20...,%20V_n%5C%7D"> (Endogenous Variables)</strong>: 모델 내부에서 결정되며, 우리가 관측할 수 있는 변수들입니다.</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?U%20=%20%5C%7BU_1,%20...,%20U_m%5C%7D"> (Exogenous Variables)</strong>: 모델 외부에서 결정되는 변수들로, 관측되지 않는 배경 요인(Background factors)이나 노이즈를 의미합니다.</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?F%20=%20%5C%7Bf_1,%20...,%20f_n%5C%7D"> (Structural Functions)</strong>: 각 내생 변수 <img src="https://latex.codecogs.com/png.latex?V_i">가 어떻게 결정되는지를 정의하는 함수 집합입니다. <img src="https://latex.codecogs.com/png.latex?v_i%20%5Cleftarrow%20f_i(pa_i,%20u_i)"> 여기서 <img src="https://latex.codecogs.com/png.latex?pa_i%20%5Csubseteq%20V%20%5Csetminus%20%5C%7BV_i%5C%7D">는 <img src="https://latex.codecogs.com/png.latex?V_i">의 부모 변수(직접적인 원인)들이고, <img src="https://latex.codecogs.com/png.latex?u_i%20%5Csubseteq%20U">는 관련된 외생 변수입니다.</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?P(U)"></strong>: 외생 변수 <img src="https://latex.codecogs.com/png.latex?U">에 대한 확률 분포입니다.</li>
</ol>
</section>
<section id="properties-of-scm" class="level2">
<h2 class="anchored" data-anchor-id="properties-of-scm">2.2 Properties of SCM</h2>
<p>[cite_start]SCM은 다음과 같은 중요한 성질을 가집니다. [cite: 2572-2637]</p>
<ol type="1">
<li><strong>Induces <img src="https://latex.codecogs.com/png.latex?P(V)"></strong>: 외생 변수의 분포 <img src="https://latex.codecogs.com/png.latex?P(U)">와 함수 <img src="https://latex.codecogs.com/png.latex?F">를 통해 관측 변수들의 결합 확률 분포 <img src="https://latex.codecogs.com/png.latex?P(V)">가 결정됩니다.</li>
<li><strong>Induces Causal Diagram</strong>: 변수 간의 함수적 관계(<img src="https://latex.codecogs.com/png.latex?f_i">)를 통해 인과 그래프(DAG)를 그릴 수 있습니다.</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-02/images/scm_conceptual.png" class="img-fluid figure-img"></p>
<figcaption>Figure: SCM의 개념도. 외생 변수 U가 확률 분포 P(U)를 따르고, 함수 F를 통해 내생 변수 V의 값을 결정하여 관측 데이터 분포 P(V)를 유도한다.</figcaption>
</figure>
</div>
<hr>
</section>
</section>
<section id="causal-diagrams-dags" class="level1">
<h1>3. Causal Diagrams (DAGs)</h1>
<p>SCM은 시각적으로 <strong>유향 비순환 그래프(DAG, Directed Acyclic Graph)</strong>로 표현됩니다. [cite_start]그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D%20=%20%5Clangle%20V,%20E%20%5Crangle">는 다음 규칙에 따라 생성됩니다. [cite: 2683-2687]</p>
<ol type="1">
<li><strong>Nodes</strong>: 각 내생 변수 <img src="https://latex.codecogs.com/png.latex?V_i">를 노드로 합니다.</li>
<li><strong>Directed Edges (<img src="https://latex.codecogs.com/png.latex?%5Crightarrow">)</strong>: 함수 <img src="https://latex.codecogs.com/png.latex?f_i">에서 <img src="https://latex.codecogs.com/png.latex?V_j">가 <img src="https://latex.codecogs.com/png.latex?V_i">의 인자(<img src="https://latex.codecogs.com/png.latex?pa_i">)로 사용되면 <img src="https://latex.codecogs.com/png.latex?V_j%20%5Crightarrow%20V_i"> 엣지를 그립니다.</li>
<li><strong>Bidirected Edges (<img src="https://latex.codecogs.com/png.latex?%5Cleftrightarrow">)</strong>: 두 변수 <img src="https://latex.codecogs.com/png.latex?V_i,%20V_j">가 공통된 외생 변수(Common unobserved confounder)를 공유하거나, 그들의 외생 변수 <img src="https://latex.codecogs.com/png.latex?U_i,%20U_j">가 서로 종속적(Correlated)일 때 점선 양방향 화살표로 연결합니다.</li>
</ol>
<hr>
</section>
<section id="markovian-factorization" class="level1">
<h1>4. Markovian Factorization</h1>
<p>SCM의 가장 강력한 점 중 하나는 복잡한 결합 확률 분포를 간단한 조건부 확률의 곱으로 분해할 수 있다는 것입니다. 이를 <strong>Markovian Factorization</strong> 또는 <strong>Bayesian Factorization</strong>이라고 합니다.</p>
<section id="markovian-condition" class="level2">
<h2 class="anchored" data-anchor-id="markovian-condition">4.1 Markovian Condition</h2>
<p>[cite_start]만약 모든 외생 변수 <img src="https://latex.codecogs.com/png.latex?U_i">들이 서로 <strong>독립(Jointly Independent)</strong>이라면, 즉 그래프에 양방향 엣지(<img src="https://latex.codecogs.com/png.latex?%5Cleftrightarrow">)가 하나도 없다면, 이 모델을 <strong>Markovian</strong>이라고 합니다. [cite: 2988-2991]</p>
</section>
<section id="mathematical-derivation" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-derivation">4.2 Mathematical Derivation</h2>
<p>[cite_start]Markovian 가정 하에서 결합 확률 분포 <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)">가 어떻게 분해되는지 단계별로 유도해 보겠습니다. [cite: 2992-2993]</p>
<p><strong>Step 1: Law of Total Probability</strong> 모든 변수 <img src="https://latex.codecogs.com/png.latex?V">의 결합 확률은 외생 변수 <img src="https://latex.codecogs.com/png.latex?U">를 포함한 전체 확률에서 <img src="https://latex.codecogs.com/png.latex?U">를 합(Summing out)하여 얻습니다. SCM에서 <img src="https://latex.codecogs.com/png.latex?v_i">는 <img src="https://latex.codecogs.com/png.latex?pa_i">와 <img src="https://latex.codecogs.com/png.latex?u_i">에 의해 결정되므로(<img src="https://latex.codecogs.com/png.latex?P(v_i%7Cpa_i,%20u_i)">는 0 또는 1), 다음과 같이 쓸 수 있습니다. <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)%20=%20%5Csum_%7B%5Cmathbf%7Bu%7D%7D%20P(%5Cmathbf%7Bu%7D)%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%5Cmid%20pa_i,%20u_i)"></p>
<p><strong>Step 2: Independence of Exogenous Variables</strong> Markovian 가정에 의해 <img src="https://latex.codecogs.com/png.latex?U">들이 서로 독립이므로, <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bu%7D)%20=%20%5Cprod%20P(u_i)">가 됩니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7B%5Cmathbf%7Bu%7D%7D%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%5Cmid%20pa_i,%20u_i)%20P(u_i)"></p>
<p><strong>Step 3: Independence of <img src="https://latex.codecogs.com/png.latex?U_i"> and <img src="https://latex.codecogs.com/png.latex?Pa_i"></strong> 외생 변수 <img src="https://latex.codecogs.com/png.latex?U_i">는 시스템 외부에서 결정되므로 내생 변수인 부모 <img src="https://latex.codecogs.com/png.latex?Pa_i">와 독립입니다. 따라서 <img src="https://latex.codecogs.com/png.latex?P(u_i)%20=%20P(u_i%20%5Cmid%20pa_i)">로 쓸 수 있습니다. 이를 식에 대입하고, 확률의 곱셈 법칙(<img src="https://latex.codecogs.com/png.latex?P(A%7CB)P(B)%20=%20P(A,B)">)을 적용합니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7B%5Cmathbf%7Bu%7D%7D%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%5Cmid%20pa_i,%20u_i)%20P(u_i%20%5Cmid%20pa_i)"> <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7B%5Cmathbf%7Bu%7D%7D%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i,%20u_i%20%5Cmid%20pa_i)"></p>
<p><strong>Step 4: Commutativity of Sum and Product</strong> 각 항은 자신에게 해당되는 <img src="https://latex.codecogs.com/png.latex?u_i">에만 의존하므로, 전체 합(<img src="https://latex.codecogs.com/png.latex?%5Csum_%7B%5Cmathbf%7Bu%7D%7D">)을 개별 합(<img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bu_i%7D">)의 곱으로 바꿀 수 있습니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20%5Cleft(%20%5Csum_%7Bu_i%7D%20P(v_i,%20u_i%20%5Cmid%20pa_i)%20%5Cright)"></p>
<p><strong>Step 5: Marginalization (Final Result)</strong> 괄호 안의 식은 결합 확률에서 <img src="https://latex.codecogs.com/png.latex?u_i">를 마지널라이즈(Marginalize)한 것과 같으므로 최종적으로 다음 식이 성립합니다. <img src="https://latex.codecogs.com/png.latex?%5Cboxed%7BP(%5Cmathbf%7Bv%7D)%20=%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%5Cmid%20pa_i)%7D"></p>
<p>이 결과는 관측 불가능한 <img src="https://latex.codecogs.com/png.latex?U">를 모르더라도, <strong>오직 부모-자식 간의 관계(Local Information)만으로 전체 시스템의 분포를 설명할 수 있음</strong>을 의미합니다.</p>
<hr>
</section>
</section>
<section id="conditional-independence-d-separation" class="level1">
<h1>5. Conditional Independence &amp; d-separation</h1>
<p>그래프 구조는 변수들 간의 조건부 독립성(Conditional Independence) 정보를 담고 있습니다. [cite_start]이를 파악하기 위해 세 가지 기본 구조(Triplets)를 이해해야 합니다. [cite: 3014-3191]</p>
<section id="the-three-basic-structures-triplets" class="level2">
<h2 class="anchored" data-anchor-id="the-three-basic-structures-triplets">5.1 The Three Basic Structures (Triplets)</h2>
<section id="chain-causal-chain" class="level3">
<h3 class="anchored" data-anchor-id="chain-causal-chain">1. Chain (Causal Chain)</h3>
<ul>
<li><strong>구조</strong>: <img src="https://latex.codecogs.com/png.latex?X%20%5Crightarrow%20Z%20%5Crightarrow%20Y"></li>
<li><strong>해석</strong>: <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Z">를 유발하고, <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?Y">를 유발합니다. (예: 공부 습관 <img src="https://latex.codecogs.com/png.latex?%5Cto"> 수능 점수 <img src="https://latex.codecogs.com/png.latex?%5Cto"> 대학 합격)</li>
<li><strong>독립성</strong>:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Z">를 모를 때: <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">는 종속적입니다.</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?Z">를 알 때 (Given <img src="https://latex.codecogs.com/png.latex?Z">)</strong>: <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 영향은 <img src="https://latex.codecogs.com/png.latex?Z">에 의해 차단(Blocked)되므로 <strong><img src="https://latex.codecogs.com/png.latex?X%20%5Cperp%20Y%20%5Cmid%20Z"></strong> (독립)입니다.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-02/images/causal_chain.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Causal Chain 구조. 중간 변수 Z를 관측하면 X와 Y의 정보 흐름이 차단되어 독립이 된다.</figcaption>
</figure>
</div>
</section>
<section id="fork-common-cause" class="level3">
<h3 class="anchored" data-anchor-id="fork-common-cause">2. Fork (Common Cause)</h3>
<ul>
<li><strong>구조</strong>: <img src="https://latex.codecogs.com/png.latex?X%20%5Cleftarrow%20Z%20%5Crightarrow%20Y"></li>
<li><strong>해석</strong>: <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">의 공통 원인입니다. (예: 비 <img src="https://latex.codecogs.com/png.latex?%5Cto"> 교통체증, 비 <img src="https://latex.codecogs.com/png.latex?%5Cto"> 우산 사용)</li>
<li><strong>독립성</strong>:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Z">를 모를 때: 공통 원인에 의해 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">는 상관관계를 가집니다(Spurious Correlation).</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?Z">를 알 때 (Given <img src="https://latex.codecogs.com/png.latex?Z">)</strong>: 공통 원인을 통제했으므로 <strong><img src="https://latex.codecogs.com/png.latex?X%20%5Cperp%20Y%20%5Cmid%20Z"></strong> (독립)입니다.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-02/images/common_cause.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Common Cause (Fork) 구조. 공통 원인 Z를 통제하면 X와 Y 사이의 허위 상관관계가 사라진다.</figcaption>
</figure>
</div>
</section>
<section id="collider-common-effect" class="level3">
<h3 class="anchored" data-anchor-id="collider-common-effect">3. Collider (Common Effect)</h3>
<ul>
<li><strong>구조</strong>: <img src="https://latex.codecogs.com/png.latex?X%20%5Crightarrow%20Z%20%5Cleftarrow%20Y"></li>
<li><strong>해석</strong>: 서로 독립인 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">가 공통 결과 <img src="https://latex.codecogs.com/png.latex?Z">를 유발합니다. (예: 감기 <img src="https://latex.codecogs.com/png.latex?%5Cto"> 결석, 휴일 <img src="https://latex.codecogs.com/png.latex?%5Cto"> 결석)</li>
<li><strong>독립성</strong>:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Z">를 모를 때: <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">는 서로 독립입니다. (<img src="https://latex.codecogs.com/png.latex?P(X,Y)%20=%20P(X)P(Y)">)</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?Z">를 알 때 (Given <img src="https://latex.codecogs.com/png.latex?Z">)</strong>: <strong><img src="https://latex.codecogs.com/png.latex?X%20%5Cnot%5Cperp%20Y%20%5Cmid%20Z"></strong> (종속)이 됩니다. 이를 <strong>“Explaining Away”</strong> 현상이라고 합니다. 결석(<img src="https://latex.codecogs.com/png.latex?Z=1">)했는데 휴일이 아니라면(<img src="https://latex.codecogs.com/png.latex?Y=0">), 감기일 확률(<img src="https://latex.codecogs.com/png.latex?X=1">)이 높아지기 때문입니다.</li>
<li><strong>주의</strong>: Collider 본인뿐만 아니라 <strong>Collider의 자손(Descendant)</strong>을 관측해도 경로가 열립니다.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-02/images/common_effect.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Common Effect (Collider) 구조. 두 독립적인 원인이 공통 결과 Z를 조건부로 알게 되었을 때 종속적으로 변하는 Explaining Away 현상을 보여준다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="d-separation-rule" class="level2">
<h2 class="anchored" data-anchor-id="d-separation-rule">5.2 d-separation Rule</h2>
<p>[cite_start]이 세 가지 규칙을 일반화하여 그래프상의 두 노드 <img src="https://latex.codecogs.com/png.latex?X,%20Y">가 조건부 집합 <img src="https://latex.codecogs.com/png.latex?Z">에 대해 독립인지 판별하는 규칙을 <strong>d-separation</strong>이라고 합니다. [cite: 3224-3228]</p>
<ul>
<li>두 노드 사이의 <strong>모든 경로</strong>가 차단(Blocked)되면 d-separated 되었다고 합니다.</li>
<li><strong>경로가 차단되는 조건</strong>:
<ol type="1">
<li>경로 상에 <img src="https://latex.codecogs.com/png.latex?Z">에 포함된 Chain이나 Fork 노드가 있을 때.</li>
<li>경로 상에 Collider가 있으면서, 그 Collider와 자손들이 하나도 <img src="https://latex.codecogs.com/png.latex?Z">에 포함되지 않았을 때.</li>
</ol></li>
</ul>
<hr>
</section>
</section>
<section id="implementation-topological-order" class="level1">
<h1>6. Implementation: Topological Order</h1>
<p>DAG에서 부모가 항상 자식보다 먼저 오도록 노드를 정렬하는 것을 위상 정렬(Topological Order)이라고 합니다. [cite_start]이는 인과 추론 알고리즘 구현의 기초가 됩니다. [cite: 3231-3250]</p>
<p>다음은 Python을 이용한 위상 정렬 구현 예시입니다.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> collections <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> deque</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> topological_order(G):</span>
<span id="cb1-4">    order <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> deque()</span>
<span id="cb1-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. 모든 노드의 진입 차수(in-degree) 계산 (부모의 수)</span></span>
<span id="cb1-6">    in_degrees <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {V: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(G.Pa(V)) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> V <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> G.Vs}</span>
<span id="cb1-7">    </span>
<span id="cb1-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">while</span> in_degrees:</span>
<span id="cb1-9">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. 부모가 없는(in-degree=0) 소스 노드 찾기</span></span>
<span id="cb1-10">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> v, v_deg <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> in_degrees.items():</span>
<span id="cb1-11">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> v_deg <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb1-12">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">break</span></span>
<span id="cb1-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb1-14">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 루프가 break 없이 끝났다면 사이클이 존재한다는 의미 (DAG가 아님)</span></span>
<span id="cb1-15">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">raise</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">ValueError</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cyclic'</span>)</span>
<span id="cb1-16">        </span>
<span id="cb1-17">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. 소스 노드를 순서에 추가하고 그래프에서 제거 개념 적용</span></span>
<span id="cb1-18">        order.append(v)</span>
<span id="cb1-19">        <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">del</span> in_degrees[v]</span>
<span id="cb1-20">        </span>
<span id="cb1-21">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 4. 해당 노드의 자식들의 진입 차수 감소</span></span>
<span id="cb1-22">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> G.Ch(v):</span>
<span id="cb1-23">            in_degrees[c] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb1-24">            </span>
<span id="cb1-25">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> order</span></code></pre></div></div>
<hr>
</section>
<section id="summary" class="level1">
<h1>7. Summary</h1>
<p>이번 포스트에서는 인과 추론의 기초가 되는 SCM과 인과 그래프에 대해 알아보았습니다.</p>
<ol type="1">
<li><strong>SCM</strong>: 현실의 메커니즘을 변수, 외생 변수, 함수적 관계로 정의하는 모델 ().</li>
<li><strong>Markovian Factorization</strong>: 외생 변수의 독립성을 가정하면, 결합 확률을 <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)%20=%20%5Cprod%20P(v_i%20%7C%20pa_i)">로 분해할 수 있습니다.</li>
<li><strong>d-separation</strong>: Chain, Fork, Collider 구조를 통해 변수 간의 조건부 독립성을 파악할 수 있으며, 특히 Collider가 관측될 때 경로가 열린다는 점에 주의해야 합니다.</li>
</ol>
<hr>
<section id="checklist-for-content-verification" class="level3">
<h3 class="anchored" data-anchor-id="checklist-for-content-verification">Checklist for Content Verification</h3>
<ul class="task-list">
<li><label><input type="checkbox" checked=""><strong>Motivation</strong>: Simpson’s Paradox 예시와 Data vs Reality의 차이 설명 포함.</label></li>
<li><label><input type="checkbox" checked=""><strong>SCM Definition</strong>: 4-tuple 정의 및 구성 요소 설명 포함.</label></li>
<li><label><input type="checkbox" checked=""><strong>Mathematical Derivation</strong>: Markovian Factorization의 단계별 유도 과정 LaTeX 수식으로 포함.</label></li>
<li><label><input type="checkbox" checked=""><strong>Basic Structures</strong>: Chain, Fork, Collider의 구조 및 독립성 조건 설명 포함.</label></li>
<li><label><input type="checkbox" checked=""><strong>d-separation</strong>: 경로 차단 조건 및 규칙 설명 포함.</label></li>
<li><label><input type="checkbox" checked=""><strong>Algorithm</strong>: 위상 정렬 알고리즘 및 Python 코드 포함.</label></li>
</ul>
<pre><code></code></pre>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L02/part-02/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 02. Causal Models and Graphs (Part 1)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L02/part-01/</link>
  <description><![CDATA[ 





<section id="introduction-from-statistics-to-causality" class="level1">
<h1>1. Introduction: From Statistics to Causality</h1>
<p>전통적인 통계학이나 머신러닝의 추론(Inference) 패러다임은 데이터의 <strong>결합 확률 분포(Joint Distribution)</strong> <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)">를 찾아내는 것에 집중합니다. 예를 들어, “상품 A를 산 고객이 상품 B도 살 확률은 얼마인가?”(<img src="https://latex.codecogs.com/png.latex?P(B%7CA)">)와 같은 질문은 관측된 데이터의 패턴(Association)만으로 충분히 답할 수 있습니다.</p>
<p>하지만 현실의 문제 해결은 종종 <strong>“만약 우리가 X를 변화시킨다면, Y는 어떻게 변할까?”</strong>라는 질문을 던집니다. * 가격을 두 배로 올리면 판매량은 어떻게 될까? * 흡연을 금지하면 암 발병률은 낮아질까?</p>
<p>이러한 질문은 데이터 자체(<img src="https://latex.codecogs.com/png.latex?P">)가 아니라 데이터가 생성되는 <strong>현실의 메커니즘(Reality)</strong>에 대한 이해를 요구합니다. 이번 포스트에서는 인과 추론의 핵심 언어인 <strong>구조적 인과 모델(Structural Causal Model, SCM)</strong>과 이를 시각화한 <strong>인과 그래프(Causal Graph)</strong>에 대해 다룹니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-01/images/stats_vs_causal_paradigm.png" class="img-fluid figure-img"></p>
<figcaption>Figure: 통계적 추론과 인과적 추론의 차이. 통계적 추론은 데이터 <img src="https://latex.codecogs.com/png.latex?P"> 내에서의 성질 <img src="https://latex.codecogs.com/png.latex?Q(P)">를 찾지만, 인과 추론은 데이터 생성 모델 <img src="https://latex.codecogs.com/png.latex?M">을 통해 현실의 메커니즘을 이해하고, 개입 후의 분포 <img src="https://latex.codecogs.com/png.latex?P'">를 추정하려 한다.</figcaption>
</figure>
</div>
<section id="motivation-simpsons-paradox-example" class="level2">
<h2 class="anchored" data-anchor-id="motivation-simpsons-paradox-example">1.1 Motivation: Simpson’s Paradox Example</h2>
<p>왜 데이터만으로는 충분하지 않을까요? 강의 자료에 제시된 ‘약물 투여와 생존율’ 예시를 봅시다.</p>
<ul>
<li><strong>상황</strong>: 특정 도시에 전염병이 돌고 있고, 치료제(Drug)가 있습니다.</li>
<li><strong>숨겨진 진실(Reality)</strong>:
<ol type="1">
<li>부유층(Rich)은 약물 복용 여부와 상관없이 생존합니다 (좋은 생활 환경).</li>
<li>빈곤층(Poor)은 약물을 복용하면 알레르기 반응으로 사망하고, 복용하지 않으면 생존합니다(자연 면역).</li>
<li>의사들은 부유층에게만 주로 약을 처방합니다(비용 문제).</li>
</ol></li>
</ul>
<p>이 경우 데이터만 보면 “약물을 복용한 집단(대부분 부유층)”의 생존율이 높게 나타납니다. 알고리즘은 “약을 먹어라”라고 추천할 것입니다. 하지만 실제 메커니즘(빈곤층에게는 치명적)을 안다면 빈곤층에게 약을 주면 안 된다는 정반대의 결론에 도달해야 합니다. 즉, <strong>데이터 생성 과정(Data Generating Process)</strong>을 모델링하지 않으면 잘못된 의사결정을 내리게 됩니다.</p>
<hr>
</section>
</section>
<section id="structural-causal-model-scm" class="level1">
<h1>2. Structural Causal Model (SCM)</h1>
<p>인과 관계를 수학적으로 엄밀하게 정의하기 위해 <strong>구조적 인과 모델(SCM)</strong>을 도입합니다.</p>
<section id="definition" class="level2">
<h2 class="anchored" data-anchor-id="definition">2.1 Definition</h2>
<p>SCM <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BM%7D">은 다음 4가지 요소의 튜플 <img src="https://latex.codecogs.com/png.latex?%5Clangle%20V,%20U,%20F,%20P(U)%20%5Crangle">로 정의됩니다.</p>
<ol type="1">
<li><strong><img src="https://latex.codecogs.com/png.latex?V%20=%20%5C%7BV_1,%20...,%20V_n%5C%7D"></strong>: <strong>내생 변수(Endogenous variables)</strong>. 우리가 관측할 수 있는 변수들입니다. (예: 흡연 여부, 폐암 발병 여부)</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?U%20=%20%5C%7BU_1,%20...,%20U_m%5C%7D"></strong>: <strong>외생 변수(Exogenous variables)</strong>. 모델 내부의 다른 변수에 의해 설명되지 않는, 시스템 외부에서 결정되는 변수들입니다. (예: 유전적 요인, 미관측 환경 요인)</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?F%20=%20%5C%7Bf_1,%20...,%20f_n%5C%7D"></strong>: <strong>구조적 함수(Structural functions)</strong>. 각 내생 변수 <img src="https://latex.codecogs.com/png.latex?V_i">가 어떻게 결정되는지를 나타내는 함수입니다. <img src="https://latex.codecogs.com/png.latex?v_i%20%5Cleftarrow%20f_i(pa_i,%20u_i)"> 여기서 <img src="https://latex.codecogs.com/png.latex?pa_i%20%5Csubseteq%20V%20%5Csetminus%20%5C%7BV_i%5C%7D">는 <img src="https://latex.codecogs.com/png.latex?V_i">의 <strong>부모(Parents)</strong> 변수 집합이고, <img src="https://latex.codecogs.com/png.latex?u_i%20%5Csubseteq%20U">는 관련된 외생 변수입니다.</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?P(U)"></strong>: 외생 변수 <img src="https://latex.codecogs.com/png.latex?U">에 대한 확률 분포입니다.</li>
</ol>
<blockquote class="blockquote">
<p><strong>Key Idea</strong>: SCM에서 자연(Nature)은 결정론적(Deterministic) 함수 <img src="https://latex.codecogs.com/png.latex?F">와 확률적(Probabilistic) 노이즈 <img src="https://latex.codecogs.com/png.latex?P(U)">의 결합으로 세상을 정의합니다.</p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-01/images/scm_conceptual_diagram.png" class="img-fluid figure-img"></p>
<figcaption>Figure: SCM의 개념적 도식. 외생 변수 U가 확률 분포 P(U)를 따르고, 함수 F를 통해 내생 변수 V의 값을 결정하여 관측 데이터 분포 P(V)를 유도한다.</figcaption>
</figure>
</div>
</section>
<section id="scm-induces-a-distribution-pv" class="level2">
<h2 class="anchored" data-anchor-id="scm-induces-a-distribution-pv">2.2 SCM Induces a Distribution <img src="https://latex.codecogs.com/png.latex?P(V)"></h2>
<p>SCM은 단순히 변수 간의 관계만 정의하는 것이 아니라, 관측 가능한 변수 <img src="https://latex.codecogs.com/png.latex?V">의 결합 확률 분포 <img src="https://latex.codecogs.com/png.latex?P(V)">를 유도(Induce)합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)%20=%20%5Csum_%7B%5Cmathbf%7Bu%7D%20:%20Y(%5Cmathbf%7Bu%7D)%20=%20%5Cmathbf%7Bv%7D%7D%20P(%5Cmathbf%7Bu%7D)"></p>
<p>즉, 우리가 관측하는 데이터의 분포는 <strong>외생 변수의 불확실성(<img src="https://latex.codecogs.com/png.latex?P(U)">)이 함수 <img src="https://latex.codecogs.com/png.latex?F">를 통과하여 내생 변수 <img src="https://latex.codecogs.com/png.latex?V">로 전파된 결과</strong>입니다.</p>
<hr>
</section>
</section>
<section id="causal-diagrams-graphical-models" class="level1">
<h1>3. Causal Diagrams (Graphical Models)</h1>
<p>SCM은 수식으로 정의되지만, 이를 직관적으로 이해하고 분석하기 위해 <strong>유향 비순환 그래프(DAG, Directed Acyclic Graph)</strong> 형태인 인과 그래프로 표현할 수 있습니다.</p>
<section id="construction-rules" class="level2">
<h2 class="anchored" data-anchor-id="construction-rules">3.1 Construction Rules</h2>
<p>SCM <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BM%7D">으로부터 인과 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D">를 그리는 규칙은 다음과 같습니다.</p>
<ol type="1">
<li><strong>Nodes</strong>: 각 내생 변수 <img src="https://latex.codecogs.com/png.latex?V_i">를 노드(Vertex)로 그립니다.</li>
<li><strong>Directed Edges (<img src="https://latex.codecogs.com/png.latex?%5Crightarrow">)</strong>: 함수 <img src="https://latex.codecogs.com/png.latex?f_i">에서 <img src="https://latex.codecogs.com/png.latex?V_j">가 <img src="https://latex.codecogs.com/png.latex?V_i">의 입력(<img src="https://latex.codecogs.com/png.latex?pa_i">)으로 사용된다면, <img src="https://latex.codecogs.com/png.latex?V_j%20%5Cto%20V_i"> 화살표를 그립니다.</li>
<li><strong>Bidirected Edges (<img src="https://latex.codecogs.com/png.latex?%5Cleftrightarrow">)</strong>: 두 변수 <img src="https://latex.codecogs.com/png.latex?V_i,%20V_j">에 영향을 주는 외생 변수 <img src="https://latex.codecogs.com/png.latex?U_i,%20U_j">가 서로 상관관계가 있거나(Correlated), 같은 외생 변수를 공유한다면 점선 양방향 화살표로 연결합니다. 이는 <strong>미관측 교란 요인(Unobserved Confounder)</strong>의 존재를 의미합니다.</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-01/images/scm_to_dag_example.png" class="img-fluid figure-img"></p>
<figcaption>Figure: SCM에서 인과 그래프로의 변환 예시. (좌) 수식으로 표현된 SCM, (우) 이에 대응하는 DAG. 외생 변수 U는 보통 그래프에서 생략되거나 점선으로 표현된다.</figcaption>
</figure>
</div>
</section>
<section id="terminology" class="level2">
<h2 class="anchored" data-anchor-id="terminology">3.2 Terminology</h2>
<ul>
<li><strong>Parents (<img src="https://latex.codecogs.com/png.latex?Pa_i">)</strong>: <img src="https://latex.codecogs.com/png.latex?V_i">로 직접 화살표를 보내는 변수들.</li>
<li><strong>Children (<img src="https://latex.codecogs.com/png.latex?Ch_i">)</strong>: <img src="https://latex.codecogs.com/png.latex?V_i">로부터 직접 화살표를 받는 변수들.</li>
<li><strong>Ancestors / Descendants</strong>: 화살표를 따라 거슬러 올라가거나 내려갈 수 있는 변수들.</li>
</ul>
<hr>
</section>
</section>
<section id="markovian-factorization-detailed-derivation" class="level1">
<h1>4. Markovian Factorization (Detailed Derivation)</h1>
<p>이 포스트의 핵심 파트입니다. SCM과 그래프 구조를 이용하여 복잡한 결합 확률 분포 <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)">를 어떻게 간단한 조건부 확률들의 곱으로 분해할 수 있는지 증명합니다.</p>
<section id="the-markovian-condition" class="level2">
<h2 class="anchored" data-anchor-id="the-markovian-condition">4.1 The Markovian Condition</h2>
<p>만약 외생 변수들 <img src="https://latex.codecogs.com/png.latex?U">가 서로 <strong>독립(Jointly Independent)</strong>이라면, 즉 그래프 상에 양방향 엣지(<img src="https://latex.codecogs.com/png.latex?%5Cleftrightarrow">)가 하나도 없다면, 이 모델을 <strong>Markovian</strong>이라고 부릅니다.</p>
</section>
<section id="derivation-of-bayesian-factorization" class="level2">
<h2 class="anchored" data-anchor-id="derivation-of-bayesian-factorization">4.2 Derivation of Bayesian Factorization</h2>
<p>우리의 목표는 <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)">를 <img src="https://latex.codecogs.com/png.latex?%5Cprod%20P(v_i%20%7C%20pa_i)"> 형태로 만드는 것입니다. 이를 <strong>Bayesian Factorization</strong>이라 합니다.</p>
<p><strong>Step 1: Law of Total Probability</strong> 모든 변수 <img src="https://latex.codecogs.com/png.latex?V">의 결합 확률은 외생 변수 <img src="https://latex.codecogs.com/png.latex?U">를 포함한 결합 확률에서 <img src="https://latex.codecogs.com/png.latex?U">를 합(Summing out)하여 얻을 수 있습니다. <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)%20=%20%5Csum_%7B%5Cmathbf%7Bu%7D%7D%20P(%5Cmathbf%7Bv%7D,%20%5Cmathbf%7Bu%7D)"></p>
<p>SCM에서 <img src="https://latex.codecogs.com/png.latex?V">는 <img src="https://latex.codecogs.com/png.latex?Pa">와 <img src="https://latex.codecogs.com/png.latex?U">에 의해 결정되므로(<img src="https://latex.codecogs.com/png.latex?v_i%20=%20f_i(pa_i,%20u_i)">), <img src="https://latex.codecogs.com/png.latex?P(v_i%20%7C%20pa_i,%20u_i)">는 결정론적입니다(0 또는 1). 이를 이용하여 식을 전개하면: <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)%20=%20%5Csum_%7B%5Cmathbf%7Bu%7D%7D%20P(%5Cmathbf%7Bu%7D)%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%5Cmid%20%5Cmathbf%7Bpa%7D_i,%20%5Cmathbf%7Bu%7D_i)"></p>
<p><strong>Step 2: Independence of Exogenous Variables</strong> Markovian 가정에 의해 <img src="https://latex.codecogs.com/png.latex?U">들이 서로 독립이므로, <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bu%7D)%20=%20%5Cprod%20P(%5Cmathbf%7Bu%7D_i)">가 성립합니다. 이를 대입합니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7B%5Cmathbf%7Bu%7D%7D%20%5Cleft(%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(%5Cmathbf%7Bu%7D_i)%20%5Cright)%20%5Cleft(%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%5Cmid%20%5Cmathbf%7Bpa%7D_i,%20%5Cmathbf%7Bu%7D_i)%20%5Cright)"></p>
<p><strong>Step 3: Independence of <img src="https://latex.codecogs.com/png.latex?U_i"> and <img src="https://latex.codecogs.com/png.latex?Pa_i"></strong> 외생 변수 <img src="https://latex.codecogs.com/png.latex?U_i">는 시스템 외부에서 결정되므로, 내생 변수인 부모 <img src="https://latex.codecogs.com/png.latex?Pa_i">와는 독립입니다. 따라서 <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bu%7D_i)%20=%20P(%5Cmathbf%7Bu%7D_i%20%5Cmid%20%5Cmathbf%7Bpa%7D_i)">로 쓸 수 있습니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7B%5Cmathbf%7Bu%7D%7D%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%5Cmid%20%5Cmathbf%7Bpa%7D_i,%20%5Cmathbf%7Bu%7D_i)%20P(%5Cmathbf%7Bu%7D_i%20%5Cmid%20%5Cmathbf%7Bpa%7D_i)"></p>
<p><strong>Step 4: Merging Conditional Probabilities</strong> 곱셈 법칙 <img src="https://latex.codecogs.com/png.latex?P(A%7CB)P(B)%20=%20P(A,B)">를 적용하여 항을 합칩니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7B%5Cmathbf%7Bu%7D%7D%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i,%20%5Cmathbf%7Bu%7D_i%20%5Cmid%20%5Cmathbf%7Bpa%7D_i)"></p>
<p><strong>Step 5: Rearranging Sum and Product</strong> 전체 외생 변수 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D">에 대한 합(<img src="https://latex.codecogs.com/png.latex?%5Csum_%7B%5Cmathbf%7Bu%7D%7D">)을 개별 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D_i">에 대한 합으로 분리하여 곱셈 기호 안으로 넣습니다. 각 항은 해당되는 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D_i">에만 의존하기 때문에 가능합니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20%5Cleft(%20%5Csum_%7B%5Cmathbf%7Bu%7D_i%7D%20P(v_i,%20%5Cmathbf%7Bu%7D_i%20%5Cmid%20%5Cmathbf%7Bpa%7D_i)%20%5Cright)"></p>
<p><strong>Step 6: Marginalization</strong> 괄호 안의 식 <img src="https://latex.codecogs.com/png.latex?%5Csum_%7B%5Cmathbf%7Bu%7D_i%7D%20P(v_i,%20%5Cmathbf%7Bu%7D_i%20%5Cmid%20%5Cmathbf%7Bpa%7D_i)">는 결합 확률에서 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D_i">를 덜어내는(Marginalize) 과정이므로 <img src="https://latex.codecogs.com/png.latex?P(v_i%20%5Cmid%20%5Cmathbf%7Bpa%7D_i)">가 됩니다.</p>
<p><strong>Final Result:</strong> <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)%20=%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%5Cmid%20%5Cmathbf%7Bpa%7D_i)"></p>
<p>이 결과는 매우 강력합니다. 우리가 관측할 수 없는 <img src="https://latex.codecogs.com/png.latex?U">를 모르더라도, <strong>오직 관측 가능한 데이터 내에서 부모-자식 간의 조건부 확률만 알면 전체 분포를 알 수 있다</strong>는 것을 의미하기 때문입니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-01/images/markovian_factorization_derivation.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Markovian Factorization 유도 과정 요약. 독립성 가정과 확률의 연쇄 법칙을 통해 복잡한 결합 확률이 조건부 확률의 곱으로 분해됨을 보여준다.</figcaption>
</figure>
</div>
<hr>
</section>
</section>
<section id="conditional-independence-d-separation" class="level1">
<h1>5. Conditional Independence &amp; d-separation</h1>
<p>그래프 구조는 변수들 사이의 조건부 독립(Conditional Independence, CI) 정보를 담고 있습니다. 이를 파악하기 위해 3가지 기본 구조(Triplets)를 이해해야 합니다.</p>
<section id="the-three-basic-structures-triplets" class="level2">
<h2 class="anchored" data-anchor-id="the-three-basic-structures-triplets">5.1 The Three Basic Structures (Triplets)</h2>
<section id="chain-x-rightarrow-z-rightarrow-y" class="level3">
<h3 class="anchored" data-anchor-id="chain-x-rightarrow-z-rightarrow-y">1. Chain (<img src="https://latex.codecogs.com/png.latex?X%20%5Crightarrow%20Z%20%5Crightarrow%20Y">)</h3>
<ul>
<li><strong>구조</strong>: <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Z">에 영향을 주고, <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?Y">에 영향을 줍니다.</li>
<li><strong>독립성</strong>:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Z">를 모를 때: <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">는 종속입니다 (정보가 흐름).</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?Z">를 알 때 (Given <img src="https://latex.codecogs.com/png.latex?Z">)</strong>: <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 영향은 이미 <img src="https://latex.codecogs.com/png.latex?Z">에 의해 설명되었으므로, <strong><img src="https://latex.codecogs.com/png.latex?X%20%5Cperp%20Y%20%5Cmid%20Z"> (독립)</strong>입니다. <img src="https://latex.codecogs.com/png.latex?Z">가 정보를 차단(Block)합니다.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-01/images/causal_chain.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Causal Chain 구조와 독립성. 중간 매개변수 Z를 조건부로 알게 되면 X와 Y 사이의 정보 흐름이 차단되어 독립이 된다.</figcaption>
</figure>
</div>
</section>
<section id="fork-common-cause-x-leftarrow-z-rightarrow-y" class="level3">
<h3 class="anchored" data-anchor-id="fork-common-cause-x-leftarrow-z-rightarrow-y">2. Fork / Common Cause (<img src="https://latex.codecogs.com/png.latex?X%20%5Cleftarrow%20Z%20%5Crightarrow%20Y">)</h3>
<ul>
<li><strong>구조</strong>: <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">의 공통 원인입니다. (예: <img src="https://latex.codecogs.com/png.latex?Z">=날씨, <img src="https://latex.codecogs.com/png.latex?X">=교통체증, <img src="https://latex.codecogs.com/png.latex?Y">=우산사용)</li>
<li><strong>독립성</strong>:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Z">를 모를 때: <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">는 종속입니다 (상관관계 발생).</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?Z">를 알 때 (Given <img src="https://latex.codecogs.com/png.latex?Z">)</strong>: 공통 원인을 통제했으므로 <strong><img src="https://latex.codecogs.com/png.latex?X%20%5Cperp%20Y%20%5Cmid%20Z"> (독립)</strong>입니다.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-01/images/common_cause.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Common Cause 구조와 독립성. 공통 원인 Z를 통제하면 X와 Y 사이의 허위 상관관계(Spurious Correlation)가 사라져 독립이 된다.</figcaption>
</figure>
</div>
</section>
<section id="collider-common-effect-x-rightarrow-z-leftarrow-y" class="level3">
<h3 class="anchored" data-anchor-id="collider-common-effect-x-rightarrow-z-leftarrow-y">3. Collider / Common Effect (<img src="https://latex.codecogs.com/png.latex?X%20%5Crightarrow%20Z%20%5Cleftarrow%20Y">)</h3>
<ul>
<li><strong>구조</strong>: <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">가 동시에 <img src="https://latex.codecogs.com/png.latex?Z">에 영향을 줍니다. (예: <img src="https://latex.codecogs.com/png.latex?X">=감기, <img src="https://latex.codecogs.com/png.latex?Y">=휴일, <img src="https://latex.codecogs.com/png.latex?Z">=결석)</li>
<li><strong>독립성</strong>:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Z">를 모를 때: <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">는 <strong>독립</strong>입니다 (서로 관계없는 사건).</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?Z">를 알 때 (Given <img src="https://latex.codecogs.com/png.latex?Z">)</strong>: <strong><img src="https://latex.codecogs.com/png.latex?X%20%5Cnot%5Cperp%20Y%20%5Cmid%20Z"> (종속)</strong>이 됩니다.</li>
</ul></li>
<li><strong>Explaining Away</strong>: 결석(<img src="https://latex.codecogs.com/png.latex?Z=1">)했다는 사실을 알 때, 휴일이 아니라면(<img src="https://latex.codecogs.com/png.latex?Y=0">), 아플 확률(<img src="https://latex.codecogs.com/png.latex?X=1">)이 높아집니다. 즉, 결과를 알면 원인들 사이에 상관관계가 생깁니다. <strong>Collider는 관측될 때 경로를 엽니다(Open).</strong></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-01/images/collider_structure.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Common Effect (Collider) 구조와 Explaining Away 현상. 두 독립적인 원인이 공통 결과 Z를 조건부로 알게 되었을 때 종속적으로 변하는 현상을 설명한다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="d-separation" class="level2">
<h2 class="anchored" data-anchor-id="d-separation">5.2 d-separation</h2>
<p>이 세 가지 규칙을 일반화한 것이 <strong>d-separation</strong>입니다. 그래프 상의 두 노드 <img src="https://latex.codecogs.com/png.latex?X,%20Y"> 사이의 모든 경로가 관측된 변수 집합 <img src="https://latex.codecogs.com/png.latex?Z">에 의해 차단(Blocked)된다면, <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">는 <img src="https://latex.codecogs.com/png.latex?Z">에 대해 조건부 독립입니다.</p>
<ul>
<li>경로가 차단되는 경우:
<ol type="1">
<li>경로 상의 Chain이나 Fork 노드가 <img src="https://latex.codecogs.com/png.latex?Z">에 포함될 때.</li>
<li>경로 상의 <strong>Collider 노드와 그 자손들이 <img src="https://latex.codecogs.com/png.latex?Z">에 포함되지 않을 때</strong>.</li>
</ol></li>
</ul>
</section>
<section id="food-for-thought-quiz" class="level2">
<h2 class="anchored" data-anchor-id="food-for-thought-quiz">5.3 Food for Thought (Quiz)</h2>
<p>아래 그래프를 보고 독립성을 판별해 봅시다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L02/part-01/images/food_for_thought_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure: d-separation 연습을 위한 복합 그래프 예시. A, B, C, D 노드와 실선/점선 엣지가 섞여 있어 다양한 경로의 독립성을 테스트한다.</figcaption>
</figure>
</div>
<ol type="1">
<li><strong>Is <img src="https://latex.codecogs.com/png.latex?A%20%5Cperp%20D">? (No)</strong>
<ul>
<li>경로: <img src="https://latex.codecogs.com/png.latex?A%20%5Cleftrightarrow%20B%20%5Crightarrow%20D">.</li>
<li><img src="https://latex.codecogs.com/png.latex?B">는 Chain/Fork 역할을 하지만 관측되지 않았으므로 경로가 열려 있습니다.</li>
</ul></li>
<li><strong>Is <img src="https://latex.codecogs.com/png.latex?A%20%5Cperp%20C">? (Yes)</strong>
<ul>
<li>경로: <img src="https://latex.codecogs.com/png.latex?A%20%5Cleftrightarrow%20B%20%5Cleftarrow%20C">.</li>
<li><img src="https://latex.codecogs.com/png.latex?B">는 Collider입니다. 관측되지 않았으므로 경로는 <strong>차단</strong>되어 있습니다.</li>
</ul></li>
<li><strong>Is <img src="https://latex.codecogs.com/png.latex?A%20%5Cperp%20C%20%5Cmid%20D">? (No)</strong>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?D">는 Collider <img src="https://latex.codecogs.com/png.latex?B">의 자손(Descendant)입니다.</li>
<li><img src="https://latex.codecogs.com/png.latex?D">를 관측하면 <img src="https://latex.codecogs.com/png.latex?B">가 열리게 되어 경로가 연결됩니다.</li>
</ul></li>
<li><strong>Is <img src="https://latex.codecogs.com/png.latex?D%20%5Cperp%20C%20%5Cmid%20B">? (No)</strong>
<ul>
<li>경로 1: <img src="https://latex.codecogs.com/png.latex?C%20%5Crightarrow%20B%20%5Crightarrow%20D">. <img src="https://latex.codecogs.com/png.latex?B">를 알면 차단됩니다.</li>
<li>경로 2: <img src="https://latex.codecogs.com/png.latex?C%20%5Cleftrightarrow%20D"> (Backdoor path, <img src="https://latex.codecogs.com/png.latex?C%20%5Cleftarrow%20U%20%5Crightarrow%20D">). 이 경로는 <img src="https://latex.codecogs.com/png.latex?B">와 무관하게 열려 있습니다.</li>
<li>하나라도 열린 경로가 있으므로 종속입니다.</li>
</ul></li>
</ol>
<hr>
</section>
</section>
<section id="summary" class="level1">
<h1>6. Summary</h1>
<p>이번 포스트에서는 인과 추론의 기초가 되는 SCM과 인과 그래프에 대해 알아보았습니다.</p>
<ol type="1">
<li><strong>SCM</strong>: 현실의 메커니즘을 변수, 외생 변수, 함수적 관계로 정의하는 모델입니다.</li>
<li><strong>Markovian Factorization</strong>: 외생 변수의 독립성을 가정하면, 결합 확률 분포를 <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bv%7D)%20=%20%5Cprod%20P(v_i%20%7C%20pa_i)">로 분해할 수 있습니다.</li>
<li><strong>d-separation</strong>: 그래프 구조(Chain, Fork, Collider)를 통해 변수 간의 조건부 독립성을 파악할 수 있으며, 특히 Collider가 관측될 때 경로가 열린다는 점(Explaining Away)이 중요합니다.</li>
</ol>
<p>다음 시간에는 이 구조 위에서 실제로 <strong>개입(Intervention)</strong>을 했을 때 어떤 일이 벌어지는지(Pearl’s Causal Hierarchy의 2단계)에 대해 다루겠습니다.</p>
<hr>
<section id="checklist-for-content-verification" class="level3">
<h3 class="anchored" data-anchor-id="checklist-for-content-verification"><strong>Checklist for Content Verification</strong></h3>
<ul class="task-list">
<li><label><input type="checkbox" checked=""><strong>Motivation</strong>: Simpson’s Paradox (Drug example) included? (Yes)</label></li>
<li><label><input type="checkbox" checked=""><strong>SCM Definition</strong>: 4-tuple and definition of components included? (Yes)</label></li>
<li><label><input type="checkbox" checked=""><strong>Induced Distribution</strong>: How SCM induces <img src="https://latex.codecogs.com/png.latex?P(v)"> described? (Yes)</label></li>
<li><label><input type="checkbox" checked=""><strong>Causal Diagrams</strong>: Construction rules (Nodes, Edges) included? (Yes)</label></li>
<li><label><input type="checkbox" checked=""><strong>Markovian Factorization</strong>: Detailed mathematical derivation included? (Yes)</label></li>
<li><label><input type="checkbox" checked=""><strong>Conditional Independence</strong>: 3 Basic structures (Chain, Fork, Collider) explained? (Yes)</label></li>
<li><label><input type="checkbox" checked=""><strong>d-separation</strong>: General rule and specific quiz (Food for thought) analysis included? (Yes)</label></li>
<li><label><input type="checkbox" checked=""><strong>Algebra Review</strong>: Sum of products logic implicitly handled in the derivation section? (Yes)</label></li>
</ul>
<p>```</p>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L02/part-01/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 03. Identification of Causal Effects</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L03/</link>
  <description><![CDATA[ 





<blockquote class="blockquote">
<p>[cite_start]<strong>Note</strong>: 본 포스트는 서울대학교 GSDS 이상학 교수님의 “Identification of Causal Effects” 강의 자료를 바탕으로 작성되었습니다. [cite: 1, 2]</p>
</blockquote>
<section id="introduction-the-challenge-of-causal-inference" class="level1">
<h1>1. Introduction: The Challenge of Causal Inference</h1>
<p>인과 추론(Causal Inference)의 핵심 목표는 정적인 데이터(Static conditions)로부터 <strong>변화(Change)</strong>를 예측하는 것입니다.</p>
<p>[cite_start]우리가 흔히 접하는 관측 데이터(Observational Data)는 특정 체제(Regime) 하에서의 인구 집단 분포를 설명할 뿐, 시스템에 변화가 가해졌을 때 인구 집단이 어떻게 반응할지는 말해주지 않습니다[cite: 27, 28].</p>
<p>[cite_start]예를 들어, “흡연을 금지시킨다면 암 환자가 줄어들까?”라는 질문은 <img src="https://latex.codecogs.com/png.latex?P(Cancer%7CSmoking)">이라는 관측된 조건부 확률(Association)이 아니라, <img src="https://latex.codecogs.com/png.latex?P(Cancer%7Cdo(Smoking=no))">라는 개입(Intervention) 후의 확률을 묻는 것입니다[cite: 24, 25].</p>
<p>이 포스트에서는 <strong>구조적 인과 모형(Structural Causal Model, SCM)</strong>을 사용하여 관측 데이터(<img src="https://latex.codecogs.com/png.latex?P">)와 인과 그래프(<img src="https://latex.codecogs.com/png.latex?G">)가 주어졌을 때, 인과 효과(<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">)를 식별(Identify)해내는 과정을 수학적으로 다룹니다.</p>
<hr>
</section>
<section id="structural-causal-model-intervention" class="level1">
<h1>2. Structural Causal Model &amp; Intervention</h1>
<section id="real-world-vs.-hypothetical-world" class="level2">
<h2 class="anchored" data-anchor-id="real-world-vs.-hypothetical-world">2.1. Real World vs.&nbsp;Hypothetical World</h2>
<p>인과 효과를 정의하기 위해 우리는 두 개의 세계를 비교해야 합니다.</p>
<ol type="1">
<li><strong>Real World (Observational World):</strong> 변수들이 자연스러운 인과 구조에 따라 값을 갖는 세계. 결합 확률 분포 <img src="https://latex.codecogs.com/png.latex?P(z,%20x,%20w,%20y)">로 표현됩니다.</li>
<li><strong>Hyphetical World (Interventional World):</strong> 우리가 변수 <img src="https://latex.codecogs.com/png.latex?X">를 강제로 특정 값 <img src="https://latex.codecogs.com/png.latex?x">로 고정(<img src="https://latex.codecogs.com/png.latex?do(X=x)">)했을 때의 세계. [cite_start]분포 <img src="https://latex.codecogs.com/png.latex?P(z,%20w,%20y%20%7C%20do(x))">로 표현됩니다 [cite: 33-44].</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L03/images/real_vs_hypothetical_world.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Real world vs.&nbsp;Hypothetical world. 왼쪽(Real world)에서는 Z가 X에 영향을 주지만, 오른쪽(Hyphetical world)에서는 X에 대한 개입(do(X))으로 인해 Z에서 X로 가는 화살표가 끊어진(Mutilated) 것을 볼 수 있다.</figcaption>
</figure>
</div>
<p>위 그림에서 볼 수 있듯이, 개입 <img src="https://latex.codecogs.com/png.latex?do(X=x)">는 모델 내에서 <img src="https://latex.codecogs.com/png.latex?X">를 결정하는 모든 방정식(화살표)을 삭제하고, <img src="https://latex.codecogs.com/png.latex?X=x">라는 상수로 대체하는 연산입니다. [cite_start]이를 통해 <img src="https://latex.codecogs.com/png.latex?Z">(교란 변수)가 <img src="https://latex.codecogs.com/png.latex?X">에 미치는 영향을 차단합니다 [cite: 52-71].</p>
</section>
<section id="causal-effect의-정의" class="level2">
<h2 class="anchored" data-anchor-id="causal-effect의-정의">2.2. Causal Effect의 정의</h2>
<p>수학적으로, <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 <strong>인과 효과(Causal Effect)</strong> <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">는 다음과 같이 정의됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))%20=%20P_x(y)"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?P_x(y)">는 서브모델(Submodel) <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BM%7D_x">에서 <img src="https://latex.codecogs.com/png.latex?Y=y">일 확률을 의미합니다. [cite_start]<img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BM%7D_x">는 원래 모델 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BM%7D">에서 <img src="https://latex.codecogs.com/png.latex?X">에 관련된 모든 방정식을 삭제하고 <img src="https://latex.codecogs.com/png.latex?X=x">를 대입하여 얻은 모델입니다 [cite: 96-98].</p>
<hr>
</section>
</section>
<section id="computing-causal-effects-the-sprinkler-example" class="level1">
<h1>3. Computing Causal Effects: The Sprinkler Example</h1>
<p>[cite_start]이론적인 정의를 넘어, 실제 관측 데이터로 이를 어떻게 계산하는지 “스프링클러 예제”를 통해 살펴보겠습니다[cite: 125].</p>
<section id="시나리오-및-그래프" class="level2">
<h2 class="anchored" data-anchor-id="시나리오-및-그래프">3.1. 시나리오 및 그래프</h2>
<p>다음과 같은 변수와 인과 관계가 있다고 가정합니다. * <strong>Season (<img src="https://latex.codecogs.com/png.latex?Sn">):</strong> 계절 (모든 변수의 근원) * <strong>Sprinkler (<img src="https://latex.codecogs.com/png.latex?Sp">):</strong> 스프링클러 가동 여부 (계절에 영향 받음) * <strong>Rain (<img src="https://latex.codecogs.com/png.latex?Rn">):</strong> 비 옴 여부 (계절에 영향 받음) * <strong>Wet (<img src="https://latex.codecogs.com/png.latex?Wt">):</strong> 땅이 젖음 (스프링클러와 비에 영향 받음) * <strong>Slippery (<img src="https://latex.codecogs.com/png.latex?Sl">):</strong> 미끄러움 (땅이 젖음에 영향 받음)</p>
<p>전체 결합 확률 분포(Markovian factorization)는 다음과 같습니다: <img src="https://latex.codecogs.com/png.latex?P(v)%20=%20P(Sn)P(Sp%7CSn)P(Rn%7CSn)P(Wt%7CSp,%20Rn)P(Sl%7CWt)"> [cite_start][cite: 127]</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L03/images/sprinkler_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Sprinkler Example Causal Graph. Season이 Sprinkler와 Rain의 공통 원인(Confounder)으로 작용하고 있으며, Sprinkler와 Rain은 Wet의 원인이 된다.</figcaption>
</figure>
</div>
</section>
<section id="query-1-observation-pwtspon" class="level2">
<h2 class="anchored" data-anchor-id="query-1-observation-pwtspon">3.2. Query 1: Observation (<img src="https://latex.codecogs.com/png.latex?P(Wt%7CSp=on)">)</h2>
<p>우리가 단순히 “스프링클러가 켜진 것을 목격했을 때(<img src="https://latex.codecogs.com/png.latex?Sp=on">)”, 땅이 젖어 있을 확률은 조건부 확률의 정의에 따라 다음과 같습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AQ_1%20=%20P(Wt%20%7C%20Sp=%5Ctext%7Bon%7D)%20=%20%5Cfrac%7B%5Csum_%7Bsn,%20rn%7D%20P(sn)%20%5Cmathbf%7BP(Sp=%5Ctext%7Bon%7D%7Csn)%7D%20P(rn%7Csn)%20P(wt%7CSp=%5Ctext%7Bon%7D,%20rn)%7D%7B%5Csum_%7Bsn%7D%20%5Cmathbf%7BP(Sp=%5Ctext%7Bon%7D%7Csn)%7D%20P(sn)%7D%0A"> [cite_start][cite: 148]</p>
<ul>
<li><strong>해석:</strong> 여기서 <img src="https://latex.codecogs.com/png.latex?P(Sp=%5Ctext%7Bon%7D%7Csn)"> 항이 살아있습니다. 즉, 계절에 따라 스프링클러를 켜는 경향성(Selection Bias)이 결과에 반영됩니다.</li>
</ul>
</section>
<section id="query-2-intervention-pwtdospon" class="level2">
<h2 class="anchored" data-anchor-id="query-2-intervention-pwtdospon">3.3. Query 2: Intervention (<img src="https://latex.codecogs.com/png.latex?P(Wt%7Cdo(Sp=on))">)</h2>
<p>이제 우리가 “스프링클러를 강제로 켰을 때(<img src="https://latex.codecogs.com/png.latex?do(Sp=on)">)”, 땅이 젖어 있을 확률을 구해보겠습니다. 개입이 일어나면 <img src="https://latex.codecogs.com/png.latex?Sn%20%5Crightarrow%20Sp">의 화살표가 끊어지므로, <img src="https://latex.codecogs.com/png.latex?Sp">는 더 이상 <img src="https://latex.codecogs.com/png.latex?Sn">의 함수가 아닙니다. 따라서 분해 식에서 <strong><img src="https://latex.codecogs.com/png.latex?P(Sp%7CSn)"> 항이 제거(Truncated)</strong> 됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AQ_2%20=%20P(Wt%20%7C%20do(Sp=%5Ctext%7Bon%7D))%20=%20%5Csum_%7Bsn,%20rn%7D%20P(sn)%20P(rn%7Csn)%20P(wt%7CSp=%5Ctext%7Bon%7D,%20rn)%0A"> [cite_start][cite: 165]</p>
<ul>
<li><strong>중요한 차이:</strong> 관측 식(<img src="https://latex.codecogs.com/png.latex?Q_1">)과 달리, <img src="https://latex.codecogs.com/png.latex?Q_2">에서는 <img src="https://latex.codecogs.com/png.latex?P(Sp%7CSn)"> 항이 사라졌습니다. 대신 자연적인 계절의 분포 <img src="https://latex.codecogs.com/png.latex?P(Sn)">과 비의 분포 <img src="https://latex.codecogs.com/png.latex?P(Rn%7CSn)">에 따라 가중 평균을 구하게 됩니다.</li>
<li>[cite_start]이것은 관측 분포와 개입 분포 사이의 변환을 <strong>재가중(Re-weighting) 과정</strong>으로 해석할 수 있음을 보여줍니다[cite: 211].</li>
</ul>
<hr>
</section>
</section>
<section id="truncated-factorization-formula" class="level1">
<h1>4. Truncated Factorization Formula</h1>
<p>위 예제에서 본 원리를 일반화하면 <strong>Truncated Factorization Formula (절단된 분해 공식)</strong>를 얻을 수 있습니다. 이것은 마르코프 모형(Markovian Model)에서 인과 효과를 계산하는 가장 기본적인 정리입니다.</p>
<section id="theorem-manipulation-theorem" class="level2">
<h2 class="anchored" data-anchor-id="theorem-manipulation-theorem">4.1. Theorem (Manipulation Theorem)</h2>
<p>마르코프 모형 <img src="https://latex.codecogs.com/png.latex?M">에서 개입 <img src="https://latex.codecogs.com/png.latex?do(X=x)">에 의해 생성된 확률 분포는 다음과 같이 주어집니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?P(v%20%5Csetminus%20x%20%7C%20do(x))%20=%20%5Cprod_%7BV_i%20%5Cin%20V%20%5Csetminus%20X%7D%20P(v_i%20%7C%20pa_i)"> [cite_start][cite: 173]</p>
<p>즉, 전체 결합 확률 <img src="https://latex.codecogs.com/png.latex?P(v)%20=%20%5Cprod%20P(v_i%7Cpa_i)">에서 개입된 변수 <img src="https://latex.codecogs.com/png.latex?X">에 해당하는 항 <img src="https://latex.codecogs.com/png.latex?P(x%7Cpa_x)">만 제거한 형태입니다.</p>
</section>
<section id="re-weighting-관점" class="level2">
<h2 class="anchored" data-anchor-id="re-weighting-관점">4.2. Re-weighting 관점</h2>
<p>이 식은 관측 데이터의 분포 <img src="https://latex.codecogs.com/png.latex?P(v)">를 이용해 다음과 같이 다시 쓸 수 있습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(v%20%5Csetminus%20x%20%7C%20do(x))%20=%20%5Cfrac%7BP(v)%7D%7B%5Cprod_%7BX%20%5Cin%20X%7D%20P(x%7Cpa_X)%7D%0A"></p>
<p>만약 <img src="https://latex.codecogs.com/png.latex?X">가 단일 변수라면(Singleton), 이는 다음과 같이 표현됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(v%20%5Csetminus%20x%20%7C%20do(x))%20=%20%5Cfrac%7BP(v)%7D%7BP(x%7Cpa_X)%7D%20=%20P(v''%20%7C%20x,%20pa_X)P(pa_X)%0A"> (여기서 <img src="https://latex.codecogs.com/png.latex?V''%20=%20V%20%5Csetminus%20Pa_X%20%5Csetminus%20%5C%7BX%5C%7D">) [cite_start][cite: 200, 209].</p>
<p>이 공식은 인과 추론 문제를 “어떻게 <img src="https://latex.codecogs.com/png.latex?P(x%7Cpa_x)">(Propensity Score)로 관측 데이터를 역가중(Inverse weighting)할 것인가”의 문제로 연결해 줍니다.</p>
<hr>
</section>
</section>
<section id="the-identification-problem" class="level1">
<h1>5. The Identification Problem</h1>
<p>이제 근본적인 질문을 던져봅시다. <strong>“우리는 언제 인과 효과를 구할 수 있는가?”</strong></p>
<section id="식별-가능성-identifiability-정의" class="level2">
<h2 class="anchored" data-anchor-id="식별-가능성-identifiability-정의">5.1. 식별 가능성 (Identifiability) 정의</h2>
<p>[cite_start]인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">가 인과 그래프 <img src="https://latex.codecogs.com/png.latex?G">로부터 <strong>식별 가능하다(Identifiable)</strong>는 것은, 관측 가능한 변수들의 확률 분포 <img src="https://latex.codecogs.com/png.latex?P(v)"> (<img src="https://latex.codecogs.com/png.latex?P(v)%3E0">)만으로 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 유일하게(Uniquely) 계산해낼 수 있다는 뜻입니다[cite: 219].</p>
<p><img src="https://latex.codecogs.com/png.latex?P%5E%7BM_1%7D(v)%20=%20P%5E%7BM_2%7D(v)%20%5Cimplies%20P%5E%7BM_1%7D(y%7Cdo(x))%20=%20P%5E%7BM_2%7D(y%7Cdo(x))"></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L03/images/identifiability_venn.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Identifiability Venn Diagram. 관측 분포 P(v)와 그래프 G를 공유하는 모든 모델(M1, M2)이 동일한 인과 효과 P(y|do(x))를 내놓는다면, 그 효과는 식별 가능하다. 만약 그렇지 않다면(빨간 교집합 영역), 식별 불가능하다.</figcaption>
</figure>
</div>
<p>[cite_start]즉, 데이터(<img src="https://latex.codecogs.com/png.latex?P(v)">)와 가정(<img src="https://latex.codecogs.com/png.latex?G">)이 같다면, 내부 파라미터가 달라도 결론(<img src="https://latex.codecogs.com/png.latex?Q">)은 같아야 한다는 것입니다 [cite: 302-304].</p>
<hr>
</section>
</section>
<section id="identification-in-markovian-models" class="level1">
<h1>6. Identification in Markovian Models</h1>
<p>모든 관련 변수가 관측된(Hidden variable이 없는) 마르코프 모형에서는 인과 효과가 <strong>항상 식별 가능</strong>합니다.</p>
<section id="general-theorem" class="level2">
<h2 class="anchored" data-anchor-id="general-theorem">6.1. General Theorem</h2>
<p>[cite_start]모든 변수 <img src="https://latex.codecogs.com/png.latex?V">가 측정된 마르코프 모형의 인과 그래프 <img src="https://latex.codecogs.com/png.latex?G">가 주어졌을 때, 임의의 집합 <img src="https://latex.codecogs.com/png.latex?X,%20Y">에 대한 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">는 식별 가능하며, 다음 두 단계로 계산됩니다 [cite: 361-364].</p>
<ol type="1">
<li><strong>Truncated Factorization:</strong> 전체 시스템의 개입 후 분포를 구합니다. <img src="https://latex.codecogs.com/png.latex?P(v'%20%7C%20do(x))%20=%20%5Cprod_%7BV_i%20%5Cin%20V%20%5Csetminus%20X%7D%20P(v_i%20%7C%20pa_i)"></li>
<li><strong>Marginalization (Hence step):</strong> 관심 있는 결과 변수 <img src="https://latex.codecogs.com/png.latex?Y">를 제외한 나머지 변수(<img src="https://latex.codecogs.com/png.latex?V'%20%5Csetminus%20Y">)를 합(Summation)하여 제거합니다. <img src="https://latex.codecogs.com/png.latex?P(y%20%7C%20do(x))%20=%20%5Csum_%7BV'%20%5Csetminus%20Y%7D%20%5Cprod_%7BV_i%20%5Cin%20V%20%5Csetminus%20X%7D%20P(v_i%20%7C%20pa_i)"></li>
</ol>
<hr>
</section>
</section>
<section id="adjustment-formulas-backdoor-adjustment" class="level1">
<h1>7. Adjustment Formulas (Backdoor Adjustment)</h1>
<p>위의 일반 정리를 실전에서 자주 쓰이는 형태로 정리한 것이 <strong>조정 공식(Adjustment Formula)</strong>입니다.</p>
<section id="adjustment-by-direct-parents-singleton" class="level2">
<h2 class="anchored" data-anchor-id="adjustment-by-direct-parents-singleton">7.1. Adjustment by Direct Parents (Singleton)</h2>
<p>[cite_start]단일 변수 <img src="https://latex.codecogs.com/png.latex?X">에 대해, 그 부모 변수들 <img src="https://latex.codecogs.com/png.latex?Pa_X">가 모두 관측되었다면, 인과 효과는 다음과 같이 부모 변수를 조정(Conditioning)하여 계산할 수 있습니다 [cite: 368-369].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bpa_X%7D%20P(y%7Cx,%20pa_X)P(pa_X)%0A"></p>
<p>이 공식은 “원인의 직접적인 원인(Parents)”을 통제하면 교란 요인을 차단할 수 있다는 직관을 수식화한 것입니다.</p>
</section>
<section id="adjustment-by-direct-parents-set-of-treatments---advanced" class="level2">
<h2 class="anchored" data-anchor-id="adjustment-by-direct-parents-set-of-treatments---advanced">7.2. Adjustment by Direct Parents (Set of Treatments) - Advanced</h2>
<p>만약 <img src="https://latex.codecogs.com/png.latex?X">가 단일 변수가 아니라 변수들의 집합 <img src="https://latex.codecogs.com/png.latex?X%20=%20%5C%7BX_1,%20...,%20X_k%5C%7D">라면 어떻게 될까요? [cite_start]변수들이 위상학적 순서(Topological order)로 정렬되어 있다고 가정할 때, 다음 조건이 만족되면 일반화된 조정 공식을 사용할 수 있습니다 [cite: 374-379].</p>
<p><strong>Theorem:</strong> 만약 모든 <img src="https://latex.codecogs.com/png.latex?i%20%3C%20j">에 대해, <img src="https://latex.codecogs.com/png.latex?Pa_%7BX_j%7D%20%5Csetminus%20(X_%7B%3Cj%7D%20%5Ccup%20Pa_%7BX_%7B%3Cj%7D%7D%5E-)">가 <img src="https://latex.codecogs.com/png.latex?X_i">의 자손(Descendant)이 아니라면:</p>
<p><img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))%20=%20%5Csum_%7Bpa_X%5E-%7D%20P(y%7Cx,%20pa_X%5E-)P(pa_X%5E-)"> (여기서 <img src="https://latex.codecogs.com/png.latex?Pa_X%5E-%20=%20Pa_X%20%5Csetminus%20X">)</p>
<p>[cite_start]<strong>Proof Sketch (by Induction):</strong> [cite: 382-401]</p>
<p>이 증명은 <img src="https://latex.codecogs.com/png.latex?P(x_%7B%5Cle%20i%7D%20%7C%20pa_%7BX_%7B%5Cle%20i%7D%7D%5E-)">가 <img src="https://latex.codecogs.com/png.latex?%5Cprod_%7BX%20%5Cin%20X_%7B%5Cle%20i%7D%7D%20P(x%7Cpa_X)">와 같음을 보이는 귀납법을 사용합니다. 1. <strong>Base case:</strong> <img src="https://latex.codecogs.com/png.latex?i=1">일 때 성립함은 자명합니다. 2. <strong>Hypothesis:</strong> <img src="https://latex.codecogs.com/png.latex?i-1">까지 성립한다고 가정하고, <img src="https://latex.codecogs.com/png.latex?i">번째 단계에서 조건부 독립(d-separation)과 연쇄 법칙(Chain rule)을 사용하여 식을 전개합니다. 3. 핵심은 <img src="https://latex.codecogs.com/png.latex?P(pa_%7BX_i%7D'%20%7C%20x_%7B%3Ci%7D,%20pa_%7BX_%7B%3Ci%7D%7D%5E-)"> 항이 <img src="https://latex.codecogs.com/png.latex?P(pa_%7BX_i%7D'%20%7C%20pa_%7BX_%7B%3Ci%7D%7D%5E-)">로 단순화되는 과정에 있으며, 이는 가정된 그래프 구조(자손이 아님) 덕분에 성립합니다.</p>
<p>[cite_start]이 정리는 복잡한 다중 처치(Multiple Treatments) 상황에서도 부모 변수들을 적절히 조정하면 인과 효과를 식별할 수 있음을 보장합니다[cite: 414].</p>
<hr>
</section>
</section>
<section id="handling-latent-variables-latent-season-example" class="level1">
<h1>8. Handling Latent Variables: Latent Season Example</h1>
<p>마지막으로, 만약 중요한 교란 변수가 관측되지 않았다면(Latent) 어떻게 될까요? [cite_start]앞선 스프링클러 예제에서 <strong>Season이 관측 불가능한 잠재 변수</strong>라고 가정해 봅시다[cite: 419].</p>
<p>우리는 <img src="https://latex.codecogs.com/png.latex?Q_2%20=%20P(Wt%20%7C%20do(Sp=on))">을 계산하고 싶습니다. 원래 식은 다음과 같았습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?Q_2%20=%20%5Csum_%7Bsn,%20rn%7D%20P(sn)P(rn%7Csn)P(wt%7CSp=on,%20rn)"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?P(sn)">과 <img src="https://latex.codecogs.com/png.latex?P(rn%7Csn)">은 관측 불가능한 <img src="https://latex.codecogs.com/png.latex?sn">을 포함하고 있어 계산이 불가능해 보입니다. 하지만 수식을 정리해보면 놀라운 결과를 얻습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0AQ_2%20&amp;=%20%5Csum_%7Brn%7D%20P(wt%7CSp=on,%20rn)%20%5Csum_%7Bsn%7D%20P(sn)P(rn%7Csn)%20%5C%5C%0A&amp;=%20%5Csum_%7Brn%7D%20P(wt%7CSp=on,%20rn)%20%5Csum_%7Bsn%7D%20P(rn,%20sn)%20%5C%5C%0A&amp;=%20%5Csum_%7Brn%7D%20P(wt%7CSp=on,%20rn)%20P(rn)%0A%5Cend%7Baligned%7D%0A"> [cite_start][cite: 462-465]</p>
<p><strong>결론:</strong> 최종 식 <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Brn%7D%20P(wt%7CSp=on,%20rn)%20P(rn)">에는 관측 불가능한 <img src="https://latex.codecogs.com/png.latex?Season">이 사라졌습니다! 이는 <img src="https://latex.codecogs.com/png.latex?Season">을 몰라도, <img src="https://latex.codecogs.com/png.latex?Rain">과 <img src="https://latex.codecogs.com/png.latex?Sprinkler">만 관측하면 인과 효과를 계산할 수 있음을 의미합니다.</p>
<p>이 예시는 모든 교란 변수를 통제할 수 없는 상황에서도, 그래프 구조와 확률 법칙을 잘 활용하면 인과 효과가 <strong>식별 가능(Identifiable)</strong>할 수 있음을 시사합니다.</p>
<hr>
</section>
<section id="summary" class="level1">
<h1>Summary</h1>
<ol type="1">
<li><strong>인과 효과의 식별:</strong> 관측 데이터(<img src="https://latex.codecogs.com/png.latex?P(v)">)와 인과 그래프(<img src="https://latex.codecogs.com/png.latex?G">)를 통해 개입 효과(<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">)를 유일하게 결정하는 과정입니다.</li>
<li><strong>Truncated Factorization:</strong> <img src="https://latex.codecogs.com/png.latex?P(v%20%5Csetminus%20x%20%7C%20do(x))%20=%20%5Cprod_%7BV_i%20%5Cin%20V%20%5Csetminus%20X%7D%20P(v_i%20%7C%20pa_i)">. 모든 마르코프 모형의 기초가 되는 공식입니다.</li>
<li><strong>Adjustment Formula:</strong> <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))%20=%20%5Csum_%7Bpa_X%7D%20P(y%7Cx,%20pa_X)P(pa_X)">. 원인의 부모 변수를 조정하여 인과 효과를 계산하는 실용적인 공식입니다.</li>
<li><strong>잠재 변수:</strong> 변수가 숨겨져 있어도(Latent), 구조에 따라 인과 효과가 식별 가능할 수 있습니다.</li>
</ol>
<hr>
<section id="check-list-coverage-verification" class="level3">
<h3 class="anchored" data-anchor-id="check-list-coverage-verification">Check List: Coverage &amp; Verification</h3>
<ul>
<li><strong>SCM &amp; Intervention Definition:</strong> <img src="https://latex.codecogs.com/png.latex?%5Ccheckmark"> (Sec 2)</li>
<li><strong>The Challenge (Static vs Change):</strong> <img src="https://latex.codecogs.com/png.latex?%5Ccheckmark"> (Sec 1)</li>
<li><strong>Sprinkler Example (Obs vs Intervention):</strong> <img src="https://latex.codecogs.com/png.latex?%5Ccheckmark"> (Sec 3)</li>
<li><strong>Truncated Factorization Theory:</strong> <img src="https://latex.codecogs.com/png.latex?%5Ccheckmark"> (Sec 4)</li>
<li><strong>Identifiability Definition (Venn Diagram):</strong> <img src="https://latex.codecogs.com/png.latex?%5Ccheckmark"> (Sec 5)</li>
<li><strong>Identification in Markovian Models (Theorem):</strong> <img src="https://latex.codecogs.com/png.latex?%5Ccheckmark"> (Sec 6)</li>
<li><strong>Adjustment Formula (Singleton):</strong> <img src="https://latex.codecogs.com/png.latex?%5Ccheckmark"> (Sec 7.1)</li>
<li><strong>Adjustment Formula (Set of Treatments - Proof included):</strong> <img src="https://latex.codecogs.com/png.latex?%5Ccheckmark"> (Sec 7.2)</li>
<li><strong>Latent Variable Case (Derivation included):</strong> <img src="https://latex.codecogs.com/png.latex?%5Ccheckmark"> (Sec 8)</li>
</ul>
<p><strong>누락된 내용:</strong> 없음. 강의 자료의 모든 핵심 정리와 예제를 포함하였으며, 특히 Optional로 표시된 다중 처치(Set of Treatments) 증명 과정까지 상세히 기술하였습니다.</p>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L03/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 05. Adjustment Criterion (Part 1)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L05/part-01/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>인과 추론(Causal Inference)의 핵심 목표 중 하나는 관찰된 데이터 분포 <img src="https://latex.codecogs.com/png.latex?P(V)">로부터 개입 분포(Interventional Distribution) <img src="https://latex.codecogs.com/png.latex?P(Y%7Cdo(X))">를 식별(Identification)하는 것입니다. 이를 위한 가장 강력하고 널리 알려진 도구는 <strong>Back-door Criterion</strong>입니다.</p>
<p>하지만 Back-door Criterion은 충분조건(sufficient condition)일 뿐 필요조건(necessary condition)은 아닙니다. 즉, Back-door Criterion을 만족하지 못하더라도 <img src="https://latex.codecogs.com/png.latex?P(Y%7Cdo(X))">를 식별할 수 있는 경우가 존재합니다. [cite_start]이번 포스트에서는 Back-door Criterion을 복습하고, 왜 더 일반화된 <strong>Adjustment Criterion</strong>이 필요한지 그 동기(Motivation)와 한계(Tightness)를 구체적인 그래프 예시를 통해 살펴봅니다[cite: 5, 8, 13].</p>
<blockquote class="blockquote">
<p>[cite_start]<strong>Note:</strong> 본 포스트는 서울대학교 데이터사이언스 대학원 이상학 교수님의 “인과추론 및 실습” 강의 자료를 바탕으로 작성되었습니다[cite: 1, 2, 3].</p>
</blockquote>
<hr>
</section>
<section id="the-back-door-criterion-review" class="level1">
<h1>2. The Back-door Criterion (Review)</h1>
<p>[cite_start]Pearl(2000)이 제시한 Back-door Criterion은 공변량 집합 <img src="https://latex.codecogs.com/png.latex?Z">를 조정(adjustment)함으로써 인과 효과를 식별할 수 있는 조건을 제시합니다[cite: 38].</p>
<section id="definition" class="level2">
<h2 class="anchored" data-anchor-id="definition">2.1. Definition</h2>
<p>[cite_start]어떤 변수 집합 <img src="https://latex.codecogs.com/png.latex?Z">가 변수 쌍 <img src="https://latex.codecogs.com/png.latex?(X,%20Y)">에 대해 <strong>Back-door Criterion</strong>을 만족하려면 다음 두 가지 조건을 충족해야 합니다[cite: 18, 23, 32].</p>
<ol type="1">
<li>[cite_start]<strong>Condition (i) - No Descendants:</strong> <img src="https://latex.codecogs.com/png.latex?Z">의 어떤 노드도 <img src="https://latex.codecogs.com/png.latex?X">의 후손(descendant)이 아니어야 합니다[cite: 19, 24, 34].</li>
<li>[cite_start]<strong>Condition (ii) - Blocking Paths:</strong> <img src="https://latex.codecogs.com/png.latex?Z">는 <img src="https://latex.codecogs.com/png.latex?X">로 들어가는 화살표를 포함하는 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 모든 경로(path)를 차단(block)해야 합니다[cite: 26, 35].</li>
</ol>
</section>
<section id="identification-formula" class="level2">
<h2 class="anchored" data-anchor-id="identification-formula">2.2. Identification Formula</h2>
<p>[cite_start]만약 집합 <img src="https://latex.codecogs.com/png.latex?Z">가 위 조건을 만족한다면, <img src="https://latex.codecogs.com/png.latex?Y">에 대한 <img src="https://latex.codecogs.com/png.latex?X">의 인과 효과는 다음과 같이 식별 가능합니다[cite: 27, 36, 37].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(y%7Cx,z)P(z)%0A"></p>
<p>이 식은 우리가 <img src="https://latex.codecogs.com/png.latex?do">-calculus나 가상의 실험 없이, 관찰된 데이터의 조건부 확률 <img src="https://latex.codecogs.com/png.latex?P(y%7Cx,z)">와 주변 확률 <img src="https://latex.codecogs.com/png.latex?P(z)">만으로 인과 효과를 계산할 수 있음을 의미합니다.</p>
<hr>
</section>
</section>
<section id="why-no-descendants-simpsons-paradox" class="level1">
<h1>3. Why “No Descendants”? (Simpson’s Paradox)</h1>
<p>Back-door Criterion의 첫 번째 조건인 “조정 집합 <img src="https://latex.codecogs.com/png.latex?Z">에 <img src="https://latex.codecogs.com/png.latex?X">의 후손을 포함하지 말라”는 조건은 왜 필요할까요? [cite_start]이는 <strong>인과 경로(Causal Path)</strong>를 차단하지 않기 위해서입니다[cite: 100].</p>
<p>[cite_start]가장 유명한 예시인 심슨의 역설(Simpson’s Paradox)을 통해 이를 직관적으로 이해할 수 있습니다[cite: 40]. 아래 두 가지 그래프 구조를 비교해 봅시다.</p>
<section id="case-1-confounder-structure" class="level3">
<h3 class="anchored" data-anchor-id="case-1-confounder-structure">Case 1: Confounder Structure</h3>
<p>첫 번째 경우는 성별(<img src="https://latex.codecogs.com/png.latex?F">)이 약물 복용(<img src="https://latex.codecogs.com/png.latex?X">)과 회복(<img src="https://latex.codecogs.com/png.latex?Y">) 모두에 영향을 주는 <strong>교란 요인(Confounder)</strong>인 상황입니다.</p>
<p><img src="https://shsha0110.github.io/posts/lecture/L05/part-01/images/simpsons_paradox_confounder.png" class="img-fluid" alt="Figure 1: Confounder Structure. F(성별)는 X(약물)와 Y(회복)의 공통 원인이다. 점선 화살표는 교란 경로를 의미한다."> [cite_start]<em>(그림 설명: <img src="https://latex.codecogs.com/png.latex?F%20%5Cto%20X">, <img src="https://latex.codecogs.com/png.latex?F%20%5Cto%20Y">, <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Y"> 구조를 가짐. 여기서 <img src="https://latex.codecogs.com/png.latex?%5Cemptyset">은 Back-door를 만족하지 못하며, <img src="https://latex.codecogs.com/png.latex?%5C%7BF%5C%7D">를 조정해야 올바른 인과 효과를 추정할 수 있음[cite: 39, 53].)</em></p>
<p>이 경우 데이터를 합쳐서(Aggregated) 보면 안 되고, 성별(<img src="https://latex.codecogs.com/png.latex?F">)로 층화(stratify)하여 분석해야 합니다. 즉, <img src="https://latex.codecogs.com/png.latex?%5C%7BF%5C%7D">는 <strong>Admissible</strong> 합니다.</p>
</section>
<section id="case-2-mediator-structure" class="level3">
<h3 class="anchored" data-anchor-id="case-2-mediator-structure">Case 2: Mediator Structure</h3>
<p>두 번째 경우는 약물(<img src="https://latex.codecogs.com/png.latex?X">)이 혈압 등 중간 매개체(<img src="https://latex.codecogs.com/png.latex?F">)에 영향을 주고, 그것이 다시 회복(<img src="https://latex.codecogs.com/png.latex?Y">)에 영향을 주는 <strong>매개(Mediator)</strong> 상황입니다.</p>
<p><img src="https://shsha0110.github.io/posts/lecture/L05/part-01/images/simpsons_paradox_mediator.png" class="img-fluid" alt="Figure 2: Mediator Structure. X(약물)가 F(중간 요인)에 영향을 주고, F가 Y(회복)에 영향을 준다."> [cite_start]<em>(그림 설명: <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20F%20%5Cto%20Y"> 및 <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Y"> 구조. 여기서 <img src="https://latex.codecogs.com/png.latex?F">는 <img src="https://latex.codecogs.com/png.latex?X">의 후손(Descendant)이다. <img src="https://latex.codecogs.com/png.latex?F">를 조정해버리면 <img src="https://latex.codecogs.com/png.latex?X">에서 <img src="https://latex.codecogs.com/png.latex?Y">로 가는 인과 경로 중 하나를 차단하게 되어 전체 효과를 과소평가하게 된다[cite: 39].)</em></p>
<p>이 경우, <img src="https://latex.codecogs.com/png.latex?F">는 <img src="https://latex.codecogs.com/png.latex?X">의 후손이므로 Back-door Criterion의 조건 (i)을 위반합니다. 따라서 <img src="https://latex.codecogs.com/png.latex?%5C%7BF%5C%7D">는 <strong>Not Admissible</strong> 합니다. [cite_start]데이터를 합쳐서 보는 것(<img src="https://latex.codecogs.com/png.latex?%5Cemptyset"> is admissible)이 오히려 올바른 접근입니다[cite: 54, 55].</p>
</section>
<section id="data-example" class="level3">
<h3 class="anchored" data-anchor-id="data-example">Data Example</h3>
<p>[cite_start]강의 자료의 데이터 예시를 보면 구조적 차이의 중요성이 명확해집니다[cite: 41, 42].</p>
<ul>
<li><strong>Male (<img src="https://latex.codecogs.com/png.latex?F=0">)</strong>: Drug 60% vs No-Drug 70% (약물이 안 좋아 보임)</li>
<li><strong>Female (<img src="https://latex.codecogs.com/png.latex?F=1">)</strong>: Drug 20% vs No-Drug 30% (약물이 안 좋아 보임)</li>
<li><strong>Aggregated</strong>: Drug <img src="https://latex.codecogs.com/png.latex?%5Capprox"> 50% vs No-Drug <img src="https://latex.codecogs.com/png.latex?%5Capprox"> 40% (약물이 좋아 보임)</li>
</ul>
<p>구조가 Case 1(Confounder)이라면 층화된 결과(안 좋다)가 진실이고, Case 2(Mediator)라면 합쳐진 결과(좋다)가 진실입니다. 즉, <strong>데이터만으로는 인과 효과를 알 수 없으며, 인과 그래프(구조)에 따라 조정 대상이 달라집니다.</strong></p>
<hr>
</section>
</section>
<section id="conditional-back-door-criterion" class="level1">
<h1>4. Conditional Back-door Criterion</h1>
<p>Back-door Criterion은 특정 조건부 상황으로 확장될 수 있습니다. [cite_start]이를 <strong>Conditional Back-door Criterion</strong>이라 합니다[cite: 60].</p>
<p>우리가 특정 공변량 <img src="https://latex.codecogs.com/png.latex?W">가 주어진 상황에서의 <img src="https://latex.codecogs.com/png.latex?X">의 효과, 즉 <img src="https://latex.codecogs.com/png.latex?w">-specific effect인 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x),%20w)">를 알고 싶다고 가정해 봅시다. [cite_start]이때 측정 가능한 집합 <img src="https://latex.codecogs.com/png.latex?Z">가 있어 <img src="https://latex.codecogs.com/png.latex?W%20%5Ccup%20Z">가 Back-door Criterion을 만족한다면, 이 효과는 다음과 같이 식별됩니다[cite: 61, 63].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x),%20%5Cforall%20w)%20=%20%5Csum_%7Bz%7D%20P(y%7Cx,z,%20%5Cforall%20w)P(z%7C%5Cforall%20w)%20=%20P_x(y%7CW)%0A"></p>
<p>[cite_start]이 공식의 유도는 <img src="https://latex.codecogs.com/png.latex?do">-calculus에 대한 이해가 필요합니다[cite: 64].</p>
<hr>
</section>
<section id="tightness-of-the-back-door-criterion" class="level1">
<h1>5. Tightness of the Back-door Criterion</h1>
<p>이제 이번 포스트의 핵심 주제인 <strong>Back-door Criterion의 한계(Tightness)</strong>로 넘어갑니다. 질문의 핵심은 다음과 같습니다.</p>
<blockquote class="blockquote">
<p>“Back-door Criterion은 충분조건이다. 그렇다면 필요조건인가?” 즉, “Back-door를 만족하지 못하면 조정(Adjustment)으로 식별이 불가능한가?”</p>
</blockquote>
<p>정답은 <strong>“아니오”</strong> 입니다. [cite_start]Back-door Criterion은 충분하지만 필요조건은 아닙니다(Sufficient but not necessary)[cite: 95].</p>
<section id="counter-example-graph" class="level2">
<h2 class="anchored" data-anchor-id="counter-example-graph">5.1. Counter-Example Graph</h2>
<p>다음과 같은 인과 그래프를 고려해 봅시다. [cite_start]여기서 <img src="https://latex.codecogs.com/png.latex?X%20=%20%5C%7BX_1,%20X_2%5C%7D">이고 <img src="https://latex.codecogs.com/png.latex?Y">는 결과 변수입니다[cite: 76, 78].</p>
<p><img src="https://shsha0110.github.io/posts/lecture/L05/part-01/images/tightness_dag.png" class="img-fluid" alt="Figure 3: Counter-Example DAG for Back-door Criterion. X1 -> Z1 -> Z2 -> X2 -> Y 의 경로와 X1 -> Y 직접 경로가 존재하며, Z2와 Y 사이에 bidirected edge(confounder)가 존재한다."> [cite_start]<em>(그림 설명: <img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20Z_1%20%5Cto%20Z_2%20%5Cto%20X_2%20%5Cto%20Y">, <img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20Y">. 그리고 <img src="https://latex.codecogs.com/png.latex?Z_2%20%5Cleftrightarrow%20Y"> (점선) 관계가 존재함. <img src="https://latex.codecogs.com/png.latex?X%20=%20%5C%7BX_1,%20X_2%5C%7D">가 처리 변수 집합임[cite: 76, 79, 80, 81, 82, 83].)</em></p>
</section>
<section id="why-back-door-fails-here" class="level2">
<h2 class="anchored" data-anchor-id="why-back-door-fails-here">5.2. Why Back-door Fails here?</h2>
<p>이 그래프에서 가능한 모든 조정 변수 후보는 <img src="https://latex.codecogs.com/png.latex?%5C%7BZ_1,%20Z_2%5C%7D">입니다. [cite_start]그러나 <img src="https://latex.codecogs.com/png.latex?Z_1">과 <img src="https://latex.codecogs.com/png.latex?Z_2">는 모두 <img src="https://latex.codecogs.com/png.latex?X_1">의 후손(descendant)입니다[cite: 86].</p>
<ul>
<li>Back-door Criterion의 <strong>Condition (i)</strong>: “<img src="https://latex.codecogs.com/png.latex?Z">의 어떤 노드도 <img src="https://latex.codecogs.com/png.latex?X">의 후손이면 안 된다.”</li>
<li>[cite_start]이 그래프에서는 <img src="https://latex.codecogs.com/png.latex?X=%5C%7BX_1,%20X_2%5C%7D">이므로, <img src="https://latex.codecogs.com/png.latex?X_1">의 후손인 <img src="https://latex.codecogs.com/png.latex?Z_1,%20Z_2">를 조정 집합에 포함하는 순간 <strong>조건 (i)을 위반</strong>하게 됩니다[cite: 78].</li>
</ul>
<p>따라서, 이 그래프에서는 <strong>Back-door Admissible Set이 존재하지 않습니다.</strong></p>
</section>
<section id="but-adjustment-is-possible" class="level2">
<h2 class="anchored" data-anchor-id="but-adjustment-is-possible">5.3. But Adjustment IS Possible!</h2>
<p>[cite_start]놀랍게도, <img src="https://latex.codecogs.com/png.latex?do">-calculus나 다른 방법을 통해 유도해보면 이 그래프에서 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">는 여전히 표준 조정 공식(Standard Adjustment Formula) 형태로 식별 가능합니다[cite: 93, 94].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(y%7Cx,z)P(z)%0A"></p>
<p>이것이 시사하는 바는 명확합니다.</p>
<ol type="1">
<li>Back-door Criterion은 <strong>너무 보수적(strict)</strong>입니다.</li>
<li>[cite_start]<img src="https://latex.codecogs.com/png.latex?X">의 후손(descendant)이라 할지라도, 조정을 위해 사용될 수 있으며 심지어 <strong>필요한 경우</strong>도 있습니다[cite: 102].</li>
<li>[cite_start]특히, <strong><img src="https://latex.codecogs.com/png.latex?X">의 후손이면서 동시에 <img src="https://latex.codecogs.com/png.latex?X">의 조상(ancestor)인 변수</strong>(예: <img src="https://latex.codecogs.com/png.latex?X_1">의 후손이면서 <img src="https://latex.codecogs.com/png.latex?X_2">의 조상인 <img src="https://latex.codecogs.com/png.latex?Z_2">)들은 인과 경로를 방해하지 않으면서 교란을 제거하는 데 사용될 수 있습니다[cite: 103].</li>
</ol>
</section>
<section id="conclusion-motivation-for-adjustment-criterion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-motivation-for-adjustment-criterion">5.4. Conclusion: Motivation for Adjustment Criterion</h2>
<p>결국 우리는 Back-door Criterion보다 더 일반화된 기준이 필요합니다. [cite_start]“무조건 후손은 안 된다”가 아니라, <strong>“정말 피해야 할 변수는 무엇인가?”(What are the variables that we really need to avoid?)</strong>를 정의해야 합니다[cite: 104].</p>
<p>[cite_start]Condition (i)의 원래 목적은 <strong>인과 경로(Causal Path)를 보존(preserve)</strong>하는 것입니다[cite: 99, 100]. 따라서 후손이더라도 인과 경로를 막지 않는다면 조정 집합에 포함시킬 수 있어야 합니다. 이것이 바로 다음 포스트에서 다룰 <strong>Adjustment Criterion</strong>의 등장 배경입니다.</p>
<hr>
</section>
</section>
<section id="summary" class="level1">
<h1>6. Summary</h1>
<ul>
<li><strong>Back-door Criterion</strong>은 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 식별하는 강력한 도구이지만, <img src="https://latex.codecogs.com/png.latex?X">의 후손을 조정 집합에서 원천적으로 배제합니다.</li>
<li><strong>Simpson’s Paradox</strong> 예시는 후손(Mediator)을 통제하면 안 되는 이유를 잘 보여줍니다.</li>
<li>하지만 <strong>복잡한 그래프(Tightness example)</strong>에서는 <img src="https://latex.codecogs.com/png.latex?X">의 구성요소 사이에 있는 변수(<img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20Z%20%5Cto%20X_2">)들이 존재하며, 이들은 후손임에도 불구하고 조정이 필요하거나 가능할 수 있습니다.</li>
<li>Back-door Criterion은 충분조건이지만 필요조건이 아니며, 이를 보완하기 위해 더 일반적인 <strong>Adjustment Criterion</strong>이 필요합니다.</li>
</ul>
<p>다음 포스트에서는 어떤 후손이 허용되고 어떤 후손이 금지되는지 명확히 정의하는 <strong>Adjustment Criterion의 정의와 알고리즘</strong>에 대해 자세히 알아보겠습니다.</p>
<hr>
<section id="누락-방지-검증-missing-content-check" class="level3">
<h3 class="anchored" data-anchor-id="누락-방지-검증-missing-content-check">누락 방지 검증 (Missing Content Check)</h3>
<p>강의 자료(PDF 1-11p)를 기반으로 아래 항목들이 포함되었는지 확인합니다.</p>
<ul>
<li>[cite_start][x] <strong>Back-door Criterion의 정의 (조건 i, ii)</strong> [cite: 18, 19, 26]</li>
<li>[cite_start][x] <strong>Adjustment Formula 수식</strong> [cite: 37]</li>
<li>[cite_start][x] <strong>Simpson’s Paradox 예시 (표 및 그래프 구조 설명)</strong> [cite: 41, 42, 53, 55]</li>
<li>[cite_start][x] <strong>Conditional Back-door Criterion의 개념 및 수식</strong> [cite: 60, 63]</li>
<li>[cite_start][x] <strong>Tightness 예제 그래프 (<img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20Z%20%5Cto%20X_2"> 구조)</strong> [cite: 76, 78]</li>
<li>[cite_start][x] <strong>Back-door의 한계 설명 (후손이지만 조정 가능한 케이스 존재)</strong> [cite: 93, 94, 95]</li>
<li>[cite_start][x] <strong>Condition (i)의 원래 목적 (Causal path 보존)</strong> [cite: 99, 100]</li>
</ul>
<p><strong>Note on omitted content:</strong> PDF의 12페이지 이후(Algorithm, Theoretical Tool 등)는 제공된 파일 범위에 포함되지 않아 본 포스트에서는 다루지 않고 “다음 포스트”로 넘겼습니다. 제공된 1~11페이지 내의 내용은 모두 포함되었습니다.</p>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L05/part-01/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 05. Adjustment Criterion (Part 2)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L05/part-02/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>이전 포스트(Part 1)에서 우리는 <strong>Back-door Criterion</strong>이 인과 효과 식별을 위한 <strong>충분조건(Sufficient condition)</strong>이지만, <strong>필요조건(Necessary condition)</strong>은 아님을 확인했습니다. 즉, Back-door Criterion을 만족하지 못하더라도 변수들의 구조적 위치에 따라 여전히 조정(Adjustment)을 통해 인과 효과를 구할 수 있는 경우가 존재합니다.</p>
<p>이번 포스트에서는 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 표준 조정 공식(Standard Adjustment Formula)으로 식별하기 위한 <strong>필요충분조건(Necessary and Sufficient Condition)</strong>인 <strong>Adjustment Criterion</strong>에 대해 다룹니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AZ%20%5Ctext%7B%20satisfies%20Adjustment%20Criterion%7D%20%5Ciff%20P(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(y%7Cx,z)P(z)%0A"></p>
<p>[cite_start]이를 위해 <strong>Proper Causal Path</strong>라는 개념을 도입하고, 복잡한 그래프에서 유효한 조정 집합 <img src="https://latex.codecogs.com/png.latex?Z">를 찾아내는 알고리즘과 <strong>명시적 구성(Explicit Construction)</strong> 방법을 살펴봅니다[cite: 131, 134].</p>
<hr>
</section>
<section id="proper-causal-paths-pcp" class="level1">
<h1>2. Proper Causal Paths (PCP)</h1>
<p>Adjustment Criterion을 정의하기 전에, <strong>어떤 경로(Path)를 건드리면 안 되는지</strong>를 명확히 해야 합니다.</p>
<section id="definition" class="level2">
<h2 class="anchored" data-anchor-id="definition">2.1. Definition</h2>
<p>[cite_start]<strong>Proper Causal Path (진인과경로)</strong>는 <img src="https://latex.codecogs.com/png.latex?X">에서 출발하여 <img src="https://latex.codecogs.com/png.latex?Y">로 향하는 인과 경로(Directed path) 중, <strong>시작점인 <img src="https://latex.codecogs.com/png.latex?X">를 제외하고는 <img src="https://latex.codecogs.com/png.latex?X"> 집합의 다른 노드를 거치지 않는 경로</strong>를 의미합니다[cite: 138, 139].</p>
<ul>
<li><strong>Causal Path:</strong> 화살표의 방향이 일관되게 <img src="https://latex.codecogs.com/png.latex?X">에서 <img src="https://latex.codecogs.com/png.latex?Y">로 흐르는 경로.</li>
<li><strong>Proper:</strong> 경로상에 <img src="https://latex.codecogs.com/png.latex?X">의 다른 원소가 포함되지 않음.</li>
</ul>
<p><img src="https://shsha0110.github.io/posts/lecture/L05/part-02/images/proper_causal_path_example.png" class="img-fluid" alt="Figure 1: Proper vs Non-proper Causal Paths. X_1 \to W_3 \to Y와 X_2 \to W_2 \to Y는 Proper하다. 반면 X_1 \to W_1 \to X_2 \dots는 중간에 X_2를 거치므로 Non-proper하다."> [cite_start]<em>(그림 설명: <img src="https://latex.codecogs.com/png.latex?X=%5C%7BX_1,%20X_2%5C%7D">인 상황. <img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20W_3%20%5Cto%20Y">는 <img src="https://latex.codecogs.com/png.latex?X">의 다른 원소를 거치지 않으므로 Proper Causal Path이다. 반면 <img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20W_1%20%5Cto%20X_2%20%5Cto%20W_2%20%5Cto%20Y">는 경로 중간에 <img src="https://latex.codecogs.com/png.latex?X_2(%5Cin%20X)">가 포함되므로 Non-proper Causal Path이다.)</em> [cite: 146, 148]</p>
</section>
<section id="why-proper-causal-paths-matter" class="level2">
<h2 class="anchored" data-anchor-id="why-proper-causal-paths-matter">2.2. Why Proper Causal Paths Matter?</h2>
<p>우리가 구하고자 하는 것은 <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 <strong>총 효과(Total Effect)</strong>입니다. [cite_start]따라서 <img src="https://latex.codecogs.com/png.latex?X">에서 <img src="https://latex.codecogs.com/png.latex?Y">로 흐르는 인과적 흐름을 담고 있는 <strong>Proper Causal Path를 차단해서는 안 됩니다</strong>[cite: 160].</p>
<p>만약 Proper Causal Path 상에 있는 변수(Mediator)나 그 변수의 후손(Descendant)을 조정 집합 <img src="https://latex.codecogs.com/png.latex?Z">에 포함하면 어떻게 될까요? 간단한 체인 구조 <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20W%20%5Cto%20Y">와 <img src="https://latex.codecogs.com/png.latex?W%20%5Cto%20Z">가 있는 그래프를 가정해 봅시다. [cite_start]여기서 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))%20=%20P(y%7Cx)">입니다 (Back-door 경로가 없음)[cite: 152, 161].</p>
<p>하지만 우리가 <img src="https://latex.codecogs.com/png.latex?Z">(Mediator의 후손)에 대해 조정(Adjustment)을 수행하면 편향이 발생합니다. 이를 수식으로 확인해 봅시다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Csum_%7Bz%7D%20P(y%7Cx,z)P(z)%20&amp;=%20%5Csum_%7Bz,w%7D%20P(y%7Cx,z,w)P(w%7Cx,z)P(z)%20%5Cquad%20(%5Ctext%7BLaw%20of%20Total%20Probability%7D)%20%5C%5C%0A&amp;=%20%5Csum_%7Bz,w%7D%20P(y%7Cw)P(w%7Cx,z)P(z)%20%5Cquad%20(Y%20%5Cperp%5C!%5C!%5Cperp%20X,%20Z%20%7C%20W)%20%5C%5C%0A&amp;=%20%5Csum_%7Bw%7D%20P(y%7Cw)%20%5Csum_%7Bz%7D%20P(w%7Cx,z)P(z)%0A%5Cend%7Baligned%7D%0A"> [cite_start][cite: 162-165]</p>
<p>진정한 인과 효과는 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))%20=%20%5Csum_w%20P(y%7Cw)P(w%7Cx)">입니다. 하지만 위 식의 두 번째 항 <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bz%7D%20P(w%7Cx,z)P(z)">는 일반적으로 <img src="https://latex.codecogs.com/png.latex?P(w%7Cx)">와 다릅니다. [cite_start]이는 <img src="https://latex.codecogs.com/png.latex?P(z)%20%5Cneq%20P(z%7Cx)">이기 때문입니다[cite: 172, 174].</p>
<p>[cite_start]결국, Proper Causal Path 상의 변수나 그 후손을 조정하면 인과 효과 추정치가 <strong>왜곡(disturbed)</strong>됩니다[cite: 175].</p>
<hr>
</section>
</section>
<section id="the-adjustment-criterion" class="level1">
<h1>3. The Adjustment Criterion</h1>
<p>Shpitser et al.&nbsp;(2010)은 Back-door Criterion을 일반화하여 <strong>Adjustment Criterion</strong>을 제안했습니다. [cite_start]집합 <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?(X,%20Y)">에 대해 Admissible하기 위해서는 다음 두 조건을 만족해야 합니다[cite: 179].</p>
<section id="condition-i-preserve-causal-paths" class="level2">
<h2 class="anchored" data-anchor-id="condition-i-preserve-causal-paths">3.1. Condition (i): Preserve Causal Paths</h2>
<blockquote class="blockquote">
<p><strong>Condition (i):</strong> <img src="https://latex.codecogs.com/png.latex?Z">의 어떤 원소도 <img src="https://latex.codecogs.com/png.latex?X">에서 <img src="https://latex.codecogs.com/png.latex?Y">로 가는 <strong>Proper Causal Path</strong> 상에 있는 변수(<img src="https://latex.codecogs.com/png.latex?X"> 제외)의 후손(descendant)이 아니어야 한다.</p>
</blockquote>
<p><img src="https://latex.codecogs.com/png.latex?%0AZ%20%5Ccap%20De(W%20%5Csetminus%20X)%20=%20%5Cemptyset,%20%5Cquad%20%5Ctext%7Bfor%20any%20%7D%20W%20%5Ctext%7B%20on%20a%20proper%20causal%20path%7D%0A"></p>
<p>[cite_start]이 조건은 우리가 인과 경로를 실수로 차단하거나 왜곡하는 것을 방지합니다[cite: 180, 186]. 즉, “미래의 변수”를 통제하지 말라는 원칙을 더 엄밀하게 정의한 것입니다.</p>
</section>
<section id="condition-ii-block-spurious-paths" class="level2">
<h2 class="anchored" data-anchor-id="condition-ii-block-spurious-paths">3.2. Condition (ii): Block Spurious Paths</h2>
<blockquote class="blockquote">
<p><strong>Condition (ii):</strong> <img src="https://latex.codecogs.com/png.latex?Z">는 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 모든 <strong>Proper Non-causal Path</strong>를 차단(block)해야 한다.</p>
</blockquote>
<p><img src="https://latex.codecogs.com/png.latex?%0A(Y%20%5Cperp%5C!%5C!%5Cperp%20X%20%7C%20Z)_%7B%5Cmathcal%7BG%7D'%7D%0A"></p>
<p>여기서 <strong>Proper Non-causal Path</strong>란 <img src="https://latex.codecogs.com/png.latex?X">에서 시작하지만 인과 경로가 아닌(화살표가 <img src="https://latex.codecogs.com/png.latex?X">로 들어오거나 중간에 꺾이는) 경로들을 의미합니다. [cite_start]이것들은 교란(Confounding) 요인이므로 반드시 막아야 합니다[cite: 190, 197].</p>
<blockquote class="blockquote">
<p>[cite_start]<strong>Note:</strong> 초기 논문에서는 단순히 ’non-causal paths’라고 했으나, 이후 ’proper non-causal paths’로 수정되었습니다[cite: 198, 199].</p>
</blockquote>
<hr>
</section>
</section>
<section id="implementation-idea-the-mathcalg-method" class="level1">
<h1>4. Implementation Idea: The <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'"> Method</h1>
<p>Condition (ii)를 그래프상에서 직관적으로 검사하기 위해 보조 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">를 사용할 수 있습니다.</p>
<section id="step-1-forbidden-set-f-확인" class="level3">
<h3 class="anchored" data-anchor-id="step-1-forbidden-set-f-확인">Step 1: Forbidden Set (<img src="https://latex.codecogs.com/png.latex?F">) 확인</h3>
<p>먼저 Condition (i)에 위배되는 변수들을 찾습니다. Proper Causal Path 위에 있는 모든 변수(X 제외)와 그 후손들을 모아 집합 <img src="https://latex.codecogs.com/png.latex?F">를 만듭니다. [cite_start]<img src="https://latex.codecogs.com/png.latex?Z">는 <img src="https://latex.codecogs.com/png.latex?F">와 겹치면 안 됩니다[cite: 217, 218].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AF%20=%20De(W%20%5Csetminus%20X)_%7B%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D%7D%0A"></p>
</section>
<section id="step-2-construct-mathcalg" class="level3">
<h3 class="anchored" data-anchor-id="step-2-construct-mathcalg">Step 2: Construct <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'"></h3>
<p>원래 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D">에서 <strong>모든 Proper Causal Path의 첫 번째 엣지(Edge)를 제거</strong>합니다. [cite_start]이렇게 만든 그래프를 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">라고 합니다[cite: 227, 313].</p>
</section>
<section id="step-3-d-separation-test" class="level3">
<h3 class="anchored" data-anchor-id="step-3-d-separation-test">Step 3: D-separation Test</h3>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">에서 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">가 <img src="https://latex.codecogs.com/png.latex?Z">에 의해 d-separated 되는지 확인합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A(X%20%5Cperp%5C!%5C!%5Cperp%20Y%20%7C%20Z)_%7B%5Cmathcal%7BG%7D'%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">에서는 인과 경로가 끊겨 있으므로, 남은 연결은 모두 Non-causal Path입니다. [cite_start]만약 <img src="https://latex.codecogs.com/png.latex?Z">가 이들을 모두 막는다면 Condition (ii)가 만족됩니다[cite: 228, 314].</p>
<hr>
</section>
</section>
<section id="a-worked-example" class="level1">
<h1>5. A Worked Example</h1>
<p>복잡한 그래프 예시를 통해 실제로 적용해 봅시다. * <strong>Target:</strong> <img src="https://latex.codecogs.com/png.latex?X=%5C%7BX_1,%20X_2%5C%7D">, <img src="https://latex.codecogs.com/png.latex?Y=%5C%7BY_1,%20Y_2%5C%7D"> * [cite_start]<strong>Candidates:</strong> <img src="https://latex.codecogs.com/png.latex?Z=%5C%7BC,%20D,%20I%5C%7D">가 Admissible한가? [cite: 263]</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L05/part-02/images/complex_dag_example.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: Example Graph for Adjustment Criterion. <img src="https://latex.codecogs.com/png.latex?X=%5C%7BX_1,%20X_2%5C%7D">에서 <img src="https://latex.codecogs.com/png.latex?Y=%5C%7BY_1,%20Y_2%5C%7D">로 가는 복잡한 경로들이 얽혀 있다.</figcaption>
</figure>
</div>
<section id="step-1-identify-proper-causal-paths" class="level3">
<h3 class="anchored" data-anchor-id="step-1-identify-proper-causal-paths">Step 1: Identify Proper Causal Paths</h3>
<p><img src="https://latex.codecogs.com/png.latex?X">에서 <img src="https://latex.codecogs.com/png.latex?Y">로 가는 Proper Causal Path를 찾습니다. * <img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20Y_1"> * <img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20E%20%5Cto%20Y_2"> * <img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20D%20%5Cto%20I%20%5Cto%20Y_1"> (이 경로는 <img src="https://latex.codecogs.com/png.latex?X_2">를 안 거치므로 Proper) * <img src="https://latex.codecogs.com/png.latex?X_2%20%5Cto%20F%20%5Cto%20Y_2"> [cite_start]등이 있습니다[cite: 260].</p>
</section>
<section id="step-2-check-condition-i-forbidden-set" class="level3">
<h3 class="anchored" data-anchor-id="step-2-check-condition-i-forbidden-set">Step 2: Check Condition (i) (Forbidden Set)</h3>
<p>Proper Causal Path 위에 있는 중간 변수들은 <img src="https://latex.codecogs.com/png.latex?E,%20F"> 등입니다. * <img src="https://latex.codecogs.com/png.latex?E">의 후손: <img src="https://latex.codecogs.com/png.latex?%5C%7BE,%20Y_2%20%5Cdots%5C%7D"> * <img src="https://latex.codecogs.com/png.latex?F">의 후손: <img src="https://latex.codecogs.com/png.latex?%5C%7BF,%20H,%20Y_2%20%5Cdots%5C%7D"> 따라서 <img src="https://latex.codecogs.com/png.latex?Z">에 <img src="https://latex.codecogs.com/png.latex?E,%20F,%20H">가 포함되면 안 됩니다. [cite_start]우리의 후보 <img src="https://latex.codecogs.com/png.latex?Z=%5C%7BC,%20D,%20I%5C%7D">는 이들과 겹치지 않으므로 <strong>Condition (i) 만족</strong>[cite: 293, 294].</p>
</section>
<section id="step-3-check-condition-ii-via-mathcalg" class="level3">
<h3 class="anchored" data-anchor-id="step-3-check-condition-ii-via-mathcalg">Step 3: Check Condition (ii) via <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'"></h3>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">를 만들기 위해 Proper Causal Path의 첫 엣지를 자릅니다. * <img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20Y_1"> 제거 * <img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20D"> 제거 * <img src="https://latex.codecogs.com/png.latex?X_1%20%5Cto%20E"> 제거 * <img src="https://latex.codecogs.com/png.latex?X_2%20%5Cto%20F"> 제거 [cite_start]등등[cite: 313].</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L05/part-02/images/g_prime_example.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3: The Modified Graph <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">. Proper Causal Path의 첫 번째 엣지들이 제거된 상태이다. 점선 화살표와 Back-door 경로들만 남았다.</figcaption>
</figure>
</div>
<p>이제 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">에서 <img src="https://latex.codecogs.com/png.latex?(X%20%5Cperp%5C!%5C!%5Cperp%20Y%20%7C%20%5C%7BC,%20D,%20I%5C%7D)">인지 확인합니다. <img src="https://latex.codecogs.com/png.latex?C,%20D,%20I">를 조건부로 주었을 때, 남은 교란 경로들이 모두 차단된다면 <img src="https://latex.codecogs.com/png.latex?Z">는 유효합니다. [cite_start]이 예제에서는 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">에서 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">가 분리되므로 <strong>Condition (ii) 만족</strong>입니다[cite: 333, 334].</p>
<hr>
</section>
</section>
<section id="explicit-construction-of-admissible-sets" class="level1">
<h1>6. Explicit Construction of Admissible Sets</h1>
<p>“매번 <img src="https://latex.codecogs.com/png.latex?Z">를 추측하고 검증해야 하나요?”라는 질문에 대한 답으로, 유효한 조정 집합을 <strong>직접 구성(Explicit Construction)</strong>하는 방법이 있습니다. [cite_start]이를 <strong>One-shot Verification</strong>이라고도 합니다[cite: 413].</p>
<section id="lemma-constructive-method" class="level3">
<h3 class="anchored" data-anchor-id="lemma-constructive-method">Lemma: Constructive Method</h3>
<p>만약 어떤 Admissible Set이 존재한다면, 다음 집합 <img src="https://latex.codecogs.com/png.latex?Z_0">도 반드시 Admissible합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AZ_0%20=%20An%5E%7B-%7D(X%20%5Ccup%20Y)%20%5Csetminus%20F%0A"></p>
<ul>
<li>[cite_start]<img src="https://latex.codecogs.com/png.latex?An%5E%7B-%7D(X%20%5Ccup%20Y)">: <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">의 조상(Ancestors)들의 집합 (<img src="https://latex.codecogs.com/png.latex?X,%20Y"> 자신 제외)[cite: 358, 363].</li>
<li>[cite_start]<img src="https://latex.codecogs.com/png.latex?F">: Condition (i)에 의해 금지된 변수들 (Proper Causal Path 상의 변수 및 후손)[cite: 354].</li>
</ul>
</section>
<section id="significance" class="level3">
<h3 class="anchored" data-anchor-id="significance">Significance</h3>
<p>[cite_start]이 정리가 강력한 이유는 <strong>“<img src="https://latex.codecogs.com/png.latex?Z_0">가 실패하면, 그 어떤 <img src="https://latex.codecogs.com/png.latex?Z">도 실패한다”</strong>는 점입니다[cite: 359, 412]. 즉, 우리는 <img src="https://latex.codecogs.com/png.latex?Z_0"> 딱 하나만 만들어보고 테스트하면 됩니다.</p>
</section>
<section id="apply-to-example" class="level3">
<h3 class="anchored" data-anchor-id="apply-to-example">Apply to Example</h3>
<p>위의 예제 그래프에 적용해 봅시다. 1. [cite_start]<strong>Forbidden Set (<img src="https://latex.codecogs.com/png.latex?F">):</strong> <img src="https://latex.codecogs.com/png.latex?%5C%7BE,%20F,%20H%5C%7D"> (PC Path 상의 변수와 그 후손)[cite: 402]. 2. [cite_start]<strong>Ancestors (<img src="https://latex.codecogs.com/png.latex?An%5E%7B-%7D">):</strong> <img src="https://latex.codecogs.com/png.latex?X,%20Y">의 조상을 모두 찾으면 <img src="https://latex.codecogs.com/png.latex?%5C%7BA,%20B,%20C,%20D,%20E,%20F,%20I%5C%7D"> 입니다[cite: 403]. 3. <strong>Construct <img src="https://latex.codecogs.com/png.latex?Z_0">:</strong> <img src="https://latex.codecogs.com/png.latex?Z_0%20=%20%5C%7BA,%20B,%20C,%20D,%20E,%20F,%20I%5C%7D%20%5Csetminus%20%5C%7BE,%20F,%20H%5C%7D%20=%20%5C%7BA,%20B,%20C,%20D,%20I%5C%7D"> 4. <strong>Verification:</strong> 이 <img src="https://latex.codecogs.com/png.latex?Z_0">가 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">에서 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">를 d-separation 시키는지 확인합니다. [cite_start]확인 결과 Admissible 합니다[cite: 404, 405].</p>
<hr>
</section>
</section>
<section id="summary" class="level1">
<h1>7. Summary</h1>
<ul>
<li><strong>Proper Causal Path:</strong> <img src="https://latex.codecogs.com/png.latex?X">에서 시작해 <img src="https://latex.codecogs.com/png.latex?Y">로 가는 경로 중, 다시 <img src="https://latex.codecogs.com/png.latex?X">를 거치지 않는 경로. 이 경로들은 인과 효과의 본질이므로 <strong>절대 차단하거나 조정해서는 안 됩니다.</strong></li>
<li><strong>Adjustment Criterion:</strong>
<ol type="1">
<li><ol type="i">
<li>Proper Causal Path 상의 변수(및 후손)를 <img src="https://latex.codecogs.com/png.latex?Z">에 포함하지 말 것.</li>
</ol></li>
<li><ol start="2" type="i">
<li><img src="https://latex.codecogs.com/png.latex?Z">는 모든 Proper Non-causal Path(교란 경로)를 차단할 것.</li>
</ol></li>
</ol></li>
<li><strong>Implementation:</strong> <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">(PC Path의 첫 엣지 제거)를 이용하면 Condition (ii)를 d-separation 문제로 쉽게 환원할 수 있습니다.</li>
<li><strong>Constructive Solution:</strong> <img src="https://latex.codecogs.com/png.latex?Z_0%20=%20An%5E%7B-%7D(X%20%5Ccup%20Y)%20%5Csetminus%20F">를 계산함으로써, 유효한 조정 집합의 존재 여부를 한 번에 파악할 수 있습니다.</li>
</ul>
<p>이로써 우리는 Back-door Criterion의 한계를 넘어, 그래프 구조만 주어진다면 언제, 무엇을 조정해야 하는지 완벽하게 판단할 수 있는 도구를 갖추게 되었습니다.</p>
<hr>
<section id="누락-방지-검증-missing-content-check" class="level3">
<h3 class="anchored" data-anchor-id="누락-방지-검증-missing-content-check">누락 방지 검증 (Missing Content Check)</h3>
<p>강의 자료(PDF 0502 파일)의 내용을 기반으로 아래 항목들이 포함되었는지 확인합니다.</p>
<ul>
<li>[cite_start][x] <strong>Adjustment Criterion 정의 (필요충분조건)</strong> [cite: 134]</li>
<li>[cite_start][x] <strong>Proper Causal Path 정의 및 예시</strong> [cite: 138-148]</li>
<li>[cite_start][x] <strong>Proper Causal Path 조정 시 발생하는 편향(Math Derivation)</strong> [cite: 162-176]</li>
<li>[cite_start][x] <strong>Adjustment Criterion의 두 가지 조건 (i), (ii)</strong> [cite: 179-197]</li>
<li>[cite_start][x] <strong>Implementation Idea (Forbidden Set <img src="https://latex.codecogs.com/png.latex?F">, Graph <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D'">)</strong> [cite: 202-234]</li>
<li>[cite_start][x] <strong>복잡한 그래프 예제 (Evaluating Set Z)</strong> [cite: 247-334]</li>
<li>[cite_start][x] <strong>Explicit Construction Lemma (<img src="https://latex.codecogs.com/png.latex?Z_0">) 및 예제 적용</strong> [cite: 353-405]</li>
<li>[cite_start][x] <strong>One-shot verification의 의미</strong> [cite: 412, 413]</li>
</ul>
<p><strong>Note:</strong> 제공된 PDF의 모든 핵심 내용(페이지 1-22)이 본 포스트에 반영되었습니다.</p>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L05/part-02/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 05. Adjustment Criterion (Part 3)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L05/part-03/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>이전 포스트들에서 우리는 <strong>Adjustment Criterion</strong>의 이론적 배경과 정의를 살펴보았습니다. 우리는 특정 변수 집합 <img src="https://latex.codecogs.com/png.latex?Z">가 주어졌을 때, 그것이 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 식별(Identification)하기 위해 유효한지(Admissible) 판별하는 방법을 알고 있습니다.</p>
<p>하지만 현실적인 인과 추론 문제에서는 단순히 “이 <img src="https://latex.codecogs.com/png.latex?Z">가 유효한가?”를 묻는 것을 넘어, <strong>“유효한 <img src="https://latex.codecogs.com/png.latex?Z">들을 어떻게 모두 찾을 것인가?”</strong> 또는 <strong>“어떤 <img src="https://latex.codecogs.com/png.latex?Z">를 선택하는 것이 최선인가?”</strong>라는 질문에 직면하게 됩니다.</p>
<section id="motivation-why-find-all-sets" class="level2">
<h2 class="anchored" data-anchor-id="motivation-why-find-all-sets">1.1. Motivation: Why Find All Sets?</h2>
<p>[cite_start]일반적으로 주어진 인과 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D">에서 Admissible Set은 하나가 아니라 여러 개 존재할 수 있습니다. [cite: 439] 그렇다면 우리는 왜 여러 집합을 고려해야 할까요?</p>
<ol type="1">
<li><strong>Measurement Cost (측정 비용):</strong> 어떤 변수는 측정하기 매우 비싸거나 위험할 수 있습니다.</li>
<li><strong>Variance (분산):</strong> 어떤 조정 집합은 다른 집합보다 추정량의 분산을 더 줄여줄 수 있습니다.</li>
<li>[cite_start]<strong>Availability &amp; Ethics:</strong> 개인정보 보호나 공정성 이슈로 특정 변수를 사용할 수 없을 수 있습니다. [cite: 444]</li>
</ol>
<blockquote class="blockquote">
<p><strong>Example:</strong> 어떤 질병(<img src="https://latex.codecogs.com/png.latex?X">)과 결과(<img src="https://latex.codecogs.com/png.latex?Y">) 사이의 인과 효과를 추정할 때, 유전적 조건(<img src="https://latex.codecogs.com/png.latex?A">)과 두통(<img src="https://latex.codecogs.com/png.latex?B">)이 모두 각각 유효한 조정 집합이라고 가정해 봅시다 (<img src="https://latex.codecogs.com/png.latex?%5C%7BA%5C%7D"> is admissible, <img src="https://latex.codecogs.com/png.latex?%5C%7BB%5C%7D"> is admissible). * <img src="https://latex.codecogs.com/png.latex?A"> (유전자): 검사 비용이 비쌈, 개인정보 이슈. * <img src="https://latex.codecogs.com/png.latex?B"> (두통): 설문으로 쉽게 확인 가능.</p>
<p>이 경우, 이론적으로는 둘 다 유효하지만 현실적으로는 <img src="https://latex.codecogs.com/png.latex?B">를 선택하는 것이 훨씬 유리합니다. [cite_start]따라서 우리는 <strong>가능한 모든 Admissible Set을 나열</strong>하고, 그중 비용-효율적인 것을 선택할 필요가 있습니다. [cite: 446-454]</p>
</blockquote>
<hr>
</section>
</section>
<section id="the-computational-challenge" class="level1">
<h1>2. The Computational Challenge</h1>
<p>문제는 그래프의 크기가 커질수록 가능한 부분집합의 개수가 기하급수적으로 늘어난다는 점입니다.</p>
<section id="exponential-search-space" class="level2">
<h2 class="anchored" data-anchor-id="exponential-search-space">2.1. Exponential Search Space</h2>
<p>변수가 <img src="https://latex.codecogs.com/png.latex?n">개일 때, 가능한 변수 조합은 <img src="https://latex.codecogs.com/png.latex?2%5En">개입니다. [cite_start]만약 우리가 “Magic Function” <img src="https://latex.codecogs.com/png.latex?f">를 가지고 있어서 모든 Admissible Set을 <img src="https://latex.codecogs.com/png.latex?O(1)"> 시간에 찾는다고 해도, 출력해야 할 집합의 개수 자체가 지수적으로 많다면 전체 실행 시간은 엄청나게 길어질 것입니다. [cite: 457]</p>
<p>따라서 우리의 목표는 “전체 실행 시간을 줄이는 것”이 아니라(이는 불가능할 수 있음), <strong>“첫 번째 답을 찾을 때까지, 그리고 하나의 답을 찾고 다음 답을 찾을 때까지 걸리는 시간”</strong>을 합리적으로 유지하는 것입니다.</p>
</section>
<section id="polynomial-delay" class="level2">
<h2 class="anchored" data-anchor-id="polynomial-delay">2.2. Polynomial Delay</h2>
<p>우리는 <strong>Polynomial Delay</strong> 알고리즘을 목표로 합니다. 알고리즘이 <img src="https://latex.codecogs.com/png.latex?O(n%5Ed)"> (단, <img src="https://latex.codecogs.com/png.latex?d">는 상수) 시간 내에 다음 작업을 수행한다면 Polynomial Delay를 가진다고 합니다.</p>
<ol type="1">
<li>프로그램 시작 후 첫 번째 출력을 내놓을 때까지.</li>
<li>하나의 출력을 내놓고 다음 출력을 내놓을 때까지.</li>
<li>마지막 출력을 내놓고 종료할 때까지.</li>
</ol>
<p><img src="https://shsha0110.github.io/posts/lecture/L05/part-03/images/polynomial_delay_timeline.png" class="img-fluid" alt="Figure 1: Concept of Polynomial Delay. 각 출력(s_1, s_2, \dots) 사이의 간격이 입력 크기 n의 다항식 시간 O(n^d) 이내로 제한된다."> [cite_start]<em>(그림 설명: 시간 축 위에서 알고리즘이 해(solution) <img src="https://latex.codecogs.com/png.latex?s_1,%20s_2,%20%5Cdots">를 출력하는 시점을 나타냄. 각 간격이 너무 길어지지 않도록 보장하는 것이 핵심임.)</em> [cite: 470-479]</p>
<hr>
</section>
</section>
<section id="theoretical-foundation-inclusion-restriction" class="level1">
<h1>3. Theoretical Foundation: Inclusion &amp; Restriction</h1>
<p>효율적인 탐색을 위해 “Divide and Conquer(분할 정복)” 전략을 사용할 것입니다. 이를 위해서는 탐색 공간의 특정 가지(branch)에 해가 존재하는지 빠르게(Polynomial time에) 판단할 수 있는 도구가 필요합니다.</p>
<section id="the-lemma" class="level2">
<h2 class="anchored" data-anchor-id="the-lemma">3.1. The Lemma</h2>
<p>우리가 찾고자 하는 분리 집합(Separating Set) <img src="https://latex.codecogs.com/png.latex?Z">가 다음 조건을 만족한다고 가정해 봅시다. <img src="https://latex.codecogs.com/png.latex?I%20%5Csubseteq%20Z%20%5Csubseteq%20R"> 즉, <img src="https://latex.codecogs.com/png.latex?Z">는 반드시 <img src="https://latex.codecogs.com/png.latex?I">를 포함(Include)해야 하고, <img src="https://latex.codecogs.com/png.latex?R">에 포함(Restrict)되어야 합니다.</p>
<p>이때, <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">를 분리하는 유효한 <img src="https://latex.codecogs.com/png.latex?Z">가 범위 <img src="https://latex.codecogs.com/png.latex?%5BI,%20R%5D"> 내에 존재하는지 확인하는 방법은 다음과 같습니다.</p>
<blockquote class="blockquote">
<p><strong>Lemma (Existence of Separator in Range):</strong> 범위 <img src="https://latex.codecogs.com/png.latex?I%20%5Csubseteq%20Z%20%5Csubseteq%20R"> 내에 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">를 분리하는 집합 <img src="https://latex.codecogs.com/png.latex?Z">가 <strong>존재한다면</strong>, 특수하게 구성된 집합 <strong><img src="https://latex.codecogs.com/png.latex?Z_0"></strong> 또한 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">를 분리한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?Z_0%20=%20An(X%20%5Ccup%20Y%20%5Ccup%20I)%20%5Ccap%20R"></p>
<p>[cite_start]반대로, <strong><img src="https://latex.codecogs.com/png.latex?Z_0">가 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">를 분리하지 못한다면, 해당 범위 내에 분리 집합은 존재하지 않는다.</strong> [cite: 493-498]</p>
</blockquote>
<p><img src="https://shsha0110.github.io/posts/lecture/L05/part-03/images/inclusion_restriction_venn.png" class="img-fluid" alt="Figure 2: Venn Diagram of Inclusion (I) and Restriction (R). Z는 I를 감싸고 R 내부에 있어야 한다. Z_0는 이 조건 하에서 구성 가능한 가장 ’조상’에 가까운 집합이다."> [cite_start]<em>(그림 설명: <img src="https://latex.codecogs.com/png.latex?I">를 포함하고 <img src="https://latex.codecogs.com/png.latex?R">에 속하는 <img src="https://latex.codecogs.com/png.latex?Z">들의 공간. <img src="https://latex.codecogs.com/png.latex?Z_0">는 <img src="https://latex.codecogs.com/png.latex?X,%20Y,%20I">의 조상(<img src="https://latex.codecogs.com/png.latex?An">)이면서 <img src="https://latex.codecogs.com/png.latex?R">에 속하는 교집합으로 정의됨.)</em> [cite: 492]</p>
</section>
<section id="significance" class="level2">
<h2 class="anchored" data-anchor-id="significance">3.2. Significance</h2>
<p>이 Lemma가 중요한 이유는 <strong>탐색의 가지치기(Pruning)</strong>를 가능하게 하기 때문입니다. 우리는 <img src="https://latex.codecogs.com/png.latex?Z_0">를 구성하고 d-separation을 검사하는 것을 <img src="https://latex.codecogs.com/png.latex?O(n+m)"> (그래프 탐색 시간) 내에 수행할 수 있습니다. [cite_start]만약 <img src="https://latex.codecogs.com/png.latex?Z_0">가 실패하면, 그 하위의 모든 조합을 일일이 확인하지 않고 즉시 탐색을 중단할 수 있습니다. [cite: 508-509]</p>
<hr>
</section>
</section>
<section id="the-algorithm-list-seps" class="level1">
<h1>4. The Algorithm: <code>list-seps</code></h1>
<p>이제 위 이론을 바탕으로 모든 Admissible Set을 찾는 알고리즘 <code>list-seps</code>를 정의합니다.</p>
<section id="setup" class="level2">
<h2 class="anchored" data-anchor-id="setup">4.1. Setup</h2>
<p>먼저, <strong>Adjustment Criterion</strong>의 조건 (i)(Proper Causal Path 보존)을 만족하기 위해, 절대 조정하면 안 되는 변수들의 집합 <img src="https://latex.codecogs.com/png.latex?F">를 정의합니다. 그리고 알고리즘 내부적으로 사용할 <img src="https://latex.codecogs.com/png.latex?F%5E+">를 정의합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?F%5E+%20=%20X%20%5Ccup%20Y%20%5Ccup%20F"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?F">: <img src="https://latex.codecogs.com/png.latex?X">를 제외한 Proper Causal Path 상의 변수들과 그들의 후손.</li>
<li><img src="https://latex.codecogs.com/png.latex?G'">: Proper Causal Path의 첫 번째 엣지를 모두 제거한 그래프. (Part 2에서 배운 내용)</li>
</ul>
<p>이제 우리는 <img src="https://latex.codecogs.com/png.latex?G'">에서 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">를 분리하되, <img src="https://latex.codecogs.com/png.latex?F%5E+">의 원소는 포함하지 않는 <img src="https://latex.codecogs.com/png.latex?Z">를 찾으면 됩니다. [cite_start]이는 초기 조건 <img src="https://latex.codecogs.com/png.latex?I=%5Cemptyset">, <img src="https://latex.codecogs.com/png.latex?R=V%20%5Csetminus%20F%5E+">로 설정하여 해결할 수 있습니다. [cite: 529-533]</p>
</section>
<section id="algorithm-structure-divide-and-conquer" class="level2">
<h2 class="anchored" data-anchor-id="algorithm-structure-divide-and-conquer">4.2. Algorithm Structure (Divide and Conquer)</h2>
<p>[cite_start]함수 <code>list-seps(G, X, Y, I, R)</code>은 다음과 같이 재귀적으로 동작합니다. [cite: 596-602, 696-704]</p>
<ol type="1">
<li><strong>Existence Check:</strong> 먼저 <code>exist-sep(G, X, Y, I, R)</code>을 호출합니다. (앞서 배운 Lemma 사용).
<ul>
<li>만약 <code>False</code>라면, 이 범위에 해가 없으므로 즉시 <strong>Return</strong> (가지치기).</li>
</ul></li>
<li><strong>Output Check:</strong> 만약 <img src="https://latex.codecogs.com/png.latex?I%20=%20R">이라면, 더 이상 선택의 여지가 없습니다. <img src="https://latex.codecogs.com/png.latex?I">가 유효한 집합이므로 <strong>Output <img src="https://latex.codecogs.com/png.latex?I"></strong>.</li>
<li><strong>Branching:</strong> 아직 결정되지 않은 변수 <img src="https://latex.codecogs.com/png.latex?W%20%5Cin%20R%20%5Csetminus%20I">를 하나 선택합니다.
<ul>
<li><strong>Case 1 (Include W):</strong> <img src="https://latex.codecogs.com/png.latex?W">를 조정 집합에 포함시킵니다. <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> <code>list-seps(G, X, Y, I</code> <img src="https://latex.codecogs.com/png.latex?%5Ccup"> <code>{W}, R)</code></li>
<li><strong>Case 2 (Exclude W):</strong> <img src="https://latex.codecogs.com/png.latex?W">를 조정 집합에서 배제합니다. <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> <code>list-seps(G, X, Y, I, R</code> <img src="https://latex.codecogs.com/png.latex?%5Csetminus"> <code>{W})</code></li>
</ul></li>
</ol>
<p>이 과정을 통해 유효한 집합이 있는 경로만 탐색하며(Polynomial Delay), 모든 해를 나열할 수 있습니다.</p>
<hr>
</section>
</section>
<section id="worked-example" class="level1">
<h1>5. Worked Example</h1>
<p>다음 그래프를 통해 알고리즘을 단계별로 추적해 봅시다.</p>
<p><img src="https://shsha0110.github.io/posts/lecture/L05/part-03/images/running_example_graph.png" class="img-fluid" alt="Figure 3: Running Example Graph. X \to C \to Y (Proper Causal Path), X \leftarrow A \to B \to Y, X \leftarrow D \leftarrow \dots 등의 구조를 가짐."> [cite_start]<em>(그림 설명: <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20C%20%5Cto%20Y">가 Proper Causal Path임. <img src="https://latex.codecogs.com/png.latex?A,%20B,%20D">는 교란 요인일 가능성이 있음. 점선 화살표는 Hidden Confounder 혹은 Back-door path를 의미.)</em> [cite: 535]</p>
<section id="step-1-initialize" class="level2">
<h2 class="anchored" data-anchor-id="step-1-initialize">Step 1: Initialize</h2>
<ul>
<li><strong>Forbidden Set (<img src="https://latex.codecogs.com/png.latex?F">):</strong> <img src="https://latex.codecogs.com/png.latex?C">는 Proper Causal Path 위에 있으므로 금지됩니다. <img src="https://latex.codecogs.com/png.latex?X,%20Y">도 포함할 수 없습니다.</li>
<li><strong><img src="https://latex.codecogs.com/png.latex?F%5E+">:</strong> <img src="https://latex.codecogs.com/png.latex?%5C%7BX,%20Y,%20C%5C%7D"></li>
<li><strong>Initial Range:</strong>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?I%20=%20%5Cemptyset"></li>
<li><img src="https://latex.codecogs.com/png.latex?R%20=%20V%20%5Csetminus%20F%5E+%20=%20%5C%7BA,%20B,%20D%5C%7D"></li>
</ul></li>
<li>[cite_start]<strong>Graph <img src="https://latex.codecogs.com/png.latex?G'">:</strong> <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20C"> 엣지를 제거하여 Proper Causal Path를 끊습니다. [cite: 546-547]</li>
</ul>
</section>
<section id="step-2-recursion-tree-trace" class="level2">
<h2 class="anchored" data-anchor-id="step-2-recursion-tree-trace">Step 2: Recursion Tree Trace</h2>
<p>알고리즘은 변수를 하나씩 선택하며 <img src="https://latex.codecogs.com/png.latex?I">에 넣을지(<img src="https://latex.codecogs.com/png.latex?I%20%5Ccup%20W">), <img src="https://latex.codecogs.com/png.latex?R">에서 뺄지(<img src="https://latex.codecogs.com/png.latex?R%20%5Csetminus%20W">) 결정합니다.</p>
<ol type="1">
<li><strong>Start:</strong> <img src="https://latex.codecogs.com/png.latex?I=%5C%7B%5C%7D,%20R=%5C%7BA,%20B,%20D%5C%7D">. <code>exist-sep</code> 통과(True).</li>
<li><strong>Pick D:</strong>
<ul>
<li><strong>Branch Left (Include D):</strong> <img src="https://latex.codecogs.com/png.latex?I=%5C%7BD%5C%7D,%20R=%5C%7BA,%20B,%20D%5C%7D">.
<ul>
<li><strong>Pick A:</strong>
<ul>
<li><strong>Include A:</strong> <img src="https://latex.codecogs.com/png.latex?I=%5C%7BA,%20D%5C%7D,%20R=%5C%7BA,%20B,%20D%5C%7D">. … <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> Output <img src="https://latex.codecogs.com/png.latex?%5C%7BA,%20B,%20D%5C%7D,%20%5C%7BA,%20D%5C%7D">…</li>
<li><strong>Exclude A:</strong> <img src="https://latex.codecogs.com/png.latex?R=%5C%7BB,%20D%5C%7D">. …</li>
</ul></li>
</ul></li>
<li><strong>Branch Right (Exclude D):</strong> <img src="https://latex.codecogs.com/png.latex?R=%5C%7BA,%20B%5C%7D">.
<ul>
<li>여기서 만약 <img src="https://latex.codecogs.com/png.latex?D">가 없으면 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">를 분리할 수 없다고 가정해 봅시다.</li>
<li>[cite_start]그러면 <code>exist-sep</code>이 False를 반환하고, 이 가지(branch)는 더 이상 탐색하지 않고 <strong>Pruning</strong> 됩니다. [cite: 561-591]</li>
</ul></li>
</ul></li>
</ol>
</section>
<section id="step-3-result" class="level2">
<h2 class="anchored" data-anchor-id="step-3-result">Step 3: Result</h2>
<p>결과적으로 트리의 리프 노드(Leaf Node) 중에서 <img src="https://latex.codecogs.com/png.latex?I=R">인 지점들이 Admissible Set으로 출력됩니다. 예를 들어 <img src="https://latex.codecogs.com/png.latex?%5C%7BA,%20B,%20D%5C%7D,%20%5C%7BA,%20D%5C%7D,%20%5C%7BB,%20D%5C%7D"> 등이 출력될 수 있습니다. (구체적인 출력은 그래프의 d-separation 구조에 따라 결정됨).</p>
<hr>
</section>
</section>
<section id="complexity-analysis" class="level1">
<h1>6. Complexity Analysis</h1>
<p>이 알고리즘의 효율성은 다음과 같이 분석됩니다.</p>
<ol type="1">
<li><strong>Tree Depth:</strong> 트리의 깊이는 최대 변수의 개수 <img src="https://latex.codecogs.com/png.latex?n">입니다.</li>
<li><strong>Work per Node:</strong> 각 노드에서 <code>exist-sep</code>을 수행하는 데 <img src="https://latex.codecogs.com/png.latex?O(n+m)"> 시간이 걸립니다. (<img src="https://latex.codecogs.com/png.latex?Z_0"> 계산 및 d-sep 확인).</li>
<li><strong>Delay:</strong> 하나의 출력을 찾기 위해 트리의 깊이만큼 내려갔다가 다시 올라오는 과정을 거칩니다. 잘못된 길로 들어서더라도 <code>exist-sep</code> 덕분에 즉시 되돌아옵니다.
<ul>
<li>[cite_start]따라서, 출력과 출력 사이의 지연 시간(Delay)은 최악의 경우에도 <strong><img src="https://latex.codecogs.com/png.latex?O(n(n+m))"></strong>입니다. [cite: 707]</li>
</ul></li>
</ol>
<blockquote class="blockquote">
<p><strong>Conclusion:</strong> [cite_start]전체 해의 개수가 지수적일지라도, 우리는 <img src="https://latex.codecogs.com/png.latex?O(n%5E2)"> 정도의 합리적인 대기 시간으로 유효한 조정 집합들을 하나씩 끊임없이(stream) 얻을 수 있습니다. [cite: 708-709]</p>
</blockquote>
<hr>
</section>
<section id="summary" class="level1">
<h1>7. Summary</h1>
<ul>
<li><strong>Necessity:</strong> 비용, 윤리, 분산 등의 이유로 <em>모든</em> Admissible Set을 탐색하는 것이 필요합니다.</li>
<li><strong>Challenge:</strong> 단순 전수 조사는 지수 시간(<img src="https://latex.codecogs.com/png.latex?2%5En">)이 걸려 불가능합니다. 목표는 <strong>Polynomial Delay</strong>입니다.</li>
<li><strong>Key Tool:</strong> <img src="https://latex.codecogs.com/png.latex?I%20%5Csubseteq%20Z%20%5Csubseteq%20R"> 범위 내에 해가 존재하는지 판별하는 Lemma(<img src="https://latex.codecogs.com/png.latex?Z_0">)를 통해, 가망 없는 탐색 경로를 즉시 차단(Pruning)합니다.</li>
<li><strong>Algorithm:</strong> <code>list-seps</code>는 <img src="https://latex.codecogs.com/png.latex?I">(포함)와 <img src="https://latex.codecogs.com/png.latex?R">(제한)을 갱신하며 재귀적으로 탐색하되, Lemma를 활용해 효율성을 보장합니다.</li>
<li><strong>Performance:</strong> 이 알고리즘은 <img src="https://latex.codecogs.com/png.latex?O(n(n+m))">의 Delay를 보장하여, 대규모 그래프에서도 실용적으로 사용할 수 있습니다.</li>
</ul>
<p>이로써 Adjustment Criterion의 정의부터(Part 1, 2), 실제로 유효한 집합들을 찾아내는 알고리즘(Part 3)까지 모두 다루었습니다. 이제 여러분은 복잡한 인과 그래프가 주어져도 어떤 변수를 통제해야 하는지 완벽하게 분석할 수 있습니다.</p>
<hr>
<section id="누락-방지-검증-missing-content-check" class="level3">
<h3 class="anchored" data-anchor-id="누락-방지-검증-missing-content-check">누락 방지 검증 (Missing Content Check)</h3>
<p>강의 자료(PDF 0503 파일)의 내용을 기반으로 아래 항목들이 포함되었는지 확인합니다.</p>
<ul>
<li>[cite_start][x] <strong>Motivation:</strong> 측정 비용, 분산, 프라이버시 등 여러 집합을 찾아야 하는 이유 [cite: 444]</li>
<li>[cite_start][x] <strong>Computational Challenge:</strong> 지수적 탐색 공간과 “Polynomial Delay”의 정의 [cite: 470-473]</li>
<li>[cite_start][x] <strong>Theoretical Tool (Lemma):</strong> <img src="https://latex.codecogs.com/png.latex?I%20%5Csubseteq%20Z%20%5Csubseteq%20R"> 조건 하의 존재성 판별법 (<img src="https://latex.codecogs.com/png.latex?Z_0">) [cite: 493-496]</li>
<li>[cite_start][x] <strong>Algorithm Structure:</strong> <code>list-seps</code> 함수의 재귀적 구조 (Include/Exclude) [cite: 596-602]</li>
<li>[cite_start][x] <strong>Pruning Strategy:</strong> <code>exist-sep</code>을 이용한 가지치기 [cite: 650-654]</li>
<li>[cite_start][x] <strong>Running Example:</strong> 그래프 예시를 통한 <img src="https://latex.codecogs.com/png.latex?I,%20R"> 변화 추적 [cite: 546-590]</li>
<li>[cite_start][x] <strong>Time Complexity:</strong> <img src="https://latex.codecogs.com/png.latex?O(n(n+m))"> Delay 분석 [cite: 707]</li>
<li>[cite_start][x] <strong>Algorithm Setup:</strong> <img src="https://latex.codecogs.com/png.latex?F%5E+"> 정의 및 초기 조건 [cite: 530-531]</li>
</ul>
<p><strong>Note:</strong> 제공된 PDF의 모든 핵심 내용(페이지 1-22)이 본 포스트에 반영되었습니다.</p>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L05/part-03/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 05. Adjustment Criterion (Part 4)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L05/part-04/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>지금까지 우리는 Judea Pearl의 <strong>SCM(Structural Causal Model)</strong> 관점에서 인과 효과를 식별(Identification)하는 과정을 살펴보았습니다. Back-door Criterion부터 시작해, 더 일반화된 Adjustment Criterion, 그리고 유효한 조정 집합(Admissible Set)을 찾는 알고리즘까지 다루었습니다.</p>
<p>이번 마지막 포스트에서는 이 그래프 기반의 접근법이 통계학 및 경제학에서 널리 쓰이는 Rubin의 <strong>Potential Outcome Framework</strong>와 어떻게 연결되는지 설명합니다. 특히, 인과 추론의 핵심 가정인 <strong>Conditional Ignorability</strong>가 그래프 상에서 어떻게 정당화되는지 알아보고, Adjustment Criterion 전체 내용을 요약합니다.</p>
<hr>
</section>
<section id="connecting-with-ignorability" class="level1">
<h1>2. Connecting with Ignorability</h1>
<p>Potential Outcome(잠재적 결과) 프레임워크에서 인과 효과를 식별하기 위해 가장 중요하게 사용되는 가정은 <strong>Conditional Ignorability(조건부 무시 가능성)</strong>입니다.</p>
<section id="definition" class="level2">
<h2 class="anchored" data-anchor-id="definition">2.1. Definition</h2>
<p>Conditional Ignorability는 반사실적(Counterfactual) 표기법을 사용하여 다음과 같이 정의됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AY_%7Bx%7D%20%5Cperp%5C!%5C!%5Cperp%20X%20%5Cmid%20Z%0A"></p>
<p>[cite_start][cite: 723-724, 733]</p>
<p>여기서: * <img src="https://latex.codecogs.com/png.latex?Y_%7Bx%7D">: 처리가 <img src="https://latex.codecogs.com/png.latex?X=x">로 고정되었을 때의 잠재적 결과 (Potential Outcome) * <img src="https://latex.codecogs.com/png.latex?X">: 실제 관찰된 처리 (Treatment) * <img src="https://latex.codecogs.com/png.latex?Z">: 공변량 집합 (Covariates)</p>
<p>이 식의 의미는 <strong>“공변량 <img src="https://latex.codecogs.com/png.latex?Z">를 통제(Conditioning)했을 때, 잠재적 결과 <img src="https://latex.codecogs.com/png.latex?Y_x">는 처리 <img src="https://latex.codecogs.com/png.latex?X">의 할당과 독립적이다”</strong>라는 것입니다. 즉, <img src="https://latex.codecogs.com/png.latex?Z">가 주어지면, 처리를 받은 그룹과 받지 않은 그룹 간에 체계적인 차이(교란 요인에 의한 편향)가 사라져 마치 무작위 할당(Random Assignment)된 것과 같아짐을 의미합니다.</p>
</section>
<section id="mathematical-equivalence" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-equivalence">2.2. Mathematical Equivalence</h2>
<p>이 가정은 SCM의 <img src="https://latex.codecogs.com/png.latex?do">-calculus 관점에서 다음과 같은 확률적 동치로 표현됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%20%5Cmid%20do(x),%20z)%20=%20P(y%20%5Cmid%20x,%20z)%0A"></p>
<p>[cite_start][cite: 729, 734]</p>
<p>이 등식은 <strong>개입(Intervention)</strong> 후의 확률 분포가 <strong>관찰(Observation)</strong> 된 조건부 확률 분포와 같아짐을 보여줍니다. 즉, <img src="https://latex.codecogs.com/png.latex?Z">가 교란 요인을 모두 차단했다면, 단순히 데이터를 <img src="https://latex.codecogs.com/png.latex?Z">로 층화하여 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">의 관계를 보는 것만으로 인과 효과를 계산할 수 있다는 뜻입니다.</p>
</section>
<section id="the-role-of-adjustment-criterion" class="level2">
<h2 class="anchored" data-anchor-id="the-role-of-adjustment-criterion">2.3. The Role of Adjustment Criterion</h2>
<p>Potential Outcome 프레임워크에서는 연구자가 “우리는 필요한 모든 교란 요인 <img src="https://latex.codecogs.com/png.latex?Z">를 측정했다”고 <strong>가정(Assume)</strong>하고 분석을 시작하는 경우가 많습니다.</p>
<p>하지만 <strong>“그 가정이 타당한가?”</strong>, <strong>“어떤 <img src="https://latex.codecogs.com/png.latex?Z">를 포함해야 이 가정이 성립하는가?”</strong>라는 질문에 대해 Potential Outcome 프레임워크 자체만으로는 답하기 어려울 때가 있습니다.</p>
<p>여기서 <strong>Adjustment Criterion</strong>이 강력한 이론적 도구(Theoretical Tool)가 됩니다.</p>
<blockquote class="blockquote">
<p>[cite_start]“While this is usually ‘assumed’ to hold in the PO framework, the adjustment criterion provides a <strong>justification</strong> under what conditions such set exists based on a given model of reality.” [cite: 735]</p>
</blockquote>
<p>즉, 우리가 현실 세계에 대한 모델(Causal Graph)을 그릴 수 있다면, Adjustment Criterion은 <strong>Conditional Ignorability 가정이 성립하기 위한 <img src="https://latex.codecogs.com/png.latex?Z">의 조건</strong>을 수학적으로 증명해 줍니다. 그래프 상에서 <img src="https://latex.codecogs.com/png.latex?Z">가 Back-door/Adjustment Criterion을 만족한다면, <img src="https://latex.codecogs.com/png.latex?Y_x%20%5Cperp%5C!%5C!%5Cperp%20X%20%7C%20Z">는 가정이 아니라 <strong>정리(Theorem)</strong>로서 성립하게 됩니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L05/part-04/images/scm_po_bridge_diagram.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: The bridge between SCM and PO Frameworks. 그래프(Graph)를 통해 현실을 모델링하면, Adjustment Criterion이 Ignorability 가정을 정당화(Justify)해주고, 이를 통해 통계적 추정(Estimation)이 가능해진다.</figcaption>
</figure>
</div>
<hr>
</section>
</section>
<section id="summary-of-adjustment-criterion" class="level1">
<h1>3. Summary of Adjustment Criterion</h1>
<p>이제 Adjustment Criterion 시리즈 전체를 관통하는 핵심 내용을 요약해 보겠습니다.</p>
<section id="why-adjustment" class="level2">
<h2 class="anchored" data-anchor-id="why-adjustment">3.1. Why Adjustment?</h2>
<p>[cite_start]조정(Adjustment)은 데이터 과학 전반에서 인과 효과를 식별하기 위해 가장 널리 사용되는 기법입니다. [cite: 738, 744, 750, 756] 관찰 데이터에서 혼란 변수(Confounder)의 영향을 제거하여 인과적 결론을 도출하는 표준적인 방법론입니다.</p>
</section>
<section id="identification-principle" class="level2">
<h2 class="anchored" data-anchor-id="identification-principle">3.2. Identification Principle</h2>
<p>[cite_start]Back-door Criterion과 이를 일반화한 Adjustment Criterion은 어떤 변수 집합 <img src="https://latex.codecogs.com/png.latex?Z">를 조정해야 타당한지(validity)를 판단하는 <strong>원칙적인 조건(Principled condition)</strong>을 제공합니다. [cite: 739, 745, 751, 757]</p>
<ul>
<li><strong>Back-door Criterion:</strong> <img src="https://latex.codecogs.com/png.latex?X">의 후손을 제외하고, 모든 Back-door Path를 차단하라.</li>
<li><strong>Adjustment Criterion:</strong> <img src="https://latex.codecogs.com/png.latex?X">의 후손이라도 인과 경로(Proper Causal Path)를 방해하지 않으면 사용 가능하다. (Back-door의 Tightness 문제 해결)</li>
</ul>
</section>
<section id="algorithmic-discovery" class="level2">
<h2 class="anchored" data-anchor-id="algorithmic-discovery">3.3. Algorithmic Discovery</h2>
<p>[cite_start]우리는 그래프와 목표 인과 효과가 주어졌을 때, 유효한 조정 집합(Admissible sets)을 <strong>체계적이고 효율적으로(Systematically and Efficiently)</strong> 찾을 수 있습니다. [cite: 740, 746, 752, 758]</p>
<ul>
<li><strong>Constructive Method:</strong> <img src="https://latex.codecogs.com/png.latex?Z_0%20=%20An(X%20%5Ccup%20Y%20%5Ccup%20I)%20%5Ccap%20R"> 등의 공식을 통해 존재 여부를 즉시 확인 가능.</li>
<li><strong>Polynomial Delay Algorithm:</strong> 가능한 모든 유효 집합을 합리적인 시간 복잡도 내에서 나열 가능.</li>
</ul>
</section>
<section id="from-identification-to-estimation" class="level2">
<h2 class="anchored" data-anchor-id="from-identification-to-estimation">3.4. From Identification to Estimation</h2>
<p>식별(Identification)은 인과 추론의 첫 단계일 뿐입니다. [cite_start]유효한 조정 집합 <img src="https://latex.codecogs.com/png.latex?Z">를 찾았다면(Identification 단계 완료), 이제 유한한 샘플(Finite samples)로부터 목표 효과를 계산하는 <strong>추정(Estimation)</strong> 단계로 넘어가야 합니다. [cite: 741, 747, 753, 759]</p>
<p>대표적인 추정 기법은 다음과 같습니다: * <strong>IPW (Inverse Probability Weighting):</strong> 성향 점수(Propensity Score)를 이용한 가중치 부여. * <strong>Standardization (G-computation):</strong> 조건부 평균을 모델링하여 전체 평균 계산. * <strong>Doubly Robust Estimators:</strong> 위 두 방법을 결합하여 강건성 확보.</p>
<p>결국 Adjustment Criterion은 <strong>“무엇을 측정하고 모델링에 포함해야 하는가?”</strong>에 대한 명확한 가이드라인을 제시함으로써, 이후의 통계적 추정이 편향 없이 수행될 수 있는 기반을 마련해 줍니다.</p>
<hr>
</section>
</section>
<section id="conclusion" class="level1">
<h1>4. Conclusion</h1>
<p>이로써 Adjustment Criterion에 대한 긴 여정을 마칩니다. 우리는 그래프 이론에서 출발하여 알고리즘을 거쳐, 잠재적 결과(Potential Outcome)와의 연결고리까지 확인했습니다.</p>
<p>이 시리즈의 핵심 메시지는 다음과 같습니다: <strong>“데이터만으로는 인과관계를 말할 수 없다. 하지만 현실에 대한 가정(Graph)이 있다면, 우리는 수학적으로 올바른 통제 변수를 찾아낼 수 있다.”</strong></p>
<p>다음 시리즈에서는 식별된 인과 효과를 실제로 계산하는 <strong>추정(Estimation)</strong> 방법론에 대해 더 깊이 다뤄보도록 하겠습니다.</p>
<hr>
<section id="누락-방지-검증-missing-content-check" class="level3">
<h3 class="anchored" data-anchor-id="누락-방지-검증-missing-content-check">누락 방지 검증 (Missing Content Check)</h3>
<p>강의 자료(PDF 0504 파일)의 내용을 기반으로 아래 항목들이 포함되었는지 확인합니다.</p>
<ul>
<li><label><input type="checkbox" checked=""><strong>Conditional Ignorability 정의:</strong> <img src="https://latex.codecogs.com/png.latex?Y_x%20%5Cperp%5C!%5C!%5Cperp%20X%20%7C%20%5Bcite_start%5DZ"> 표기 및 의미 설명 [cite: 723-724, 733]</label></li>
<li>[cite_start][x] <strong>Counterfactual Notation과 SCM의 연결:</strong> <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x),z)%20=%20P(y%7Cx,z)"> 등식 [cite: 729, 734]</li>
<li>[cite_start][x] <strong>Adjustment Criterion의 역할:</strong> PO 프레임워크의 가정을 그래프 모델로 정당화(Justification)함 [cite: 735]</li>
<li>[cite_start][x] <strong>Summary - Popularity:</strong> Adjustment의 보편성 [cite: 738]</li>
<li>[cite_start][x] <strong>Summary - Validity:</strong> Back-door/Adjustment Criterion의 역할 [cite: 739]</li>
<li>[cite_start][x] <strong>Summary - Algorithm:</strong> 체계적인 탐색 가능성 [cite: 740]</li>
<li>[cite_start][x] <strong>Summary - Estimation:</strong> IPW 등 추정 기법과의 연계 [cite: 741]</li>
</ul>
<p><strong>Note:</strong> 제공된 PDF의 모든 핵심 내용(페이지 1-8)이 본 포스트에 반영되었습니다.</p>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L05/part-04/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 06. The Causal Calculus (Part 1)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L06/part-01/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>인과추론(Causal Inference)의 핵심 목표 중 하나는 관측 데이터(Observational Data)로부터 개입(Intervention)의 효과를 추정하는 것입니다. 이를 <strong>식별(Identification)</strong> 문제라고 합니다.</p>
<p>우리는 변수 <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 인과적 효과를 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">로 표기합니다. 하지만 현실 세계에서 우리는 <img src="https://latex.codecogs.com/png.latex?do(x)">(강제적 개입)가 적용된 데이터가 아니라, 자연스럽게 발생한 결합 확률 분포 <img src="https://latex.codecogs.com/png.latex?P(V)">만을 관측할 수 있습니다.</p>
<p>이번 포스트에서는 Judea Pearl의 Causal Calculus 프레임워크를 기반으로, <strong>구조적 인과 모델(Semi-Markovian Models)</strong> 하에서 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 계산하는 체계적인 접근법을 다룹니다. 특히 다음 세 가지 대표적인 그래프 구조를 통해 식별 가능성(Identifiability)을 분석합니다.</p>
<ol type="1">
<li><strong>Back-door Graph:</strong> 식별 가능 (Identifiable)</li>
<li><strong>Bow Graph:</strong> 식별 불가능 (Non-Identifiable)</li>
<li><strong>Front-door Graph:</strong> 식별 가능 (Identifiable)</li>
</ol>
</section>
<section id="truncated-factorization-in-semi-markovian-models" class="level1">
<h1>2. Truncated Factorization in Semi-Markovian Models</h1>
<section id="structural-causal-model-scm" class="level2">
<h2 class="anchored" data-anchor-id="structural-causal-model-scm">2.1. Structural Causal Model (SCM)</h2>
<p>[cite_start]변수 집합 <img src="https://latex.codecogs.com/png.latex?V">와 관측되지 않은 잠재 변수(Latent Variables) 집합 <img src="https://latex.codecogs.com/png.latex?U">가 있을 때, 구조적 인과 모델 <img src="https://latex.codecogs.com/png.latex?M">은 다음과 같은 함수들의 집합으로 정의됩니다[cite: 28].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Av_i%20=%20f_i(pa_i,%20u_i),%20%5Cquad%20%5Ctext%7Bfor%20each%20%7D%20V_i%20%5Cin%20V%0A"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?pa_i">는 <img src="https://latex.codecogs.com/png.latex?V_i">의 부모 변수(parents)를 의미합니다. [cite_start]전체 결합 확률 분포 <img src="https://latex.codecogs.com/png.latex?P(v)">는 잠재 변수 <img src="https://latex.codecogs.com/png.latex?u">에 대한 합(또는 적분)을 통해 다음과 같이 표현됩니다[cite: 29].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(v)%20=%20%5Csum_%7Bu%7D%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%7C%20pa_i,%20u_i)%20P(u)%0A"></p>
</section>
<section id="interventions-and-truncated-factorization" class="level2">
<h2 class="anchored" data-anchor-id="interventions-and-truncated-factorization">2.2. Interventions and Truncated Factorization</h2>
<p>변수 <img src="https://latex.codecogs.com/png.latex?X">에 특정 값 <img src="https://latex.codecogs.com/png.latex?x">를 강제로 할당하는 개입 <img src="https://latex.codecogs.com/png.latex?do(X=x)">가 발생하면, <img src="https://latex.codecogs.com/png.latex?X">를 결정하던 기존의 구조적 함수 <img src="https://latex.codecogs.com/png.latex?X%20%5Cleftarrow%20f_X(%5Cdots)">는 삭제되고 상수 <img src="https://latex.codecogs.com/png.latex?X=x">로 대체됩니다. [cite_start]이를 그래프 관점에서는 <img src="https://latex.codecogs.com/png.latex?X">로 들어오는 모든 화살표를 제거하는 것으로 해석할 수 있습니다[cite: 36].</p>
<p>[cite_start]이때, 개입 후의 분포 <img src="https://latex.codecogs.com/png.latex?P(v'%7Cdo(x))">는 <strong>Truncated Factorization</strong> 공식에 의해 다음과 같이 주어집니다[cite: 17, 18].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(v'%7Cdo(x))%20=%20%5Csum_%7Bu%7D%20%5Cprod_%7BV_i%20%5Cin%20V%20%5Csetminus%20X%7D%20P(v_i%20%7C%20pa_i,%20u_i)%20P(u)%0A"></p>
<p>즉, <img src="https://latex.codecogs.com/png.latex?X">와 관련된 확률 항만 제거되고 나머지 메커니즘은 불변(Invariant)한다는 가정입니다. [cite_start]관심 있는 결과 변수 집합 <img src="https://latex.codecogs.com/png.latex?Y">에 대한 효과는 <img src="https://latex.codecogs.com/png.latex?V">에서 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">를 제외한 나머지 변수들에 대해 주변화(marginalization)하여 구할 수 있습니다[cite: 21].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bv%20%5Csetminus%20(x%20%5Ccup%20y)%7D%20%5Csum_%7Bu%7D%20%5Cprod_%7BV_i%20%5Cin%20V%20%5Csetminus%20X%7D%20P(v_i%20%7C%20pa_i,%20u_i)%20P(u)%0A"></p>
<hr>
</section>
</section>
<section id="case-study-1-the-back-door-graph" class="level1">
<h1>3. Case Study 1: The Back-door Graph</h1>
<p>가장 기본적인 교란 요인(Confounder) 구조를 살펴보겠습니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L06/part-01/images/backdoor_graph_structure.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: Back-door Graph Structure. Z는 X와 Y의 공통 원인(Confounder)으로 작용하며, X에서 Y로 가는 직접 경로도 존재합니다. 이 구조에서는 Z가 Back-door path를 형성합니다.</figcaption>
</figure>
</div>
<section id="model-setup" class="level2">
<h2 class="anchored" data-anchor-id="model-setup">3.1. Model Setup</h2>
<p>[cite_start]이 모델의 SCM은 다음과 같습니다[cite: 28]. <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BH%7D%20=%20%5Cbegin%7Bcases%7D%0AZ%20%5Cleftarrow%20f_Z(u_z)%20%5C%5C%0AX%20%5Cleftarrow%20f_X(z,%20u_x)%20%5C%5C%0AY%20%5Cleftarrow%20f_Y(x,%20z,%20u_y)%0A%5Cend%7Bcases%7D%0A"></p>
<p>[cite_start]관측 분포 <img src="https://latex.codecogs.com/png.latex?P(v)">는 다음과 같이 분해됩니다[cite: 29]. <img src="https://latex.codecogs.com/png.latex?%0AP(x,%20y,%20z)%20=%20%5Csum_%7Bu%7D%20P(z%7Cu_z)%20P(x%7Cz,%20u_x)%20P(y%7Cx,%20z,%20u_y)%20P(u)%0A"></p>
</section>
<section id="derivation-of-intervention-distribution" class="level2">
<h2 class="anchored" data-anchor-id="derivation-of-intervention-distribution">3.2. Derivation of Intervention Distribution</h2>
<p>개입 <img src="https://latex.codecogs.com/png.latex?do(X=x)">가 발생하면, <img src="https://latex.codecogs.com/png.latex?X">의 결정 식은 <img src="https://latex.codecogs.com/png.latex?X=x">로 고정되고 <img src="https://latex.codecogs.com/png.latex?X">로 향하는 <img src="https://latex.codecogs.com/png.latex?Z">의 영향력은 사라집니다. [cite_start]우리는 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 구하고자 합니다[cite: 40].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bu%7D%20P(z%7Cu_z)%20P(y%7Cx,%20z,%20u_y)%20P(u)%0A"></p>
<p>[cite_start]여기서 잠재 변수 <img src="https://latex.codecogs.com/png.latex?u">를 <img src="https://latex.codecogs.com/png.latex?u_z,%20u_x,%20u_y">로 나누어 합을 전개하면 다음과 같습니다[cite: 42].</p>
<ol type="1">
<li><strong>Decomposition:</strong> <img src="https://latex.codecogs.com/png.latex?%0A=%20%5Csum_%7Bu_z%7D%20P(z%7Cu_z)P(u_z)%20%5Csum_%7Bu_y%7D%20P(y%7Cx,z,u_y)P(u_y)%20%5Csum_%7Bu_x%7D%20P(u_x)%0A"></li>
<li><strong>Simplification:</strong> <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bu_x%7D%20P(u_x)%20=%201"> 이므로 소거됩니다. 또한 <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bu_z%7D%20P(z%7Cu_z)P(u_z)%20=%20P(z)"> 입니다.</li>
<li><strong>Result:</strong> <img src="https://latex.codecogs.com/png.latex?%0A=%20P(z)%20%5Csum_%7Bu_y%7D%20P(y%7Cx,z,u_y)%20P(u_y)%0A"> [cite_start]이때, <img src="https://latex.codecogs.com/png.latex?P(y%7Cx,z)%20=%20%5Csum_%7Bu_y%7D%20P(y%7Cx,z,u_y)P(u_y)"> 이므로 최종적으로 다음과 같은 식을 얻습니다[cite: 45, 46].</li>
</ol>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(y%7Cx,%20z)%20P(z)%0A"></p>
<p>이것이 바로 유명한 <strong>Back-door Adjustment Formula</strong>입니다. [cite_start]<img src="https://latex.codecogs.com/png.latex?Z">를 통제(conditioning)하고 <img src="https://latex.codecogs.com/png.latex?Z">의 주변 확률로 가중 평균을 냄으로써 인과 효과를 식별할 수 있습니다[cite: 47].</p>
<hr>
</section>
</section>
<section id="case-study-2-the-bow-graph-non-identifiable" class="level1">
<h1>4. Case Study 2: The Bow Graph (Non-Identifiable)</h1>
<p>만약 관측되지 않은 교란 변수(Unobserved Confounder)가 존재하면 어떻게 될까요?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L06/part-01/images/bow_graph_structure.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: Bow Graph Structure. X에서 Y로 가는 직접 경로 외에, 관측되지 않은 교란 변수 U’이 X와 Y 모두에게 영향을 미치고 있습니다. 그래프 모양이 활(Bow)과 같아 Bow Graph라 불립니다.</figcaption>
</figure>
</div>
<section id="model-setup-1" class="level2">
<h2 class="anchored" data-anchor-id="model-setup-1">4.1. Model Setup</h2>
<p>[cite_start]Bow Graph의 SCM은 다음과 같습니다[cite: 55]. 여기서 <img src="https://latex.codecogs.com/png.latex?u'">은 관측 불가능한 공통 원인입니다. <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BH%7D%20=%20%5Cbegin%7Bcases%7D%0AX%20%5Cleftarrow%20f_X(u',%20u_x)%20%5C%5C%0AY%20%5Cleftarrow%20f_Y(x,%20u',%20u_y)%0A%5Cend%7Bcases%7D%0A"></p>
</section>
<section id="attempting-derivation" class="level2">
<h2 class="anchored" data-anchor-id="attempting-derivation">4.2. Attempting Derivation</h2>
<p>[cite_start]<img src="https://latex.codecogs.com/png.latex?do(X=x)">에 대한 Truncated Factorization을 적용해 봅시다[cite: 66].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bu%7D%20P(y%7Cx,%20u',%20u_y)%20P(u)%0A"></p>
<p>[cite_start]이 식을 전개하면 다음과 같습니다[cite: 68, 69].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0AP(y%7Cdo(x))%20&amp;=%20%5Csum_%7Bu'%7D%20P(u')%20%5Cleft(%20%5Csum_%7Bu_y%7D%20P(y%7Cx,%20u',%20u_y)%20P(u_y)%20%5Cright)%20%5Cleft(%20%5Csum_%7Bu_x%7D%20P(u_x)%20%5Cright)%20%5C%5C%0A&amp;=%20%5Csum_%7Bu'%7D%20P(y%7Cx,%20u')%20P(u')%0A%5Cend%7Baligned%7D%0A"></p>
<p><strong>문제점:</strong> 위 식의 우변에 있는 <img src="https://latex.codecogs.com/png.latex?u'">은 관측되지 않는 잠재 변수입니다. 우리는 데이터에서 <img src="https://latex.codecogs.com/png.latex?P(u')">이나 <img src="https://latex.codecogs.com/png.latex?P(y%7Cx,%20u')">를 추정할 수 없습니다. 따라서 이 경우 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">는 관측 데이터 <img src="https://latex.codecogs.com/png.latex?P(x,y)">만으로는 <strong>식별 불가능(Non-Identifiable)</strong>합니다.</p>
<hr>
</section>
</section>
<section id="case-study-3-the-front-door-graph" class="level1">
<h1>5. Case Study 3: The Front-door Graph</h1>
<p>관측되지 않은 교란 변수 <img src="https://latex.codecogs.com/png.latex?U'">이 존재하더라도, <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이를 매개하는 변수 <img src="https://latex.codecogs.com/png.latex?Z">가 있다면 식별이 가능할 수 있습니다. 이를 <strong>Front-door Criterion</strong>이라 합니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L06/part-01/images/frontdoor_graph_structure.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3: Front-door Graph Structure. X와 Y 사이에 관측되지 않은 교란 변수 U’이 존재하여 직접적인 Back-door 조정은 불가능합니다. 그러나 X가 Z에 영향을 주고, Z가 Y에 영향을 주는 경로가 존재하며, Z는 U’의 영향을 받지 않습니다.</figcaption>
</figure>
</div>
<section id="model-setup-2" class="level2">
<h2 class="anchored" data-anchor-id="model-setup-2">5.1. Model Setup</h2>
<p>[cite_start]Front-door 모델의 구조는 다음과 같습니다[cite: 82]. <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BM%7D%20=%20%5Cbegin%7Bcases%7D%0AX%20%5Cleftarrow%20f_X(u_x,%20u')%20%5C%5C%0AZ%20%5Cleftarrow%20f_Z(x,%20u_z)%20%5C%5C%0AY%20%5Cleftarrow%20f_Y(z,%20u',%20u_y)%0A%5Cend%7Bcases%7D%0A"> [cite_start]여기서 중요한 특징은 <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?u'">의 영향을 받지 않고 오직 <img src="https://latex.codecogs.com/png.latex?x">와 <img src="https://latex.codecogs.com/png.latex?u_z">에 의해서만 결정된다는 점입니다[cite: 82].</p>
</section>
<section id="step-by-step-derivation" class="level2">
<h2 class="anchored" data-anchor-id="step-by-step-derivation">5.2. Step-by-Step Derivation</h2>
<p>우리의 목표는 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 관측 가능한 확률들의 조합으로 표현하는 것입니다.</p>
<section id="step-1-truncated-factorization" class="level3">
<h3 class="anchored" data-anchor-id="step-1-truncated-factorization">Step 1: Truncated Factorization</h3>
<p>[cite_start]개입 후의 분포는 다음과 같습니다[cite: 91]. <img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bu%7D%20P(x%7Cu',%20u_x)%20P(z%7Cx,%20u_z)%20P(y%7Cz,%20u',%20u_y)%20P(u)%0A"> [cite_start]하지만 개입 <img src="https://latex.codecogs.com/png.latex?do(X=x)"> 하에서 <img src="https://latex.codecogs.com/png.latex?P(x%7Cu',%20u_x)"> 항은 삭제되거나 1이 되므로(intervention에 의해 고정됨), 식은 다음과 같이 정리됩니다[cite: 95].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bu%7D%20P(z%7Cx,%20u_z)%20P(y%7Cz,%20u',%20u_y)%20P(u)%0A"></p>
</section>
<section id="step-2-grouping-terms" class="level3">
<h3 class="anchored" data-anchor-id="step-2-grouping-terms">Step 2: Grouping Terms</h3>
<p>[cite_start]잠재 변수들을 그룹화하여 전개합니다[cite: 96]. <img src="https://latex.codecogs.com/png.latex?%0A=%20%5Cleft(%20%5Csum_%7Bu_z%7D%20P(z%7Cx,%20u_z)%20P(u_z)%20%5Cright)%20%5Cleft(%20%5Csum_%7Bu',%20u_y%7D%20P(y%7Cz,%20u',%20u_y)%20P(u',%20u_y)%20%5Cright)%20%5Cleft(%20%5Csum_%7Bu_x%7D%20P(u_x)%20%5Cright)%0A"> 마지막 항은 1이 되어 사라집니다. 첫 번째 항은 <img src="https://latex.codecogs.com/png.latex?P(z%7Cx)">가 됩니다 (왜냐하면 <img src="https://latex.codecogs.com/png.latex?Z">는 <img src="https://latex.codecogs.com/png.latex?X"> 외의 다른 교란 변수 <img src="https://latex.codecogs.com/png.latex?U'">의 영향을 받지 않기 때문입니다).</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A=%20P(z%7Cx)%20%5Csum_%7Bu',%20u_y%7D%20P(y%7Cz,%20u',%20u_y)%20P(u_y%7Cu')%20P(u')%0A"></p>
<p>[cite_start]내부의 <img src="https://latex.codecogs.com/png.latex?u_y">에 대한 합을 계산하면 <img src="https://latex.codecogs.com/png.latex?P(y%7Cz,%20u')">이 됩니다[cite: 97, 98]. <img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(z%7Cx)%20%5Csum_%7Bu'%7D%20P(y%7Cz,%20u')%20P(u')%0A"> 아직 <img src="https://latex.codecogs.com/png.latex?u'">이 남아 있습니다. 이 식을 어떻게 관측 가능한 변수로 바꿀 수 있을까요?</p>
</section>
<section id="step-3-leveraging-x" class="level3">
<h3 class="anchored" data-anchor-id="step-3-leveraging-x">Step 3: Leveraging X’</h3>
<p>여기서 핵심 트릭은 <img src="https://latex.codecogs.com/png.latex?X">의 값을 <img src="https://latex.codecogs.com/png.latex?x'">로 관측했을 때의 정보를 이용하는 것입니다. <img src="https://latex.codecogs.com/png.latex?P(y%7Cz,%20x')">를 생각해 봅시다. <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?x'">일 때 <img src="https://latex.codecogs.com/png.latex?Z">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 관계를 이용해 <img src="https://latex.codecogs.com/png.latex?u'"> 항을 <img src="https://latex.codecogs.com/png.latex?x'">에 대한 식으로 변환할 수 있습니다. [cite_start]유도 과정을 따라가면 다음과 같은 최종 식을 얻습니다 [cite: 130-134].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bu'%7D%20P(y%7Cz,%20u')%20P(u')%20=%20%5Csum_%7Bx'%7D%20P(y%7Cz,%20x')%20P(x')%0A"> <em>(상세 유도: <img src="https://latex.codecogs.com/png.latex?u'">은 <img src="https://latex.codecogs.com/png.latex?x'">와 독립적이지 않을 수 있지만, Back-door path를 차단하는 <img src="https://latex.codecogs.com/png.latex?z">와 <img src="https://latex.codecogs.com/png.latex?x">의 관계를 이용해 <img src="https://latex.codecogs.com/png.latex?P(u')"> 성분을 <img src="https://latex.codecogs.com/png.latex?P(x')"> 성분으로 대체하여 표현함)</em></p>
</section>
<section id="step-4-final-front-door-formula" class="level3">
<h3 class="anchored" data-anchor-id="step-4-final-front-door-formula">Step 4: Final Front-door Formula</h3>
<p>[cite_start]결과적으로 다음과 같은 식별 공식을 얻습니다[cite: 134].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(z%7Cx)%20%5Csum_%7Bx'%7D%20P(y%7Cz,%20x')%20P(x')%0A"></p>
<p>이 공식은 관측되지 않은 교란 변수 <img src="https://latex.codecogs.com/png.latex?U'">이 존재하더라도, <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Z%20%5Cto%20Y"> 경로를 통해 인과 효과를 두 단계로 나누어(<img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Z"> 그리고 <img src="https://latex.codecogs.com/png.latex?Z%20%5Cto%20Y">) 추정함으로써 전체 효과를 계산할 수 있음을 보여줍니다.</p>
<hr>
</section>
</section>
</section>
<section id="summary" class="level1">
<h1>6. Summary</h1>
<p>이번 포스트에서는 구조적 인과 모델과 Do-Calculus의 기초적인 식별 전략들을 살펴보았습니다.</p>
<ul>
<li><strong>Truncated Factorization:</strong> 개입이 발생했을 때 확률 분포가 어떻게 변하는지를 수식화한 기본 원리입니다.</li>
<li><strong>Back-door Criterion:</strong> 교란 요인을 관측할 수 있다면, 이를 통제(Conditioning)하여 인과 효과를 식별합니다. (<img src="https://latex.codecogs.com/png.latex?Z">로 조정)</li>
<li><strong>Front-door Criterion:</strong> 교란 요인을 관측할 수 없더라도, 매개 변수 <img src="https://latex.codecogs.com/png.latex?Z">가 존재하고 특정 조건을 만족하면 인과 효과를 식별할 수 있습니다. (<img src="https://latex.codecogs.com/png.latex?Z">와 <img src="https://latex.codecogs.com/png.latex?X'">로 조정)</li>
</ul>
<p>다음 포스트에서는 이러한 규칙들을 일반화한 <strong>General Do-Calculus Rules</strong>에 대해 더 깊이 다루도록 하겠습니다.</p>
<hr>
<section id="누락-방지-검증-체크리스트" class="level3">
<h3 class="anchored" data-anchor-id="누락-방지-검증-체크리스트">누락 방지 검증 체크리스트</h3>
<ul class="task-list">
<li><label><input type="checkbox" checked=""><strong>강의 핵심 개념 포함:</strong> Truncated Factorization, Back-door, Bow Graph, Front-door Graph 모두 포함됨.</label></li>
<li><label><input type="checkbox" checked=""><strong>수식 유도 과정:</strong> 결과 식뿐만 아니라 <img src="https://latex.codecogs.com/png.latex?u">에 대한 합(summation) 분해 과정을 단계별로 서술함.</label></li>
<li><label><input type="checkbox" checked=""><strong>이미지 Placeholder:</strong> 각 그래프(Triangle, Bow, Front-door)에 대한 이미지 삽입 구문 및 상세 설명 포함.</label></li>
<li><label><input type="checkbox" checked=""><strong>출처 표기:</strong> 강의 자료의 내용을 인용할 때마다 `` 형식을 준수함.</label></li>
<li><label><input type="checkbox" checked=""><strong>내용 범위:</strong> 제공된 PDF 텍스트가 Front-door Derivation(약 11페이지 분량)까지이므로, 해당 범위까지 충실히 작성하고 마무리함.</label></li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L06/part-01/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 06. The Causal Calculus (Part 2)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L06/part-02/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>이전 포스트들에서 우리는 Back-door와 Front-door 기준을 통해 특정 그래프 구조에서 인과 효과를 식별하는 방법을 배웠습니다. 하지만 모든 인과 모형이 이러한 표준적인 형태를 띠는 것은 아닙니다. 더욱 복잡한 그래프 구조에서 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 식별하기 위해서는 보다 일반화된 규칙이 필요합니다.</p>
<p>이번 포스트에서는 Judea Pearl의 <strong>Do-Calculus</strong>가 등장하게 된 배경과, 이를 구성하는 세 가지 핵심 통찰(Three Insights)에 대해 다룹니다. [cite_start]이는 인과적 질문(Query)을 관측 가능한 통계적 추정량(Estimand)으로 변환하는 체계적인(Systematic) 접근법의 기초가 됩니다[cite: 147].</p>
</section>
<section id="the-syntactical-goal-on-identification" class="level1">
<h1>2. The Syntactical Goal on Identification</h1>
<section id="the-problem-definition" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-definition">2.1. The Problem Definition</h2>
<p>Back-door와 Front-door 설정 모두에서 우리의 목표는 하나였습니다. [cite_start]바로 개입(Intervention)에 의한 확률 분포 <img src="https://latex.codecogs.com/png.latex?Q%20=%20P(y%7Cdo(x))">를 관측 데이터의 분포 <img src="https://latex.codecogs.com/png.latex?P(v)">만으로 계산 가능한 식(expression)으로 환원(reduce)하는 것입니다[cite: 152, 160].</p>
</section>
<section id="two-approaches" class="level2">
<h2 class="anchored" data-anchor-id="two-approaches">2.2. Two Approaches</h2>
<p>이 목표를 달성하기 위한 방법은 크게 두 가지로 나뉩니다.</p>
<ol type="1">
<li><p><strong>Algebraic Approach (Truncated Factorization):</strong> [cite_start]구조적 인과 모델(SCM)의 Truncated Factorization 공식을 사용하여, 잠재 변수 <img src="https://latex.codecogs.com/png.latex?U">가 포함되지 않은(U-free) 표현식을 유도하는 방법입니다[cite: 156, 161]. 이는 앞서 Back-door/Front-door 공식을 유도할 때 사용했던 방식입니다.</p></li>
<li><p><strong>Axiomatic Approach (Do-Calculus):</strong> [cite_start]잠재 변수 <img src="https://latex.codecogs.com/png.latex?U">를 직접 다루거나 매번 적분을 수행하는 대신, <img src="https://latex.codecogs.com/png.latex?do(%5Ccdot)"> 연산자를 포함한 식을 <img src="https://latex.codecogs.com/png.latex?do(%5Ccdot)">가 없는 식(do-free expression)으로 변환하는 <strong>일련의 규칙(rules) 또는 공리(axioms)</strong>를 사용하는 방법입니다[cite: 157, 162].</p></li>
</ol>
<p>[cite_start]우리는 이 두 번째 접근법, 즉 타겟 효과(Target Effect)와의 등가성을 유지하면서 <img src="https://latex.codecogs.com/png.latex?do"> 표현식을 체계적으로 변환할 수 있는 규칙에 관심을 가질 것입니다[cite: 163].</p>
</section>
</section>
<section id="prelude-conditional-independence-in-submodels" class="level1">
<h1>3. Prelude: Conditional Independence in Submodels</h1>
<p>본격적인 규칙을 다루기 전에, 개입 <img src="https://latex.codecogs.com/png.latex?do(X=x)">가 가해진 세상에서의 조건부 독립성이 그래프 상에서 어떻게 표현되는지 정의해야 합니다.</p>
<section id="submodel-mathcalh_x-and-graph-mathcalg_overlinex" class="level2">
<h2 class="anchored" data-anchor-id="submodel-mathcalh_x-and-graph-mathcalg_overlinex">3.1. Submodel <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BH%7D_x"> and Graph <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D"></h2>
<p>[cite_start]<img src="https://latex.codecogs.com/png.latex?do(X=x)">라는 행위는 모델 내에서 <img src="https://latex.codecogs.com/png.latex?X">를 결정하는 구조적 함수 <img src="https://latex.codecogs.com/png.latex?f_X">를 상수 <img src="https://latex.codecogs.com/png.latex?x">로 대체하는 것을 의미합니다[cite: 189, 201]. <img src="https://latex.codecogs.com/png.latex?%0AX%20%5Cleftarrow%20x%0A"> [cite_start]이를 그래프 관점에서 보면, 변수 <img src="https://latex.codecogs.com/png.latex?X">가 더 이상 다른 변수(부모 변수)들의 영향을 받지 않음을 의미합니다[cite: 196, 202]. 따라서 원래 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D">에서 <strong><img src="https://latex.codecogs.com/png.latex?X">로 들어오는 모든 화살표(incoming edges)를 제거</strong>한 그래프를 생각할 수 있으며, 이를 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">라고 표기합니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L06/part-02/images/submodel_graph_Gx_bar.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: Submodel Graph <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">. 점선 화살표는 원래 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D">에는 존재했으나, 개입 <img src="https://latex.codecogs.com/png.latex?do(X)">로 인해 <img src="https://latex.codecogs.com/png.latex?X">가 상수로 고정되면서 제거된 경로를 나타냅니다. <img src="https://latex.codecogs.com/png.latex?X">는 이제 외부 변수의 영향을 받지 않는 고립된 노드(부모가 없는 노드)처럼 행동합니다.</figcaption>
</figure>
</div>
</section>
<section id="independence-condition" class="level2">
<h2 class="anchored" data-anchor-id="independence-condition">3.2. Independence Condition</h2>
<p>개입된 세상 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BH%7D_x">에서의 조건부 독립성은 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">에서의 d-separation으로 해석할 수 있습니다. [cite_start]특히, <img src="https://latex.codecogs.com/png.latex?X">는 이제 상수 <img src="https://latex.codecogs.com/png.latex?x">로 고정되었으므로, 이는 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">에서 <img src="https://latex.codecogs.com/png.latex?X=x">로 조건부(conditioning)를 건 것과 유사하게 동작합니다[cite: 203, 219].</p>
<p>[cite_start]따라서, <img src="https://latex.codecogs.com/png.latex?do(x)"> 하에서의 조건부 독립성 <img src="https://latex.codecogs.com/png.latex?(A%20%5Cperp%5C!%5C!%5C!%5Cperp%20B%20%7C%20C)">는 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D"> 그래프상에서의 분리(separation)와 동치입니다[cite: 220, 221].</p>
</section>
</section>
<section id="three-insights-for-identification" class="level1">
<h1>4. Three Insights for Identification</h1>
<p>Do-Calculus의 세 가지 규칙은 다음의 세 가지 직관적인 상황(Insights)에서 유도됩니다.</p>
<section id="insight-1-addingremoving-observations" class="level2">
<h2 class="anchored" data-anchor-id="insight-1-addingremoving-observations">4.1. Insight 1: Adding/Removing Observations</h2>
<p>첫 번째 통찰은 <strong>“언제 관측 변수 <img src="https://latex.codecogs.com/png.latex?Z">를 무시해도 되는가?”</strong>에 대한 것입니다.</p>
<p>[cite_start]원래 모델에서는 <img src="https://latex.codecogs.com/png.latex?Z">와 <img src="https://latex.codecogs.com/png.latex?Y">가 서로 연관되어 있어 분리할 수 없다고 가정해 봅시다(예: <img src="https://latex.codecogs.com/png.latex?Z%20%5Cnot%5Cperp%5C!%5C!%5C!%5Cperp%20Y%20%7C%20X">)[cite: 226]. [cite_start]하지만 <img src="https://latex.codecogs.com/png.latex?X">에 개입을 가한 <img src="https://latex.codecogs.com/png.latex?do(X)"> 세상(즉, <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">)에서 <img src="https://latex.codecogs.com/png.latex?Y">와 <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?X">에 의해 d-separated 된다면, <img src="https://latex.codecogs.com/png.latex?Z">를 관측하는 것은 <img src="https://latex.codecogs.com/png.latex?Y">의 확률 분포에 아무런 추가 정보를 주지 않습니다[cite: 228, 229].</p>
<section id="the-rule" class="level3">
<h3 class="anchored" data-anchor-id="the-rule">The Rule</h3>
<p><img src="https://latex.codecogs.com/png.latex?%0A(Y%20%5Cperp%5C!%5C!%5C!%5Cperp%20Z%20%7C%20X)_%7B%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D%7D%20%5Cimplies%20P(y%7Cdo(x),%20z)%20=%20P(y%7Cdo(x))%0A"> 즉, 개입된 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">에서 조건부 독립이 성립하면, <img src="https://latex.codecogs.com/png.latex?do(x)"> 식에서 조건절의 <img src="https://latex.codecogs.com/png.latex?z">를 제거할 수 있습니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L06/part-02/images/insight1_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: Insight 1 Graph Structure. <img src="https://latex.codecogs.com/png.latex?X">에 개입하여 <img src="https://latex.codecogs.com/png.latex?X">로 들어오는 화살표가 제거된 상황(<img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">)입니다. 이 그래프에서 <img src="https://latex.codecogs.com/png.latex?X">가 주어졌을 때 <img src="https://latex.codecogs.com/png.latex?Z">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 모든 경로가 차단된다면(d-separated), <img src="https://latex.codecogs.com/png.latex?Z">는 <img src="https://latex.codecogs.com/png.latex?Y">에 대한 추가적인 정보를 제공하지 않습니다.</figcaption>
</figure>
</div>
</section>
<section id="derivation" class="level3">
<h3 class="anchored" data-anchor-id="derivation">Derivation</h3>
<p>Truncated Factorization을 이용해 이를 증명할 수 있습니다. 개입 분포 <img src="https://latex.codecogs.com/png.latex?P(y,z%7Cdo(x))">는 다음과 같이 주어집니다. <img src="https://latex.codecogs.com/png.latex?%0AP(y,z%7Cdo(x))%20=%20%5Csum_%7Bu%7D%20P(z%7Cu_z)%20P(y%7Cx,%20u_y,%20u')%20P(u)%20=%20P(z)%20%5Csum_%7Bu'%7D%20P(y%7Cx,%20u')%20P(u')%0A"> [cite_start][cite: 240]</p>
<p>이때 조건부 확률의 정의에 따라: <img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x),%20z)%20=%20%5Cfrac%7BP(y,z%7Cdo(x))%7D%7BP(z%7Cdo(x))%7D%0A"> [cite_start]분모인 <img src="https://latex.codecogs.com/png.latex?P(z%7Cdo(x))">를 계산해보면 <img src="https://latex.codecogs.com/png.latex?P(z)">가 나옵니다(모든 <img src="https://latex.codecogs.com/png.latex?y">에 대해 합을 취함)[cite: 252]. <img src="https://latex.codecogs.com/png.latex?%0AP(z%7Cdo(x))%20=%20%5Csum_%7By%7D%20P(z)%20%5Csum_%7Bu'%7D%20P(y%7Cx,%20u')%20P(u')%20=%20P(z)%20%5Ccdot%201%20=%20P(z)%0A"> [cite_start]따라서 분자와 분모의 <img src="https://latex.codecogs.com/png.latex?P(z)">가 약분되어 다음을 얻습니다[cite: 263]. <img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x),%20z)%20=%20%5Csum_%7Bu'%7D%20P(y%7Cx,%20u')%20P(u')%20=%20P(y%7Cdo(x))%0A"></p>
</section>
</section>
<section id="insight-2-actionobservation-exchange" class="level2">
<h2 class="anchored" data-anchor-id="insight-2-actionobservation-exchange">4.2. Insight 2: Action/Observation Exchange</h2>
<p>두 번째 통찰은 <strong>“언제 개입(Action)을 단순 관측(Observation)으로 바꿀 수 있는가?”</strong>입니다. [cite_start]이는 Back-door 기준의 핵심 논리와 맞닿아 있습니다[cite: 273, 286].</p>
<p>[cite_start]만약 <img src="https://latex.codecogs.com/png.latex?Z">를 관측한 상태에서, <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 영향이 오직 인과적 경로(causal paths)를 통해서만 전달되고 교란 요인(confounders)에 의한 영향이 없다면, <img src="https://latex.codecogs.com/png.latex?see(X=x)">는 <img src="https://latex.codecogs.com/png.latex?do(X=x)">와 동일한 효과를 갖습니다[cite: 284, 285].</p>
<section id="the-rule-1" class="level3">
<h3 class="anchored" data-anchor-id="the-rule-1">The Rule</h3>
<p>[cite_start]이 조건은 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Cunderline%7BX%7D%7D"> (X에서 <strong>나가는</strong> 화살표를 제거한 그래프)에서 확인합니다[cite: 288, 308]. <img src="https://latex.codecogs.com/png.latex?%0A(Y%20%5Cperp%5C!%5C!%5C!%5Cperp%20X%20%7C%20Z)_%7B%5Cmathcal%7BG%7D_%7B%5Cunderline%7BX%7D%7D%7D%20%5Cimplies%20P(y%7Cdo(x),%20z)%20=%20P(y%7Cx,%20z)%0A"> [cite_start]이것이 성립하면 <img src="https://latex.codecogs.com/png.latex?do(x)">를 일반 조건부 확률 <img src="https://latex.codecogs.com/png.latex?x">로 바꿀 수 있습니다 (Exchange of Action &amp; Observation)[cite: 294, 295].</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L06/part-02/images/insight2_graph_Gx_under.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3: Insight 2 Graph Structure (<img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Cunderline%7BX%7D%7D">). <img src="https://latex.codecogs.com/png.latex?X">에서 <img src="https://latex.codecogs.com/png.latex?Y">로 가는 직접적인 인과 경로(outgoing edge)를 제거한 그래프입니다. 이 상태에서 <img src="https://latex.codecogs.com/png.latex?Z">를 조건부로 했을 때 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">가 독립이라면(d-separated), <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 Back-door path가 모두 차단된 것입니다.</figcaption>
</figure>
</div>
</section>
<section id="derivation-1" class="level3">
<h3 class="anchored" data-anchor-id="derivation-1">Derivation</h3>
<p>Back-door adjustment가 성립하는 구조(<img src="https://latex.codecogs.com/png.latex?Z">가 Back-door path를 차단)를 가정합니다. <img src="https://latex.codecogs.com/png.latex?%0AP(y,%20z%7Cdo(x))%20=%20%5Csum_%7Bu%7D%20P(z%7Cu_z)%20P(y%7Cx,%20z,%20u_y)%20P(u)%20=%20P(z)%20P(y%7Cx,%20z)%0A"> [cite_start][cite: 297] [cite_start]마찬가지로 <img src="https://latex.codecogs.com/png.latex?P(z%7Cdo(x))%20=%20P(z)">입니다[cite: 305, 306]. 따라서 비율을 계산하면: <img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x),%20z)%20=%20%5Cfrac%7BP(z)P(y%7Cx,%20z)%7D%7BP(z)%7D%20=%20P(y%7Cx,%20z)%0A"> [cite_start][cite: 307].</p>
</section>
</section>
<section id="insight-3-addingremoving-actions" class="level2">
<h2 class="anchored" data-anchor-id="insight-3-addingremoving-actions">4.3. Insight 3: Adding/Removing Actions</h2>
<p>세 번째 통찰은 <strong>“언제 개입(Action) 자체가 결과에 아무런 영향을 주지 않아 무시할 수 있는가?”</strong>입니다.</p>
<p>[cite_start]매우 직관적인 사실은, 만약 <img src="https://latex.codecogs.com/png.latex?X">에서 <img src="https://latex.codecogs.com/png.latex?Z">로 가는 인과적 경로(causal path)가 전혀 없다면, <img src="https://latex.codecogs.com/png.latex?X">에 어떤 개입을 하더라도 <img src="https://latex.codecogs.com/png.latex?Z">의 분포는 변하지 않는다는 것입니다[cite: 311].</p>
<section id="the-rule-2" class="level3">
<h3 class="anchored" data-anchor-id="the-rule-2">The Rule</h3>
<p><img src="https://latex.codecogs.com/png.latex?%0A(Z%20%5Cperp%5C!%5C!%5C!%5Cperp%20X)_%7B%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D%7D%20%5Cimplies%20P(z%7Cdo(x))%20=%20P(z)%0A"> [cite_start]개입된 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">에서 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Z">가 독립이라면(즉, 연결된 경로가 없다면), <img src="https://latex.codecogs.com/png.latex?do(x)">라는 행위 자체를 식에서 제거할 수 있습니다[cite: 319, 321].</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L06/part-02/images/insight3_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 4: Insight 3 Graph Structure. <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Z"> 사이에 인과적 연결이 없는 상황을 묘사합니다. <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">에서 <img src="https://latex.codecogs.com/png.latex?X">에서 <img src="https://latex.codecogs.com/png.latex?Z">로 가는 경로가 없다면, <img src="https://latex.codecogs.com/png.latex?X">에 대한 조작은 <img src="https://latex.codecogs.com/png.latex?Z">의 분포에 영향을 미치지 않습니다.</figcaption>
</figure>
</div>
</section>
<section id="derivation-2" class="level3">
<h3 class="anchored" data-anchor-id="derivation-2">Derivation</h3>
<p>개입 분포 <img src="https://latex.codecogs.com/png.latex?P(z%7Cdo(x))">를 주변화(marginalization)를 통해 전개하면: <img src="https://latex.codecogs.com/png.latex?%0AP(z%7Cdo(x))%20=%20%5Csum_%7By%7D%20%5Csum_%7Bu%7D%20P(z%7Cu_%7Bzy%7D,%20u_%7Bzx%7D)%20P(y%7Cx,%20u_%7Bzy%7D)%20P(u)%0A"> [cite_start]여기서 <img src="https://latex.codecogs.com/png.latex?Z">의 결정 식에는 <img src="https://latex.codecogs.com/png.latex?x">가 관여하지 않으므로, <img src="https://latex.codecogs.com/png.latex?u">에 대한 합을 정리하면 <img src="https://latex.codecogs.com/png.latex?P(z)">가 그대로 유도됩니다[cite: 332]. <img src="https://latex.codecogs.com/png.latex?%0A=%20%5Csum_%7Bu%7D%20P(z%7Cu)%20P(u)%20=%20P(z)%0A"> (상세 유도 과정에서 <img src="https://latex.codecogs.com/png.latex?y">와 관련된 항들은 합쳐져서 1이 됩니다).</p>
</section>
</section>
</section>
<section id="summary" class="level1">
<h1>5. Summary</h1>
<p>이번 포스트에서는 복잡한 인과 효과 식별 문제를 풀기 위한 기초 작업으로 세 가지 통찰을 살펴보았습니다.</p>
<ol type="1">
<li><strong>Observation Removal:</strong> <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">에서 조건부 독립이면, 관측값 <img src="https://latex.codecogs.com/png.latex?z">를 조건절에서 제거 가능.</li>
<li><strong>Action to Observation:</strong> <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Cunderline%7BX%7D%7D">에서 조건부 독립이면, <img src="https://latex.codecogs.com/png.latex?do(x)">를 <img src="https://latex.codecogs.com/png.latex?x">로 변환 가능.</li>
<li><strong>Action Removal:</strong> <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">에서 독립이면, <img src="https://latex.codecogs.com/png.latex?do(x)"> 자체를 제거 가능.</li>
</ol>
<p>이 세 가지 통찰은 다음 포스트에서 다룰 <strong>Do-Calculus의 3가지 공식 규칙(The 3 Rules of Do-Calculus)</strong>으로 정식화됩니다. 이 규칙들은 인과 추론의 “미분 적분학”과 같은 역할을 하여, 그래프 구조만 주어진다면 어떤 복잡한 인과 효과도 식별 가능한지 판별하고 계산할 수 있게 해줍니다.</p>
<hr>
<section id="누락-방지-검증-체크리스트" class="level3">
<h3 class="anchored" data-anchor-id="누락-방지-검증-체크리스트">누락 방지 검증 체크리스트</h3>
<ul>
<li><strong>포함된 내용:</strong>
<ul>
<li>[cite_start][x] 식별(Identification)의 구문론적 목표 (Syntactical Goal) 및 두 가지 접근법 (Algebraic vs Axiomatic) [cite: 151, 156, 163]</li>
<li>[cite_start][x] Submodel <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BH%7D_x">와 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">의 정의 및 조건부 독립성의 의미 [cite: 188, 196, 220]</li>
<li>[cite_start][x] <strong>Insight 1:</strong> Adding/Removing Observations의 조건, 규칙, 유도 과정 [cite: 229, 240, 263]</li>
<li>[cite_start][x] <strong>Insight 2:</strong> Action/Observation Exchange의 조건, 규칙(<img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Cunderline%7BX%7D%7D"> 사용), 유도 과정 [cite: 287, 297, 307]</li>
<li>[cite_start][x] <strong>Insight 3:</strong> Adding/Removing Actions의 조건, 규칙, 유도 과정 [cite: 319, 332]</li>
<li><label><input type="checkbox" checked="">각 개념에 대응하는 Markdown 이미지 Placeholder 및 상세 캡션</label></li>
</ul></li>
<li><strong>생략된 내용:</strong>
<ul>
<li>없음. 제공된 PDF 범위(Slide 6 ~ 12) 내의 모든 핵심 이론과 수식 유도를 포함함.</li>
</ul></li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L06/part-02/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 06. The Causal Calculus (Part 3)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L06/part-03/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>이전 포스트에서 우리는 Do-Calculus의 직관적인 배경인 ’Three Insights’를 살펴보았습니다. 이번 포스트에서는 이를 일반화하여 Judea Pearl(1995)이 정립한 <strong>Do-Calculus의 3가지 공식 규칙</strong>을 정의하고, 이를 통해 인과 효과를 식별하는 과정을 단계별로 유도해 보겠습니다. [cite_start]또한, 모든 인과 효과가 식별 가능한 것은 아니며, 특정 그래프 구조(예: Bow-arc)에서는 식별이 불가능하다는 이론적 한계에 대해서도 다룹니다[cite: 334, 340].</p>
<p>우리의 최종적인 구문론적 목표(Syntactical Goal)는 여전히 동일합니다. <img src="https://latex.codecogs.com/png.latex?Q%20=%20P(y%7Cdo(x))"> [cite_start]위 식을 확률 공리(Probability Axioms)와 Do-Calculus 규칙을 적용하여, <img src="https://latex.codecogs.com/png.latex?do(%5Ccdot)"> 연산자가 없는(do-free) 표현식으로 변환하는 것입니다[cite: 577, 578].</p>
</section>
<section id="the-rules-of-do-calculus-theorem" class="level1">
<h1>2. The Rules of Do-Calculus (Theorem)</h1>
<p>인과 모델 <img src="https://latex.codecogs.com/png.latex?M">에 의해 유도된 모든 <img src="https://latex.codecogs.com/png.latex?do">-분포에 대해 다음 세 가지 변환 규칙이 성립합니다. [cite_start]여기서 <img src="https://latex.codecogs.com/png.latex?X,%20Y,%20Z,%20W">는 변수들의 집합을 나타냅니다[cite: 371].</p>
<section id="rule-1-addingremoving-observations" class="level2">
<h2 class="anchored" data-anchor-id="rule-1-addingremoving-observations">Rule 1: Adding/Removing Observations</h2>
<p>관측 변수 <img src="https://latex.codecogs.com/png.latex?Z">가 개입된 그래프에서 <img src="https://latex.codecogs.com/png.latex?Y">와 독립이라면, 조건부 확률에서 <img src="https://latex.codecogs.com/png.latex?Z">를 제거하거나 추가할 수 있습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x),%20z,%20w)%20=%20P(y%7Cdo(x),%20w)"></p>
<ul>
<li>[cite_start]<strong>조건:</strong> <img src="https://latex.codecogs.com/png.latex?(Y%20%5Cperp%5C!%5C!%5C!%5Cperp%20Z%20%7C%20X,%20W)_%7B%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D%7D"> [cite: 373, 378]</li>
<li><strong>해석:</strong> <img src="https://latex.codecogs.com/png.latex?X">에 개입하여 <img src="https://latex.codecogs.com/png.latex?X">로 들어오는 화살표가 제거된 그래프(<img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%7D">)에서, <img src="https://latex.codecogs.com/png.latex?W">가 주어졌을 때 <img src="https://latex.codecogs.com/png.latex?Y">와 <img src="https://latex.codecogs.com/png.latex?Z">가 d-separated 되어 있다면 <img src="https://latex.codecogs.com/png.latex?Z">는 <img src="https://latex.codecogs.com/png.latex?Y">에 대한 추가 정보를 제공하지 않습니다.</li>
</ul>
</section>
<section id="rule-2-actionobservation-exchange" class="level2">
<h2 class="anchored" data-anchor-id="rule-2-actionobservation-exchange">Rule 2: Action/Observation Exchange</h2>
<p>특정 조건하에서 개입(Action) <img src="https://latex.codecogs.com/png.latex?do(z)">를 단순 관측(Observation) <img src="https://latex.codecogs.com/png.latex?z">로 교체하거나 그 반대로 바꿀 수 있습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x),%20do(z),%20w)%20=%20P(y%7Cdo(x),%20z,%20w)"></p>
<ul>
<li>[cite_start]<strong>조건:</strong> <img src="https://latex.codecogs.com/png.latex?(Y%20%5Cperp%5C!%5C!%5C!%5Cperp%20Z%20%7C%20X,%20W)_%7B%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%5Cunderline%7BZ%7D%7D%7D"> [cite: 375, 379]</li>
<li><strong>해석:</strong> 그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%5Cunderline%7BZ%7D%7D">는 <img src="https://latex.codecogs.com/png.latex?X">로 들어오는 화살표를 제거하고(<img src="https://latex.codecogs.com/png.latex?%5Coverline%7BX%7D">), <img src="https://latex.codecogs.com/png.latex?Z">에서 나가는 화살표를 제거한(<img src="https://latex.codecogs.com/png.latex?%5Cunderline%7BZ%7D">) 그래프입니다. 이 구조에서 <img src="https://latex.codecogs.com/png.latex?Y">와 <img src="https://latex.codecogs.com/png.latex?Z">가 독립이라면, <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 영향은 오직 <img src="https://latex.codecogs.com/png.latex?Z">의 부모를 통한 Back-door path뿐이므로, Back-door criterion에 의해 <img src="https://latex.codecogs.com/png.latex?do(z)">와 <img src="https://latex.codecogs.com/png.latex?z">가 등가입니다.</li>
</ul>
</section>
<section id="rule-3-addingremoving-actions" class="level2">
<h2 class="anchored" data-anchor-id="rule-3-addingremoving-actions">Rule 3: Adding/Removing Actions</h2>
<p>개입 <img src="https://latex.codecogs.com/png.latex?do(z)">가 <img src="https://latex.codecogs.com/png.latex?Y">의 확률 분포에 아무런 영향을 주지 않는다면, 식에서 <img src="https://latex.codecogs.com/png.latex?do(z)">를 제거할 수 있습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x),%20do(z),%20w)%20=%20P(y%7Cdo(x),%20w)"></p>
<ul>
<li>[cite_start]<strong>조건:</strong> <img src="https://latex.codecogs.com/png.latex?(Y%20%5Cperp%5C!%5C!%5C!%5Cperp%20Z%20%7C%20X,%20W)_%7B%5Cmathcal%7BG%7D_%7B%5Coverline%7BX%7D%5Coverline%7BZ(W)%7D%7D%7D"> [cite: 377, 380]</li>
<li><strong>해석:</strong> 여기서 <img src="https://latex.codecogs.com/png.latex?Z(W)">는 <img src="https://latex.codecogs.com/png.latex?Z">의 노드 중 <img src="https://latex.codecogs.com/png.latex?W">의 조상(Ancestor)이 아닌 노드들의 집합입니다. 해당 그래프에서 <img src="https://latex.codecogs.com/png.latex?Y">와 <img src="https://latex.codecogs.com/png.latex?Z">가 독립이라면, <img src="https://latex.codecogs.com/png.latex?Z">에 대한 개입은 <img src="https://latex.codecogs.com/png.latex?Y">에 인과적 영향을 주지 않습니다.</li>
</ul>
</section>
</section>
<section id="deep-dive-understanding-the-logic" class="level1">
<h1>3. Deep Dive: Understanding the Logic</h1>
<section id="logic-of-rule-2-regime-indicator" class="level2">
<h2 class="anchored" data-anchor-id="logic-of-rule-2-regime-indicator">3.1. Logic of Rule 2 (Regime Indicator)</h2>
<p>Rule 2는 근본적으로 “우리가 보는 것(Seeing)”과 “우리가 하는 것(Doing)”이 언제 같은지를 묻습니다. [cite_start]이를 이해하기 위해 <img src="https://latex.codecogs.com/png.latex?Z">의 상태를 결정하는 <strong>Regime Indicator <img src="https://latex.codecogs.com/png.latex?F_Z"></strong>를 도입할 수 있습니다[cite: 404, 418].</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?F_Z%20=%200">: 자연스러운 관측 모드 (<img src="https://latex.codecogs.com/png.latex?Z%20%5Cleftarrow%20f_Z(W,%20U_Z)">)</li>
<li><img src="https://latex.codecogs.com/png.latex?F_Z%20=%201">: 개입 모드 (<img src="https://latex.codecogs.com/png.latex?Z%20%5Cleftarrow%20z">)</li>
</ul>
<p>[cite_start]Rule 2가 성립한다는 것은 <img src="https://latex.codecogs.com/png.latex?F_Z">의 값이 0이든 1이든 <img src="https://latex.codecogs.com/png.latex?Y">의 분포가 변하지 않는다는 뜻입니다[cite: 473]. <img src="https://latex.codecogs.com/png.latex?P(y%7Cz,%20w,%20F_Z=1)%20=%20P(y%7Cz,%20w,%20F_Z=0)"> 이는 그래프상에서 <img src="https://latex.codecogs.com/png.latex?F_Z">와 <img src="https://latex.codecogs.com/png.latex?Y">가 조건부 독립 <img src="https://latex.codecogs.com/png.latex?(F_Z%20%5Cperp%5C!%5C!%5C!%5Cperp%20Y%20%7C%20Z,%20W)">임을 의미합니다. <img src="https://latex.codecogs.com/png.latex?Z">가 조건부로 주어졌으므로 <img src="https://latex.codecogs.com/png.latex?Z">를 통과하는 경로는 차단되고, 남은 것은 <img src="https://latex.codecogs.com/png.latex?Z">로 들어오는 Back-door path뿐입니다. [cite_start]따라서 Rule 2는 본질적으로 <img src="https://latex.codecogs.com/png.latex?Z">에 대한 Back-door path가 차단되었는지를 확인하는 것입니다[cite: 497].</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L06/part-03/images/rule2_regime_indicator.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: Rule 2와 Regime Indicator. <img src="https://latex.codecogs.com/png.latex?F_Z"> 노드는 <img src="https://latex.codecogs.com/png.latex?Z">가 관측(idle) 상태인지 개입(do) 상태인지를 결정합니다. <img src="https://latex.codecogs.com/png.latex?Z">와 <img src="https://latex.codecogs.com/png.latex?W">가 주어졌을 때 <img src="https://latex.codecogs.com/png.latex?F_Z">에서 <img src="https://latex.codecogs.com/png.latex?Y">로 가는 경로가 없다면(d-separated), 개입 여부는 결과 <img src="https://latex.codecogs.com/png.latex?Y">에 영향을 주지 않습니다.</figcaption>
</figure>
</div>
</section>
<section id="logic-of-rule-3-zw-and-ancestry" class="level2">
<h2 class="anchored" data-anchor-id="logic-of-rule-3-zw-and-ancestry">3.2. Logic of Rule 3 (<img src="https://latex.codecogs.com/png.latex?Z(W)"> and Ancestry)</h2>
<p>Rule 3에서 <img src="https://latex.codecogs.com/png.latex?Z(W)">라는 복잡한 표기법을 사용하는 이유는 무엇일까요? 우리가 <img src="https://latex.codecogs.com/png.latex?W">를 조건부로 하고 있을 때, <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?W">의 조상(Ancestor)이라면 <img src="https://latex.codecogs.com/png.latex?Z">에 개입하는 것이 <img src="https://latex.codecogs.com/png.latex?W">의 분포를 바꾸고, 이것이 다시 <img src="https://latex.codecogs.com/png.latex?Y">에 영향을 줄 수 있기 때문입니다.</p>
<ul>
<li>만약 <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?W">의 조상이 아니라면(<img src="https://latex.codecogs.com/png.latex?Z%20%5Cnotin%20An(W)">), <img src="https://latex.codecogs.com/png.latex?Z">에 개입해도 <img src="https://latex.codecogs.com/png.latex?W">는 변하지 않습니다. 따라서 <img src="https://latex.codecogs.com/png.latex?Z%20%5Cto%20Y"> 경로만 없다면 개입을 제거할 수 있습니다.</li>
<li>만약 <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?W">의 조상이라면, <img src="https://latex.codecogs.com/png.latex?Z">에 대한 개입은 <img src="https://latex.codecogs.com/png.latex?W">를 변화시키므로 함부로 제거할 수 없습니다.</li>
</ul>
<p>[cite_start]따라서 Rule 3은 <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?Y">에 미치는 직접적인 효과가 없을 뿐만 아니라, <img src="https://latex.codecogs.com/png.latex?W">를 통해 간접적으로 미치는 효과도 통제되었을 때만 적용 가능합니다[cite: 541, 546].</p>
</section>
</section>
<section id="derivation-example-in-do-calculus" class="level1">
<h1>4. Derivation Example in Do-Calculus</h1>
<p>[cite_start]간단한 그래프 <img src="https://latex.codecogs.com/png.latex?S%20%5Cto%20T%20%5Cto%20C">에서 <img src="https://latex.codecogs.com/png.latex?P(c%7Cdo(s))">를 유도하는 과정을 통해 Do-Calculus가 실제로 어떻게 작동하는지 살펴봅시다 [cite: 580-615].</p>
<p><strong>Model:</strong> <img src="https://latex.codecogs.com/png.latex?S%20%5Cto%20T%20%5Cto%20C"> (Chain structure) <strong>Goal:</strong> Compute <img src="https://latex.codecogs.com/png.latex?P(c%7Cdo(s))"></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L06/part-03/images/derivation_chain_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: 유도 예제를 위한 그래프. <img src="https://latex.codecogs.com/png.latex?S%20%5Cto%20T%20%5Cto%20C"> 형태의 간단한 연쇄(Chain) 구조입니다. <img src="https://latex.codecogs.com/png.latex?S">는 <img src="https://latex.codecogs.com/png.latex?T">에, <img src="https://latex.codecogs.com/png.latex?T">는 <img src="https://latex.codecogs.com/png.latex?C">에 영향을 미치며, <img src="https://latex.codecogs.com/png.latex?S">에서 <img src="https://latex.codecogs.com/png.latex?C">로 가는 직접 경로는 없습니다.</figcaption>
</figure>
</div>
<ol type="1">
<li><p><strong>Probability Axioms (Expansion):</strong> <img src="https://latex.codecogs.com/png.latex?T">에 대해 주변화(marginalization)하고 조건부 확률의 정의를 사용합니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7Bt%7D%20P(c%7Cdo(s),%20t)%20P(t%7Cdo(s))"></p></li>
<li><p><strong>Rule 2 (Action to Observation for T):</strong> 두 번째 항 <img src="https://latex.codecogs.com/png.latex?P(t%7Cdo(s))">를 봅시다. 그래프에서 <img src="https://latex.codecogs.com/png.latex?S%20%5Cto%20T"> 경로가 존재하므로 단순 제거는 불가능합니다. 하지만 Back-door path가 없으므로 Rule 2를 적용해 <img src="https://latex.codecogs.com/png.latex?do(s)">를 <img src="https://latex.codecogs.com/png.latex?s">로 바꿀 수 있을까요? 네, 가능합니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7Bt%7D%20P(c%7Cdo(s),%20t)%20P(t%7Cs)"> <em>(참고: <img src="https://latex.codecogs.com/png.latex?S%20%5Cto%20T"> 관계에서 교란 변수가 없다면 <img src="https://latex.codecogs.com/png.latex?P(t%7Cdo(s))%20=%20P(t%7Cs)">)</em></p></li>
<li><p><strong>Rule 2 (Introduction of Action <img src="https://latex.codecogs.com/png.latex?do(t)">):</strong> 첫 번째 항 <img src="https://latex.codecogs.com/png.latex?P(c%7Cdo(s),%20t)">에서 <img src="https://latex.codecogs.com/png.latex?t">를 <img src="https://latex.codecogs.com/png.latex?do(t)">로 바꿀 수 있습니다. 왜냐하면 <img src="https://latex.codecogs.com/png.latex?S">가 차단된 상태에서 <img src="https://latex.codecogs.com/png.latex?T">로 들어오는 Back-door path가 없기 때문입니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7Bt%7D%20P(c%7Cdo(s),%20do(t))%20P(t%7Cs)"></p></li>
<li><p><strong>Rule 3 (Removing Action <img src="https://latex.codecogs.com/png.latex?do(s)">):</strong> 이제 <img src="https://latex.codecogs.com/png.latex?P(c%7Cdo(s),%20do(t))">를 봅시다. <img src="https://latex.codecogs.com/png.latex?T">에 개입(<img src="https://latex.codecogs.com/png.latex?do(t)">)을 하면 <img src="https://latex.codecogs.com/png.latex?T">는 상수로 고정됩니다. 이 상태에서 <img src="https://latex.codecogs.com/png.latex?S">는 <img src="https://latex.codecogs.com/png.latex?C">에 영향을 줄 수 있는 경로가 없습니다 (<img src="https://latex.codecogs.com/png.latex?S%20%5Cto%20T%20%5Cto%20C">가 <img src="https://latex.codecogs.com/png.latex?T">에서 끊김). 따라서 <img src="https://latex.codecogs.com/png.latex?do(s)">를 제거할 수 있습니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7Bt%7D%20P(c%7Cdo(t))%20P(t%7Cs)"></p></li>
<li><p><strong>Rule 2 (Action to Observation for C):</strong> 마지막으로 <img src="https://latex.codecogs.com/png.latex?P(c%7Cdo(t))">에서 <img src="https://latex.codecogs.com/png.latex?T%20%5Cto%20C"> 사이에 교란 요인이 없다면 Rule 2에 의해 <img src="https://latex.codecogs.com/png.latex?P(c%7Ct)">가 됩니다. <img src="https://latex.codecogs.com/png.latex?=%20%5Csum_%7Bt%7D%20P(c%7Ct)%20P(t%7Cs)"></p></li>
</ol>
<p>결과적으로 <img src="https://latex.codecogs.com/png.latex?P(c%7Cdo(s))%20=%20%5Csum_t%20P(c%7Ct)P(t%7Cs)">라는, 우리가 잘 아는 연쇄 법칙(Chain Rule) 공식이 유도되었습니다.</p>
</section>
<section id="non-identifiability-when-do-calculus-fails" class="level1">
<h1>5. Non-identifiability: When Do-Calculus Fails</h1>
<p>모든 인과 효과를 관측 데이터로 식별할 수는 없습니다. 식별 불가능성(Non-identifiability)을 증명하는 대표적인 예시와 기준을 알아보겠습니다.</p>
<section id="the-fair-coin-counter-example" class="level2">
<h2 class="anchored" data-anchor-id="the-fair-coin-counter-example">5.1. The “Fair Coin” Counter-example</h2>
<p>[cite_start]동일한 관측 분포 <img src="https://latex.codecogs.com/png.latex?P(v)">를 가지지만, 서로 다른 개입 분포 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 갖는 두 모델이 존재한다면, 해당 인과 효과는 식별 불가능합니다[cite: 616].</p>
<ul>
<li><strong>Model 1:</strong> <img src="https://latex.codecogs.com/png.latex?X%20%5Cleftarrow%20U,%20Y%20%5Cleftarrow%20f_Y(X,%20U)"></li>
<li><strong>Model 2:</strong> <img src="https://latex.codecogs.com/png.latex?X%20%5Cleftarrow%20U">, <img src="https://latex.codecogs.com/png.latex?Y">는 <img src="https://latex.codecogs.com/png.latex?X=U">일 때만 <img src="https://latex.codecogs.com/png.latex?f_Y">를 따르고 그 외엔 상수 출력.</li>
</ul>
<p>관측 데이터상에서는 항상 <img src="https://latex.codecogs.com/png.latex?X=U">이므로 두 모델을 구별할 수 없습니다(<img src="https://latex.codecogs.com/png.latex?P%5E%7B(1)%7D(v)%20=%20P%5E%7B(2)%7D(v)">). [cite_start]하지만 <img src="https://latex.codecogs.com/png.latex?do(X=x)">로 개입하면 <img src="https://latex.codecogs.com/png.latex?X%20%5Cneq%20U">인 상황이 발생하고, 이때 두 모델은 서로 다른 <img src="https://latex.codecogs.com/png.latex?Y"> 값을 출력합니다(<img src="https://latex.codecogs.com/png.latex?P%5E%7B(1)%7D(y%7Cdo(x))%20%5Cneq%20P%5E%7B(2)%7D(y%7Cdo(x))">)[cite: 626, 641]. 이는 데이터만으로는 인과 구조를 완벽히 파악할 수 없음을 시사합니다.</p>
</section>
<section id="graphical-criterion-tian-and-pearl-2002" class="level2">
<h2 class="anchored" data-anchor-id="graphical-criterion-tian-and-pearl-2002">5.2. Graphical Criterion (Tian and Pearl, 2002)</h2>
<p>그래프 구조만 보고 식별 불가능성을 판단할 수 있는 기준이 있습니다.</p>
<p><strong>Theorem (Bow-arc Criterion):</strong> [cite_start]그래프 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BG%7D">에서 <img src="https://latex.codecogs.com/png.latex?X">와 그 자식 노드(children) 중 하나 사이에 <strong>양방향 화살표(bidirected edge, 점선)</strong>가 존재한다면, 즉 <img src="https://latex.codecogs.com/png.latex?X%20%5Cleftrightarrow%20%5Cdots%20%5Cleftrightarrow%20Y"> 형태의 교란 경로가 존재하고 직접 경로 <img src="https://latex.codecogs.com/png.latex?X%20%5Cto%20Y">가 있다면, <img src="https://latex.codecogs.com/png.latex?P(v'%7Cdo(x))">는 식별 불가능합니다[cite: 650].</p>
<p>이러한 구조를 <strong>Bow-arc Graph</strong>라고 부릅니다. 활(Bow) 모양처럼 직접 경로와 교란 경로가 동시에 존재하기 때문입니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L06/part-03/images/non_identifiable_graphs.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3: 식별 불가능한 그래프 패턴들. (a)와 같은 Bow-arc 구조(X에서 Y로 가는 화살표와 점선 양방향 화살표가 병존)가 가장 대표적인 식별 불가능 패턴입니다. 이 경우 Do-Calculus를 아무리 적용해도 do 연산자를 제거할 수 없습니다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="summary" class="level1">
<h1>6. Summary</h1>
<p>Do-Calculus는 인과 추론의 “미분 적분학”과 같습니다. 3가지 규칙을 통해 우리는 복잡한 인과적 질문을 관측 가능한 통계적 질문으로 변환할 수 있습니다.</p>
<ol type="1">
<li><strong>Rule 1:</strong> 관측값 추가/제거 (d-separation 확인)</li>
<li><strong>Rule 2:</strong> 개입과 관측의 교환 (Back-door path 확인)</li>
<li><strong>Rule 3:</strong> 개입의 추가/제거 (인과적 영향력 확인)</li>
</ol>
<p>하지만 Bow-arc와 같은 특정 구조에서는 이러한 변환이 불가능하며, 이는 데이터만으로는 인과관계를 밝혀낼 수 없다는 근본적인 한계를 보여줍니다. 다음 단계로는 이러한 규칙들을 알고리즘화하여 자동으로 식별 가능성을 판별하는 ID 알고리즘 등이 존재합니다.</p>
<hr>
<section id="누락-방지-검증-체크리스트" class="level3">
<h3 class="anchored" data-anchor-id="누락-방지-검증-체크리스트">누락 방지 검증 체크리스트</h3>
<ul>
<li><strong>포함된 내용:</strong>
<ul class="task-list">
<li><label><input type="checkbox" checked=""><strong>Do-Calculus 3대 규칙의 정형적 정의:</strong> Unconditional 및 General Conditional 버전 포함 Rule 1, 2, 3 서술.</label></li>
<li><label><input type="checkbox" checked=""><strong>Rule 2의 심층 원리:</strong> Regime Indicator <img src="https://latex.codecogs.com/png.latex?F_Z">를 이용한 설명 및 그래프 해석 포함.</label></li>
<li><label><input type="checkbox" checked=""><strong>Rule 3의 심층 원리:</strong> <img src="https://latex.codecogs.com/png.latex?Z(W)"> 표기법과 조상(Ancestry) 관계에 따른 개입 제거 조건 설명.</label></li>
<li><label><input type="checkbox" checked=""><strong>유도 예제:</strong> <img src="https://latex.codecogs.com/png.latex?S%20%5Cto%20T%20%5Cto%20C"> 그래프에서의 단계별 수식 유도(<img src="https://latex.codecogs.com/png.latex?P(c%7Cdo(s))">) 및 각 단계의 근거(Rule 적용) 설명.</label></li>
<li><label><input type="checkbox" checked=""><strong>식별 불가능성(Non-identifiability):</strong> Fair Coin 반례(Counter-example)를 통한 증명 논리 포함.</label></li>
<li><label><input type="checkbox" checked=""><strong>그래프 기준(Graphical Criterion):</strong> Tian &amp; Pearl (2002)의 정리 및 Bow-arc 구조 설명.</label></li>
<li><label><input type="checkbox" checked=""><strong>이미지:</strong> Rule 2, 유도 예제, Bow-arc 그래프에 대한 이미지 태그 및 설명 포함.</label></li>
<li><label><input type="checkbox" checked=""><strong>출처:</strong> 모든 주요 진술에 `` 형식으로 출처 표기 완료.</label></li>
</ul></li>
<li><strong>생략된 내용:</strong>
<ul>
<li>없음. 제공된 PDF 페이지 13~28의 모든 이론적 내용과 예제를 포괄함.</li>
</ul></li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L06/part-03/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 06. The Causal Calculus (Part 4)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L06/part-04/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>통계학을 공부하다 보면 직관과 데이터가 충돌하는 순간을 마주하게 됩니다. 가장 대표적인 예가 바로 <strong>심슨의 역설(Simpson’s Paradox)</strong>입니다. 이는 부분 집합에서 나타나는 경향성이 데이터를 전체로 합쳤을 때 반전되는 현상을 말합니다.</p>
<p>[cite_start]초기 통계학자인 Karl Pearson은 이를 두고 “이질적인 그룹들이 섞여 있을 때 발생하는 가짜 상관관계(spurious correlation)”라고 표현하며 충격을 받았습니다[cite: 728, 731]. 하지만 Judea Pearl은 이 역설이 단순한 통계적 오류가 아니라, <strong>인과적 구조(Causal Structure)를 무시한 채 데이터만 해석하려 할 때 발생하는 문제</strong>라고 주장합니다.</p>
<p>이번 포스트에서는 심슨의 역설을 <code>do-operator</code>를 통해 수학적으로 해결(dissolve)하고, 인과추론이 왜 데이터 과학의 필수적인 도구인지 확인해 보겠습니다.</p>
</section>
<section id="the-anatomy-of-the-paradox" class="level1">
<h1>2. The Anatomy of the Paradox</h1>
<p>심슨의 역설을 이해하기 위해 가상의 약물 치료 실험 데이터를 살펴보겠습니다. 목표는 약물(Drug, <img src="https://latex.codecogs.com/png.latex?X">)이 회복(Recovery, <img src="https://latex.codecogs.com/png.latex?Y">)에 도움이 되는지 판단하는 것입니다.</p>
<section id="the-data-statistical-reversal" class="level2">
<h2 class="anchored" data-anchor-id="the-data-statistical-reversal">2.1. The Data: Statistical Reversal</h2>
<p>[cite_start]다음은 전체 환자(Total)와 성별(Male/Female, <img src="https://latex.codecogs.com/png.latex?F">)로 나누어 본 회복률 데이터입니다[cite: 742, 746, 747].</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Group</th>
<th style="text-align: left;">Treatment (<img src="https://latex.codecogs.com/png.latex?X">)</th>
<th style="text-align: left;">Recovery (<img src="https://latex.codecogs.com/png.latex?Y=1">)</th>
<th style="text-align: left;">Rate (<img src="https://latex.codecogs.com/png.latex?P(Y%7CX)">)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Total</strong></td>
<td style="text-align: left;">Drug</td>
<td style="text-align: left;">20 / 40</td>
<td style="text-align: left;"><strong>50%</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">No Drug</td>
<td style="text-align: left;">16 / 40</td>
<td style="text-align: left;">40%</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Male (<img src="https://latex.codecogs.com/png.latex?%5Cneg%20F">)</strong></td>
<td style="text-align: left;">Drug</td>
<td style="text-align: left;">18 / 30</td>
<td style="text-align: left;">60%</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">No Drug</td>
<td style="text-align: left;">7 / 10</td>
<td style="text-align: left;"><strong>70%</strong></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Female (<img src="https://latex.codecogs.com/png.latex?F">)</strong></td>
<td style="text-align: left;">Drug</td>
<td style="text-align: left;">2 / 10</td>
<td style="text-align: left;">20%</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">No Drug</td>
<td style="text-align: left;">9 / 30</td>
<td style="text-align: left;"><strong>30%</strong></td>
</tr>
</tbody>
</table>
<p>여기서 충격적인 모순이 발생합니다. * <strong>전체 데이터:</strong> 약물을 복용한 집단의 회복률(50%)이 복용하지 않은 집단(40%)보다 높습니다. (<img src="https://latex.codecogs.com/png.latex?P(Y%7CX)%20%3E%20P(Y%7C%5Cneg%20X)">) * <strong>부분 데이터:</strong> 남성과 여성 그룹 각각을 보면, 약물을 복용하지 않은 쪽의 회복률이 더 높습니다. * 남성: <img src="https://latex.codecogs.com/png.latex?P(Y%7C%5Cneg%20F,%20X)%20%3C%20P(Y%7C%5Cneg%20F,%20%5Cneg%20X)"> (60% vs 70%) * 여성: <img src="https://latex.codecogs.com/png.latex?P(Y%7CF,%20X)%20%3C%20P(Y%7CF,%20%5Cneg%20X)"> (20% vs 30%)</p>
<p>우리는 약을 써야 할까요, 말아야 할까요? [cite_start]남성에게도 해롭고 여성에게도 해로운 약이, 어떻게 전체 인류에게는 유익할 수 있을까요? [cite: 743-745]</p>
</section>
<section id="why-this-happens" class="level2">
<h2 class="anchored" data-anchor-id="why-this-happens">2.2. Why This Happens</h2>
<p>이 현상은 우리가 “본 것(Seeing)”과 “하는 것(Doing)”을 혼동하기 때문에 발생합니다. [cite_start]위 데이터에서 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">는 단순한 사건(Events)으로 취급되었습니다[cite: 754]. 성별(<img src="https://latex.codecogs.com/png.latex?F">)이 약물 복용 여부(<img src="https://latex.codecogs.com/png.latex?X">)와 회복률(<img src="https://latex.codecogs.com/png.latex?Y">) 모두에 영향을 미치는 교란 변수(Confounder)로 작용하여, 약물 복용 집단의 분포를 왜곡시킨 것입니다. (예: 회복력이 좋은 남성들이 약물을 더 많이 복용함)</p>
</section>
</section>
<section id="dissolving-the-paradox-with-do-calculus" class="level1">
<h1>3. Dissolving the Paradox with Do-Calculus</h1>
<p>이 역설을 해결하기 위해서는 관측된 조건부 확률 <img src="https://latex.codecogs.com/png.latex?P(Y%7CX)">가 아니라, 개입에 의한 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(Y%7Cdo(X))">를 비교해야 합니다.</p>
<section id="the-inequality-flip" class="level2">
<h2 class="anchored" data-anchor-id="the-inequality-flip">3.1. The Inequality Flip</h2>
<p>Do-notation을 사용하여 질문을 다시 쓰면 역설은 사라집니다. [cite_start]만약 각 하위 그룹(성별)에서 약물이 해롭다면, 전체 인구에 대해서도 약물 복용(<img src="https://latex.codecogs.com/png.latex?do(X)">)이 약물 비복용(<img src="https://latex.codecogs.com/png.latex?do(%5Cneg%20X)">)보다 해로워야 합니다[cite: 760, 768].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BIf%20%7D%20%5Cbegin%7Bcases%7D%20P(Y%7CF,%20do(X))%20%3C%20P(Y%7CF,%20do(%5Cneg%20X))%20%5C%5C%20P(Y%7C%5Cneg%20F,%20do(X))%20%3C%20P(Y%7C%5Cneg%20F,%20do(%5Cneg%20X))%20%5Cend%7Bcases%7D%0A"> <img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BThen,%20it%20must%20hold%20that:%20%7D%20P(Y%7Cdo(X))%20%3C%20P(Y%7Cdo(%5Cneg%20X))%0A"></p>
<p>[cite_start]즉, 인과적 관점(<img src="https://latex.codecogs.com/png.latex?do">-calculus)에서는 “부분의 합이 전체와 모순되는” 반전(Reversal)이 발생하지 않습니다[cite: 789].</p>
</section>
<section id="mathematical-proof" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-proof">3.2. Mathematical Proof</h2>
<p>이를 수학적으로 증명해 봅시다. 우리는 전체 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 계산하기 위해 성별 <img src="https://latex.codecogs.com/png.latex?F">를 조정(adjustment)해야 합니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L06/part-04/images/simpsons_paradox_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: 심슨의 역설을 설명하는 인과 그래프. 성별(F)은 약물 복용(X)과 회복(Y) 모두에 영향을 미치는 교란 요인(Confounder)입니다. X에서 Y로 가는 인과 효과를 올바르게 추정하기 위해서는 F로 인한 Back-door path를 차단해야 합니다.</figcaption>
</figure>
</div>
<p>[cite_start]Do-Calculus의 규칙과 전확률의 법칙(Law of Total Probability)을 사용하면 다음과 같이 유도됩니다[cite: 774].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0AP(y%7Cdo(x))%20&amp;=%20%5Csum_%7Bf%7D%20P(y%7Cdo(x),%20f)%20P(f%7Cdo(x))%20%5C%5C%0A&amp;=%20%5Csum_%7Bf%7D%20P(y%7Cx,%20f)%20P(f)%0A%5Cend%7Baligned%7D%0A"></p>
<p><strong>유도 단계 설명:</strong> 1. <strong>Rule 2 (Action to Observation):</strong> <img src="https://latex.codecogs.com/png.latex?f">가 주어졌을 때 <img src="https://latex.codecogs.com/png.latex?x">와 <img src="https://latex.codecogs.com/png.latex?y"> 사이의 Back-door path가 차단되므로, <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x),%20f)%20=%20P(y%7Cx,%20f)">가 됩니다. 즉, 성별이 같은 그룹 내에서는 관측된 효과가 곧 인과 효과입니다. 2. <strong>Rule 3 (Deleting Action):</strong> 성별(<img src="https://latex.codecogs.com/png.latex?F">)은 약물 복용(<img src="https://latex.codecogs.com/png.latex?X">)보다 먼저 결정되므로, 약물 복용에 개입한다고 해서 성별의 분포가 바뀌지 않습니다. 따라서 <img src="https://latex.codecogs.com/png.latex?P(f%7Cdo(x))%20=%20P(f)">입니다.</p>
<p><strong>결론:</strong> 이 공식(<img src="https://latex.codecogs.com/png.latex?%5Csum%20P(y%7Cx,%20f)P(f)">)은 각 그룹의 회복률(<img src="https://latex.codecogs.com/png.latex?P(y%7Cx,%20f)">)을, 약물 복용 여부에 편향되지 않은 <strong>전체 인구의 성비(<img src="https://latex.codecogs.com/png.latex?P(f)">)</strong>로 가중 평균을 냅니다. 이렇게 하면 데이터의 불균형이 보정되어, 부분 그룹의 경향성(약물이 해롭다)이 전체 결과에도 그대로 반영됩니다.</p>
</section>
</section>
<section id="the-sure-thing-principle" class="level1">
<h1>4. The Sure Thing Principle</h1>
<p>[cite_start]심슨의 역설의 해결은 Savage(1972)가 제창한 <strong>Sure Thing Principle</strong>과 맞닿아 있습니다[cite: 781].</p>
<blockquote class="blockquote">
<p>[cite_start]“만약 어떤 행동 <img src="https://latex.codecogs.com/png.latex?X">가 모든 하위 집단에서 사건 <img src="https://latex.codecogs.com/png.latex?Y">의 확률을 증가시킨다면, 그 행동은 전체 집단에서도 <img src="https://latex.codecogs.com/png.latex?Y">의 확률을 증가시켜야 한다. <strong>단, 그 행동이 하위 집단의 분포를 변화시키지 않는다면.</strong>” [cite: 784]</p>
</blockquote>
<p>여기서 중요한 단서는 <strong>“행동이 하위 집단의 분포를 변화시키지 않는다”</strong>는 점입니다. * 단순 관측 <img src="https://latex.codecogs.com/png.latex?P(Y%7CX)">에서는 <img src="https://latex.codecogs.com/png.latex?X">의 값에 따라 <img src="https://latex.codecogs.com/png.latex?F">의 분포가 달라집니다(예: 약을 먹은 그룹에 남자가 더 많음). 따라서 원칙이 적용되지 않고 역설이 발생할 수 있습니다. * 개입 <img src="https://latex.codecogs.com/png.latex?P(Y%7Cdo(X))">에서는 <img src="https://latex.codecogs.com/png.latex?do(X)">가 <img src="https://latex.codecogs.com/png.latex?F">의 분포 <img src="https://latex.codecogs.com/png.latex?P(F)">를 변화시키지 않으므로(<img src="https://latex.codecogs.com/png.latex?P(F%7Cdo(x))%20=%20P(F)">), Sure Thing Principle이 성립하여 역설이 사라집니다.</p>
</section>
<section id="food-for-thought-the-napkin-graph" class="level1">
<h1>5. Food for Thought: The Napkin Graph</h1>
<p>[cite_start]강의의 마지막에는 흥미로운 도전 과제인 <strong>Napkin Graph</strong>가 제시됩니다[cite: 798].</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L06/part-04/images/napkin_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: The Napkin Graph. 복잡한 인과 구조를 가진 그래프로, W는 두 개의 점선(양방향 화살표, 잠재적 교란 요인)의 충돌(Collider) 지점에 위치하며, Z와 X, Y가 얽혀 있습니다. 이 그래프에서 P(y|do(x))가 식별 가능한지가 문제입니다.</figcaption>
</figure>
</div>
<p><strong>문제:</strong> 위 Napkin Graph 구조에서 관측 데이터 <img src="https://latex.codecogs.com/png.latex?P(v)">만으로 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 식별(Identification)할 수 있을까요?</p>
<p>이 문제는 단순히 Back-door나 Front-door 기준만으로는 풀기 어려운 복잡한 구조를 가지고 있습니다. 하지만 Do-Calculus의 규칙들을 체계적으로 적용하거나, c-component 분해 알고리즘을 사용하면 식별 가능성을 판별할 수 있습니다. (정답은 독자 여러분의 연습 문제로 남겨둡니다!)</p>
</section>
<section id="summary-of-the-series" class="level1">
<h1>6. Summary of the Series</h1>
<p>지금까지 우리는 Causal Calculus의 여정을 함께했습니다.</p>
<ol type="1">
<li>[cite_start]<strong>Do-Calculus의 필요성:</strong> 정책 평가나 개입의 효과를 분석하기 위해 구문론적(syntactical) 접근이 필요합니다[cite: 793].</li>
<li>[cite_start]<strong>식별 문제의 해결:</strong> 교란(Confounding)과 식별(Identification) 문제는 Do-Calculus를 통해 비모수적(non-parametrically)으로 완전히 해결되었습니다[cite: 794].</li>
<li>[cite_start]<strong>심슨의 역설 해결:</strong> 역설은 수학적으로 정식화되었으며, 인과적 관점에서 해소되었습니다[cite: 795].</li>
</ol>
<p>[cite_start]인과추론은 이제 사회과학, 보건학뿐만 아니라 머신러닝과 AI의 공정성(fairness) 문제를 다루는 핵심 도구가 되었습니다[cite: 796].</p>
<hr>
<section id="누락-방지-검증-체크리스트" class="level3">
<h3 class="anchored" data-anchor-id="누락-방지-검증-체크리스트">누락 방지 검증 체크리스트</h3>
<ul>
<li><strong>포함된 내용:</strong>
<ul class="task-list">
<li><label><input type="checkbox" checked=""><strong>심슨의 역설 정의 및 역사:</strong> Pearson의 “Spurious Correlation” 발언 및 역사적 배경.</label></li>
<li><label><input type="checkbox" checked=""><strong>구체적 예시:</strong> UC Berkeley 및 약물/회복 테이블 데이터(Aggregated vs Segregated rates) 수치 포함.</label></li>
<li><label><input type="checkbox" checked=""><strong>역설의 핵심 모순:</strong> 부등식의 역전 현상 (<img src="https://latex.codecogs.com/png.latex?P(Y%7CX)"> vs <img src="https://latex.codecogs.com/png.latex?P(Y%7Cdo(X))">) 명시.</label></li>
<li><label><input type="checkbox" checked=""><strong>해결 과정 (Dissolving):</strong> Do-notation 도입 및 조건부 확률과 개입 확률의 차이 설명.</label></li>
<li><label><input type="checkbox" checked=""><strong>수학적 증명:</strong> <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">의 유도 과정 (Back-door adjustment 형태) 및 각 단계(<img src="https://latex.codecogs.com/png.latex?P(f%7Cdo(x))=P(f)"> 등)의 근거.</label></li>
<li><label><input type="checkbox" checked=""><strong>Sure Thing Principle:</strong> Savage의 정의 및 “하위 집단 분포 불변” 조건의 중요성 설명.</label></li>
<li><label><input type="checkbox" checked=""><strong>Napkin Graph:</strong> “Food for Thought”로 제시된 그래프 구조 및 식별 문제 소개.</label></li>
<li><label><input type="checkbox" checked=""><strong>요약:</strong> 강의 전체(Do-calculus, Identification, Applications)에 대한 요약.</label></li>
<li><label><input type="checkbox" checked=""><strong>이미지:</strong> 테이블 데이터, 인과 그래프, Napkin Graph에 대한 태그 포함.</label></li>
</ul></li>
<li><strong>생략된 내용:</strong>
<ul>
<li>없음. 제공된 PDF 페이지 29~39의 모든 내용을 포괄함.</li>
</ul></li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L06/part-04/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 07. An Algorithmic Approach to Identification (Part 1)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L07/part-01/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>인과 추론(Causal Inference)의 핵심 목표 중 하나는 관측 가능한 데이터(<img src="https://latex.codecogs.com/png.latex?P(v)">)로부터 우리가 관심을 가지는 인과 효과(<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">)를 식별(Identification)해내는 것입니다. 간단한 구조에서는 <em>Back-door criterion</em>이나 <em>Front-door criterion</em>을 사용할 수 있지만, 변수 간의 관계가 복잡하고 관측되지 않은 교란 요인(Unobserved Confounder)이 존재하는 일반적인 SCM(Structural Causal Model) 환경에서는 보다 체계적이고 알고리즘적인 접근이 필요합니다.</p>
<p>[cite_start]이번 포스트에서는 관측 분포를 인과 다이어그램(Causal Diagram)의 위상(Topology)에 따라 분해(Decomposition)하고, 이를 <strong>C-Factor(Confounded Factor)</strong> 라는 개념으로 일반화하여 인과 효과를 식별하는 과정을 다룹니다[cite: 209, 210].</p>
<p>[cite_start]주요 로드맵은 다음과 같습니다[cite: 292, 293, 294, 295]: 1. SCM과 인과 다이어그램에 기반하여 확률 분포를 분해(Factorization)하는 방법을 정의합니다. 2. 분포의 특정 구성 요소(Factor)를 식별할 수 있는 연산(Operation)을 확립합니다. 3. 타겟 인과 효과를 이러한 Factor들의 조합으로 표현하여 식별 가능성을 판단합니다.</p>
<hr>
</section>
<section id="decomposition-of-probability-distributions" class="level1">
<h1>2. Decomposition of Probability Distributions</h1>
<section id="markovian-case-no-unobserved-confounders" class="level2">
<h2 class="anchored" data-anchor-id="markovian-case-no-unobserved-confounders">2.1 Markovian Case (No Unobserved Confounders)</h2>
<p>모든 변수가 관측 가능하고, 오차항(Error terms)들이 서로 독립인 <strong>Markovian 모델</strong>을 먼저 살펴봅시다. [cite_start]이 경우, 관측 변수 집합 <img src="https://latex.codecogs.com/png.latex?V">에 대한 결합 확률 분포 <img src="https://latex.codecogs.com/png.latex?P(v)">는 베이지안 네트워크의 분해 성질에 따라 각 변수의 부모 변수(<img src="https://latex.codecogs.com/png.latex?pa_i">)에 대한 조건부 확률의 곱으로 표현됩니다[cite: 303, 304, 305].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(v)%20=%20%5Csum_%7Bu%7D%20P(u)%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%7C%20pa_i,%20u_i)%20=%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%7C%20pa_i)%0A"></p>
<p>[cite_start]여기서 <img src="https://latex.codecogs.com/png.latex?P(v_i%7Cpa_i)">는 <img src="https://latex.codecogs.com/png.latex?P(v)">로부터 직접 계산 가능하므로, 이를 <strong>Canonical Factor</strong>라고 부를 수 있습니다[cite: 316].</p>
<p><img src="https://shsha0110.github.io/posts/lecture/L07/part-01/images/markovian_dag_example.png" class="img-fluid" alt="Figure: Markovian 모델에서의 변수 간 관계와 조건부 독립성"> <em>이 그림은 <img src="https://latex.codecogs.com/png.latex?X,%20Y,%20Z"> 변수로 구성된 단순한 Markovian 모델을 보여줍니다. <img src="https://latex.codecogs.com/png.latex?U"> 변수들이 서로 독립이므로, 전체 분포는 <img src="https://latex.codecogs.com/png.latex?P(z)P(x%7Cz)P(y%7Cx,z)">와 같이 각 노드의 조건부 확률곱으로 깔끔하게 분해됩니다.</em></p>
</section>
<section id="semi-markovian-case-with-unobserved-confounders" class="level2">
<h2 class="anchored" data-anchor-id="semi-markovian-case-with-unobserved-confounders">2.2 Semi-Markovian Case (With Unobserved Confounders)</h2>
<p>현실에서는 관측되지 않은 교란 변수 <img src="https://latex.codecogs.com/png.latex?U">가 존재하여 변수들 간의 Markovian 성질을 깰 수 있습니다. 이를 <strong>Semi-Markovian 모델</strong>이라 합니다. [cite_start]예를 들어, <img src="https://latex.codecogs.com/png.latex?V_1%20%5Crightarrow%20V_2%20%5Crightarrow%20V_3%20%5Cdots"> 와 같은 구조에 관측되지 않은 <img src="https://latex.codecogs.com/png.latex?U_1">이 <img src="https://latex.codecogs.com/png.latex?V_1">과 <img src="https://latex.codecogs.com/png.latex?V_3">에 동시에 영향을 준다면, 분포의 분해는 더 복잡해집니다[cite: 336, 341].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(v)%20=%20%5Csum_%7Bu%7D%20P(u)%20%5Cprod_%7BV_i%20%5Cin%20V%7D%20P(v_i%20%7C%20pa_i,%20u_i)%0A"></p>
<p>강의 자료의 예제(<img src="https://latex.codecogs.com/png.latex?V_1%20%5Cdots%20V_5">와 <img src="https://latex.codecogs.com/png.latex?U_1,%20U_2,%20U_3">가 섞인 모델)를 보면, <img src="https://latex.codecogs.com/png.latex?U">에 대해 합(Summation)을 취하는 과정에서 서로 얽혀있는 항들이 생겨납니다. [cite_start]이로 인해 단순한 조건부 확률의 곱(<img src="https://latex.codecogs.com/png.latex?%5Cprod%20P(v_i%7Cpa_i)">) 형태로 표현되지 않고, <strong><img src="https://latex.codecogs.com/png.latex?U">를 공유하는 변수들의 묶음(Term)</strong> 들이 나타나게 됩니다[cite: 384].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(v)%20=%20%5Cunderbrace%7B%5Cleft(%20%5Csum_%7Bu_3%7D%20P(v_2%7Cv_1,%20u_3)P(v_4%7Cv_3,%20u_3)P(u_3)%20%5Cright)%7D_%7B%5Ctext%7BFactor%201%7D%7D%20%5Ccdot%20%5Cunderbrace%7B%5Cleft(%20%5Csum_%7Bu_1,%20u_2%7D%20P(u_1,%20u_2)%20%5Cdots%20%5Cright)%7D_%7B%5Ctext%7BFactor%202%7D%7D%0A"></p>
<p>이러한 복잡한 묶음들을 체계적으로 다루기 위해 새로운 함수 <img src="https://latex.codecogs.com/png.latex?Q">를 도입합니다.</p>
<hr>
</section>
</section>
<section id="c-factors-confounded-factors" class="level1">
<h1>3. C-Factors (Confounded Factors)</h1>
<section id="definition-of-q-function" class="level2">
<h2 class="anchored" data-anchor-id="definition-of-q-function">3.1 Definition of Q-function</h2>
<p>복잡한 합(Summation) 형태의 항들을 추상화하여 <strong>Q-Factor</strong> 또는 <strong>C-Factor</strong>라고 정의합니다. [cite_start]변수 집합 <img src="https://latex.codecogs.com/png.latex?C%20%5Csubseteq%20V">에 대하여 <img src="https://latex.codecogs.com/png.latex?Q%5BC%5D">는 다음과 같이 정의됩니다[cite: 220, 221, 396]:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AQ%5BC%5D(c,%20pa_c)%20=%20%5Csum_%7Bu(C)%7D%20P(u(C))%20%5Cprod_%7BV_i%20%5Cin%20C%7D%20P(v_i%20%7C%20pa_i,%20u_i)%0A"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?U(C)">는 <img src="https://latex.codecogs.com/png.latex?C">에 속한 변수들의 부모인 오차항들의 집합(<img src="https://latex.codecogs.com/png.latex?%5Cbigcup_%7BV_i%20%5Cin%20C%7D%20U_i">)을 의미합니다. [cite_start]이 정의를 사용하면, 앞서 복잡했던 <img src="https://latex.codecogs.com/png.latex?P(v)"> 식을 C-Factor들의 곱으로 간결하게 다시 쓸 수 있습니다[cite: 397, 400].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(v)%20=%20Q%5B%5C%7BV_2,%20V_4%5C%7D%5D%20%5Ccdot%20Q%5B%5C%7BV_1,%20V_3,%20V_5%5C%7D%5D%0A"></p>
</section>
<section id="interpretation-c-factors-as-causal-effects" class="level2">
<h2 class="anchored" data-anchor-id="interpretation-c-factors-as-causal-effects">3.2 Interpretation: C-Factors as Causal Effects</h2>
<p>C-Factor <img src="https://latex.codecogs.com/png.latex?Q%5BC%5D">는 단순한 수식적 정의를 넘어 중요한 인과적 의미를 가집니다. [cite_start]<img src="https://latex.codecogs.com/png.latex?Q%5BC%5D">는 <strong>“<img src="https://latex.codecogs.com/png.latex?C">를 제외한 모든 변수(<img src="https://latex.codecogs.com/png.latex?V%20%5Csetminus%20C">)에 개입(Intervention)했을 때, <img src="https://latex.codecogs.com/png.latex?C">가 가질 확률 분포”</strong> 로 해석될 수 있습니다[cite: 404, 407].</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AQ%5BC%5D%20=%20P(c%20%5Cmid%20do(v%20%5Csetminus%20c))%0A"></p>
<p><strong>유도 과정:</strong> Truncated Product Formula에 의해 <img src="https://latex.codecogs.com/png.latex?P(c%20%5Cmid%20do(v%20%5Csetminus%20c))">는 <img src="https://latex.codecogs.com/png.latex?C">에 속하지 않는 변수들의 구조적 방정식(또는 조건부 확률)을 제거한 분포입니다. <img src="https://latex.codecogs.com/png.latex?C">의 부모가 아닌 <img src="https://latex.codecogs.com/png.latex?U">들은 모두 합쳐져서 사라지므로(Summed out), 결국 <img src="https://latex.codecogs.com/png.latex?C">에 영향을 주는 <img src="https://latex.codecogs.com/png.latex?U(C)">와 구조적 식들만 남아 <img src="https://latex.codecogs.com/png.latex?Q%5BC%5D">의 정의와 일치하게 됩니다.</p>
<hr>
</section>
</section>
<section id="operations-on-c-factors" class="level1">
<h1>4. Operations on C-Factors</h1>
<p>C-Factor를 자유자재로 다루기 위해 두 가지 핵심 연산(Operation)이 필요합니다.</p>
<section id="ancestral-reduction-marginalization" class="level2">
<h2 class="anchored" data-anchor-id="ancestral-reduction-marginalization">4.1 Ancestral Reduction (Marginalization)</h2>
<p>특정 조건 하에서 C-Factor <img src="https://latex.codecogs.com/png.latex?Q%5BC%5D">로부터 일부 변수를 제거(Marginalization)하여 더 작은 집합의 <img src="https://latex.codecogs.com/png.latex?Q">를 얻을 수 있습니다.</p>
<p>[cite_start]<strong>Lemma (Ancestral-Reduction)</strong>[cite: 422, 423]: 집합 <img src="https://latex.codecogs.com/png.latex?W%20%5Csubseteq%20C">가 <img src="https://latex.codecogs.com/png.latex?C"> 내에서 유도된 서브그래프 <img src="https://latex.codecogs.com/png.latex?G%5BC%5D"> 상에서 <strong>조상(Ancestral) 집합</strong>이라면(즉, <img src="https://latex.codecogs.com/png.latex?W">의 모든 조상이 <img src="https://latex.codecogs.com/png.latex?W">에 포함된다면), 다음이 성립합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AQ%5BW%5D%20=%20%5Csum_%7Bc%20%5Csetminus%20w%7D%20Q%5BC%5D%0A"></p>
<p>이 정리는 우리가 구하고자 하는 <img src="https://latex.codecogs.com/png.latex?Q"> 팩터가 너무 클 때, 불필요한 변수를 합(Summation)으로 제거할 수 있는 조건을 제시합니다. [cite_start]예를 들어, <img src="https://latex.codecogs.com/png.latex?V_1%20%5Crightarrow%20V_2"> 관계에서 <img src="https://latex.codecogs.com/png.latex?%5C%7BV_1%5C%7D">은 조상 집합이므로 <img src="https://latex.codecogs.com/png.latex?Q%5B%5C%7BV_1%5C%7D%5D%20=%20%5Csum_%7Bv_2%7D%20Q%5B%5C%7BV_1,%20V_2%5C%7D%5D">가 가능하지만, <img src="https://latex.codecogs.com/png.latex?%5C%7BV_2%5C%7D">만 남기는 것은 불가능할 수 있습니다[cite: 424].</p>
</section>
<section id="c-component-factorization-tians-lemma" class="level2">
<h2 class="anchored" data-anchor-id="c-component-factorization-tians-lemma">4.2 C-Component Factorization (Tian’s Lemma)</h2>
<p>가장 강력한 도구는 그래프의 <strong>C-Component(Confounded Component)</strong> 구조를 이용해 <img src="https://latex.codecogs.com/png.latex?Q%5BC%5D">를 더 작은 단위로 쪼개는 것입니다.</p>
<p>[cite_start]<strong>Definition (C-Component)</strong>[cite: 426, 427]: 두 변수 <img src="https://latex.codecogs.com/png.latex?V_i,%20V_j">가 관측되지 않은 공통 부모 <img src="https://latex.codecogs.com/png.latex?U">를 공유한다면(즉, <img src="https://latex.codecogs.com/png.latex?V_i%20%5Cleftrightarrow%20%5Cdots%20%5Cleftrightarrow%20V_j"> 경로가 있다면), 두 변수는 같은 C-Component에 속합니다. [cite_start]이 관계는 반사, 대칭, 추이적(Reflexive, Symmetric, Transitive)이므로 변수 집합 <img src="https://latex.codecogs.com/png.latex?V">를 분할(Partition)합니다[cite: 431].</p>
<p>[cite_start]<strong>Lemma (Tian [2002])</strong>[cite: 438, 439]: 어떤 변수 집합 <img src="https://latex.codecogs.com/png.latex?H%20%5Csubseteq%20V">에 대해, <img src="https://latex.codecogs.com/png.latex?G%5BH%5D">의 C-Component들이 <img src="https://latex.codecogs.com/png.latex?H_1,%20%5Cdots,%20H_k">라면, <img src="https://latex.codecogs.com/png.latex?Q%5BH%5D">는 다음과 같이 분해됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AQ%5BH%5D%20=%20%5Cprod_%7Bj=1%7D%5E%7Bk%7D%20Q%5BH_j%5D%0A"></p>
<p>이 정리는 전체 분포 <img src="https://latex.codecogs.com/png.latex?P(v)%20=%20Q%5BV%5D">를 그래프상의 연결 요소(Connected Component via bidirected edges)별로 쪼갤 수 있음을 의미합니다.</p>
<section id="computing-factors-via-topological-order" class="level3">
<h3 class="anchored" data-anchor-id="computing-factors-via-topological-order">Computing Factors via Topological Order</h3>
<p>[cite_start]각 C-Component <img src="https://latex.codecogs.com/png.latex?Q%5BH_j%5D">를 실제로 계산하기 위해, <img src="https://latex.codecogs.com/png.latex?H">에 대한 위상 정렬(Topological Order) <img src="https://latex.codecogs.com/png.latex?V_%7B(1)%7D%20%3C%20%5Cdots%20%3C%20V_%7B(%7CH%7C)%7D">을 이용합니다[cite: 442, 443]. <img src="https://latex.codecogs.com/png.latex?H_%7B%5Cle%20i%7D">를 위상 정렬상 <img src="https://latex.codecogs.com/png.latex?V_%7B(i)%7D">까지의 변수 집합이라고 할 때,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AQ%5BH_j%5D%20=%20%5Cprod_%7BV_%7B(i)%7D%20%5Cin%20H_j%7D%20%5Cfrac%7BQ%5BH_%7B%5Cle%20i%7D%5D%7D%7BQ%5BH_%7B%5Cle%20i-1%7D%5D%7D%20=%20%5Cprod_%7BV_%7B(i)%7D%20%5Cin%20H_j%7D%20P(v_%7B(i)%7D%20%5Cmid%20v%5E%7B(i-1)%7D)%0A"> (여기서 <img src="https://latex.codecogs.com/png.latex?v%5E%7B(i-1)%7D">는 위상 정렬 상 앞선 변수들)</p>
<p>[cite_start]이 공식을 통해 복잡한 <img src="https://latex.codecogs.com/png.latex?Q"> 팩터들을 관측 데이터 <img src="https://latex.codecogs.com/png.latex?P(v)">의 조건부 확률들의 곱 형태로 구체적으로 계산할 수 있습니다[cite: 268].</p>
<p><img src="https://shsha0110.github.io/posts/lecture/L07/part-01/images/c_factor_lattice.png" class="img-fluid" alt="Figure: C-Component Factorization Visualization"> <em>C-Factorization의 개념도. 전체 집합 <img src="https://latex.codecogs.com/png.latex?V">에 대한 <img src="https://latex.codecogs.com/png.latex?Q%5BV%5D">에서 시작하여, 그래프의 C-Component 구조에 따라 더 작은 <img src="https://latex.codecogs.com/png.latex?Q"> 팩터들(<img src="https://latex.codecogs.com/png.latex?Q%5BV_%7B123%7D%5D,%20Q%5BV_%7B24%7D%5D"> 등)로 쪼개지는 과정을 나타냅니다. 분해된 팩터들은 더 이상 분해되지 않을 때까지(Atomic) 계속됩니다.</em></p>
<hr>
</section>
</section>
</section>
<section id="detailed-example-derivation" class="level1">
<h1>5. Detailed Example: Derivation</h1>
<p>[cite_start]강의 자료의 예시(<img src="https://latex.codecogs.com/png.latex?V_1,%20%5Cdots,%20V_5">)를 통해 <img src="https://latex.codecogs.com/png.latex?Q%5B%5C%7BV_1,%20V_3,%20V_5%5C%7D%5D">를 실제로 계산해봅시다[cite: 267, 268].</p>
<ol type="1">
<li><strong>목표</strong>: <img src="https://latex.codecogs.com/png.latex?Q%5B%5C%7BV_1,%20V_3,%20V_5%5C%7D%5D"> 계산.</li>
<li><strong>Topological Order</strong>: <img src="https://latex.codecogs.com/png.latex?V_1%20%3C%20V_2%20%3C%20V_3%20%3C%20V_4%20%3C%20V_5">라고 가정.</li>
<li><strong>Ancestral Reduction &amp; Ratio</strong>: <img src="https://latex.codecogs.com/png.latex?Q%5BH%5D"> 분해 공식을 적용하면 각 단계별로 <img src="https://latex.codecogs.com/png.latex?P(v)">의 조건부 확률 형태가 나타납니다. <img src="https://latex.codecogs.com/png.latex?%0AQ%5B%5C%7BV_1,%20V_3,%20V_5%5C%7D%5D%20=%20%5Cfrac%7BQ%5B%5C%7BV_1%5C%7D%5D%7D%7B1%7D%20%5Ctimes%20%5Cfrac%7BQ%5B%5C%7BV_1,%20V_2,%20V_3%5C%7D%5D%7D%7BQ%5B%5C%7BV_1,%20V_2%5C%7D%5D%7D%20%5Ctimes%20%5Cfrac%7BQ%5B%5C%7BV_1%20%5Cdots%20V_5%5C%7D%5D%7D%7BQ%5B%5C%7BV_1%20%5Cdots%20V_4%5C%7D%5D%7D%0A"> 각 항은 Ancestral Reduction에 의해 다음과 같이 <img src="https://latex.codecogs.com/png.latex?P">의 마지널/조건부 확률로 변환됩니다.
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7BQ%5B%5C%7BV_1%5C%7D%5D%7D%7B1%7D%20=%20P(v_1)"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7BQ%5B%5C%7BV_1,%20V_2,%20V_3%5C%7D%5D%7D%7BQ%5B%5C%7BV_1,%20V_2%5C%7D%5D%7D%20=%20%5Cfrac%7BP(v_1,%20v_2,%20v_3)%7D%7BP(v_1,%20v_2)%7D%20=%20P(v_3%20%7C%20v_1,%20v_2)"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7BQ%5BV%5D%7D%7BQ%5BV%20%5Csetminus%20%5C%7BV_5%5C%7D%5D%7D%20=%20P(v_5%20%7C%20v_1,%20v_2,%20v_3,%20v_4)"></li>
</ul></li>
<li><strong>최종 결과</strong>: <img src="https://latex.codecogs.com/png.latex?%0AQ%5B%5C%7BV_1,%20V_3,%20V_5%5C%7D%5D%20=%20P(v_1)%20P(v_3%20%7C%20v_1,%20v_2)%20P(v_5%20%7C%20v_1,%20v_2,%20v_3,%20v_4)%0A"></li>
</ol>
<p>이처럼 추상적인 <img src="https://latex.codecogs.com/png.latex?Q"> 팩터는 위상 정렬과 Ancestral Reduction을 통해 관측 가능한 조건부 확률들의 곱으로 명확히 식별(Identified)됩니다.</p>
<hr>
</section>
<section id="summary" class="level1">
<h1>6. Summary</h1>
<p>이번 포스트에서는 복잡한 인과 모델에서 인과 효과를 식별하기 위한 알고리즘적 기초를 다루었습니다. [cite_start]핵심 내용을 정리하면 다음과 같습니다[cite: 286].</p>
<ul>
<li><strong>C-Factor (<img src="https://latex.codecogs.com/png.latex?Q%5BC%5D">)</strong>: 변수 집합 <img src="https://latex.codecogs.com/png.latex?C">에 대한 인과적 기여분(Causal Contribution)을 나타내며, <img src="https://latex.codecogs.com/png.latex?P(c%7Cdo(v%20%5Csetminus%20c))">와 같습니다.</li>
<li><strong>Ancestral Reduction</strong>: <img src="https://latex.codecogs.com/png.latex?Q%5BC%5D">에서 조상 집합에 해당하는 변수들만 남기고 나머지를 합(Summation)으로 제거할 수 있습니다 (<img src="https://latex.codecogs.com/png.latex?Q%5BW%5D%20=%20%5Csum_%7Bc%20%5Csetminus%20w%7D%20Q%5BC%5D">).</li>
<li><strong>C-Component Factorization</strong>: 그래프의 양방향 엣지(Bidirected edges)로 연결된 컴포넌트(C-Component)별로 <img src="https://latex.codecogs.com/png.latex?Q"> 팩터를 곱의 형태로 분해할 수 있습니다 (<img src="https://latex.codecogs.com/png.latex?Q%5BH%5D%20=%20%5Cprod%20Q%5BH_j%5D">).</li>
<li><strong>Identifiability</strong>: 이러한 분해와 연산 과정을 통해 타겟 인과 효과를 <img src="https://latex.codecogs.com/png.latex?P(v)">의 함수로 표현할 수 있다면, 해당 인과 효과는 식별 가능(Identifiable)합니다.</li>
</ul>
<p>이러한 <strong>C-Factor Algebra</strong>는 단순한 공식을 넘어, 인과 추론의 가장 일반적인 식별 알고리즘인 <strong>ID 알고리즘(Identification Algorithm)</strong> 의 근간이 됩니다.</p>
<hr>
<section id="누락-방지-검증-checklist" class="level3">
<h3 class="anchored" data-anchor-id="누락-방지-검증-checklist">누락 방지 검증 (Checklist)</h3>
<ul>
<li><strong>[포함]</strong> 확률 분포의 분해 (Markovian vs Semi-Markovian)</li>
<li><strong>[포함]</strong> C-Factor (<img src="https://latex.codecogs.com/png.latex?Q%5BC%5D">)의 정의 및 인과적 의미 (<img src="https://latex.codecogs.com/png.latex?do">-calculus와의 연결)</li>
<li><strong>[포함]</strong> Ancestral Reduction (Marginalization) Lemma</li>
<li><strong>[포함]</strong> C-Component의 정의 및 성질 (Reflexive, Symmetric, Transitive)</li>
<li><strong>[포함]</strong> Tian’s Factorization Lemma (C-Component Factorization)</li>
<li><strong>[포함]</strong> 위상 정렬(Topological Order)을 이용한 구체적 계산 공식 및 예제 (<img src="https://latex.codecogs.com/png.latex?Q%5B%5C%7BV_1,%20V_3,%20V_5%5C%7D%5D"> 유도)</li>
<li><strong>[포함]</strong> 핵심 시각화 자료 (Markovian DAG, C-Factor Lattice) 설명 포함</li>
<li><strong>[생략]</strong> 없음 (강의 자료의 핵심 이론적 흐름을 모두 포함함)</li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L07/part-01/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 07. An Algorithmic Approach to Identification (Part 2)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L07/part-02/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>지난 포스트에서는 인과 추론을 위한 알고리즘적 접근의 기초인 <strong>C-Factor(Confounded Factor)</strong> 와 <strong>Tian’s Factorization</strong>을 다루었습니다. 관측 분포 <img src="https://latex.codecogs.com/png.latex?P(v)">를 인과 그래프의 위상(Topology)에 따라 <img src="https://latex.codecogs.com/png.latex?Q%5BC%5D">라는 구성 요소들로 쪼개는 방법이었죠.</p>
<p>이번 포스트에서는 이 강력한 도구를 사용하여 실제로 인과 효과를 식별(Identification)하는 과정을 살펴봅니다. 교과서적인 <strong>Back-door</strong>와 <strong>Front-door</strong> 기준이 C-Factor 관점에서 어떻게 유도되는지 확인하고, 직관적으로 해결하기 어려운 <strong>Napkin Model</strong>을 단계별로 풀어봅니다. 마지막으로, 모든 식별 가능한 인과 효과를 찾아낼 수 있는 <strong>일반화된 ID 알고리즘(General Identification Algorithm)</strong> 의 전체 프로세스를 정리합니다.</p>
<hr>
</section>
<section id="re-deriving-standard-criteria-via-c-factors" class="level1">
<h1>2. Re-deriving Standard Criteria via C-Factors</h1>
<p>C-Factor 이론이 강력한 이유는 기존의 Back-door나 Front-door 기준을 별도의 정리 없이도 자연스럽게 유도해낼 수 있기 때문입니다.</p>
<section id="the-back-door-criterion" class="level2">
<h2 class="anchored" data-anchor-id="the-back-door-criterion">2.1 The Back-door Criterion</h2>
<p>가장 기본적인 교란 구조를 살펴봅시다. <img src="https://latex.codecogs.com/png.latex?Z">가 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y">의 공통 원인인 경우입니다.</p>
<ul>
<li><strong>Graph:</strong> <img src="https://latex.codecogs.com/png.latex?X%20%5Cleftarrow%20Z%20%5Crightarrow%20Y"> 그리고 <img src="https://latex.codecogs.com/png.latex?X%20%5Crightarrow%20Y"></li>
<li><strong>Query:</strong> <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))"></li>
</ul>
<p>이 그래프에서 모든 변수는 각자의 C-Component를 형성합니다(양방향 화살표가 없음). 따라서 결합 분포는 다음과 같이 분해됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(x,%20y,%20z)%20=%20Q%5BX%5D%20%5Ccdot%20Q%5BY%5D%20%5Ccdot%20Q%5BZ%5D%0A"></p>
<p>각 <img src="https://latex.codecogs.com/png.latex?Q"> 팩터는 해당 변수의 조건부 확률(부모 변수가 주어졌을 때)과 같습니다. <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign%7D%0AQ%5BZ%5D%20&amp;=%20P(z)%20%5C%5C%0AQ%5BX%5D%20&amp;=%20P(x%7Cz)%20%5C%5C%0AQ%5BY%5D%20&amp;=%20P(y%7Cx,%20z)%0A%5Cend%7Balign%7D%0A"></p>
<p>우리가 구하고자 하는 개입 분포 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">는, <img src="https://latex.codecogs.com/png.latex?X">로 들어오는 모든 화살표를 끊고 <img src="https://latex.codecogs.com/png.latex?X=x">로 고정한 모델에서의 분포입니다. C-Factor 관점에서는 <img src="https://latex.codecogs.com/png.latex?X">의 메커니즘인 <img src="https://latex.codecogs.com/png.latex?Q%5BX%5D">를 제거하고, 나머지 메커니즘 <img src="https://latex.codecogs.com/png.latex?Q%5BY%5D,%20Q%5BZ%5D">는 그대로 유지한 채 <img src="https://latex.codecogs.com/png.latex?Y">에 대해 합(Marginalization)을 구하는 것과 같습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign%7D%0AP(y%7Cdo(x))%20&amp;=%20%5Csum_%7Bz%7D%20Q%5BY%5D(x,%20z)%20%5Ccdot%20Q%5BZ%5D(z)%20%5C%5C%0A&amp;=%20%5Csum_%7Bz%7D%20P(y%7Cx,%20z)%20P(z)%0A%5Cend%7Balign%7D%0A"></p>
<p>이 결과는 우리가 잘 아는 <strong>Back-door Adjustment Formula</strong>와 정확히 일치합니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L07/part-02/images/backdoor_decomposition.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Back-door 그래프 구조와 분해. Z는 X와 Y의 교란 요인(Confounder)이며, 개입 시 X와 Z의 연결이 끊어짐을 보여준다.</figcaption>
</figure>
</div>
</section>
<section id="the-front-door-criterion" class="level2">
<h2 class="anchored" data-anchor-id="the-front-door-criterion">2.2 The Front-door Criterion</h2>
<p>다음은 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이에 관측되지 않은 교란 변수 <img src="https://latex.codecogs.com/png.latex?U">가 존재하지만(<img src="https://latex.codecogs.com/png.latex?X%20%5Cleftrightarrow%20Y">), 중간 매개 변수 <img src="https://latex.codecogs.com/png.latex?Z">가 존재하는 <strong>Front-door</strong> 구조입니다.</p>
<ul>
<li><strong>Graph:</strong> <img src="https://latex.codecogs.com/png.latex?X%20%5Crightarrow%20Z%20%5Crightarrow%20Y">, <img src="https://latex.codecogs.com/png.latex?X%20%5Cleftrightarrow%20Y"> (via <img src="https://latex.codecogs.com/png.latex?U">)</li>
<li><strong>Query:</strong> <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))"></li>
</ul>
<p>이 그래프의 C-Component는 양방향 엣지로 연결된 <img src="https://latex.codecogs.com/png.latex?%5C%7BX,%20Y%5C%7D">와, 독립적인 <img src="https://latex.codecogs.com/png.latex?%5C%7BZ%5C%7D">로 나뉩니다. <img src="https://latex.codecogs.com/png.latex?%0AP(x,%20y,%20z)%20=%20Q%5B%5C%7BX,%20Y%5C%7D%5D%20%5Ccdot%20Q%5B%5C%7BZ%5C%7D%5D%0A"></p>
<p>여기서 각 팩터를 관측 데이터로 식별해 봅시다. 1. <strong><img src="https://latex.codecogs.com/png.latex?Q%5B%5C%7BZ%5C%7D%5D"></strong>: <img src="https://latex.codecogs.com/png.latex?Z">의 부모는 <img src="https://latex.codecogs.com/png.latex?X">뿐이므로, <img src="https://latex.codecogs.com/png.latex?Q%5B%5C%7BZ%5C%7D%5D%20=%20P(z%7Cx)">. 2. <strong><img src="https://latex.codecogs.com/png.latex?Q%5B%5C%7BX,%20Y%5C%7D%5D"></strong>: 전체 분포를 <img src="https://latex.codecogs.com/png.latex?Q%5B%5C%7BZ%5C%7D%5D">로 나누면 얻을 수 있습니다. <img src="https://latex.codecogs.com/png.latex?Q%5B%5C%7BX,%20Y%5C%7D%5D%20=%20%5Cfrac%7BP(x,%20y,%20z)%7D%7BP(z%7Cx)%7D%20=%20P(y%7Cx,%20z)P(x)"></p>
<p>이제 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 구하기 위해 <img src="https://latex.codecogs.com/png.latex?X">에 개입합니다. 이는 그래프에서 <img src="https://latex.codecogs.com/png.latex?X">로 들어오는 엣지를 끊는 것인데, 이 모델에서 <img src="https://latex.codecogs.com/png.latex?X">의 부모는 <img src="https://latex.codecogs.com/png.latex?U">입니다. <img src="https://latex.codecogs.com/png.latex?do(x)"> 연산은 <img src="https://latex.codecogs.com/png.latex?X">가 <img src="https://latex.codecogs.com/png.latex?U">의 영향을 받지 않게 하므로, <img src="https://latex.codecogs.com/png.latex?Q%5B%5C%7BX,%20Y%5C%7D%5D"> 내에서 <img src="https://latex.codecogs.com/png.latex?X">의 확률 부분(<img src="https://latex.codecogs.com/png.latex?P(x)">)을 제거하거나, <img src="https://latex.codecogs.com/png.latex?X">를 상수로 고정하고 <img src="https://latex.codecogs.com/png.latex?U">에 대해 적분하는 과정을 거칩니다.</p>
<p>수식적으로 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">는 다음과 같이 유도됩니다 (Chain rule of do-calculus 활용 형태):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(z%7Cdo(x))%20P(y%7Cdo(x),%20z)%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?X%20%5Crightarrow%20Z">는 교란이 없으므로 <img src="https://latex.codecogs.com/png.latex?P(z%7Cdo(x))%20=%20P(z%7Cx)">. <img src="https://latex.codecogs.com/png.latex?Z%20%5Crightarrow%20Y">의 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(z))">는 <img src="https://latex.codecogs.com/png.latex?X">가 Back-door 역할을 하므로 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(z))%20=%20%5Csum_%7Bx'%7D%20P(y%7Cx',%20z)P(x')">. 이를 종합하면:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bz%7D%20P(z%7Cx)%20%5Csum_%7Bx'%7D%20P(y%7Cx',%20z)P(x')%0A"></p>
<p>이것이 바로 <strong>Front-door Adjustment Formula</strong>입니다.</p>
<hr>
</section>
</section>
<section id="solving-the-napkin-problem" class="level1">
<h1>3. Solving the “Napkin” Problem</h1>
<p>이제 직관만으로는 해결하기 어려운 복잡한 그래프, 이른바 <strong>Napkin Model</strong>을 C-Factor 알고리즘으로 풀어보겠습니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L07/part-02/images/napkin_graph.png" class="img-fluid figure-img"></p>
<figcaption>Figure: The Napkin Graph. W2 -&gt; X, W1 -&gt; W2, W1 -&gt; Y, 그리고 X와 Y 사이의 양방향 엣지(Confounder)가 존재하는 구조.</figcaption>
</figure>
</div>
<section id="model-setup-decomposition" class="level3">
<h3 class="anchored" data-anchor-id="model-setup-decomposition">3.1 Model Setup &amp; Decomposition</h3>
<ul>
<li><strong>Variables:</strong> <img src="https://latex.codecogs.com/png.latex?W_1,%20W_2,%20X,%20Y"></li>
<li><strong>Edges:</strong> <img src="https://latex.codecogs.com/png.latex?W_1%20%5Crightarrow%20W_2">, <img src="https://latex.codecogs.com/png.latex?W_2%20%5Crightarrow%20X">, <img src="https://latex.codecogs.com/png.latex?W_1%20%5Crightarrow%20Y">, <img src="https://latex.codecogs.com/png.latex?X%20%5Cleftrightarrow%20Y"> (비관측 교란)</li>
<li><strong>C-Components:</strong>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?S_1%20=%20%5C%7BW_1%5C%7D"></li>
<li><img src="https://latex.codecogs.com/png.latex?S_2%20=%20%5C%7BW_2%5C%7D"></li>
<li><img src="https://latex.codecogs.com/png.latex?S_3%20=%20%5C%7BX,%20Y%5C%7D"> (양방향 엣지로 연결됨)</li>
</ul></li>
</ul>
<p>따라서 결합 분포는 다음과 같이 분해됩니다: <img src="https://latex.codecogs.com/png.latex?%0AP(v)%20=%20Q%5BW_1%5D%20%5Ccdot%20Q%5BW_2%5D%20%5Ccdot%20Q%5BX,%20Y%5D%0A"></p>
<p>각 팩터의 식별: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign%7D%0AQ%5BW_1%5D%20&amp;=%20P(w_1)%20%5C%5C%0AQ%5BW_2%5D%20&amp;=%20P(w_2%7Cw_1)%20%5C%5C%0AQ%5BX,%20Y%5D%20&amp;=%20P(y%7Cx,%20w_1,%20w_2)P(x%7Cw_1,%20w_2)%0A%5Cend%7Balign%7D%0A"> (참고: <img src="https://latex.codecogs.com/png.latex?Q%5BX,Y%5D">는 <img src="https://latex.codecogs.com/png.latex?P(v)">를 <img src="https://latex.codecogs.com/png.latex?Q%5BW_1%5DQ%5BW_2%5D">로 나눈 나머지입니다.)</p>
</section>
<section id="target-identification-pydox" class="level3">
<h3 class="anchored" data-anchor-id="target-identification-pydox">3.2 Target Identification: <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))"></h3>
<p>우리의 목표는 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">입니다. 이는 <img src="https://latex.codecogs.com/png.latex?Q"> 팩터 관점에서 <img src="https://latex.codecogs.com/png.latex?Q%5BY%5D_x"> (개입 후의 Y 관련 팩터)를 구하는 것과 같습니다. <img src="https://latex.codecogs.com/png.latex?X%20%5Cleftrightarrow%20Y">가 하나의 C-Component에 묶여 있으므로, <img src="https://latex.codecogs.com/png.latex?X">를 개입(제거)하고 <img src="https://latex.codecogs.com/png.latex?Y">만 남기는 과정이 필요합니다.</p>
<p><strong>Step 1: <img src="https://latex.codecogs.com/png.latex?Q%5BX,%20Y%5D">에서 <img src="https://latex.codecogs.com/png.latex?Q%5BY%5D"> 분리하기</strong> Tian’s Lemma에 의해 <img src="https://latex.codecogs.com/png.latex?Q%5BX,%20Y%5D">는 더 분해될 수 없지만, 우리가 원하는 것은 <img src="https://latex.codecogs.com/png.latex?do(x)"> 상황이므로 <img src="https://latex.codecogs.com/png.latex?X">를 조건부화하거나 합으로 제거하는 조작이 필요합니다. 알고리즘적으로는 <img src="https://latex.codecogs.com/png.latex?Q%5BX,%20Y%5D">를 이용해 <img src="https://latex.codecogs.com/png.latex?Q%5BY%5D"> (정확히는 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">의 핵심 파트)를 유도합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AQ%5BY%5D(w_1,%20w_2,%20x)%20=%20%5Cfrac%7BQ%5BX,%20Y%5D%7D%7B%5Csum_%7By%7D%20Q%5BX,%20Y%5D%7D%20%5Ctimes%20(%5Ctext%7Bnormalization?%20No.%7D)%0A"></p>
<p>정확한 유도 과정은 다음과 같습니다. <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">는 그래프에서 <img src="https://latex.codecogs.com/png.latex?X">의 들어오는 엣지를 끊은 것입니다. 이 모델에서 <img src="https://latex.codecogs.com/png.latex?X">의 부모는 <img src="https://latex.codecogs.com/png.latex?W_2">입니다. <img src="https://latex.codecogs.com/png.latex?X">를 <img src="https://latex.codecogs.com/png.latex?x">로 고정했을 때, <img src="https://latex.codecogs.com/png.latex?Y">의 분포는 <img src="https://latex.codecogs.com/png.latex?W_1">과 <img src="https://latex.codecogs.com/png.latex?W_2">의 분포에 의해 가중 평균됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bw_1,%20w_2%7D%20P(y%7Cdo(x),%20w_1,%20w_2)%20P(w_1,%20w_2)%0A"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x),%20w_1,%20w_2)">는 <img src="https://latex.codecogs.com/png.latex?X%20%5Cleftrightarrow%20Y"> 교란이 존재하더라도, <img src="https://latex.codecogs.com/png.latex?W_2">가 <img src="https://latex.codecogs.com/png.latex?X">의 유일한 부모(Instrumental Variable 역할)임을 이용해 식별 가능합니다. 하지만 C-Factor 대수를 쓰면 더 기계적으로 풀립니다.</p>
<p>최종 식별 식은 다음과 같습니다: <img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bw_1%7D%20P(w_1)%20%5Csum_%7Bw_2%7D%20P(y%7Cx,%20w_1,%20w_2)%20P(w_2%7Cw_1)%20%5Cdots%20(%5Ctext%7BCheck%20Derivation%7D)%0A"></p>
<p>강의 자료의 유도 흐름을 따르면: <img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bw_1%7D%20P(w_1)%20%5Csum_%7Bw_2%7D%20P(x%7Cw_1,%20w_2)%20P(y%7Cw_1,%20w_2,%20x)%0A"> <em>(주의: 이 식은 슬라이드의 Napkin 해결 과정에서 <img src="https://latex.codecogs.com/png.latex?Q"> 팩터들의 재조립을 통해 얻어집니다. 핵심은 <img src="https://latex.codecogs.com/png.latex?X">와 <img src="https://latex.codecogs.com/png.latex?Y"> 사이의 교란을 <img src="https://latex.codecogs.com/png.latex?W_2">와 <img src="https://latex.codecogs.com/png.latex?W_1">을 통해 통제한다는 점입니다.)</em></p>
<hr>
</section>
</section>
<section id="a-general-identification-algorithm-id-algorithm" class="level1">
<h1>4. A General Identification Algorithm (ID Algorithm)</h1>
<p>앞선 예제들은 특정 그래프에 대한 해결책일 뿐입니다. Shpitser와 Pearl은 임의의 인과 그래프 <img src="https://latex.codecogs.com/png.latex?G">와 쿼리 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">에 대해 식별 가능성을 판별하고, 가능하다면 식을 도출하는 <strong>완전한(Complete) 알고리즘</strong>을 제안했습니다.</p>
<p>이 알고리즘은 <strong>입력</strong>으로 <img src="https://latex.codecogs.com/png.latex?(y,%20x,%20P,%20G)">를 받고, <strong>출력</strong>으로 식별된 표현식(Expression) 또는 <strong>실패(Fail)</strong> 를 반환합니다.</p>
<section id="the-algorithm-steps" class="level3">
<h3 class="anchored" data-anchor-id="the-algorithm-steps">The Algorithm Steps</h3>
<p>함수 <img src="https://latex.codecogs.com/png.latex?ID(y,%20x,%20P,%20G)">:</p>
<ol type="1">
<li><p><strong>Base Case (Empty x):</strong> 만약 <img src="https://latex.codecogs.com/png.latex?x%20=%20%5Cemptyset">이면, <img src="https://latex.codecogs.com/png.latex?P(y)">를 반환합니다. (개입할 것이 없으므로 관측 분포의 마지널) <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bif%20%7D%20x%20=%20%5Cemptyset%20%5Ctext%7B%20return%20%7D%20%5Csum_%7Bv%20%5Csetminus%20y%7D%20P(v)"></p></li>
<li><p><strong>Ancestral Reduction:</strong> <img src="https://latex.codecogs.com/png.latex?y">의 조상(Ancestor)이 아닌 변수들은 인과 효과에 영향을 주지 않으므로 제거합니다. <img src="https://latex.codecogs.com/png.latex?V'%20=%20An(y)_G%20%5Csetminus%20x"> <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Breturn%20%7D%20ID(y,%20x%20%5Ccap%20V',%20%5Csum_%7Bv%20%5Csetminus%20v'%7D%20P,%20G%5BV'%5D)"></p></li>
<li><p><strong>Forcing Action (W-Graph):</strong> 개입 <img src="https://latex.codecogs.com/png.latex?do(x)">에 의해 <img src="https://latex.codecogs.com/png.latex?x">로 들어오는 엣지가 끊어진 그래프 <img src="https://latex.codecogs.com/png.latex?G_%7B%5Coverline%7Bx%7D%7D">에서, <img src="https://latex.codecogs.com/png.latex?x">가 <img src="https://latex.codecogs.com/png.latex?y">와 연결되지 않는다면(독립적이라면), <img src="https://latex.codecogs.com/png.latex?x">는 <img src="https://latex.codecogs.com/png.latex?y">에 아무런 인과적 영향을 주지 않습니다.</p></li>
<li><p><strong>C-Component Decomposition:</strong> 문제를 더 작은 C-Component 단위로 쪼갭니다. <img src="https://latex.codecogs.com/png.latex?G%5BV%20%5Csetminus%20x%5D">의 C-Component들을 <img src="https://latex.codecogs.com/png.latex?S_1,%20%5Cdots,%20S_k">라고 할 때, 전체 효과는 각 컴포넌트 효과의 조합으로 표현됩니다.</p></li>
<li><p><strong>The Hedge (Fail Condition):</strong> 알고리즘이 실패하는 유일한 조건입니다. 만약 특정 C-Component 구조(C-Forest)가 발견되면, 해당 인과 효과는 <strong>식별 불가능(Unidentifiable)</strong> 함이 증명되어 있습니다. 이를 “Hedge”라고 부릅니다. <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BThrow%20FAIL%20(Non-identifiable)%7D"></p></li>
<li><p><strong>Recursion on C-Components:</strong> 만약 <img src="https://latex.codecogs.com/png.latex?y">가 단일 C-Component <img src="https://latex.codecogs.com/png.latex?S">에 포함되지 않는다면, <img src="https://latex.codecogs.com/png.latex?S">에 포함된 부분만 남기고 나머지는 재귀적으로 처리합니다.</p></li>
<li><p><strong>Subset Recursion:</strong> <img src="https://latex.codecogs.com/png.latex?y">가 단일 C-Component <img src="https://latex.codecogs.com/png.latex?S'">에 속한다면, 분포를 <img src="https://latex.codecogs.com/png.latex?Q%5BS'%5D">로 축소하여 재귀 호출합니다. <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Breturn%20%7D%20ID(y,%20x%20%5Ccap%20S',%20%5Cprod%20Q%5BS_i%5D,%20G%5BS'%5D)"></p></li>
</ol>
</section>
<section id="soundness-and-completeness" class="level3">
<h3 class="anchored" data-anchor-id="soundness-and-completeness">4.2 Soundness and Completeness</h3>
<p>이 알고리즘은 두 가지 중요한 수학적 성질을 가집니다. 1. <strong>Soundness (건전성):</strong> 알고리즘이 식을 반환한다면, 그 식은 항상 올바른 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">를 나타냅니다. 2. <strong>Completeness (완전성):</strong> 만약 이 알고리즘이 “실패(Fail)”를 반환한다면, 해당 인과 효과는 관측 데이터만으로는 <strong>절대로 식별할 수 없음</strong>이 증명되어 있습니다. 즉, 더 좋은 알고리즘은 존재하지 않습니다.</p>
<hr>
</section>
</section>
<section id="summary" class="level1">
<h1>5. Summary</h1>
<p>이번 포스트에서는 C-Factor 이론을 실제 문제 해결에 적용해 보았습니다.</p>
<ol type="1">
<li><strong>Back-door &amp; Front-door:</strong> 복잡한 정리 없이도 <img src="https://latex.codecogs.com/png.latex?P(v)%20=%20%5Cprod%20Q%5BC_i%5D"> 분해를 통해 자연스럽게 유도됨을 확인했습니다.</li>
<li><strong>Napkin Model:</strong> 직관적으로 파악하기 힘든 구조도 <img src="https://latex.codecogs.com/png.latex?Q"> 팩터 연산을 통해 기계적으로 식별할 수 있습니다.</li>
<li><strong>ID Algorithm:</strong> 인과 추론의 “만능 열쇠”입니다. 그래프 구조만 주어지면, 재귀적인 C-Component 분해를 통해 식별 가능성을 판정하고 공식을 도출합니다.</li>
</ol>
<p>이로써 우리는 <strong>Non-parametric Structural Causal Model</strong>에서 인과 효과를 식별하는 가장 일반적이고 강력한 이론적 토대를 마련했습니다. 다음 단계는 이러한 식별식을 바탕으로 실제 데이터에서 추정(Estimation)을 수행하는 것입니다.</p>
<hr>
<section id="누락-방지-검증-checklist" class="level3">
<h3 class="anchored" data-anchor-id="누락-방지-검증-checklist">누락 방지 검증 (Checklist)</h3>
<ul>
<li><strong>[포함]</strong> Back-door 기준의 C-Factor 유도 과정 (<img src="https://latex.codecogs.com/png.latex?Q%5BX%5D,%20Q%5BY%5D,%20Q%5BZ%5D"> 분해)</li>
<li><strong>[포함]</strong> Front-door 기준의 C-Factor 유도 과정 (Step-by-step 설명)</li>
<li><strong>[포함]</strong> Napkin Model의 그래프 구조 설명 및 식별 과정</li>
<li><strong>[포함]</strong> 일반화된 ID 알고리즘의 7단계 프로세스 서술</li>
<li><strong>[포함]</strong> ID 알고리즘의 건전성(Soundness)과 완전성(Completeness) 설명</li>
<li><strong>[포함]</strong> 실패 조건인 “Hedge”에 대한 언급</li>
<li><strong>[포함]</strong> 각 단계별 주요 수식 LaTeX 처리 및 이미지 플레이스홀더</li>
<li><strong>[생략]</strong> 없음 (강의 자료 Part 2의 핵심인 예제 적용과 일반 알고리즘 정의를 모두 포함함)</li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L07/part-02/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[Causal Inference] 07. An Algorithmic Approach to Identification (Part 3)</title>
  <dc:creator>유성현 </dc:creator>
  <link>https://shsha0110.github.io/posts/lecture/L07/part-03/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>이전 포스트들에서는 <strong>C-Factor (<img src="https://latex.codecogs.com/png.latex?Q%5BC%5D">)</strong> 의 개념을 도입하고, Back-door, Front-door, 그리고 Napkin 문제와 같은 구체적인 사례들을 통해 인과 효과를 식별하는 방법을 살펴보았습니다.</p>
<p>하지만 현실의 인과 그래프는 교과서적인 예제보다 훨씬 복잡할 수 있습니다. 수십 개의 변수와 복잡하게 얽힌 교란 요인(Unobserved Confounder)이 존재하는 상황에서, 매번 직관이나 특수한 기법에 의존할 수는 없습니다.</p>
<p>이번 포스트에서는 <strong>Shpitser and Pearl</strong>에 의해 정립된 <strong>일반화된 식별 알고리즘(General Identification Algorithm)</strong>을 다룹니다. 이 알고리즘은 임의의 인과 그래프 <img src="https://latex.codecogs.com/png.latex?G">와 쿼리 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">가 주어졌을 때, 해당 효과가 식별 가능한지(Identifiable) 판별하고, 가능하다면 관측 데이터 <img src="https://latex.codecogs.com/png.latex?P(v)">의 함수로 표현된 식을 도출해냅니다.</p>
<hr>
</section>
<section id="key-concepts-for-the-general-algorithm" class="level1">
<h1>2. Key Concepts for the General Algorithm</h1>
<p>알고리즘을 단계별로 정의하기 전에, 핵심이 되는 두 가지 개념인 <strong>Ancestral Reduction(조상 축소)</strong> 과 <strong>C-Component Decomposition(C-컴포넌트 분해)</strong> 를 다시 정리합니다.</p>
<section id="ancestral-reduction" class="level2">
<h2 class="anchored" data-anchor-id="ancestral-reduction">2.1 Ancestral Reduction</h2>
<p>우리가 관심 있는 결과 변수 <img src="https://latex.codecogs.com/png.latex?Y">에 인과적인 영향을 줄 수 있는 변수들은 <img src="https://latex.codecogs.com/png.latex?Y">의 <strong>조상(Ancestors)</strong> 들뿐입니다. 따라서 전체 그래프 <img src="https://latex.codecogs.com/png.latex?G">에서 <img src="https://latex.codecogs.com/png.latex?Y">의 조상이 아닌 변수들은 인과 효과 계산에서 제거(Marginalize out)해도 무방합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AD%20=%20An(Y)_%7BG_%7B%5Coverline%7BX%7D%7D%7D%0A"></p>
<p>여기서 <img src="https://latex.codecogs.com/png.latex?G_%7B%5Coverline%7BX%7D%7D">는 <img src="https://latex.codecogs.com/png.latex?X">로 들어오는 엣지를 끊은 그래프(Intervention Graph)를 의미하며, <img src="https://latex.codecogs.com/png.latex?An(Y)">는 <img src="https://latex.codecogs.com/png.latex?Y"> 자신을 포함한 <img src="https://latex.codecogs.com/png.latex?Y">의 조상 집합을 의미합니다. 즉, <img src="https://latex.codecogs.com/png.latex?D">는 <strong><img src="https://latex.codecogs.com/png.latex?do(x)"> 상황에서 <img src="https://latex.codecogs.com/png.latex?Y">와 인과적으로 연관된 모든 변수의 집합</strong>입니다.</p>
</section>
<section id="identification-formula-via-c-factors" class="level2">
<h2 class="anchored" data-anchor-id="identification-formula-via-c-factors">2.2 Identification Formula via C-Factors</h2>
<p>C-Factor 이론에 따르면, 개입 후의 분포 <img src="https://latex.codecogs.com/png.latex?P(v%7Cdo(x))">는 <img src="https://latex.codecogs.com/png.latex?X">를 제외한 나머지 변수들의 메커니즘(<img src="https://latex.codecogs.com/png.latex?Q"> 팩터)은 유지되고 <img src="https://latex.codecogs.com/png.latex?X">의 메커니즘만 제거된 상태입니다. 즉, 전체 변수 <img src="https://latex.codecogs.com/png.latex?V">에 대해 다음이 성립합니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(v%20%5Csetminus%20x%20%7C%20do(x))%20=%20Q%5BV%20%5Csetminus%20X%5D%0A"></p>
<p>따라서 우리가 구하고자 하는 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">는 <img src="https://latex.codecogs.com/png.latex?Q%5BV%20%5Csetminus%20X%5D">에서 <img src="https://latex.codecogs.com/png.latex?Y">를 제외한 나머지 변수들을 합(Summation)으로 제거하여 구할 수 있습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bv%20%5Csetminus%20(x%20%5Ccup%20y)%7D%20Q%5BV%20%5Csetminus%20X%5D%0A"></p>
<p>여기서 앞서 정의한 Ancestral Reduction을 적용하면, 합을 구해야 하는 범위가 전체 <img src="https://latex.codecogs.com/png.latex?V">에서 <img src="https://latex.codecogs.com/png.latex?D">(관심 있는 조상 집합)로 축소됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bd%20%5Csetminus%20y%7D%20Q%5BD%5D%0A"></p>
<hr>
</section>
</section>
<section id="the-general-identification-algorithm" class="level1">
<h1>3. The General Identification Algorithm</h1>
<p>이제 본격적으로 일반화된 식별 알고리즘의 프로세스를 도식화해보겠습니다. 이 알고리즘은 <strong>입력</strong>으로 그래프 <img src="https://latex.codecogs.com/png.latex?G">와 쿼리 <img src="https://latex.codecogs.com/png.latex?Y,%20X">를 받으며, <strong>출력</strong>으로 식별된 확률 수식(Estimand)을 반환합니다.</p>
<section id="step-1-ancestral-reduction-변수-범위-축소" class="level2">
<h2 class="anchored" data-anchor-id="step-1-ancestral-reduction-변수-범위-축소">Step 1: Ancestral Reduction (변수 범위 축소)</h2>
<p>가장 먼저, 분석 대상을 <img src="https://latex.codecogs.com/png.latex?Y">의 조상 집합 <img src="https://latex.codecogs.com/png.latex?D">로 제한합니다. <img src="https://latex.codecogs.com/png.latex?%0AD%20=%20An(Y)_%7BG_%7B%5Coverline%7BX%7D%7D%7D%0A"> 이 단계는 불필요한 변수를 제거하여 계산 복잡도를 줄이고 문제의 본질에 집중하게 합니다.</p>
</section>
<section id="step-2-c-component-decomposition-그래프-분해" class="level2">
<h2 class="anchored" data-anchor-id="step-2-c-component-decomposition-그래프-분해">Step 2: C-Component Decomposition (그래프 분해)</h2>
<p>축소된 변수 집합 <img src="https://latex.codecogs.com/png.latex?D">로 구성된 서브그래프 <img src="https://latex.codecogs.com/png.latex?G%5BD%5D">를 고려합니다. 이 그래프 내에서 양방향 엣지(Bidirected edges, <img src="https://latex.codecogs.com/png.latex?%5Cleftrightarrow">)로 연결된 요소들을 찾아 <strong>C-Component</strong>들로 분해합니다. 만약 <img src="https://latex.codecogs.com/png.latex?G%5BD%5D">가 <img src="https://latex.codecogs.com/png.latex?k">개의 C-Component <img src="https://latex.codecogs.com/png.latex?D_1,%20D_2,%20%5Cdots,%20D_k">로 나뉜다면, 전체 <img src="https://latex.codecogs.com/png.latex?Q"> 팩터는 각 컴포넌트의 <img src="https://latex.codecogs.com/png.latex?Q"> 팩터의 곱으로 표현됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AQ%5BD%5D%20=%20%5Cprod_%7Bi=1%7D%5E%7Bk%7D%20Q%5BD_i%5D%0A"></p>
<p>이 성질은 Tian’s Factorization Lemma에 기반합니다.</p>
</section>
<section id="step-3-compute-target-quantity-최종-식별" class="level2">
<h2 class="anchored" data-anchor-id="step-3-compute-target-quantity-최종-식별">Step 3: Compute Target Quantity (최종 식별)</h2>
<p>위의 두 단계를 결합하면, 최종적인 인과 효과 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))">는 각 C-Component (<img src="https://latex.codecogs.com/png.latex?D_i">)에 해당하는 <img src="https://latex.codecogs.com/png.latex?Q%5BD_i%5D">들의 곱을 <img src="https://latex.codecogs.com/png.latex?Y">를 제외한 나머지 변수들(<img src="https://latex.codecogs.com/png.latex?D%20%5Csetminus%20Y">)에 대해 합(Sum)한 것과 같습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bd%20%5Csetminus%20y%7D%20%5Cprod_%7Bi=1%7D%5E%7Bk%7D%20Q%5BD_i%5D%0A"></p>
<p>여기서 각 <img src="https://latex.codecogs.com/png.latex?Q%5BD_i%5D">는 관측 데이터 <img src="https://latex.codecogs.com/png.latex?P(v)">로부터 계산 가능(Computable)합니다. (Part 1에서 다룬 위상 정렬을 이용한 계산법 적용)</p>
<hr>
</section>
</section>
<section id="detailed-example-breakdown" class="level1">
<h1>4. Detailed Example Breakdown</h1>
<p>강의 자료에 제시된 복잡한 그래프 예시(변수 <img src="https://latex.codecogs.com/png.latex?A,%20X,%20C,%20Y"> 등이 포함된 구조)를 통해 알고리즘을 실제로 적용해 보겠습니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://shsha0110.github.io/posts/lecture/L07/part-03/images/example_graph_axcy.png" class="img-fluid figure-img"></p>
<figcaption>Figure: General ID Algorithm Example Graph. 변수 A, X, C, Y 등이 복잡한 인과 경로와 양방향 엣지(교란)로 연결된 구조를 보여줌.</figcaption>
</figure>
</div>
<p><strong>Scenario:</strong> * <strong>Query:</strong> <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))"> * <strong>Graph Structure (Example):</strong> <img src="https://latex.codecogs.com/png.latex?A%20%5Crightarrow%20X%20%5Crightarrow%20C%20%5Crightarrow%20Y">, 그리고 <img src="https://latex.codecogs.com/png.latex?X%20%5Cleftrightarrow%20Y"> (via confounder), <img src="https://latex.codecogs.com/png.latex?A%20%5Cleftrightarrow%20C"> (via confounder) 등의 복잡한 구조 가정.</p>
<section id="step-1-ancestral-reduction" class="level3">
<h3 class="anchored" data-anchor-id="step-1-ancestral-reduction">Step 1: Ancestral Reduction</h3>
<p><img src="https://latex.codecogs.com/png.latex?Y">에 영향을 주지 않는 변수들을 제거합니다. <img src="https://latex.codecogs.com/png.latex?%0AD%20=%20An(Y)_%7BG_%7B%5Coverline%7BX%7D%7D%7D%0A"> 예를 들어, <img src="https://latex.codecogs.com/png.latex?Y">의 후손(Descendant)인 <img src="https://latex.codecogs.com/png.latex?E">가 있다면 <img src="https://latex.codecogs.com/png.latex?E">는 제거됩니다. 분석 대상은 <img src="https://latex.codecogs.com/png.latex?A,%20X,%20C,%20Y"> 등으로 축소됩니다.</p>
</section>
<section id="step-2-c-component-decomposition" class="level3">
<h3 class="anchored" data-anchor-id="step-2-c-component-decomposition">Step 2: C-Component Decomposition</h3>
<p>남은 변수 집합 <img src="https://latex.codecogs.com/png.latex?D">에서 C-Component를 찾습니다. 가령, 교란 구조에 의해 다음과 같이 두 개의 컴포넌트로 나뉜다고 가정해 봅시다. * <img src="https://latex.codecogs.com/png.latex?D_1%20=%20%5C%7BC,%20Y%5C%7D"> (만약 <img src="https://latex.codecogs.com/png.latex?C%20%5Cleftrightarrow%20Y">가 있다면) * <img src="https://latex.codecogs.com/png.latex?D_2%20=%20%5C%7BA,%20X%5C%7D"> (만약 <img src="https://latex.codecogs.com/png.latex?A%20%5Cleftrightarrow%20X">가 있다면) <em>(주의: 실제 강의 슬라이드의 예제 구조에 따라 컴포넌트 구성은 달라집니다. 여기서는 슬라이드의 <img src="https://latex.codecogs.com/png.latex?Q%5BC,%20Y%5D"> 예시를 따릅니다.)</em></p>
<p>슬라이드 예시에서는 최종적으로 다음과 같은 형태의 분해를 유도합니다: <img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cdo(x))%20=%20%5Csum_%7Bc%7D%20Q%5B%5C%7BC,%20Y%5C%7D%5D%20%5Ctimes%20(%5Ctext%7BOther%20Factors%7D)%0A"></p>
</section>
<section id="step-3-calculation-of-factors" class="level3">
<h3 class="anchored" data-anchor-id="step-3-calculation-of-factors">Step 3: Calculation of Factors</h3>
<p>각 팩터는 관측 데이터의 조건부 확률로 변환됩니다. * “미래는 과거에 영향을 줄 수 없다”는 원칙과 <img src="https://latex.codecogs.com/png.latex?do">-calculus의 Rule 3(개입의 삭제)에 의해, 특정 조건하에서 <img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))%20=%20P(y%7Cx)">가 되거나 특정 변수가 독립이 됩니다. * 예를 들어, <img src="https://latex.codecogs.com/png.latex?Q%5B%5C%7BC,%20Y%5C%7D%5D">는 <img src="https://latex.codecogs.com/png.latex?P(c,%20y%20%7C%20do(x,%20a))">와 같은 형태에서 유도될 수 있으며, 이는 최종적으로 <img src="https://latex.codecogs.com/png.latex?%5Csum_c%20P(y%7Cc,%20x,%20a)P(c%7Ca,%20x)"> 와 같은 식별 식(Adjustment Formula)으로 귀결됩니다.</p>
<hr>
</section>
</section>
<section id="completeness-and-interpretations" class="level1">
<h1>5. Completeness and Interpretations</h1>
<p>이 알고리즘의 가장 중요한 의의는 <strong>완전성(Completeness)</strong> 에 있습니다.</p>
<section id="what-does-completeness-mean" class="level3">
<h3 class="anchored" data-anchor-id="what-does-completeness-mean">5.1 What does Completeness mean?</h3>
<ol type="1">
<li><strong>If the algorithm succeeds:</strong> 도출된 식은 올바른 인과 효과를 나타냅니다 (<strong>Soundness</strong>).</li>
<li><strong>If the algorithm fails:</strong> 해당 그래프 구조에서는 관측 데이터만으로 인과 효과를 식별하는 것이 <strong>수학적으로 불가능</strong>합니다. 즉, “더 똑똑한 알고리즘”을 기다릴 필요 없이, 데이터를 더 수집하거나 가정을 추가해야 함을 의미합니다.</li>
</ol>
</section>
<section id="failure-condition-the-hedge" class="level3">
<h3 class="anchored" data-anchor-id="failure-condition-the-hedge">5.2 Failure Condition: The Hedge</h3>
<p>알고리즘이 실패하는 특정 그래프 패턴을 <strong>Hedge</strong> 또는 <strong>C-Forest</strong>라고 부릅니다. 이 구조가 발견되면 알고리즘은 “Fail”을 반환하며, 이는 식별 불가능함을 증명하는 것과 같습니다.</p>
</section>
<section id="practical-implication" class="level3">
<h3 class="anchored" data-anchor-id="practical-implication">5.3 Practical Implication</h3>
<p>이 알고리즘은 우리가 Back-door나 Front-door 같은 개별적인 “족보”를 외울 필요를 없애줍니다. 그래프만 그릴 수 있다면, 이 알고리즘을 통해 식별 가능 여부와 추정 식을 자동으로 얻을 수 있기 때문입니다. 이는 현대 Causal Inference 라이브러리(예: <code>DoWhy</code>, <code>Ananke</code>)의 엔진이 되는 핵심 이론입니다.</p>
<hr>
</section>
</section>
<section id="summary" class="level1">
<h1>6. Summary</h1>
<p>총 3부에 걸친 “Algorithmic Identification” 시리즈를 통해 우리는 다음을 배웠습니다.</p>
<ol type="1">
<li><strong>Decomposition (Part 1):</strong> 관측 분포 <img src="https://latex.codecogs.com/png.latex?P(v)">는 인과 그래프의 구조에 따라 <img src="https://latex.codecogs.com/png.latex?Q%5BC%5D"> 팩터들의 곱으로 분해됩니다.</li>
<li><strong>Specific Examples (Part 2):</strong> Back-door, Front-door, Napkin 문제 등은 모두 <img src="https://latex.codecogs.com/png.latex?Q"> 팩터의 조작을 통해 해결됩니다.</li>
<li><strong>General Algorithm (Part 3):</strong> Ancestral Reduction과 C-Component Decomposition을 결합하면, 임의의 모델에 대한 인과 효과 식별 문제를 기계적으로 해결할 수 있습니다.</li>
</ol>
<p>이로써 <strong>Non-parametric Identification</strong>의 여정은 마무리됩니다. 다음 단계는 이렇게 식별된 식(Estimand)을 바탕으로, 실제 데이터에서 통계적으로 효율적인 <strong>추정(Estimation)</strong> 을 수행하는 것입니다.</p>
<hr>
<section id="누락-방지-검증-checklist" class="level3">
<h3 class="anchored" data-anchor-id="누락-방지-검증-checklist">누락 방지 검증 (Checklist)</h3>
<ul>
<li><strong>[포함]</strong> 일반화된 식별 알고리즘의 입력(<img src="https://latex.codecogs.com/png.latex?G,%20Q">)과 출력(Estimand) 정의</li>
<li><strong>[포함]</strong> Ancestral Reduction (<img src="https://latex.codecogs.com/png.latex?D%20=%20An(Y)_%7BG_%7B%5Coverline%7BX%7D%7D%7D">)의 개념 및 필요성 설명</li>
<li><strong>[포함]</strong> C-Component 분해를 통한 식별 공식 (<img src="https://latex.codecogs.com/png.latex?P(y%7Cdo(x))%20=%20%5Csum%20Q%5BD_i%5D">) 유도</li>
<li><strong>[포함]</strong> <img src="https://latex.codecogs.com/png.latex?Q%5BV%20%5Csetminus%20X%5D">와 Marginalization의 관계 설명</li>
<li><strong>[포함]</strong> 구체적 예제 그래프(AXCYE 등)를 통한 알고리즘 적용 과정 서술</li>
<li><strong>[포함]</strong> “미래는 과거에 영향을 못 준다”는 인과적 시간 순서 개념 언급</li>
<li><strong>[포함]</strong> 알고리즘의 완전성(Completeness)과 실패 조건(Hedge)의 의미 해석</li>
<li><strong>[생략]</strong> 없음 (강의 자료 Part 3의 핵심인 일반 알고리즘과 예제를 모두 포함함)</li>
</ul>



</section>
</section>

 ]]></description>
  <category>Causal Inference</category>
  <guid>https://shsha0110.github.io/posts/lecture/L07/part-03/</guid>
  <pubDate>Thu, 22 Jan 2026 15:00:00 GMT</pubDate>
</item>
</channel>
</rss>
