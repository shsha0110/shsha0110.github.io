<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="유성현">
<meta name="dcterms.date" content="2026-02-06">
<meta name="description" content="NeurIPS 2018: Time-dependent confounding 해결을 위한 Deep Learning 기반의 RMSN 모델 소개">

<title>[Paper Review] Forecasting Treatment Responses Over Time Using Recurrent Marginal Structural Networks – shsha0110.github.io</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-5b4ad623e5705c0698d39aec6f10cf02.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<meta name="google-site-verification" content="wnUhrJyUH9DivslRuyTASn9K6KXZlRrojFuwYY1q2hI">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">shsha0110.github.io</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">[Paper Review] Forecasting Treatment Responses Over Time Using Recurrent Marginal Structural Networks</h1>
                  <div>
        <div class="description">
          NeurIPS 2018: Time-dependent confounding 해결을 위한 Deep Learning 기반의 RMSN 모델 소개
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Paper Review</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>유성현 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 6, 2026</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">1. Introduction</a>
  <ul class="collapse">
  <li><a href="#연구의-배경과-필요성" id="toc-연구의-배경과-필요성" class="nav-link" data-scroll-target="#연구의-배경과-필요성">연구의 배경과 필요성</a></li>
  <li><a href="#핵심-문제-시간-의존적-교란-time-dependent-confounding" id="toc-핵심-문제-시간-의존적-교란-time-dependent-confounding" class="nav-link" data-scroll-target="#핵심-문제-시간-의존적-교란-time-dependent-confounding">1.1 핵심 문제: 시간 의존적 교란 (Time-dependent Confounding)</a>
  <ul class="collapse">
  <li><a href="#기존-방법론의-한계" id="toc-기존-방법론의-한계" class="nav-link" data-scroll-target="#기존-방법론의-한계">기존 방법론의 한계</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#기존-해결책과-한계-marginal-structural-models-msms" id="toc-기존-해결책과-한계-marginal-structural-models-msms" class="nav-link" data-scroll-target="#기존-해결책과-한계-marginal-structural-models-msms">2. 기존 해결책과 한계: Marginal Structural Models (MSMs)</a>
  <ul class="collapse">
  <li><a href="#역확률-가중치-iptw" id="toc-역확률-가중치-iptw" class="nav-link" data-scroll-target="#역확률-가중치-iptw">2.1 역확률 가중치 (IPTW)</a></li>
  <li><a href="#한계점-limitations" id="toc-한계점-limitations" class="nav-link" data-scroll-target="#한계점-limitations">2.2 한계점 (Limitations)</a></li>
  </ul></li>
  <li><a href="#제안-모델-recurrent-marginal-structural-networks-r-msn" id="toc-제안-모델-recurrent-marginal-structural-networks-r-msn" class="nav-link" data-scroll-target="#제안-모델-recurrent-marginal-structural-networks-r-msn">3. 제안 모델: Recurrent Marginal Structural Networks (R-MSN)</a>
  <ul class="collapse">
  <li><a href="#주요-기여점-key-contributions" id="toc-주요-기여점-key-contributions" class="nav-link" data-scroll-target="#주요-기여점-key-contributions">3.1 주요 기여점 (Key Contributions)</a>
  <ul class="collapse">
  <li><a href="#a.-sequence-to-sequence-구조를-통한-다중-시점-예측" id="toc-a.-sequence-to-sequence-구조를-통한-다중-시점-예측" class="nav-link" data-scroll-target="#a.-sequence-to-sequence-구조를-통한-다중-시점-예측">A. Sequence-to-Sequence 구조를 통한 다중 시점 예측</a></li>
  <li><a href="#b.-복잡한-치료-시나리오-분석-scenario-analysis" id="toc-b.-복잡한-치료-시나리오-분석-scenario-analysis" class="nav-link" data-scroll-target="#b.-복잡한-치료-시나리오-분석-scenario-analysis">B. 복잡한 치료 시나리오 분석 (Scenario Analysis)</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">4. Summary</a></li>
  <li><a href="#related-works" id="toc-related-works" class="nav-link" data-scroll-target="#related-works">2. Related Works</a>
  <ul class="collapse">
  <li><a href="#prologue-왜-이-논문을-읽는가" id="toc-prologue-왜-이-논문을-읽는가" class="nav-link" data-scroll-target="#prologue-왜-이-논문을-읽는가">0. Prologue: 왜 이 논문을 읽는가?</a></li>
  <li><a href="#전통적-접근-g-computation과-구조적-모델-epidemiology" id="toc-전통적-접근-g-computation과-구조적-모델-epidemiology" class="nav-link" data-scroll-target="#전통적-접근-g-computation과-구조적-모델-epidemiology">1. 전통적 접근: G-computation과 구조적 모델 (Epidemiology)</a>
  <ul class="collapse">
  <li><a href="#주요-방법론의-분류" id="toc-주요-방법론의-분류" class="nav-link" data-scroll-target="#주요-방법론의-분류">1.1 주요 방법론의 분류</a></li>
  <li><a href="#한계점-선형성linearity의-덫" id="toc-한계점-선형성linearity의-덫" class="nav-link" data-scroll-target="#한계점-선형성linearity의-덫">1.2 한계점: “선형성(Linearity)”의 덫</a></li>
  </ul></li>
  <li><a href="#베이지안-비모수-모델-bayesian-nonparametric-models" id="toc-베이지안-비모수-모델-bayesian-nonparametric-models" class="nav-link" data-scroll-target="#베이지안-비모수-모델-bayesian-nonparametric-models">2. 베이지안 비모수 모델 (Bayesian Nonparametric Models)</a>
  <ul class="collapse">
  <li><a href="#접근-방식" id="toc-접근-방식" class="nav-link" data-scroll-target="#접근-방식">2.1 접근 방식</a></li>
  <li><a href="#한계점-가정의-제약과-계산-복잡도" id="toc-한계점-가정의-제약과-계산-복잡도" class="nav-link" data-scroll-target="#한계점-가정의-제약과-계산-복잡도">2.2 한계점: 가정의 제약과 계산 복잡도</a></li>
  </ul></li>
  <li><a href="#딥러닝-기반-인과추론-deep-learning-for-causal-inference" id="toc-딥러닝-기반-인과추론-deep-learning-for-causal-inference" class="nav-link" data-scroll-target="#딥러닝-기반-인과추론-deep-learning-for-causal-inference">3. 딥러닝 기반 인과추론 (Deep Learning for Causal Inference)</a>
  <ul class="collapse">
  <li><a href="#기존-딥러닝-연구의-한계" id="toc-기존-딥러닝-연구의-한계" class="nav-link" data-scroll-target="#기존-딥러닝-연구의-한계">3.1 기존 딥러닝 연구의 한계</a></li>
  <li><a href="#rnn의-등장-필요성" id="toc-rnn의-등장-필요성" class="nav-link" data-scroll-target="#rnn의-등장-필요성">3.2 RNN의 등장 필요성</a></li>
  </ul></li>
  <li><a href="#요약-시나리오-분석을-위한-새로운-프레임워크" id="toc-요약-시나리오-분석을-위한-새로운-프레임워크" class="nav-link" data-scroll-target="#요약-시나리오-분석을-위한-새로운-프레임워크">4. 요약: 시나리오 분석을 위한 새로운 프레임워크</a>
  <ul class="collapse">
  <li><a href="#방법론-비교-요약" id="toc-방법론-비교-요약" class="nav-link" data-scroll-target="#방법론-비교-요약">방법론 비교 요약</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#problem-definition" id="toc-problem-definition" class="nav-link" data-scroll-target="#problem-definition">3. Problem Definition</a>
  <ul class="collapse">
  <li><a href="#prologue" id="toc-prologue" class="nav-link" data-scroll-target="#prologue">0. Prologue</a></li>
  <li><a href="#notation-data-structure" id="toc-notation-data-structure" class="nav-link" data-scroll-target="#notation-data-structure">1. Notation &amp; Data Structure</a></li>
  <li><a href="#treatment-responses-over-time-목표-함수" id="toc-treatment-responses-over-time-목표-함수" class="nav-link" data-scroll-target="#treatment-responses-over-time-목표-함수">2. Treatment Responses Over Time (목표 함수)</a>
  <ul class="collapse">
  <li><a href="#the-estimation-target" id="toc-the-estimation-target" class="nav-link" data-scroll-target="#the-estimation-target">The Estimation Target</a></li>
  </ul></li>
  <li><a href="#inverse-probability-of-treatment-weighting-iptw" id="toc-inverse-probability-of-treatment-weighting-iptw" class="nav-link" data-scroll-target="#inverse-probability-of-treatment-weighting-iptw">3. Inverse Probability of Treatment Weighting (IPTW)</a>
  <ul class="collapse">
  <li><a href="#stabilized-weights-안정화-가중치" id="toc-stabilized-weights-안정화-가중치" class="nav-link" data-scroll-target="#stabilized-weights-안정화-가중치">3.1. Stabilized Weights (안정화 가중치)</a></li>
  <li><a href="#adjusting-for-censoring-중도-절단-보정" id="toc-adjusting-for-censoring-중도-절단-보정" class="nav-link" data-scroll-target="#adjusting-for-censoring-중도-절단-보정">3.2. Adjusting for Censoring (중도 절단 보정)</a></li>
  </ul></li>
  <li><a href="#implementation-loss-function" id="toc-implementation-loss-function" class="nav-link" data-scroll-target="#implementation-loss-function">4. Implementation &amp; Loss Function</a>
  <ul class="collapse">
  <li><a href="#weight-truncation-normalization" id="toc-weight-truncation-normalization" class="nav-link" data-scroll-target="#weight-truncation-normalization">4.1. Weight Truncation &amp; Normalization</a></li>
  <li><a href="#weighted-loss-function" id="toc-weighted-loss-function" class="nav-link" data-scroll-target="#weighted-loss-function">4.2. Weighted Loss Function</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#recurrent-marginal-structural-networks" id="toc-recurrent-marginal-structural-networks" class="nav-link" data-scroll-target="#recurrent-marginal-structural-networks">4. Recurrent Marginal Structural Networks</a>
  <ul class="collapse">
  <li><a href="#propensity-networks" id="toc-propensity-networks" class="nav-link" data-scroll-target="#propensity-networks">4.1. Propensity Networks</a></li>
  </ul></li>
  <li><a href="#introduction-r-msn-framework" id="toc-introduction-r-msn-framework" class="nav-link" data-scroll-target="#introduction-r-msn-framework">1. Introduction: R-MSN Framework</a></li>
  <li><a href="#propensity-networks의-필요성과-구조" id="toc-propensity-networks의-필요성과-구조" class="nav-link" data-scroll-target="#propensity-networks의-필요성과-구조">2. Propensity Networks의 필요성과 구조</a>
  <ul class="collapse">
  <li><a href="#왜-rnnlstm인가" id="toc-왜-rnnlstm인가" class="nav-link" data-scroll-target="#왜-rnnlstm인가">2.1. 왜 RNN(LSTM)인가?</a></li>
  <li><a href="#가지-핵심-확률-함수-4-key-probability-functions" id="toc-가지-핵심-확률-함수-4-key-probability-functions" class="nav-link" data-scroll-target="#가지-핵심-확률-함수-4-key-probability-functions">2.2. 4가지 핵심 확률 함수 (4 Key Probability Functions)</a></li>
  </ul></li>
  <li><a href="#모델링-상세-modeling-details" id="toc-모델링-상세-modeling-details" class="nav-link" data-scroll-target="#모델링-상세-modeling-details">3. 모델링 상세 (Modeling Details)</a>
  <ul class="collapse">
  <li><a href="#multi-target-lstm과-상관관계-반영" id="toc-multi-target-lstm과-상관관계-반영" class="nav-link" data-scroll-target="#multi-target-lstm과-상관관계-반영">3.1. Multi-target LSTM과 상관관계 반영</a></li>
  <li><a href="#출력층-설계와-유연성-flexibility" id="toc-출력층-설계와-유연성-flexibility" class="nav-link" data-scroll-target="#출력층-설계와-유연성-flexibility">3.2. 출력층 설계와 유연성 (Flexibility)</a>
  <ul class="collapse">
  <li><a href="#discrete-treatment-이산형-치료-변수" id="toc-discrete-treatment-이산형-치료-변수" class="nav-link" data-scroll-target="#discrete-treatment-이산형-치료-변수">Discrete Treatment (이산형 치료 변수)</a></li>
  <li><a href="#continuous-treatment-연속형-치료-변수" id="toc-continuous-treatment-연속형-치료-변수" class="nav-link" data-scroll-target="#continuous-treatment-연속형-치료-변수">Continuous Treatment (연속형 치료 변수)</a></li>
  </ul></li>
  <li><a href="#prediction-network" id="toc-prediction-network" class="nav-link" data-scroll-target="#prediction-network">4.2. Prediction Network</a></li>
  </ul></li>
  <li><a href="#introduction-1" id="toc-introduction-1" class="nav-link" data-scroll-target="#introduction-1">1. Introduction</a></li>
  <li><a href="#core-concepts-motivation" id="toc-core-concepts-motivation" class="nav-link" data-scroll-target="#core-concepts-motivation">2. Core Concepts &amp; Motivation</a>
  <ul class="collapse">
  <li><a href="#the-challenge-of-multi-step-prediction" id="toc-the-challenge-of-multi-step-prediction" class="nav-link" data-scroll-target="#the-challenge-of-multi-step-prediction">2.1 The Challenge of Multi-step Prediction</a></li>
  <li><a href="#proposed-solution-action-only-decoder" id="toc-proposed-solution-action-only-decoder" class="nav-link" data-scroll-target="#proposed-solution-action-only-decoder">2.2 Proposed Solution: Action-Only Decoder</a></li>
  </ul></li>
  <li><a href="#model-architecture" id="toc-model-architecture" class="nav-link" data-scroll-target="#model-architecture">3. Model Architecture</a></li>
  <li><a href="#mathematical-formulation-derivations" id="toc-mathematical-formulation-derivations" class="nav-link" data-scroll-target="#mathematical-formulation-derivations">4. Mathematical Formulation &amp; Derivations</a>
  <ul class="collapse">
  <li><a href="#encoder-learning-representations" id="toc-encoder-learning-representations" class="nav-link" data-scroll-target="#encoder-learning-representations">4.1 Encoder: Learning Representations</a></li>
  <li><a href="#memory-adapter" id="toc-memory-adapter" class="nav-link" data-scroll-target="#memory-adapter">4.2 Memory Adapter</a></li>
  <li><a href="#decoder-action-driven-forecasting" id="toc-decoder-action-driven-forecasting" class="nav-link" data-scroll-target="#decoder-action-driven-forecasting">4.3 Decoder: Action-Driven Forecasting</a></li>
  <li><a href="#activation-functions" id="toc-activation-functions" class="nav-link" data-scroll-target="#activation-functions">4.4 Activation Functions</a></li>
  <li><a href="#training-procedure" id="toc-training-procedure" class="nav-link" data-scroll-target="#training-procedure">4.3. Training Procedure</a></li>
  </ul></li>
  <li><a href="#introduction-2" id="toc-introduction-2" class="nav-link" data-scroll-target="#introduction-2">1. Introduction</a></li>
  <li><a href="#step-by-step-training-procedure" id="toc-step-by-step-training-procedure" class="nav-link" data-scroll-target="#step-by-step-training-procedure">2. Step-by-Step Training Procedure</a>
  <ul class="collapse">
  <li><a href="#step-1-propensity-network-training-bias-removal" id="toc-step-1-propensity-network-training-bias-removal" class="nav-link" data-scroll-target="#step-1-propensity-network-training-bias-removal">Step 1: Propensity Network Training (Bias Removal)</a>
  <ul class="collapse">
  <li><a href="#motivation" id="toc-motivation" class="nav-link" data-scroll-target="#motivation">Motivation</a></li>
  <li><a href="#mechanism" id="toc-mechanism" class="nav-link" data-scroll-target="#mechanism">Mechanism</a></li>
  </ul></li>
  <li><a href="#step-2-encoder-training-representation-learning" id="toc-step-2-encoder-training-representation-learning" class="nav-link" data-scroll-target="#step-2-encoder-training-representation-learning">Step 2: Encoder Training (Representation Learning)</a>
  <ul class="collapse">
  <li><a href="#motivation-1" id="toc-motivation-1" class="nav-link" data-scroll-target="#motivation-1">Motivation</a></li>
  <li><a href="#mechanism-1" id="toc-mechanism-1" class="nav-link" data-scroll-target="#mechanism-1">Mechanism</a></li>
  </ul></li>
  <li><a href="#step-3-decoder-training-counterfactual-prediction" id="toc-step-3-decoder-training-counterfactual-prediction" class="nav-link" data-scroll-target="#step-3-decoder-training-counterfactual-prediction">Step 3: Decoder Training (Counterfactual Prediction)</a>
  <ul class="collapse">
  <li><a href="#motivation-2" id="toc-motivation-2" class="nav-link" data-scroll-target="#motivation-2">Motivation</a></li>
  <li><a href="#mechanism-2" id="toc-mechanism-2" class="nav-link" data-scroll-target="#mechanism-2">Mechanism</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#mathematical-formulation-of-loss-functions" id="toc-mathematical-formulation-of-loss-functions" class="nav-link" data-scroll-target="#mathematical-formulation-of-loss-functions">3. Mathematical Formulation of Loss Functions</a>
  <ul class="collapse">
  <li><a href="#notation-definition" id="toc-notation-definition" class="nav-link" data-scroll-target="#notation-definition">Notation Definition</a></li>
  <li><a href="#detailed-derivation-of-error-function-ei-t-tau" id="toc-detailed-derivation-of-error-function-ei-t-tau" class="nav-link" data-scroll-target="#detailed-derivation-of-error-function-ei-t-tau">Detailed Derivation of Error Function <span class="math inline">\(e(i, t, \tau)\)</span></a></li>
  <li><a href="#interpretation" id="toc-interpretation" class="nav-link" data-scroll-target="#interpretation">Interpretation</a></li>
  </ul></li>
  <li><a href="#experiments-with-cancer-growth-simulation-model" id="toc-experiments-with-cancer-growth-simulation-model" class="nav-link" data-scroll-target="#experiments-with-cancer-growth-simulation-model">5. Experiments With Cancer Growth Simulation Model</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">6. Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<section id="연구의-배경과-필요성" class="level2">
<h2 class="anchored" data-anchor-id="연구의-배경과-필요성">연구의 배경과 필요성</h2>
<ul>
<li><p>최근 전자의무기록(Electronic Health Records, EHR)의 보급이 확대되면서, 관측 데이터(Observational Data)를 활용해 환자의 상태 변화에 따른 <strong>동적 치료 반응(Dynamic Treatment Responses)</strong>을 학습하려는 시도가 늘어나고 있습니다. 이러한 데이터는 실제 임상 현장에서 수집된 것으로, 과거 치료 요법(Regimen)의 효과를 비용 효율적으로 분석할 수 있는 중요한 자원입니다.</p></li>
<li><p>그러나 기존 연구들은 대부분 단일 시점(Single point in time)의 개입 효과를 추정하는 데 그쳤습니다. 실제 의료 현장은 훨씬 복잡합니다. 예를 들어:</p>
<ul>
<li><ol type="1">
<li><strong>약물 저항성(Drug Resistance):</strong> 암 환자의 경우 시간이 지남에 따라 치료 효율이 변할 수 있습니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>복합 치료(Joint Prescriptions):</strong> 항암화학요법(Chemotherapy)과 방사선 치료(Radiotherapy)가 서로 다른 시점에 병행되기도 합니다.</li>
</ol></li>
</ul></li>
<li><p>따라서 의사가 최적의 처방 내용뿐만 아니라 <strong>‘언제(Optimal Time)’</strong> 처방할지를 결정하기 위해서는, 시간에 따른 치료 효과를 정확히 추정하는 방법론이 필수적입니다.</p></li>
</ul>
</section>
<section id="핵심-문제-시간-의존적-교란-time-dependent-confounding" class="level2">
<h2 class="anchored" data-anchor-id="핵심-문제-시간-의존적-교란-time-dependent-confounding">1.1 핵심 문제: 시간 의존적 교란 (Time-dependent Confounding)</h2>
<p>관측 데이터에서 인과 효과를 추정할 때 가장 큰 걸림돌은 <strong>시간 의존적 교란(Time-dependent Confounding)</strong>의 존재입니다[cite: 11, 18]. 이는 개입(Treatment)이 환자의 과거 상태(Biomarker)에 따라 결정되고, 그 환자의 상태는 다시 과거의 개입에 의해 영향을 받는 상황을 의미합니다.</p>
<blockquote class="blockquote">
<p><strong>예시: 천식(Asthma) 치료</strong> [cite: 19, 20]</p>
<ul>
<li>천식 응급 약물은 단기적으로 폐 기능을 빠르게 개선합니다.</li>
<li>하지만, 이 약물은 주로 <strong>이미 폐 기능이 저하된 환자</strong>에게 처방됩니다.</li>
<li>단순한(Naive) 비교 방법을 사용하면, 마치 <strong>“약물을 투여하면 폐 기능이 나빠진다”</strong>는 잘못된 결론(Reverse Causality)에 도달할 수 있습니다.</li>
</ul>
</blockquote>
<section id="기존-방법론의-한계" class="level3">
<h3 class="anchored" data-anchor-id="기존-방법론의-한계">기존 방법론의 한계</h3>
<p>일반적인 인과추론 조정 방법(예: 층화(Stratification), 매칭(Matching), 성향 점수(Propensity Scoring))을 시계열 데이터에 그대로 적용할 경우, 오히려 <strong>편향(Bias)을 유발</strong>할 수 있습니다[cite: 23]. 이는 과거의 치료가 미래의 치료 결정에 영향을 미치는 공변량(Covariate)을 변화시키는 경로(Mediator)를 통제해버리기 때문입니다.</p>
<hr>
</section>
</section>
</section>
<section id="기존-해결책과-한계-marginal-structural-models-msms" class="level1">
<h1>2. 기존 해결책과 한계: Marginal Structural Models (MSMs)</h1>
<p>역학(Epidemiology) 분야에서는 이러한 문제를 해결하기 위해 <strong>Marginal Structural Models (MSMs)</strong>을 사용해 왔습니다[cite: 12, 24].</p>
<section id="역확률-가중치-iptw" class="level2">
<h2 class="anchored" data-anchor-id="역확률-가중치-iptw">2.1 역확률 가중치 (IPTW)</h2>
<p>MSM의 핵심 아이디어는 <strong>역확률 치료 가중치(Inverse Probability of Treatment Weighting, IPTW)</strong>를 사용하는 것입니다. <span class="math display">\[
SW_t = \frac{P(A_t \mid H_{t-1})}{P(A_t \mid H_{t-1}, L_{t-1})}
\]</span> (위 식은 논문의 텍스트 설명을 바탕으로 개념적으로 재구성한 식입니다.)</p>
<p>이 방법은 각 시점 <span class="math inline">\(t\)</span>에서의 치료 확률을 추정하여 가중치를 부여함으로써, 관측 데이터를 마치 무작위 임상 시험(Randomized Clinical Trial)과 유사한 <strong>‘유사 모집단(Pseudo-population)’</strong>으로 재구성합니다[cite: 24]. 이를 통해 시간 의존적 교란 요인을 제거하고 편향을 보정합니다.</p>
</section>
<section id="한계점-limitations" class="level2">
<h2 class="anchored" data-anchor-id="한계점-limitations">2.2 한계점 (Limitations)</h2>
<p>하지만 기존 MSM 방식에는 분명한 한계가 존재합니다.</p>
<ol type="1">
<li><strong>가중치 추정의 정확성 의존:</strong> 편향 보정의 효과는 치료 할당 확률(Propensity score)을 얼마나 정확하게 추정하느냐에 달려 있습니다[cite: 25].</li>
<li><strong>모델의 단순성:</strong> 표준 MSM은 <strong>통합 로지스틱 회귀(Pooled Logistic Regression)</strong>를 사용하는데, 이는 치료 결정 확률 분포에 대해 매우 강력하고 단순한 가정(Strong assumptions)을 전제합니다[cite: 26].</li>
<li><strong>장기 예측의 어려움:</strong> 긴 시계열 데이터의 경우, 매 시점마다 별도의 계수를 추정해야 하거나 모델이 지나치게 복잡해지는 문제가 있습니다[cite: 27].</li>
</ol>
<hr>
</section>
</section>
<section id="제안-모델-recurrent-marginal-structural-networks-r-msn" class="level1">
<h1>3. 제안 모델: Recurrent Marginal Structural Networks (R-MSN)</h1>
<p>본 논문에서는 MSM의 프레임워크를 딥러닝에 접목한 <strong>Recurrent Marginal Structural Network (R-MSN)</strong>을 제안합니다[cite: 12, 28].</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/figure1_tumor_forecast.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: 여러 치료 시나리오에 따른 종양 성장 예측. X축은 진단 후 경과 시간, Y축은 종양의 크기를 나타낸다. 그래프는 과거 측정치(History)를 바탕으로 미래(Forecast)를 예측하는 구조를 보여준다. ’Scenario 1(회색)’은 치료받지 않았을 때 종양이 계속 성장함을, ’Scenario 2(붉은 점선)’는 화학요법(Chemotherapy) 후 종양이 일시 감소했다가 다시 증가함을, ’Scenario 3(파란 점선)’은 방사선 치료(Radiotherapy) 후 종양이 급격히 감소하여 소멸됨을 보여준다. 이는 R-MSN이 다양한 치료 계획(언제, 무엇을 투여할지)에 따른 결과를 시뮬레이션할 수 있음을 시각화한 것이다.</figcaption>
</figure>
</div>
<section id="주요-기여점-key-contributions" class="level2">
<h2 class="anchored" data-anchor-id="주요-기여점-key-contributions">3.1 주요 기여점 (Key Contributions)</h2>
<section id="a.-sequence-to-sequence-구조를-통한-다중-시점-예측" class="level3">
<h3 class="anchored" data-anchor-id="a.-sequence-to-sequence-구조를-통한-다중-시점-예측">A. Sequence-to-Sequence 구조를 통한 다중 시점 예측</h3>
<p>자연어 처리(NLP) 분야의 Seq2Seq 아키텍처에서 영감을 받아, 환자의 상태를 두 단계로 처리합니다[cite: 30, 31]. * <strong>Encoder RNN:</strong> 환자의 현재 임상 상태(Clinical State)에 대한 표현(Representation)을 학습합니다. * <strong>Decoder RNN:</strong> Encoder의 마지막 메모리 상태를 초기값으로 받아, 계획된 치료(Planned Treatments)에 따른 미래 반응을 예측합니다. * <strong>유연성:</strong> Decoder의 길이를 조절함으로써 예측 구간(Prediction Horizon)을 자유롭게 변경할 수 있습니다[cite: 32].</p>
</section>
<section id="b.-복잡한-치료-시나리오-분석-scenario-analysis" class="level3">
<h3 class="anchored" data-anchor-id="b.-복잡한-치료-시나리오-분석-scenario-analysis">B. 복잡한 치료 시나리오 분석 (Scenario Analysis)</h3>
<p>실제 임상적 의사결정은 1) 원하는 결과(생존율 등), 2) 치료 종류(이진형/연속형), 3) 치료 기간 등 다양한 변수의 상호작용으로 이루어집니다[cite: 33]. * R-MSN은 다중 입출력(Multi-input/output) RNN을 사용하여 이러한 복잡성을 자연스럽게 모델링합니다[cite: 34]. * 특히, 기존 MSM의 로지스틱 회귀 대신 <strong>LSTM(Long Short-Term Memory)</strong>을 사용하여 성향 점수(Propensity Weighting)를 계산함으로써, 모델 오설정(Misspecification) 위험을 줄이고 시간적 의존성을 더 잘 포착합니다[cite: 36].</p>
<p>결과적으로 R-MSN은 의료진이 특정 환자에게 맞춤화된 치료 계획(Regimen)을 수립하고, 다양한 시나리오(예: 위 Figure 1의 화학요법 vs 방사선치료)에 따른 결과를 미리 시뮬레이션해볼 수 있도록 지원합니다[cite: 37, 38].</p>
<hr>
</section>
</section>
</section>
<section id="summary" class="level1">
<h1>4. Summary</h1>
<p>이번 포스트에서는 <strong>Lim et al.&nbsp;(2018)</strong>의 서론을 통해 시계열 의료 데이터 분석의 난제와 R-MSN의 제안 배경을 살펴보았습니다.</p>
<ul>
<li><strong>문제:</strong> 시계열 데이터에는 <strong>시간 의존적 교란(Time-dependent confounding)</strong>이 존재하여, 단순한 회귀분석이나 고정된 인과추론 기법으로는 편향된 결과를 얻기 쉽습니다.</li>
<li><strong>기존 대안:</strong> 역학의 <strong>MSM(IPTW)</strong> 방식이 존재하지만, 로지스틱 회귀 기반이라 복잡한 비선형 관계나 장기 의존성을 포착하는 데 한계가 있습니다.</li>
<li><strong>해결책:</strong> <strong>R-MSN</strong>은 MSM의 가중치 보정 아이디어를 계승하되, <strong>Seq2Seq 딥러닝 아키텍처</strong>를 도입하여 유연한 다중 시점 예측과 정확한 성향 점수 추정을 가능하게 했습니다.</li>
</ul>
<p>다음 포스트에서는 R-MSN의 구체적인 수식적 정의와 네트워크 구조에 대해 다루겠습니다.</p>
<hr>
</section>
<section id="related-works" class="level1">
<h1>2. Related Works</h1>
<section id="prologue-왜-이-논문을-읽는가" class="level2">
<h2 class="anchored" data-anchor-id="prologue-왜-이-논문을-읽는가">0. Prologue: 왜 이 논문을 읽는가?</h2>
<p>인과추론(Causal Inference)을 연구하다 보면, 특히 의료 데이터나 사회과학 패널 데이터처럼 <strong>시간의 흐름에 따라 치료(Treatment)와 상태(Covariates)가 서로 영향을 주고받는 상황</strong>에서 난관에 부딪히게 됩니다. 이를 <strong>Time-dependent Confounding</strong>이라고 합니다.</p>
<p>이번 포스트에서는 <em>Lim et al.&nbsp;(2018)</em>의 <strong>Recurrent Marginal Structural Networks (R-MSN)</strong> 논문 중 <strong>“Related Works”</strong> 섹션을 심층 분석합니다. 이 섹션은 단순히 관련 연구를 나열하는 것을 넘어, 왜 전통적인 역학(Epidemiology) 방법론과 베이지안(Bayesian) 접근법이 복잡한 시계열 인과추론에서 한계를 가지는지, 그리고 왜 딥러닝(RNN)이 그 대안이 될 수밖에 없는지를 명확히 설명하고 있습니다. [cite: 6, 33, 34]</p>
</section>
<section id="전통적-접근-g-computation과-구조적-모델-epidemiology" class="level2">
<h2 class="anchored" data-anchor-id="전통적-접근-g-computation과-구조적-모델-epidemiology">1. 전통적 접근: G-computation과 구조적 모델 (Epidemiology)</h2>
<p>시간에 따라 변화하는 교란 요인을 통제하기 위한 연구는 역학(Epidemiology) 분야에서 오랫동안 진행되어 왔습니다. 가장 대표적인 연구는 Robins의 선구적인 연구들입니다. [cite: 36]</p>
<section id="주요-방법론의-분류" class="level3">
<h3 class="anchored" data-anchor-id="주요-방법론의-분류">1.1 주요 방법론의 분류</h3>
<p>이 분야의 방법론은 크게 세 가지 그룹으로 나눌 수 있습니다: [cite: 37]</p>
<ol type="1">
<li><strong>G-computation Formula:</strong> 교란 요인들의 분포를 모델링하여 인과 효과를 추정하는 방식.</li>
<li><strong>Structural Nested Mean Models (SNMMs):</strong> 계층적 구조를 가진 평균 모델.</li>
<li><strong>Marginal Structural Models (MSMs):</strong> 역확률 가중치(IPTW) 등을 사용하여 가상의 무작위 대조군(Pseudo-population)을 생성하는 방식.</li>
</ol>
</section>
<section id="한계점-선형성linearity의-덫" class="level3">
<h3 class="anchored" data-anchor-id="한계점-선형성linearity의-덫">1.2 한계점: “선형성(Linearity)”의 덫</h3>
<p>이러한 모델들은 Time-dependent confounding을 보정하기 위한 강력한 이론적 토대를 제공합니다. 하지만 실제 예측 모델을 구축할 때 치명적인 약점이 존재합니다.</p>
<blockquote class="blockquote">
<p><strong>“Their prediction models are typically based on linear or logistic regression.”</strong> [cite: 38]</p>
</blockquote>
<p>대부분의 전통적 모델은 예측을 위해 <strong>선형 회귀(Linear Regression)</strong>나 <strong>로지스틱 회귀(Logistic Regression)</strong>를 기본으로 사용합니다. 만약 환자의 예후(Outcomes)나 치료 정책(Treatment Policy)이 환자의 과거 이력(Covariate History)과 <strong>비선형적이고 복잡한 의존성</strong>을 가진다면, 이러한 선형 모델은 현실을 제대로 반영하지 못하고 <strong>Model Misspecification(모델 설정 오류)</strong> 문제를 일으키게 됩니다. [cite: 39]</p>
</section>
</section>
<section id="베이지안-비모수-모델-bayesian-nonparametric-models" class="level2">
<h2 class="anchored" data-anchor-id="베이지안-비모수-모델-bayesian-nonparametric-models">2. 베이지안 비모수 모델 (Bayesian Nonparametric Models)</h2>
<p>선형 모델의 경직성을 극복하기 위해 제안된 것이 <strong>베이지안 비모수 모델(Bayesian Nonparametric Models)</strong>, 특히 <strong>가우시안 프로세스(Gaussian Processes, GPs)</strong>를 활용한 접근입니다. [cite: 40, 41]</p>
<section id="접근-방식" class="level3">
<h3 class="anchored" data-anchor-id="접근-방식">2.1 접근 방식</h3>
<p>이 방법론은 종단 데이터(Longitudinal Data)에서 잠재적인 결과(Potential Outcomes)를 추정하기 위해 사용됩니다. * <strong>Gaussian Processes (GPs):</strong> 시간에 따른 기저 진행(Baseline Progression)을 모델링합니다. * 미래의 여러 시점에서 치료 효과를 추정할 수 있는 유연성을 제공합니다.</p>
</section>
<section id="한계점-가정의-제약과-계산-복잡도" class="level3">
<h3 class="anchored" data-anchor-id="한계점-가정의-제약과-계산-복잡도">2.2 한계점: 가정의 제약과 계산 복잡도</h3>
<p>하지만 베이지안 접근법 역시 두 가지 큰 장벽이 존재합니다. [cite: 42]</p>
<p><strong>1) 강력한 모델 가정 (Strong Assumptions)</strong> 모델의 보정(Calibration)을 돕기 위해 현실적으로 받아들이기 힘든 가정들을 도입하곤 합니다. * <strong>독립성 가정:</strong> 질병의 자연적 진행(Baseline progression)과 치료에 대한 반응(Treatment response)이 서로 독립적이라고 가정합니다. [cite: 42] * <strong>이질성(Heterogeneity) 무시:</strong> 유전적 정보나 인구통계학적 정보와 같은 Baseline Covariates를 무시하거나, 단순히 선형 결합(Linear components)으로만 처리하여 환자 개개인의 이질적인 치료 효과(Heterogeneous Effects)를 충분히 반영하지 못합니다. [cite: 42]</p>
<p><strong>2) 계산 복잡도 (Computational Complexity)</strong> 베이지안 추론은 데이터가 커질수록 계산량이 기하급수적으로 증가합니다. [cite: 44, 45] * G-computation을 위해 <strong>MCMC (Markov Chain Monte Carlo)</strong> 샘플링을 사용해야 합니다. * Sparse GP를 사용하더라도 최소 <span class="math inline">\(O(NM^2)\)</span>의 복잡도를 가집니다. <span class="math display">\[
    \text{Complexity} \approx O(NM^2)
    \]</span> 여기서 <span class="math inline">\(N\)</span>은 관측치의 수, <span class="math inline">\(M\)</span>은 Inducing points의 수입니다. 이는 대규모 헬스케어 데이터셋에 적용하기에는 확장성(Scalability)이 매우 떨어짐을 의미합니다. [cite: 45]</p>
</section>
</section>
<section id="딥러닝-기반-인과추론-deep-learning-for-causal-inference" class="level2">
<h2 class="anchored" data-anchor-id="딥러닝-기반-인과추론-deep-learning-for-causal-inference">3. 딥러닝 기반 인과추론 (Deep Learning for Causal Inference)</h2>
<p>최근 딥러닝은 인과추론 분야에서도 주목받고 있습니다. 기존 연구들은 주로 다음과 같은 방법들을 사용했습니다: [cite: 49]</p>
<ul>
<li><strong>Instrumental Variable Approaches (도구 변수)</strong> [cite: 49]</li>
<li><strong>Generative Adversarial Networks (GANs)</strong> [cite: 49]</li>
<li><strong>Multi-task Architectures</strong> [cite: 49]</li>
</ul>
<section id="기존-딥러닝-연구의-한계" class="level3">
<h3 class="anchored" data-anchor-id="기존-딥러닝-연구의-한계">3.1 기존 딥러닝 연구의 한계</h3>
<p>하지만 이 논문이 발표될 당시(2018년)까지의 딥러닝 인과추론 연구는 대부분 <strong>“고정된 시점(Fixed time)에서의 단일 개입(Single Intervention)”</strong>에 국한되어 있었습니다. 즉, 시간이 흐름에 따라 변화하는 동적인 치료 효과를 추정하는 데에는 적용되지 못했습니다. [cite: 49, 50]</p>
</section>
<section id="rnn의-등장-필요성" class="level3">
<h3 class="anchored" data-anchor-id="rnn의-등장-필요성">3.2 RNN의 등장 필요성</h3>
<p>이 지점에서 저자들은 <strong>Recurrent Neural Networks (RNNs)</strong>의 도입 필요성을 역설합니다. RNN은 위에서 언급한 한계점들을 다음과 같이 해결할 수 있습니다.</p>
<ol type="1">
<li><strong>Model Specification 불필요:</strong> 데이터로부터 직접 복잡한 비선형 관계를 학습하므로, 선형 모델처럼 명시적인 모델 구조를 미리 정의할 필요가 없습니다. [cite: 43]</li>
<li><strong>확장성(Scalability):</strong> 새로운 관측치가 들어올 때마다 내부 상태(Internal States)를 업데이트하는 방식이므로, 베이지안 모델보다 계산 효율성이 뛰어나고 대용량 데이터 처리에 유리합니다. [cite: 46]</li>
<li><strong>복합 개입 및 다중 목표(Multi-input/Multi-output):</strong> 기존 모델들과 달리, RNN 구조는 여러 종류의 치료(Combined Interventions)와 여러 개의 결과 변수(Multiple Targets)를 동시에 처리하는 데 매우 자연스러운 구조를 가집니다. [cite: 47, 48]</li>
</ol>
</section>
</section>
<section id="요약-시나리오-분석을-위한-새로운-프레임워크" class="level2">
<h2 class="anchored" data-anchor-id="요약-시나리오-분석을-위한-새로운-프레임워크">4. 요약: 시나리오 분석을 위한 새로운 프레임워크</h2>
<p>이 논문은 결론적으로 기존 방법론의 한계를 극복하고, <strong>Time-dependent confounding</strong>이 존재하는 상황에서 복잡한 치료 계획(Treatment Planning)을 시뮬레이션할 수 있는 딥러닝 모델(R-MSN)을 제안합니다.</p>
<p>아래 그림은 이 논문이 풀고자 하는 문제 상황을 시각적으로 보여줍니다. 과거의 데이터(History)를 바탕으로, 미래에 ’화학요법(Chemotherapy)’을 할지, ’방사선 치료(Radiotherapy)’를 할지, 혹은 ’치료하지 않을지(Untreated)’에 따라 종양 크기가 어떻게 변할지 예측하는 것입니다.</p>
<p><img src="./images/figure1_tumor_growth_scenarios.png" class="img-fluid" alt="Figure 1: 다양한 치료 시나리오에 따른 종양 성장 예측. 과거 측정값(Past Measurements)을 바탕으로, 미래 시점(Forecast)에서 화학요법(Scenario 2)이나 방사선 치료(Scenario 3)를 선택했을 때 종양의 크기(Y_t)가 어떻게 변화할지 예측한다. R-MSN은 이러한 동적인 시나리오 분석을 가능하게 한다."> [cite: 16, 32]</p>
<section id="방법론-비교-요약" class="level3">
<h3 class="anchored" data-anchor-id="방법론-비교-요약">방법론 비교 요약</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">구분</th>
<th style="text-align: left;">전통적 방법 (G-formula, MSM)</th>
<th style="text-align: left;">베이지안 비모수 (GPs)</th>
<th style="text-align: left;">제안 모델 (R-MSN)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>기반 모델</strong></td>
<td style="text-align: left;">Linear / Logistic Regression [cite: 38]</td>
<td style="text-align: left;">Gaussian Processes [cite: 41]</td>
<td style="text-align: left;"><strong>RNN (Seq2Seq)</strong> [cite: 6, 8]</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>비선형성</strong></td>
<td style="text-align: left;">낮음 (Misspecification 위험) [cite: 39]</td>
<td style="text-align: left;">높음</td>
<td style="text-align: left;"><strong>높음 (데이터에서 학습)</strong> [cite: 43]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>확장성</strong></td>
<td style="text-align: left;">높음</td>
<td style="text-align: left;">낮음 (<span class="math inline">\(O(NM^2)\)</span>) [cite: 45]</td>
<td style="text-align: left;"><strong>높음 (Online Update)</strong> [cite: 46]</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>주요 한계</strong></td>
<td style="text-align: left;">복잡한 의존성 포착 불가</td>
<td style="text-align: left;">계산 비용, 독립성 가정</td>
<td style="text-align: left;">(학습 데이터 필요량 등)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Time-dependent</strong></td>
<td style="text-align: left;">가능 (이론적 토대)</td>
<td style="text-align: left;">가능</td>
<td style="text-align: left;"><strong>가능 (Deep Learning 최초)</strong> [cite: 50]</td>
</tr>
</tbody>
</table>
<hr>
</section>
</section>
</section>
<section id="problem-definition" class="level1">
<h1>3. Problem Definition</h1>
<section id="prologue" class="level2">
<h2 class="anchored" data-anchor-id="prologue">0. Prologue</h2>
<p>인과추론(Causal Inference), 특히 시계열 데이터(Longitudinal Data)에서의 인과 효과 추정은 매우 까다로운 문제입니다. 환자의 상태(<span class="math inline">\(L\)</span>)에 따라 치료(<span class="math inline">\(A\)</span>)가 결정되고, 그 치료가 다시 미래의 상태(<span class="math inline">\(L\)</span>)에 영향을 미치는 <strong>시간 의존적 교란(Time-dependent confounding)</strong> 구조가 존재하기 때문입니다.</p>
<p>오늘 다룰 논문인 <strong>“Recurrent Marginal Structural Networks (RMSN)”</strong>은 이러한 환경에서 Deep Learning(RNN)을 활용하여 치료 효과를 추정하는 프레임워크를 제안합니다. 이번 포스트에서는 모델의 구체적인 아키텍처로 들어가기 전, 이 논문이 풀고자 하는 <strong>문제의 수학적 정의(Problem Definition)</strong>와 핵심 방법론인 <strong>역확률 가중치(IPTW)</strong>의 수식적 배경을 꼼꼼하게 정리해 봅니다.</p>
</section>
<section id="notation-data-structure" class="level2">
<h2 class="anchored" data-anchor-id="notation-data-structure">1. Notation &amp; Data Structure</h2>
<p>시계열 인과추론 문제를 정의하기 위해 먼저 데이터의 구조를 명확히 해야 합니다. 이 논문에서는 다변량(Multivariate) 결과와 치료를 다루기 위해 벡터 표기법을 사용합니다[cite: 17].</p>
<p>각 환자 <span class="math inline">\(i\)</span>와 시간 <span class="math inline">\(t\)</span>에 대하여 다음과 같이 정의합니다.</p>
<ul>
<li><strong>Outcomes (<span class="math inline">\(Y_{t,i}\)</span>)</strong>: 관측된 결과 변수 벡터입니다. 크기는 <span class="math inline">\(\Omega_y\)</span>로, 여러 개의 결과를 동시에 추적할 수 있습니다. <span class="math display">\[Y_{t,i} = [Y_{t,i}(1), ..., Y_{t,i}(\Omega_y)]\]</span></li>
<li><strong>Treatments (<span class="math inline">\(A_{t,i}\)</span>)</strong>: 실제로 수행된 치료(Action) 벡터입니다. 크기는 <span class="math inline">\(\Omega_a\)</span>입니다. <span class="math display">\[A_{t,i} = [A_{t,i}(1), ..., A_{t,i}(\Omega_a)]\]</span></li>
<li><strong>Time-dependent Covariates (<span class="math inline">\(L_{t,i}\)</span>)</strong>: 시간에 따라 변하는 공변량(예: 혈압, 맥박 등) 벡터입니다. <span class="math display">\[L_{t,i} = [L_{t,i}(1), ..., L_{t,i}(\Omega_l)]\]</span></li>
<li><strong>Static Features (<span class="math inline">\(X_i\)</span>)</strong>: 환자의 고유한, 변하지 않는 특성(예: 유전 정보, 성별)입니다. <span class="math display">\[X_{i} = [X_{i}(1), ..., X_{i}(\Omega_v)]\]</span></li>
</ul>
<p><strong>History (<span class="math inline">\(H_t\)</span>)의 정의</strong> 특정 시점 <span class="math inline">\(t\)</span>에서의 환자의 전체 이력(History)은 과거의 모든 치료 내역과 공변량을 포함합니다[cite: 22]. <span class="math display">\[H_t = (L_t, A_{t-1}, X)\]</span> 여기서 <span class="math inline">\(\bar{L}_t = (L_1, ..., L_t)\)</span>, <span class="math inline">\(\bar{A}_{t-1} = (A_1, ..., A_{t-1})\)</span>는 과거부터 현재까지의 궤적(trajectory)을 나타냅니다.</p>
</section>
<section id="treatment-responses-over-time-목표-함수" class="level2">
<h2 class="anchored" data-anchor-id="treatment-responses-over-time-목표-함수">2. Treatment Responses Over Time (목표 함수)</h2>
<p>우리의 목표는 단순히 다음 시점의 값을 예측하는 것이 아니라, <strong>“만약 특정 치료 계획을 따랐다면 결과가 어떠했을까?”</strong>라는 반사실적(Counterfactual) 질문에 답하는 것입니다.</p>
<p>논문에서는 이를 예측 구간(prediction horizon) <span class="math inline">\(\tau\)</span> 동안의 기대 결과(expected outcome)를 추정하는 함수 <span class="math inline">\(g(\cdot)\)</span>를 학습하는 문제로 정의합니다[cite: 19].</p>
<section id="the-estimation-target" class="level3">
<h3 class="anchored" data-anchor-id="the-estimation-target">The Estimation Target</h3>
<p>시점 <span class="math inline">\(t\)</span>에서, 미래 <span class="math inline">\(\tau\)</span> 시점의 결과 <span class="math inline">\(Y_{t+\tau}\)</span>에 대한 기대값은 다음과 같이 모델링됩니다.</p>
<p><span class="math display">\[
\mathbb{E}[Y_{t+\tau} \mid a(t, \tau-1), \bar{H}_t] = g(\tau, a(t, \tau-1), \bar{H}_t) \quad \text{--- (1)}
\]</span></p>
<p>이 식의 구성 요소를 분해해보면 다음과 같습니다[cite: 20, 22].</p>
<ul>
<li><strong><span class="math inline">\(a(t, \tau-1) = (a_t, ..., a_{t+\tau-1})\)</span></strong>: 현재 시점 <span class="math inline">\(t\)</span>부터 결과 관측 직전까지 수행할 <strong>의도된 치료 시퀀스(intended sequence of treatments)</strong>입니다. 이는 실제로 관측된 <span class="math inline">\(A\)</span>와 다를 수 있는 가상의 개입(Intervention)입니다.</li>
<li><strong><span class="math inline">\(\bar{H}_t\)</span></strong>: 현재 시점까지 관측된 환자의 이력입니다.</li>
<li><strong><span class="math inline">\(g(\cdot)\)</span></strong>: 우리가 학습하고자 하는 비선형 함수입니다.</li>
</ul>
<p>즉, <strong>“과거 기록 <span class="math inline">\(\bar{H}_t\)</span>가 주어졌을 때, 앞으로 계획된 치료 <span class="math inline">\(a\)</span>를 수행한다면 <span class="math inline">\(\tau\)</span> 시점 뒤의 결과는 무엇인가?”</strong>를 추정하는 문제입니다.</p>
</section>
</section>
<section id="inverse-probability-of-treatment-weighting-iptw" class="level2">
<h2 class="anchored" data-anchor-id="inverse-probability-of-treatment-weighting-iptw">3. Inverse Probability of Treatment Weighting (IPTW)</h2>
<p>하지만 관측 데이터(Observational Data)로 위 식 (1)을 바로 학습하면 문제가 발생합니다. 의사는 환자의 상태(<span class="math inline">\(H_t\)</span>)를 보고 치료(<span class="math inline">\(A_t\)</span>)를 결정하기 때문에, 치료군과 대조군의 특성이 달라지는 <strong>Selection Bias(선택 편향)</strong>가 존재하기 때문입니다.</p>
<p>이를 보정하기 위해 RMSN은 <strong>Marginal Structural Models (MSM)</strong>의 핵심 아이디어인 <strong>IPTW(역확률 가중치)</strong>를 사용합니다[cite: 23].</p>
<section id="stabilized-weights-안정화-가중치" class="level3">
<h3 class="anchored" data-anchor-id="stabilized-weights-안정화-가중치">3.1. Stabilized Weights (안정화 가중치)</h3>
<p>기본적인 IPTW는 분모(Propensity Score)가 매우 작아질 경우 가중치가 폭발하는(high variance) 문제가 있습니다. 이를 완화하기 위해 <strong>Stabilized Weights (SW)</strong>를 사용합니다.</p>
<p>결합 치료 할당(Joint Treatment Assignments)을 고려한 Stabilized Weight <span class="math inline">\(SW(t, \tau)\)</span>는 다음과 같이 정의됩니다[cite: 26].</p>
<p><span class="math display">\[
SW(t, \tau) = \prod_{n=t}^{t+\tau} \frac{f(A_n \mid \bar{A}_{n-1})}{f(A_n \mid \bar{H}_n)} \quad \text{--- (2)}
\]</span></p>
<section id="수식의-상세-해석-및-유도-논리" class="level4">
<h4 class="anchored" data-anchor-id="수식의-상세-해석-및-유도-논리">수식의 상세 해석 및 유도 논리</h4>
<p>이 식은 단순히 주어진 것이 아니라, <strong>Confounding을 제거하면서도 치료의 주변 확률 분포는 유지</strong>하기 위해 설계되었습니다.</p>
<ol type="1">
<li><strong>분모 (Denominator): <span class="math inline">\(f(A_n \mid \bar{H}_n)\)</span></strong>
<ul>
<li>현재 환자의 모든 상세 이력(Confounder 포함)을 조건으로 한 치료 확률입니다.</li>
<li>이 값으로 나누어 줌으로써, 데이터에서 <span class="math inline">\(H_n \to A_n\)</span> (공변량이 치료에 미치는 영향)의 연결 고리를 끊어냅니다. 즉, Pseudo-population에서는 치료가 공변량과 무관하게 할당되도록 만듭니다.</li>
</ul></li>
<li><strong>분자 (Numerator): <span class="math inline">\(f(A_n \mid \bar{A}_{n-1})\)</span></strong>
<ul>
<li>환자의 상태 <span class="math inline">\(L\)</span>은 보지 않고, 오직 과거 치료 이력 <span class="math inline">\(\bar{A}_{n-1}\)</span>에만 의존하는 치료 확률입니다.</li>
<li>분자가 1인 기본 IPTW와 달리, 분자에 이 항을 추가함으로써 가중치의 변동성을 줄이고(Stabilization), 치료 자체의 시간적 상관성(예: 어제 약을 먹었으면 오늘도 먹을 확률이 높음)은 보존합니다.</li>
</ul></li>
<li><strong>누적 곱 (<span class="math inline">\(\prod_{n=t}^{t+\tau}\)</span>)</strong>
<ul>
<li>우리는 단일 시점이 아니라 <span class="math inline">\(t\)</span>부터 <span class="math inline">\(t+\tau\)</span>까지의 <strong>Trajectory</strong>를 예측합니다. 따라서 각 시점의 확률을 모두 곱하여 시퀀스 전체의 가중치를 계산합니다.</li>
</ul></li>
<li><strong>다중 치료 (Multi-treatment) 확장</strong>
<ul>
<li>만약 치료가 여러 종류(<span class="math inline">\(k=1, ..., \Omega_a\)</span>)라면, 각 시점의 확률은 개별 치료 확률의 결합으로 표현됩니다[cite: 26]. <span class="math display">\[\frac{\prod_{k=1}^{\Omega_a} f(A_n(k) \mid \bar{A}_{n-1})}{\prod_{k=1}^{\Omega_a} f(A_n(k) \mid \bar{H}_n)}\]</span></li>
</ul></li>
</ol>
</section>
</section>
<section id="adjusting-for-censoring-중도-절단-보정" class="level3">
<h3 class="anchored" data-anchor-id="adjusting-for-censoring-중도-절단-보정">3.2. Adjusting for Censoring (중도 절단 보정)</h3>
<p>시계열 데이터에서는 환자가 추적 관찰에서 이탈하는 <strong>중도 절단(Censoring)</strong> 문제가 빈번합니다. 이를 보정하기 위해 추가적인 가중치 <span class="math inline">\(SW^*\)</span>를 도입합니다[cite: 31].</p>
<p><span class="math display">\[
SW^*(t, \tau) = \prod_{n=t}^{t+\tau} \frac{f(C_n=0 \mid \mathcal{T} &gt; n, \bar{A}_{n-1})}{f(C_n=0 \mid \mathcal{T} &gt; n, \bar{L}_{n-1}, \bar{A}_{n-1}, X)} \quad \text{--- (3)}
\]</span></p>
<ul>
<li><span class="math inline">\(C_n=0\)</span>: 중도 절단이 발생하지 않음(데이터가 관측됨).</li>
<li><span class="math inline">\(\mathcal{T} &gt; n\)</span>: 아직 생존(또는 관찰) 중임.</li>
<li><strong>해석</strong>: 치료 가중치와 마찬가지로, “환자의 상태(<span class="math inline">\(L\)</span>)가 나빠서 병원을 그만두는(Censoring)” 편향을 제거하기 위해, 상태를 고려한 관측 확률(분모)과 상태를 고려하지 않은 관측 확률(분자)의 비율을 사용합니다.</li>
</ul>
</section>
</section>
<section id="implementation-loss-function" class="level2">
<h2 class="anchored" data-anchor-id="implementation-loss-function">4. Implementation &amp; Loss Function</h2>
<section id="weight-truncation-normalization" class="level3">
<h3 class="anchored" data-anchor-id="weight-truncation-normalization">4.1. Weight Truncation &amp; Normalization</h3>
<p>이론적으로는 위 가중치를 그대로 사용하면 되지만, 딥러닝 모델 학습 시 수치적 불안정성을 방지하기 위해 추가적인 테크닉을 적용합니다.</p>
<ol type="1">
<li><strong>Truncation</strong>: 가중치 값의 1% (하위)와 99% (상위) 지점에서 값을 잘라냅니다(Clip). 극단적인 가중치로 인해 그래디언트가 튀는 것을 막기 위함입니다.</li>
<li><strong>Normalization</strong>: 고정된 예측 구간(Horizon)에 대해 가중치의 평균이 1이 되도록 정규화합니다. <span class="math display">\[\tilde{SW}_{i}(t, \tau) = \frac{SW_{i}(t, \tau)}{\frac{1}{N} \sum_{i=1}^{I} \sum_{t=1}^{T_i} SW_{i}(t, \tau)}\]</span></li>
</ol>
</section>
<section id="weighted-loss-function" class="level3">
<h3 class="anchored" data-anchor-id="weighted-loss-function">4.2. Weighted Loss Function</h3>
<p>최종적으로, RMSN의 Prediction Network를 학습시키기 위한 손실 함수(Loss Function)는 정규화된 가중치가 적용된 <strong>Weighted Squared Error</strong>입니다[cite: 36].</p>
<p><span class="math display">\[
\mathcal{L}(i, t, \tau) = \underbrace{\tilde{SW}_{i}(t, \tau-1)}_{\text{Treatment Weight}} \times \underbrace{\tilde{SW}^*_{i}(t, \tau-1)}_{\text{Censoring Weight}} \times \left\| Y_{t+\tau, i} - g(\tau, a(t, \tau-1), \bar{H}_t) \right\|^2 \quad \text{--- (4)}
\]</span></p>
<ul>
<li><strong>의미</strong>: 편향이 발생하기 쉬운 샘플(관측 확률이 낮은 케이스)에 더 큰 가중치를 부여하여 오차(Error)를 계산합니다. 이를 통해 모델 <span class="math inline">\(g(\cdot)\)</span>는 교란 요인이 제거된 가상 모집단(Pseudo-population)에서의 인과 효과를 학습하게 됩니다.</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="recurrent-marginal-structural-networks" class="level1">
<h1>4. Recurrent Marginal Structural Networks</h1>
<section id="propensity-networks" class="level2">
<h2 class="anchored" data-anchor-id="propensity-networks">4.1. Propensity Networks</h2>
</section>
</section>
<section id="introduction-r-msn-framework" class="level1">
<h1>1. Introduction: R-MSN Framework</h1>
<p>시계열 데이터에서 인과 효과(Causal Effect)를 추정할 때, 가장 큰 난관 중 하나는 시간의 흐름에 따라 변하는 교란 요인(Time-dependent Confounding)을 제어하는 것입니다. 이를 해결하기 위해 전통적인 역확률 가중치(IPTW) 방식이 사용되지만, 고차원의 복잡한 데이터에서는 추정의 정확도가 떨어질 수 있습니다.</p>
<p>이번 포스트에서는 <strong>Recurrent Marginal Structural Networks (R-MSN)</strong> 논문의 핵심인 <strong>Propensity Networks</strong>에 대해 다룹니다. R-MSN은 크게 두 가지 하위 모델(Submodels)로 구성됩니다.</p>
<ol type="1">
<li><strong>Propensity Networks:</strong> IPTW(Inverse Probability of Treatment Weighting)를 계산하기 위한 치료 확률(Propensity Score)을 추정하는 네트워크</li>
<li><strong>Prediction Network:</strong> 계산된 가중치를 바탕으로 실제 치료 반응(Treatment Response)을 예측하는 네트워크</li>
</ol>
<p>이 글에서는 첫 번째 파트인 <strong>Propensity Networks</strong>가 어떻게 시계열 데이터의 이력(History)을 학습하고, 안정화된 가중치(Stabilized Weights)를 산출하는지 상세히 분석합니다.</p>
</section>
<section id="propensity-networks의-필요성과-구조" class="level1">
<h1>2. Propensity Networks의 필요성과 구조</h1>
<section id="왜-rnnlstm인가" class="level2">
<h2 class="anchored" data-anchor-id="왜-rnnlstm인가">2.1. 왜 RNN(LSTM)인가?</h2>
<p>시계열 인과추론에서 안정화된 가중치(Stabilized Weights)를 계산하기 위해서는 <strong>과거의 모든 관측 이력(History)</strong>을 조건부로 하는 확률을 구해야 합니다.</p>
<p>수식으로 표현하자면, 시점 <span class="math inline">\(n\)</span>에서의 가중치를 구하기 위해 우리는 다음과 같은 확률 함수들이 필요합니다.</p>
<p><span class="math display">\[
P(A_n \mid \bar{A}_{n-1}, \bar{H}_n)
\]</span></p>
<p>여기서: * <span class="math inline">\(\bar{A}_{n-1}\)</span>: 과거 치료 이력 (History of past treatments) * <span class="math inline">\(\bar{H}_n\)</span>: 과거 공변량 이력 (History of past covariates)</p>
<p>시간이 지날수록 <span class="math inline">\(n\)</span>이 커지면서 조건부 변수들의 차원(Dimension)이 계속 증가합니다. 일반적인 Feed-forward Neural Network로는 가변 길이의 이력을 처리하기 어렵습니다.</p>
<p>논문에서는 이러한 문제의 자연스러운 해결책으로 <strong>RNN(Recurrent Neural Networks)</strong>, 특히 <strong>LSTM(Long Short-Term Memory)</strong>을 제안합니다. RNN은 은닉 상태(Hidden State)를 통해 과거의 정보를 압축하여 유지할 수 있으므로, <span class="math inline">\(\bar{A}_{n-1}\)</span>과 <span class="math inline">\(\bar{H}_n\)</span>과 같은 이력 데이터를 모델링하는 데 최적화되어 있습니다.</p>
</section>
<section id="가지-핵심-확률-함수-4-key-probability-functions" class="level2">
<h2 class="anchored" data-anchor-id="가지-핵심-확률-함수-4-key-probability-functions">2.2. 4가지 핵심 확률 함수 (4 Key Probability Functions)</h2>
<p>안정화 가중치(Stabilized Weights) <span class="math inline">\(SW\)</span>를 계산하기 위해서는 일반적으로 분자(Numerator)와 분모(Denominator)에 각각 해당하는 확률이 필요하며, 데이터에 중도 절단(Censoring)이 존재하는 경우 이를 보정하기 위한 확률까지 고려해야 합니다.</p>
<p>따라서 R-MSN은 총 <strong>4가지 핵심 확률 함수</strong>를 학습해야 합니다.</p>
<ol type="1">
<li><strong>치료 확률 (Treatment Assignment Probabilities):</strong> <span class="math inline">\(f(\bar{A}_n \mid \cdot)\)</span>
<ul>
<li>분모 모델: <span class="math inline">\(P(A_n \mid \bar{A}_{n-1}, \bar{H}_n)\)</span> (교란 요인 통제)</li>
<li>분자 모델: <span class="math inline">\(P(A_n \mid \bar{A}_{n-1})\)</span> (주변 확률 근사)</li>
</ul></li>
<li><strong>중도 절단 확률 (Censoring Probabilities):</strong> <span class="math inline">\(f(C_n=0 \mid \cdot)\)</span>
<ul>
<li>분모 모델: <span class="math inline">\(P(C_n=0 \mid \bar{A}_{n-1}, \bar{H}_n, A_n)\)</span></li>
<li>분자 모델: <span class="math inline">\(P(C_n=0 \mid \bar{A}_{n-1}, A_n)\)</span></li>
</ul></li>
</ol>
<p>이 4가지 함수는 모두 과거의 이력에 의존하므로, R-MSN에서는 이들을 통칭하여 <strong>Propensity Networks</strong>라고 부르며 각각을 LSTM으로 파라미터화합니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/propensity_networks_architecture.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: Propensity Networks의 개념적 구조. 상단은 치료(Action) 확률을 추정하는 Multi-target LSTM, 하단은 중도 절단(Censoring) 여부를 추정하는 Single-output LSTM을 나타낸다. 입력으로 과거의 이력(History)이 들어가고, 출력으로 각 시점의 확률값이 산출되어 IPTW 계산에 활용된다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="모델링-상세-modeling-details" class="level1">
<h1>3. 모델링 상세 (Modeling Details)</h1>
<section id="multi-target-lstm과-상관관계-반영" class="level2">
<h2 class="anchored" data-anchor-id="multi-target-lstm과-상관관계-반영">3.1. Multi-target LSTM과 상관관계 반영</h2>
<p>Propensity Networks의 독창적인 점 중 하나는 치료 확률을 모델링할 때 <strong>Multi-target LSTM</strong>을 사용한다는 점입니다.</p>
<p>의료 데이터나 현실 세계의 시계열 데이터에서는 여러 가지 치료(Treatment)가 동시에 행해지는 경우가 많습니다. 예를 들어, 동일한 질병을 치료하기 위해 <strong>보완적인 약물(Complementary drugs)</strong>이 함께 처방될 수 있습니다.</p>
<ul>
<li><strong>기존 접근:</strong> 각 치료 <span class="math inline">\(A^{(1)}, A^{(2)}\)</span>를 독립적인 모델로 추정 <span class="math inline">\(\rightarrow\)</span> 치료 간의 상관관계(Correlation)를 무시함.</li>
<li><strong>R-MSN 접근:</strong> 하나의 LSTM에서 여러 치료 확률을 <strong>결합적(Jointly)</strong>으로 생성하는 Multi-target 구조 채택.</li>
</ul>
<p>이를 통해 <span class="math inline">\(A_n\)</span> 내부의 여러 차원 간에 존재하는 상관성을 모델이 학습할 수 있게 되어, 더 정확한 경향성 점수(Propensity Score) 추정이 가능해집니다. 반면, 중도 절단(Censoring) 확률 <span class="math inline">\(f(C_n=0 \mid \cdot)\)</span>은 단일 출력이므로 <strong>Single-output LSTM</strong>을 사용합니다.</p>
</section>
<section id="출력층-설계와-유연성-flexibility" class="level2">
<h2 class="anchored" data-anchor-id="출력층-설계와-유연성-flexibility">3.2. 출력층 설계와 유연성 (Flexibility)</h2>
<p>RNN 아키텍처의 유연성 덕분에, 치료 변수(<span class="math inline">\(A_n\)</span>)의 형태에 따라 다양한 출력층을 설계할 수 있습니다.</p>
<section id="discrete-treatment-이산형-치료-변수" class="level3">
<h3 class="anchored" data-anchor-id="discrete-treatment-이산형-치료-변수">Discrete Treatment (이산형 치료 변수)</h3>
<p>가장 일반적인 경우로, 치료 여부가 O/X 이거나 카테고리인 경우입니다.</p>
<ul>
<li><strong>이진 변수 (Binary):</strong>
<ul>
<li><strong>Activation:</strong> Standard LSTM + <strong>Sigmoid</strong> output layer</li>
<li>본 논문의 실험(Section 5)에서는 이 구성을 사용하여 이진 확률을 계산했습니다.</li>
<li>Hidden State 활성화 함수로는 <code>tanh</code>를 사용했습니다.</li>
</ul></li>
<li><strong>범주형 변수 (Categorical):</strong>
<ul>
<li><strong>Activation:</strong> Standard LSTM + <strong>Softmax</strong> layer</li>
</ul></li>
</ul>
</section>
<section id="continuous-treatment-연속형-치료-변수" class="level3">
<h3 class="anchored" data-anchor-id="continuous-treatment-연속형-치료-변수">Continuous Treatment (연속형 치료 변수)</h3>
<p>치료가 약물의 투여량(Dosage)처럼 연속적인 값으로 매핑되는 경우, 단순한 LSTM으로는 확률 밀도 함수를 추정하기 어렵습니다.</p>
<ul>
<li>이 경우 논문에서는 <strong>Variational RNNs (VRNNs)</strong> [Reference 6]과 같은 더 복잡한 아키텍처를 도입하여 연속적인 확률 분포를 모델링할 수 있음을 언급합니다.</li>
<li>이는 R-MSN 프레임워크가 단순히 이진 치료에만 국한되지 않고, 다양한 형태의 개입(Intervention)으로 확장될 수 있음을 시사합니다.</li>
</ul>
<hr>
</section>
</section>
<section id="prediction-network" class="level2">
<h2 class="anchored" data-anchor-id="prediction-network">4.2. Prediction Network</h2>
</section>
</section>
<section id="introduction-1" class="level1">
<h1>1. Introduction</h1>
<p>의료 데이터나 사회과학 데이터와 같이 시간의 흐름에 따라 치료(Treatment)와 환자의 상태(Covariates)가 지속적으로 변하는 환경에서는 <strong>Time-dependent Confounding</strong> 문제가 발생합니다. 이번 포스트에서는 이러한 환경에서 환자의 치료 반응(Treatment Response)을 정확하게 예측하기 위해 제안된 <strong>R-MSN (Recurrent Marker Selection Networks)</strong>의 핵심 아키텍처인 <strong>Prediction Network</strong>에 대해 심층적으로 다뤄보겠습니다.</p>
<p>기존의 표준 RNN(Recurrent Neural Networks)은 한 시점 앞(One-step-ahead)을 예측하는 데에는 유용하지만, 실제 임상 현장이나 정책 결정 과정에서는 훨씬 복잡한 시나리오가 요구됩니다. 예를 들어, “앞으로 3일간 약물 A를 투여하고, 그 후 2일간 약물 B를 투여했을 때 환자의 상태 변화”와 같이 <strong>다양한 기간과 개입(Intervention) 계획</strong>에 따른 장기적인 예후를 예측해야 합니다.</p>
<p>이 논문의 섹션 4.2에서는 이러한 Multi-step Prediction 문제를 해결하기 위해 <strong>Sequence-to-Sequence (Seq2Seq)</strong> 아키텍처를 변형하여 제안합니다. 왜 표준 Seq2Seq가 아닌 변형된 구조가 필요한지, 그리고 수학적으로 어떻게 모델링되는지 상세히 살펴보겠습니다.</p>
</section>
<section id="core-concepts-motivation" class="level1">
<h1>2. Core Concepts &amp; Motivation</h1>
<section id="the-challenge-of-multi-step-prediction" class="level3">
<h3 class="anchored" data-anchor-id="the-challenge-of-multi-step-prediction">2.1 The Challenge of Multi-step Prediction</h3>
<p>일반적인 시계열 예측에서 미래 시점 <span class="math inline">\(t+k\)</span>의 결과 <span class="math inline">\(\hat{Y}_{t+k}\)</span>를 예측하려면, 재귀적(Recursive) 방식이 주로 사용됩니다. 즉, <span class="math inline">\(t+1\)</span> 시점의 예측값을 다시 입력으로 사용하여 <span class="math inline">\(t+2\)</span>를 예측하는 방식입니다.</p>
<p>하지만 인과추론(Causal Inference) 관점, 특히 의료 데이터에서는 심각한 문제가 발생합니다. 미래의 결과(Outcome)를 예측하기 위해서는 미래의 공변량(Covariates, 예: 혈압, 체온 등)의 정보가 필요합니다. 하지만 <strong>모든 공변량(<span class="math inline">\(L\)</span>)을 예측하면서 미래로 나아가는 것은 오차 전파(Error Propagation) 문제를 야기</strong>하며, 모델이 불필요하게 복잡해집니다.</p>
</section>
<section id="proposed-solution-action-only-decoder" class="level3">
<h3 class="anchored" data-anchor-id="proposed-solution-action-only-decoder">2.2 Proposed Solution: Action-Only Decoder</h3>
<p>연구진은 이 문제를 해결하기 위해 <strong>Encoder-Decoder</strong> 구조를 채택하되, 디코더(Decoder)의 입력을 제한하는 영리한 전략을 취합니다.</p>
<ul>
<li><strong>Encoder</strong>: 현재 시점까지의 모든 정보(과거 기록, 현재 상태, 이전 치료)를 압축하여 환자의 현재 임상 상태(Clinical State)를 학습합니다.</li>
<li><strong>Decoder</strong>: 미래의 공변량을 예측하여 입력으로 쓰는 대신, <strong>계획된 치료 행동(Planned Future Actions)</strong>만을 입력으로 받아 미래를 예측합니다.</li>
</ul>
<p>이는 우리가 관심 있는 것이 “모든 생체 신호의 변화”가 아니라, “특정 치료 계획에 따른 결과(Response)”이기 때문입니다.</p>
</section>
</section>
<section id="model-architecture" class="level1">
<h1>3. Model Architecture</h1>
<p>아래 그림은 R-MSN의 Prediction Network 전체 구조를 보여줍니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/rmsn_architecture_fig2.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: R-MSN Architecture for Multi-step Treatment Response Prediction. 좌측의 Encoder는 과거의 시계열 데이터(History)를 처리하여 현재 상태(Representation)를 생성하고, 우측의 Decoder는 계획된 미래의 치료(Actions)만을 입력받아 순차적으로 미래의 결과(Outcome)를 예측한다. 두 네트워크 사이에는 차원 변환을 위한 Memory Adapter가 존재한다.</figcaption>
</figure>
</div>
<p>이 구조는 크게 세 부분으로 나뉩니다: 1. <strong>Encoder</strong>: 과거 정보 요약 및 <span class="math inline">\(t+1\)</span> 시점 예측 2. <strong>Memory Adapter</strong>: Encoder와 Decoder 사이의 State 전달 3. <strong>Decoder</strong>: <span class="math inline">\(t+2\)</span> 시점 이후의 장기 예측</p>
</section>
<section id="mathematical-formulation-derivations" class="level1">
<h1>4. Mathematical Formulation &amp; Derivations</h1>
<p>각 컴포넌트의 수학적 작동 원리를 단계별로 유도해 보겠습니다.</p>
<section id="encoder-learning-representations" class="level3">
<h3 class="anchored" data-anchor-id="encoder-learning-representations">4.1 Encoder: Learning Representations</h3>
<p>Encoder의 목표는 환자의 현재 상태를 잘 나타내는 <strong>Representation (<span class="math inline">\(h_t\)</span>)</strong>을 학습하는 것입니다. 이를 위해 표준 LSTM(Long Short-Term Memory)을 사용합니다.</p>
<p>현재 시점 <span class="math inline">\(t\)</span>에서 사용 가능한 정보는 다음과 같습니다: * <span class="math inline">\(L_t\)</span>: 현재 시점의 공변량 (Covariates) * <span class="math inline">\(A_{t-1}\)</span>: 이전 시점의 치료 (Previous Treatments) * <span class="math inline">\(X\)</span>: 정적 변수 (Static features) - <em>문맥상 <span class="math inline">\(X\)</span>가 표기된 경우</em></p>
<p>Encoder LSTM은 다음과 같이 상태를 업데이트합니다:</p>
<p><span class="math display">\[
h_t = \text{LSTM}_{enc}(h_{t-1}, [L_t, A_{t-1}, X])
\]</span></p>
<p>여기서 <span class="math inline">\(h_t\)</span>는 과거의 모든 정보를 함축한 은닉 상태(Hidden State)입니다.</p>
<p><strong>Key Difference:</strong> 일반적인 Seq2Seq 모델과 달리, R-MSN의 Encoder 마지막 유닛은 단순히 Context Vector만 넘겨주는 것이 아니라, <strong>첫 번째 미래 시점(<span class="math inline">\(t+1\)</span>)의 예측</strong>에도 직접 관여합니다.</p>
<p><span class="math display">\[
\hat{Y}_{t+1} = \phi_{out}(h_t)
\]</span></p>
<p>이때 <span class="math inline">\(\phi_{out}\)</span>은 선형 출력 층(Linear Output Layer)입니다. 이는 가장 최신의 공변량 정보(<span class="math inline">\(L_t\)</span>)를 손실 없이 사용하여 바로 다음 단계를 예측하기 위함입니다.</p>
</section>
<section id="memory-adapter" class="level3">
<h3 class="anchored" data-anchor-id="memory-adapter">4.2 Memory Adapter</h3>
<p>Encoder와 Decoder는 서로 다른 역할을 수행하므로, 필요한 State Size(차원)가 다를 수 있습니다. 또한 Encoder의 복잡한 feature space를 Decoder가 처리할 수 있는 형태로 변환해주어야 합니다.</p>
<p>이를 위해 <strong>Memory Adapter</strong>라는 단일 신경망 층을 도입합니다. 활성화 함수로는 <strong>ELU (Exponential Linear Unit)</strong>를 사용합니다.</p>
<p><span class="math display">\[
z_t = \text{ELU}(W_{adapt} h_t + b_{adapt})
\]</span></p>
<ul>
<li><span class="math inline">\(h_t\)</span>: Encoder의 마지막 은닉 상태 (Cell state 포함 가능)</li>
<li><span class="math inline">\(z_t\)</span>: Decoder의 초기 상태로 주입될 변환된 벡터</li>
<li>참고: 여기서 <span class="math inline">\(h_t\)</span>와 <span class="math inline">\(z_t\)</span>는 LSTM의 Cell State와 Hidden State가 연결(Concatenation)된 형태를 의미합니다.</li>
</ul>
</section>
<section id="decoder-action-driven-forecasting" class="level3">
<h3 class="anchored" data-anchor-id="decoder-action-driven-forecasting">4.3 Decoder: Action-Driven Forecasting</h3>
<p>Decoder의 핵심 목적은 <strong>미래의 입력 공변량을 예측하지 않고(Avoiding forecast input covariates)</strong>, 오직 제안된 치료 계획(Planned Treatment Assignments)에 기반하여 미래를 시뮬레이션하는 것입니다.</p>
<p>미래 시점 <span class="math inline">\(t+k\)</span> (<span class="math inline">\(k \ge 1\)</span>)에 대해, Decoder는 다음과 같이 작동합니다:</p>
<ol type="1">
<li><strong>Input:</strong> 오직 계획된 행동 <span class="math inline">\(a_{t+k}\)</span> 만을 입력으로 받습니다.</li>
<li><strong>State Update:</strong> 이전 상태 <span class="math inline">\(z_{t+k-1}\)</span>와 현재 행동 <span class="math inline">\(a_{t+k}\)</span>를 결합합니다.</li>
</ol>
<p><span class="math display">\[
z_{t+k} = \text{LSTM}_{dec}(z_{t+k-1}, a_{t+k})
\]</span></p>
<ol start="3" type="1">
<li><strong>Prediction:</strong> 업데이트된 상태 <span class="math inline">\(z_{t+k}\)</span>를 통해 결과 변수를 예측합니다.</li>
</ol>
<p><span class="math display">\[
\hat{Y}_{t+k+1} = \phi_{out}(z_{t+k})
\]</span></p>
<p>이 과정을 통해 모델은 <span class="math inline">\(L_{t+1}, L_{t+2}, \dots\)</span> 와 같은 중간 공변량을 예측할 필요 없이, <span class="math inline">\(z_t\)</span>에 압축된 ’환자의 현재 상태’와 <span class="math inline">\(a_{t+1}, a_{t+2}, \dots\)</span>라는 ’개입 계획’만을 가지고 미래 반응을 전파(Propagate)시킬 수 있습니다.</p>
</section>
<section id="activation-functions" class="level3">
<h3 class="anchored" data-anchor-id="activation-functions">4.4 Activation Functions</h3>
<p>논문에서는 연속적인(Continuous) 예측을 위해 다음과 같은 활성화 함수 구성을 명시하고 있습니다:</p>
<ul>
<li><strong>State Activations (LSTM 내부 및 Adapter):</strong> ELU (Exponential Linear Unit) <span class="math display">\[
  \text{ELU}(x) = \begin{cases} x &amp; \text{if } x &gt; 0 \\ \alpha(e^x - 1) &amp; \text{if } x \le 0 \end{cases}
  \]</span> ELU는 ReLU의 장점을 가지면서도 음수 영역에서 0이 아닌 값을 가져, 정보 소실을 줄이고 학습 안정성을 높이는 데 기여합니다.</li>
<li><strong>Output Layer:</strong> Linear Layer (Regression 문제)</li>
</ul>
<hr>
</section>
<section id="training-procedure" class="level2">
<h2 class="anchored" data-anchor-id="training-procedure">4.3. Training Procedure</h2>
</section>
</section>
<section id="introduction-2" class="level1">
<h1>1. Introduction</h1>
<p>시계열 데이터에서 인과 효과(Causal Effect)를 추정할 때 가장 큰 난관은 <strong>시간에 따라 변하는 교란 요인(Time-dependent confounding)</strong>입니다. 과거의 치료(Treatment)가 현재의 환자 상태(Covariates)에 영향을 주고, 다시 이 상태가 미래의 치료 결정에 영향을 주는 복잡한 피드백 루프가 존재하기 때문입니다.</p>
<p>본 포스트에서는 이러한 문제를 해결하기 위해 제안된 <strong>Recurrent Marginal Structural Networks (R-MSNs)</strong>의 핵심인 <strong>학습 과정(Training Procedure)</strong>을 상세히 분석합니다. R-MSN의 학습은 단일 단계로 이루어지지 않으며, 인과성을 보존하기 위해 <strong>(1) 성향 점수 네트워크, (2) 인코더, (3) 디코더</strong>의 3단계 파이프라인으로 구성됩니다.</p>
</section>
<section id="step-by-step-training-procedure" class="level1">
<h1>2. Step-by-Step Training Procedure</h1>
<p>R-MSN의 학습은 인과적 편향(Bias)을 제거하기 위한 가중치 계산부터 시작하여, 과거 상태의 표현(Representation) 학습, 그리고 미래 결과 예측(Prediction)으로 이어지는 논리적 흐름을 따릅니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/rmsn_training_pipeline.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: R-MSN의 전체 학습 파이프라인 개요. (a)는 성향 점수 네트워크를 통해 안정화 가중치(SW)를 계산하는 과정, (b)는 계산된 가중치를 적용하여 과거 데이터를 인코딩하는 과정, (c)는 미래 시점의 치료 계획에 따른 결과를 예측하는 디코더 학습 과정을 나타낸다.</figcaption>
</figure>
</div>
<section id="step-1-propensity-network-training-bias-removal" class="level2">
<h2 class="anchored" data-anchor-id="step-1-propensity-network-training-bias-removal">Step 1: Propensity Network Training (Bias Removal)</h2>
<p>첫 번째 단계는 관측 데이터에 존재하는 선택 편향(Selection Bias)을 제거하기 위한 <strong>성향 점수(Propensity Score)</strong> 학습입니다.</p>
<section id="motivation" class="level3">
<h3 class="anchored" data-anchor-id="motivation">Motivation</h3>
<p>관찰 데이터(Observational Data)에서는 치료 <span class="math inline">\(A_t\)</span>가 무작위로 할당되지 않습니다. 의사는 환자의 이전 상태 <span class="math inline">\(H_{t-1}\)</span>를 보고 치료를 결정합니다. 이를 보정하지 않고 학습하면 모델은 치료 효과가 아닌, 치료를 받게 된 환자의 상태적 특성을 학습하게 됩니다. 이를 해결하기 위해 <strong>역확률 가중치(Inverse Probability Weighting, IPW)</strong> 기법을 사용합니다.</p>
</section>
<section id="mechanism" class="level3">
<h3 class="anchored" data-anchor-id="mechanism">Mechanism</h3>
<p>각 시점 <span class="math inline">\(t\)</span>에서 성향 점수 네트워크는 이전 처리 <span class="math inline">\(A_{t-1}\)</span>와 히스토리 <span class="math inline">\(H_{t-1}\)</span>를 입력으로 받아, 현재 시점 <span class="math inline">\(t\)</span>에서 특정 치료를 받을 확률을 추정합니다.</p>
<ol type="1">
<li><p><strong>확률 추정:</strong> 이진 교차 엔트로피(Binary Cross Entropy) 손실 함수를 사용하여 치료 할당 확률을 학습합니다.</p></li>
<li><p><strong>안정화 가중치(Stabilized Weights, SW) 계산:</strong> 시계열 데이터에서 가중치의 분산이 지나치게 커지는 것을 막기 위해 안정화 가중치를 사용합니다.</p>
<p><span class="math display">\[\mathbf{SW}(t, 0) = \frac{f(A_t | A_{t-1})}{f(A_t | H_t)}\]</span></p>
<p>여기서 분자는 이전 치료 이력만 고려한 확률, 분모는 모든 히스토리를 고려한 확률입니다.</p></li>
<li><p><strong>누적 가중치 계산:</strong> 장기적인 미래 시점 <span class="math inline">\(\tau\)</span>까지의 효과를 추정하기 위해, 현재 시점부터 미래 시점까지의 가중치를 누적 곱(Cumulative Product)으로 계산합니다.</p>
<p><span class="math display">\[\mathbf{SW}(t, \tau) = \prod_{j=0}^{\tau} \mathbf{SW}(t+j, 0)\]</span></p></li>
</ol>
<blockquote class="blockquote">
<p><strong>Note:</strong> 본 연구에서는 표준적인 이진 교차 엔트로피(Standard Binary Cross Entropy) 손실함수를 사용하였으며, 치료 할당(Treatment Assignment)과 중도 절단(Censoring) 여부를 모두 이진 관측값으로 취급하여 학습했습니다.</p>
</blockquote>
</section>
</section>
<section id="step-2-encoder-training-representation-learning" class="level2">
<h2 class="anchored" data-anchor-id="step-2-encoder-training-representation-learning">Step 2: Encoder Training (Representation Learning)</h2>
<p>두 번째 단계는 환자의 임상적 상태(Clinical State)를 요약하는 <strong>인코더(Encoder)</strong>를 학습하는 과정입니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/encoder_training.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: 인코더 학습 과정 상세. 과거의 공변량(X), 치료(A), 결과(L)를 입력받아 은닉 상태(h)를 갱신하며, 다음 시점의 결과(<span class="math inline">\(\hat{Y}_{t+1}\)</span>)를 예측한다. 이때 Step 1에서 구한 가중치를 손실 함수에 적용하여 편향을 보정한다.</figcaption>
</figure>
</div>
<section id="motivation-1" class="level3">
<h3 class="anchored" data-anchor-id="motivation-1">Motivation</h3>
<p>시계열 데이터는 차원이 높고 노이즈가 많습니다. 인코더는 과거의 모든 정보(치료, 공변량 등)를 고정된 크기의 벡터인 <strong>은닉 상태(Hidden State, <span class="math inline">\(h_t\)</span>)</strong>로 압축합니다. 중요한 점은, 이 과정에서 <strong>Step 1에서 구한 가중치(SW)</strong>를 사용하여 편향된 데이터 분포를 보정한다는 것입니다.</p>
</section>
<section id="mechanism-1" class="level3">
<h3 class="anchored" data-anchor-id="mechanism-1">Mechanism</h3>
<p>인코더는 표준적인 RNN 구조(LSTM 또는 GRU)를 따르며, <strong>One-step-ahead prediction</strong>을 수행합니다. 즉, <span class="math inline">\(t\)</span> 시점까지의 정보를 바탕으로 <span class="math inline">\(t+1\)</span> 시점의 결과를 예측하도록 훈련됩니다.</p>
<ul>
<li><strong>Input:</strong> <span class="math inline">\(\{L_{t-1}, A_{t-1}, X\}\)</span> (이전 결과, 이전 치료, 정적 공변량)</li>
<li><strong>Target:</strong> <span class="math inline">\(\hat{Y}_{t+1}\)</span> (다음 시점의 실제 결과)</li>
<li><strong>Bias Correction:</strong> 손실 함수 계산 시 각 샘플에 <span class="math inline">\(\mathbf{SW}\)</span>를 곱해줌으로써, 마치 무작위 할당된 데이터(Pseudo-population)에서 학습하는 것과 같은 효과를 냅니다.</li>
</ul>
</section>
</section>
<section id="step-3-decoder-training-counterfactual-prediction" class="level2">
<h2 class="anchored" data-anchor-id="step-3-decoder-training-counterfactual-prediction">Step 3: Decoder Training (Counterfactual Prediction)</h2>
<p>마지막 단계는 학습된 표현(<span class="math inline">\(h_t\)</span>)을 바탕으로, 가상의 미래 치료 계획에 따른 결과를 예측하는 <strong>디코더(Decoder)</strong>를 학습하는 것입니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/decoder_training.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3: 디코더 학습 과정 상세. 인코더에서 넘어온 초기 상태 <span class="math inline">\(h_t\)</span>를 시작점으로 하여, 미래의 가상 치료 시퀀스 <span class="math inline">\(A_{t+1}, \dots\)</span> 가 주어졌을 때 미래 결과 <span class="math inline">\(Y\)</span>를 순차적으로 예측한다.</figcaption>
</figure>
</div>
<section id="motivation-2" class="level3">
<h3 class="anchored" data-anchor-id="motivation-2">Motivation</h3>
<p>우리의 최종 목표는 “만약 환자가 미래에 A라는 치료 계획을 따른다면 결과는 어떨까?”라는 반사실적(Counterfactual) 질문에 답하는 것입니다. 인코더는 과거를 요약할 뿐 미래를 시뮬레이션하지 못하므로, 별도의 디코더가 필요합니다.</p>
</section>
<section id="mechanism-2" class="level3">
<h3 class="anchored" data-anchor-id="mechanism-2">Mechanism</h3>
<ol type="1">
<li><strong>초기화:</strong> 인코더가 생성한 마지막 시점의 은닉 상태 <span class="math inline">\(h_t\)</span>를 디코더의 초기 상태로 사용합니다.</li>
<li><strong>Sequence Prediction:</strong> 디코더는 미래의 치료 시퀀스 <span class="math inline">\(A_{t+1}, A_{t+2}, \dots\)</span>를 입력받아 미래의 결과 <span class="math inline">\(\hat{Y}_{t+2}, \hat{Y}_{t+3}, \dots\)</span>를 예측합니다.</li>
<li><strong>Mini-batching Strategy:</strong>
<ul>
<li>모든 환자의 모든 시점 <span class="math inline">\(t\)</span>를 시작점으로 간주합니다.</li>
<li>최대 예측 범위 <span class="math inline">\(\tau_{max}\)</span>까지의 시퀀스를 생성합니다.</li>
<li>데이터 형식: <span class="math inline">\([\mathbf{h}_t, \{\mathbf{A}_{t+1}, \dots, \mathbf{A}_{t+\tau_{max}-1}\}, \{\mathbf{Y}_{t+2}, \dots, \mathbf{Y}_{t+\tau_{max}}\}]\)</span></li>
</ul></li>
</ol>
</section>
</section>
</section>
<section id="mathematical-formulation-of-loss-functions" class="level1">
<h1>3. Mathematical Formulation of Loss Functions</h1>
<p>논문의 식 (5)에 제시된 손실 함수를 구체적으로 분석해보겠습니다. 이 손실 함수는 인코더와 디코더가 각각의 목표를 달성하도록 설계되었습니다.</p>
<p><span class="math display">\[
\mathcal{L}_{encoder} = \sum_{i=1}^{I} \sum_{t=1}^{T_i} e(i, t, 1)
\]</span></p>
<p><span class="math display">\[
\mathcal{L}_{decoder} = \sum_{i=1}^{I} \sum_{t=1}^{T_i} \sum_{\tau=2}^{\min(T_i - t, \tau_{max})} e(i, t, \tau)
\]</span></p>
<section id="notation-definition" class="level3">
<h3 class="anchored" data-anchor-id="notation-definition">Notation Definition</h3>
<ul>
<li><span class="math inline">\(i\)</span>: 환자 인덱스 (<span class="math inline">\(1, \dots, I\)</span>)</li>
<li><span class="math inline">\(t\)</span>: 현재 시점 (<span class="math inline">\(1, \dots, T_i\)</span>)</li>
<li><span class="math inline">\(\tau\)</span>: 예측 Horizon (미래 몇 스텝 뒤인지)</li>
<li><span class="math inline">\(e(i, t, \tau)\)</span>: 개별 오차 함수 (Error Function)</li>
</ul>
</section>
<section id="detailed-derivation-of-error-function-ei-t-tau" class="level3">
<h3 class="anchored" data-anchor-id="detailed-derivation-of-error-function-ei-t-tau">Detailed Derivation of Error Function <span class="math inline">\(e(i, t, \tau)\)</span></h3>
<p>논문에서는 “weighted mean-squared error loss”를 사용한다고 명시되어 있습니다. 이를 수식으로 구체화하면 다음과 같습니다.</p>
<p><span class="math display">\[e(i, t, \tau) = \mathbf{SW}_i(t, \tau-1) \cdot \| Y_{i, t+\tau} - \hat{Y}_{i, t+\tau} \|^2\]</span></p>
<ol type="1">
<li><strong>Squared Error:</strong> <span class="math inline">\(\| Y - \hat{Y} \|^2\)</span> 항은 연속형 변수(Continuous Outcomes)에 대한 예측 오차를 측정합니다. (이산형 변수의 경우 Cross Entropy 사용 가능)</li>
<li><strong>Weighting:</strong> <span class="math inline">\(\mathbf{SW}_i(t, \tau-1)\)</span> 항은 Step 1에서 계산한 안정화 가중치입니다.
<ul>
<li>인코더의 경우 <span class="math inline">\(\tau=1\)</span>이므로 <span class="math inline">\(\mathbf{SW}(t, 0)\)</span> 즉, 현재 시점의 가중치만 사용합니다.</li>
<li>디코더의 경우 <span class="math inline">\(\tau \ge 2\)</span>이므로 누적 가중치(Cumulative Product)를 사용하여 시간이 지날수록 커질 수 있는 편향을 보정합니다.</li>
</ul></li>
</ol>
</section>
<section id="interpretation" class="level3">
<h3 class="anchored" data-anchor-id="interpretation">Interpretation</h3>
<ul>
<li><strong>Encoder Loss (<span class="math inline">\(\mathcal{L}_{encoder}\)</span>):</strong> 모든 환자와 모든 시점에 대해, <strong>바로 다음 스텝(<span class="math inline">\(\tau=1\)</span>)</strong>을 얼마나 잘 예측하는지 측정합니다. 이는 Representation Learning의 핵심입니다.</li>
<li><strong>Decoder Loss (<span class="math inline">\(\mathcal{L}_{decoder}\)</span>):</strong> 모든 환자와 시점에 대해, <strong><span class="math inline">\(\tau=2\)</span>부터 최대 <span class="math inline">\(\tau_{max}\)</span>까지의 미래</strong>를 얼마나 잘 예측하는지 측정합니다. 이는 Counterfactual Inference의 핵심입니다.</li>
</ul>
<hr>
</section>
</section>
<section id="experiments-with-cancer-growth-simulation-model" class="level1">
<h1>5. Experiments With Cancer Growth Simulation Model</h1>
<hr>
</section>
<section id="conclusion" class="level1">
<h1>6. Conclusion</h1>



</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/shsha0110\.github\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>