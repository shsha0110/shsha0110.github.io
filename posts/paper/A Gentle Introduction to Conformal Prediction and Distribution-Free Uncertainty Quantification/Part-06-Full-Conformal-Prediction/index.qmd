---
title: "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 6)"
subtitle: "6. Full Conformal Prediction"
author: "유성현"
date: "2026-01-16"
categories: [Paper Review]
format:
  html:
    toc: true
    number-sections: false
    code-fold: show
---

# Introduction: The Efficiency Trade-off

지금까지 우리가 다룬 방식은 **Split Conformal Prediction (Inductive CP)**이었습니다.
이 방식은 데이터를 학습용(Train)과 보정용(Calibration)으로 나누어 사용합니다.
* **장점**: 계산이 매우 빠릅니다. 모델을 딱 한 번만 학습시키면 됩니다.
* **단점**: 데이터를 쪼개야 하므로 **통계적 효율성(Statistical Efficiency)**이 떨어집니다. 보정용 데이터는 학습에 기여하지 못하고, 학습용 데이터는 보정에 기여하지 못하기 때문입니다.

데이터가 매우 귀하거나(예: 희귀병 임상 데이터), 예측의 정확도가 비용보다 훨씬 중요한 상황이라면 어떨까요?
이때 우리는 계산 비용을 감수하더라도 모든 데이터를 학습과 보정에 동시에 사용하는 **Full Conformal Prediction (Transductive CP)**을 고려해야 합니다.

# The Core Idea: "What if?"

Full CP의 핵심 아이디어는 새로운 데이터 $X_{n+1}$에 대해 **"만약 정답이 $y$라면, 이 데이터가 기존 데이터들과 잘 어울리는가(Exchangeable)?"**를 테스트하는 것입니다.

우리는 아직 정답 $Y_{n+1}$을 모르지만, 가능한 모든 후보 $y \in \mathcal{Y}$를 하나씩 대입해볼 수는 있습니다.
만약 $y$가 진짜 정답이라면, $(X_{n+1}, y)$를 포함한 전체 데이터셋은 통계적으로 동질적(Exchangeable)이어야 합니다.

# The Algorithm

알고리즘은 모든 가능한 라벨 $y$에 대해 재학습(Retraining)을 수행해야 하므로 꽤 무겁습니다.

## Step 1: Loop over all possible labels
테스트 포인트 $X_{n+1}$에 대해, 가능한 모든 정답 후보 $y \in \mathcal{Y}$ (예: 분류 문제의 모든 클래스)에 대해 다음 과정을 반복합니다.

## Step 2: Augment and Retrain
기존 데이터셋에 가상의 데이터 포인트 $(X_{n+1}, y)$를 추가하여 확장된 데이터셋을 만듭니다.
그리고 이 데이터셋으로 모델 $\hat{f}^y$를 **처음부터 다시 학습**시킵니다.

$$ \text{Train } \hat{f}^y \text{ on } \{(X_1, Y_1), \dots, (X_n, Y_n), (X_{n+1}, y)\} $$

> **주의**: 이때 사용하는 학습 알고리즘은 데이터의 순서에 영향을 받지 않는 **대칭적(Symmetric)** 알고리즘이어야 합니다.

## Step 3: Compute Scores
학습된 모델 $\hat{f}^y$를 사용하여, 확장된 데이터셋 내의 모든 포인트($i=1 \dots n+1$)에 대해 Conformal Score를 계산합니다.

$$ s_i^y = s(X_i, Y_i, \hat{f}^y) \quad \text{for } i=1, \dots, n $$
$$ s_{n+1}^y = s(X_{n+1}, y, \hat{f}^y) $$

## Step 4: Compute Quantile
이 $n+1$개의 점수들 사이에서 $s_{n+1}^y$의 위치를 확인합니다.
정확히는 $1-\alpha$ 분위수 $\hat{q}^y$를 계산하여, $s_{n+1}^y$가 이 안에 들어오는지 확인합니다.

$$ \hat{q}^y = \text{Quantile}\left( \{s_1^y, \dots, s_{n+1}^y\} ; \frac{\lceil (n+1)(1-\alpha) \rceil}{n+1} \right) $$

## Step 5: Construct Prediction Set
위 조건을 만족하는(즉, 기존 데이터들과 잘 섞이는) 모든 $y$를 예측 집합에 포함시킵니다.

$$ \mathcal{C}(X_{n+1}) = \{ y \in \mathcal{Y} : s_{n+1}^y \le \hat{q}^y \} $$

# Statistical Interpretation: Permutation Test

이 과정은 통계학의 **순열 검정(Permutation Test)**과 완벽하게 동일합니다.

* **귀무가설 ($H_0$)**: 데이터 포인트 $(X_{n+1}, y)$는 기존 데이터들과 동일한 분포에서 왔다(Exchangeable).
* **검정 통계량**: Conformal Score $s$.
* **기각**: 만약 $s_{n+1}^y$가 다른 점수들에 비해 터무니없이 크다면(상위 $\alpha$ 영역), 우리는 "이 데이터는 이 집단에 속하지 않는다"고 판단하고 귀무가설을 기각합니다. 즉, $y$는 정답이 아닐 가능성이 높으므로 예측 집합에서 제외합니다.

Full CP의 예측 집합은 **"가설 검정을 통과한(기각되지 않은) 모든 $y$의 집합"**입니다.

# Computational Cost vs. Statistical Efficiency

## The Cost
이 방법의 가장 큰 문제는 **계산 비용**입니다.
테스트 데이터가 하나 들어올 때마다, 그리고 후보 클래스 $K$개마다 매번 모델을 재학습해야 합니다.
* 총 학습 횟수: $(n+1) \times K$

따라서 딥러닝과 같이 학습이 오래 걸리는 모델이나, 회귀 문제(Regression)처럼 후보 $y$가 무한히 많은 경우에는 그대로 적용하기 어렵습니다.

## The Benefit
하지만 데이터를 나누지 않고 $n$개를 모두 사용하므로, **예측 집합이 더 작고 효율적(Sharp)**입니다.
Split CP보다 정보 손실이 적어, 데이터가 적은 상황에서는 훨씬 강력한 성능을 발휘합니다.

# Theoretical Guarantee

Full CP 역시 수학적으로 엄밀한 커버리지를 보장합니다.

> **Theorem 5 (Full conformal coverage guarantee)**
>
> 데이터가 교환 가능(Exchangeable)하고 학습 알고리즘이 대칭적(Symmetric)이라면, 다음이 성립한다.
>
> $$ \mathbb{P}(Y_{n+1} \in \mathcal{C}(X_{n+1})) \ge 1-\alpha $$

# Summary

| Feature | Split Conformal (SCP) | Full Conformal (FCP) |
| :--- | :--- | :--- |
| **Data Usage** | Train / Calib 분할 (비효율) | 전체 데이터 사용 (효율) |
| **Computation** | 1회 학습 (빠름) | $K$회 재학습 (매우 느림) |
| **Use Case** | Big Data, Deep Learning | Small Data, Statistically Critical Tasks |
| **Interpretation** | Validation Score Quantile | Permutation Test |

Full CP는 계산 비용 때문에 현대 머신러닝에서는 잘 쓰이지 않지만, **Jackknife+**나 **CV+** (Section 6.2) 같은 기법들의 이론적 토대가 되는 매우 중요한 개념입니다.

---
**Final Note**: 이것으로 "A Gentle Introduction to Conformal Prediction" 논문의 핵심적인 이론과 알고리즘들을 모두 정리했습니다. 이 시리즈가 여러분의 모델에 '신뢰'를 더하는 데 도움이 되기를 바랍니다.