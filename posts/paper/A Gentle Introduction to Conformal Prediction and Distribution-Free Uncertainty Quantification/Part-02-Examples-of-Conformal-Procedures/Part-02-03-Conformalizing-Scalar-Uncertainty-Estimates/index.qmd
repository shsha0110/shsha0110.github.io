---
title: "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.3)"
subtitle: "2.3. Conformalizing Scalar Uncertainty Estimates"
author: "유성현"
date: "2026-01-16"
categories: [Paper Review]
format:
  html:
    toc: true
    number-sections: false
    code-fold: show
---

# Introduction

* 이전 포스트에서 다룬 **Conformalized Quantile Regression (CQR)**은 매우 강력하지만, 두 개의 Quantile을 학습시켜야 한다는 조건이 있습니다.
* 하지만 실무에서는 종종 **평균($\mu$)과 분산($\sigma^2$)**만을 예측하는 더 단순한 모델을 사용하거나, 혹은 모델 앙상블의 분산 등을 불확실성 지표로 삼기도 합니다.

* 이번 포스트에서는 이러한 **단일 스칼라 불확실성 지표(Scalar Uncertainty Estimate)**를 활용하여 통계적으로 유효한 예측 구간을 생성하는 방법을 알아봅니다.

# Heuristic Uncertainty: The Estimated Standard Deviation

가장 흔한 시나리오는 데이터가 정규분포(Gaussian)를 따른다고 가정하고 모델을 학습시키는 것입니다.

$$ Y | X = x \sim \mathcal{N}(\mu(x), \sigma(x)) $$

* 딥러닝 프레임워크(PyTorch 등)에서는 `GaussianNLLLoss`와 같은 손실 함수를 제공하여, 모델이 평균 예측값 $\hat{f}(x)$와 불확실성 예측값 $\hat{\sigma}(x)$를 동시에 학습하도록 돕습니다.

* 하지만 실제 데이터는 **정규분포를 따르지 않는 경우가 대부분**입니다.
* 따라서 모델이 예측한 $\hat{\sigma}(x)$를 그대로 사용하여 $\hat{f}(x) \pm 1.96\hat{\sigma}(x)$와 같은 구간을 만들면, 실제로는 95% 커버리지를 보장할 수 없습니다.

* 우리는 Conformal Prediction을 사용하여 이 부정확한(Heuristic) $\hat{\sigma}(x)$를 **보정(Calibrate)**할 것입니다.

# Generalizing Uncertainty Scalars

* 이 방법은 비단 표준편차뿐만 아니라, **"값이 클수록 불확실하다"**는 의미를 가진 어떤 함수 $u(x)$에도 적용 가능합니다.

* 논문에서는 $u(x)$로 사용할 수 있는 다양한 예시를 제시합니다:
    * 1.  **Residual Prediction**: $|y - \hat{f}(x)|$를 예측하는 별도의 모델 학습.
    * 2.  **Ensemble Variance**: 여러 모델 예측값들의 분산 측정.
    * 3.  **Dropout Variance**: 추론 시 Dropout을 켜고 여러 번 예측했을 때의 분산.
    * 4.  **Input Perturbation**: 입력에 작은 노이즈를 주었을 때 출력의 변화량.

* 우리는 이 $u(x)$를 "불확실성의 크기(Magnitude)"로 간주하고, 이를 스케일링하는 방식(Multiplicative Correction)을 사용합니다.

# The Algorithm

* 알고리즘의 핵심은 **"실제 에러가 불확실성 지표 $u(x)$ 대비 몇 배나 큰가?"**를 측정하는 것입니다.

## Step 1: Define Score Function
* Calibration 데이터 $(X_i, Y_i)$에 대해 다음과 같은 Score를 정의합니다.

$$
s(x, y) = \frac{|y - \hat{f}(x)|}{u(x)}
$$

* **분자 $|y - \hat{f}(x)|$**: 실제 모델의 예측 오차(절대값)입니다.
* **분모 $u(x)$**: 모델이 스스로 추정한 불확실성입니다.
* **의미**: "모델이 예상한 불확실성 대비 실제 오차의 비율"입니다.
    * 만약 모델이 불확실하다고 판단($u(x)$ 큼)했는데 오차도 크다면, $s$는 적절한 값을 가집니다.
    * 만약 모델이 확실하다고 판단($u(x)$ 작음)했는데 오차가 크다면, $s$는 매우 커집니다 (Penalty).

## Step 2: Calibration (Get $\hat{q}$)
* 계산된 점수들 $s_1, \dots, s_n$에 대해 $1-\alpha$ 분위수(Quantile) $\hat{q}$를 구합니다.

$$
\hat{q} = \text{Quantile}\left( \frac{\lceil (n+1)(1-\alpha) \rceil}{n} ; \{s_1, \dots, s_n\} \right)
$$

* 여기서 구해진 $\hat{q}$는 **"불확실성 지표 $u(x)$에 곱해야 할 보정 계수(Multiplier)"** 역할을 합니다.

## Step 3: Construct Prediction Interval
* 새로운 입력 $X_{test}$에 대한 예측 구간은 중심 예측값 $\hat{f}(x)$에서 불확실성 지표 $u(x)$의 $\hat{q}$배만큼 벌려준 구간이 됩니다.

$$
\mathcal{C}(x) = [\hat{f}(x) - \hat{q}u(x), \quad \hat{f}(x) + \hat{q}u(x)]
$$

### 유도 과정 (Derivation of Validity)
* 이 구간이 왜 $1-\alpha$ 커버리지를 보장하는지 살펴보겠습니다.

1.  Calibration 단계에서 $\hat{q}$를 구했으므로, 새로운 데이터에 대해 다음 확률이 성립합니다.
    $$ \mathbb{P}[s(X_{test}, Y_{test}) \le \hat{q}] \ge 1 - \alpha $$
2.  Score $s$의 정의를 대입합니다.
    $$ \mathbb{P}\left[ \frac{|Y_{test} - \hat{f}(X_{test})|}{u(X_{test})} \le \hat{q} \right] \ge 1 - \alpha $$
3.  양변에 $u(X_{test})$를 곱합니다 (불확실성은 항상 양수이므로 부등호 유지).
    $$ \mathbb{P}\left[ |Y_{test} - \hat{f}(X_{test})| \le \hat{q}u(X_{test}) \right] \ge 1 - \alpha $$
4.  절대값을 풉니다.
    $$ \mathbb{P}\left[ -\hat{q}u(X_{test}) \le Y_{test} - \hat{f}(X_{test}) \le \hat{q}u(X_{test}) \right] \ge 1 - \alpha $$
5.  $Y_{test}$에 대해 정리하면 최종 구간이 도출됩니다.
    $$ \mathbb{P}\left[ \hat{f}(X_{test}) - \hat{q}u(X_{test}) \le Y_{test} \le \hat{f}(X_{test}) + \hat{q}u(X_{test}) \right] \ge 1 - \alpha $$

![Figure 8: Uncertainty Scalar를 이용한 예측 구간 시각화. 중심 예측값 $\hat{f}(x)$를 기준으로, 위아래로 $\hat{q}u(x)$만큼 벌어진 대칭적인 구간을 형성한다.](./images/figure8_scalar_visualization.png)

# Implementation

* 이 방법은 구현이 매우 간단하며, PyTorch 등의 라이브러리와 쉽게 결합됩니다.

![Figure 9: Conformalized Uncertainty Scalars 구현을 위한 Python 코드. Score를 계산할 때 예측된 표준편차(model output의 두 번째 컬럼)로 나누어주는 것이 핵심이다.](./images/figure9_scalar_python_code.png)

1.  **Get Scores**: 에러의 절대값을 예측된 표준편차(또는 불확실성 지표)로 나눕니다.
2.  **Get Quantile**: 점수들의 분위수 $\hat{q}$를 계산합니다.
3.  **Deploy**: 예측값 $\pm (\text{불확실성} \times \hat{q})$를 통해 구간을 생성합니다.

# Discussion

* 이 방법은 **Symmetric(대칭적)**인 구간을 생성한다는 특징이 있습니다.
    * **장점**: 구현이 쉽고 직관적입니다. 이미 학습된 모델(Gaussian Output 등)을 그대로 재활용하기 좋습니다.
    * **단점**: CQR과 달리 구간이 항상 예측값을 중심으로 대칭입니다. 실제 데이터 분포가 비대칭(Skewed)이라면 효율적이지 않을 수 있습니다. 또한, $u(x)$가 실제 분위수와 비례하지 않는다면 CQR보다 성능(구간의 평균 길이 등)이 떨어질 수 있습니다.

* 따라서 가능하다면 **Quantile Regression (CQR)**을 사용하는 것이 더 좋지만, 상황이 여의치 않거나 빠른 배포가 필요할 때 이 방법은 훌륭한 대안이 됩니다.

---
**Next Step**: 지금까지는 Black-box 모델의 불확실성을 다루었습니다. 다음 포스트에서는 이 기법들이 실제 복잡한 문제(Computer Vision 등)에서 어떻게 확장되는지 살펴보겠습니다.