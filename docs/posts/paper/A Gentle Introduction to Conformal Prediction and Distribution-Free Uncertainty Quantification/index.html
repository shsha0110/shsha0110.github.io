<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="유성현">
<meta name="dcterms.date" content="2026-01-15">

<title>[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification – shsha0110.github.io</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-5b4ad623e5705c0698d39aec6f10cf02.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<meta name="google-site-verification" content="wnUhrJyUH9DivslRuyTASn9K6KXZlRrojFuwYY1q2hI">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">shsha0110.github.io</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">[Paper Review] A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Paper Review</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>유성현 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 15, 2026</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#from-average-effects-to-individual-effects" id="toc-from-average-effects-to-individual-effects" class="nav-link active" data-scroll-target="#from-average-effects-to-individual-effects">1. From Average Effects To Individual Effects</a>
  <ul class="collapse">
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#the-intuition-classification-example" id="toc-the-intuition-classification-example" class="nav-link" data-scroll-target="#the-intuition-classification-example">The Intuition: Classification Example</a></li>
  <li><a href="#the-conformal-prediction-algorithm" id="toc-the-conformal-prediction-algorithm" class="nav-link" data-scroll-target="#the-conformal-prediction-algorithm">The Conformal Prediction Algorithm</a>
  <ul class="collapse">
  <li><a href="#step-1-calibration-data-준비" id="toc-step-1-calibration-data-준비" class="nav-link" data-scroll-target="#step-1-calibration-data-준비">Step 1: Calibration Data 준비</a></li>
  <li><a href="#step-2-conformal-score-계산" id="toc-step-2-conformal-score-계산" class="nav-link" data-scroll-target="#step-2-conformal-score-계산">Step 2: Conformal Score 계산</a></li>
  <li><a href="#step-3-quantile-구하기" id="toc-step-3-quantile-구하기" class="nav-link" data-scroll-target="#step-3-quantile-구하기">Step 3: Quantile 구하기</a></li>
  <li><a href="#step-4-prediction-set-구성-inference" id="toc-step-4-prediction-set-구성-inference" class="nav-link" data-scroll-target="#step-4-prediction-set-구성-inference">Step 4: Prediction Set 구성 (Inference)</a></li>
  </ul></li>
  <li><a href="#general-instructions-for-conformal-prediction" id="toc-general-instructions-for-conformal-prediction" class="nav-link" data-scroll-target="#general-instructions-for-conformal-prediction">General Instructions for Conformal Prediction</a></li>
  <li><a href="#theoretical-guarantee" id="toc-theoretical-guarantee" class="nav-link" data-scroll-target="#theoretical-guarantee">Theoretical Guarantee</a></li>
  </ul></li>
  <li><a href="#from-point-estimates-to-interval-estimates" id="toc-from-point-estimates-to-interval-estimates" class="nav-link" data-scroll-target="#from-point-estimates-to-interval-estimates">2. From Point Estimates To Interval Estimates</a>
  <ul class="collapse">
  <li><a href="#problem-setup" id="toc-problem-setup" class="nav-link" data-scroll-target="#problem-setup">2.1. Problem Setup</a>
  <ul class="collapse">
  <li><a href="#introduction-why-adaptive" id="toc-introduction-why-adaptive" class="nav-link" data-scroll-target="#introduction-why-adaptive">Introduction: Why Adaptive?</a></li>
  <li><a href="#the-intuition-water-filling-approach" id="toc-the-intuition-water-filling-approach" class="nav-link" data-scroll-target="#the-intuition-water-filling-approach">The Intuition: “Water-filling” Approach</a></li>
  <li><a href="#mathematical-formulation" id="toc-mathematical-formulation" class="nav-link" data-scroll-target="#mathematical-formulation">Mathematical Formulation</a></li>
  <li><a href="#implementation-steps" id="toc-implementation-steps" class="nav-link" data-scroll-target="#implementation-steps">Implementation Steps</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  </ul></li>
  <li><a href="#traditional-inferential-targets" id="toc-traditional-inferential-targets" class="nav-link" data-scroll-target="#traditional-inferential-targets">2.2. Traditional Inferential Targets</a>
  <ul class="collapse">
  <li><a href="#introduction-1" id="toc-introduction-1" class="nav-link" data-scroll-target="#introduction-1">Introduction</a></li>
  <li><a href="#base-model-quantile-regression" id="toc-base-model-quantile-regression" class="nav-link" data-scroll-target="#base-model-quantile-regression">Base Model: Quantile Regression</a></li>
  <li><a href="#the-problem-why-conformalize" id="toc-the-problem-why-conformalize" class="nav-link" data-scroll-target="#the-problem-why-conformalize">The Problem: Why Conformalize?</a></li>
  <li><a href="#conformalized-quantile-regression-algorithm" id="toc-conformalized-quantile-regression-algorithm" class="nav-link" data-scroll-target="#conformalized-quantile-regression-algorithm">Conformalized Quantile Regression Algorithm</a></li>
  <li><a href="#implementation" id="toc-implementation" class="nav-link" data-scroll-target="#implementation">Implementation</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul></li>
  <li><a href="#coverage-of-interval-estimates" id="toc-coverage-of-interval-estimates" class="nav-link" data-scroll-target="#coverage-of-interval-estimates">2.3. Coverage of Interval Estimates</a>
  <ul class="collapse">
  <li><a href="#introduction-2" id="toc-introduction-2" class="nav-link" data-scroll-target="#introduction-2">Introduction</a></li>
  <li><a href="#heuristic-uncertainty-the-estimated-standard-deviation" id="toc-heuristic-uncertainty-the-estimated-standard-deviation" class="nav-link" data-scroll-target="#heuristic-uncertainty-the-estimated-standard-deviation">Heuristic Uncertainty: The Estimated Standard Deviation</a></li>
  <li><a href="#generalizing-uncertainty-scalars" id="toc-generalizing-uncertainty-scalars" class="nav-link" data-scroll-target="#generalizing-uncertainty-scalars">Generalizing Uncertainty Scalars</a></li>
  <li><a href="#the-algorithm" id="toc-the-algorithm" class="nav-link" data-scroll-target="#the-algorithm">The Algorithm</a></li>
  <li><a href="#implementation-1" id="toc-implementation-1" class="nav-link" data-scroll-target="#implementation-1">Implementation</a></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">Discussion</a></li>
  </ul></li>
  <li><a href="#conformalizing-bayes" id="toc-conformalizing-bayes" class="nav-link" data-scroll-target="#conformalizing-bayes">2.4. Conformalizing Bayes</a>
  <ul class="collapse">
  <li><a href="#introduction-3" id="toc-introduction-3" class="nav-link" data-scroll-target="#introduction-3">Introduction</a></li>
  <li><a href="#the-bayesian-ideal-vs.-reality" id="toc-the-bayesian-ideal-vs.-reality" class="nav-link" data-scroll-target="#the-bayesian-ideal-vs.-reality">The Bayesian Ideal vs.&nbsp;Reality</a></li>
  <li><a href="#the-algorithm-1" id="toc-the-algorithm-1" class="nav-link" data-scroll-target="#the-algorithm-1">The Algorithm</a></li>
  <li><a href="#mathematical-derivation-validity" id="toc-mathematical-derivation-validity" class="nav-link" data-scroll-target="#mathematical-derivation-validity">Mathematical Derivation &amp; Validity</a></li>
  <li><a href="#why-is-this-useful-bayes-optimality" id="toc-why-is-this-useful-bayes-optimality" class="nav-link" data-scroll-target="#why-is-this-useful-bayes-optimality">Why is this useful? (Bayes Optimality)</a></li>
  <li><a href="#summary-1" id="toc-summary-1" class="nav-link" data-scroll-target="#summary-1">Summary</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#from-observables-to-counterfactuals" id="toc-from-observables-to-counterfactuals" class="nav-link" data-scroll-target="#from-observables-to-counterfactuals">3. From Observables To Counterfactuals</a>
  <ul class="collapse">
  <li><a href="#evaluating-adaptivity" id="toc-evaluating-adaptivity" class="nav-link" data-scroll-target="#evaluating-adaptivity">3.1. Evaluating Adaptivity</a>
  <ul class="collapse">
  <li><a href="#introduction-4" id="toc-introduction-4" class="nav-link" data-scroll-target="#introduction-4">Introduction</a></li>
  <li><a href="#metric-1-set-size-distribution" id="toc-metric-1-set-size-distribution" class="nav-link" data-scroll-target="#metric-1-set-size-distribution">Metric 1: Set Size Distribution</a></li>
  <li><a href="#metric-2-conditional-coverage" id="toc-metric-2-conditional-coverage" class="nav-link" data-scroll-target="#metric-2-conditional-coverage">Metric 2: Conditional Coverage</a></li>
  <li><a href="#summary-2" id="toc-summary-2" class="nav-link" data-scroll-target="#summary-2">Summary</a></li>
  </ul></li>
  <li><a href="#the-effect-of-the-size-of-the-calibration-set" id="toc-the-effect-of-the-size-of-the-calibration-set" class="nav-link" data-scroll-target="#the-effect-of-the-size-of-the-calibration-set">3.2. The Effect of the Size of the Calibration Set</a>
  <ul class="collapse">
  <li><a href="#introduction-5" id="toc-introduction-5" class="nav-link" data-scroll-target="#introduction-5">Introduction</a></li>
  <li><a href="#validity-vs.-stability" id="toc-validity-vs.-stability" class="nav-link" data-scroll-target="#validity-vs.-stability">Validity vs.&nbsp;Stability</a></li>
  <li><a href="#mathematical-derivation-beta-distribution" id="toc-mathematical-derivation-beta-distribution" class="nav-link" data-scroll-target="#mathematical-derivation-beta-distribution">Mathematical Derivation: Beta Distribution</a></li>
  <li><a href="#visualizing-the-effect-of-n" id="toc-visualizing-the-effect-of-n" class="nav-link" data-scroll-target="#visualizing-the-effect-of-n">Visualizing the Effect of <span class="math inline">\(n\)</span></a></li>
  <li><a href="#practical-guideline-the-n1000-rule" id="toc-practical-guideline-the-n1000-rule" class="nav-link" data-scroll-target="#practical-guideline-the-n1000-rule">Practical Guideline: The “n=1000” Rule</a></li>
  <li><a href="#summary-3" id="toc-summary-3" class="nav-link" data-scroll-target="#summary-3">Summary</a></li>
  </ul></li>
  <li><a href="#checking-for-correct-coverage" id="toc-checking-for-correct-coverage" class="nav-link" data-scroll-target="#checking-for-correct-coverage">3.3. Checking for Correct Coverage</a>
  <ul class="collapse">
  <li><a href="#introduction-6" id="toc-introduction-6" class="nav-link" data-scroll-target="#introduction-6">Introduction</a></li>
  <li><a href="#methodology-repeated-experiments" id="toc-methodology-repeated-experiments" class="nav-link" data-scroll-target="#methodology-repeated-experiments">Methodology: Repeated Experiments</a></li>
  <li><a href="#the-practical-challenge-limited-data" id="toc-the-practical-challenge-limited-data" class="nav-link" data-scroll-target="#the-practical-challenge-limited-data">The Practical Challenge: Limited Data</a></li>
  <li><a href="#implementation-2" id="toc-implementation-2" class="nav-link" data-scroll-target="#implementation-2">Implementation</a></li>
  <li><a href="#interpretation-of-results" id="toc-interpretation-of-results" class="nav-link" data-scroll-target="#interpretation-of-results">Interpretation of Results</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#from-counterfactuals-to-treatment-effects" id="toc-from-counterfactuals-to-treatment-effects" class="nav-link" data-scroll-target="#from-counterfactuals-to-treatment-effects">4. From Counterfactuals to Treatment Effects</a>
  <ul class="collapse">
  <li><a href="#group-balanced-conformal-prediction" id="toc-group-balanced-conformal-prediction" class="nav-link" data-scroll-target="#group-balanced-conformal-prediction">4.1. Group-Balanced Conformal Prediction</a>
  <ul class="collapse">
  <li><a href="#introduction-the-fairness-problem" id="toc-introduction-the-fairness-problem" class="nav-link" data-scroll-target="#introduction-the-fairness-problem">Introduction: The Fairness Problem</a></li>
  <li><a href="#problem-formulation" id="toc-problem-formulation" class="nav-link" data-scroll-target="#problem-formulation">Problem Formulation</a></li>
  <li><a href="#the-algorithm-2" id="toc-the-algorithm-2" class="nav-link" data-scroll-target="#the-algorithm-2">The Algorithm</a></li>
  <li><a href="#theoretical-guarantee-1" id="toc-theoretical-guarantee-1" class="nav-link" data-scroll-target="#theoretical-guarantee-1">Theoretical Guarantee</a></li>
  <li><a href="#practical-note" id="toc-practical-note" class="nav-link" data-scroll-target="#practical-note">Practical Note</a></li>
  </ul></li>
  <li><a href="#class-conditional-conformal-prediction" id="toc-class-conditional-conformal-prediction" class="nav-link" data-scroll-target="#class-conditional-conformal-prediction">4.2. Class-Conditional Conformal Prediction</a>
  <ul class="collapse">
  <li><a href="#introduction-the-problem-with-imbalanced-classes" id="toc-introduction-the-problem-with-imbalanced-classes" class="nav-link" data-scroll-target="#introduction-the-problem-with-imbalanced-classes">Introduction: The Problem with Imbalanced Classes</a></li>
  <li><a href="#problem-formulation-1" id="toc-problem-formulation-1" class="nav-link" data-scroll-target="#problem-formulation-1">Problem Formulation</a></li>
  <li><a href="#the-algorithm-3" id="toc-the-algorithm-3" class="nav-link" data-scroll-target="#the-algorithm-3">The Algorithm</a></li>
  <li><a href="#comparison-group-balanced-vs.-class-conditional" id="toc-comparison-group-balanced-vs.-class-conditional" class="nav-link" data-scroll-target="#comparison-group-balanced-vs.-class-conditional">Comparison: Group-Balanced vs.&nbsp;Class-Conditional</a></li>
  <li><a href="#theoretical-guarantee-2" id="toc-theoretical-guarantee-2" class="nav-link" data-scroll-target="#theoretical-guarantee-2">Theoretical Guarantee</a></li>
  <li><a href="#conclusion-1" id="toc-conclusion-1" class="nav-link" data-scroll-target="#conclusion-1">Conclusion</a></li>
  </ul></li>
  <li><a href="#conformal-risk-control" id="toc-conformal-risk-control" class="nav-link" data-scroll-target="#conformal-risk-control">4.3. Conformal Risk Control</a>
  <ul class="collapse">
  <li><a href="#introduction-beyond-coverage" id="toc-introduction-beyond-coverage" class="nav-link" data-scroll-target="#introduction-beyond-coverage">Introduction: Beyond Coverage</a></li>
  <li><a href="#problem-formulation-2" id="toc-problem-formulation-2" class="nav-link" data-scroll-target="#problem-formulation-2">Problem Formulation</a></li>
  <li><a href="#the-algorithm-4" id="toc-the-algorithm-4" class="nav-link" data-scroll-target="#the-algorithm-4">The Algorithm</a></li>
  <li><a href="#example-multilabel-classification" id="toc-example-multilabel-classification" class="nav-link" data-scroll-target="#example-multilabel-classification">Example: Multilabel Classification</a></li>
  <li><a href="#theoretical-guarantee-3" id="toc-theoretical-guarantee-3" class="nav-link" data-scroll-target="#theoretical-guarantee-3">Theoretical Guarantee</a></li>
  </ul></li>
  <li><a href="#outlier-detection" id="toc-outlier-detection" class="nav-link" data-scroll-target="#outlier-detection">4.4. Outlier Detection</a>
  <ul class="collapse">
  <li><a href="#introduction-unsupervised-setting" id="toc-introduction-unsupervised-setting" class="nav-link" data-scroll-target="#introduction-unsupervised-setting">Introduction: Unsupervised Setting</a></li>
  <li><a href="#problem-formulation-3" id="toc-problem-formulation-3" class="nav-link" data-scroll-target="#problem-formulation-3">Problem Formulation</a></li>
  <li><a href="#the-algorithm-5" id="toc-the-algorithm-5" class="nav-link" data-scroll-target="#the-algorithm-5">The Algorithm</a></li>
  <li><a href="#theoretical-guarantee-interpretation" id="toc-theoretical-guarantee-interpretation" class="nav-link" data-scroll-target="#theoretical-guarantee-interpretation">Theoretical Guarantee &amp; Interpretation</a></li>
  <li><a href="#conclusion-2" id="toc-conclusion-2" class="nav-link" data-scroll-target="#conclusion-2">Conclusion</a></li>
  </ul></li>
  <li><a href="#conformal-prediction-under-covariate-shift" id="toc-conformal-prediction-under-covariate-shift" class="nav-link" data-scroll-target="#conformal-prediction-under-covariate-shift">4.5. Conformal Prediction Under Covariate Shift</a>
  <ul class="collapse">
  <li><a href="#introduction-when-the-i.i.d.-assumption-fails" id="toc-introduction-when-the-i.i.d.-assumption-fails" class="nav-link" data-scroll-target="#introduction-when-the-i.i.d.-assumption-fails">Introduction: When the i.i.d. Assumption Fails</a></li>
  <li><a href="#problem-formulation-covariate-shift" id="toc-problem-formulation-covariate-shift" class="nav-link" data-scroll-target="#problem-formulation-covariate-shift">Problem Formulation: Covariate Shift</a></li>
  <li><a href="#the-solution-weighted-conformal-prediction" id="toc-the-solution-weighted-conformal-prediction" class="nav-link" data-scroll-target="#the-solution-weighted-conformal-prediction">The Solution: Weighted Conformal Prediction</a></li>
  <li><a href="#intuition-how-quantile-changes" id="toc-intuition-how-quantile-changes" class="nav-link" data-scroll-target="#intuition-how-quantile-changes">Intuition: How Quantile Changes</a></li>
  <li><a href="#theorem-guarantee" id="toc-theorem-guarantee" class="nav-link" data-scroll-target="#theorem-guarantee">Theorem &amp; Guarantee</a></li>
  <li><a href="#conclusion-3" id="toc-conclusion-3" class="nav-link" data-scroll-target="#conclusion-3">Conclusion</a></li>
  </ul></li>
  <li><a href="#conformal-prediction-under-distribution-shift" id="toc-conformal-prediction-under-distribution-shift" class="nav-link" data-scroll-target="#conformal-prediction-under-distribution-shift">4.6. Conformal Prediction Under Distribution Shift</a>
  <ul class="collapse">
  <li><a href="#introduction-when-data-changes-over-time" id="toc-introduction-when-data-changes-over-time" class="nav-link" data-scroll-target="#introduction-when-data-changes-over-time">Introduction: When Data Changes Over Time</a></li>
  <li><a href="#the-method-weighted-conformal-prediction-again" id="toc-the-method-weighted-conformal-prediction-again" class="nav-link" data-scroll-target="#the-method-weighted-conformal-prediction-again">The Method: Weighted Conformal Prediction (Again)</a></li>
  <li><a href="#theoretical-analysis" id="toc-theoretical-analysis" class="nav-link" data-scroll-target="#theoretical-analysis">Theoretical Analysis</a></li>
  <li><a href="#practical-consideration-effective-sample-size" id="toc-practical-consideration-effective-sample-size" class="nav-link" data-scroll-target="#practical-consideration-effective-sample-size">Practical Consideration: Effective Sample Size</a></li>
  <li><a href="#conclusion-4" id="toc-conclusion-4" class="nav-link" data-scroll-target="#conclusion-4">Conclusion</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#worked-examples" id="toc-worked-examples" class="nav-link" data-scroll-target="#worked-examples">5. Worked Examples</a>
  <ul class="collapse">
  <li><a href="#introduction-7" id="toc-introduction-7" class="nav-link" data-scroll-target="#introduction-7">Introduction</a></li>
  <li><a href="#multilabel-classification-with-fnr-control" id="toc-multilabel-classification-with-fnr-control" class="nav-link" data-scroll-target="#multilabel-classification-with-fnr-control">1. Multilabel Classification with FNR Control</a>
  <ul class="collapse">
  <li><a href="#problem-setup-1" id="toc-problem-setup-1" class="nav-link" data-scroll-target="#problem-setup-1">Problem Setup</a></li>
  <li><a href="#methodology-conformal-risk-control" id="toc-methodology-conformal-risk-control" class="nav-link" data-scroll-target="#methodology-conformal-risk-control">Methodology: Conformal Risk Control</a></li>
  </ul></li>
  <li><a href="#tumor-segmentation" id="toc-tumor-segmentation" class="nav-link" data-scroll-target="#tumor-segmentation">2. Tumor Segmentation</a>
  <ul class="collapse">
  <li><a href="#problem-setup-2" id="toc-problem-setup-2" class="nav-link" data-scroll-target="#problem-setup-2">Problem Setup</a></li>
  <li><a href="#methodology" id="toc-methodology" class="nav-link" data-scroll-target="#methodology">Methodology</a></li>
  </ul></li>
  <li><a href="#weather-prediction-time-series" id="toc-weather-prediction-time-series" class="nav-link" data-scroll-target="#weather-prediction-time-series">3. Weather Prediction (Time-Series)</a>
  <ul class="collapse">
  <li><a href="#problem-setup-3" id="toc-problem-setup-3" class="nav-link" data-scroll-target="#problem-setup-3">Problem Setup</a></li>
  <li><a href="#methodology-weighted-conformal-prediction" id="toc-methodology-weighted-conformal-prediction" class="nav-link" data-scroll-target="#methodology-weighted-conformal-prediction">Methodology: Weighted Conformal Prediction</a></li>
  </ul></li>
  <li><a href="#toxic-comment-identification-outlier-detection" id="toc-toxic-comment-identification-outlier-detection" class="nav-link" data-scroll-target="#toxic-comment-identification-outlier-detection">4. Toxic Comment Identification (Outlier Detection)</a>
  <ul class="collapse">
  <li><a href="#problem-setup-4" id="toc-problem-setup-4" class="nav-link" data-scroll-target="#problem-setup-4">Problem Setup</a></li>
  <li><a href="#methodology-conformal-outlier-detection" id="toc-methodology-conformal-outlier-detection" class="nav-link" data-scroll-target="#methodology-conformal-outlier-detection">Methodology: Conformal Outlier Detection</a></li>
  </ul></li>
  <li><a href="#selective-classification-abstention" id="toc-selective-classification-abstention" class="nav-link" data-scroll-target="#selective-classification-abstention">5. Selective Classification (Abstention)</a>
  <ul class="collapse">
  <li><a href="#problem-setup-5" id="toc-problem-setup-5" class="nav-link" data-scroll-target="#problem-setup-5">Problem Setup</a></li>
  <li><a href="#methodology-learn-then-test" id="toc-methodology-learn-then-test" class="nav-link" data-scroll-target="#methodology-learn-then-test">Methodology: Learn then Test</a></li>
  </ul></li>
  <li><a href="#conclusion-5" id="toc-conclusion-5" class="nav-link" data-scroll-target="#conclusion-5">Conclusion</a></li>
  </ul></li>
  <li><a href="#full-conformal-prediction" id="toc-full-conformal-prediction" class="nav-link" data-scroll-target="#full-conformal-prediction">6. Full Conformal Prediction</a>
  <ul class="collapse">
  <li><a href="#introduction-the-efficiency-trade-off" id="toc-introduction-the-efficiency-trade-off" class="nav-link" data-scroll-target="#introduction-the-efficiency-trade-off">Introduction: The Efficiency Trade-off</a></li>
  <li><a href="#the-core-idea-what-if" id="toc-the-core-idea-what-if" class="nav-link" data-scroll-target="#the-core-idea-what-if">The Core Idea: “What if?”</a></li>
  <li><a href="#the-algorithm-6" id="toc-the-algorithm-6" class="nav-link" data-scroll-target="#the-algorithm-6">The Algorithm</a>
  <ul class="collapse">
  <li><a href="#step-1-loop-over-all-possible-labels" id="toc-step-1-loop-over-all-possible-labels" class="nav-link" data-scroll-target="#step-1-loop-over-all-possible-labels">Step 1: Loop over all possible labels</a></li>
  <li><a href="#step-2-augment-and-retrain" id="toc-step-2-augment-and-retrain" class="nav-link" data-scroll-target="#step-2-augment-and-retrain">Step 2: Augment and Retrain</a></li>
  <li><a href="#step-3-compute-scores" id="toc-step-3-compute-scores" class="nav-link" data-scroll-target="#step-3-compute-scores">Step 3: Compute Scores</a></li>
  <li><a href="#step-4-compute-quantile" id="toc-step-4-compute-quantile" class="nav-link" data-scroll-target="#step-4-compute-quantile">Step 4: Compute Quantile</a></li>
  <li><a href="#step-5-construct-prediction-set" id="toc-step-5-construct-prediction-set" class="nav-link" data-scroll-target="#step-5-construct-prediction-set">Step 5: Construct Prediction Set</a></li>
  </ul></li>
  <li><a href="#statistical-interpretation-permutation-test" id="toc-statistical-interpretation-permutation-test" class="nav-link" data-scroll-target="#statistical-interpretation-permutation-test">Statistical Interpretation: Permutation Test</a>
  <ul class="collapse">
  <li><a href="#the-null-hypothesis-of-exchangeability" id="toc-the-null-hypothesis-of-exchangeability" class="nav-link" data-scroll-target="#the-null-hypothesis-of-exchangeability">The Null Hypothesis of Exchangeability</a></li>
  <li><a href="#the-test-statistic-p-value" id="toc-the-test-statistic-p-value" class="nav-link" data-scroll-target="#the-test-statistic-p-value">The Test Statistic &amp; P-value</a></li>
  <li><a href="#decision-rule-validity-theorem" id="toc-decision-rule-validity-theorem" class="nav-link" data-scroll-target="#decision-rule-validity-theorem">Decision Rule (Validity Theorem)</a></li>
  </ul></li>
  <li><a href="#computational-cost-vs.-statistical-efficiency" id="toc-computational-cost-vs.-statistical-efficiency" class="nav-link" data-scroll-target="#computational-cost-vs.-statistical-efficiency">Computational Cost vs.&nbsp;Statistical Efficiency</a>
  <ul class="collapse">
  <li><a href="#the-cost" id="toc-the-cost" class="nav-link" data-scroll-target="#the-cost">The Cost</a></li>
  <li><a href="#the-benefit" id="toc-the-benefit" class="nav-link" data-scroll-target="#the-benefit">The Benefit</a></li>
  </ul></li>
  <li><a href="#theoretical-guarantee-4" id="toc-theoretical-guarantee-4" class="nav-link" data-scroll-target="#theoretical-guarantee-4">Theoretical Guarantee</a></li>
  <li><a href="#summary-4" id="toc-summary-4" class="nav-link" data-scroll-target="#summary-4">Summary</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="from-average-effects-to-individual-effects" class="level1">
<h1>1. From Average Effects To Individual Effects</h1>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<ul>
<li><p>딥러닝 모델과 같은 Black-box 머신러닝 모델들은 의료 진단이나 자율 주행과 같은 High-risk 환경에서 일상적으로 사용되고 있습니다.</p></li>
<li><p>하지만 이러한 모델들은 종종 잘못된 예측을 내놓으면서도 높은 확신(Overconfidence)을 보이는 문제가 있습니다.</p></li>
<li><p><strong>Conformal Prediction(CP)</strong>는 이러한 모델의 예측에 대해 통계적으로 엄밀한 불확실성 구간(Uncertainty Sets/Intervals)을 생성하는 방법론입니다.</p></li>
<li><p>CP의 가장 큰 장점은 다음과 같습니다:</p>
<ol type="1">
<li><strong>Distribution-free</strong>: 데이터의 분포에 대한 가정(가우시안 분포 등)이 필요하지 않습니다.</li>
<li><strong>Model-agnostic</strong>: 뉴럴 네트워크를 포함한 어떤 학습된 모델(Pre-trained model)에도 적용 가능합니다.</li>
<li><strong>Finite-sample guarantee</strong>: 무한한 데이터가 아닌, 유한한 샘플 수에서도 통계적 커버리지(<span class="math inline">\(1-\alpha\)</span>)를 보장합니다.</li>
</ol></li>
<li><p>이 글에서는 논문 <em>“A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification”</em>의 핵심 내용을 바탕으로 CP의 원리와 구현 방법을 정리합니다.</p></li>
</ul>
</section>
<section id="the-intuition-classification-example" class="level2">
<h2 class="anchored" data-anchor-id="the-intuition-classification-example">The Intuition: Classification Example</h2>
<ul>
<li>CP를 이해하기 위해 가장 간단한 이미지 분류(Classification) 문제를 예로 들어보겠습니다.</li>
<li><span class="math inline">\(K\)</span>개의 클래스를 분류하는 모델 <span class="math inline">\(\hat{f}\)</span>가 있다고 가정합시다.</li>
<li>이 모델은 입력 이미지 <span class="math inline">\(x\)</span>에 대해 각 클래스에 속할 확률(Softmax score)을 출력합니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/figure1_prediction_sets.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: ImageNet 데이터셋에 대한 Prediction Set 예시. 다람쥐(Squirrel)와 같이 모델이 헷갈리는 이미지에 대해서는 여러 클래스를 포함하는 Set을 출력하여 정답을 포함할 확률을 보장한다.</figcaption>
</figure>
</div>
<ul>
<li><p>우리의 목표는 단순히 가장 높은 확률을 가진 하나의 라벨을 뱉는 것이 아니라, <strong>정답 라벨 <span class="math inline">\(Y\)</span>를 <span class="math inline">\(1-\alpha\)</span>(예: 90%)의 확률로 포함하는 후보 라벨들의 집합(Set) <span class="math inline">\(\mathcal{C}(X)\)</span></strong>를 만드는 것입니다. <span class="math display">\[
1-\alpha \le \mathbb{P}(Y_{test} \in \mathcal{C}(X_{test})) \le 1-\alpha + \frac{1}{n+1}
\]</span></p></li>
<li><p>위 식은 <strong>Marginal Coverage</strong>라고 불리며, Calibration 데이터와 테스트 데이터의 무작위성을 평균했을 때 예측 집합이 정답을 포함할 확률이 <span class="math inline">\(1-\alpha\)</span> 이상임을 의미합니다.</p></li>
</ul>
</section>
<section id="the-conformal-prediction-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="the-conformal-prediction-algorithm">The Conformal Prediction Algorithm</h2>
<ul>
<li>CP는 복잡한 최적화 과정 없이 <strong>Calibration Step</strong>이라고 불리는 간단한 절차를 통해 수행됩니다.</li>
<li>핵심은 모델이 학습 과정에서 보지 못한 <strong>Calibration Data</strong> (약 500개 정도의 소규모 데이터)를 사용하는 것입니다.</li>
</ul>
<section id="step-1-calibration-data-준비" class="level3">
<h3 class="anchored" data-anchor-id="step-1-calibration-data-준비">Step 1: Calibration Data 준비</h3>
<ul>
<li>학습에 사용되지 않은 <span class="math inline">\(n\)</span>개의 데이터 쌍 <span class="math inline">\((X_1, Y_1), \dots, (X_n, Y_n)\)</span>을 준비합니다.</li>
<li>이 데이터는 교환 가능(Exchangeable), 일반적으로는 i.i.d. 가정만 만족하면 됩니다.</li>
</ul>
</section>
<section id="step-2-conformal-score-계산" class="level3">
<h3 class="anchored" data-anchor-id="step-2-conformal-score-계산">Step 2: Conformal Score 계산</h3>
<ul>
<li>각 Calibration 데이터에 대해 모델이 얼마나 “잘못” 예측했는지를 나타내는 <strong>Conformal Score</strong> <span class="math inline">\(s_i\)</span>를 계산합니다.</li>
<li>분류 문제에서 가장 일반적인 점수 함수는 다음과 같습니다:</li>
</ul>
<p><span class="math display">\[
s_i = 1 - \hat{f}(X_i)_{Y_i}
\]</span></p>
<ul>
<li>여기서 <span class="math inline">\(\hat{f}(X_i)_{Y_i}\)</span>는 정답 클래스 <span class="math inline">\(Y_i\)</span>에 대한 모델의 Softmax 확률입니다.</li>
<li>모델이 정답을 확신할수록 <span class="math inline">\(\hat{f}(X_i)_{Y_i} \approx 1\)</span>이므로 점수 <span class="math inline">\(s_i\)</span>는 0에 가까워집니다.</li>
<li>모델이 틀렸거나 불확실할수록 점수 <span class="math inline">\(s_i\)</span>는 커집니다.</li>
</ul>
</section>
<section id="step-3-quantile-구하기" class="level3">
<h3 class="anchored" data-anchor-id="step-3-quantile-구하기">Step 3: Quantile 구하기</h3>
<ul>
<li><p>우리는 새로운 데이터가 들어왔을 때, 모델의 불확실성(Score)이 어느 수준 이하이어야 안심할 수 있는지를 결정해야 합니다.</p></li>
<li><p>이를 위해 계산된 점수들 <span class="math inline">\(s_1, \dots, s_n\)</span>의 분포에서 <strong><span class="math inline">\(\hat{q}\)</span> (Quantile)</strong> 값을 찾습니다.</p></li>
<li><p>엄밀한 커버리지를 보장하기 위해 다음과 같은 보정된 분위수(Adjusted Quantile)를 사용합니다:</p></li>
</ul>
<p><span class="math display">\[
\hat{q} = \text{Quantile}\left( \frac{\lceil (n+1)(1-\alpha) \rceil}{n} ; \{s_1, \dots, s_n\} \right)
\]</span></p>
<ul>
<li>이 <span class="math inline">\(\hat{q}\)</span> 값은 “전체 데이터의 <span class="math inline">\((1-\alpha)\)</span> 비율이 이 점수보다 낮다”는 경계선 역할을 합니다.</li>
</ul>
</section>
<section id="step-4-prediction-set-구성-inference" class="level3">
<h3 class="anchored" data-anchor-id="step-4-prediction-set-구성-inference">Step 4: Prediction Set 구성 (Inference)</h3>
<ul>
<li>이제 새로운 테스트 데이터 <span class="math inline">\(X_{test}\)</span>가 들어오면, 예측 집합 <span class="math inline">\(\mathcal{C}(X_{test})\)</span>를 다음과 같이 구성합니다:</li>
</ul>
<p><span class="math display">\[
\mathcal{C}(X_{test}) = \{ y : 1 - \hat{f}(X_{test})_y \le \hat{q} \} = \{ y : \hat{f}(X_{test})_y \ge 1 - \hat{q} \}
\]</span></p>
<ul>
<li>즉, 모델의 예측 확률이 <span class="math inline">\(1-\hat{q}\)</span> 이상인 모든 클래스를 후보로 포함시킵니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/figure2_algorithm_process.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: Conformal Prediction의 전체 프로세스 도식화 및 Python 코드 예시. (1) Score 계산, (2) Quantile 계산, (3) Prediction Set 구성의 3단계로 이루어진다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="general-instructions-for-conformal-prediction" class="level2">
<h2 class="anchored" data-anchor-id="general-instructions-for-conformal-prediction">General Instructions for Conformal Prediction</h2>
<ul>
<li>앞서 설명한 분류 문제는 CP의 특수한 사례일 뿐입니다.</li>
<li>CP는 Regression, Segmentation 등 어떤 문제에도 적용할 수 있는 일반적인 프레임워크입니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/diagram_heuristic_to_rigorous.png" class="img-fluid figure-img"></p>
<figcaption>Diagram 1: Heuristic Notion of Uncertainty를 CP를 통해 Rigorous Uncertainty로 변환하는 과정</figcaption>
</figure>
</div>
<p>일반화된 CP 알고리즘은 다음과 같습니다:</p>
<ol type="1">
<li><p><strong>Heuristic Notion of Uncertainty 식별</strong>: Pre-trained 모델을 사용하여 불확실성을 나타내는 지표를 정의합니다.</p></li>
<li><p><strong>Score Function 정의</strong>: <span class="math inline">\(s(x, y) \in \mathbb{R}\)</span>. 점수가 클수록 모델의 예측 <span class="math inline">\(x\)</span>와 실제값 <span class="math inline">\(y\)</span> 사이의 불일치(Error)가 큼을 의미해야 합니다.</p></li>
<li><p><strong>Quantile <span class="math inline">\(\hat{q}\)</span> 계산</strong>: Calibration 데이터셋에 대해 Score를 계산하고, <span class="math inline">\(\frac{\lceil(n+1)(1-\alpha)\rceil}{n}\)</span> 분위수를 구합니다.</p></li>
<li><p><strong>Prediction Set 생성</strong>: <span class="math display">\[ \mathcal{C}(X_{test}) = \{ y : s(X_{test}, y) \le \hat{q} \} \]</span> 이 집합은 Score가 <span class="math inline">\(\hat{q}\)</span>보다 작거나 같은 모든 <span class="math inline">\(y\)</span>를 포함합니다.</p></li>
</ol>
</section>
<section id="theoretical-guarantee" class="level2">
<h2 class="anchored" data-anchor-id="theoretical-guarantee">Theoretical Guarantee</h2>
<ul>
<li>Conformal Prediction이 강력한 이유는 다음의 정리에 의해 <strong>수학적으로 증명된 커버리지</strong>를 제공하기 때문입니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Theorem 1 (Conformal Coverage Guarantee)</strong></p>
<p>Calibration 데이터 <span class="math inline">\((X_i, Y_i)_{i=1}^n\)</span>와 테스트 데이터 <span class="math inline">\((X_{test}, Y_{test})\)</span>가 i.i.d.라고 가정하자. 위에서 정의한 절차에 따라 <span class="math inline">\(\hat{q}\)</span>를 계산하고 집합 <span class="math inline">\(\mathcal{C}(X_{test})\)</span>를 구성하면, 다음이 성립한다:</p>
<p><span class="math display">\[ P(Y_{test} \in \mathcal{C}(X_{test})) \ge 1 - \alpha \]</span></p>
</blockquote>
<ul>
<li>이 정리는 모델이 아무리 엉터리(Bad)여도 성립합니다.</li>
<li>하지만 <strong>“유용한(Useful)”</strong> 예측 집합을 얻기 위해서는 Score Function의 설계가 중요합니다.
<ul>
<li>Score Function이 불확실성을 잘 반영한다면: 쉬운 입력에는 집합 크기가 작고, 어려운 입력에는 커집니다 (Adaptive).</li>
<li>Score Function이 랜덤하다면: 집합 크기가 불필요하게 커지지만, 여전히 <span class="math inline">\(1-\alpha\)</span> 커버리지는 만족합니다.</li>
</ul></li>
<li>따라서 CP의 성패는 <strong>“좋은 Score Function을 어떻게 정의하느냐”</strong>에 달려 있습니다.</li>
</ul>
</section>
</section>
<section id="from-point-estimates-to-interval-estimates" class="level1">
<h1>2. From Point Estimates To Interval Estimates</h1>
<section id="problem-setup" class="level2">
<h2 class="anchored" data-anchor-id="problem-setup">2.1. Problem Setup</h2>
<section id="introduction-why-adaptive" class="level3">
<h3 class="anchored" data-anchor-id="introduction-why-adaptive">Introduction: Why Adaptive?</h3>
<ul>
<li><p>이전 포스트(Section 1)에서 다룬 기본적인 Conformal Prediction 방법은 단순하고 강력하지만 한 가지 단점이 있습니다.</p></li>
<li><p>기존 방식(Naive method)은 단순히 <span class="math inline">\(1 - \hat{f}(x)_y\)</span>를 점수로 사용하기 때문에, 모든 클래스에 대해 고정된 임계값(Threshold)을 적용하는 경향이 있습니다.</p></li>
<li><p>이로 인해 다음과 같은 문제가 발생합니다:</p>
<ul>
<li><ol type="1">
<li><strong>Hard Inputs (어려운 이미지)</strong>: 모델이 헷갈려하는 경우에도 예측 집합이 충분히 커지지 않아 정답을 놓칠 수 있습니다 (Under-coverage).</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Easy Inputs (쉬운 이미지)</strong>: 모델이 확신하는 경우에도 예측 집합이 불필요하게 클 수 있습니다 (Over-coverage).</li>
</ol></li>
</ul></li>
<li><p>우리는 입력 이미지의 난이도에 따라 <strong>어려우면 집합을 크게, 쉬우면 집합을 작게</strong> 만드는 <strong>Adaptive Prediction Sets (APS)</strong> 기법을 도입하여 이 문제를 해결할 것입니다.</p></li>
</ul>
</section>
<section id="the-intuition-water-filling-approach" class="level3">
<h3 class="anchored" data-anchor-id="the-intuition-water-filling-approach">The Intuition: “Water-filling” Approach</h3>
<ul>
<li>APS의 핵심 아이디어는 직관적입니다.</li>
<li>만약 모델의 예측 확률 <span class="math inline">\(\hat{f}(x)\)</span>가 완벽하다면, 우리는 확률이 높은 클래스부터 순서대로 골라 담으면서 그 <strong>확률의 합(Cumulative Sum)이 <span class="math inline">\(1-\alpha\)</span> (예: 90%)를 넘기는 순간</strong> 멈추면 됩니다.</li>
</ul>
<p><span class="math display">\[
\sum_{j=1}^{k} \hat{f}(x)_{\pi_j(x)} \ge 1 - \alpha
\]</span></p>
<ul>
<li><p>여기서 <span class="math inline">\(\pi(x)\)</span>는 확률이 높은 순서대로 정렬된 클래스의 순열(Permutation)입니다.</p></li>
<li><p>이 방식은 “컵에 물(확률)을 <span class="math inline">\(90\%\)</span>가 찰 때까지 붓는 것”과 유사합니다.</p></li>
<li><p><strong>쉬운 문제</strong>: 확률 분포가 뾰족(Peaked)하므로, 1~2개만 담아도 금방 <span class="math inline">\(90\%\)</span>가 찹니다. <span class="math inline">\(\rightarrow\)</span> <strong>Small Set</strong></p></li>
<li><p><strong>어려운 문제</strong>: 확률 분포가 평평(Flat)하므로, 여러 개를 담아야 <span class="math inline">\(90\%\)</span>가 찹니다. <span class="math inline">\(\rightarrow\)</span> <strong>Large Set</strong></p></li>
<li><p>하지만 실제 모델의 확률 <span class="math inline">\(\hat{f}(x)\)</span>는 완벽하지 않으므로(Overconfident/Underconfident), 단순히 <span class="math inline">\(1-\alpha\)</span>에서 끊으면 커버리지를 보장할 수 없습니다.</p></li>
<li><p>따라서 <strong>Conformal Prediction을 사용하여 이 “멈추는 지점(Threshold)”을 보정</strong>해야 합니다.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/figure4_aps_visualization.png" class="img-fluid figure-img"></p>
<figcaption>Figure 4: Adaptive Prediction Sets (APS) 알고리즘의 시각화. 확률이 높은 클래스(Fox squirrel, Gray fox…)부터 순서대로 누적 합을 구하고, 그 합이 보정된 분위수(Quantile)를 넘을 때까지 클래스를 포함시킨다.</figcaption>
</figure>
</div>
</section>
<section id="mathematical-formulation" class="level3">
<h3 class="anchored" data-anchor-id="mathematical-formulation">Mathematical Formulation</h3>
<ul>
<li>이제 이를 수학적으로 엄밀하게 정의해보겠습니다.</li>
</ul>
<section id="defining-the-score-function" class="level4">
<h4 class="anchored" data-anchor-id="defining-the-score-function">1. Defining the Score Function</h4>
<ul>
<li><p>APS를 위한 Score Function <span class="math inline">\(s(x, y)\)</span>는 <strong>“정답 클래스 <span class="math inline">\(y\)</span>를 포함시키기 위해, 확률 상위 몇 번째 클래스까지 내려가야 하는가?”</strong>를 누적 확률로 나타냅니다.</p></li>
<li><p>먼저, 입력 <span class="math inline">\(x\)</span>에 대해 모델이 예측한 확률을 내림차순으로 정렬하는 순열 함수 <span class="math inline">\(\pi(x)\)</span>를 정의합니다. <span class="math display">\[ \hat{f}(x)_{\pi_1(x)} \ge \hat{f}(x)_{\pi_2(x)} \ge \dots \ge \hat{f}(x)_{\pi_K(x)} \]</span></p></li>
<li><p>이때, 정답 클래스 <span class="math inline">\(y\)</span>가 정렬된 순서상 <span class="math inline">\(k\)</span>번째에 위치한다고 가정합시다 (<span class="math inline">\(y = \pi_k(x)\)</span>).</p></li>
<li><p>Score <span class="math inline">\(s(x, y)\)</span>는 <span class="math inline">\(y\)</span>까지의 누적 확률 질량(Cumulative Probability Mass)으로 정의됩니다:</p></li>
</ul>
<p><span class="math display">\[
s(x,y) = \sum_{j=1}^{k} \hat{f}(x)_{\pi_j(x)}
\]</span></p>
<ul>
<li><strong>의미</strong>: “모델이 가장 가능성 높다고 생각하는 것부터 정답 <span class="math inline">\(y\)</span>가 나올 때까지 확률을 다 더한 값”입니다.
<ul>
<li>만약 모델이 정답을 1순위로 예측했다면, <span class="math inline">\(s(x,y)\)</span>는 작을 것입니다.</li>
<li>만약 모델이 정답을 하위권으로 예측했다면, <span class="math inline">\(s(x,y)\)</span>는 1에 가까워질 것입니다.</li>
</ul></li>
</ul>
</section>
<section id="calibration-finding-hatq" class="level4">
<h4 class="anchored" data-anchor-id="calibration-finding-hatq">2. Calibration (Finding <span class="math inline">\(\hat{q}\)</span>)</h4>
<ul>
<li>이제 Calibration 데이터셋 <span class="math inline">\((X_1, Y_1), \dots, (X_n, Y_n)\)</span>에 대해 위 점수들을 계산합니다.</li>
<li>그리고 다음 식을 만족하는 분위수(Quantile) <span class="math inline">\(\hat{q}\)</span>를 찾습니다.</li>
</ul>
<p><span class="math display">\[
\hat{q} = \text{Quantile}\left( \frac{\lceil (n+1)(1-\alpha) \rceil}{n} ; \{s_1, \dots, s_n\} \right)
\]</span></p>
<ul>
<li>이 <span class="math inline">\(\hat{q}\)</span>는 “정답을 포함하기 위해 누적 확률을 어디까지 허용해야 하는가?”에 대한 통계적 임계값입니다.</li>
</ul>
</section>
<section id="constructing-the-prediction-set" class="level4">
<h4 class="anchored" data-anchor-id="constructing-the-prediction-set">3. Constructing the Prediction Set</h4>
<ul>
<li>새로운 테스트 데이터 <span class="math inline">\(X_{test}\)</span>에 대해 예측 집합 <span class="math inline">\(\mathcal{C}(X_{test})\)</span>는 누적 확률이 <span class="math inline">\(\hat{q}\)</span>를 넘어서는 지점까지의 모든 클래스를 포함하여 구성됩니다.</li>
</ul>
<p><span class="math display">\[
\mathcal{C}(x) = \{ \pi_1(x), \dots, \pi_k(x) \}
\]</span></p>
<ul>
<li>여기서 <span class="math inline">\(k\)</span>는 다음을 만족하는 가장 작은 정수입니다: <span class="math display">\[
\text{sup} \left\{ k' : \sum_{j=1}^{k'} \hat{f}(x)_{\pi_j(x)} &lt; \hat{q} \right\} + 1
\]</span></li>
<li>즉, 누적 합이 <span class="math inline">\(\hat{q}\)</span>를 초과하는 순간까지 포함합니다.</li>
</ul>
</section>
</section>
<section id="implementation-steps" class="level3">
<h3 class="anchored" data-anchor-id="implementation-steps">Implementation Steps</h3>
<ul>
<li>Python 코드로 구현할 때의 핵심 로직은 다음과 같습니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/figure5_aps_python_code.png" class="img-fluid figure-img"></p>
<figcaption>Figure 5: Adaptive Prediction Sets 구현을 위한 Python 코드 예시. <code>argsort</code>를 통해 정렬하고 <code>cumsum</code>을 통해 누적 확률을 계산하는 과정이 포함되어 있다.</figcaption>
</figure>
</div>
<ol type="1">
<li><strong>Softmax &amp; Sort</strong>: 모델 출력값(Softmax)을 구하고 <code>argsort</code>를 이용해 내림차순 정렬합니다.</li>
<li><strong>Cumulative Sum</strong>: 정렬된 확률값들의 누적 합(<code>cumsum</code>)을 계산합니다.</li>
<li><strong>Calculate Scores (Calibration)</strong>: 정답 라벨 위치에서의 누적 합을 가져와 <span class="math inline">\(s_i\)</span>를 구하고, Quantile <span class="math inline">\(\hat{q}\)</span>를 계산합니다.</li>
<li><strong>Prediction (Test)</strong>: 테스트 데이터의 누적 합이 <span class="math inline">\(\hat{q}\)</span>보다 작거나 같은 클래스들을 선택합니다. (엄밀하게는 <span class="math inline">\(\hat{q}\)</span>를 넘는 첫 번째 클래스까지 포함해야 함)</li>
</ol>
</section>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<ul>
<li><strong>Adaptive Prediction Sets (APS)</strong>는 불확실성을 더 지능적으로 다루는 방법입니다.</li>
<li>단순히 모델의 Softmax 값 하나만 보는 것이 아니라, <strong>전체 확률 분포의 형상(Shape)</strong>을 고려합니다.</li>
<li>그 결과, <strong>쉬운 샘플에는 작은 집합</strong>을, <strong>어려운 샘플에는 큰 집합</strong>을 할당하여 사용자가 모델의 신뢰도를 직관적으로 파악할 수 있게 해줍니다.</li>
<li>이 모든 과정에서도 <span class="math inline">\(1-\alpha\)</span>라는 통계적 커버리지는 엄격하게 보장됩니다.</li>
</ul>
<hr>
</section>
</section>
<section id="traditional-inferential-targets" class="level2">
<h2 class="anchored" data-anchor-id="traditional-inferential-targets">2.2. Traditional Inferential Targets</h2>
<section id="introduction-1" class="level3">
<h3 class="anchored" data-anchor-id="introduction-1">Introduction</h3>
<ul>
<li><p>이전 포스트에서는 분류(Classification) 문제에 대한 Conformal Prediction을 다루었습니다.</p></li>
<li><p>이번에는 <strong>연속적인 값(Continuous Output)을 예측하는 회귀(Regression)</strong> 문제로 넘어가 보겠습니다.</p></li>
<li><p>회귀 문제에서 우리의 목표는 입력 <span class="math inline">\(x\)</span>에 대해 단순히 하나의 예측값 <span class="math inline">\(\hat{y}\)</span>를 내놓는 것이 아니라, 정답 <span class="math inline">\(y\)</span>가 포함될 확률이 <span class="math inline">\(1-\alpha\)</span> (예: 90%)인 <strong>예측 구간(Prediction Interval)</strong>을 생성하는 것입니다.</p></li>
</ul>
<p><span class="math display">\[
\mathcal{C}(x) = [\text{Lower Bound}, \text{Upper Bound}]
\]</span></p>
<ul>
<li>이를 위해 가장 효과적인 베이스 모델 중 하나인 <strong>Quantile Regression</strong>을 사용하고, CP를 통해 이를 보정하는 <strong>Conformalized Quantile Regression (CQR)</strong> 기법을 알아보겠습니다.</li>
</ul>
</section>
<section id="base-model-quantile-regression" class="level3">
<h3 class="anchored" data-anchor-id="base-model-quantile-regression">Base Model: Quantile Regression</h3>
<section id="concept" class="level4">
<h4 class="anchored" data-anchor-id="concept">Concept</h4>
<ul>
<li><p>일반적인 회귀 모델은 평균(Mean)을 예측(MSE Loss 사용)하지만, <strong>Quantile Regression</strong>은 조건부 분포의 특정 분위수(Quantile)를 예측합니다.</p></li>
<li><p>90%의 커버리지를 목표로 한다면, 우리는 양쪽 꼬리에서 5%씩을 제외한 구간을 알고 싶을 것입니다. 즉, 다음 두 가지 분위수를 학습합니다:</p>
<ul>
<li><strong>Lower Quantile</strong>: <span class="math inline">\(\alpha/2 = 0.05\)</span> (5% 지점)</li>
<li><strong>Upper Quantile</strong>: <span class="math inline">\(1 - \alpha/2 = 0.95\)</span> (95% 지점)</li>
</ul></li>
<li><p>모델이 완벽하다면, 정답 <span class="math inline">\(y\)</span>는 90%의 확률로 이 구간 <span class="math inline">\([\hat{t}_{\alpha/2}(x), \hat{t}_{1-\alpha/2}(x)]\)</span> 사이에 존재해야 합니다.</p></li>
</ul>
</section>
<section id="quantile-loss-pinball-loss" class="level4">
<h4 class="anchored" data-anchor-id="quantile-loss-pinball-loss">Quantile Loss (Pinball Loss)</h4>
<ul>
<li>이러한 분위수를 학습하기 위해 <strong>Quantile Loss (Pinball Loss)</strong>를 사용합니다.</li>
</ul>
<p><span class="math display">\[
L_{\gamma}(\hat{t}_{\gamma}, y) = (y - \hat{t}_{\gamma})\gamma \mathbb{1}\{y &gt; \hat{t}_{\gamma}\} + (\hat{t}_{\gamma} - y)(1-\gamma)\mathbb{1}\{y \le \hat{t}_{\gamma}\}
\]</span></p>
<ul>
<li><span class="math inline">\(\gamma\)</span>: 타겟 분위수 (예: 0.05 또는 0.95)</li>
<li>이 손실 함수를 사용하여 뉴럴 네트워크 등 어떤 모델이든 특정 분위수를 예측하도록 학습시킬 수 있습니다.</li>
</ul>
</section>
</section>
<section id="the-problem-why-conformalize" class="level3">
<h3 class="anchored" data-anchor-id="the-problem-why-conformalize">The Problem: Why Conformalize?</h3>
<ul>
<li><p>Quantile Regression으로 구한 구간 <span class="math inline">\([\hat{t}_{0.05}(x), \hat{t}_{0.95}(x)]\)</span>는 꽤 훌륭한 불확실성 추정치입니다.</p></li>
<li><p>하지만 문제는 <strong>“Finite Sample”에서 90% 커버리지를 보장하지 못한다</strong>는 점입니다.</p></li>
<li><p>모델이 과적합(Overfitting)되거나 학습이 덜 되면, 실제 정답이 이 구간을 벗어나는 비율이 10%보다 훨씬 클 수도, 작을 수도 있습니다.</p></li>
<li><p>따라서 우리는 Conformal Prediction을 사용하여 이 구간을 <strong>보정(Calibrate)</strong>해야 합니다.</p></li>
</ul>
</section>
<section id="conformalized-quantile-regression-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="conformalized-quantile-regression-algorithm">Conformalized Quantile Regression Algorithm</h3>
<ul>
<li>CQR의 핵심 아이디어는 학습된 분위수 구간을 <strong><span class="math inline">\(\hat{q}\)</span>만큼 늘리거나 줄여서</strong> 엄밀한 커버리지를 맞추는 것입니다.</li>
</ul>
<section id="step-1-define-score-function" class="level4">
<h4 class="anchored" data-anchor-id="step-1-define-score-function">Step 1: Define Score Function</h4>
<ul>
<li>Calibration 데이터 <span class="math inline">\((X_i, Y_i)\)</span>에 대해, 정답 <span class="math inline">\(Y_i\)</span>가 학습된 구간 <span class="math inline">\([\hat{t}_{\alpha/2}(X_i), \hat{t}_{1-\alpha/2}(X_i)]\)</span> 밖으로 얼마나 나갔는지를 측정하는 Score를 정의합니다.</li>
</ul>
<p><span class="math display">\[
s(x, y) = \max \{ \hat{t}_{\alpha/2}(x) - y, \quad y - \hat{t}_{1-\alpha/2}(x) \}
\]</span></p>
<ul>
<li>이 식의 의미를 직관적으로 살펴봅시다:
<ul>
<li><strong>Case 1: <span class="math inline">\(y\)</span>가 구간 안에 있을 때</strong>:
<ul>
<li><span class="math inline">\(\hat{t}_{\text{lower}} &lt; y &lt; \hat{t}_{\text{upper}}\)</span> 이므로, 두 항 모두 음수가 됩니다.</li>
<li><span class="math inline">\(s(x, y) &lt; 0\)</span> (즉, 안전함)</li>
</ul></li>
<li><strong>Case 2: <span class="math inline">\(y\)</span>가 구간 밖(위쪽)에 있을 때</strong>:
<ul>
<li><span class="math inline">\(y &gt; \hat{t}_{\text{upper}}\)</span> 이므로 <span class="math inline">\(y - \hat{t}_{\text{upper}}\)</span> 가 양수가 됩니다.</li>
<li><span class="math inline">\(s(x, y) &gt; 0\)</span> (즉, 위험함/에러)</li>
</ul></li>
</ul></li>
<li>즉, 점수 <span class="math inline">\(s\)</span>가 클수록 정답이 예측 구간을 크게 벗어났음을 의미합니다.</li>
</ul>
</section>
<section id="step-2-calibration-get-hatq" class="level4">
<h4 class="anchored" data-anchor-id="step-2-calibration-get-hatq">Step 2: Calibration (Get <span class="math inline">\(\hat{q}\)</span>)</h4>
<ul>
<li>계산된 점수들 <span class="math inline">\(s_1, \dots, s_n\)</span>의 분포에서 <span class="math inline">\(1-\alpha\)</span> 분위수 <span class="math inline">\(\hat{q}\)</span>를 찾습니다.</li>
</ul>
<p><span class="math display">\[
\hat{q} = \text{Quantile}\left( \frac{\lceil (n+1)(1-\alpha) \rceil}{n} ; \{s_1, \dots, s_n\} \right)
\]</span></p>
<ul>
<li>만약 모델이 불확실성을 과소평가했다면(구간이 너무 좁으면), 많은 <span class="math inline">\(y\)</span>가 구간 밖에 있을 것이고 <span class="math inline">\(s\)</span>값들이 커져서 <strong>양수의 <span class="math inline">\(\hat{q}\)</span></strong>가 나옵니다.</li>
<li>만약 모델이 불확실성을 과대평가했다면(구간이 너무 넓으면), <span class="math inline">\(s\)</span>값들이 대부분 음수일 것이고 <strong>음수의 <span class="math inline">\(\hat{q}\)</span></strong>가 나옵니다.</li>
</ul>
</section>
<section id="step-3-construct-prediction-interval" class="level4">
<h4 class="anchored" data-anchor-id="step-3-construct-prediction-interval">Step 3: Construct Prediction Interval</h4>
<ul>
<li>최종적으로 새로운 입력 <span class="math inline">\(X_{test}\)</span>에 대한 예측 구간을 생성할 때, 원래 구간을 <span class="math inline">\(\hat{q}\)</span>만큼 조정합니다.</li>
</ul>
<p><span class="math display">\[
\mathcal{C}(X_{test}) = [\hat{t}_{\alpha/2}(X_{test}) - \hat{q}, \quad \hat{t}_{1-\alpha/2}(X_{test}) + \hat{q}]
\]</span></p>
<ul>
<li><span class="math inline">\(\hat{q} &gt; 0\)</span>: 원래 구간이 너무 좁았으므로, 양쪽으로 <span class="math inline">\(\hat{q}\)</span>만큼 <strong>넓힙니다</strong>.</li>
<li><span class="math inline">\(\hat{q} &lt; 0\)</span>: 원래 구간이 너무 넓었으므로, 양쪽으로 <span class="math inline">\(|\hat{q}|\)</span>만큼 <strong>좁힙니다</strong>.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/figure6_cqr_visualization.png" class="img-fluid figure-img"></p>
<figcaption>Figure 6: CQR 알고리즘의 시각화. 원래의 Quantile Regression 구간(파란색 영역)을 Calibration을 통해 얻은 상수 <span class="math inline">\(\hat{q}\)</span>만큼 확장하거나 축소하여 최종 Prediction Set을 생성한다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="implementation" class="level3">
<h3 class="anchored" data-anchor-id="implementation">Implementation</h3>
<p>Python으로 CQR을 구현하는 것은 매우 간단합니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/figure7_cqr_python_code.png" class="img-fluid figure-img"></p>
<figcaption>Figure 7: Conformalized Quantile Regression 구현을 위한 Python 코드. Score를 계산하고 Quantile을 구하여 최종 구간을 조정하는 과정이 몇 줄의 코드로 구현된다.</figcaption>
</figure>
</div>
<ul>
<li><ol type="1">
<li><strong>Get Scores</strong>: Calibration 데이터에 대해 <code>max(lower - y, y - upper)</code>를 계산합니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Get Quantile</strong>: 위 점수들의 <span class="math inline">\((1-\alpha)\)</span> 분위수 <span class="math inline">\(\hat{q}\)</span>를 계산합니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Deploy</strong>: 새로운 데이터의 Lower/Upper 예측값에 각각 <span class="math inline">\(-\hat{q}, +\hat{q}\)</span>를 더해줍니다.</li>
</ol></li>
</ul>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<ul>
<li><p><strong>Conformalized Quantile Regression (CQR)</strong>은 회귀 문제에서 가장 널리 사용되는 최신 기법 중 하나입니다.</p></li>
<li><p><strong>Adaptivity</strong>: 입력값 <span class="math inline">\(x\)</span>에 따라 구간의 길이(불확실성 크기)가 달라지는 Quantile Regression의 장점을 그대로 가집니다. (어려운 입력은 구간이 넓고, 쉬운 입력은 구간이 좁음)</p></li>
<li><p><strong>Validity</strong>: Conformal Prediction을 통해 통계적 커버리지를 엄밀하게 보장합니다.</p></li>
<li><p>이 방법은 단순한 MSE 기반 회귀보다 훨씬 풍부한 정보를 제공하며, 의료나 금융과 같이 리스크 관리가 중요한 분야에서 필수적인 도구입니다.</p></li>
</ul>
<hr>
</section>
</section>
<section id="coverage-of-interval-estimates" class="level2">
<h2 class="anchored" data-anchor-id="coverage-of-interval-estimates">2.3. Coverage of Interval Estimates</h2>
<section id="introduction-2" class="level3">
<h3 class="anchored" data-anchor-id="introduction-2">Introduction</h3>
<ul>
<li><p>이전 포스트에서 다룬 <strong>Conformalized Quantile Regression (CQR)</strong>은 매우 강력하지만, 두 개의 Quantile을 학습시켜야 한다는 조건이 있습니다.</p></li>
<li><p>하지만 실무에서는 종종 <strong>평균(<span class="math inline">\(\mu\)</span>)과 분산(<span class="math inline">\(\sigma^2\)</span>)</strong>만을 예측하는 더 단순한 모델을 사용하거나, 혹은 모델 앙상블의 분산 등을 불확실성 지표로 삼기도 합니다.</p></li>
<li><p>이번 포스트에서는 이러한 <strong>단일 스칼라 불확실성 지표(Scalar Uncertainty Estimate)</strong>를 활용하여 통계적으로 유효한 예측 구간을 생성하는 방법을 알아봅니다.</p></li>
</ul>
</section>
<section id="heuristic-uncertainty-the-estimated-standard-deviation" class="level3">
<h3 class="anchored" data-anchor-id="heuristic-uncertainty-the-estimated-standard-deviation">Heuristic Uncertainty: The Estimated Standard Deviation</h3>
<p>가장 흔한 시나리오는 데이터가 정규분포(Gaussian)를 따른다고 가정하고 모델을 학습시키는 것입니다.</p>
<p><span class="math display">\[ Y | X = x \sim \mathcal{N}(\mu(x), \sigma(x)) \]</span></p>
<ul>
<li><p>딥러닝 프레임워크(PyTorch 등)에서는 <code>GaussianNLLLoss</code>와 같은 손실 함수를 제공하여, 모델이 평균 예측값 <span class="math inline">\(\hat{f}(x)\)</span>와 불확실성 예측값 <span class="math inline">\(\hat{\sigma}(x)\)</span>를 동시에 학습하도록 돕습니다.</p></li>
<li><p>하지만 실제 데이터는 <strong>정규분포를 따르지 않는 경우가 대부분</strong>입니다.</p></li>
<li><p>따라서 모델이 예측한 <span class="math inline">\(\hat{\sigma}(x)\)</span>를 그대로 사용하여 <span class="math inline">\(\hat{f}(x) \pm 1.96\hat{\sigma}(x)\)</span>와 같은 구간을 만들면, 실제로는 95% 커버리지를 보장할 수 없습니다.</p></li>
<li><p>우리는 Conformal Prediction을 사용하여 이 부정확한(Heuristic) <span class="math inline">\(\hat{\sigma}(x)\)</span>를 <strong>보정(Calibrate)</strong>할 것입니다.</p></li>
</ul>
</section>
<section id="generalizing-uncertainty-scalars" class="level3">
<h3 class="anchored" data-anchor-id="generalizing-uncertainty-scalars">Generalizing Uncertainty Scalars</h3>
<ul>
<li><p>이 방법은 비단 표준편차뿐만 아니라, <strong>“값이 클수록 불확실하다”</strong>는 의미를 가진 어떤 함수 <span class="math inline">\(u(x)\)</span>에도 적용 가능합니다.</p></li>
<li><p>논문에서는 <span class="math inline">\(u(x)\)</span>로 사용할 수 있는 다양한 예시를 제시합니다:</p>
<ul>
<li><ol type="1">
<li><strong>Residual Prediction</strong>: <span class="math inline">\(|y - \hat{f}(x)|\)</span>를 예측하는 별도의 모델 학습.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Ensemble Variance</strong>: 여러 모델 예측값들의 분산 측정.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Dropout Variance</strong>: 추론 시 Dropout을 켜고 여러 번 예측했을 때의 분산.</li>
</ol></li>
<li><ol start="4" type="1">
<li><strong>Input Perturbation</strong>: 입력에 작은 노이즈를 주었을 때 출력의 변화량.</li>
</ol></li>
</ul></li>
<li><p>우리는 이 <span class="math inline">\(u(x)\)</span>를 “불확실성의 크기(Magnitude)”로 간주하고, 이를 스케일링하는 방식(Multiplicative Correction)을 사용합니다.</p></li>
</ul>
</section>
<section id="the-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="the-algorithm">The Algorithm</h3>
<ul>
<li>알고리즘의 핵심은 <strong>“실제 에러가 불확실성 지표 <span class="math inline">\(u(x)\)</span> 대비 몇 배나 큰가?”</strong>를 측정하는 것입니다.</li>
</ul>
<section id="step-1-define-score-function-1" class="level4">
<h4 class="anchored" data-anchor-id="step-1-define-score-function-1">Step 1: Define Score Function</h4>
<ul>
<li>Calibration 데이터 <span class="math inline">\((X_i, Y_i)\)</span>에 대해 다음과 같은 Score를 정의합니다.</li>
</ul>
<p><span class="math display">\[
s(x, y) = \frac{|y - \hat{f}(x)|}{u(x)}
\]</span></p>
<ul>
<li><strong>분자 <span class="math inline">\(|y - \hat{f}(x)|\)</span></strong>: 실제 모델의 예측 오차(절대값)입니다.</li>
<li><strong>분모 <span class="math inline">\(u(x)\)</span></strong>: 모델이 스스로 추정한 불확실성입니다.</li>
<li><strong>의미</strong>: “모델이 예상한 불확실성 대비 실제 오차의 비율”입니다.
<ul>
<li>만약 모델이 불확실하다고 판단(<span class="math inline">\(u(x)\)</span> 큼)했는데 오차도 크다면, <span class="math inline">\(s\)</span>는 적절한 값을 가집니다.</li>
<li>만약 모델이 확실하다고 판단(<span class="math inline">\(u(x)\)</span> 작음)했는데 오차가 크다면, <span class="math inline">\(s\)</span>는 매우 커집니다 (Penalty).</li>
</ul></li>
</ul>
</section>
<section id="step-2-calibration-get-hatq-1" class="level4">
<h4 class="anchored" data-anchor-id="step-2-calibration-get-hatq-1">Step 2: Calibration (Get <span class="math inline">\(\hat{q}\)</span>)</h4>
<ul>
<li>계산된 점수들 <span class="math inline">\(s_1, \dots, s_n\)</span>에 대해 <span class="math inline">\(1-\alpha\)</span> 분위수(Quantile) <span class="math inline">\(\hat{q}\)</span>를 구합니다.</li>
</ul>
<p><span class="math display">\[
\hat{q} = \text{Quantile}\left( \frac{\lceil (n+1)(1-\alpha) \rceil}{n} ; \{s_1, \dots, s_n\} \right)
\]</span></p>
<ul>
<li>여기서 구해진 <span class="math inline">\(\hat{q}\)</span>는 <strong>“불확실성 지표 <span class="math inline">\(u(x)\)</span>에 곱해야 할 보정 계수(Multiplier)”</strong> 역할을 합니다.</li>
</ul>
</section>
<section id="step-3-construct-prediction-interval-1" class="level4">
<h4 class="anchored" data-anchor-id="step-3-construct-prediction-interval-1">Step 3: Construct Prediction Interval</h4>
<ul>
<li>새로운 입력 <span class="math inline">\(X_{test}\)</span>에 대한 예측 구간은 중심 예측값 <span class="math inline">\(\hat{f}(x)\)</span>에서 불확실성 지표 <span class="math inline">\(u(x)\)</span>의 <span class="math inline">\(\hat{q}\)</span>배만큼 벌려준 구간이 됩니다.</li>
</ul>
<p><span class="math display">\[
\mathcal{C}(x) = [\hat{f}(x) - \hat{q}u(x), \quad \hat{f}(x) + \hat{q}u(x)]
\]</span></p>
<section id="유도-과정-derivation-of-validity" class="level5">
<h5 class="anchored" data-anchor-id="유도-과정-derivation-of-validity">유도 과정 (Derivation of Validity)</h5>
<ul>
<li>이 구간이 왜 <span class="math inline">\(1-\alpha\)</span> 커버리지를 보장하는지 살펴보겠습니다.</li>
</ul>
<ol type="1">
<li>Calibration 단계에서 <span class="math inline">\(\hat{q}\)</span>를 구했으므로, 새로운 데이터에 대해 다음 확률이 성립합니다. <span class="math display">\[ \mathbb{P}[s(X_{test}, Y_{test}) \le \hat{q}] \ge 1 - \alpha \]</span></li>
<li>Score <span class="math inline">\(s\)</span>의 정의를 대입합니다. <span class="math display">\[ \mathbb{P}\left[ \frac{|Y_{test} - \hat{f}(X_{test})|}{u(X_{test})} \le \hat{q} \right] \ge 1 - \alpha \]</span></li>
<li>양변에 <span class="math inline">\(u(X_{test})\)</span>를 곱합니다 (불확실성은 항상 양수이므로 부등호 유지). <span class="math display">\[ \mathbb{P}\left[ |Y_{test} - \hat{f}(X_{test})| \le \hat{q}u(X_{test}) \right] \ge 1 - \alpha \]</span></li>
<li>절대값을 풉니다. <span class="math display">\[ \mathbb{P}\left[ -\hat{q}u(X_{test}) \le Y_{test} - \hat{f}(X_{test}) \le \hat{q}u(X_{test}) \right] \ge 1 - \alpha \]</span></li>
<li><span class="math inline">\(Y_{test}\)</span>에 대해 정리하면 최종 구간이 도출됩니다. <span class="math display">\[ \mathbb{P}\left[ \hat{f}(X_{test}) - \hat{q}u(X_{test}) \le Y_{test} \le \hat{f}(X_{test}) + \hat{q}u(X_{test}) \right] \ge 1 - \alpha \]</span></li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/figure8_scalar_visualization.png" class="img-fluid figure-img"></p>
<figcaption>Figure 8: Uncertainty Scalar를 이용한 예측 구간 시각화. 중심 예측값 <span class="math inline">\(\hat{f}(x)\)</span>를 기준으로, 위아래로 <span class="math inline">\(\hat{q}u(x)\)</span>만큼 벌어진 대칭적인 구간을 형성한다.</figcaption>
</figure>
</div>
</section>
</section>
</section>
<section id="implementation-1" class="level3">
<h3 class="anchored" data-anchor-id="implementation-1">Implementation</h3>
<ul>
<li>이 방법은 구현이 매우 간단하며, PyTorch 등의 라이브러리와 쉽게 결합됩니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/figure9_scalar_python_code.png" class="img-fluid figure-img"></p>
<figcaption>Figure 9: Conformalized Uncertainty Scalars 구현을 위한 Python 코드. Score를 계산할 때 예측된 표준편차(model output의 두 번째 컬럼)로 나누어주는 것이 핵심이다.</figcaption>
</figure>
</div>
<ol type="1">
<li><strong>Get Scores</strong>: 에러의 절대값을 예측된 표준편차(또는 불확실성 지표)로 나눕니다.</li>
<li><strong>Get Quantile</strong>: 점수들의 분위수 <span class="math inline">\(\hat{q}\)</span>를 계산합니다.</li>
<li><strong>Deploy</strong>: 예측값 <span class="math inline">\(\pm (\text{불확실성} \times \hat{q})\)</span>를 통해 구간을 생성합니다.</li>
</ol>
</section>
<section id="discussion" class="level3">
<h3 class="anchored" data-anchor-id="discussion">Discussion</h3>
<ul>
<li>이 방법은 <strong>Symmetric(대칭적)</strong>인 구간을 생성한다는 특징이 있습니다.
<ul>
<li><strong>장점</strong>: 구현이 쉽고 직관적입니다. 이미 학습된 모델(Gaussian Output 등)을 그대로 재활용하기 좋습니다.</li>
<li><strong>단점</strong>: CQR과 달리 구간이 항상 예측값을 중심으로 대칭입니다. 실제 데이터 분포가 비대칭(Skewed)이라면 효율적이지 않을 수 있습니다. 또한, <span class="math inline">\(u(x)\)</span>가 실제 분위수와 비례하지 않는다면 CQR보다 성능(구간의 평균 길이 등)이 떨어질 수 있습니다.</li>
</ul></li>
<li>따라서 가능하다면 <strong>Quantile Regression (CQR)</strong>을 사용하는 것이 더 좋지만, 상황이 여의치 않거나 빠른 배포가 필요할 때 이 방법은 훌륭한 대안이 됩니다.</li>
</ul>
<hr>
</section>
</section>
<section id="conformalizing-bayes" class="level2">
<h2 class="anchored" data-anchor-id="conformalizing-bayes">2.4. Conformalizing Bayes</h2>
<section id="introduction-3" class="level3">
<h3 class="anchored" data-anchor-id="introduction-3">Introduction</h3>
<ul>
<li><p>Bayesian Neural Network와 같은 베이지안 모델들은 불확실성 정량화(Uncertainty Quantification) 분야에서 매우 매력적인 도구입니다.</p></li>
<li><p>이들은 사전 지식(Prior)을 반영할 수 있고, 예측의 결과물로 단일 값이 아닌 분포(Posterior Predictive Density)를 제공하기 때문입니다.</p></li>
<li><p>하지만 베이지안 모델에는 치명적인 약점이 있습니다.</p></li>
<li><p><strong>“모델의 가정(Prior, Likelihood function 등)이 완벽하게 맞아야만”</strong> 예측된 불확실성이 정확하다는 점입니다.</p></li>
<li><p>현실의 복잡한 데이터에서 이러한 가정이 완벽히 들어맞기는 어렵습니다.</p></li>
<li><p><strong>Conformalizing Bayes</strong>는 베이지안 모델의 정보량을 그대로 활용하되, <strong>Conformal Prediction을 통해 “가정이 틀렸더라도” 통계적 커버리지를 보장</strong>하는 강력한 방법론입니다.</p></li>
</ul>
</section>
<section id="the-bayesian-ideal-vs.-reality" class="level3">
<h3 class="anchored" data-anchor-id="the-bayesian-ideal-vs.-reality">The Bayesian Ideal vs.&nbsp;Reality</h3>
<section id="ideal-scenario" class="level4">
<h4 class="anchored" data-anchor-id="ideal-scenario">Ideal Scenario</h4>
<ul>
<li>만약 우리가 만든 베이지안 모델 <span class="math inline">\(\hat{f}(y|x)\)</span> (입력 <span class="math inline">\(x\)</span>가 주어졌을 때 <span class="math inline">\(y\)</span>의 사후 확률 밀도)가 완벽하다면, 최적의 예측 집합 <span class="math inline">\(S(x)\)</span>는 단순히 밀도 함수(Density)가 높은 영역을 잘라내어 만들 수 있습니다.</li>
</ul>
<p><span class="math display">\[
S(x) = \{ y : \hat{f}(y|x) &gt; t \}
\]</span></p>
<ul>
<li>여기서 임계값 <span class="math inline">\(t\)</span>는 해당 영역의 적분값이 <span class="math inline">\(1-\alpha\)</span>가 되도록 설정합니다. <span class="math display">\[\int_{y \in S(x)} \hat{f}(y|x) dy = 1-\alpha\]</span></li>
<li>이를 <strong>Highest Posterior Density (HPD) Region</strong>이라고도 합니다.</li>
</ul>
</section>
<section id="reality" class="level4">
<h4 class="anchored" data-anchor-id="reality">Reality</h4>
<ul>
<li><p>하지만 우리는 모델 <span class="math inline">\(\hat{f}\)</span>가 완벽하다고 보장할 수 없습니다.</p></li>
<li><p>따라서 위 방식으로 구한 집합은 실제로는 90%를 커버하지 못할 수도(Under-coverage), 너무 넓을 수도(Over-coverage) 있습니다.</p></li>
<li><p>우리는 베이지안 모델의 <span class="math inline">\(\hat{f}(y|x)\)</span>를 <strong>“진짜 확률”이 아니라 “유용한 불확실성 점수(Heuristic Score)”로 간주</strong>하고, CP를 적용하여 올바른 임계값(Threshold)을 찾을 것입니다.</p></li>
</ul>
</section>
</section>
<section id="the-algorithm-1" class="level3">
<h3 class="anchored" data-anchor-id="the-algorithm-1">The Algorithm</h3>
<ul>
<li>Conformalizing Bayes의 절차는 우리가 익숙한 CP의 흐름을 그대로 따릅니다.</li>
</ul>
<section id="step-1-define-score-function-2" class="level4">
<h4 class="anchored" data-anchor-id="step-1-define-score-function-2">Step 1: Define Score Function</h4>
<ul>
<li>우리는 모델이 예측한 <strong>사후 확률 밀도(Posterior Predictive Density)</strong>가 높을수록 에러가 작다(확실하다)고 봅니다.</li>
<li>Conformal Score는 “불확실한 정도”를 나타내야 하므로, 밀도 함수의 <strong>음수(Negative)</strong>를 취합니다. <span class="math display">\[
s(x, y) = - \hat{f}(y|x)
\]</span>
<ul>
<li><span class="math inline">\(\hat{f}(y|x)\)</span>가 높음 (모델이 정답을 확신함) <span class="math inline">\(\rightarrow\)</span> Score <span class="math inline">\(s\)</span>는 매우 작은 음수.</li>
<li><span class="math inline">\(\hat{f}(y|x)\)</span>가 낮음 (모델이 정답을 예측 못함) <span class="math inline">\(\rightarrow\)</span> Score <span class="math inline">\(s\)</span>는 큰 값(0에 가까운 값 혹은 양수).</li>
</ul></li>
</ul>
</section>
<section id="step-2-calibration-finding-hatq" class="level4">
<h4 class="anchored" data-anchor-id="step-2-calibration-finding-hatq">Step 2: Calibration (Finding <span class="math inline">\(\hat{q}\)</span>)</h4>
<ul>
<li>Calibration 데이터 <span class="math inline">\((X_1, Y_1), \dots, (X_n, Y_n)\)</span>에 대해 점수들을 계산하고, <span class="math inline">\(1-\alpha\)</span> 분위수 <span class="math inline">\(\hat{q}\)</span>를 찾습니다.</li>
</ul>
<p><span class="math display">\[
\hat{q} = \text{Quantile}\left( \frac{\lceil (n+1)(1-\alpha) \rceil}{n} ; \{s_1, \dots, s_n\} \right)
\]</span></p>
<ul>
<li>여기서 구한 <span class="math inline">\(\hat{q}\)</span>는 <strong>“밀도 함수를 어디서 잘라야(Thresholding) 하는가?”</strong>에 대한 보정된 기준선이 됩니다.</li>
</ul>
</section>
<section id="step-3-construct-prediction-set" class="level4">
<h4 class="anchored" data-anchor-id="step-3-construct-prediction-set">Step 3: Construct Prediction Set</h4>
<ul>
<li>새로운 입력 <span class="math inline">\(X_{test}\)</span>에 대해, Score가 <span class="math inline">\(\hat{q}\)</span> 이하인(즉, 밀도가 <span class="math inline">\(-\hat{q}\)</span> 이상인) 모든 <span class="math inline">\(y\)</span>를 포함합니다.</li>
</ul>
<p><span class="math display">\[
\mathcal{C}(x) = \{ y : s(x, y) \le \hat{q} \} = \{ y : -\hat{f}(y|x) \le \hat{q} \}
\]</span></p>
<ul>
<li>이를 정리하면 최종 예측 집합은 다음과 같습니다:</li>
</ul>
<p><span class="math display">\[
\mathcal{C}(x) = \{ y : \hat{f}(y|x) \ge -\hat{q} \}
\]</span></p>
<ul>
<li>즉, <strong>보정된 임계값 <span class="math inline">\(-\hat{q}\)</span>보다 확률 밀도가 높은 모든 <span class="math inline">\(y\)</span>의 집합(Superlevel Set)</strong>을 구성합니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/bayes_visualization.png" class="img-fluid figure-img"></p>
<figcaption>Figure 10: Conformalized Bayes 알고리즘 시각화. 사후 확률 밀도 함수(Posterior Predictive Density) <span class="math inline">\(\hat{f}(y|x)\)</span>를 Conformal Prediction으로 구한 임계값 <span class="math inline">\(-\hat{q}\)</span>에서 잘라(Slicing), 그 위의 영역을 예측 집합으로 삼는다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="mathematical-derivation-validity" class="level3">
<h3 class="anchored" data-anchor-id="mathematical-derivation-validity">Mathematical Derivation &amp; Validity</h3>
<ul>
<li><p>이 집합이 왜 유효한지(Valid) 수학적으로 살펴보겠습니다.</p></li>
<li><ol type="1">
<li><strong>Calibration Guarantee</strong>:</li>
</ol>
<ul>
<li>Calibration 단계에서 <span class="math inline">\(\hat{q}\)</span>를 구했으므로, 새로운 i.i.d. 샘플에 대해 다음이 성립합니다. <span class="math display">\[ \mathbb{P}[s(X_{test}, Y_{test}) \le \hat{q}] \ge 1 - \alpha \]</span></li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Substitution</strong>:</li>
</ol>
<ul>
<li>Score의 정의 <span class="math inline">\(s(x,y) = -\hat{f}(y|x)\)</span>를 대입합니다. <span class="math display">\[ \mathbb{P}[-\hat{f}(Y_{test} | X_{test}) \le \hat{q}] \ge 1 - \alpha \]</span></li>
</ul></li>
<li><ol start="3" type="1">
<li><strong>Inequality Rearrangement</strong>:</li>
</ol>
<ul>
<li>부등식의 양변에 -1을 곱하여 부등호 방향을 바꿉니다. <span class="math display">\[ \mathbb{P}[\hat{f}(Y_{test} | X_{test}) \ge -\hat{q}] \ge 1 - \alpha \]</span></li>
</ul></li>
</ul>
<p><em>4. <strong>Conclusion</strong>: </em> 따라서, 예측 집합 <span class="math inline">\(\mathcal{C}(X_{test}) = \{ y : \hat{f}(y|X_{test}) \ge -\hat{q} \}\)</span>는 정답 <span class="math inline">\(Y_{test}\)</span>를 <span class="math inline">\(1-\alpha\)</span> 확률로 포함합니다.</p>
</section>
<section id="why-is-this-useful-bayes-optimality" class="level3">
<h3 class="anchored" data-anchor-id="why-is-this-useful-bayes-optimality">Why is this useful? (Bayes Optimality)</h3>
<ul>
<li><p>이 방법은 단순히 유효할(Valid) 뿐만 아니라, 특정 조건 하에서 <strong>효율적(Efficient)</strong>입니다.</p></li>
<li><p>논문에 따르면, 만약 원래의 베이지안 모델이 (비록 틀렸을지라도) 어느 정도 합리적이라면, 이 방법으로 생성된 예측 집합은 <strong><span class="math inline">\(1-\alpha\)</span> 커버리지를 만족하는 모든 예측 집합 중에서 평균 크기(Average Size)가 가장 작습니다 (Bayes Optimal).</strong></p></li>
<li><p>이는 Neyman-Pearson Lemma와 유사한 논리로, “가장 확률 밀도가 높은 곳부터 담는 것”이 주어진 확률 질량을 채우면서 집합의 크기(Volume)를 최소화하는 전략이기 때문입니다.</p></li>
</ul>
</section>
<section id="summary-1" class="level3">
<h3 class="anchored" data-anchor-id="summary-1">Summary</h3>
<ul>
<li><strong>Conformalizing Bayes</strong>는 베이지안 모델의 확률 밀도 함수를 Score로 사용하여 CP를 적용하는 기법입니다.</li>
<li>결과적으로 <strong>“Superlevel Set of Density”</strong> 형태의 예측 집합을 얻게 됩니다.</li>
<li>이 방법은 베이지안 모델의 가정이 틀려도 <strong>Coverage를 보장</strong>하며, 동시에 베이지안 모델의 정보량을 활용하여 <strong>집합의 크기를 최적화</strong>할 수 있습니다.</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="from-observables-to-counterfactuals" class="level1">
<h1>3. From Observables To Counterfactuals</h1>
<section id="evaluating-adaptivity" class="level2">
<h2 class="anchored" data-anchor-id="evaluating-adaptivity">3.1. Evaluating Adaptivity</h2>
<section id="introduction-4" class="level3">
<h3 class="anchored" data-anchor-id="introduction-4">Introduction</h3>
<ul>
<li><p>지금까지 우리는 Conformal Prediction(CP)을 통해 <span class="math inline">\(1-\alpha\)</span>의 커버리지를 보장하는 예측 집합을 만드는 법을 배웠습니다.</p></li>
<li><p>하지만 <strong>“평균적으로 90% 정답을 포함한다(Marginal Coverage)”</strong>는 사실만으로는 충분하지 않습니다.</p></li>
<li><p>예를 들어, 어떤 의사가 쉬운 환자에게는 100% 정확한 진단을 내리지만, 어려운 희귀병 환자에게는 0%의 정확도를 보인다면 어떨까요?</p></li>
<li><p>전체 평균으로는 90% 정확도일지 몰라도, 이는 좋은 시스템이라 할 수 없습니다.</p></li>
<li><p>좋은 CP 알고리즘은 <strong>쉬운 입력에는 작은 집합(Small Sets)</strong>을, <strong>어려운 입력에는 큰 집합(Large Sets)</strong>을 출력해야 합니다. 이를 <strong>Adaptivity(적응성)</strong>라고 합니다.</p></li>
<li><p>이번 포스트에서는 내 모델이 얼마나 “적응적(Adaptive)”인지 평가하는 구체적인 지표들을 알아봅니다.</p></li>
</ul>
</section>
<section id="metric-1-set-size-distribution" class="level3">
<h3 class="anchored" data-anchor-id="metric-1-set-size-distribution">Metric 1: Set Size Distribution</h3>
<ul>
<li>가장 먼저 확인해야 할 지표는 예측 집합 크기(Set Size)의 분포입니다.</li>
<li>단순히 평균 크기만 보는 것이 아니라, <strong>히스토그램</strong>을 그려봐야 합니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/set_size_histogram.png" class="img-fluid figure-img"></p>
<figcaption>Placeholder: Histogram of Set Sizes. X축은 집합의 크기, Y축은 빈도수를 나타낸다. 분포가 넓게 퍼져 있을수록 다양한 난이도의 입력을 잘 구별하고 있다는 의미이다.</figcaption>
</figure>
</div>
<ul>
<li><ol type="1">
<li><strong>Average Set Size</strong>:</li>
</ol>
<ul>
<li>작을수록 좋습니다. (단, <span class="math inline">\(1-\alpha\)</span> 커버리지를 만족하는 전제하에)</li>
<li>평균이 너무 크다면? <span class="math inline">\(\rightarrow\)</span> 모델 성능이 나쁘거나, Score Function이 효율적이지 않음을 의미합니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Spread of Set Sizes</strong>:</li>
</ol>
<ul>
<li>분포가 넓을수록(Dynamic Range가 클수록) 좋습니다.</li>
<li>분포가 넓다는 것은 모델이 “확실한 것(크기 1)”과 “불확실한 것(크기 5 이상)”을 잘 구분하고 있다는 뜻입니다.</li>
</ul></li>
</ul>
</section>
<section id="metric-2-conditional-coverage" class="level3">
<h3 class="anchored" data-anchor-id="metric-2-conditional-coverage">Metric 2: Conditional Coverage</h3>
<ul>
<li>우리가 궁극적으로 원하는 것은 모든 개별 입력 <span class="math inline">\(X\)</span>에 대해 커버리지를 보장하는 <strong>Conditional Coverage</strong>입니다.</li>
</ul>
<p><span class="math display">\[
\mathbb{P}[Y_{test} \in \mathcal{C}(X_{test}) | X_{test}] \ge 1 - \alpha
\]</span></p>
<ul>
<li>하지만 현실적으로 모든 <span class="math inline">\(X\)</span>값 하나하나에 대해 이를 검증하는 것은 불가능합니다(Impossible in general case).</li>
<li>대신 우리는 데이터를 의미 있는 <strong>그룹(Group)</strong>으로 나누어, 각 그룹별로 커버리지가 잘 지켜지는지 확인해야 합니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/conditional_coverage.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Marginal Coverage vs Conditional Coverage 비교. (좌측) 커버리지가 지켜지지 않음. (중앙) Marginal Coverage는 만족하지만 특정 그룹(Group 2)에서 에러가 집중됨. (우측) Conditional Coverage는 모든 그룹에서 고르게 에러가 분산됨.</figcaption>
</figure>
</div>
<ul>
<li>위 그림의 중앙(Marginal) 케이스를 봅시다.
<ul>
<li><strong>Group 1 (Easy)</strong>: 100% 커버리지 (과잉)</li>
<li><strong>Group 2 (Hard)</strong>: 80% 커버리지 (부족)</li>
<li><strong>전체 평균</strong>: 90% 커버리지 (만족)</li>
</ul></li>
<li>이런 경우 “Marginal Coverage는 만족하지만, Conditional Coverage는 실패했다”고 합니다.</li>
<li>이를 잡아내기 위해 다음 두 가지 지표를 사용합니다.</li>
</ul>
<section id="feature-stratified-coverage-fsc" class="level4">
<h4 class="anchored" data-anchor-id="feature-stratified-coverage-fsc">2.1 Feature-stratified Coverage (FSC)</h4>
<ul>
<li><p>데이터의 특성(Feature)에 따라 그룹을 나누어 커버리지를 측정하는 방법입니다.</p></li>
<li><p>예를 들어 인종(Race), 나이대(Age), 혹은 이미지의 밝기 등으로 데이터를 그룹화(<span class="math inline">\(g=1, \dots, G\)</span>)합니다.</p></li>
<li><p>각 그룹 <span class="math inline">\(\mathcal{I}_g\)</span>에 속한 데이터들의 커버리지를 계산하고, <strong>가장 성능이 안 좋은 그룹(Minimum Coverage)</strong>을 찾습니다.</p></li>
</ul>
<p><span class="math display">\[
\text{FSC metric} = \min_{g \in \{1, \dots, G\}} \frac{1}{|\mathcal{I}_g|} \sum_{i \in \mathcal{I}_g} \mathbb{I}\{ Y_i \in \mathcal{C}(X_i) \}
\]</span></p>
<ul>
<li>만약 완벽한 Conditional Coverage라면, 이 값은 <span class="math inline">\(1-\alpha\)</span>에 근접해야 합니다.</li>
<li>이 값이 <span class="math inline">\(1-\alpha\)</span>보다 현저히 낮다면, 특정 그룹(예: 야간 주행 이미지)에서 모델이 실패하고 있음을 의미합니다.</li>
</ul>
</section>
<section id="size-stratified-coverage-ssc" class="level4">
<h4 class="anchored" data-anchor-id="size-stratified-coverage-ssc">2.2 Size-stratified Coverage (SSC)</h4>
<ul>
<li>하지만 어떤 Feature가 중요한지 모를 때는 어떻게 할까요?</li>
<li>이때 사용할 수 있는 아주 일반적이고 강력한 방법이 <strong>“예측 집합의 크기”</strong>로 그룹을 나누는 것입니다.
<ul>
<li>그룹 1: 집합 크기가 1인 데이터들 (<span class="math inline">\(\mathcal{C}(x)| = 1\)</span>)</li>
<li>그룹 2: 집합 크기가 2인 데이터들</li>
<li>…</li>
</ul></li>
<li>모델이 “이건 정말 어려워서 후보를 10개나 뽑았어”라고 말한 경우(집합 크기 10), 실제로도 그 안에 정답이 90% 확률로 들어 있어야 합니다.</li>
</ul>
<p><span class="math display">\[
\text{SSC metric} = \min_{g \in \{ \text{set sizes} \}} \frac{1}{|\mathcal{I}_g|} \sum_{i \in \mathcal{I}_g} \mathbb{I}\{ Y_i \in \mathcal{C}(X_i) \}
\]</span></p>
<ul>
<li>이 지표는 사용자가 사전에 그룹을 정의할 필요가 없으므로(Feature-agnostic), 어떤 상황에서도 바로 적용해볼 수 있는 훌륭한 진단 도구입니다.</li>
</ul>
</section>
</section>
<section id="summary-2" class="level3">
<h3 class="anchored" data-anchor-id="summary-2">Summary</h3>
<ul>
<li>Conformal Prediction을 평가할 때는 단순히 전체 커버리지만 보지 말고, 다음을 꼭 확인해야합니다:
<ul>
<li><ol type="1">
<li><strong>Histogram of Set Sizes</strong>: 쉬운 건 작게, 어려운 건 크게 잘 구분하고 있는가?</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Stratified Coverage (FSC / SSC)</strong>: 특정 그룹(인종, 나이, 혹은 모델이 불확실해하는 그룹)에서만 커버리지가 깨지고 있지는 않은가?</li>
</ol></li>
</ul></li>
<li>이러한 <strong>Adaptivity</strong> 체크는 실험실 환경을 넘어 실제 서비스(Production)에 CP를 적용할 때 “Non-negotiable(타협할 수 없는)” 필수 검증 단계입니다.</li>
</ul>
<hr>
</section>
</section>
<section id="the-effect-of-the-size-of-the-calibration-set" class="level2">
<h2 class="anchored" data-anchor-id="the-effect-of-the-size-of-the-calibration-set">3.2. The Effect of the Size of the Calibration Set</h2>
<section id="introduction-5" class="level3">
<h3 class="anchored" data-anchor-id="introduction-5">Introduction</h3>
<ul>
<li>Conformal Prediction(CP)을 실제 서비스에 배포할 때, 엔지니어가 가장 먼저 마주하는 실무적인 질문은 이것입니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>“Calibration Set(<span class="math inline">\(n\)</span>)의 크기는 얼마나 커야 할까요? 100개면 충분한가요, 아니면 1,000개가 필요한가요?”</strong></p>
</blockquote>
<ul>
<li><p>이론적으로 CP의 커버리지 보장(<span class="math inline">\(1-\alpha\)</span>)은 <span class="math inline">\(n\)</span>의 크기와 상관없이 성립합니다(Finite-sample guarantee).</p></li>
<li><p>하지만 직관적으로 생각했을 때, 데이터가 많을수록 더 안정적일 것이라 예상할 수 있습니다.</p></li>
<li><p>이번 포스트에서는 <strong>Calibration Set의 크기 <span class="math inline">\(n\)</span>이 예측 구간의 안정성(Stability)에 미치는 영향</strong>을 수학적으로 분석하고, 실무적인 가이드라인(<span class="math inline">\(n \approx 1000\)</span>)을 제시합니다.</p></li>
</ul>
</section>
<section id="validity-vs.-stability" class="level3">
<h3 class="anchored" data-anchor-id="validity-vs.-stability">Validity vs.&nbsp;Stability</h3>
<section id="the-theoretical-guarantee-validity" class="level4">
<h4 class="anchored" data-anchor-id="the-theoretical-guarantee-validity">The Theoretical Guarantee (Validity)</h4>
<ul>
<li>놀랍게도, CP의 커버리지 보장 정리(Theorem 1)는 <strong>모든 <span class="math inline">\(n\)</span>에 대해 성립</strong>합니다.</li>
<li>Calibration 데이터가 단 10개뿐이라도, 새로운 데이터에 대한 평균 커버리지는 <span class="math inline">\(1-\alpha\)</span>를 만족합니다.</li>
</ul>
</section>
<section id="the-catch-stability" class="level4">
<h4 class="anchored" data-anchor-id="the-catch-stability">The Catch (Stability)</h4>
<ul>
<li><p>하지만 여기에는 중요한 디테일이 숨어 있습니다.</p></li>
<li><p>우리가 보장하는 것은 <strong>“Calibration Set을 무한히 새로 뽑았을 때의 평균”</strong>입니다.</p></li>
<li><p>하지만 현실에서 우리는 <strong>단 하나의 고정된 Calibration Set</strong>을 사용합니다.</p></li>
<li><p>만약 우리가 운이 나빠서 이상한(Bias된) 데이터가 섞인 Calibration Set을 뽑았다면 어떨까요?</p></li>
<li><p>이 고정된 데이터셋으로 학습된 CP 모델을 무한한 테스트 데이터에 적용했을 때의 실제 커버리지는 <span class="math inline">\(1-\alpha\)</span>와 정확히 일치하지 않을 수 있습니다.</p></li>
<li><p>즉, <strong>Calibration Set 자체의 무작위성(Randomness)</strong> 때문에 실제 커버리지는 <strong>확률 변수(Random Quantity)</strong>가 됩니다.</p></li>
</ul>
</section>
</section>
<section id="mathematical-derivation-beta-distribution" class="level3">
<h3 class="anchored" data-anchor-id="mathematical-derivation-beta-distribution">Mathematical Derivation: Beta Distribution</h3>
<ul>
<li>Vladimir Vovk는 고정된 Calibration Set이 주어졌을 때, 무한한 검증 데이터에 대한 커버리지 확률 분포가 <strong>베타 분포(Beta Distribution)</strong>를 따른다는 것을 증명했습니다.</li>
</ul>
<p><span class="math display">\[
\mathbb{P}(Y_{test} \in \mathcal{C}(X_{test}) \mid \{(X_i, Y_i)\}_{i=1}^n) \sim \text{Beta}(n+1-l, l)
\]</span></p>
<ul>
<li>여기서 파라미터 <span class="math inline">\(l\)</span>은 다음과 같이 정의됩니다: <span class="math display">\[
l = \lfloor (n+1)\alpha \rfloor
\]</span>
<ul>
<li><strong>의미</strong>: 이 식은 <span class="math inline">\(n\)</span>이 커질수록 커버리지 확률 분포가 <span class="math inline">\(1-\alpha\)</span>를 중심으로 얼마나 뾰족하게(Sharp) 모이는지를 설명합니다.</li>
<li><strong>평균</strong>: 베타 분포의 성질에 의해 이 분포의 기댓값은 정확히 <span class="math inline">\(1-\alpha\)</span>가 됩니다 (Validity).</li>
<li><strong>분산</strong>: <span class="math inline">\(n\)</span>이 작을수록 분산이 커져서, 실제 커버리지가 목표치 <span class="math inline">\(1-\alpha\)</span>에서 크게 벗어날 확률이 높아집니다.</li>
</ul></li>
</ul>
</section>
<section id="visualizing-the-effect-of-n" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-the-effect-of-n">Visualizing the Effect of <span class="math inline">\(n\)</span></h3>
<ul>
<li>이 현상을 시각적으로 확인해보겠습니다.</li>
<li>아래 그래프는 Calibration Set의 크기 <span class="math inline">\(n\)</span>에 따른 커버리지 확률의 밀도 함수를 보여줍니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/coverage_distribution.png" class="img-fluid figure-img"></p>
<figcaption>Figure: 무한한 Validation Set에 대한 커버리지 분포. <span class="math inline">\(n\)</span>이 100일 때는 분포가 넓게 퍼져 있지만, <span class="math inline">\(n\)</span>이 10,000일 때는 <span class="math inline">\(1-\alpha(0.9)\)</span> 근처에 매우 좁게 집중된다. 분포는 <span class="math inline">\(\mathcal{O}(n^{-1/2})\)</span>의 속도로 수렴한다.</figcaption>
</figure>
</div>
<ul>
<li><strong><span class="math inline">\(n=100\)</span> (파란색)</strong>: 그래프가 넓게 퍼져 있습니다. 운이 나쁘면 실제 커버리지가 85%나 95%가 될 수도 있습니다.</li>
<li><strong><span class="math inline">\(n=1,000\)</span> (주황색)</strong>: 그래프가 훨씬 좁아졌습니다. 대부분의 경우 커버리지가 <strong>88% ~ 92%</strong> 사이로 유지됩니다.</li>
<li><strong><span class="math inline">\(n=10,000\)</span> (초록색)</strong>: 매우 뾰족합니다. 거의 정확하게 90%를 맞춥니다.</li>
</ul>
</section>
<section id="practical-guideline-the-n1000-rule" class="level3">
<h3 class="anchored" data-anchor-id="practical-guideline-the-n1000-rule">Practical Guideline: The “n=1000” Rule</h3>
<ul>
<li>그렇다면 실무에서는 몇 개를 써야 할까요?</li>
<li>논문에서는 <strong><span class="math inline">\(n=1000\)</span> 정도면 대부분의 목적에 충분하다</strong>고 제안합니다.
<ul>
<li><ol type="1">
<li><strong>안정성 확보</strong>: 위 그래프에서 보듯이, <span class="math inline">\(n=1000\)</span>일 때 커버리지는 목표치(<span class="math inline">\(1-\alpha\)</span>)에서 <span class="math inline">\(\pm 2\%\)</span> 내외의 오차 범위를 가집니다. 이는 대부분의 머신러닝 애플리케이션에서 허용 가능한 수준입니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>비용 효율성</strong>: 데이터를 10,000개까지 늘려도 얻을 수 있는 이득(오차 감소)은 크지 않습니다. (수렴 속도가 <span class="math inline">\(\mathcal{O}(n^{-1/2})\)</span>로 느려지기 때문)</li>
</ol></li>
</ul></li>
</ul>
<section id="required-sample-size-calculation" class="level4">
<h4 class="anchored" data-anchor-id="required-sample-size-calculation">Required Sample Size Calculation</h4>
<ul>
<li>만약 더 엄격한 기준(예: 99% 확률로 오차 1% 이내)이 필요하다면, 다음 표를 참고하여 필요한 <span class="math inline">\(n\)</span>을 역산할 수 있습니다.</li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">허용 오차 (<span class="math inline">\(\epsilon\)</span>)</th>
<th style="text-align: left;">필요한 <span class="math inline">\(n\)</span> (신뢰도 90%)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0.1 (10%)</td>
<td style="text-align: left;">22</td>
</tr>
<tr class="even">
<td style="text-align: left;">0.05 (5%)</td>
<td style="text-align: left;">102</td>
</tr>
<tr class="odd">
<td style="text-align: left;">0.01 (1%)</td>
<td style="text-align: left;">2,491</td>
</tr>
<tr class="even">
<td style="text-align: left;">0.005 (0.5%)</td>
<td style="text-align: left;">9,812</td>
</tr>
</tbody>
</table>
<ul>
<li>일반적인 기준인 90% 신뢰도(<span class="math inline">\(\delta=0.1\)</span>)에서 목표 커버리지와의 오차를 1%(<span class="math inline">\(\epsilon=0.01\)</span>) 이내로 줄이려면 약 <strong>2,500개</strong>의 데이터가 필요합니다.</li>
<li>하지만 5% 오차(<span class="math inline">\(\epsilon=0.05\)</span>)를 허용한다면 <strong>102개</strong>로도 충분합니다.</li>
</ul>
</section>
</section>
<section id="summary-3" class="level3">
<h3 class="anchored" data-anchor-id="summary-3">Summary</h3>
<ul>
<li>Conformal Prediction은 <span class="math inline">\(n\)</span>이 작아도 평균적으로는 커버리지를 보장합니다.</li>
<li>하지만 <strong>개별 Calibration Set에 대한 신뢰도(Stability)</strong>를 높이기 위해서는 충분한 <span class="math inline">\(n\)</span>이 필요합니다.</li>
<li><strong>Rule of Thumb</strong>: 약 <strong>1,000개</strong>의 Calibration 데이터를 사용하면, 실제 커버리지가 목표치에서 크게 벗어나지 않음(약 <span class="math inline">\(\pm 2\%\)</span>)을 확신할 수 있습니다.</li>
</ul>
<hr>
</section>
</section>
<section id="checking-for-correct-coverage" class="level2">
<h2 class="anchored" data-anchor-id="checking-for-correct-coverage">3.3. Checking for Correct Coverage</h2>
<section id="introduction-6" class="level3">
<h3 class="anchored" data-anchor-id="introduction-6">Introduction</h3>
<ul>
<li><p>Conformal Prediction(CP)을 구현했다면, 가장 먼저 해야 할 일은 <strong>“이게 정말 작동하는가?”</strong>를 확인하는 것입니다.</p></li>
<li><p>즉, 우리가 설정한 목표 커버리지(예: 90%)가 실제 테스트 데이터에서도 지켜지는지 검증해야 합니다.</p></li>
<li><p>하지만 단순히 한 번의 테스트 셋 결과만 보고 “90.1%니까 성공!”이라고 단정 짓기는 어렵습니다.</p></li>
<li><p>데이터의 무작위성 때문에 우연히 잘 나왔을 수도, 우연히 못 나왔을 수도 있기 때문입니다.</p></li>
<li><p>따라서 우리는 <strong>여러 번의 실험(Trials)</strong>을 통해 커버리지 분포를 확인해야 합니다.</p></li>
</ul>
</section>
<section id="methodology-repeated-experiments" class="level3">
<h3 class="anchored" data-anchor-id="methodology-repeated-experiments">Methodology: Repeated Experiments</h3>
<ul>
<li>가장 확실한 검증 방법은 <span class="math inline">\(R\)</span>번의 독립적인 실험을 수행하는 것입니다.</li>
<li>각 실험 <span class="math inline">\(j=1, \dots, R\)</span>마다 새로운 Calibration Set과 Validation Set을 준비하고, 다음 과정을 반복합니다:
<ul>
<li><ol type="1">
<li>Calibration 수행 <span class="math inline">\(\rightarrow\)</span> <span class="math inline">\(\hat{q}_j\)</span> 계산</li>
</ol></li>
<li><ol start="2" type="1">
<li>Validation Set에 대해 예측 집합 구성 <span class="math inline">\(\mathcal{C}_j\)</span></li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>경험적 커버리지(Empirical Coverage)</strong> <span class="math inline">\(C_j\)</span> 계산:</li>
</ol></li>
</ul></li>
</ul>
<p><span class="math display">\[
C_j = \frac{1}{n_{val}} \sum_{i=1}^{n_{val}} \mathbb{I} \{ Y_{i,j}^{(val)} \in \mathcal{C}_j(X_{i,j}^{(val)}) \}
\]</span></p>
<ul>
<li>이렇게 얻은 <span class="math inline">\(R\)</span>개의 커버리지 값들 <span class="math inline">\(C_1, \dots, C_R\)</span>의 평균 <span class="math inline">\(\overline{C}\)</span>는 이론적으로 <span class="math inline">\(1-\alpha\)</span>에 매우 근접해야 합니다.</li>
</ul>
<p><span class="math display">\[
\overline{C} = \frac{1}{R} \sum_{j=1}^{R} C_j \approx 1 - \alpha
\]</span></p>
<ul>
<li>또한, <span class="math inline">\(C_j\)</span>들의 히스토그램을 그렸을 때 <span class="math inline">\(1-\alpha\)</span>를 중심으로 종 모양(Bell-curve) 분포를 보여야 합니다.</li>
</ul>
</section>
<section id="the-practical-challenge-limited-data" class="level3">
<h3 class="anchored" data-anchor-id="the-practical-challenge-limited-data">The Practical Challenge: Limited Data</h3>
<ul>
<li><p>현실적인 문제는 <strong>“매번 새로운 데이터를 어디서 구하는가?”</strong>입니다.</p></li>
<li><p>우리가 가진 데이터는 유한(총 <span class="math inline">\(n_{total} = n + n_{val}\)</span>)하므로, <span class="math inline">\(R\)</span>번이나 새로운 데이터를 수집할 수는 없습니다.</p></li>
<li><p>따라서 우리는 <strong>Resampling (Random Split)</strong> 방식을 사용합니다.</p></li>
<li><p>전체 데이터를 무작위로 섞어서 Calibration/Validation 셋으로 나누는 과정을 <span class="math inline">\(R\)</span>번 반복하는 것입니다.</p></li>
</ul>
<section id="efficiency-trick-score-caching" class="level4">
<h4 class="anchored" data-anchor-id="efficiency-trick-score-caching">Efficiency Trick: Score Caching</h4>
<ul>
<li><p>하지만 <span class="math inline">\(R\)</span>번(예: 100번)이나 모델을 다시 학습시키거나 추론(Inference)을 돌리는 것은 계산 비용이 매우 큽니다.</p></li>
<li><p>여기서 중요한 팁은 <strong>Conformal Score를 미리 계산해두는 것(Caching)</strong>입니다.</p></li>
<li><p>CP 알고리즘은 <strong>Score값(<span class="math inline">\(s_i\)</span>)들의 순위</strong>에만 의존합니다.</p></li>
<li><p>데이터가 어느 셋(Calibration vs Validation)에 속하느냐에 따라 역할만 달라질 뿐, 각 데이터 포인트의 Score 값 자체는 변하지 않습니다.</p></li>
<li><p>따라서 다음과 같이 효율적으로 검증할 수 있습니다:</p>
<ul>
<li><ol type="1">
<li><strong>Pre-computation</strong>: 전체 데이터에 대해 Score를 미리 한 번만 계산합니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Shuffle &amp; Split</strong>: 계산된 Score 배열만 무작위로 섞어서 나눕니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Evaluate</strong>: 나누어진 Score들로 Quantile을 구하고 커버리지를 계산합니다.</li>
</ol></li>
</ul></li>
<li><p>이 방식을 사용하면 딥러닝 모델을 매번 돌릴 필요가 없어 검증 속도가 수백 배 빨라집니다.</p></li>
</ul>
</section>
</section>
<section id="implementation-2" class="level3">
<h3 class="anchored" data-anchor-id="implementation-2">Implementation</h3>
<ul>
<li>Python 코드로 이를 구현하면 다음과 같습니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/coverage_check_code.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Score Caching을 이용한 효율적인 커버리지 검증 코드. 전체 Score를 미리 계산해두고(<code>get_scores</code>), 반복문 안에서는 단순히 배열을 섞고(<code>shuffle</code>) 자르는 연산만 수행한다.</figcaption>
</figure>
</div>
<section id="code-explanation" class="level4">
<h4 class="anchored" data-anchor-id="code-explanation">Code Explanation</h4>
<ul>
<li><ol type="1">
<li><strong>Load/Compute Scores</strong>: <code>get_scores(X, Y)</code>를 통해 모든 데이터의 Score를 계산하고 저장합니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Loop <span class="math inline">\(R\)</span> times</strong>:</li>
</ol>
<ul>
<li><code>np.random.shuffle(scores)</code>: Score들을 섞습니다.</li>
<li><code>calib, val = scores[:n], scores[n:]</code>: <span class="math inline">\(n\)</span>개는 Calibration용, 나머지는 검증용으로 나눕니다.</li>
<li><code>qhat</code>: Calibration Score들로 Quantile을 계산합니다.</li>
<li><code>mean()</code>: Validation Score들이 <code>qhat</code>보다 작은 비율(Coverage)을 계산합니다.</li>
</ul></li>
<li><ol start="3" type="1">
<li><strong>Check</strong>: <code>coverages.mean()</code>이 <span class="math inline">\(1-\alpha\)</span>와 비슷한지 확인하고, 히스토그램을 그립니다.</li>
</ol></li>
</ul>
</section>
</section>
<section id="interpretation-of-results" class="level3">
<h3 class="anchored" data-anchor-id="interpretation-of-results">Interpretation of Results</h3>
<ul>
<li><p>검증 결과 커버리지가 정확히 90.00%가 나오지 않더라도 당황할 필요는 없습니다.</p></li>
<li><p><span class="math inline">\(n\)</span> (Calibration 크기), <span class="math inline">\(n_{val}\)</span> (Validation 크기), <span class="math inline">\(R\)</span> (반복 횟수)이 모두 유한하기 때문에 <strong>약간의 변동(Benign Fluctuations)</strong>은 자연스러운 현상입니다.</p></li>
<li><p><strong>정상</strong>: 평균이 0.89 ~ 0.91 사이이며 히스토그램이 0.9 근처에 모여 있음.</p></li>
<li><p><strong>비정상</strong>: 평균이 0.80처럼 현저히 낮거나, 히스토그램이 한쪽으로 크게 치우침 <span class="math inline">\(\rightarrow\)</span> 구현 오류(버그) 혹은 데이터 분포의 문제(i.i.d. 위반 등)를 의심해야 합니다.</p></li>
<li><p>이 진단 과정을 통과했다면, 여러분의 Conformal Predictor는 통계적으로 신뢰할 수 있는 상태입니다.</p></li>
</ul>
<hr>
</section>
</section>
</section>
<section id="from-counterfactuals-to-treatment-effects" class="level1">
<h1>4. From Counterfactuals to Treatment Effects</h1>
<section id="group-balanced-conformal-prediction" class="level2">
<h2 class="anchored" data-anchor-id="group-balanced-conformal-prediction">4.1. Group-Balanced Conformal Prediction</h2>
<section id="introduction-the-fairness-problem" class="level3">
<h3 class="anchored" data-anchor-id="introduction-the-fairness-problem">Introduction: The Fairness Problem</h3>
<ul>
<li><p>지금까지 우리는 전체 데이터셋에 대해 평균적으로 <span class="math inline">\(1-\alpha\)</span>의 커버리지를 보장하는 방법(Marginal Coverage)을 배웠습니다.</p></li>
<li><p>하지만 현실 세계, 특히 의료나 금융 같은 민감한 분야에서는 “평균적인 성공”만으로는 충분하지 않습니다.</p></li>
<li><p>예를 들어, 어떤 질병 진단 AI가 백인 환자에게는 99%의 정확도를 보이지만, 유색 인종 환자에게는 80%의 정확도밖에 보이지 않는다고 가정해봅시다.</p></li>
<li><p>이 경우 백인 환자가 다수라면 전체 평균 정확도는 90%를 넘길 수 있겠지만, 이는 <strong>공정하지 못한(Unfair)</strong> 시스템입니다.</p></li>
<li><p><strong>Group-Balanced Conformal Prediction</strong>은 이러한 문제를 해결하기 위해, 데이터 내의 특정 그룹(인종, 성별, 연령대 등) 각각에 대해 독립적으로 커버리지를 보장하는 기법입니다.</p></li>
</ul>
</section>
<section id="problem-formulation" class="level3">
<h3 class="anchored" data-anchor-id="problem-formulation">Problem Formulation</h3>
<ul>
<li><p>우리의 입력 데이터 <span class="math inline">\(X\)</span>의 첫 번째 특성(Feature) <span class="math inline">\(X_{i,1}\)</span>이 그룹을 나타내는 범주형 변수라고 가정해봅시다.</p></li>
<li><p>이 그룹은 <span class="math inline">\(\{1, \dots, G\}\)</span> 중 하나의 값을 가집니다.</p></li>
<li><p>기존의 CP는 다음을 보장했습니다: <span class="math display">\[ \mathbb{P}(Y_{test} \in \mathcal{C}(X_{test})) \ge 1-\alpha \]</span></p></li>
<li><p>하지만 우리가 원하는 것은 <strong>모든 그룹 <span class="math inline">\(g\)</span>에 대해</strong> 다음이 성립하는 것입니다:</p></li>
</ul>
<p><span class="math display">\[
\mathbb{P}(Y_{test} \in \mathcal{C}(X_{test}) \mid X_{test,1} = g) \ge 1-\alpha, \quad \forall g \in \{1, \dots, G\}
\]</span></p>
<ul>
<li>즉, 어떤 그룹에 속한 데이터가 들어오더라도 똑같이 <span class="math inline">\(1-\alpha\)</span> 이상의 확률로 정답을 포함해야 합니다.</li>
</ul>
</section>
<section id="the-algorithm-2" class="level3">
<h3 class="anchored" data-anchor-id="the-algorithm-2">The Algorithm</h3>
<ul>
<li>이 문제를 해결하는 방법은 직관적입니다. <strong>“그룹별로 따로따로 Conformal Prediction을 수행”</strong>하는 것입니다.</li>
</ul>
<section id="step-1-stratify-calibration-data" class="level4">
<h4 class="anchored" data-anchor-id="step-1-stratify-calibration-data">Step 1: Stratify Calibration Data</h4>
<ul>
<li>Calibration 데이터셋을 그룹별로 나눕니다.</li>
<li>그룹 <span class="math inline">\(g\)</span>에 속하는 데이터들만 모아서 부분집합을 만듭니다.</li>
</ul>
<p><span class="math display">\[
S^{(g)} = \{ (X_j, Y_j) : X_{j,1} = g \}
\]</span></p>
</section>
<section id="step-2-calibrate-per-group" class="level4">
<h4 class="anchored" data-anchor-id="step-2-calibrate-per-group">Step 2: Calibrate per Group</h4>
<ul>
<li>각 그룹 <span class="math inline">\(g\)</span>에 대해 독립적으로 Quantile <span class="math inline">\(\hat{q}^{(g)}\)</span>를 계산합니다.</li>
<li><ol type="1">
<li>그룹 <span class="math inline">\(g\)</span> 데이터에 대한 Conformal Score들을 계산합니다: <span class="math display">\[s^{(g)}_1, \dots, s^{(g)}_{n^{(g)}}\]</span></li>
</ol></li>
<li><ol start="2" type="1">
<li>해당 그룹의 데이터 개수 <span class="math inline">\(n^{(g)}\)</span>를 기준으로 보정된 분위수를 구합니다: <span class="math display">\[
\hat{q}^{(g)} = \text{Quantile}\left( \frac{\lceil (n^{(g)}+1)(1-\alpha) \rceil}{n^{(g)}} ; \{s^{(g)}_1, \dots, s^{(g)}_{n^{(g)}}\} \right)
\]</span></li>
</ol></li>
<li>결과적으로 우리는 그룹의 개수만큼 서로 다른 임계값(Threshold) <span class="math inline">\(\hat{q}^{(1)}, \dots, \hat{q}^{(G)}\)</span>를 얻게 됩니다.
<ul>
<li>모델이 잘 맞추는 쉬운 그룹은 <span class="math inline">\(\hat{q}\)</span>가 작을 것이고 (작은 예측 집합),</li>
<li>모델이 어려워하는 그룹은 <span class="math inline">\(\hat{q}\)</span>가 클 것입니다 (큰 예측 집합).</li>
</ul></li>
</ul>
</section>
<section id="step-3-inference" class="level4">
<h4 class="anchored" data-anchor-id="step-3-inference">Step 3: Inference</h4>
<ul>
<li>새로운 테스트 데이터 <span class="math inline">\(X_{test}\)</span>가 들어오면, 먼저 이 데이터가 어느 그룹에 속하는지(<span class="math inline">\(X_{test,1}\)</span>) 확인합니다.</li>
<li>그리고 해당 그룹에 맞는 임계값 <span class="math inline">\(\hat{q}^{(X_{test,1})}\)</span>을 사용하여 예측 집합을 구성합니다.</li>
</ul>
<p><span class="math display">\[
\mathcal{C}(x) = \{ y : s(x, y) \le \hat{q}^{(x_1)} \}
\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/group_balanced_cp_visualization.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Group-Balanced Conformal Prediction의 개념도. 전체 데이터를 파란색 그룹과 초록색 그룹으로 나누고, 각각의 분포(Histogram)에서 별도의 Quantile <span class="math inline">\(\hat{q}^{(1)}, \hat{q}^{(2)}\)</span>를 계산하여 적용한다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="theoretical-guarantee-1" class="level3">
<h3 class="anchored" data-anchor-id="theoretical-guarantee-1">Theoretical Guarantee</h3>
<ul>
<li>이 방법은 Vovk에 의해 처음 제안되었으며, 다음의 명제에 의해 수학적으로 정당화됩니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Proposition 1 (Error control guarantee for group-balanced conformal prediction)</strong></p>
<p>데이터가 i.i.d. 가정하에 추출되었다면, 위 알고리즘을 통해 생성된 예측 집합 <span class="math inline">\(\mathcal{C}\)</span>는 모든 그룹 <span class="math inline">\(g\)</span>에 대해 다음을 만족한다.</p>
<p><span class="math display">\[ \mathbb{P}(Y_{test} \in \mathcal{C}(X_{test}) \mid X_{test,1} = g) \ge 1-\alpha \]</span></p>
</blockquote>
<ul>
<li>이로써 우리는 인종, 성별 등 민감한 속성에 관계없이 모든 사용자에게 <strong>동등한 수준의 안전장치(Equal Coverage)</strong>를 제공할 수 있게 됩니다.</li>
</ul>
</section>
<section id="practical-note" class="level3">
<h3 class="anchored" data-anchor-id="practical-note">Practical Note</h3>
<ul>
<li><strong>Explicit Groups</strong>: 인종, 성별처럼 데이터에 명시적으로 존재하는 카테고리를 사용할 수 있습니다.</li>
<li><strong>Constructed Groups (Binning)</strong>: 나이(Age)와 같은 연속형 변수라도, ‘20대’, ‘30대’ 등으로 구간화(Binning)하여 그룹을 만든 뒤 이 방법을 적용할 수 있습니다. 이를 통해 연속적인 특성에 대한 Conditional Coverage를 근사할 수 있습니다.</li>
</ul>
<hr>
</section>
</section>
<section id="class-conditional-conformal-prediction" class="level2">
<h2 class="anchored" data-anchor-id="class-conditional-conformal-prediction">4.2. Class-Conditional Conformal Prediction</h2>
<section id="introduction-the-problem-with-imbalanced-classes" class="level3">
<h3 class="anchored" data-anchor-id="introduction-the-problem-with-imbalanced-classes">Introduction: The Problem with Imbalanced Classes</h3>
<ul>
<li><p>머신러닝 분류 문제, 특히 의료 진단과 같은 분야에서는 <strong>클래스 불균형(Class Imbalance)</strong>이 흔하게 발생합니다.</p></li>
<li><p>예를 들어, 암 진단 모델을 개발한다고 가정해봅시다.</p>
<ul>
<li><strong>정상(Normal)</strong>: 데이터의 95%</li>
<li><strong>암(Cancer)</strong>: 데이터의 5%</li>
</ul></li>
<li><p>우리가 일반적인 Conformal Prediction을 사용하여 95% 커버리지를 달성했다고 칩시다.</p></li>
<li><p>가장 쉬운 달성 방법은 무엇일까요?</p></li>
<li><p><strong>“그냥 모든 환자를 ’정상’이라고 예측하고, 암 환자는 다 틀리는 것”</strong>입니다.</p></li>
<li><p>이렇게 해도 (정상 95% + 암 0%) / 100% <span class="math inline">\(\approx\)</span> 95% 커버리지는 달성됩니다.</p></li>
<li><p>하지만 이는 재앙입니다.</p></li>
<li><p>우리는 암 환자에 대해서도 똑같이 95%의 정확도로 정답을 포함시키기를 원합니다.</p></li>
<li><p><strong>Class-Conditional Conformal Prediction</strong>은 바로 이 문제, 즉 <strong>모든 정답 클래스(Ground Truth Class)</strong>에 대해 균등한 커버리지를 보장하기 위한 방법입니다.</p></li>
</ul>
</section>
<section id="problem-formulation-1" class="level3">
<h3 class="anchored" data-anchor-id="problem-formulation-1">Problem Formulation</h3>
<ul>
<li>우리의 목표는 단순한 전체 평균(<span class="math inline">\(1-\alpha\)</span>)이 아니라, <strong>각 클래스 <span class="math inline">\(y \in \{1, \dots, K\}\)</span> 별로</strong> 조건부 커버리지를 만족하는 것입니다.</li>
</ul>
<p><span class="math display">\[
\mathbb{P}(Y_{test} \in \mathcal{C}(X_{test}) \mid Y_{test} = y) \ge 1-\alpha, \quad \forall y \in \{1, \dots, K\}
\]</span></p>
<ul>
<li>이것이 보장된다면, “암 환자” 그룹 내에서도 정답이 예측 집합에 포함될 확률이 95% 이상이 되고, “정상인” 그룹 내에서도 마찬가지가 됩니다.</li>
</ul>
</section>
<section id="the-algorithm-3" class="level3">
<h3 class="anchored" data-anchor-id="the-algorithm-3">The Algorithm</h3>
<ul>
<li>알고리즘은 Group-Balanced CP와 유사하게 <strong>“따로따로(Separately)”</strong> 전략을 취하지만, 추론(Inference) 단계에서 중요한 차이가 있습니다.</li>
</ul>
<section id="step-1-stratify-calibration-data-by-class" class="level4">
<h4 class="anchored" data-anchor-id="step-1-stratify-calibration-data-by-class">Step 1: Stratify Calibration Data by Class</h4>
<ul>
<li>Calibration 데이터셋을 실제 정답 클래스(Ground Truth Class)별로 나눕니다.</li>
</ul>
<p><span class="math display">\[
S^{(k)} = \{ (X_j, Y_j) : Y_j = k \}
\]</span></p>
</section>
<section id="step-2-calibrate-per-class" class="level4">
<h4 class="anchored" data-anchor-id="step-2-calibrate-per-class">Step 2: Calibrate per Class</h4>
<ul>
<li>각 클래스 <span class="math inline">\(k\)</span>에 대해 독립적으로 Quantile <span class="math inline">\(\hat{q}^{(k)}\)</span>를 계산합니다.
<ul>
<li><ol type="1">
<li>클래스 <span class="math inline">\(k\)</span>에 속하는 데이터들의 Score <span class="math inline">\(s^{(k)}_1, \dots, s^{(k)}_{n^{(k)}}\)</span>를 모읍니다.</li>
</ol></li>
<li><ol start="2" type="1">
<li>해당 클래스의 데이터 수 <span class="math inline">\(n^{(k)}\)</span>를 기준으로 보정된 분위수를 구합니다: <span class="math display">\[
\hat{q}^{(k)} = \text{Quantile}\left( \frac{\lceil (n^{(k)}+1)(1-\alpha) \rceil}{n^{(k)}} ; \{s^{(k)}_1, \dots, s^{(k)}_{n^{(k)}}\} \right)
\]</span></li>
</ol></li>
</ul></li>
<li>결과적으로 우리는 클래스 개수만큼의 임계값 <span class="math inline">\(\hat{q}^{(1)}, \dots, \hat{q}^{(K)}\)</span>를 얻습니다.
<ul>
<li>샘플이 적거나 모델이 어려워하는 클래스(예: 암)는 임계값이 높게(보수적으로) 설정될 것입니다.</li>
</ul></li>
</ul>
</section>
<section id="step-3-inference-iterative-check" class="level4">
<h4 class="anchored" data-anchor-id="step-3-inference-iterative-check">Step 3: Inference (Iterative Check)</h4>
<ul>
<li><p>이 부분이 4.1절(Group-Balanced)과 가장 다릅니다.</p></li>
<li><p>테스트 시점에는 입력 <span class="math inline">\(X_{test}\)</span>의 <strong>진짜 클래스(True Class)가 무엇인지 모릅니다.</strong></p></li>
<li><p>따라서 “해당 그룹의 <span class="math inline">\(\hat{q}\)</span>를 가져다 쓰는” 방식은 불가능합니다.</p></li>
<li><p>대신, 우리는 <strong>“만약 정답이 클래스 <span class="math inline">\(y\)</span>라면?”</strong>이라는 가정을 모든 후보 클래스에 대해 수행합니다.</p></li>
<li><p>예측 집합 <span class="math inline">\(\mathcal{C}(x)\)</span>는 다음 조건을 만족하는 모든 클래스 <span class="math inline">\(y\)</span>를 포함합니다: <span class="math display">\[
\mathcal{C}(x) = \{ y : s(x, y) \le \hat{q}^{(y)} \}
\]</span></p>
<ul>
<li>후보 클래스 <span class="math inline">\(y\)</span>가 ‘암’이라면? <span class="math inline">\(\rightarrow\)</span> <span class="math inline">\(s(x, \text{암})\)</span>을 계산하고, 이를 ’암’ 클래스의 임계값 <span class="math inline">\(\hat{q}^{(\text{암})}\)</span>과 비교합니다.</li>
<li>후보 클래스 <span class="math inline">\(y\)</span>가 ‘정상’이라면? <span class="math inline">\(\rightarrow\)</span> <span class="math inline">\(s(x, \text{정상})\)</span>을 계산하고, 이를 ’정상’ 클래스의 임계값 <span class="math inline">\(\hat{q}^{(\text{정상})}\)</span>과 비교합니다.</li>
</ul></li>
<li><p>각 클래스마다 <strong>자신만의 기준(Threshold)</strong>을 통과해야 집합에 들어갈 수 있는 것입니다.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/class_conditional_cp_visualization.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Class-Conditional Conformal Prediction의 개념도. Calibration 데이터를 색깔(클래스)별로 나누어 각각의 분포 <span class="math inline">\(\hat{q}^{(1)}, \hat{q}^{(2)}\)</span>를 구한다. 추론 시에는 각 후보 클래스 <span class="math inline">\(y\)</span>가 자신의 기준 <span class="math inline">\(\hat{q}^{(y)}\)</span>를 만족하는지 확인한다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="comparison-group-balanced-vs.-class-conditional" class="level3">
<h3 class="anchored" data-anchor-id="comparison-group-balanced-vs.-class-conditional">Comparison: Group-Balanced vs.&nbsp;Class-Conditional</h3>
<ul>
<li>이 두 가지 확장의 차이를 명확히 구분하는 것이 중요합니다.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">특징</th>
<th style="text-align: left;">Group-Balanced (4.1)</th>
<th style="text-align: left;">Class-Conditional (4.2)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>기준 (Condition)</strong></td>
<td style="text-align: left;">입력 특성 (Input Feature <span class="math inline">\(X_{:,1}\)</span>)</td>
<td style="text-align: left;">출력 라벨 (Output Label <span class="math inline">\(Y\)</span>)</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>정보 가용성</strong></td>
<td style="text-align: left;">테스트 시점에 <span class="math inline">\(X\)</span>를 통해 그룹을 <strong>알 수 있음</strong></td>
<td style="text-align: left;">테스트 시점에 <span class="math inline">\(Y\)</span>를 <strong>알 수 없음</strong></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>적용 방식</strong></td>
<td style="text-align: left;">그룹을 확인하고 <span class="math inline">\(\rightarrow\)</span> 해당 그룹의 <span class="math inline">\(\hat{q}\)</span> 적용</td>
<td style="text-align: left;">모든 <span class="math inline">\(y\)</span>에 대해 순회하며 <span class="math inline">\(\rightarrow\)</span> 각자의 <span class="math inline">\(\hat{q}^{(y)}\)</span> 적용</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>주요 사용처</strong></td>
<td style="text-align: left;">공정성 (인종, 성별 간 평등)</td>
<td style="text-align: left;">불균형 데이터 (희귀 클래스 탐지)</td>
</tr>
</tbody>
</table>
</section>
<section id="theoretical-guarantee-2" class="level3">
<h3 class="anchored" data-anchor-id="theoretical-guarantee-2">Theoretical Guarantee</h3>
<ul>
<li>Vovk의 증명에 따르면, 이 방법 또한 수학적으로 엄밀한 커버리지를 보장합니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Proposition 2 (Error control guarantee for class-balanced conformal prediction)</strong></p>
<p>데이터가 i.i.d.라면, 위 알고리즘으로 생성된 집합 <span class="math inline">\(\mathcal{C}\)</span>는 모든 클래스 <span class="math inline">\(y\)</span>에 대해 다음을 만족한다.</p>
<p><span class="math display">\[ \mathbb{P}(Y_{test} \in \mathcal{C}(X_{test}) \mid Y_{test} = y) \ge 1-\alpha \]</span></p>
</blockquote>
</section>
<section id="conclusion-1" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-1">Conclusion</h3>
<ul>
<li>Class-Conditional CP는 불균형한 데이터셋에서 <strong>소수 클래스(Minority Class)의 성능을 희생하지 않기 위한 필수적인 기법</strong>입니다.</li>
<li>비록 소수 클래스의 데이터가 적어서 <span class="math inline">\(\hat{q}\)</span>가 커지고(불확실성이 커지고), 결과적으로 예측 집합의 크기가 커질 수는 있습니다.</li>
<li>하지만 이는 “틀리는 것”보다는 훨씬 낫습니다. 우리는 적어도 그 안에 정답이 있다는 확신(Safety)을 가질 수 있기 때문입니다.</li>
</ul>
<hr>
</section>
</section>
<section id="conformal-risk-control" class="level2">
<h2 class="anchored" data-anchor-id="conformal-risk-control">4.3. Conformal Risk Control</h2>
<section id="introduction-beyond-coverage" class="level3">
<h3 class="anchored" data-anchor-id="introduction-beyond-coverage">Introduction: Beyond Coverage</h3>
<ul>
<li>지금까지 우리가 다룬 Conformal Prediction의 핵심 보장은 다음과 같은 형태였습니다.</li>
</ul>
<p><span class="math display">\[ \mathbb{P}(Y_{test} \notin \mathcal{C}(X_{test})) \le \alpha \]</span></p>
<ul>
<li>즉, “정답을 놓칠 확률(Miscoverage rate)”을 <span class="math inline">\(\alpha\)</span> 이하로 묶는 것이었습니다.</li>
<li>하지만 현실의 많은 머신러닝 문제에서는 단순히 “맞았다/틀렸다”의 이진(Binary) 에러보다 더 복잡한 <strong>손실(Loss)</strong>을 제어해야 할 때가 많습니다.
<ul>
<li><strong>의료 영상 분할(Tumor Segmentation)</strong>: 암 영역을 조금이라도 놓치면(False Negative) 치명적입니다. 픽셀 단위의 재현율(Recall)을 보장해야 할 수 있습니다.</li>
<li><strong>다중 라벨 분류(Multilabel Classification)</strong>: 여러 개의 태그 중 90% 이상을 맞추기를 원할 수 있습니다 (F1-score 등).</li>
</ul></li>
<li><strong>Conformal Risk Control (CRC)</strong>은 이러한 요구를 반영하여, 임의의 유계 손실 함수(Bounded Loss Function)의 기댓값을 제어하는 기법입니다.</li>
</ul>
<p><span class="math display">\[
\mathbb{E}[l(\mathcal{C}(X_{test}), Y_{test})] \le \alpha
\]</span></p>
</section>
<section id="problem-formulation-2" class="level3">
<h3 class="anchored" data-anchor-id="problem-formulation-2">Problem Formulation</h3>
<ul>
<li>우리의 목표는 모델의 출력 집합 <span class="math inline">\(\mathcal{C}(X)\)</span>가 커질수록 <strong>손실(Loss)이 줄어드는</strong> 상황에서, 기대 손실(Expected Risk)이 사용자 지정 허용치 <span class="math inline">\(\alpha\)</span> 이하가 되도록 하는 파라미터를 찾는 것입니다.</li>
</ul>
<section id="key-components" class="level4">
<h4 class="anchored" data-anchor-id="key-components">Key Components</h4>
<ul>
<li><ol type="1">
<li><strong>Nested Sets (<span class="math inline">\(\mathcal{C}_\lambda\)</span>)</strong>:</li>
</ol>
<ul>
<li>우리는 파라미터 <span class="math inline">\(\lambda\)</span>를 조절하여 예측 집합의 크기(보수적인 정도)를 조절합니다.</li>
<li><span class="math inline">\(\lambda\)</span>가 커질수록 예측 집합 <span class="math inline">\(\mathcal{C}_\lambda(x)\)</span>는 더 커지고(더 많은 후보를 포함), 따라서 더 안전해집니다(Conservative).</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Monotone Loss Function (<span class="math inline">\(l\)</span>)</strong>:</li>
</ol>
<ul>
<li>손실 함수 <span class="math inline">\(l(\mathcal{C}, Y)\)</span>는 집합 <span class="math inline">\(\mathcal{C}\)</span>가 커질수록 감소하거나 같아야 합니다 (Non-increasing).</li>
<li>또한, 손실값은 어떤 상한선 <span class="math inline">\(B\)</span>를 넘지 않아야 합니다 (<span class="math inline">\(l \in (-\infty, B]\)</span>).</li>
</ul>
<span class="math display">\[ \lambda_1 \le \lambda_2 \implies l(\mathcal{C}_{\lambda_1}(x), y) \ge l(\mathcal{C}_{\lambda_2}(x), y) \]</span></li>
</ul>
</section>
</section>
<section id="the-algorithm-4" class="level3">
<h3 class="anchored" data-anchor-id="the-algorithm-4">The Algorithm</h3>
<ul>
<li>CRC의 알고리즘은 기존 CP와 매우 유사하지만, Quantile 대신 <strong>경험적 리스크(Empirical Risk)</strong>를 사용한다는 점이 다릅니다.</li>
</ul>
<section id="step-1-calculate-empirical-risk" class="level4">
<h4 class="anchored" data-anchor-id="step-1-calculate-empirical-risk">Step 1: Calculate Empirical Risk</h4>
<ul>
<li>Calibration 데이터셋 <span class="math inline">\((X_1, Y_1), \dots, (X_n, Y_n)\)</span>에 대해, 특정 파라미터 <span class="math inline">\(\lambda\)</span>를 썼을 때의 평균 손실(Empirical Risk)을 계산하는 함수 <span class="math inline">\(\hat{R}(\lambda)\)</span>를 정의합니다.</li>
</ul>
<p><span class="math display">\[
\hat{R}(\lambda) = \frac{1}{n} \sum_{i=1}^{n} l(\mathcal{C}_{\lambda}(X_i), Y_i)
\]</span></p>
<ul>
<li>이 함수는 <span class="math inline">\(\lambda\)</span>가 증가함에 따라 손실이 감소하는 우하향 곡선을 그립니다.</li>
</ul>
</section>
<section id="step-2-find-optimal-lambda" class="level4">
<h4 class="anchored" data-anchor-id="step-2-find-optimal-lambda">Step 2: Find Optimal <span class="math inline">\(\lambda\)</span></h4>
<ul>
<li><p>우리는 기대 손실이 <span class="math inline">\(\alpha\)</span> 이하가 되기를 원합니다.</p></li>
<li><p>하지만 유한한 데이터(<span class="math inline">\(n\)</span>)로 인한 불확실성을 고려해야 하므로, 단순히 <span class="math inline">\(\hat{R}(\lambda) \le \alpha\)</span>가 되는 지점을 찾으면 안 됩니다.</p></li>
<li><p>대신, 다음과 같이 <strong>보정된 기준(Conservative Target)</strong>을 사용합니다.</p></li>
</ul>
<p><span class="math display">\[
\hat{\lambda} = \inf \left\{ \lambda : \hat{R}(\lambda) \le \alpha - \frac{B - \alpha}{n} \right\}
\]</span></p>
<ul>
<li><strong><span class="math inline">\(B\)</span></strong>: 손실 함수의 최댓값 (Upper Bound)</li>
<li><strong>Correction Term (<span class="math inline">\(\frac{B-\alpha}{n}\)</span>)</strong>: 데이터 개수 <span class="math inline">\(n\)</span>이 적을 때 더 보수적으로 <span class="math inline">\(\lambda\)</span>를 선택하게 만드는 항입니다. <span class="math inline">\(n\)</span>이 무한대로 가면 이 항은 0이 되어 <span class="math inline">\(\alpha\)</span>에 수렴합니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/risk_control_visualization.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Conformal Risk Control의 개념도. 파란색 실선은 <span class="math inline">\(\lambda\)</span>에 따른 경험적 리스크 <span class="math inline">\(\hat{R}(\lambda)\)</span>를 나타낸다. 목표 리스크 <span class="math inline">\(\alpha\)</span>에서 보정항 <span class="math inline">\(\frac{B-\alpha}{n}\)</span>만큼을 뺀 점선과 만나는 지점에서 <span class="math inline">\(\hat{\lambda}\)</span>를 결정한다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="example-multilabel-classification" class="level3">
<h3 class="anchored" data-anchor-id="example-multilabel-classification">Example: Multilabel Classification</h3>
<ul>
<li><p>다중 라벨 분류 문제를 예로 들어보겠습니다.</p></li>
<li><p>하나의 이미지가 ‘사람’, ‘차’, ‘신호등’ 등 여러 클래스(<span class="math inline">\(Y_i \subseteq \{1, \dots, K\}\)</span>)를 가질 수 있습니다.</p></li>
<li><ol type="1">
<li><strong>Prediction Set</strong>:</li>
</ol>
<ul>
<li>모델이 각 클래스에 대해 예측한 점수 <span class="math inline">\(f(X)_k\)</span>가 임계값 <span class="math inline">\(1-\lambda\)</span> 이상인 클래스들을 담습니다. <span class="math display">\[ \mathcal{C}_\lambda(x) = \{ k : f(x)_k \ge 1-\lambda \} \]</span>
<ul>
<li><span class="math inline">\(\lambda\)</span>가 클수록 임계값이 낮아져 더 많은 클래스가 선택됨</li>
</ul></li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Loss Function</strong>:</li>
</ol>
<ul>
<li>“전체 정답 태그 중 놓친 태그의 비율”을 손실로 정의합니다. <span class="math display">\[ l(\mathcal{C}, Y) = 1 - \frac{|Y \cap \mathcal{C}|}{|Y|} \]</span></li>
<li>이 값은 0(모두 맞춤)과 1(하나도 못 맞춤) 사이이므로 <span class="math inline">\(B=1\)</span>입니다.</li>
</ul></li>
<li><ol start="3" type="1">
<li><strong>Applying CRC</strong>:</li>
</ol>
<ul>
<li>사용자가 <span class="math inline">\(\alpha=0.1\)</span>로 설정했다면, 위 알고리즘을 통해 구한 <span class="math inline">\(\hat{\lambda}\)</span>를 사용했을 때 <strong>“평균적으로 정답 태그의 90% 이상을 포함”</strong>하는 예측 집합을 얻게 됩니다.</li>
</ul></li>
</ul>
</section>
<section id="theoretical-guarantee-3" class="level3">
<h3 class="anchored" data-anchor-id="theoretical-guarantee-3">Theoretical Guarantee</h3>
<ul>
<li>이 알고리즘은 다음 정리에 의해 수학적으로 보장됩니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Theorem 2 (Conformal Risk Control)</strong></p>
<p>데이터가 i.i.d.이고 손실 함수가 단조 감소(Monotone)한다면, 위 알고리즘으로 선택된 <span class="math inline">\(\hat{\lambda}\)</span>에 대해 다음이 성립한다.</p>
<p><span class="math display">\[ \mathbb{E}[l(\mathcal{C}_{\hat{\lambda}}(X_{test}), Y_{test})] \le \alpha \]</span></p>
</blockquote>
<ul>
<li>이 정리는 CP가 단순히 “에러율 제어”를 넘어, FNR, False Discovery Rate 등 <strong>비즈니스에 중요한 다양한 KPI를 직접 제어</strong>할 수 있는 도구로 확장됨을 의미합니다.</li>
</ul>
<hr>
</section>
</section>
<section id="outlier-detection" class="level2">
<h2 class="anchored" data-anchor-id="outlier-detection">4.4. Outlier Detection</h2>
<section id="introduction-unsupervised-setting" class="level3">
<h3 class="anchored" data-anchor-id="introduction-unsupervised-setting">Introduction: Unsupervised Setting</h3>
<ul>
<li>이전까지 우리는 입력 <span class="math inline">\(X\)</span>와 정답 <span class="math inline">\(Y\)</span>가 있는 지도 학습 환경을 다루었습니다.</li>
<li>하지만 <span class="math inline">\(Y\)</span> 라벨이 없는 경우, 특히 <strong>“정상 데이터 분포에서 벗어난 이상치(Outlier)”</strong>를 탐지해야 하는 상황은 어떻게 해야 할까요?
<ul>
<li>공장 설비의 이상 진동 감지</li>
<li>네트워크 침입 탐지</li>
<li>불량품 검출</li>
</ul></li>
<li>이러한 <strong>Outlier Detection (Anomaly Detection)</strong> 문제에서도 Conformal Prediction을 활용하면, <strong>“정상 데이터를 이상치라고 오판할 확률(False Positive Rate)”</strong>을 통계적으로 제어할 수 있습니다.</li>
</ul>
</section>
<section id="problem-formulation-3" class="level3">
<h3 class="anchored" data-anchor-id="problem-formulation-3">Problem Formulation</h3>
<ul>
<li><p>우리는 오염되지 않은 <strong>깨끗한 데이터(Clean Dataset)</strong> <span class="math inline">\(X_1, \dots, X_n\)</span>을 가지고 있습니다.</p></li>
<li><p>이들은 모두 정상(Inlier) 분포에서 나왔다고 가정합니다.</p></li>
<li><p>우리의 목표는 새로운 데이터 <span class="math inline">\(X_{test}\)</span>가 들어왔을 때, 이것이 정상 분포에서 온 것인지 아니면 이상치인지 판단하는 함수 <span class="math inline">\(\mathcal{C}\)</span>를 만드는 것입니다.</p></li>
<li><p>이때, <strong>실제로는 정상인데 이상치라고 잘못 판단할 확률(Type I Error)</strong>을 <span class="math inline">\(\alpha\)</span> 이하로 억제해야 합니다. <span class="math display">\[
\mathbb{P}(\mathcal{C}(X_{test}) = \text{outlier}) \le \alpha
\]</span></p>
<ul>
<li>여기서 확률은 <span class="math inline">\(X_{test}\)</span>가 정상 데이터 분포에서 왔을 때의 확률입니다.</li>
</ul></li>
</ul>
</section>
<section id="the-algorithm-5" class="level3">
<h3 class="anchored" data-anchor-id="the-algorithm-5">The Algorithm</h3>
<ul>
<li>알고리즘은 기존의 Conformal Prediction과 매우 유사하지만, <span class="math inline">\(Y\)</span>가 없기 때문에 <strong>입력 <span class="math inline">\(X\)</span>만으로 계산되는 Score</strong>를 사용합니다.</li>
</ul>
<section id="step-1-define-heuristic-score-function" class="level4">
<h4 class="anchored" data-anchor-id="step-1-define-heuristic-score-function">Step 1: Define Heuristic Score Function</h4>
<ul>
<li>비지도 학습 모델(예: One-class SVM, Isolation Forest, Autoencoder의 Reconstruction Error 등)을 사용하여, 데이터 포인트가 이상치일수록 커지는 점수 함수 <span class="math inline">\(s(x)\)</span>를 정의합니다. <span class="math display">\[ s(x): \mathcal{X} \rightarrow \mathbb{R} \]</span>
<ul>
<li><span class="math inline">\(s(x)\)</span>가 큼 <span class="math inline">\(\rightarrow\)</span> 이상치(Outlier)일 가능성 높음</li>
<li><span class="math inline">\(s(x)\)</span>가 작음 <span class="math inline">\(\rightarrow\)</span> 정상(Inlier)일 가능성 높음</li>
</ul></li>
</ul>
</section>
<section id="step-2-calibration" class="level4">
<h4 class="anchored" data-anchor-id="step-2-calibration">Step 2: Calibration</h4>
<ul>
<li>깨끗한 데이터셋 <span class="math inline">\(X_1, \dots, X_n\)</span>에 대해 점수들을 계산합니다. <span class="math display">\[ s_i = s(X_i), \quad i=1, \dots, n \]</span></li>
<li>그리고 이 점수들의 분포에서 <span class="math inline">\(1-\alpha\)</span> 분위수(Quantile)에 해당하는 임계값 <span class="math inline">\(\hat{q}\)</span>를 계산합니다.</li>
</ul>
<p><span class="math display">\[
\hat{q} = \text{Quantile}\left( \{s_1, \dots, s_n\} ; \frac{\lceil (n+1)(1-\alpha) \rceil}{n} \right)
\]</span></p>
</section>
<section id="step-3-detection-inference" class="level4">
<h4 class="anchored" data-anchor-id="step-3-detection-inference">Step 3: Detection (Inference)</h4>
<ul>
<li>새로운 테스트 데이터 <span class="math inline">\(X_{test}\)</span>가 들어오면 점수 <span class="math inline">\(s(X_{test})\)</span>를 계산하고, 임계값 <span class="math inline">\(\hat{q}\)</span>와 비교하여 판정합니다.</li>
</ul>
<p><span class="math display">\[
\mathcal{C}(x) = \begin{cases} \text{inlier} &amp; \text{if } s(x) \le \hat{q} \\ \text{outlier} &amp; \text{if } s(x) &gt; \hat{q} \end{cases}
\]</span></p>
</section>
</section>
<section id="theoretical-guarantee-interpretation" class="level3">
<h3 class="anchored" data-anchor-id="theoretical-guarantee-interpretation">Theoretical Guarantee &amp; Interpretation</h3>
<ul>
<li>이 간단한 절차는 다음 명제에 의해 False Positive Rate를 <span class="math inline">\(\alpha\)</span> 이하로 보장합니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Proposition 3 (Error control guarantee for outlier detection)</strong></p>
<p><span class="math inline">\(X_1, \dots, X_n\)</span>과 <span class="math inline">\(X_{test}\)</span>가 동일한 분포(i.i.d.)에서 추출되었다면, 위 알고리즘은 다음을 만족한다. <span class="math display">\[ \mathbb{P}(\mathcal{C}(X_{test}) = \text{outlier}) \le \alpha \]</span></p>
</blockquote>
<section id="statistical-interpretation" class="level5">
<h5 class="anchored" data-anchor-id="statistical-interpretation">Statistical Interpretation</h5>
<ul>
<li>이 과정은 통계적 <strong>가설 검정(Hypothesis Testing)</strong>과도 연결됩니다.
<ul>
<li><strong>귀무가설(<span class="math inline">\(H_0\)</span>)</strong>: <span class="math inline">\(X_{test}\)</span>는 정상 데이터 분포(Calibration Data)와 교환 가능하다(Exchangeable).</li>
<li><strong>기각</strong>: 만약 <span class="math inline">\(s(X_{test})\)</span>가 상위 <span class="math inline">\(\alpha\)</span> 범위에 들어간다면(즉, p-value &lt; <span class="math inline">\(\alpha\)</span>), 우리는 귀무가설을 기각하고 해당 데이터를 이상치로 판단합니다.</li>
</ul></li>
</ul>
</section>
</section>
<section id="conclusion-2" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-2">Conclusion</h3>
<ul>
<li>Conformal Outlier Detection은 복잡한 이상탐지 모델의 출력값을 <strong>“신뢰할 수 있는 통계적 판정”</strong>으로 변환해줍니다.</li>
<li>사용자는 “이 데이터는 점수가 0.8입니다”라는 모호한 말 대신, <strong>“이 데이터는 95% 신뢰수준에서 정상 범위를 벗어났습니다”</strong>라는 명확한 근거를 가지고 의사결정을 내릴 수 있습니다.</li>
</ul>
<hr>
</section>
</section>
<section id="conformal-prediction-under-covariate-shift" class="level2">
<h2 class="anchored" data-anchor-id="conformal-prediction-under-covariate-shift">4.5. Conformal Prediction Under Covariate Shift</h2>
<section id="introduction-when-the-i.i.d.-assumption-fails" class="level3">
<h3 class="anchored" data-anchor-id="introduction-when-the-i.i.d.-assumption-fails">Introduction: When the i.i.d. Assumption Fails</h3>
<ul>
<li><p>지금까지 우리가 배운 모든 Conformal Prediction(CP) 방법론은 하나의 강력한 가정에 의존하고 있습니다.</p></li>
<li><p>바로 <strong>“테스트 데이터가 Calibration 데이터와 동일한 분포(i.i.d.)에서 왔다”</strong>는 가정입니다.</p></li>
<li><p>하지만 현실은 그렇지 않습니다. 과거의 데이터가 미래를 완벽하게 대변하지 못하는 경우가 많습니다.</p>
<ul>
<li><strong>의료 진단</strong>: 학습 데이터는 성인과 유아의 비율이 50:50이었는데, 실제 병원에는 성인이 95% 방문할 수 있습니다.</li>
<li><strong>자율 주행</strong>: 아침(밝음)에 데이터를 수집하여 학습했는데, 실제 주행은 오후(어두움)에 이루어질 수 있습니다.</li>
</ul></li>
<li><p>이러한 분포의 변화 중 <strong>Covariate Shift</strong>는 입력 변수 <span class="math inline">\(X\)</span>의 분포 <span class="math inline">\(P(X)\)</span>는 바뀌지만, 입력과 출력 사이의 관계 <span class="math inline">\(P(Y|X)\)</span>는 유지되는 상황을 말합니다.</p></li>
<li><p>이번 포스트에서는 <strong>Weighted Conformal Prediction</strong>을 사용하여 이러한 변화 속에서도 커버리지를 보장하는 방법을 알아봅니다.</p></li>
</ul>
</section>
<section id="problem-formulation-covariate-shift" class="level3">
<h3 class="anchored" data-anchor-id="problem-formulation-covariate-shift">Problem Formulation: Covariate Shift</h3>
<ul>
<li>우리의 상황을 수식으로 정의해봅시다.
<ul>
<li><strong>Calibration Data</strong>: <span class="math inline">\(P\)</span> 분포에서 추출됨.</li>
<li><strong>Test Data</strong>: <span class="math inline">\(\mathcal{P}_{test}\)</span> 분포에서 추출됨.</li>
</ul></li>
</ul>
<p><span class="math display">\[
X \sim P \quad \rightarrow \quad X_{test} \sim \mathcal{P}_{test}
\]</span></p>
<ul>
<li>단, <span class="math inline">\(Y|X\)</span> (입력이 주어졌을 때 정답의 분포)는 변하지 않는다고 가정합니다.
<ul>
<li>이를 <strong>Covariate Shift</strong>라고 합니다.</li>
</ul></li>
<li>이 상황에서 기존의 일반적인 CP를 사용하면 커버리지가 깨질 수 있습니다.
<ul>
<li>예를 들어, 모델이 어려워하는 데이터(유아)가 테스트 셋에 더 많이 등장한다면, 에러율은 우리가 설정한 <span class="math inline">\(\alpha\)</span>보다 훨씬 높아질 것입니다.</li>
</ul></li>
</ul>
</section>
<section id="the-solution-weighted-conformal-prediction" class="level3">
<h3 class="anchored" data-anchor-id="the-solution-weighted-conformal-prediction">The Solution: Weighted Conformal Prediction</h3>
<ul>
<li>해결책의 핵심은 <strong>“테스트 분포 <span class="math inline">\(\mathcal{P}_{test}\)</span>에서 더 자주 등장할 것 같은 데이터에 더 큰 가중치(Weight)를 주는 것”</strong>입니다.</li>
</ul>
<section id="step-1-likelihood-ratio-calculation" class="level4">
<h4 class="anchored" data-anchor-id="step-1-likelihood-ratio-calculation">Step 1: Likelihood Ratio Calculation</h4>
<ul>
<li>먼저, 두 분포 사이의 비율(Likelihood Ratio)을 계산하는 함수 <span class="math inline">\(w(x)\)</span>를 정의합니다. <span class="math display">\[
w(x) = \frac{d\mathcal{P}_{test}(x)}{dP(x)}
\]</span>
<ul>
<li><span class="math inline">\(w(x) &gt; 1\)</span>: 해당 샘플 <span class="math inline">\(x\)</span>는 학습 때보다 테스트 때 더 자주 등장합니다 (중요함).</li>
<li><span class="math inline">\(w(x) &lt; 1\)</span>: 해당 샘플 <span class="math inline">\(x\)</span>는 테스트 때 덜 등장합니다 (덜 중요함).</li>
</ul></li>
</ul>
</section>
<section id="step-2-compute-normalized-weights" class="level4">
<h4 class="anchored" data-anchor-id="step-2-compute-normalized-weights">Step 2: Compute Normalized Weights</h4>
<ul>
<li>새로운 테스트 포인트 <span class="math inline">\(x\)</span>가 들어왔을 때, 이 <span class="math inline">\(x\)</span>와 기존 Calibration 데이터 <span class="math inline">\(X_i\)</span>들에게 부여할 확률 질량(Probability Mass)을 재계산합니다.</li>
</ul>
<p><span class="math display">\[
p_i^w(x) = \frac{w(X_i)}{\sum_{j=1}^{n} w(X_j) + w(x)}
\]</span></p>
<p><span class="math display">\[
p_{test}^w(x) = \frac{w(x)}{\sum_{j=1}^{n} w(X_j) + w(x)}
\]</span></p>
<ul>
<li>기존 CP에서는 모든 데이터가 <span class="math inline">\(\frac{1}{n+1}\)</span>의 동등한 확률을 가졌습니다.</li>
<li>Weighted CP에서는 <span class="math inline">\(w(\cdot)\)</span>에 비례하여 확률을 다르게 배정합니다.</li>
<li>즉, 테스트 분포와 유사한 데이터일수록 <span class="math inline">\(p_i\)</span>가 커집니다.</li>
</ul>
</section>
<section id="step-3-weighted-quantile-calculation" class="level4">
<h4 class="anchored" data-anchor-id="step-3-weighted-quantile-calculation">Step 3: Weighted Quantile Calculation</h4>
<ul>
<li>이제 가장 중요한 단계인 Quantile 계산입니다.</li>
<li>기존에는 단순히 점수를 정렬하고 <span class="math inline">\((1-\alpha)\)</span> 지점을 찾았지만, 이제는 <strong>가중치가 반영된 누적 분포(Weighted CDF)</strong>를 사용해야 합니다. <span class="math display">\[
\hat{q}(x) = \inf \left\{ s_j : \sum_{i=1}^{j} p_i^w(x) \mathbb{I}\{s_i \le s_j\} \ge 1-\alpha \right\}
\]</span>
<ul>
<li>여기서 <span class="math inline">\(s_j\)</span>는 오름차순으로 정렬된 Calibration Score라고 가정합니다.</li>
</ul></li>
<li>즉, 가중치 <span class="math inline">\(p_i^w(x)\)</span>들을 순서대로 더해가다가, 그 합이 <span class="math inline">\(1-\alpha\)</span>를 넘기는 순간의 점수를 <span class="math inline">\(\hat{q}(x)\)</span>로 선택합니다.</li>
</ul>
</section>
</section>
<section id="intuition-how-quantile-changes" class="level3">
<h3 class="anchored" data-anchor-id="intuition-how-quantile-changes">Intuition: How Quantile Changes</h3>
<ul>
<li>이 과정이 직관적으로 어떤 의미를 가질까요?</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/covariate_shift_cdf.png" class="img-fluid figure-img"></p>
<figcaption>Figure: Standard CP vs Weighted CP의 CDF 비교. (좌측) 일반적인 CP는 모든 점수의 가중치가 같아 직선 형태의 CDF를 가진다. (우측) Covariate Shift 상황에서는 가중치에 따라 CDF가 곡선이 되며, Quantile <span class="math inline">\(\hat{q}\)</span>의 위치가 달라진다.</figcaption>
</figure>
</div>
<ol type="1">
<li><p><strong>Shift towards Hard Examples</strong>: 만약 테스트 분포가 모델이 어려워하는(Score가 높은) 데이터들 쪽으로 이동했다면, 높은 점수를 가진 <span class="math inline">\(X_i\)</span>들의 가중치 <span class="math inline">\(w(X_i)\)</span>가 커집니다. <span class="math inline">\(\rightarrow\)</span> CDF 그래프에서 오른쪽 부분의 경사가 가파라집니다. <span class="math inline">\(\rightarrow\)</span> <span class="math inline">\(1-\alpha\)</span> 지점에 도달하기 위해 더 많은 점수를 지나야 하거나, 더 높은 점수에서 도달하게 됩니다. <span class="math inline">\(\rightarrow\)</span> <strong><span class="math inline">\(\hat{q}\)</span>가 증가합니다 (더 보수적인, 넓은 예측 집합 생성).</strong></p></li>
<li><p><strong>Shift towards Easy Examples</strong>: 반대로 테스트 분포가 쉬운 데이터들 위주라면, 낮은 점수들의 가중치가 커집니다. <span class="math inline">\(\rightarrow\)</span> <strong><span class="math inline">\(\hat{q}\)</span>가 감소합니다 (더 좁고 효율적인 예측 집합 생성).</strong></p></li>
</ol>
</section>
<section id="theorem-guarantee" class="level3">
<h3 class="anchored" data-anchor-id="theorem-guarantee">Theorem &amp; Guarantee</h3>
<ul>
<li>Tibshirani et al.&nbsp;(2019)에 의해 제안된 이 방법은 다음 정리에 의해 커버리지를 보장합니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Theorem 3 (Conformal prediction under covariate shift)</strong></p>
<p>데이터가 위에서 정의한 Covariate Shift 가정하에 생성되었다면, Weighted Quantile <span class="math inline">\(\hat{q}(X_{test})\)</span>를 사용한 예측 집합 <span class="math inline">\(\mathcal{C}\)</span>는 다음을 만족한다.</p>
<p><span class="math display">\[ \mathbb{P}(Y_{test} \in \mathcal{C}(X_{test})) \ge 1-\alpha \]</span></p>
</blockquote>
</section>
<section id="conclusion-3" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-3">Conclusion</h3>
<ul>
<li><p><strong>Weighted Conformal Prediction</strong>은 데이터 분포가 변하는 현실 세계의 문제에 CP를 적용하기 위한 필수적인 도구입니다.</p></li>
<li><p>단순히 <span class="math inline">\(\frac{1}{n+1}\)</span>이라는 고정 관념을 깨고, <strong>“테스트 시점에 더 중요한 데이터에 가중치를 준다”</strong>는 아이디어를 통해 분포 변화에 유연하게 대처할 수 있습니다.</p></li>
<li><p>이 방법은 <span class="math inline">\(w(x)\)</span>를 정확히 안다면 완벽하게 작동하며, <span class="math inline">\(w(x)\)</span>를 추정해야 하는 경우에도 꽤 견고한(Robust) 성능을 보여줍니다.</p></li>
</ul>
<hr>
</section>
</section>
<section id="conformal-prediction-under-distribution-shift" class="level2">
<h2 class="anchored" data-anchor-id="conformal-prediction-under-distribution-shift">4.6. Conformal Prediction Under Distribution Shift</h2>
<section id="introduction-when-data-changes-over-time" class="level3">
<h3 class="anchored" data-anchor-id="introduction-when-data-changes-over-time">Introduction: When Data Changes Over Time</h3>
<ul>
<li><p>이전 포스트(4.5절)에서는 입력 분포가 변하는 Covariate Shift를 다루었습니다.</p></li>
<li><p>하지만 그보다 더 다루기 까다로운 것은 <strong>Distribution Drift(분포 표류)</strong>입니다.</p></li>
<li><p>Distribution Drift는 데이터의 분포가 <strong>시간이 지남에 따라 서서히(Slowly varying), 혹은 알 수 없는 방식으로 변하는 현상</strong>을 말합니다.</p>
<ul>
<li><strong>주식 시장</strong>: 10년 전의 시장 상황과 오늘의 시장 상황은 전혀 다릅니다.</li>
<li><strong>센서 데이터</strong>: 기계가 노후화되면서 센서의 측정값 분포가 서서히 달라집니다.</li>
</ul></li>
<li><p>이런 시계열(Time-series) 문제에서는 “과거의 모든 데이터가 미래를 예측하는 데 동등하게 중요하다”는 i.i.d. 가정이 성립하지 않습니다.</p></li>
<li><p>1년 전 데이터보다 어제의 데이터가 훨씬 중요하기 때문입니다.</p></li>
<li><p>이번 포스트에서는 <strong>최신 데이터에 더 큰 가중치</strong>를 부여하는 Weighted Conformal Prediction을 통해 이 문제를 해결하는 방법을 알아봅니다.</p></li>
</ul>
</section>
<section id="the-method-weighted-conformal-prediction-again" class="level3">
<h3 class="anchored" data-anchor-id="the-method-weighted-conformal-prediction-again">The Method: Weighted Conformal Prediction (Again)</h3>
<ul>
<li>기본적인 아이디어는 4.5절의 Covariate Shift와 동일하게 <strong>Weighted Quantile</strong>을 사용하는 것입니다.</li>
<li>하지만 가중치 <span class="math inline">\(w_i\)</span>를 결정하는 방식이 다릅니다.</li>
<li>Likelihood Ratio를 계산하는 대신, <strong>시간적 근접성(Recency)</strong>을 기준으로 가중치를 설정합니다.</li>
</ul>
<section id="step-1-define-weight-schedule" class="level4">
<h4 class="anchored" data-anchor-id="step-1-define-weight-schedule">Step 1: Define Weight Schedule</h4>
<ul>
<li><p>사용자는 도메인 지식에 기반하여 “오래된 데이터를 얼마나 잊을 것인가”를 결정하는 가중치 스케줄을 정의합니다.</p></li>
<li><p>가장 널리 쓰이는 두 가지 방법은 다음과 같습니다:</p></li>
<li><ol type="1">
<li><strong>Rolling Window (Sliding Window)</strong>:</li>
</ol>
<ul>
<li>최근 <span class="math inline">\(K\)</span>개의 데이터만 사용하고, 나머지는 버립니다. <span class="math display">\[ w_i^{\text{fixed}} = \mathbb{I}\{i \ge n - K\} \]</span></li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Exponential Decay (Smooth Decay)</strong>:</li>
</ol>
<ul>
<li>과거 데이터의 영향력을 지수적으로 감소시킵니다. <span class="math display">\[ w_i^{\text{decay}} = \gamma^{n-i+1} \quad (0 &lt; \gamma &lt; 1) \]</span></li>
<li>예: <span class="math inline">\(\gamma = 0.99\)</span>라면 바로 직전 데이터는 1, 그 전은 0.99, 그 전은 <span class="math inline">\(0.98 \dots\)</span> 가중치를 가짐.</li>
</ul></li>
</ul>
</section>
<section id="step-2-normalize-weights" class="level4">
<h4 class="anchored" data-anchor-id="step-2-normalize-weights">Step 2: Normalize Weights</h4>
<ul>
<li>정의된 가중치 <span class="math inline">\(w_i\)</span>를 전체 합이 1이 되도록 정규화(Normalize)합니다.</li>
<li>이때 테스트 포인트 <span class="math inline">\(X_{test}\)</span>의 가중치 <span class="math inline">\(w_{test}\)</span>도 포함하여 계산합니다.
<ul>
<li>보통 <span class="math inline">\(w_{test}=1\)</span>로 둠.</li>
</ul></li>
</ul>
<p><span class="math display">\[
\tilde{w}_i = \frac{w_i}{\sum_{j=1}^{n} w_j + 1}
\]</span></p>
</section>
<section id="step-3-weighted-quantile" class="level4">
<h4 class="anchored" data-anchor-id="step-3-weighted-quantile">Step 3: Weighted Quantile</h4>
<ul>
<li>정규화된 가중치를 사용하여 보정된 분위수(Quantile) <span class="math inline">\(\hat{q}\)</span>를 계산합니다.</li>
<li>Calibration Score <span class="math inline">\(s_i\)</span>들을 오름차순 정렬했을 때, 누적 가중치 합이 <span class="math inline">\(1-\alpha\)</span>를 넘는 지점을 찾습니다.</li>
</ul>
<p><span class="math display">\[
\hat{q} = \inf \left\{ q : \sum_{i=1}^{n} \tilde{w}_i \mathbb{I}\{s_i \le q\} \ge 1-\alpha \right\}
\]</span></p>
</section>
</section>
<section id="theoretical-analysis" class="level3">
<h3 class="anchored" data-anchor-id="theoretical-analysis">Theoretical Analysis</h3>
<ul>
<li>이 방식이 왜 작동하는지 수학적으로 살펴보겠습니다.</li>
<li>Barber et al.&nbsp;(2022)의 연구에 따르면, Weighted CP는 분포 간의 거리(Total Variation Distance)에 비례하는 오차 범위 내에서 커버리지를 보장합니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Theorem 4 (Conformal prediction under distribution drift)</strong></p>
<p><span class="math inline">\(i\)</span>번째 Calibration 데이터와 테스트 데이터 사이의 TV 거리(Total Variation Distance)를 <span class="math inline">\(\epsilon_i\)</span>라고 하자. <span class="math display">\[ \epsilon_i = d_{TV}((X_i, Y_i), (X_{test}, Y_{test})) \]</span></p>
<p>이때 위에서 정의한 Weighted CP 절차는 다음을 만족한다: <span class="math display">\[ \mathbb{P}(Y_{test} \in \mathcal{C}(X_{test})) \ge 1 - \alpha - 2 \sum_{i=1}^{n} \tilde{w}_i \epsilon_i \]</span></p>
</blockquote>
<section id="interpretation" class="level5">
<h5 class="anchored" data-anchor-id="interpretation">Interpretation</h5>
<ul>
<li>이 부등식의 우변에 있는 <strong>페널티 항 (<span class="math inline">\(2 \sum \tilde{w}_i \epsilon_i\)</span>)</strong>을 줄이는 것이 핵심입니다.
<ul>
<li><strong><span class="math inline">\(\epsilon_i\)</span> (Drift)</strong>:
<ul>
<li>데이터 <span class="math inline">\(i\)</span>가 현재 시점(<span class="math inline">\(test\)</span>)과 얼마나 다른 분포를 가지는지를 나타냅니다.</li>
<li>오래된 데이터일수록 <span class="math inline">\(\epsilon_i\)</span>가 클(1에 가까울) 것입니다.</li>
</ul></li>
<li><strong><span class="math inline">\(\tilde{w}_i\)</span> (Weight)</strong>:
<ul>
<li>우리가 부여한 가중치입니다.</li>
</ul></li>
</ul></li>
<li>우리의 목표는 <strong><span class="math inline">\(\epsilon_i\)</span>가 큰(오래되어 분포가 달라진) 데이터에 작은 가중치 <span class="math inline">\(\tilde{w}_i\)</span>를 부여</strong>하여, 곱 <span class="math inline">\(\tilde{w}_i \epsilon_i\)</span>를 0에 가깝게 만드는 것입니다.</li>
<li>즉, <strong>“분포가 많이 변한 데이터는 무시하겠다”</strong>는 전략을 통해 커버리지 손실을 막을 수 있습니다.</li>
</ul>
</section>
</section>
<section id="practical-consideration-effective-sample-size" class="level3">
<h3 class="anchored" data-anchor-id="practical-consideration-effective-sample-size">Practical Consideration: Effective Sample Size</h3>
<ul>
<li>가중치를 사용하면 분포 변화에는 대응할 수 있지만, 대가가 따릅니다. 바로 <strong>유효 샘플 수(Effective Sample Size)</strong>가 줄어든다는 점입니다.</li>
</ul>
<p><span class="math display">\[
n^{\text{eff}} = \frac{(\sum w_i)^2}{\sum w_i^2}
\]</span></p>
<ul>
<li><strong>Uniform Weights (<span class="math inline">\(w_i=1\)</span>)</strong>: <span class="math inline">\(n^{\text{eff}} = n\)</span>. 모든 데이터를 다 쓰므로 샘플 수가 많아 분산이 작습니다 (안정적).</li>
<li><strong>Concentrated Weights</strong>: 최근 데이터에만 큰 가중치를 주면 <span class="math inline">\(n^{\text{eff}}\)</span>가 급격히 작아집니다.
<ul>
<li><span class="math inline">\(n^{\text{eff}}\)</span>가 작아지면 <span class="math inline">\(\rightarrow\)</span> 커버리지의 분산(Variance)이 커집니다. (즉, 예측 집합의 크기가 들쑥날쑥해짐)</li>
</ul></li>
<li>따라서 <strong>Trade-off</strong>가 존재합니다:
<ul>
<li>가중치를 너무 급격하게 줄이면(빠른 적응) <span class="math inline">\(\rightarrow\)</span> 분포 변화에는 강하지만, 예측이 불안정해짐.</li>
<li>가중치를 너무 천천히 줄이면(느린 적응) <span class="math inline">\(\rightarrow\)</span> 예측은 안정적이지만, 이미 변해버린 과거 분포의 영향을 받음.</li>
</ul></li>
</ul>
</section>
<section id="conclusion-4" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-4">Conclusion</h3>
<ul>
<li><p>Conformal Prediction Under Distribution Drift는 시계열 데이터와 같이 <strong>Non-stationary</strong> 환경에서 신뢰할 수 있는 예측 구간을 만드는 방법입니다.</p></li>
<li><p>핵심은 <strong>Weighted Quantile</strong>을 사용하는 것입니다.</p></li>
<li><p>가중치 스케줄(Sliding Window, Decay)을 통해 과거 데이터를 적절히 “망각(Forget)”해야 합니다.</p></li>
<li><p>이론적으로, 분포 변화가 큰 데이터에 가중치를 적게 줌으로써 커버리지 하락을 방어합니다.</p></li>
<li><p>하지만 너무 과도한 가중치 조절은 유효 샘플 수를 줄여 불안정성을 초래할 수 있으므로 주의가 필요합니다.</p></li>
</ul>
<hr>
</section>
</section>
</section>
<section id="worked-examples" class="level1">
<h1>5. Worked Examples</h1>
<section id="introduction-7" class="level2">
<h2 class="anchored" data-anchor-id="introduction-7">Introduction</h2>
<ul>
<li><p>지금까지 우리는 Conformal Prediction(CP)의 다양한 이론적 확장(Extension)들을 다루었습니다.</p></li>
<li><p>이제 이 도구들이 실제 머신러닝 문제에서 어떻게 작동하는지 확인할 차례입니다.</p></li>
<li><p>이번 포스트에서는 논문의 <strong>Section 5</strong>에서 소개된 5가지의 구체적인 적용 사례를 살펴봅니다.</p></li>
<li><p>각 사례는 단순한 분류/회귀를 넘어, <strong>Risk Control</strong>, <strong>Distribution Shift</strong>, <strong>Outlier Detection</strong> 등 현실적인 난제들을 어떻게 해결하는지 보여줍니다.</p></li>
</ul>
</section>
<section id="multilabel-classification-with-fnr-control" class="level2">
<h2 class="anchored" data-anchor-id="multilabel-classification-with-fnr-control">1. Multilabel Classification with FNR Control</h2>
<section id="problem-setup-1" class="level3">
<h3 class="anchored" data-anchor-id="problem-setup-1">Problem Setup</h3>
<ul>
<li>이미지 안에 있는 모든 객체를 맞추는 다중 라벨 분류(Multilabel Classification) 문제입니다.</li>
<li>단순히 정답을 포함하는 것을 넘어, <strong>“정답 객체 중 90% 이상을 찾아내라(Recall <span class="math inline">\(\ge\)</span> 90%)”</strong>와 같은 요구사항이 있을 때 사용합니다.</li>
<li>이를 위해 <strong>False Negative Rate (FNR)</strong>를 제어합니다.
<ul>
<li><strong>Dataset</strong>: Microsoft COCO (Common Objects in Context)</li>
<li><strong>Goal</strong>: 실제 객체들(<span class="math inline">\(Y\)</span>) 중 모델이 예측한 집합(<span class="math inline">\(\mathcal{C}\)</span>)에 포함되지 않은 비율(FNR)을 <span class="math inline">\(\alpha\)</span> 이하로 유지.</li>
</ul></li>
</ul>
</section>
<section id="methodology-conformal-risk-control" class="level3">
<h3 class="anchored" data-anchor-id="methodology-conformal-risk-control">Methodology: Conformal Risk Control</h3>
<ul>
<li><p>여기서는 <strong>Section 4.3</strong>에서 다룬 Conformal Risk Control(CRC)을 사용합니다.</p></li>
<li><ol type="1">
<li><strong>Prediction Set Construction</strong>:</li>
</ol>
<ul>
<li>모델의 예측 확률 <span class="math inline">\(\hat{f}(x)\)</span>가 임계값 <span class="math inline">\(\lambda\)</span> 이상인 클래스들을 선택합니다. <span class="math display">\[ \mathcal{C}_\lambda(x) = \{ k : \hat{f}(x)_k \ge \lambda \} \]</span>
<ul>
<li><span class="math inline">\(\lambda\)</span>가 작을수록 더 많은 클래스를 포함하므로 보수적이 됨.</li>
</ul></li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Loss Function (<span class="math inline">\(l_{FNR}\)</span>)</strong>:</li>
</ol>
<ul>
<li>예측 집합이 정답을 얼마나 놓쳤는지를 정의합니다. <span class="math display">\[l_{FNR}(\mathcal{C}_\lambda(x), y) = 1 - \frac{|\mathcal{C}_\lambda(x) \cap y|}{|y|}\]</span></li>
<li>만약 정답 <span class="math inline">\(y=\{\text{사람, 차}\}\)</span>인데 예측 <span class="math inline">\(\mathcal{C}=\{\text{사람}\}\)</span>이라면, 교집합은 1개, 정답은 2개이므로 손실은 <span class="math inline">\(1 - 1/2 = 0.5\)</span>입니다.</li>
</ul></li>
</ul>
<ol start="3" type="1">
<li><strong>Threshold Optimization</strong>:
<ul>
<li>Calibration Set에서 경험적 리스크가 <span class="math inline">\(\alpha\)</span> (보정항 포함) 이하가 되는 <span class="math inline">\(\hat{\lambda}\)</span>를 찾습니다. <span class="math display">\[ \hat{\lambda} = \inf \left\{ \lambda : \frac{1}{n}\sum_{i=1}^n l_{FNR}(\mathcal{C}_\lambda(X_i), Y_i) \le \alpha - \frac{1-\alpha}{n} \right\} \]</span></li>
</ul></li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/multilabel.png" class="img-fluid figure-img"></p>
<figcaption>Figure: MS COCO 데이터셋에 대한 Multilabel Classification 결과 (<span class="math inline">\(\alpha=0.1\)</span>). 빨간색 텍스트는 놓친 정답(False Negative), 파란색은 잘못 예측한 오답(False Positive), 검은색은 맞춘 정답(True Positive)을 나타낸다. 평균적으로 90% 이상의 정답 라벨을 찾아내고 있다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="tumor-segmentation" class="level2">
<h2 class="anchored" data-anchor-id="tumor-segmentation">2. Tumor Segmentation</h2>
<section id="problem-setup-2" class="level3">
<h3 class="anchored" data-anchor-id="problem-setup-2">Problem Setup</h3>
<ul>
<li>의료 영상에서 종양(Tumor) 부위를 픽셀 단위로 분할(Segmentation)하는 문제입니다.</li>
<li>여기서도 핵심은 <strong>“종양 픽셀을 놓치지 않는 것”</strong>입니다. 즉, 픽셀 단위의 FNR 제어가 필요합니다.
<ul>
<li><strong>Dataset</strong>: Gut Polyps dataset</li>
<li><strong>Goal</strong>: 전체 종양 픽셀 중 예측 마스크가 커버하지 못한 비율을 제어.</li>
</ul></li>
</ul>
</section>
<section id="methodology" class="level3">
<h3 class="anchored" data-anchor-id="methodology">Methodology</h3>
<ul>
<li><p>Multilabel Classification과 원리는 동일하지만, 대상이 <strong>클래스</strong>에서 <strong>픽셀</strong>로 바뀝니다.</p></li>
<li><ol type="1">
<li><strong>Output</strong>: <span class="math inline">\(M \times N\)</span> 크기의 확률 맵 <span class="math inline">\(\hat{f}(x)\)</span>.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Prediction Mask</strong>: 각 픽셀 <span class="math inline">\((i,j)\)</span>에 대해 확률이 <span class="math inline">\(\lambda\)</span> 이상이면 종양으로 예측. <span class="math display">\[\mathcal{C}_\lambda(x) = \{ (i,j) : \hat{f}(x)_{(i,j)} \ge \lambda \}\]</span></li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Loss Function</strong>: <span class="math display">\[l(\mathcal{C}, Y) = \frac{\text{\# of missed tumor pixels}} {\text{total \# of tumor pixels}}\]</span></li>
</ol></li>
<li><p>이 방법을 적용하면 의사는 “이 AI가 표시한 영역 안에 실제 종양의 90%가 포함되어 있다”는 확신을 가지고 진단에 임할 수 있습니다.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/segmentation.png" class="img-fluid figure-img"></p>
<figcaption>Figure: 종양 분할(Tumor Segmentation) 결과 (<span class="math inline">\(\alpha=0.1\)</span>). 붉은 영역은 모델이 놓친 종양 부위(False Negative)이다. CRC를 통해 놓치는 부위를 통계적으로 최소화할 수 있다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="weather-prediction-time-series" class="level2">
<h2 class="anchored" data-anchor-id="weather-prediction-time-series">3. Weather Prediction (Time-Series)</h2>
<section id="problem-setup-3" class="level3">
<h3 class="anchored" data-anchor-id="problem-setup-3">Problem Setup</h3>
<ul>
<li>시간의 흐름에 따라 기온(Temperature)을 예측하는 시계열 회귀 문제입니다.</li>
<li>시간이 지남에 따라 계절이 바뀌고 기후가 변하므로, 데이터는 <strong>i.i.d.가 아니며 분포가 표류(Distribution Drift)</strong>합니다.
<ul>
<li><strong>Dataset</strong>: Yandex Weather Prediction (Shifts Project)</li>
<li><strong>Challenge</strong>: 과거 데이터와 현재 데이터의 상관관계가 변함.</li>
</ul></li>
</ul>
</section>
<section id="methodology-weighted-conformal-prediction" class="level3">
<h3 class="anchored" data-anchor-id="methodology-weighted-conformal-prediction">Methodology: Weighted Conformal Prediction</h3>
<ul>
<li><strong>Section 4.6</strong>의 분포 표류(Distribution Drift) 대응법을 사용합니다.</li>
<li><ol type="1">
<li><strong>Score Function</strong>:</li>
</ol>
<ul>
<li>예측값 <span class="math inline">\(\hat{f}(X_t)\)</span>와 불확실성 추정값 <span class="math inline">\(\hat{u}(X_t)\)</span>를 이용한 정규화된 잔차(Normalized Residual)를 사용합니다. <span class="math display">\[ s_t = \frac{|Y_t - \hat{f}(X_t)|}{\hat{u}(X_t)} \]</span></li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Weighted Quantile</strong>:</li>
</ol>
<ul>
<li>최근 <span class="math inline">\(K\)</span>개의 데이터만 사용하는 <strong>Sliding Window</strong> 방식을 적용합니다.</li>
<li>가중치 <span class="math inline">\(w_{t'} = \mathbb{I}\{t' \ge t - K\}\)</span>를 사용하여, 오래된 데이터는 과감히 버리고 최근 데이터 분포에만 맞춥니다. <span class="math display">\[ \hat{q}_t = \text{Quantile}_{\text{weighted}}(s_{t-K}, \dots, s_{t-1}) \]</span></li>
</ul></li>
<li>결과적으로 급격한 기온 변화나 계절 변화가 발생했을 때, 일반 CP보다 훨씬 빠르게 적응하여 적절한 커버리지를 회복합니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/weather.png" class="img-fluid figure-img"></p>
<figcaption>Figure: 시계열 기온 예측 결과. (왼쪽) 일반 CP(주황색)는 분포 변화 시 커버리지가 무너지지만, Weighted CP(파란색)는 빠르게 회복하여 목표 커버리지(0.9)를 유지한다. (오른쪽) 예측된 구간의 시각화.</figcaption>
</figure>
</div>
</section>
</section>
<section id="toxic-comment-identification-outlier-detection" class="level2">
<h2 class="anchored" data-anchor-id="toxic-comment-identification-outlier-detection">4. Toxic Comment Identification (Outlier Detection)</h2>
<section id="problem-setup-4" class="level3">
<h3 class="anchored" data-anchor-id="problem-setup-4">Problem Setup</h3>
<ul>
<li>온라인 댓글이 유해한지(Toxic) 아닌지를 판별하는 문제입니다.</li>
<li>정상적인 대화(Non-toxic) 데이터만 잔뜩 있는 상태에서, 새로운 댓글이 <strong>정상 범주를 벗어난(Outlier/Toxic)</strong> 것인지 탐지합니다.
<ul>
<li><strong>Dataset</strong>: Jigsaw Multilingual Toxic Comment Classification</li>
<li><strong>Goal</strong>: 정상 댓글을 유해하다고 잘못 판별할 확률(False Positive Rate)을 <span class="math inline">\(\alpha\)</span> 이하로 제어. (Type-1 Error Control)</li>
</ul></li>
</ul>
</section>
<section id="methodology-conformal-outlier-detection" class="level3">
<h3 class="anchored" data-anchor-id="methodology-conformal-outlier-detection">Methodology: Conformal Outlier Detection</h3>
<ul>
<li><strong>Section 4.4</strong>의 방법을 적용합니다.</li>
<li><ol type="1">
<li><strong>Heuristic Model</strong>: BERT 기반의 유해성 점수 예측 모델 <span class="math inline">\(f(x) \in [0, 1]\)</span>.</li>
</ol></li>
<li><ol start="2" type="1">
<li><strong>Calibration</strong>: 정상 댓글(Non-toxic) <span class="math inline">\(n\)</span>개에 대해 점수 <span class="math inline">\(s_i = f(X_i)\)</span>를 계산하고 Quantile <span class="math inline">\(\hat{q}\)</span>를 구합니다.</li>
</ol></li>
<li><ol start="3" type="1">
<li><strong>Detection</strong>: <span class="math display">\[ \mathcal{C}(x) = \begin{cases} \text{Normal} &amp; \text{if } f(x) \le \hat{q} \\ \text{Toxic (Outlier)} &amp; \text{if } f(x) &gt; \hat{q} \end{cases} \]</span></li>
</ol></li>
<li>이 방식은 “이 댓글은 유해합니다”라고 경보를 울릴 때, 그 경보가 오작동일 확률을 수학적으로 보장해줍니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/toxic.png" class="img-fluid figure-img"></p>
<figcaption>Figure: 유해 댓글 탐지 예시 (<span class="math inline">\(\alpha=0.1\)</span>). 다국어 댓글에 대해 정상 댓글을 유해하다고 잘못 분류할 확률을 10%로 제한하면서, 실제 유해 댓글의 70%를 성공적으로 잡아냈다.</figcaption>
</figure>
</div>
</section>
</section>
<section id="selective-classification-abstention" class="level2">
<h2 class="anchored" data-anchor-id="selective-classification-abstention">5. Selective Classification (Abstention)</h2>
<section id="problem-setup-5" class="level3">
<h3 class="anchored" data-anchor-id="problem-setup-5">Problem Setup</h3>
<ul>
<li>모델이 확신할 수 없을 때는 <strong>“모르겠습니다(I don’t know)”</strong>라고 대답을 거부(Abstain)하는 시스템입니다.</li>
<li>목표는 대답을 거부하지 않고 예측을 내놓았을 때의 정확도가 <span class="math inline">\(\ge 1-\alpha\)</span>가 되도록 하는 것입니다.
<ul>
<li><strong>Dataset</strong>: ImageNet</li>
<li><strong>Goal</strong>: Selective Accuracy <span class="math inline">\(\ge 90\%\)</span>.</li>
</ul></li>
</ul>
</section>
<section id="methodology-learn-then-test" class="level3">
<h3 class="anchored" data-anchor-id="methodology-learn-then-test">Methodology: Learn then Test</h3>
<ul>
<li>이 문제는 정확도(Accuracy)가 임계값 <span class="math inline">\(\lambda\)</span>에 따라 단조 증가(Monotone)하지 않을 수 있기 때문에, 표준 CRC 대신 <strong>Learn then Test</strong> (Appendix A 내용) 프레임워크를 사용합니다.</li>
<li><ol type="1">
<li><strong>Risk Definition</strong>: <span class="math display">\[ R(\lambda) = \mathbb{P}(\text{Error} \mid \text{Confidence} \ge \lambda) \]</span></li>
</ol>
<ul>
<li>조건부 확률이므로 직접 제어하기 까다롭습니다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Empirical Estimate &amp; Upper Bound</strong>:</li>
</ol>
<ul>
<li>Calibration Set에서 특정 신뢰도 <span class="math inline">\(\lambda\)</span> 이상인 샘플들의 에러율 <span class="math inline">\(\hat{R}(\lambda)\)</span>를 계산합니다.</li>
<li>이 에러율은 이항 분포(Binomial Distribution)를 따르므로, 클로퍼-피어슨(Clopper-Pearson) 구간 등을 이용해 <strong>에러율의 보수적 상한선(Upper Bound) <span class="math inline">\(\hat{R}^+(\lambda)\)</span></strong>을 구합니다.</li>
</ul></li>
<li><ol start="3" type="1">
<li><strong>Scan &amp; Select</strong>: <span class="math inline">\(\hat{R}^+(\lambda) \le \alpha\)</span>를 만족하는 가장 작은 <span class="math inline">\(\lambda\)</span>를 선택합니다.</li>
</ol></li>
<li>결과적으로 모델은 자신이 없으면 대답을 회피하고, 대답을 했을 때는 매우 높은 정확도를 보장하게 됩니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/selective.png" class="img-fluid figure-img"></p>
<figcaption>Figure: ImageNet에 대한 Selective Classification 결과. (왼쪽) <span class="math inline">\(\lambda\)</span>가 커질수록(가로축), 예측을 수행하는 비율(주황색)은 줄어들지만, 정확도(파란색)는 올라간다. 점선은 목표 정확도 90%를 달성하는 지점을 나타낸다. (오른쪽) 모델이 예측한 예시(가오리)와 기권을 선택한 예시(여우).</figcaption>
</figure>
</div>
</section>
</section>
<section id="conclusion-5" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-5">Conclusion</h2>
<ul>
<li>이상의 5가지 예제는 Conformal Prediction이 단순히 이론적인 개념에 머무르지 않고, <strong>실제 현업의 복잡한 문제들을 해결하는 강력한 도구</strong>임을 보여줍니다.
<ul>
<li><strong>Segmentation/Multilabel</strong>: 단순 에러율이 아닌 FNR 등 복잡한 Metric 제어.</li>
<li><strong>Time-series</strong>: 데이터 분포 변화(Drift)에 대한 적응.</li>
<li><strong>Outlier Detection</strong>: 비지도 학습 환경에서의 통계적 보장.</li>
<li><strong>Selective Classification</strong>: 고위험 환경에서의 안전한 AI.</li>
</ul></li>
<li>이 모든 과정에서 가장 중요한 것은 <strong>“적절한 Score Function의 정의”</strong>와 <strong>“올바른 Calibration 기법의 선택”</strong>입니다.</li>
</ul>
<hr>
</section>
</section>
<section id="full-conformal-prediction" class="level1">
<h1>6. Full Conformal Prediction</h1>
<section id="introduction-the-efficiency-trade-off" class="level2">
<h2 class="anchored" data-anchor-id="introduction-the-efficiency-trade-off">Introduction: The Efficiency Trade-off</h2>
<ul>
<li>지금까지 우리가 다룬 방식은 <strong>Split Conformal Prediction (Inductive CP)</strong>이었습니다.</li>
<li>이 방식은 데이터를 학습용(Train)과 보정용(Calibration)으로 나누어 사용합니다.
<ul>
<li><strong>장점</strong>: 계산이 매우 빠릅니다. 모델을 딱 한 번만 학습시키면 됩니다.</li>
<li><strong>단점</strong>: 데이터를 쪼개야 하므로 <strong>통계적 효율성(Statistical Efficiency)</strong>이 떨어집니다. 보정용 데이터는 학습에 기여하지 못하고, 학습용 데이터는 보정에 기여하지 못하기 때문입니다.</li>
</ul></li>
<li>데이터가 매우 귀하거나(예: 희귀병 임상 데이터), 예측의 정확도가 비용보다 훨씬 중요한 상황이라면 어떨까요?</li>
<li>이때 우리는 계산 비용을 감수하더라도 모든 데이터를 학습과 보정에 동시에 사용하는 <strong>Full Conformal Prediction (Transductive CP)</strong>을 고려해야 합니다.</li>
</ul>
</section>
<section id="the-core-idea-what-if" class="level2">
<h2 class="anchored" data-anchor-id="the-core-idea-what-if">The Core Idea: “What if?”</h2>
<ul>
<li><p>Full CP의 핵심 아이디어는 새로운 데이터 <span class="math inline">\(X_{n+1}\)</span>에 대해 <strong>“만약 정답이 <span class="math inline">\(y\)</span>라면, 이 데이터가 기존 데이터들과 잘 어울리는가(Exchangeable)?”</strong>를 테스트하는 것입니다.</p></li>
<li><p>우리는 아직 정답 <span class="math inline">\(Y_{n+1}\)</span>을 모르지만, 가능한 모든 후보 <span class="math inline">\(y \in \mathcal{Y}\)</span>를 하나씩 대입해볼 수는 있습니다.</p></li>
<li><p>만약 <span class="math inline">\(y\)</span>가 진짜 정답이라면, <span class="math inline">\((X_{n+1}, y)\)</span>를 포함한 전체 데이터셋은 통계적으로 동질적(Exchangeable)이어야 합니다.</p></li>
</ul>
</section>
<section id="the-algorithm-6" class="level2">
<h2 class="anchored" data-anchor-id="the-algorithm-6">The Algorithm</h2>
<ul>
<li>알고리즘은 모든 가능한 라벨 <span class="math inline">\(y\)</span>에 대해 재학습(Retraining)을 수행해야 하므로 꽤 무겁습니다.</li>
</ul>
<section id="step-1-loop-over-all-possible-labels" class="level3">
<h3 class="anchored" data-anchor-id="step-1-loop-over-all-possible-labels">Step 1: Loop over all possible labels</h3>
<ul>
<li>테스트 포인트 <span class="math inline">\(X_{n+1}\)</span>에 대해, 가능한 모든 정답 후보 <span class="math inline">\(y \in \mathcal{Y}\)</span> (예: 분류 문제의 모든 클래스)에 대해 다음 과정을 반복합니다.</li>
</ul>
</section>
<section id="step-2-augment-and-retrain" class="level3">
<h3 class="anchored" data-anchor-id="step-2-augment-and-retrain">Step 2: Augment and Retrain</h3>
<ul>
<li>기존 데이터셋에 가상의 데이터 포인트 <span class="math inline">\((X_{n+1}, y)\)</span>를 추가하여 확장된 데이터셋을 만듭니다.</li>
<li>그리고 이 데이터셋으로 모델 <span class="math inline">\(\hat{f}^y\)</span>를 <strong>처음부터 다시 학습</strong>시킵니다.</li>
</ul>
<p><span class="math display">\[ \text{Train } \hat{f}^y \text{ on } \{(X_1, Y_1), \dots, (X_n, Y_n), (X_{n+1}, y)\} \]</span></p>
<blockquote class="blockquote">
<p><strong>주의</strong>: 이때 사용하는 학습 알고리즘은 데이터의 순서에 영향을 받지 않는 <strong>대칭적(Symmetric)</strong> 알고리즘이어야 합니다.</p>
</blockquote>
</section>
<section id="step-3-compute-scores" class="level3">
<h3 class="anchored" data-anchor-id="step-3-compute-scores">Step 3: Compute Scores</h3>
<ul>
<li>학습된 모델 <span class="math inline">\(\hat{f}^y\)</span>를 사용하여, 확장된 데이터셋 내의 모든 포인트(<span class="math inline">\(i=1 \dots n+1\)</span>)에 대해 Conformal Score를 계산합니다.</li>
</ul>
<p><span class="math display">\[ s_i^y = s(X_i, Y_i, \hat{f}^y) \quad \text{for } i=1, \dots, n \]</span> <span class="math display">\[ s_{n+1}^y = s(X_{n+1}, y, \hat{f}^y) \]</span></p>
</section>
<section id="step-4-compute-quantile" class="level3">
<h3 class="anchored" data-anchor-id="step-4-compute-quantile">Step 4: Compute Quantile</h3>
<ul>
<li>이 <span class="math inline">\(n+1\)</span>개의 점수들 사이에서 <span class="math inline">\(s_{n+1}^y\)</span>의 위치를 확인합니다.</li>
<li>정확히는 <span class="math inline">\(1-\alpha\)</span> 분위수 <span class="math inline">\(\hat{q}^y\)</span>를 계산하여, <span class="math inline">\(s_{n+1}^y\)</span>가 이 안에 들어오는지 확인합니다.</li>
</ul>
<p><span class="math display">\[ \hat{q}^y = \text{Quantile}\left( \{s_1^y, \dots, s_{n+1}^y\} ; \frac{\lceil (n+1)(1-\alpha) \rceil}{n+1} \right) \]</span></p>
</section>
<section id="step-5-construct-prediction-set" class="level3">
<h3 class="anchored" data-anchor-id="step-5-construct-prediction-set">Step 5: Construct Prediction Set</h3>
<ul>
<li>위 조건을 만족하는(즉, 기존 데이터들과 잘 섞이는) 모든 <span class="math inline">\(y\)</span>를 예측 집합에 포함시킵니다.</li>
</ul>
<p><span class="math display">\[ \mathcal{C}(X_{n+1}) = \{ y \in \mathcal{Y} : s_{n+1}^y \le \hat{q}^y \} \]</span></p>
</section>
</section>
<section id="statistical-interpretation-permutation-test" class="level2">
<h2 class="anchored" data-anchor-id="statistical-interpretation-permutation-test">Statistical Interpretation: Permutation Test</h2>
<ul>
<li>Full Conformal Prediction이 왜 작동하는지, 그리고 왜 “데이터를 섞어서(Permutation)” 판단하는지 이해하기 위해 통계학의 <strong>순열 검정(Permutation Test)</strong> 개념을 연결해보겠습니다.</li>
</ul>
<section id="the-null-hypothesis-of-exchangeability" class="level3">
<h3 class="anchored" data-anchor-id="the-null-hypothesis-of-exchangeability">The Null Hypothesis of Exchangeability</h3>
<ul>
<li>우리가 테스트 데이터 <span class="math inline">\(X_{n+1}\)</span>에 대해 어떤 가상의 정답 <span class="math inline">\(y\)</span>를 부여했을 때, 핵심 질문은 이것입니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>“이 데이터 포인트 <span class="math inline">\((X_{n+1}, y)\)</span>가 기존 데이터들과 구별되지 않고 잘 섞이는가?”</strong></p>
</blockquote>
<ul>
<li><p>이를 통계적 가설 검정의 언어로 표현하면 다음과 같습니다.</p></li>
<li><p><strong>귀무가설 (<span class="math inline">\(H_0\)</span>):</strong> 데이터들 <span class="math inline">\(Z_1, \dots, Z_{n+1}\)</span>은 <strong>교환 가능(Exchangeable)</strong>하다.</p></li>
<li><p>즉, 데이터의 순서를 뒤섞어도 그 결합 확률 분포는 변하지 않는다.</p>
<ul>
<li>여기서 <span class="math inline">\(Z_i = (X_i, Y_i)\)</span>입니다.</li>
</ul></li>
</ul>
</section>
<section id="the-test-statistic-p-value" class="level3">
<h3 class="anchored" data-anchor-id="the-test-statistic-p-value">The Test Statistic &amp; P-value</h3>
<ul>
<li>이 귀무가설을 기각하기 위해, 우리는 데이터가 얼마나 “튀는지”를 측정하는 검정 통계량 <span class="math inline">\(T\)</span>를 정의합니다.</li>
<li>Full CP에서는 <strong>Nonconformity Score (<span class="math inline">\(s\)</span>)</strong>가 바로 이 역할을 합니다.</li>
</ul>
<p><span class="math display">\[ T(Z) = s(X, Y) \]</span></p>
<ul>
<li>점수 <span class="math inline">\(s\)</span>가 클수록 해당 데이터는 다른 데이터들과 이질적이라는(Exchangeability를 위반한다는) 증거가 됩니다.</li>
<li>우리는 관측된 데이터의 점수가, 데이터를 무작위로 섞었을 때 나올 수 있는 점수들과 비교해서 얼마나 큰지 <strong>p-value</strong>를 계산합니다.</li>
</ul>
<p><span class="math display">\[ p = \frac{\sum_{\sigma \in S_{n+1}} \mathbb{1}\{ T(Z_{\sigma(1)}, \dots, Z_{\sigma(n+1)}) \ge T(Z_{observed}) \}}{(n+1)!} \]</span></p>
<ul>
<li>하지만 Full CP에서는 모든 순열을 다 계산할 필요 없이, 각 데이터 포인트의 점수 <span class="math inline">\(s_i\)</span>들의 순위(Rank)만 보면 됩니다.</li>
<li>따라서 p-value는 다음과 같이 단순화됩니다.</li>
</ul>
<p><span class="math display">\[ p(y) = \frac{1}{n+1} \sum_{i=1}^{n+1} \mathbb{1}\{ s_i^y \ge s_{n+1}^y \} \]</span></p>
</section>
<section id="decision-rule-validity-theorem" class="level3">
<h3 class="anchored" data-anchor-id="decision-rule-validity-theorem">Decision Rule (Validity Theorem)</h3>
<ul>
<li>순열 검정의 핵심 정리에 따르면, 귀무가설(<span class="math inline">\(H_0\)</span>)이 참일 때 p-value는 균등 분포(Uniform Distribution)를 따릅니다. 따라서 다음이 성립합니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Theorem (Validity of Permutation Test)</strong></p>
<p>모든 <span class="math inline">\(\tau \in [0, 1]\)</span>과 모든 교환 가능한 분포 <span class="math inline">\(P\)</span>에 대해: <span class="math display">\[ \mathbb{P}_P(p \le \tau) \le \tau \]</span></p>
</blockquote>
<ul>
<li><p>우리는 허용 가능한 에러율 <span class="math inline">\(\alpha\)</span>를 설정했으므로, <strong>p-value가 <span class="math inline">\(\alpha\)</span>보다 작으면(너무 희박한 확률이면)</strong> 귀무가설을 기각합니다.</p></li>
<li><p><strong><span class="math inline">\(p(y) \le \alpha\)</span> (기각):</strong> “<span class="math inline">\(y\)</span>를 정답이라고 가정했더니, 이 데이터는 상위 <span class="math inline">\(\alpha\)</span>% 안에 들 만큼 너무 이상해. <span class="math inline">\(y\)</span>는 정답이 아닌 것 같아.” <span class="math inline">\(\rightarrow\)</span> <strong>예측 집합에서 제외.</strong></p></li>
<li><p><strong><span class="math inline">\(p(y) &gt; \alpha\)</span> (채택):</strong> “<span class="math inline">\(y\)</span>를 정답이라고 가정해도, 데이터가 전체 무리 속에 자연스럽게 섞여 들어가네. <span class="math inline">\(y\)</span>는 정답일 수도 있어.” <span class="math inline">\(\rightarrow\)</span> <strong>예측 집합에 포함.</strong></p></li>
<li><p>결국 Full CP의 예측 집합 <span class="math inline">\(\mathcal{C}(X_{n+1})\)</span>은 <strong>“순열 검정에서 기각되지 않고 살아남은 모든 <span class="math inline">\(y\)</span>들의 모임”</strong>입니다.</p></li>
<li><p>이것이 바로 Full CP가 수학적으로 엄밀한 커버리지를 보장하는 이유입니다.</p></li>
</ul>
</section>
</section>
<section id="computational-cost-vs.-statistical-efficiency" class="level2">
<h2 class="anchored" data-anchor-id="computational-cost-vs.-statistical-efficiency">Computational Cost vs.&nbsp;Statistical Efficiency</h2>
<section id="the-cost" class="level3">
<h3 class="anchored" data-anchor-id="the-cost">The Cost</h3>
<ul>
<li><p>이 방법의 가장 큰 문제는 <strong>계산 비용</strong>입니다.</p></li>
<li><p>테스트 데이터가 하나 들어올 때마다, 그리고 후보 클래스 <span class="math inline">\(K\)</span>개마다 매번 모델을 재학습해야 합니다.</p></li>
<li><p>총 학습 횟수: <span class="math inline">\((n+1) \times K\)</span></p></li>
<li><p>따라서 딥러닝과 같이 학습이 오래 걸리는 모델이나, 회귀 문제(Regression)처럼 후보 <span class="math inline">\(y\)</span>가 무한히 많은 경우에는 그대로 적용하기 어렵습니다.</p></li>
</ul>
</section>
<section id="the-benefit" class="level3">
<h3 class="anchored" data-anchor-id="the-benefit">The Benefit</h3>
<ul>
<li>하지만 데이터를 나누지 않고 <span class="math inline">\(n\)</span>개를 모두 사용하므로, <strong>예측 집합이 더 작고 효율적(Sharp)</strong>입니다.</li>
<li>Split CP보다 정보 손실이 적어, 데이터가 적은 상황에서는 훨씬 강력한 성능을 발휘합니다.</li>
</ul>
</section>
</section>
<section id="theoretical-guarantee-4" class="level2">
<h2 class="anchored" data-anchor-id="theoretical-guarantee-4">Theoretical Guarantee</h2>
<ul>
<li>Full CP 역시 수학적으로 엄밀한 커버리지를 보장합니다.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Theorem 5 (Full conformal coverage guarantee)</strong></p>
<p>데이터가 교환 가능(Exchangeable)하고 학습 알고리즘이 대칭적(Symmetric)이라면, 다음이 성립한다.</p>
<p><span class="math display">\[ \mathbb{P}(Y_{n+1} \in \mathcal{C}(X_{n+1})) \ge 1-\alpha \]</span></p>
</blockquote>
</section>
<section id="summary-4" class="level2">
<h2 class="anchored" data-anchor-id="summary-4">Summary</h2>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">Split Conformal (SCP)</th>
<th style="text-align: left;">Full Conformal (FCP)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Data Usage</strong></td>
<td style="text-align: left;">Train / Calib 분할 (비효율)</td>
<td style="text-align: left;">전체 데이터 사용 (효율)</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Computation</strong></td>
<td style="text-align: left;">1회 학습 (빠름)</td>
<td style="text-align: left;"><span class="math inline">\(K\)</span>회 재학습 (매우 느림)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Use Case</strong></td>
<td style="text-align: left;">Big Data, Deep Learning</td>
<td style="text-align: left;">Small Data, Statistically Critical Tasks</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Interpretation</strong></td>
<td style="text-align: left;">Validation Score Quantile</td>
<td style="text-align: left;">Permutation Test</td>
</tr>
</tbody>
</table>
<ul>
<li>Full CP는 계산 비용 때문에 현대 머신러닝에서는 잘 쓰이지 않지만, <strong>Jackknife+</strong>나 <strong>CV+</strong> (Section 6.2) 같은 기법들의 이론적 토대가 되는 매우 중요한 개념입니다.</li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/shsha0110\.github\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>