---
title: "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 2.2)"
subtitle: "2.2. Conformalized Quantile Regression"
author: "유성현"
date: "2026-01-16"
categories: [Paper Review]
format:
  html:
    toc: true
    number-sections: false
    code-fold: show
---

# Introduction

이전 포스트에서는 분류(Classification) 문제에 대한 Conformal Prediction을 다루었습니다. 이번에는 **연속적인 값(Continuous Output)을 예측하는 회귀(Regression)** 문제로 넘어가 보겠습니다.

회귀 문제에서 우리의 목표는 입력 $x$에 대해 단순히 하나의 예측값 $\hat{y}$를 내놓는 것이 아니라, 정답 $y$가 포함될 확률이 $1-\alpha$ (예: 90%)인 **예측 구간(Prediction Interval)**을 생성하는 것입니다.

$$
\mathcal{C}(x) = [\text{Lower Bound}, \text{Upper Bound}]
$$

이를 위해 가장 효과적인 베이스 모델 중 하나인 **Quantile Regression**을 사용하고, CP를 통해 이를 보정하는 **Conformalized Quantile Regression (CQR)** 기법을 알아보겠습니다.

# Base Model: Quantile Regression

## Concept
일반적인 회귀 모델은 평균(Mean)을 예측(MSE Loss 사용)하지만, **Quantile Regression**은 조건부 분포의 특정 분위수(Quantile)를 예측합니다.

90%의 커버리지를 목표로 한다면, 우리는 양쪽 꼬리에서 5%씩을 제외한 구간을 알고 싶을 것입니다. 즉, 다음 두 가지 분위수를 학습합니다:
* **Lower Quantile**: $\alpha/2 = 0.05$ (5% 지점)
* **Upper Quantile**: $1 - \alpha/2 = 0.95$ (95% 지점)

모델이 완벽하다면, 정답 $y$는 90%의 확률로 이 구간 $[\hat{t}_{\alpha/2}(x), \hat{t}_{1-\alpha/2}(x)]$ 사이에 존재해야 합니다.

## Quantile Loss (Pinball Loss)
이러한 분위수를 학습하기 위해 **Quantile Loss (Pinball Loss)**를 사용합니다.

$$
L_{\gamma}(\hat{t}_{\gamma}, y) = (y - \hat{t}_{\gamma})\gamma \mathbb{I}\{y > \hat{t}_{\gamma}\} + (\hat{t}_{\gamma} - y)(1-\gamma)\mathbb{I}\{y \le \hat{t}_{\gamma}\}
$$

* $\gamma$: 타겟 분위수 (예: 0.05 또는 0.95)
* 이 손실 함수를 사용하여 뉴럴 네트워크 등 어떤 모델이든 특정 분위수를 예측하도록 학습시킬 수 있습니다.

# The Problem: Why Conformalize?

Quantile Regression으로 구한 구간 $[\hat{t}_{0.05}(x), \hat{t}_{0.95}(x)]$는 꽤 훌륭한 불확실성 추정치입니다.
하지만 문제는 **"Finite Sample"에서 90% 커버리지를 보장하지 못한다**는 점입니다.
모델이 과적합(Overfitting)되거나 학습이 덜 되면, 실제 정답이 이 구간을 벗어나는 비율이 10%보다 훨씬 클 수도, 작을 수도 있습니다.

따라서 우리는 Conformal Prediction을 사용하여 이 구간을 **보정(Calibrate)**해야 합니다.

# Conformalized Quantile Regression Algorithm

CQR의 핵심 아이디어는 학습된 분위수 구간을 **$\hat{q}$만큼 늘리거나 줄여서** 엄밀한 커버리지를 맞추는 것입니다.

## Step 1: Define Score Function
Calibration 데이터 $(X_i, Y_i)$에 대해, 정답 $Y_i$가 학습된 구간 $[\hat{t}_{\alpha/2}(X_i), \hat{t}_{1-\alpha/2}(X_i)]$ 밖으로 얼마나 나갔는지를 측정하는 Score를 정의합니다.

$$
s(x, y) = \max \{ \hat{t}_{\alpha/2}(x) - y, \quad y - \hat{t}_{1-\alpha/2}(x) \}
$$

이 식의 의미를 직관적으로 살펴봅시다:
* **Case 1: $y$가 구간 안에 있을 때**:
    * $\hat{t}_{\text{lower}} < y < \hat{t}_{\text{upper}}$ 이므로, 두 항 모두 음수가 됩니다.
    * $s(x, y) < 0$ (즉, 안전함)
* **Case 2: $y$가 구간 밖(위쪽)에 있을 때**:
    * $y > \hat{t}_{\text{upper}}$ 이므로 $y - \hat{t}_{\text{upper}}$ 가 양수가 됩니다.
    * $s(x, y) > 0$ (즉, 위험함/에러)

즉, 점수 $s$가 클수록 정답이 예측 구간을 크게 벗어났음을 의미합니다.

## Step 2: Calibration (Get $\hat{q}$)
계산된 점수들 $s_1, \dots, s_n$의 분포에서 $1-\alpha$ 분위수 $\hat{q}$를 찾습니다.

$$
\hat{q} = \text{Quantile}\left( \frac{\lceil (n+1)(1-\alpha) \rceil}{n} ; \{s_1, \dots, s_n\} \right)
$$

* 만약 모델이 불확실성을 과소평가했다면(구간이 너무 좁으면), 많은 $y$가 구간 밖에 있을 것이고 $s$값들이 커져서 **양수의 $\hat{q}$**가 나옵니다.
* 만약 모델이 불확실성을 과대평가했다면(구간이 너무 넓으면), $s$값들이 대부분 음수일 것이고 **음수의 $\hat{q}$**가 나옵니다.

## Step 3: Construct Prediction Interval
최종적으로 새로운 입력 $X_{test}$에 대한 예측 구간을 생성할 때, 원래 구간을 $\hat{q}$만큼 조정합니다.

$$
\mathcal{C}(X_{test}) = [\hat{t}_{\alpha/2}(X_{test}) - \hat{q}, \quad \hat{t}_{1-\alpha/2}(X_{test}) + \hat{q}]
$$

* $\hat{q} > 0$: 원래 구간이 너무 좁았으므로, 양쪽으로 $\hat{q}$만큼 **넓힙니다**.
* $\hat{q} < 0$: 원래 구간이 너무 넓었으므로, 양쪽으로 $|\hat{q}|$만큼 **좁힙니다**.

![Figure 6: CQR 알고리즘의 시각화. 원래의 Quantile Regression 구간(파란색 영역)을 Calibration을 통해 얻은 상수 $\hat{q}$만큼 확장하거나 축소하여 최종 Prediction Set을 생성한다.](images/figure6_cqr_visualization.png)

# Implementation

Python으로 CQR을 구현하는 것은 매우 간단합니다.

![Figure 5: Conformalized Quantile Regression 구현을 위한 Python 코드. Score를 계산하고 Quantile을 구하여 최종 구간을 조정하는 과정이 몇 줄의 코드로 구현된다.](images/figure5_cqr_python_code.png)

1.  **Get Scores**: Calibration 데이터에 대해 `max(lower - y, y - upper)`를 계산합니다.
2.  **Get Quantile**: 위 점수들의 $(1-\alpha)$ 분위수 $\hat{q}$를 계산합니다.
3.  **Deploy**: 새로운 데이터의 Lower/Upper 예측값에 각각 $-\hat{q}, +\hat{q}$를 더해줍니다.

# Conclusion

**Conformalized Quantile Regression (CQR)**은 회귀 문제에서 가장 널리 사용되는 최신 기법 중 하나입니다.
* **Adaptivity**: 입력값 $x$에 따라 구간의 길이(불확실성 크기)가 달라지는 Quantile Regression의 장점을 그대로 가집니다. (어려운 입력은 구간이 넓고, 쉬운 입력은 구간이 좁음)
* **Validity**: Conformal Prediction을 통해 통계적 커버리지를 엄밀하게 보장합니다.

이 방법은 단순한 MSE 기반 회귀보다 훨씬 풍부한 정보를 제공하며, 의료나 금융과 같이 리스크 관리가 중요한 분야에서 필수적인 도구입니다.

---
**Next Step**: 다음 포스트에서는 회귀 문제에서 Quantile Regression을 사용하기 어려운 경우(예: 단순히 평균과 분산만 예측하는 경우)에 사용할 수 있는 **Conformalizing Scalar Uncertainty Estimates**에 대해 알아보겠습니다.