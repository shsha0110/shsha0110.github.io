---
title: "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification (Part 6)"
subtitle: "6. Full Conformal Prediction"
author: "유성현"
date: "2026-01-16"
categories: [Paper Review]
format:
  html:
    toc: true
    number-sections: false
    code-fold: show
---

# Introduction: The Efficiency Trade-off

* 지금까지 우리가 다룬 방식은 **Split Conformal Prediction (Inductive CP)**이었습니다.
* 이 방식은 데이터를 학습용(Train)과 보정용(Calibration)으로 나누어 사용합니다.
  * **장점**: 계산이 매우 빠릅니다. 모델을 딱 한 번만 학습시키면 됩니다.
  * **단점**: 데이터를 쪼개야 하므로 **통계적 효율성(Statistical Efficiency)**이 떨어집니다. 보정용 데이터는 학습에 기여하지 못하고, 학습용 데이터는 보정에 기여하지 못하기 때문입니다.

* 데이터가 매우 귀하거나(예: 희귀병 임상 데이터), 예측의 정확도가 비용보다 훨씬 중요한 상황이라면 어떨까요?
* 이때 우리는 계산 비용을 감수하더라도 모든 데이터를 학습과 보정에 동시에 사용하는 **Full Conformal Prediction (Transductive CP)**을 고려해야 합니다.

# The Core Idea: "What if?"

* Full CP의 핵심 아이디어는 새로운 데이터 $X_{n+1}$에 대해 **"만약 정답이 $y$라면, 이 데이터가 기존 데이터들과 잘 어울리는가(Exchangeable)?"**를 테스트하는 것입니다.

* 우리는 아직 정답 $Y_{n+1}$을 모르지만, 가능한 모든 후보 $y \in \mathcal{Y}$를 하나씩 대입해볼 수는 있습니다.
* 만약 $y$가 진짜 정답이라면, $(X_{n+1}, y)$를 포함한 전체 데이터셋은 통계적으로 동질적(Exchangeable)이어야 합니다.

# The Algorithm

* 알고리즘은 모든 가능한 라벨 $y$에 대해 재학습(Retraining)을 수행해야 하므로 꽤 무겁습니다.

## Step 1: Loop over all possible labels
* 테스트 포인트 $X_{n+1}$에 대해, 가능한 모든 정답 후보 $y \in \mathcal{Y}$ (예: 분류 문제의 모든 클래스)에 대해 다음 과정을 반복합니다.

## Step 2: Augment and Retrain
* 기존 데이터셋에 가상의 데이터 포인트 $(X_{n+1}, y)$를 추가하여 확장된 데이터셋을 만듭니다.
* 그리고 이 데이터셋으로 모델 $\hat{f}^y$를 **처음부터 다시 학습**시킵니다.

$$ \text{Train } \hat{f}^y \text{ on } \{(X_1, Y_1), \dots, (X_n, Y_n), (X_{n+1}, y)\} $$

> **주의**: 이때 사용하는 학습 알고리즘은 데이터의 순서에 영향을 받지 않는 **대칭적(Symmetric)** 알고리즘이어야 합니다.

## Step 3: Compute Scores
* 학습된 모델 $\hat{f}^y$를 사용하여, 확장된 데이터셋 내의 모든 포인트($i=1 \dots n+1$)에 대해 Conformal Score를 계산합니다.

$$ s_i^y = s(X_i, Y_i, \hat{f}^y) \quad \text{for } i=1, \dots, n $$
$$ s_{n+1}^y = s(X_{n+1}, y, \hat{f}^y) $$

## Step 4: Compute Quantile
* 이 $n+1$개의 점수들 사이에서 $s_{n+1}^y$의 위치를 확인합니다.
* 정확히는 $1-\alpha$ 분위수 $\hat{q}^y$를 계산하여, $s_{n+1}^y$가 이 안에 들어오는지 확인합니다.

$$ \hat{q}^y = \text{Quantile}\left( \{s_1^y, \dots, s_{n+1}^y\} ; \frac{\lceil (n+1)(1-\alpha) \rceil}{n+1} \right) $$

## Step 5: Construct Prediction Set
* 위 조건을 만족하는(즉, 기존 데이터들과 잘 섞이는) 모든 $y$를 예측 집합에 포함시킵니다.

$$ \mathcal{C}(X_{n+1}) = \{ y \in \mathcal{Y} : s_{n+1}^y \le \hat{q}^y \} $$

# Statistical Interpretation: Permutation Test

* Full Conformal Prediction이 왜 작동하는지, 그리고 왜 "데이터를 섞어서(Permutation)" 판단하는지 이해하기 위해 통계학의 **순열 검정(Permutation Test)** 개념을 연결해보겠습니다.

## The Null Hypothesis of Exchangeability

* 우리가 테스트 데이터 $X_{n+1}$에 대해 어떤 가상의 정답 $y$를 부여했을 때, 핵심 질문은 이것입니다.

> **"이 데이터 포인트 $(X_{n+1}, y)$가 기존 데이터들과 구별되지 않고 잘 섞이는가?"**

* 이를 통계적 가설 검정의 언어로 표현하면 다음과 같습니다.

* **귀무가설 ($H_0$):** 데이터들 $Z_1, \dots, Z_{n+1}$은 **교환 가능(Exchangeable)**하다. 
* 즉, 데이터의 순서를 뒤섞어도 그 결합 확률 분포는 변하지 않는다.
    * 여기서 $Z_i = (X_i, Y_i)$입니다.

## The Test Statistic & P-value

* 이 귀무가설을 기각하기 위해, 우리는 데이터가 얼마나 "튀는지"를 측정하는 검정 통계량 $T$를 정의합니다. 
* Full CP에서는 **Nonconformity Score ($s$)**가 바로 이 역할을 합니다.

$$ T(Z) = s(X, Y) $$

* 점수 $s$가 클수록 해당 데이터는 다른 데이터들과 이질적이라는(Exchangeability를 위반한다는) 증거가 됩니다. 
* 우리는 관측된 데이터의 점수가, 데이터를 무작위로 섞었을 때 나올 수 있는 점수들과 비교해서 얼마나 큰지 **p-value**를 계산합니다.

$$ p = \frac{\sum_{\sigma \in S_{n+1}} \mathbb{1}\{ T(Z_{\sigma(1)}, \dots, Z_{\sigma(n+1)}) \ge T(Z_{observed}) \}}{(n+1)!} $$

* 하지만 Full CP에서는 모든 순열을 다 계산할 필요 없이, 각 데이터 포인트의 점수 $s_i$들의 순위(Rank)만 보면 됩니다. 
* 따라서 p-value는 다음과 같이 단순화됩니다.

$$ p(y) = \frac{1}{n+1} \sum_{i=1}^{n+1} \mathbb{1}\{ s_i^y \ge s_{n+1}^y \} $$

## Decision Rule (Validity Theorem)

* 순열 검정의 핵심 정리에 따르면, 귀무가설($H_0$)이 참일 때 p-value는 균등 분포(Uniform Distribution)를 따릅니다. 따라서 다음이 성립합니다.

> **Theorem (Validity of Permutation Test)**
>
> 모든 $\tau \in [0, 1]$과 모든 교환 가능한 분포 $P$에 대해:
> $$ \mathbb{P}_P(p \le \tau) \le \tau $$

* 우리는 허용 가능한 에러율 $\alpha$를 설정했으므로, **p-value가 $\alpha$보다 작으면(너무 희박한 확률이면)** 귀무가설을 기각합니다.

* **$p(y) \le \alpha$ (기각):** "$y$를 정답이라고 가정했더니, 이 데이터는 상위 $\alpha$% 안에 들 만큼 너무 이상해. $y$는 정답이 아닌 것 같아." $\rightarrow$ **예측 집합에서 제외.**
* **$p(y) > \alpha$ (채택):** "$y$를 정답이라고 가정해도, 데이터가 전체 무리 속에 자연스럽게 섞여 들어가네. $y$는 정답일 수도 있어." $\rightarrow$ **예측 집합에 포함.**

* 결국 Full CP의 예측 집합 $\mathcal{C}(X_{n+1})$은 **"순열 검정에서 기각되지 않고 살아남은 모든 $y$들의 모임"**입니다. 
* 이것이 바로 Full CP가 수학적으로 엄밀한 커버리지를 보장하는 이유입니다.

---

# Computational Cost vs. Statistical Efficiency

## The Cost
* 이 방법의 가장 큰 문제는 **계산 비용**입니다.
* 테스트 데이터가 하나 들어올 때마다, 그리고 후보 클래스 $K$개마다 매번 모델을 재학습해야 합니다.
* 총 학습 횟수: $(n+1) \times K$

* 따라서 딥러닝과 같이 학습이 오래 걸리는 모델이나, 회귀 문제(Regression)처럼 후보 $y$가 무한히 많은 경우에는 그대로 적용하기 어렵습니다.

## The Benefit
* 하지만 데이터를 나누지 않고 $n$개를 모두 사용하므로, **예측 집합이 더 작고 효율적(Sharp)**입니다.
* Split CP보다 정보 손실이 적어, 데이터가 적은 상황에서는 훨씬 강력한 성능을 발휘합니다.

# Theoretical Guarantee

* Full CP 역시 수학적으로 엄밀한 커버리지를 보장합니다.

> **Theorem 5 (Full conformal coverage guarantee)**
>
> 데이터가 교환 가능(Exchangeable)하고 학습 알고리즘이 대칭적(Symmetric)이라면, 다음이 성립한다.
>
> $$ \mathbb{P}(Y_{n+1} \in \mathcal{C}(X_{n+1})) \ge 1-\alpha $$

# Summary

| Feature | Split Conformal (SCP) | Full Conformal (FCP) |
| :--- | :--- | :--- |
| **Data Usage** | Train / Calib 분할 (비효율) | 전체 데이터 사용 (효율) |
| **Computation** | 1회 학습 (빠름) | $K$회 재학습 (매우 느림) |
| **Use Case** | Big Data, Deep Learning | Small Data, Statistically Critical Tasks |
| **Interpretation** | Validation Score Quantile | Permutation Test |

* Full CP는 계산 비용 때문에 현대 머신러닝에서는 잘 쓰이지 않지만, **Jackknife+**나 **CV+** (Section 6.2) 같은 기법들의 이론적 토대가 되는 매우 중요한 개념입니다.

---
**Final Note**: 이것으로 "A Gentle Introduction to Conformal Prediction" 논문의 핵심적인 이론과 알고리즘들을 모두 정리했습니다. 이 시리즈가 여러분의 모델에 '신뢰'를 더하는 데 도움이 되기를 바랍니다.