---
title: "[What If] Chapter 21. G-Methods For Time-Varying Treatments"
description: "시변 처리와 교란요인 피드백 상황에서의 인과 효과 추정"
author: "유성현"
date: "2026-02-10"
categories: [Paper Review, What If]
format:
  html:
    toc: true
    number-sections: false
    code-fold: show
    math: true
    theme: cosmo
---

# 21.1 The g-formula for time-varying treatments

## 1. Introduction: The Challenge of Time-Varying Treatments

* 인과추론에서 가장 까다로운 시나리오 중 하나는 **시변 처리(Time-varying treatment)**가 존재하고, 동시에 **처리-교란요인 피드백(Treatment-confounder feedback)**이 발생하는 상황입니다.

* 이전 챕터(Chapter 20)에서 우리는 이러한 구조를 가진 데이터셋에서 전통적인 조정 방법(층화, 회귀분석 등)이 실패한다는 것을 확인했습니다. 설령 실제 인과 효과가 0(Null)이라 할지라도, 전통적인 방법은 편향된 추정치를 내놓습니다.

* Chapter 21에서는 이러한 편향을 해결하기 위한 **G-Methods**의 첫 번째 주자, **The G-Formula**를 소개합니다. 이 글에서는 G-formula가 어떻게 시변 처리 상황에서 올바른 인과 효과를 식별(Identify)해내는지, 그 수리적 구조와 직관적인 시뮬레이션 관점을 자세히 살펴봅니다.

## 2. Motivating Example: Sequential Randomized Experiment

* 논의를 구체화하기 위해, Chapter 20에서 사용했던 순차적 무작위 실험(Sequentially Randomized Experiment) 데이터를 다시 가져옵니다.

### 2.1 The Data Structure

* 이 데이터는 2개의 시점($k=0, 1$)을 가집니다.
  * **$A_0, A_1$**: 치료 여부 (0 또는 1)
  * **$L_1$**: 시점 1에서 측정된 교란요인 (Confounder)
  * **$Y$**: 최종 결과 (Outcome)

![Table 21.1: 데이터의 구조와 요약 통계량. $A_0$에 따라 $L_1$의 분포가 달라지고, $L_1$에 따라 $A_1$과 $Y$의 평균이 달라지는 구조를 보여준다.](./images/table_21_1.png)

* 위 표(Table 21.1)를 트리 구조로 시각화하면 데이터의 생성 과정을 더 명확히 이해할 수 있습니다.

![Figure 21.1: 관찰된 데이터의 인과 트리. 각 가지(Branch)는 처리($A$)와 교란요인($L$)의 경로를 나타내며, 각 끝단에는 관찰된 개체 수($N$)와 평균 결과($E[Y]$)가 표시되어 있다.](./images/figure_21_1.png)

### 2.2 The Problem with Static Adjustment

* 만약 우리가 시점 1의 치료($A_1$)에만 관심이 있고, 이것이 고정된(Time-fixed) 치료라면, 우리는 단순히 $L_1$에 대해 표준화(Standardization)를 수행하면 됩니다.

$$E[Y^{a_1}] = \sum_{l_1} E[Y|A_1=a_1, L_1=l_1] f(l_1)$$

* 여기서 $f(l_1) = Pr[L_1=l_1]$은 전체 모집단에서의 교란요인 분포입니다. 이 가중 평균(Weighted Average)이 바로 고정된 치료에 대한 G-formula입니다.

* 하지만, **시변 처리($\bar{A} = (A_0, A_1)$)** 상황에서는 문제가 복잡해집니다.
  * 1.  **Feedback:** $A_0$가 $L_1$에 영향을 미칩니다.
  * 2.  **Selection:** $L_1$이 다시 $A_1$에 영향을 미칩니다.

* 이 경우, 단순한 $L_1$ 조정은 $A_0$의 효과를 가리거나(Over-adjustment), $L_1$ 자체가 collider가 되어 편향을 유발할 수 있습니다. 따라서 우리는 G-formula를 일반화해야 합니다.

## 3. The G-Formula for Time-Varying Treatments

### 3.1 Intuition: Standardization by History

* 시변 처리에 대한 G-formula의 핵심 아이디어는 **"과거의 역사(History)에 조건부로 가중치를 부여한다"**는 것입니다.

* 식별 조건(Identifiability conditions: Sequential Exchangeability, Positivity, Consistency) 하에서, G-formula 추정량은 다음과 같이 정의됩니다:

> **핵심 개념**: G-formula는 연구 모집단의 교란요인 분포로 표준화된 평균 결과를 계산하되, 이 분포는 **이전 시점의 치료 및 교란요인 역사에 조건부(Conditional)**여야 합니다.

### 3.2 Mathematical Formulation

* 2시점($k=0, 1$) 데이터에 대한 G-formula는 다음과 같습니다:

$$E[Y^{a_0, a_1}] = \sum_{l_1} E[Y | A_0=a_0, A_1=a_1, L_1=l_1] \times f(l_1 | A_0=a_0)$$

* 이 식을 고정된 치료(Time-fixed)의 경우와 비교해 봅시다.
  * **Time-fixed:** $f(l_1)$ (모집단 전체의 주변 분포 사용)
  * **Time-varying:** $f(l_1 | a_0)$ ($A_0$라는 과거 치료를 받은 하위 집단에서의 분포 사용)

* 이 조건부 확률 $f(l_1 | a_0)$을 사용하는 이유는, 우리가 개입(Intervention)을 통해 $A_0$를 $a_0$로 설정했을 때, 그에 따라 변화하는 $L_1$의 분포를 반영해야 하기 때문입니다.

### 3.3 Application to the Example

* 이제 위에서 본 데이터를 사용하여 실제 인과 효과를 계산해 봅시다. 우리는 "항상 치료($a_0=1, a_1=1$)" 전략과 "전혀 치료 안 함($a_0=0, a_1=0$)" 전략을 비교합니다.

#### Step 1: "전혀 치료 안 함" ($a_0=0, a_1=0$)

$$
\begin{aligned}
E[Y^{0,0}] &= \sum_{l_1} E[Y|A_0=0, A_1=0, L_1=l_1] \times P(L_1=l_1|A_0=0) \\
&= E[Y|0,0, L_1=0]P(L_1=0|A_0=0) + E[Y|0,0, L_1=1]P(L_1=1|A_0=0)
\end{aligned}
$$

* Figure 21.1(트리)의 데이터를 대입하면:
  * $P(L_1=0|A_0=0) = 0.25$
  * $P(L_1=1|A_0=0) = 0.75$
  * $E[Y|0,0,0] = 84$
  * $E[Y|0,0,1] = 52$

$$\text{Result} = 84 \times 0.25 + 52 \times 0.75 = 21 + 39 = 60$$

#### Step 2: "항상 치료" ($a_0=1, a_1=1$)

$$
\begin{aligned}
E[Y^{1,1}] &= \sum_{l_1} E[Y|A_0=1, A_1=1, L_1=l_1] \times P(L_1=l_1|A_0=1) \\
&= E[Y|1,1,0]P(L_1=0|1) + E[Y|1,1,1]P(L_1=1|1)
\end{aligned}
$$

* 데이터 대입:
  * $P(L_1=0|A_0=1) = 0.50$
  * $P(L_1=1|A_0=1) = 0.50$
  * $E[Y|1,1,0] = 76$
  * $E[Y|1,1,1] = 44$

$$\text{Result} = 76 \times 0.50 + 44 \times 0.50 = 38 + 22 = 60$$

#### Step 3: Causal Effect

$$\text{Effect} = E[Y^{1,1}] - E[Y^{0,0}] = 60 - 60 = 0$$

* 전통적인 방법론이 실패했던 것과 달리, G-formula는 **정확한 인과 효과인 0(Null)을 성공적으로 추정**해냈습니다.

## 4. G-Formula as a Simulation

* G-formula를 이해하는 또 다른 강력한 직관은 **시뮬레이션(Simulation)**입니다.

* 순차적 교환가능성(Sequential Exchangeability)이 성립한다면, G-formula는 연구 모집단의 모든 개체가 특정 전략 $\bar{a}$를 따랐을 때 관찰되었을 반사실적(Counterfactual) 결과 $Y^{\bar{a}}$와 공변량 역사 $\bar{L}^{\bar{a}}$의 결합 분포를 시뮬레이션하는 과정으로 볼 수 있습니다.

### 4.1 Constructing the Counterfactual Tree

* 이 시뮬레이션은 원래의 트리(Figure 21.1)를 수정하여 새로운 **반사실적 트리(Counterfactual Tree)**를 만드는 것과 같습니다.

![Figure 21.2: "항상 치료($a_0=1, a_1=1$)" 전략 하에서의 반사실적 트리. $A_0$와 $A_1$의 확률은 1로 고정되지만, $L_1$의 조건부 확률($P(L_1|A_0)$)과 조건부 평균 결과($E[Y|\dots]$)는 원본 데이터에서 그대로 가져와 보존된다.](./images/figure_21_2.png)

* 위 그림(Figure 21.2)은 모든 개체가 $A_0=1, A_1=1$을 따랐을 때의 세상을 보여줍니다.
  * 1.  **Treatment Assignment:** $k=0, 1$ 시점의 치료 확률을 1로 할당합니다.
  * 2.  **Covariate & Outcome:** 하지만 $P(L_1=l_1|A_0=a_0)$와 $E[Y|A_0=a_0, A_1=a_1, L_1=l_1]$ 값은 **원본 모집단의 값**을 그대로 가져옵니다.

* 이것이 바로 G-formula가 수학적으로 수행하는 작업입니다.

### 4.2 Why History Matters (Fine Point 21.1)

* G-formula에서 "역사(History)"에 조건부 확률을 구한다고 할 때, 이 역사는 반드시 시간적(Chronological) 순서만을 의미하는 것은 아닙니다.

* 인과적 구조상 $A_k$의 교환가능성을 확보하기 위해 필요한 교란요인들의 집합을 의미합니다.
* 일반적으로는 시간적 과거가 맞지만, 이론적으로는 미래의 변수라도 교란요인이 될 수 있습니다.
* 하지만, 단순히 시간적 과거에 있다고 해서 모두 조정하면 안 됩니다. M-bias를 유발하는 변수(Colliders)는 제외해야 합니다.

## 5. Generalization: High-Dimensional G-Formula

* 현실 세계의 데이터는 훨씬 복잡합니다. 시점 $K$까지 다수의 시변 교란요인 $L_k$가 존재하는 경우, G-formula는 다음과 같이 일반화됩니다.
$$E[Y^{\bar{a}}] = \sum_{\bar{l}} E[Y|\bar{A}=\bar{a}, \bar{L}=\bar{l}] \prod_{k=0}^{K} f(l_k | \bar{a}_{k-1}, \bar{l}_{k-1})$$
    * $\sum_{\bar{l}}$: 가능한 모든 공변량 역사($l_0, l_1, \dots, l_K$)에 대한 합입니다.
    * $\prod_{k=0}^{K}$: 각 시점 $k$에서, 과거 역사($\bar{a}_{k-1}, \bar{l}_{k-1}$)가 주어졌을 때 현재 교란요인($l_k$)이 나타날 조건부 확률의 곱입니다.

### 5.1 The Plug-in G-Formula

* 고차원 데이터에서는 모든 가능한 $\bar{l}$ 조합에 대해 빈도수를 세는 것이 불가능합니다. 따라서 우리는 모수적 모델(Parametric Models)을 사용해야 합니다.
  * 1.  **Outcome Model:** $E[Y|\bar{A}, \bar{L}]$을 추정하기 위한 회귀모형 (예: 선형 회귀).
  * 2.  **Covariate Models:** 각 시점 $k$별로 $f(l_k|\bar{a}_{k-1}, \bar{l}_{k-1})$을 추정하기 위한 모델 (예: 로지스틱 회귀).

* 이렇게 추정된 값들을 위 공식에 대입(Plug-in)하여 계산하는 방식을 **Parametric G-formula**라고 부릅니다.

---

# 21.2 IP weighting for time-varying treatments

## 1. Introduction

* 이전 장들에서 우리는 고정된 시점의 치료(Time-fixed treatment)에 대한 인과 효과를 추정하기 위해 **IP Weighting (Inverse Probability Weighting)**을 사용하는 방법을 다루었습니다. 하지만 현실의 데이터, 특히 사회과학이나 의료 데이터는 치료와 교란요인(Confounder)이 시간의 흐름에 따라 변하는 **Time-varying** 구조를 가집니다.

* 본 포스트에서는 Hernán & Robins의 *What If* Chapter 21.2를 바탕으로, 이러한 시변(Time-varying) 환경에서 IP Weighting을 어떻게 일반화할 수 있는지, 그리고 이를 통해 **Marginal Structural Model (MSM)**을 어떻게 추정하는지 상세히 정리합니다.

## 2. IP Weighting for Time-Varying Treatments

### 2.1. Motivation: Why Generalize?

* 고정된 치료(Time-fixed treatment) $A$에 대한 IP Weighting의 핵심 아이디어는 각 개인에게 $1/f(A|L)$의 가중치를 부여하여, 교란요인 $L$과 치료 $A$ 사이의 연결을 끊어버리는 **가상 모집단(Pseudo-population)**을 생성하는 것이었습니다.

* 치료가 시간 흐름에 따라 $k=0, 1, \dots, K$ 시점에 걸쳐 이루어지는 경우($\bar{A} = (A_0, A_1, \dots, A_K)$), 우리는 각 시점마다 교란요인 $\bar{L}_k$에 의해 치료 확률이 달라지는 상황을 마주하게 됩니다. 따라서 가중치 또한 시간의 흐름에 따른 조건부 확률들의 곱으로 확장되어야 합니다.

### 2.2. Construction of Weights

* Time-varying treatment $\bar{A}$와 Time-varying covariates $\bar{L}$이 존재할 때, 가중치는 다음과 같이 정의됩니다.

#### Non-stabilized Weights ($W^{\bar{A}}$)

* 비안정화 가중치는 각 시점 $k$에서 관측된 과거 이력($\bar{A}_{k-1}, \bar{L}_k$)이 주어졌을 때, 해당 개인이 실제로 받은 치료($A_k$)를 받을 확률의 역수를 누적하여 계산합니다.
$$
W^{\bar{A}} = \prod_{k=0}^{K} \frac{1}{f(A_k | \bar{A}_{k-1}, \bar{L}_k)}
$$
  * 여기서 $f(\cdot)$는 조건부 확률 밀도 함수(또는 질량 함수)를 의미합니다.

#### Stabilized Weights ($SW^{\bar{A}}$)

* 비안정화 가중치는 분모의 확률이 매우 작을 경우 가중치가 극단적으로 커져 추정량의 분산(Variance)을 폭발시킬 위험이 있습니다. 이를 방지하기 위해 분자에 치료의 주변 확률(Marginal probability)을 포함한 안정화 가중치를 사용합니다.
$$
SW^{\bar{A}} = \prod_{k=0}^{K} \frac{f(A_k | \bar{A}_{k-1})}{f(A_k | \bar{A}_{k-1}, \bar{L}_k)}
$$
  * **분모 (Denominator):** 과거의 치료 및 **교란요인 이력($\bar{L}_k$)**을 모두 고려했을 때, 현재 치료를 받을 확률. 이는 인과적 연결을 끊는 역할을 합니다.
  * **분자 (Numerator):** 과거의 **치료 이력($\bar{A}_{k-1}$)**만 고려했을 때, 현재 치료를 받을 확률. 이는 가중치의 변동성을 줄여줍니다.

> **Important:** 안정화 가중치를 사용하더라도 가상 모집단에서의 평균 인과 효과(Average Causal Effect) 추정치는 비안정화 가중치를 사용했을 때와 동일합니다 (Identifiability 조건 하에서). 단, 추정의 효율성(Efficiency) 측면에서 안정화 가중치가 선호됩니다.

### 2.3. Pseudo-population Interpretation

* 이 가중치들을 적용하여 생성된 가상 모집단에서는 다음과 같은 특성이 성립합니다:
  * 1.  **Non-stabilized:** 각 시점 $k$에서의 치료 $A_k$는 과거 이력과 무관하게 완전히 무작위 할당된 것처럼 동작합니다 (Randomization probability = constant).
  * 2.  **Stabilized:** 각 시점 $k$에서의 치료 $A_k$는 오직 과거 치료 이력 $\bar{A}_{k-1}$에만 의존하며, 교란요인 $\bar{L}_k$와는 독립이 됩니다.

* 즉, **Sequential Unconditional Exchangeability**가 성립하게 되어, 연관성(Association)이 곧 인과성(Causation)이 되는 구조가 만들어집니다.

## 3. Illustration: A Worked Example

* 교재의 Figure 21.3에 제시된 예제를 통해 IP Weighting이 어떻게 작동하는지 구체적으로 살펴보겠습니다.

![Figure 21.3: Tree graph representing the pseudo-population created by IP weighting. The graph explicitly shows the number of individuals ($N_W$) in the pseudo-population for each treatment and covariate history, alongside the calculated weights ($W^{\bar{A}}$ and $SW^{\bar{A}}$). This visualizes how the original population is re-weighted to remove confounding.](./images/figure_21_3.png)

### Setting
* 총 인구: 32,000명
* 우리의 목표: $E[Y^{a_0=1, a_1=1}]$과 $E[Y^{a_0=0, a_1=0}]$의 차이, 즉 인과 효과를 추정하는 것입니다.
* 데이터 구조: $L_0$는 없으며, 시점 $k=0, 1$에 대한 치료와 $L_1$이 존재합니다.

### Calculation
* 비안정화 가중치를 적용한 가상 모집단에서의 평균 $E_{ps}[Y | A_0=0, A_1=0]$을 계산해 봅시다.

* 1.  트리 그래프(Figure 21.3)에서 $(A_0=0, A_1=0)$ 경로를 따르는 모든 개체를 찾습니다.
* 2.  해당 경로의 가중치 $W$와 결과값 $Y$를 사용하여 가중 평균을 구합니다.
* 3.  계산 결과:
    $$
    E_{ps}[Y | \bar{a}=\bar{0}] = 84 \times \frac{8000}{32000} + 52 \times \frac{24000}{32000} = 21 + 39 = 60
    $$
   
* 동일한 방식으로 $E_{ps}[Y | \bar{a}=\bar{1}]$을 계산하면 역시 60이 나옵니다. 따라서 추정된 인과 효과는 $60 - 60 = 0$입니다. 이는 g-formula를 사용했을 때 얻은 결과와 정확히 일치합니다.

> **Insight:** g-formula와 IP Weighting은 Identifiability 조건이 성립하지 않더라도(즉, 인과적 해석이 불가능하더라도) 수치적으로는 동일한 값을 산출합니다. 이는 두 방법론이 동일한 통계적 구조를 공유함을 시사합니다.

## 4. Marginal Structural Models (MSMs)

### 4.1. The Curse of Dimensionality

* 시점이 $K$개로 늘어나면 가능한 치료 전략 $\bar{a}$의 수는 $2^K$개로 기하급수적으로 증가합니다. 데이터가 아무리 많아도 모든 가능한 치료 이력에 대해 평균 $E[Y^{\bar{a}}]$를 비모수적(Non-parametric)으로 추정하는 것은 불가능에 가깝습니다.

* 이를 해결하기 위해 우리는 치료 이력 $\bar{a}$를 요약하는 파라메트릭 모델인 **Marginal Structural Model (MSM)**을 도입합니다.

### 4.2. Model Specification

* 가장 일반적인 형태는 **누적 치료량(Cumulative treatment)**, $\text{cum}(\bar{a}) = \sum_{k=0}^K a_k$에 선형적으로 의존한다고 가정하는 것입니다.
$$
E[Y^{\bar{a}}] = \beta_0 + \beta_1 \text{cum}(\bar{a})
$$
  * $\beta_1$: 누적 치료량이 1단위 증가할 때 평균 결과값의 변화량(인과 효과).
  * 이 모델은 $2^K$개의 미지수를 단 2개의 파라미터($\beta_0, \beta_1$)로 축소시킵니다.

### 4.3. Estimation via Weighted Least Squares (WLS)

* 이 MSM의 파라미터는 관측된 데이터에 대해 **IP 가중치($SW^{\bar{A}}$)를 적용한 가중 최소 자승법(Weighted Least Squares, WLS)**으로 추정할 수 있습니다.

$$
E[Y | \bar{A}] = \theta_0 + \theta_1 \text{cum}(\bar{A}) \quad \text{(Weighted by } SW^{\bar{A}} \text{)}
$$

* Identifiability 조건 하에서, WLS로 추정된 $\hat{\theta}_1$은 인과 파라미터 $\beta_1$에 대해 일치 추정량(Consistent estimator)이 됩니다.

> **Note on Variance:** 추정량의 분산은 Non-parametric Bootstrap을 사용하거나, Robust Variance Estimator(Sandwich estimator)를 통해 구할 수 있습니다. 일반적으로 안정화 가중치($SW^{\bar{A}}$)를 사용하면 신뢰구간의 폭이 더 좁아져 효율적입니다.

### 4.4. Model Misspecification & Diagnostics

* 만약 실제 인과 효과가 누적 치료량의 제곱에 비례하거나, 특정 시점의 치료에만 의존한다면 위 선형 모델은 **Misspecified** 된 것입니다.

* 이를 검증하기 위해 더 복잡한 항(예: $cum(\bar{A})^2$ 또는 최근 5개월간의 치료량 등)을 모델에 추가하고, 해당 계수들이 0인지 검정(Wald test)하여 모델의 적합성을 평가할 수 있습니다. 다행히 IP Weighting 기반의 MSM은 g-formula와 달리 **"g-null paradox"**의 영향을 받지 않습니다.

## 5. Practical Implementation Details

* 실제 연구(Observational Study)에서는 $f(A_k | \dots)$를 알 수 없으므로 데이터를 통해 추정해야 합니다.

* 1.  **Propensity Score Estimation:** 각 시점 $k$마다 로지스틱 회귀분석 등을 사용하여 $Pr[A_k=1 | \bar{A}_{k-1}, \bar{L}_k]$를 추정합니다.
    * 보통은 데이터를 'Long format'으로 변환한 후, 시간 $k$를 공변량으로 포함하여 하나의 통합된 모델(Pooled logistic regression)을 적합합니다.
* 2.  **Weight Calculation:** 추정된 확률 $\hat{f}$를 사용하여 $W^{\bar{A}}$ 또는 $SW^{\bar{A}}$를 계산합니다.
* 3.  **WLS:** 계산된 가중치를 적용하여 MSM을 적합합니다.

## 6. Effect Modification

* IP Weighting은 기저(Baseline) 변수 $V$에 의한 효과 변경(Effect Modification)을 탐색하는 데에도 유연하게 적용될 수 있습니다.

$$
E[Y^{\bar{a}} | V] = \beta_0 + \beta_1 \text{cum}(\bar{a}) + \beta_2 V + \beta_3 \text{cum}(\bar{a})V
$$

* 이 모델 역시 $SW^{\bar{A}}(V)$ 가중치를 사용한 WLS로 추정 가능합니다. 단, $V$는 반드시 Baseline 변수여야 하며, $k>0$ 시점의 변수를 포함하면 해석이 복잡해질 수 있음을 유의해야 합니다.

---

# 21.3 A doubly robust estimator for time-varying treatments

## 1. Introduction: 왜 '이중 강건'인가?

* 인과추론, 특히 시변(Time-varying) 처리가 존재하는 복잡한 관찰 연구에서 우리는 보통 두 가지 거대한 방법론의 줄기를 마주합니다.
  * 1.  **IP Weighting (Inverse Probability Weighting):** 처리(Treatment) 모형 $P(A|L)$을 정확히 맞춰야 함.
  * 2.  **G-formula (Parametric G-formula):** 결과(Outcome) 모형 $E[Y|A, L]$을 정확히 맞춰야 함.

* 하지만 현실 데이터에서 모델을 완벽하게 명시(Specification)하는 것은 매우 어렵습니다. 만약 모델이 틀리면 어떻게 될까요?
특히 Parametric G-formula의 경우, "G-null Paradox"라고 불리는 현상이 발생할 수 있습니다. 이는 귀무가설(Null hypothesis)이 참임에도 불구하고, 모델의 오설정(misspecification)만으로 인해 귀무가설을 기각해버리는 편향(Bias)이 발생할 수 있다는 이론적 문제입니다.

* 여기서 **이중 강건 추정량(Doubly Robust Estimator, DR)**이 등장합니다. 이름에서 알 수 있듯이, 이 방법은 우리에게 **"두 번의 기회(Two chances)"**를 줍니다.

> **핵심 아이디어:** 처리 모형(Propensity score) **또는** 결과 모형(Outcome regression) 중 **하나만이라도** 맞으면, 추정값은 일치성(Consistency)을 가집니다.

* 이 글에서는 Hernán & Robins의 *What If* Chapter 21.3을 바탕으로, 시점 고정(Time-fixed) 상황에서 시작하여 시변(Time-varying) 상황으로 확장되는 DR 추정량의 알고리즘을 상세히 다룹니다.

## 2. Warm-up: 시점 고정(Time-fixed) 처리에서의 DR

* 복잡한 시변 처리를 다루기 전에, 단일 시점 처리($A$)와 결과($Y$), 그리고 교란변수($L$)가 있는 상황을 먼저 살펴보겠습니다. Bang and Robins (2005)가 제안한 이 방법론은 이후 시변 처리로 확장되는 기초가 됩니다.

### 알고리즘 개요
* 우리의 목표는 $E[Y^{a=1}]$과 $E[Y^{a=0}]$을 추정하여 인과 효과를 구하는 것입니다.

#### Step 1: 처리 모형 추정 (Propensity Score)
* 먼저, 처리($A$)에 대한 확률 모형을 적합합니다.
$$
\hat{f}(a|L) \equiv \widehat{Pr}[A=a|L]
$$
* 여기서 예측된 확률의 역수를 **가중치(Weight)**로 사용합니다. 이를 $\hat{W}^a = \frac{1}{\hat{f}(a|L)}$라고 정의합시다.

#### Step 2: 결과 모형 추정 (Clever Covariate)
* 이 단계가 핵심입니다. $Y$에 대한 회귀 모형을 적합하되, **Step 1에서 구한 가중치 $\hat{W}^a$를 공변량(Covariate)으로 추가**합니다.
$$
b(a, L; \theta) = \text{expit}(\theta_{a,0} + \theta_{a,1}L + \theta_{a,2}\hat{W}^a)
$$
  * Note: $\text{expit}(x) = \frac{e^x}{1+e^x}$)

* 이 회귀식은 $A=a$인 집단(실제 처리를 받은 집단)에 대해서만 적합(Fit)합니다.

#### Step 3: 표준화 (Standardization)
* Step 2에서 구한 회귀 계수 $\hat{\theta}$를 사용하여, **전체 표본(Treated + Untreated)**에 대해 예측값을 구하고 평균을 냅니다.

$$
\hat{E}[Y^a] = \frac{1}{n} \sum_{i=1}^{n} b(a, L_i; \hat{\theta})
$$

* 이렇게 구한 $\hat{E}[Y^{a=1}] - \hat{E}[Y^{a=0}]$은 이중 강건 성질을 가집니다.

## 3. Time-Varying Treatment로의 확장

* 이제 시간이 $k=0, 1, \dots, K$로 흐르는 동적 상황으로 확장해 봅시다. 우리는 특정 치료 전략 $\overline{a}$ (예: "항상 치료받음") 하에서의 반사실적 평균 $E[Y^{\overline{a}}]$를 추정하고 싶습니다.

* 설명의 편의를 위해 **"모든 시점에서 치료받음 ($\overline{a} = \overline{1}$)"** 전략을 기준으로 설명합니다.

![Figure: 시변 처리에서의 이중 강건 추정 흐름도. Step 1의 전향적 가중치 계산과 Step 2의 후향적 결과 회귀가 결합되는 구조를 보여줍니다.](./images/dr_time_varying_process.png)

### Step 1: 순차적 처리 모형 (Sequential Treatment Models)

* 모든 시점 $k$에 대해 처리 확률 모형 $\pi_k$를 적합합니다.
$$
\pi_k(\overline{L}_k; \alpha) = Pr[A_k=1 | \overline{A}_{k-1}=\overline{1}_{k-1}, \overline{L}_k]
$$
* 이때, $k-1$ 시점까지 계속 치료를 받은 사람들($\overline{A}_{k-1}=\overline{1}_{k-1}$)만을 대상으로 데이터를 풀링(pooling)하여 적합합니다.

#### 시변 가중치 계산
* 각 시점 $m$까지 치료받은 사람들을 위한 누적 가중치 $W^{\overline{1}_m}$을 계산합니다. 이는 Time-fixed 때와 달리 매 시점마다 누적된 확률의 역수입니다.

$$
\hat{W}^{\overline{1}_m} = \prod_{k=0}^{m} \frac{1}{\hat{\pi}_k(\overline{L}_k)}
$$

### Step 2: 순차적 결과 모형 (Sequential Outcome Models)

* 이 부분이 알고리즘적으로 가장 흥미로운 부분입니다. **미래 시점($K$)에서 현재 시점($0$)으로 시간을 거슬러 올라가는(Backward) 방식**을 사용합니다. 이를 흔히 **Iterative Conditional Expectation (ICE)** 방식이라고도 부릅니다.

* 각 시점 $m$ ($K$부터 $0$까지)에 대해 별도의 회귀 모형 $b_m$을 적합합니다.

#### 핵심 로직
* 각 시점 $m$의 회귀 모형에는 다음 두 가지가 포함됩니다.
  * 1.  **공변량:** 과거의 이력 $\overline{L}_m$
  * 2.  **Clever Covariate:** Step 1에서 구한 누적 가중치 $\hat{W}^{\overline{1}_m}$

* **종속변수(Target)가 시점마다 달라집니다:**
  * 마지막 시점 ($m=K$): 실제 결과값 $Y$가 종속변수입니다.
  * 중간 시점 ($m < K$): **바로 다음 단계($m+1$)에서 예측된 결과값** $\hat{B}_{m+1}$이 종속변수가 됩니다.

#### 수식적 표현
* 시점 $m$에서의 회귀 모형을 다음과 같이 정의할 수 있습니다 (Binary Outcome의 경우):

$$
b_m(\overline{L}_m; \beta_m) = \text{expit}\left( \gamma_m X_m + \varsigma_m \hat{W}^{\overline{1}_m} \right)
$$

* 여기서:
  * $X_m$: 공변량 $\overline{L}_m$의 벡터 함수
  * $\hat{W}^{\overline{1}_m}$: 시점 $m$까지의 누적 가중치 (Clever Covariate)

* 이 회귀식은 시점 $m$까지 치료를 지속한 사람들을 대상으로 적합하며, 이를 통해 예측값 $\hat{B}_m$을 생성합니다. 이 $\hat{B}_m$은 $m-1$ 시점 회귀 모형의 종속변수로 사용됩니다.

> **참고:** 예측값 $\hat{B}_{m+1}$은 실수가 아니지만, [0, 1] 사이의 값을 가지므로 Logistic 회귀의 종속변수로 사용할 수 있습니다 (Quasi-binomial likelihood 사용).

### Step 3: 최종 추정 (Standardization)

* Step 2의 역순환 과정을 $m=0$까지 완료하면, 우리는 시점 0에서의 예측값 $\hat{B}_0$를 얻게 됩니다.
$$
\hat{B}_0 = b_0(L_0; \hat{\beta}_0)
$$

* 최종적으로, **전체 표본(모든 개인)**에 대해 $\hat{B}_0$의 평균을 구합니다.

$$
\hat{E}[Y^{\overline{a}=\overline{1}}] = \frac{1}{n} \sum_{i=1}^{n} \hat{B}_{0,i}
$$

* 만약 대조군(예: "항상 치료받지 않음", $\overline{a}=\overline{0}$)의 효과도 보고 싶다면, 위 과정을 $\overline{a}=\overline{0}$으로 설정하여 반복한 뒤 두 결과의 차이를 구하면 됩니다.

## 4. 왜 이것이 "강건(Robust)"한가?

* 이 추정량은 단순히 "이중(Doubly)" 강건한 것을 넘어, **다중 강건(Multiply Robust)** 또는 **$K+2$ Robustness**라는 강력한 성질을 가집니다.

### K+2 Robustness의 의미
* 추정량이 일치성(Unbiasedness)을 가지기 위한 조건이 매우 유연합니다. 다음의 조합 중 하나만 성립해도 됩니다:
  * 1.  모든 시점 $m$에서 **결과 모형** $b_m$이 정확하게 명시됨.
  * 2.  모든 시점 $m$에서 **처리 모형** $\pi_k$가 정확하게 명시됨.
  * 3.  (가장 강력한 조건) 어떤 시점 $m$을 기준으로, **$0 \sim m$까지는 처리 모형**이 맞고, **$m+1 \sim K$까지는 결과 모형**이 맞아도 됨.

* 즉, 전체 기간 동안 모델을 완벽하게 맞추지 못하더라도, 구간별로 모델이 부분적으로 맞다면 여전히 올바른 인과 효과를 추정할 수 있다는 것입니다.

## 5. Technical Details & Implementation Notes

### Boundedness (경계 조건)
* 이 방식(Plug-in Estimator)의 큰 장점 중 하나는 추정값이 항상 **[0, 1] 범위 내에 존재**한다는 것입니다. 기존의 다른 이중 강건 추정량(예: $\psi_{TR}$)은 가중치가 불안정할 경우 [0, 1] 범위를 벗어나는 문제가 있었습니다.

### TMLE와의 관계
* 이 추정량은 **Targeted Minimum Loss-based Estimator (TMLE)**의 한 종류입니다. TMLE는 머신러닝 모델을 인과추론에 적용할 때 발생할 수 있는 편향을 수정하는 데 매우 효과적인 프레임워크로, 최근 딥러닝 기반 인과추론에서도 많이 언급됩니다.

### Computational Considerations
* 과거에는 이러한 절차가 계산 비용이 높고 소프트웨어가 부족하여 구현이 어려웠으나, 최근에는 머신러닝과 Sample splitting을 결합하여 복잡한 생존 분석(Failure time outcomes) 등에 적용하는 것이 가능해지고 있습니다.

---

# 21.4 G-estimation for time-varying treatments

## 1. Introduction

* 이전 포스트들에서 우리는 시간 가변적 교란요인(Time-varying confounders)이 존재하는 상황에서 인과 효과를 추정하기 위해 **IP Weighting**과 **G-formula**를 다루었습니다. 이번 포스트에서는 이 두 방법론의 대안이자, 특히 효과의 이질성(effect heterogeneity)을 모델링하는 데 강력한 **G-estimation**과 그 기초가 되는 **Structural Nested Mean Models (SNMMs)**에 대해 깊이 있게 다룹니다.

* G-formula가 결합 밀도(joint density)를 모델링하고 IP Weighting이 치료 확률(treatment assignment)을 모델링한다면, G-estimation은 **조건부 인과 효과(conditional causal effect)** 자체를 직접 모델링하는 접근 방식입니다.

![Figure: Causal Diagram representing time-varying treatments and confounders. The diagram should show nodes for L0, A0, Y, L1, A1 with arrows indicating causal paths and confounding relationships. specifically highlighting the feedback loop where past treatment affects future confounders.](./images/dag_time_varying.png)

> **Figure 1.** 시간 가변적 치료($A_k$)와 교란요인($L_k$)이 존재하는 인과 그래프(DAG). $L_1$이 이전 치료 $A_0$의 영향을 받으면서 동시에 이후 치료 $A_1$과 결과 $Y$에 영향을 미치는 구조적 특성을 보여줍니다.

## 2. Structural Nested Mean Models (SNMMs)

* G-estimation을 수행하기 위해서는 먼저 인과 효과를 구조화하는 모델이 필요합니다. 이를 **Structural Nested Mean Model (SNMM)**이라고 합니다.

### 2.1. The "Blip" Function: 효과의 정의

* SNMM은 각 시점 $k$에서의 치료 $A_k$가 결과 $Y$에 미치는 효과를 **"Blip"**이라는 개념으로 정의합니다. 이는 과거의 치료 이력($\bar{a}_{k-1}$)은 고정된 상태에서, 시점 $k$에서 치료를 받았을 때($a_k$)와 받지 않았을 때($0$)의 잠재적 결과(Counterfactual Outcome) 차이를 의미합니다.

* 가장 일반적인 형태의 SNMM은 다음과 같이 정의됩니다:

$$
E[Y^{\bar{a}_{k-1}, a_k, \underline{0}_{k+1}} - Y^{\bar{a}_{k-1}, \underline{0}_k} \mid \bar{L}_k, \bar{A}_{k-1}] = a_k \gamma_k(\bar{a}_{k-1}, \bar{l}_k, \beta)
$$

* 여기서 각 항의 의미는 다음과 같습니다:
  * $(\bar{a}_{k-1}, a_k, \underline{0}_{k+1})$: 시점 $k-1$까지는 $\bar{a}_{k-1}$, 시점 $k$에는 $a_k$, 그 이후($k+1 \dots K$)에는 치료를 전혀 받지 않는(0) 전략.
  * $(\bar{a}_{k-1}, \underline{0}_k)$: 시점 $k-1$까지는 $\bar{a}_{k-1}$, 그리고 시점 $k$부터 끝까지 치료를 받지 않는 전략.
  * $\gamma_k(\cdot)$: **Blip function**. 과거의 치료 및 공변량 이력 $(\bar{a}_{k-1}, \bar{l}_k)$에 따라 시점 $k$의 치료 효과가 어떻게 달라지는지를 나타내는 함수입니다.

### 2.2. 왜 "Nested"인가?

* 이 모델이 "Nested(중첩)"라고 불리는 이유는 효과를 추정하는 방식이 역순으로 중첩되어 있기 때문입니다.
  * 1.  마지막 시점 $K$에서의 치료 효과를 먼저 고려하고,
  * 2.  그 효과를 제거한 상태에서 $K-1$ 시점의 효과를 고려하는 식으로,
  * 3.  $k=0$이 될 때까지 거슬러 올라갑니다.

## 3. G-estimation Methodology

* G-estimation의 핵심 아이디어는 **"만약 우리가 참(True) 인과 효과 파라미터 $\psi$를 안다면, 관측된 데이터에서 치료의 효과를 제거하여 '치료를 받지 않았을 때의 잠재적 결과'를 복원할 수 있다"**는 것입니다.

### 3.1. Rank-Preserving vs. Mean Models

* 이론적 전개를 위해 먼저 더 강력한 가정인 **Rank-Preserving Model**을 살펴봅시다.
$$
Y_{i}^{a_0, a_1} = Y_{i}^{a_0, 0} + \psi_{11}a_1 + \psi_{12}a_1 L_{1,i} + \dots
$$
* 이 모델은 개별(individual) 수준에서 효과가 결정론적이라고 가정합니다. 하지만 생물학적/사회학적으로 개인 간 이질성(heterogeneity)이 존재하므로 이는 비현실적일 수 있습니다.

* 따라서 우리는 평균적인 효과에 초점을 맞추는 **Mean Model**을 주로 사용하지만, G-estimation의 알고리즘적 절차는 Rank-Preserving Model의 논리를 차용하여 수행됩니다. 놀랍게도 Rank-Preserving Model 하에서 도출된 G-estimator는 Mean Model의 파라미터에 대해서도 일치 추정량(Consistent Estimator)이 됩니다.

### 3.2. Candidate Counterfactuals ($H_k$)

* G-estimation의 핵심 단계는 **Candidate Counterfactual** $H_k(\psi^\dagger)$를 계산하는 것입니다. 이는 임의의 파라미터 값 $\psi^\dagger$를 가정했을 때, 시점 $k$부터의 치료 효과를 제거한 결과값입니다.

$$
H_{k}(\psi^{\dagger}) = Y - \sum_{j=k}^{K} A_{j} \gamma_{j}(\bar{A}_{j-1}, \bar{L}_{j}, \psi^{\dagger})
$$

* 만약 $\psi^\dagger$가 참값($\psi$)과 같다면, $H_k(\psi)$는 시점 $k$ 이후로 치료를 받지 않았을 때의 잠재적 결과 $Y^{\bar{a}_{k-1}, \underline{0}_k}$와 같아야 합니다.

### 3.3. The Estimation Procedure

* 알고리즘의 핵심은 **순차적 교환성(Sequential Exchangeability)** 가정입니다.
즉, 과거의 이력($\bar{L}_k, \bar{A}_{k-1}$)이 주어졌을 때, 시점 $k$의 치료($A_k$)는 잠재적 결과와 독립적이어야 합니다.

$$
Y^{\bar{a}} \perp A_k \mid \bar{L}_k, \bar{A}_{k-1}
$$

* 따라서, 우리가 올바른 $\psi$를 찾았다면, 계산된 $H_k(\psi)$는 $A_k$와 독립이어야 합니다(조건부 독립). 이를 이용해 다음과 같은 절차로 $\beta$(SNMM의 파라미터)를 추정합니다.
  * 1.  **Grid Search / Optimization**: 파라미터 공간 $\psi^\dagger$를 탐색합니다.
  * 2.  **Logistic Regression**: 각 $\psi^\dagger$에 대해 $H_k(\psi^\dagger)$를 공변량으로 포함하여 $A_k$에 대한 로지스틱 회귀를 수행합니다.
      $$
      \text{logit } Pr[A_k=1 \mid H_k(\psi^\dagger), \dots] = \alpha_0 + \alpha_1 H_k(\psi^\dagger) + \alpha_2 W_k
      $$
  * 3.  **Score Test**: 만약 $\psi^\dagger$가 참값이라면, $H_k$는 $A_k$를 예측하는 데 도움이 되지 않아야 하므로 $\alpha_1 = 0$이어야 합니다. 따라서 $\alpha_1=0$이라는 귀무가설에 대한 Score Test를 수행하여 P-value가 1이 되는(혹은 Score statistic이 0이 되는) $\psi^\dagger$를 찾습니다.

![Figure: Flowchart describing the G-estimation algorithm. Steps: 1. Define SNMM structure. 2. Select candidate parameter psi. 3. Compute H(psi) by subtracting effect. 4. Fit treatment model regressing A on H(psi). 5. Check if coefficient of H(psi) is zero. 6. Iterate to find optimal psi.](./images/gestimation_flowchart.png)

> **Figure 2.** G-estimation 알고리즘 순서도. 후보 파라미터를 통해 반사실적 결과를 생성하고, 이를 치료 할당 모델에 투입하여 독립성을 검정하는 반복 과정을 보여줍니다.

## 4. Mathematical Formulation (Closed Form)

* 일반적으로 탐색(search) 방식이 사용되지만, SNMM이 **선형(Linear)** 형태일 경우 닫힌 해(Closed-form solution)가 존재합니다. 이는 계산 비용을 획기적으로 줄여줍니다.

* Technical Point 21.8에 따르면, 선형 모델 $\gamma_k(\cdot) = \beta^T R_k$에 대한 G-estimator $\hat{\beta}$는 다음과 같습니다:

$$
\hat{\beta} = \left\{ \sum_{i, k} A_{i,k} X_{i,k}(\hat{\alpha}) Q_{i,k} S_{i,k}^T \right\}^{-1} \left\{ \sum_{i, k} Y_i X_{i,k}(\hat{\alpha}) Q_{i,k} \right\}
$$

* 여기서:
  * $X_{i,k}(\hat{\alpha}) = A_{i,k} - \text{expit}(\hat{\alpha}^T W_{i,k})$: 치료의 잔차(Residual)
  * $S_{i,k} = \sum_{j=k}^{K} R_{i,j}$: 누적된 공변량 함수
  * $Q_{i,k}$: 효율성을 조절하는 가중치 함수 (Consistency에는 영향 없음)

* 이 수식은 G-estimation이 본질적으로 **"치료의 예측되지 않은 변동(Residual)"과 "결과의 변동" 간의 공분산을 0으로 만드는 작업**임을 수학적으로 보여줍니다.

## 5. From Parameters to Counterfactual Means

* G-estimation을 통해 $\beta$를 구했다면, 이제 특정 치료 전략 $g$ 하에서의 평균 결과값 $E[Y^g]$를 추정할 수 있습니다. 하지만 G-formula와 달리 SNMM은 $E[Y^g]$를 직접 주지 않으므로, **Monte Carlo Simulation**이 필요합니다.

* **Technical Point 21.9 Algorithm:**
* 1.  **Baseline Estimation:** 모든 치료를 받지 않았을 때의 평균 $E[Y^{\bar{0}}]$을 $H_0(\hat{\beta})$의 표본 평균으로 추정합니다.
* 2.  **Covariate Modeling:** 공변량의 분포 $f(l_k \mid \bar{a}_{k-1}, \bar{l}_{k-1})$를 모델링합니다.
* 3.  **Simulation:** 가상의 환자들을 생성하여, 우리가 관심 있는 전략 $g$에 따라 치료를 할당하고 공변량을 생성하면서 시간을 진행시킵니다.
* 4.  **Reconstruction:** 추정된 $\beta$와 시뮬레이션된 이력을 사용하여 각 가상 환자의 잠재적 결과 $Y^g$를 계산하고 평균을 냅니다.

$$
\hat{E}[Y^g] = \hat{E}[Y^{\bar{0}}] + \frac{1}{V} \sum_{v=1}^{V} \sum_{j=0}^{K} a_{v,j} \gamma_j(\bar{a}_{v, j-1}, \bar{l}_{v,j}, \hat{\beta})
$$

## 6. SNMM vs. Marginal Structural Models (MSM)

* Technical Point 21.7은 SNMM과 MSM의 중요한 차이를 설명합니다.
  * **MSM**은 $E[Y^{\bar{a}}]$를 직접 모델링하며, 과거 공변량에 의한 효과 수정(effect modification) 여부에 대해 불가지론적(agnostic)입니다.
  * **SNMM**은 효과 수정 여부를 명시적으로 모델링해야 합니다. 만약 $\gamma_k$가 $L_k$에 의존하지 않는다고 잘못 가정하면 편향(Bias)이 발생할 수 있습니다.
  * **Trade-off:** 하지만 모델이 정확하게 명시된다면, SNMM(G-estimation)은 "과거 공변량에 의한 효과 수정이 없다"는 추가적인 가정을 활용할 수 있어 MSM(IP Weighting)보다 **통계적 효율성(Efficiency)**이 더 높습니다.

---

# 21.5 Censoring is a time-varying treatment

## 1. Introduction: The Reality of Censoring

* 인과추론 연구, 특히 장기간의 추적 관찰이 필요한 연구에서 **중도절단(Censoring)**은 피할 수 없는 문제입니다. 이상적인 상황에서는 모든 연구 대상자의 결과(Outcome)를 관찰할 수 있지만, 실제 데이터에서는 추적 소실(loss to follow-up) 등으로 인해 일부 대상자의 결과가 누락됩니다.

* 앞선 챕터들(Part II)에서는 중도절단을 시점 고정 변수(time-fixed variable) $C$로 단순화하여 다루었습니다. 하지만 현실적으로 중도절단은 연구 기간 중 **언제든지 발생할 수 있는 사건**입니다. 따라서 Hernán & Robins(2020)은 중도절단을 **시변 변수(time-varying variable)** $C_1, C_2, \dots, C_{K+1}$로 확장하여 모델링할 것을 제안합니다.

* 이 포스트에서는 중도절단을 마치 **또 하나의 치료(treatment)**처럼 취급하여, *"아무도 중도절단되지 않았을 때(had nobody been censored)"*의 인과 효과를 추정하는 방법론을 다룹니다.

## 2. Conceptual Framework

### 2.1. Time-Varying Censoring Definition
* 각 시점 $m$에서의 중도절단 지시자(indicator) $C_m$을 다음과 같이 정의합니다:

$$
C_m = \begin{cases} 
0 & \text{if the individual remains uncensored at time } m \\
1 & \text{otherwise (censored)}
\end{cases}
$$

* 중도절단은 **단조적(monotonic)** 특성을 가진 결측 데이터입니다. 즉, 특정 시점에서 중도절단이 발생하면($C_m=1$), 그 이후의 모든 시점에서도 중도절단 상태가 유지됩니다.

$$
\text{If } C_m = 0 \implies C_1 = C_2 = \dots = C_{m-1} = 0
$$

* 또한, 연구 시작 시점에는 모든 대상자가 관찰 가능해야 하므로, 정의상 $C_0=0$입니다.

### 2.2. The Joint Intervention Perspective
* 우리가 추정하고자 하는 인과 효과는 **"특정 치료 전략 $\bar{a}$를 따르고, 동시에 아무도 중도절단되지 않았을 때($\bar{c}=\bar{0}$)"**의 결과입니다.

* 이는 인과추론의 관점에서 볼 때, 치료 변수 $A$와 중도절단 변수 $C$에 대한 **결합 개입(Joint Intervention)** $(\bar{a}, \bar{c}=\bar{0})$의 효과를 추정하는 것과 동일합니다.

$$
E[Y^{\bar{a}, \bar{c}=\bar{0}}]
$$

* 이 값이 식별(identified)되려면, 치료 $A$뿐만 아니라 중도절단 $C$에 대해서도 교환가능성(exchangeability), 일치성(consistency), 양수성(positivity) 가정이 성립해야 합니다.

## 3. Method 1: The G-Formula

* 기존의 G-formula는 중도절단이 없는 이상적인 상황을 가정했습니다. 시변 중도절단이 존재하는 상황에서 Counterfactual Mean $E[Y^{\bar{a}}]$를 추정하기 위해서는, 분석 대상을 **중도절단되지 않은(uncensored) 사람-시점**으로 제한해야 합니다.

* 수정된 G-formula는 다음과 같습니다:

$$
E[Y^{\bar{a}, \bar{c}=\bar{0}}] = \sum_{\bar{l}} E[Y|\bar{C}=\bar{0}, \bar{A}=\bar{a}, \bar{L}=\bar{l}] \prod_{k=0}^{K} f(l_k | c_k=0, \bar{a}_{k-1}, \bar{l}_{k-1})
$$

### 수식 해석
* 1.  **조건부 기대값 $E[Y|\dots]$**: 모든 시점에서 중도절단이 발생하지 않았고($\bar{C}=\bar{0}$), 치료 $\bar{a}$를 받았으며, 공변량 이력이 $\bar{l}$인 집단에서의 결과값입니다.
* 2.  **확률 밀도 곱 $\prod f(\dots)$**: 각 시점 $k$에서 이전까지 중도절단되지 않은($c_k=0$) 생존자들 내에서 공변량 $L_k$가 나타날 확률을 누적합니다.
* 3.  **합 $\sum_{\bar{l}}$**: 모든 가능한 공변량 경로에 대해 가중 평균을 구합니다.

* 이 식은 "모든 개인이 치료 전략 $\bar{a}$를 받고 중도절단되지 않았을 때 관찰되었을 평균 결과"를 나타냅니다.

## 4. Method 2: IP Weighting (Inverse Probability Weighting)

* IP Weighting은 중도절단으로 인한 선택 편향(selection bias)을 보정하기 위해 **가상의 모집단(Pseudo-population)**을 생성하는 방식입니다. 이 가상 모집단에서는 중도절단이 제거되거나(unstabilized), 무작위로 발생(stabilized)합니다.

### 4.1. Non-stabilized IP Weights for Censoring
* 중도절단을 보정하기 위한 가중치 $W^{\bar{C}}$는 다음과 같이 정의됩니다.

$$
W^{\bar{C}} = \prod_{k=1}^{K+1} \frac{1}{Pr(C_k=0 | C_{k-1}=0, \bar{A}_{k-1}, \bar{L}_{k-1})}
$$

* **분모**: 과거의 치료 및 공변량 이력이 주어졌을 때, 현재 시점에서 중도절단되지 않을 확률입니다. 로지스틱 회귀 등을 통해 추정합니다.
* **해석**: 중도절단될 확률이 높은 특성을 가진 사람에게 더 큰 가중치를 부여하여, 중도절단으로 사라진 사람들을 "복제"해 채워 넣는 개념입니다. 결과적으로 가상 모집단에서는 중도절단이 존재하지 않게 됩니다.

### 4.2. Joint Weights (Treatment + Censoring)
* 치료 $A$와 중도절단 $C$를 동시에 보정하기 위해, 두 가중치를 곱하여 사용합니다.

$$
W_{joint} = W^{\bar{A}} \times W^{\bar{C}}
$$

* 이 가중치를 사용하여 결과 변수 $Y$에 대한 회귀분석(예: $E[Y|\bar{A}, \bar{C}=\bar{0}] = \theta_0 + \theta_1 \text{cum}(\bar{A})$)을 수행하면 인과 효과를 추정할 수 있습니다.

### 4.3. Stabilized Weights ($SW^{\bar{C}}$)
* 비안정화 가중치는 가상 모집단의 크기를 팽창시킬 수 있습니다. 이를 방지하기 위해 분자에 주변 확률(marginal probability)을 추가한 안정화 가중치를 사용합니다.

$$
SW^{\bar{C}} = \prod_{k=1}^{K+1} \frac{Pr(C_k=0 | C_{k-1}=0, \bar{A}_{k-1})}{Pr(C_k=0 | C_{k-1}=0, \bar{A}_{k-1}, \bar{L}_{k-1})}
$$

* **분자**: 공변량 $L$을 조건부로 하지 않은, 치료 이력 $\bar{A}$에 따른 중도절단 확률입니다.
* **효과**: 안정화 가중치를 사용한 가상 모집단은 원래 연구 모집단 중 중도절단되지 않은 사람들의 크기와 동일하게 유지됩니다. 여기서 중도절단은 완전히 사라지는 것이 아니라, 공변량 $L$과 무관하게(at random) 발생하게 됩니다.

## 5. Method 3: G-Estimation

* 구조적 중첩 평균 모델(Structural Nested Mean Models)을 이용한 G-estimation을 수행할 때도 중도절단 보정은 필수적입니다.

* 1.  **Step 1 (IPW for Censoring):** 먼저 중도절단에 대한 비안정화 가중치 $W^{\bar{C}}$를 추정합니다.
* 2.  **Step 2 (Pseudo-population):** $W^{\bar{C}}$를 이용해 "아무도 중도절단되지 않은" 가상 모집단을 생성합니다.
* 3.  **Step 3 (G-estimation):** 이 가상 모집단 데이터에 대해 치료 $A$에 대한 G-estimation을 적용합니다.

* 이는 G-estimation 자체가 치료의 효과를 추정하는 데 특화되어 있기 때문에, 데이터 누락(censoring) 문제는 IP Weighting으로 먼저 해결하고 들어가는 전략입니다.

## 6. Extension: Survival Analysis (Technical Point 21.10)

* 결과 변수가 특정 시점의 값($Y$)이 아니라, **사건 발생 시간(Failure time)**인 경우(생존 분석)에도 이 프레임워크를 확장할 수 있습니다.

### 6.1. Hazard Estimation with IP Weights
* 목표는 반사실적 위험(Counterfactual Risk) $Pr[D_{k+1}^{\bar{a}, \bar{c}=\bar{0}} = 1]$을 추정하는 것입니다. 이를 위해 풀링된 로지스틱 회귀(Pooled Logistic Model)를 사용하여 이산형 위험(discrete-time hazards)을 모델링할 수 있습니다.

* 이때 각 개인-시점 데이터에 시변 가중치 $W_k^{\bar{A}} \times W_k^{\bar{C}}$를 적용합니다.
$$
W_k^{\bar{C}} = \prod_{m=1}^{k} \frac{1}{Pr(C_m=0 | \bar{A}_{m-1}, D_{m-1}=C_{m-1}=0, \bar{L}_{m-1})}
$$
  * Note: 생존 분석에서는 이전 시점까지 생존($D_{m-1}=0$)하고 중도절단되지 않은($C_{m-1}=0$) 조건이 추가됩니다.

### 6.2. Causal Graph (DAG) Interpretation

![Figure 21.4: Causal diagram for time-varying treatment and failure time outcome. 화살표는 시간의 흐름에 따른 인과 관계를 나타냅니다. $L_k$는 공변량, $A_k$는 치료, $D_k$는 사건 발생(사망 등)을 의미합니다. $U_k$는 측정되지 않은 교란 요인입니다. 각 시점의 변수는 미래의 모든 변수에 영향을 미칠 수 있습니다.](./images/figure_21_4.png)

* 위 그림(Figure 21.4)은 시변 치료와 실패 시간 결과(Failure time outcome)를 나타내는 인과 다이어그램입니다.
  * $D_k$: 시점 $k$에서의 사건 발생 여부 (1=발생, 0=생존).
  * 이 구조에서 중도절단 $C$까지 고려한다면, IP Weighting을 통해 $L_k$와 $A_k$에서 미래의 $C_m$ ($m>k$)으로 가는 화살표를 제거하는 효과를 얻습니다.

---

# 21.6 The big g-formula

## 1. Introduction: 관측 데이터의 한계를 넘어서

* 우리는 지금까지 인과효과를 식별(Identification)하기 위해 주로 **Sequential Exchangeability (순차적 교환가능성)** 가정을 사용했습니다. 이는 우리가 측정한 공변량(covariates) $\overline{L}$이 교란요인(confounder)을 충분히 통제한다고 가정할 때 유효합니다. 이 경우, 표준적인 **g-formula**를 통해 관측 데이터의 분포만으로 인과효과를 계산할 수 있었습니다.

* 하지만 현실은 복잡합니다. **측정되지 않은 교란요인(Unmeasured Confounders, $\overline{U}$)**이 존재하여 $\overline{L}$만으로는 교환가능성이 성립하지 않는다면 어떻게 해야 할까요?

* 이 포스트에서는 Hernán & Robins의 *What If* Chapter 21.6에서 소개하는 **The Big G-Formula**를 다룹니다. 이는 측정 여부와 관계없이 *모든* 변수를 포함하는 이론적 공식으로, 인과추론의 난제(Front Door Criterion 등)를 해결하는 강력한 수학적 도구로 작동합니다.

## 2. Factuals vs. Counterfactuals

* 본격적인 수식에 앞서, 논문(책)에서 정의하는 변수의 범주를 명확히 할 필요가 있습니다.

* **Observed Variables (관측 변수):** $(\overline{A}, \overline{L}, Y)$ - 우리가 데이터셋에서 실제로 볼 수 있는 값들입니다.
* **Factuals (실제 변수):** $(\overline{A}, \overline{L}, Y, \overline{U})$ - 관측 여부와 상관없이, 실제 세계(Actual World)에 존재하는 모든 변수입니다. 여기서 $\overline{U}$는 데이터 분석에는 사용할 수 없지만 실존하는 변수입니다.
* **Counterfactuals (반사실적 변수):** $Y^{\overline{a}}$ - 특정 치료 전략 $g$ 혹은 $\overline{a}$를 따랐을 때 발생했을 잠재적 결과입니다.

* 저자들은 **Factuals**를 Counterfactuals와 구별하며, Big G-formula는 바로 이 Factuals의 결합 분포에 기반한다고 강조합니다.

## 3. The Big G-Formula의 정의

* 만약 우리가 신(God)의 관점에서 측정되지 않은 변수 $\overline{U}$를 포함한 모든 변수 $\overline{X} = (\overline{L}, \overline{U})$를 관측할 수 있다고 가정해 봅시다.

* 인과적 DAG(Directed Acyclic Graph)의 성질에 따라, 어떤 치료 변수 $A$의 부모(Parents) 변수는 반드시 $\overline{A}$ (과거 치료) 혹은 $\overline{X}$ (모든 공변량) 안에 포함됩니다. 따라서, $\overline{X}$를 조건부로 하면 **항상(Always)** 순차적 교환가능성이 성립합니다.

* 이를 수식으로 표현한 것이 바로 **The Big G-Formula**입니다.

$$
f(y^g) = \int \prod_{k=0}^{K} f(x_k | \overline{x}_{k-1}, \overline{a}_{k-1}) dy d\overline{x}
$$

* 하지만 이 식은 실용적이지 않습니다. 왜냐하면 식 안에 **관측 불가능한 $\overline{U}$**가 포함되어 있기 때문입니다. 그렇다면 이 식은 왜 중요할까요?

> **핵심 질문 (The Mathematical Question):**
>
> "관측되지 않은 변수 $\overline{U}$를 포함하는 Big G-Formula를, DAG의 조건부 독립성(d-separation)만을 이용하여 **오직 관측된 변수 $(\overline{A}, \overline{L}, Y)$만의 함수**로 환원(Reduce)할 수 있는가?"

* 이 질문에 대한 답이 'Yes'라면, 우리는 $\overline{U}$를 측정하지 못해도 인과효과를 식별할 수 있습니다. 이것이 바로 Pearl의 **ID Algorithm**이나 **Front Door Criterion**이 작동하는 원리입니다.

## 4. Case Study: Front Door Criterion

* Big G-Formula가 어떻게 관측 데이터 공식으로 변환되는지 가장 잘 보여주는 예시가 바로 **Front Door Criterion**입니다.

### 4.1. 시나리오 설정

![Figure: Front Door Criterion DAG. A는 치료, Y는 결과, M은 매개변수, U는 A와 Y에 모두 영향을 주는 측정되지 않은 교란요인이다. A에서 Y로 가는 직접 경로는 없고 오직 M을 통해서만 흐른다.](./images/front_door_dag.png)

* 위 그림과 같은 상황을 가정해 봅시다.
  * $A \rightarrow Y$: 직접적인 화살표가 없음 (모든 효과는 $M$을 통함)
  * $U \rightarrow A, U \rightarrow Y$: 측정되지 않은 교란요인 $U$가 존재 ($A$와 $Y$ 사이의 Back-door path가 열려 있음)
  * $A \rightarrow M \rightarrow Y$: $A$의 효과는 $M$을 통해서만 전달됨

* 이 경우 $U$ 때문에 표준적인 G-formula는 사용할 수 없습니다. 하지만 Big G-Formula를 이용해 식별 식을 유도해낼 수 있습니다.

### 4.2. Big G-Formula를 이용한 증명 (Derivation)

* Hernán & Robins는 Technical Point 21.11에서 반사실적 변수($Y^m$)의 존재를 가정하지 않고, 오직 Factuals의 결합 분포와 d-separation만을 이용하여 **Front Door Formula**를 유도합니다.

* **목표:** $P(Y^a = y)$를 관측 데이터 $(A, M, Y)$로 표현하기.

* **Step 1: Big G-Formula 작성**
  * 모든 변수 $(A, M, Y, U)$를 포함한 G-formula는 다음과 같습니다.
$$
P(Y^a = y) = \sum_{m} \sum_{u} P(Y=y | M=m, A=a, U=u) P(M=m | A=a, U=u) P(U=u)
$$

* **Step 2: DAG 구조를 이용한 단순화**
  * DAG($A \rightarrow M \rightarrow Y$, $U \rightarrow A, U \rightarrow Y$)를 보면 다음 조건부 독립성이 성립합니다.
    * 1.  **$M \perp U | A$**: $M$은 $A$에 의해서만 결정되므로 ($U \rightarrow A \rightarrow M$), $A$가 주어지면 $U$와 독립입니다. 따라서 $P(M|A, U) = P(M|A)$.
    * 2.  **$Y \perp A | M, U$**: $A$가 $Y$에 미치는 영향은 $M$에 의해 차단(blocked)되므로, $M$과 $U$를 알면 $Y$는 $A$와 무관합니다. 따라서 $P(Y|M, A, U) = P(Y|M, U)$.

* 이 식을 Step 1에 대입합니다.

$$
= \sum_{m} P(M=m|A=a) \sum_{u} P(Y=y | M=m, U=u) P(U=u)
$$

* **Step 3: U를 제거하기 위한 "Marginalization Trick"**
  * 여기서 천재적인 조작이 들어갑니다. $P(U=u)$를 $A$에 대해 주변화(marginalize)된 형태로 다시 씁니다.
$$
P(U=u) = \sum_{a'} P(U=u | A=a') P(A=a')
$$
* 이를 위 식에 대입합니다.

$$
= \sum_{m} P(M=m|A=a) \sum_{u} P(Y=y | M=m, U=u) \left\{ \sum_{a'} P(U=u | A=a') P(A=a') \right\}
$$

* **Step 4: 식 정리 및 Front Door Formula 도출**
  * 합(Summation)의 순서를 바꿉니다.

$$
= \sum_{m} P(M=m|A=a) \sum_{a'} P(A=a') \underbrace{\left\{ \sum_{u} P(Y=y | M=m, U=u) P(U=u | A=a') \right\}}_{(*)}
$$

* 여기서 $(*)$ 부분을 자세히 봅시다. $M \perp U | A$ (Step 2에서 확인)이므로, $P(U=u|A=a') = P(U=u|M=m, A=a')$로 쓸 수 있습니다. 그렇다면 $(*)$ 부분은 $M, A$가 주어졌을 때 $Y$의 주변 확률이 됩니다.

$$
(*) = \sum_{u} P(Y=y | M=m, A=a', U=u) P(U=u | M=m, A=a') = P(Y=y | M=m, A=a')
$$
  * Note: 위 식 변환에서 $Y \perp A | M, U$ 성질을 사용하여 조건문에 $A=a'$을 추가했습니다.

* **최종 결과:**
$$
P(Y^a = y) = \sum_{m} P(M=m|A=a) \sum_{a'} P(Y=y | M=m, A=a') P(A=a')
$$

* 이것이 바로 우리가 아는 **Front Door Formula**입니다! 놀랍게도 식 안에 $U$는 사라지고 모두 관측 가능한 $(A, M, Y)$만 남았습니다.

## 5. Alternative Proof: SWIGs (Single World Intervention Graphs)

* Technical Point 21.12에서는 **SWIGs**를 이용한 또 다른 증명 방법을 제시합니다. 이 방법은 반사실적 변수들 간의 독립성을 시각적으로 파악하기 용이합니다.

> **SWIG Property:**
> $G^a$ (SWIG) 상에서, 고정된 노드(fixed node) $a$가 공변량 $C^a$를 조건부로 결과 $B^a$와 d-separated 되어 있다면:
> $$P(B^a=b | C^a=c) \text{ does not depend on } a$$
> 즉, $E[Y^a | M^a, A] = E[Y^{a'} | M^{a'}, A]$ 가 성립합니다.

* Front Door Graph의 SWIG에서 $a$에서 $Y^a$로 가는 길은 $M^a$에 의해 막혀있습니다. 따라서 다음 등식이 성립합니다.

$$
E[Y^a | M^a] = \sum_{a'} E[Y^a | M^a, A=a'] P(A=a' | M^a)
$$

* 여기서 $M^a \perp A$ (M은 A의 하류 변수이므로 개입 시 독립) 이므로 $P(A=a'|M^a) = P(A=a')$가 됩니다.
* 또한 SWIG property에 의해 $E[Y^a | M^a, A=a'] = E[Y | M, A=a']$ (Consistency)가 됩니다.

* 결국:
$$
E[Y^a] = \sum_m E[Y^a | M^a=m] P(M^a=m)
$$
$$
= \sum_m \left( \sum_{a'} E[Y | M=m, A=a'] P(A=a') \right) P(M=m | A=a)
$$

* 이 방식은 수식 전개보다 그래프 상의 독립성을 직관적으로 활용한다는 장점이 있습니다.

## 6. Summary & Implications

* 이 챕터가 시사하는 바는 다음과 같습니다.
  * 1.  **일반화된 도구:** Big G-Formula는 관측되지 않은 변수가 있는 상황에서도 인과효과(Counterfactual mean)를 정의하는 가장 일반적인 수학적 틀(Mathematical framework)입니다.
  * 2.  **연결 고리:** Tian & Pearl (2002), Shpitser & Pearl (2006) 등이 정립한 그래프 기반 식별 알고리즘(ID algorithm)이 결국 Big G-Formula를 관측 데이터 분포로 환원하는 과정임을 보여줍니다.
  * 3.  **인과성 vs 수학:** Big G-Formula가 관측 데이터 공식으로 환원될 수 있는지는 **순수하게 수학적인(d-separation) 문제**입니다. 하지만 그 결과가 "인과효과"로 해석되려면, 우리가 그린 **DAG가 실제 인과 관계를 정확히 반영(Causal DAG)**한다는 전제가 필요합니다.